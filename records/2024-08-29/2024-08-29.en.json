[
  {
    "id": 41386319,
    "title": "Air Con: $1697 for an on/off switch",
    "originLink": "https://blog.hopefullyuseful.com/blog/advantage-air-ezone-tablet-diy-repair/",
    "originBody": "Air Con: $1697 for an on/off switch Aug 28, 2024 14 minute read Forcing customers to replace an entire system just because the cheapest component failed might be really profitable, I have no idea… But I do know that it annoyed me enough to make me want to fix it myself. While I understand that what I do next is beyond a large number of Advantage Air customers, in my investigation I found that there seems to be only software choices preventing modern tablets from working with older control systems. Adding a simple “system” chooser to their software applications would give solutions to everyone, while the custom POE connector would ensure they still need their hardware. Aircon Controller My family had a new home built in 2019. As part of the build package a large ducted reverse cycle (heatpump) air conditioning system was installed. As it was part of the entire build I am not sure on the specific price of this system but based on other quotes I have seen for a similar sized house I would guess $10k-$12k. The system has two main parts, the actual Daikin airconditioner and an Advantage Air control box in attic that opens the vents to the various zones. This control system is operated by a cheap POE powered Android tablet on the wall of the living room. The Advantage Air e-zone system is an adequate interface that does its job reasonably well, it has the ability to actively monitor temperature and adjust vent opening angles and fan speed to achieve desired temperatures across multiple zones. This combined with the ability to allow remote control via phone apps from anywhere meant I would have happily recommended this system to anyone. Control Lost On Sunday the 18th of August 2024 approximately 6 months past warranty this changed. The tablet was complaining that “Sorry Google services has stopped”. I dismissed this message and continued with the task I had intended and turned off the heater. Later that day I returned home and went to turn the heater on again, only to find that this time the e-zone app itself had died and refused to launch. I restarted the tablet only to be greeted with a never ending ANDROID loading screen. Being a Sunday the next few hours I researched and tried everything I could find to get this tablet working again. I entered recovery modes both English and Chinese and cleared every setting/partition I could. There was no visible USB interface on the device so I couldn’t connect it to a computer. Clearly there was something wrong with the operating system, a “system integrity check” returned multiple errors. Disappointing Service I called Advantage Air support the next day and waited for a call back. Eventually a support agent called and I explained my problem. One of the first questions I received was on the age of the system. Once he had established it was out of warranty it was explained to me that if the tablet was dead I would need a whole new control system for $1245. When I pushed back complaining that I only needed the cheap tablet replaced I received what sounded like a well rehearsed excuse along the lines of “Well technology keeps moving forward and systems aren’t compatible, new phones come out every year”. I was incredulous, I’m all for smart things, but this is effectively just the on/off switch for my air conditioner. To be clear, the Airconditioner worked fine, the control box worked fine, only the Android tablet had failed. We ended the call with him offering to send me instructions on how to hard reset the tablet. Recovery: System Check Failed Factory recovery menu Very common problem When the instructions arrived I found they were nothing I hadn’t already tried. In the meantime I had my hopes buoyed with evidence of people effectively using the latest tablet models with systems older than mine. This began a series of back and forth emails between myself and support where I would get increasingly frustrated at their complete refusal to sell me a control tablet and the bullshit excuses that always came along with it. I was angry and it is clear that I’m not the only one. The straw that broke the camels back was when their official quote came through. Apparently not only the tablet and control system would need replacing but also the wireless temperature sensors too. This brought the price to $1697. $1697 so I could turn my heater on again. This is frankly outrageous and seems almost predatory. Fortunately it was nearly spring here in Australia, but in Summer people would pay nearly anything to get the aircon on again. Ok I’ll fix it myself I now had an angry fire lit. I was not going to pay this company a cent and became determined to fix/replace their tablet or install another companies system entirely. My first step was to rip the tablet off the wall and take it apart. The POE connection wasn’t something I recognised as standard as it was sending 12V and 2V on the middle pins. Upon opening the tablet I found a hidden USB port! Connecting this to my computer allowed me to charge the device but no matter what I did, fastboot, recovery, adb sideload mode, everything… it wouldn’t recognise it. I initially thought this was due to me never enabling “USB Debugging” inside the android interface but I would later realise it was the POE connector. After a couple of hours of frustratingly trying to load different firmwares via SDCard (I should state I am a total Android noob and was clumsily doing all of this) I finally decided to unscrew the main board and see where the extra wires from the POE connector went. Inside the tablet POE to USB connection found! AHA 3 wires, connected to USB 5V and data lines! The first thing I did was cut those datalines and immediately I could see the tablet when I ran fastboot devicesThis lead to another couple of hours going down the rabbit hole of trying to use mtktool to unlock the bootloader. While it looked promising it would always fail on stage2 what ever that is and did feel hardware related. In retrospect I wasted way too much time trying to resurrect this clearly broken tablet. For whatever reason (I suspect some sort of storage failure) everyone’s tablets die around the same time. When I finally gave up on the existing tablet, everything started falling into place. The only really unique part of this tablet, hardware wise was the POE adapter. I could see it served two functions. First it was wired to replace the battery to allow always on use, and secondly it was a USB device. My first instinct was to go buy another cheap android tablet and wire it up exactly as this one was. But I know next to nothing about circuit boards and my soldering of small components is atrocious. So my second instinct was to wire this POE connector up to a USB-A plug, connect it to my computer (via a hub, I didn’t trust my wiring at all ) then see if I could detect it. I couldn’t detect anything, then realised that maybe it was acting as a host and therefore could only connect to tablets/phones. I needed an Android tablet or phone. Fortunately I remembered that I did have an Android tablet, I won a Samsung Galaxy Tab 4 back in 2015 in a Hahn beer competition I entered randomly. I had no idea where it was so spent another hour turning the house upside down for this forgotten relic. My wife asked me what I was doing and when I told her she nonchalantly said “Oh the white one, yeah I saw it in the laundry cupboard a while back, does it even work?” I had no idea if it worked or not, but after 5 minutes of charging I saw the lock screen and excitedly attached my terribly soldered connector. POE to USB connection First connection attempt Whoa! This was a step forward and also the exact point when I knew my venture would be successful. I am not a hardware/electronics expert, but I am very comfortable in software. The original ezone tablet had been running Android 6.0, this Samsung was still on 5.0 but I didnt think that would cause any issues so I got started on doing what was clearly missing: The required apps. All ezone apps are available both on the Advantage Air website and the apkpure site. I only learned of the apkpure site from a post claiming he had been directed to it by a AA tech support person. I installed two apps. The AAService app, which I guessed was the always on “service” and the Ezone “interface” app. I excitedly connected the poe dongle again: “Not on AA Hardware” Well duh, I didn’t expect it to be THAT easy but it was another roadblock, I would have to learn how to patch Android apps. I cut my teeth on Softice in DOS reversing much more complicated software for fun so I wasn’t daunted by this, but I also wasn’t expecting it to be so damn easy. Android app patching Thanks to this article. I learned that you can use a tool, er… apktool that allows you to not only disassemble an apk into smali ( a kind of Java runtime machine code ) but you can make modifications and run the command in reverse apktool b and it rebuilds it into a runnable app! No need for replacing bytes with a hex editor to stay within bounds etc… lol this seems like magic. $ apktool d app-aaservice2-release-14.116 Copy Cherry on the top is that you can also use a de-compiler JAXE on an apk that does its best to turn it back into Java. This code wont compile, but it has the exact same structure as the smali code. So you can identify what you need to modify in the pseudo-java, then make the changes in the smali. I used the awesome hosted version here. So I opened the decompiled java project in VSCode, then one search for “AA Hardware” and I was here: /* access modifiers changed from: protected */ public void onResume() { super.onResume(); f2272e.set(true); Log.d(f2271d, \"onResume\"); if (ServicePleaseReboot.f2283b.get()) { setContentView(R.layout.reboot_now); e.a((Activity) this); } else if (f.a()) { a(); } else { Log.d(f2271d, \"Not on AA Hardware\"); Toast.makeText(this, R.string.not_on_aa_hardware_error, 1).show(); finish(); } } Copy Excellent, so if f.a() is false then the “Not on AA Hardware” error will display and the app will quit. Following the imports ( I am not a Java person so this caught me out ) I found the f class was this: import b.a.a.a.i; /* compiled from: GetTabletInfo */ class f { static boolean a() { return i.c() || i.d() || i.e() || i.g() || i.f() || i.b(); } } Copy Now if you now go to sources/b/a/a/a/i.java you will find that each one of these is a check against the device Build.MODEL for example i.c() is: public static boolean c() { return a().contains(\"eZone\") || a().contains(\"e-zone\") || a().equals(\"PIC7KS-EZ\") || a().equals(\"PIC7KS6\") || a().equals(\"PIC7KS6-EZ\"); } Copy So each of these i.c() i.d() etc… just feature flag functions checking against the model name. This c() function above is probably named something like isEzone(). Another might be something like isMyAir4() or isZone10() etc… So I had two easy options to make this work with my e-Zone controller box. I could make the i.c() (isEzone()) function always return true, or I could make the a() function always return my old tablet devicename. In retrospect I think the first option would have worked fine, but at the time I didn’t know if the model name was being checked anywhere else so I chose the latter. My old tablet’s model name was on a sticker on the inside of the case, but looking at the code I saw it needed the -EZ identifier tagged to end. So the string I was to return was “PIC7KS6-EZ”. The original Java function looked like this: private static String a() { String str = Build.MODEL; if (str.equals(\"SM-T113\")) { str = \"MyAir5\"; } . . // other if statements overriding Build.MODEL . if (str.equals(\"PIC8GS8\")) { return \"MyAir5\"; } return str; // equals(Ljava/lang/Object;)Z move-result v1 if-eqz v1, :cond_5 goto :goto_0 :cond_5 #move-object v2, v0 # <-- this was return str; const-string v2, \"PIC7KS6-EZ\" # this returning the new string instead :goto_0 return-object v2 .end method Copy Ok modification done time to rebuild it $ apktool b app-aaservice2-release-14.116 Copy Like magic you now have a new apk in the dist folder. This apk is unsigned though so I needed to sign it. I don’t do any android work so I had to google what to do, but I ended up creating a key store like this. $ keytool -genkey -v -keystore my-release-key.jks -keyalg RSA -keysize 2048 -validity 10000 -alias my-android-release Copy Then I signed the apk with this command jarsigner -verbose -sigalg MD5withRSA -digestalg SHA1 -keystore ../my-release-key.jks -storepass passwordiused dist/app-aaservice2-release-14.116.apk my-android-release Copy Then I connected my tablet and tried to install. Only to be hit with INSTALL_FAILED_DUPLICATE_PERMISSION. Turns out this was because I was installing the aaservice app which was requesting the same permissions as the ezone app. This is fine if they are both signed by the same key but they were not. To get things moving I just deleted the ezone app. This time I fired up the aaservice app and it worked! I even got a nice notification announcing “System connected”. OK Great! I had a working service, now only needed the UI app eZone working. I did did the exact same apktool d and JAXE decompile as before but VSCode didn’t find any device strings or “Build.MODEL” checks. I quickly signed the eZone app with the matching key and installed, hoping that it didn’t need any other modifications. Upon opening it seemed to be attempting to connect but ended up returning an error about an un-recognised system. I went back to the decompiled java and realised that actually VSCode’s search was just taking a long time, so I restricted the search to the java files. It didn’t take long to find the exact same device checking code. I made the exact same change to smali/com/air/advantage/w1/k.smali and rebuilt the apk. Installed it, connected to the POE and … E-Zone running on a normal Android tablet E-Zone running perfectly on an ancient Samsung Galaxy Tab 4. I was elated. After I gave up on repairing the original, getting this tablet working took only a few hours and was a hell of a lot of fun. This tablet is 10+ years old and yet still is much snappier than the junk that came with the system, but if I want to upgrade to something more powerful, say to control my homeassistant etc… all I need to do is plug it into the usb. But for turning the AC on and off it is more than enough and I am currently waiting on a nice flush connector to arrive then will mount it on the wall. My aircon company (Not Advantage Air) kindly emailed me the next day to let me know that one of their installers had found an old tablet in the back of a van that I could purchase for $400. Although still outrageously expensive for what it is, had Advantage Air offered this originally I probably would have jumped at it. Instead I am thankful I had the opportunity to get this working on my own. Hopefully this post is useful to someone else in the same situation. None of this can be done without the original POE connector so it won’t help anyone that doesn’t already have AA hardware, but if this extremely common tablet failure is the problem you are facing then a little soldering and a new tablet is all you need. Followup This post is being discussed on Hacker News which sparked some great comments like this one from gstar who lives in the same city and was working on the same problem: The system uses RS422, with a base64 encoded AES key in the aaservice binary, and I was contemplating building an esp32 based open source implementation of the controller…Incidentally, if you root your tablet you can just change the build.MODEL to “MyAir5” and everything will work on a third party tablet…Oh, and you just need one of these and a TTL to RS422 converter off aliexpress to replicate the interface: https://www.aliexpress.com/item/1005005918675239.html The connectors on the small RJ45 daughter board are JST-SH 1.0 The yellow lead puts out 4.2v to replicate a Li-Ion battery (as far as I can tell). You can ignore this. Red is positive Black is negative Green is usb d+ Blue is usb d- ― gstar, Hacker News Comment",
    "commentLink": "https://news.ycombinator.com/item?id=41386319",
    "commentBody": "Air Con: $1697 for an on/off switch (hopefullyuseful.com)1637 points by ranebo 17 hours agohidepastfavorite420 comments gstar 15 hours agoOMFG; I am in Perth, I have the same system, the very same problem and solved it almost the same way and was in the process of writing it up. The system uses RS422, with a base64 encoded AES key in the aaservice binary, and I was contemplating building an esp32 based open source implementation of the controller. That's a crazy weird coincidence. reply gstar 15 hours agoparentIncidentally, if you root your tablet you can just change the build.MODEL to \"MyAir5\" and everything will work on a third party tablet. reply gstar 15 hours agorootparentOh, and you just need one of these and a TTL to RS422 converter off aliexpress to replicate the interface: https://www.aliexpress.com/item/1005005918675239.html The connectors on the small RJ45 daughter board are JST-SH 1.0 The yellow lead puts out 4.2v to replicate a Li-Ion battery (as far as I can tell). You can ignore this. Red is positive Black is negative Green is usb d+ Blue is usb d- reply ranebo 14 hours agorootparentThis is all fantastic info. I have included the details and a link to these comments at the bottom of the post. Great work! reply lucioperca 9 hours agorootparentTip: Instead of soldering I use splicing connectors with levers for testing stuff like this out. For example: https://www.wago.com/de-en/c/installation-terminal-blocks-an... reply dt3ft 7 hours agorootparentWago has great stuff. reply saylisteins 10 hours agorootparentprevTiny QOL change without too much work, you could install something like teamviewer on the tablet, and now you're able to control your AC remotely from your PC, your phone, or anywhere! reply selcuka 8 hours agorootparentThe MyAir (or e-Zone) app can already be accessed remotely. You install the app on your phone and pair it with your system by connecting to the same LAN. After the initial pairing it can be used from everywhere. reply emilfihlman 8 hours agorootparentUsing which reverse service, though? reply selcuka 8 hours agorootparentFrom memory it connects to Firebase, possibly using the Realtime Database to sync state. reply Nursie 12 hours agorootparentprevHey - As the owner of a similar system I have a question for you - do you use their phone app to control your system from your phone in/out of the house, and did it still work after this? reply ranebo 11 hours agorootparentI use the home assistant plugin with it personally, but I have tried the apps and they still work fine both locally and remote. reply Nursie 11 hours agorootparentCool, that's all I needed to know, I'll be following in your footsteps at some point, thanks for taking the leap and doing all this :) Now back to connecting an orange-pi zero to the petcube cam someone bought me for Christmas. I've found TTL pins on there and I want to know what's going on... reply nehz 12 hours agorootparentprevWould you have the RJ45 pinout too? Thanks! reply FLT8 9 hours agorootparentThis is from my earlier notes, hope it helps some. Pin 1: RS422 +/B Pin 2: RS422 -/A Pin 3: ? - appears to be unused; connected to unpopulated pad on PCB Pin 4: GND Pin 5: ~14.2v DC unloaded Pin 6: GND Pin 7: ? Pin 8: ? Shield: GND Note: the RS422 protocol has a basic bus arbitration built-in to allow both ends to communicate. The control unit sends Ping messages, after which it opens a slot for the Tablet to communicate back to it. At least on my system xx represents a simple CRC value that can be used to validate message authenticity. I haven't seen any AES encryption in use, messages I've seen are all plaintext, maybe the AES encryption was introduced in a later revision. reply binary_slinger 8 hours agorootparentWouldn't RS422 need 2 TX and 2 RX? reply upofadown 7 hours agorootparentNormally, yes. Perhaps this could be more properly termed RS-485 operating in 2 wire (half duplex) mode: * https://en.wikipedia.org/wiki/RS-485 reply gstar 7 hours agorootparentprevI have something slightly different 1 is RS422 B 2 is RS422 A 3 & 5 - GND 4 & 6 - VCC Not sure what 7 and 8 do. reply FLT8 6 hours agorootparentInteresting, not sure what's going on there then.. how recently was your system installed? Maybe they have updated the pinout on newer models? I'll go back and check though. reply gstar 5 hours agorootparentYou're right! The serial bus isn't encrypted! I got inspired, and have plugged in my scope, and then an RS422 to serial adapter, and I'm getting XML encoded (weird) CAN messages, which I presume are the same as what's on the CAN bus exposed on some of the control box's ports. I'll get out the can analyser tomorrow and check. Now the trick will be to reverse engineer this protocol. Here's a tiny sample: setCAN 0201000000236000000000000 getCAN 1 Ping ackCAN 1Ping setCAN getCAN 1 Ping ackCAN 1Ping setCAN getCAN 1 Ping ackCAN 1Ping setCAN getCAN 1 Ping ackCAN 1Ping setCAN getCAN 1 Ping ackCAN 1Ping reply FLT8 14 minutes agorootparentI have reached out to your email address (as described in your profile) with some additional information that I've been putting together. Let me know if you didn't receive my mail. nehz 4 hours agorootparentprevThe AES encryption might be related to the android intent messages that are sent to the AAservice. I recall they had an encrypted mode and a \"signed app\" mode that AAservice will respond to reply gstar 7 hours agorootparentprevNot always - if it's used as a bus, it's 2 wire. reply gstar 12 hours agorootparentprevNo, sorry - I may be able to buzz one out of the a/c controller later on. I do, have 2 spare USB-C to JST-SH adapters that suit the round advantage air circuit board if anyone wants one (Perth, Free). Email in profile. reply thrtythreeforty 14 hours agoparentprevWhat the hell, why does a control system need an AES-secured control channel at all? The only possible intention is to make interop more difficult. If they wanted security then they wouldn't use a hard coded AES key. reply gstar 14 hours agorootparentIt 100% is designed so that you have to use their hardware. reply cameldrv 2 hours agorootparentThe biggest maker of garage door openers in the U.S. has done the same thing. For a button that goes on the wall to open the door, now it sends an encrypted code instead of just shorting two wires so that you have to use their button instead of a regular doorbell button like people have been doing for decades. reply spikej 2 hours agorootparentWhich company, and which product did you see this with? reply coupdejarnac 44 minutes agorootparentChamberlain devices do this. Genie devices do not. reply Liquix 13 hours agorootparentprevso if the company has established they're willing to go that far to lock customers into their ecosystem and milk for $$$... it's not inconceivable that they also engineered (or chose not to fix) the cheap flash + chatty logging hardware failure for the same purpose. reply raxxorraxor 4 hours agorootparentI would switch brands instantly. This is a company that has no customer orientation and I have never seen a company recover from that (they might have financial success, but they will never create good products again). They probably will sell you expensive crap. This time the device was fixable, but the manufacturer worked against the user on that. reply tracker1 1 hour agorootparentSo, you'd rather spend $12k+ to replace the entire system just to spite the manufacturer over making a minor patch to support a new tablet yourself? reply yuye 12 hours agorootparentprevSeems those tablets die not long after the warranty expires. I'm willing to bet money on that it's planned obsolescence, especially considering their \"technology keeps moving forward\" bullshit. reply zeroflow 11 hours agorootparentI'm offering you a different viewpoint: They made the analysis, how long the flash will live and saw, that it will make it out of the warranty period. Thus they did not opt for more durable and expensive flash and/or software change. I've seen this myself before. One process step before release of the control module was a write cycle analysis to make sure the unit will live for at least 10 years (i think) before the guaranteed write cycles of the flash memory were consumed. reply audunw 11 hours agorootparentYou're both missing one of the more likely explanation.. that nobody gave much thought about how long the device would last. \"It's solid state electronics, it'll probably outlast the warranty anyway\".. I can imagine an aircon company puts a lot of effort into analyzing the air-conditioning unit itself to make sure it lasts at least as long as the warranty, with good margin. But I can totally see them winging it on an external control device, which was perhaps even a project they outsourced anyway. I don't think actual malicious planned obsolescence is as prevalent as many believe. A device breaking right after warranty is not a good strategy to get repeat customers. It's also a huge risk if you miscalculated and you suddenly get a lot of warranty cases. You want a lot of margin there. I've been involved in the design of a thing myself, where something the manufacturer hadn't clearly communicated - and we just barely caught - could have made the device die just around a typical warranty period for such a device. When we found out, of course we worked on this problem to make sure it didn't die prematurely. reply yuye 10 hours agorootparentAdvantage Air doesn't produce ACs. They produce smart home solutions, including AC controllers. They're not winging it on an external control device, they're cheaping out on their main product. Also, their claim is that they're not outsourcing. If you check their website, it claims everything is designed and manufactured in Australia. Nevertheless, I'd have given them the benefit of the doubt if it were not for: 1. The only option being a full system replacement. 2. Communication protocol being encrypted. 3. App being locked down to certain hard-coded models. None of these give me any hope that this is a well-meaning company that just has some issues. Also, I think a company that sells a product most customers would only buy once or twice in their lives is not a company that expects many repeat customers. reply michaelt 10 hours agorootparent> Also, their claim is that they're not outsourcing. If you check their website, it claims everything is designed and manufactured in Australia. Looking at pictures like [1] and [2] I suppose it's possible they're making their own generic android tablet control panel, designed and manufactured in Australia and they just happened to add a camera, side-mounted USB charging connector, a headphone socket, microsd card slot, and a battery charge level indicator, loads of space for a battery that isn't present, a connector named VBAT and also a chinese-language bootloader but accidentally forgot to include the power and data connector they need, poking out the back of the device so they had someone bodge it on afterwards by hand with a soldering iron but IMHO it's more likely they mean \"manufactured in Australia from components sourced internationally\" and one of those components is a generic android tablet. [1] https://www.myplacenz.co.nz/are-you-making-the-most-of-your-... [2] https://blog.hopefullyuseful.com/blog/advantage-air-ezone-ta... reply yuye 9 hours agorootparentShould've added a bit more snark to that line to properly communicate that I absolutely don't believe their claims that everything is designed/made in Australia. It's very obvious they just went for the cheapest bottom-of-the-barrel tablet Alibaba has to offer on one of their main products. I wouldn't trust this company to do anything competently. reply VBprogrammer 7 hours agorootparentprevLocking in the model numbers for me is particularly icky. They are leveraging the Android and therefore Linux and open source communities efforts to make this custom display which would have cost them an arm and a leg to have custom built with half the features - then turning around and sticking two fingers up at those communities. reply jerf 6 hours agorootparentprevI generally treat my tablets and phones very well. I wouldn't trust a tablet, at scale, to last much beyond three years. By \"at scale\" that means, say, a replacement rate of less than 10%. By contrast ACs are on the decadal scale. Integrating a tablet can't work. It's a dumb idea from the outset. Similar hardware can work. There are touchscreen UIs that do last for a long time, especially on an AC unit where they're not getting used all the time. But they aren't tablets. In particular I'd finger the lithium ion batteries optimized for tablet-style usage as something you don't put into a system you want to last about ten years. Most of my tablets \"die\" when the battery just becomes unusable. And you probably want an LCD chosen for robustness rather than being the cheapest possible high resolution display... again, plenty of LCDs can last for a long time, but the trifecta of \"high resolution\", \"cheap\", and \"lasts a long time\" is asking an awful lot for a fleet of systems. (\"Cheap\" and \"lasts a long time\" is, by contrast, readily available; it just won't be pretty. But it'll work fine.) And by \"high resolution\" I don't mean \"retina display\", just anything suitable for a tablet. Ye Olde 640x480 is plenty for an AC display, even in monochrome. You want something pretty, give it a way for a real app to access it on the network. Except don't bother, really, because there's no way you're going to maintain that for 10 years either. reply Sohcahtoa82 1 hour agorootparentprev> I don't think actual malicious planned obsolescence is as prevalent as many believe. I've been saying this for a while. Consumers are insanely price-sensitive while also short-sighted. They'll buy a $20 blender that will die in a year rather than the $100 blender that will last a lifetime. Manufacturers know this and there's a race to the bottom on pricing. To get pricing as low as possible, quality and durability take a hit. reply fmbb 9 hours agorootparentprevNever attribute to laziness or stupidity that which is adequately explained by the profit motive. reply oefrha 7 hours agorootparentHaving worked with clients who apparently have little clue about technical details of what’s supposed to be their core tech, I’ll attribute to laziness or stupidity unless there’s ample evidence suggesting otherwise. reply Workaccount2 4 hours agorootparentprev>I don't think actual malicious planned obsolescence is as prevalent as many believe. Working in the electronics industry, I have never once heard anyone talk about this. Engineers love engineering, and if it was real their would be a whole field devoted to it. But there isn't. Also, since this board is stacked with software guys... Planned obsolescence is way easier to implement in software. How many of you have been asked to put a time bomb in a warrantied product? Planned obsolescence is a term that lay people use to describe unfortunate breaking of things that are sufficiently complex to be considered \"a magical black box\". In reality it is just another apparition of Murphy's law. reply WhyNotHugo 2 hours agorootparentprevIn other words, _Never attribute to malice that which is adequately explained by stupidity._ This device should not need to write to storage. It has to save settings when the user manually changes them, which can't be more than a few kilobytes per year. Any other writes are likely an oversight on the developer's part. reply yuye 11 hours agorootparentprev>Thus they did not opt for more durable and expensive flash and/or software change. Opting out of a more durable solution when you know the device will break right after warranty is still planned obsolescence. reply muppetman 11 hours agorootparentprevIsn't that kinda the definition of planned obselence? You plan so that past you point you have to care, it could well die/become useless? reply TeMPOraL 10 hours agorootparentPlanned obsolescence is when you purposefully design it to fail as soon as possible (but past any warranty period), to force repeat purchase. reply nikau 9 hours agorootparentprevI'd guess they just didn't think of flash wear, like Tesla did in the early model s , and they got lucky they failed outside the warranty period. reply foobarian 6 hours agorootparentEverybody forgets the noatime thing at least once in their career reply datavirtue 5 hours agorootparentprevCompanies don't encrypt anything unless required. Except for code and databases...they encrypt and obfuscate those to keep people running back to them. Source: my customers reply marcus0x62 6 hours agorootparentprevAnti circumvention laws don’t require good locks to provide the manufacturers a legal cudgel to use against anyone with the temerity to think they have the right to use and fix things they have paid for. The law (DMCA in the US, it looks like something called the Digital Agenda Act in Australia) is the real lock, not that AES key. reply rpearce9 10 hours agoparentprevIn case it's helpful to anyone, I put this together to drive our Advantage Air system: https://git.nethack.net/rob/aircon Essentially it just talks to the android tablet API to do things so it's no help if (when) the tablet dies, but it means I can do things like: - have the entire unit turn on/off as needed based on average zone temperatures - open/close vents based on room owners' devices being online, or temperatures of nearby zones - dump zone temperatures to influxdb reply lelandfe 3 hours agorootparentNice use of Telegram as a cheap logging tool reply FLT8 13 hours agoparentprevI've got one of these systems too. Mine hasn't died yet, touch wood, but I was concerned enough about the possibility that I went as far as documenting the comms protocol and starting to design a pi hat to talk to the main control board. I should really write that up at some point too. reply jamesholden 11 hours agorootparentDo it! I don't live in Australia or have on of these systems, but I was intrigued by how the OP had gone around the company to save themselves 1500! I'm curious to see how people are resolving things like this, so that if I have issues myself sometime, I have ideas on where to start or what is necessary :) reply virtue3 14 hours agoparentprevsounds like the memory storage is failing on some sort of logging systems for these to be going down at the same time-ish (same number of logs per day written etc over cheap flash). Shame on this manufacturer. reply sumtechguy 4 hours agorootparentIt is a conversation I have had with many a jr dev. 'ok you are logging this how much space is that going to take? how long do you want to keep it? what is your rotation schedule?' I usually get the 'oh did not think of that' because logging is a serious afterthought in many cases. It is boring and you just drop in log4j and log away right? reply radicalbyte 12 hours agoparentprevReading the original post, wouldn't be a super cool idea to make a little ESP or RPI based system which acted as a controller for the airco and a network bridge? Then literally anything could interface with it. You wouldn't even need to wire it up. No need to install some shitty app from a company who are quite clearly c*ts. reply squarefoot 9 hours agorootparentI'm sure that they made things more difficult by employing proprietary hardware wherever they can (also to discourage competition), but yes, there are a bunch of sensors and actuators in there and any board with the appropriate i/o capabilities should be able to interface to them, however writing a working firmware would be next to a nightmare: how do you find developers who want to spend months reverse engineering an AC and also know enough about ACs to put together something that works? Replacing household appliances brains with open counterparts would be a heck of a business opportunity to revive or prolong the life of dead/obsolete products, however I guess finding people who are interested enough to do that with FOSS, essentially selling only hardware and installation services would be really hard. reply datavirtue 4 hours agorootparentIt's just a pin out interface controlled via software to turn things on or off. Its trivial. Get a raspberry pie, lookup the pinout docs stuffed away in your home manuals drawer, and write the measly logic required. The most difficult part is whipping up a UI and building the scheduling logic, if want/need it. reply stavros 9 hours agorootparentprevWhat evidence do you have that the company is composed of cats? reply selcuka 9 hours agorootparentBecause cats love warm houses. reply dbetteridge 14 hours agoparentprevFor a small place there's a lot of sandgropers on HN somehow reply marcus_holmes 14 hours agorootparentTimezone effect, I think. Just us and the whole of East Asia online now. The Poms and Europeans are just about to wake up, and the Americans have logged off for the night. reply yuye 12 hours agorootparentIt's a nice and quiet time. Why do work when you can read HN? Hi from east Asia! reply iknowstuff 12 hours agorootparentprevBarely 11PM in California, prime reading time reply radicalbyte 11 hours agorootparentIt's that golden hour where AU/NZ are up, Californian nerds are up and chilling and EU/UK are getting their first (or second) dose of caffeine. Just missing our East-Coast buddies :-) reply imp0cat 13 hours agorootparentprevThis is exactly right! Good morning from Europe. :) Also congrats to the OP! Sadly, european aircon appliances are usually built the same way (last only as long as the warranty). reply Cthulhu_ 10 hours agorootparentAt least there's EU legislation that's slowly improving as well ensuring longer term warranties and the like. I hope that for household appliances like aircon or solar panels this warranty or support is set to its expected lifetime of 15-20 years. In this case, it should be mandatory that the control system can be easily swapped out by an aftermarket replacement, just like central heating thermostats are. (in fact, replacing basic central heating thermostats with a tablet device has been very successful for one energy company in my country, see https://www.eneco.nl/energieproducten/toon-thermostaat/; it wouldn't have been possible if the thermostat data thing was some complicated / encrypted nonsense) reply prmoustache 9 hours agorootparentprevMy own aircons are just simple individual items that are interchangeable between rooms. There is no single control for the whole house but on the other hand I never let it run when I am away and I am never in 2 rooms at the same time so I just close the door so I only have to keep one room cool. I fail to see the need of an aircon I could control remotely with a smartphone or any smart bullshit system that control every room at the same time. And I think if I ever needed that I would probably just control the individual aircon via small esp32 with irtransmitter driven by a home server. That way the individual remotes would still be usable in case of an individual failure. reply pimeys 4 hours agorootparentI have two separate aircons in our apartment. They both plugin to the wifi and I can control them locally from my home assistant instance. When hass detects nobody is at home, it will just automatically turn off both aircons with all the lights. It is also handy if it is extremely hot like now and we're both out to monitor if it gets over 30 inside, so we can remotely get it cooler so the plants, cats or server will not suffer too much. reply TechDebtDevin 14 hours agorootparentprevFor those also wondering: https://www.quora.com/Why-are-West-Australians-called-sandgr... reply gstar 13 hours agorootparentprevSpeaking of sandgropers, I do understand Advantage Air are based in WA - so it's fairly likely they're reading this! reply TeMPOraL 12 hours agorootparentHopefully. Shame on them. Also, good morning from Poland, EU :). reply ranebo 15 hours agoparentprevOh wow, that is crazy! That sounds awesome so please still write it up and I will link. myreal.name@gmail reply ivraatiems 14 hours agoparentprevAlmost like all the tablets fail around the same time because they're made in the same shoddy way, forcing system replacements every so many years... reply Cthulhu_ 10 hours agorootparentThey skimped on the tablet, grabbing aYou have no idea how true this is :). I had to upgrade everything, the old site didn't even have SSL. But this annoyed me so much I wanted others to know how to fix it. People like you are the ones that make the internet worth logging on for. reply anfilt 14 hours agorootparentprevGlad you did! Nice read as well. reply dclowd9901 13 hours agoparentprevI made my daughter’s bed from scratch out of anger and spite toward IKEA. reply jamesholden 11 hours agorootparentI have some freak brain (and IKEA experience) which usually let's me do IKEA pretty well. What was it that happened in your case? I'm curious what brought you to that point. reply yurishimo 7 hours agorootparentMaybe they moved? In my experience, IKEA furniture that isn't solid wood (more and more of it is heading that direction to their credit) tends to not make it more than 1 move. I just got done (mostly) reassembling a wardrobe. It's a bit more wobbly around the edges. I'm not sure if it's because I didn't put the shelves back in the exact spots (wasn't thinking and didn't label them during disassembly) or if it's something else, but once we decide it's not good enough for the room upstairs where it now lives, it's getting put in the dumpster. reply lolinder 6 hours agorootparentI tend to assume that IKEA furniture shouldn't be actually taken apart once put together, and so far that's worked out fine for us. There are some pieces that are obviously repeatable (table legs screwed into metal mounting brackets) but with a lot of the steps you can feel as you're doing it the first time that it's not going to work well if you have to undo it. reply dfox 22 minutes agorootparentIIRC when we wanted to move one of the pretty large IKEA dressers that had to be at least partially disassembled to fit through the door there was no non-destructive way to dismantle it. And that was not about trivial things like the back panel being nailed, but about fasteners of the actual structural parts being inaccessible once you put the whole thing together. One would think that going through the assembly steps in reverse should work, but for some reason it did not. I ended up breaking few structural braces (~18x48mm pieces of fiberboard) at the back of the thing to take it apart and replacing that with wooden beams of the same size. reply abanana 5 hours agorootparentprevTrue. Adding a few 2\" screws (into pilot holes) makes an enormous difference to the rigidity of their (e.g.) wardrobes and kitchen units. Even on first assembly, but especially if you have to take apart and rebuild. reply consteval 4 hours agorootparentprevThis \"trend\" of furniture being made of composite materials makes no sense to me. They're obviously so much weaker. I've had nightstands that sway like a tree in the summer breeze. Furniture today though doesn't feel much cheaper. Even the \"luxury\" brands these days, who charge big bucks, sneak in composite. reply tracker1 1 hour agorootparentIt depends, a lot of composite materials are actually stronger than just solid wood, while being lighter and easier to move. Sometimes there are too many shortcuts though. Wood veneer over cheaper materials has been common for over a century at this point though. reply michaelt 3 hours agorootparentprev>This \"trend\" of furniture being made of composite materials makes no sense to me. Solid wood is expensive, in a lot of the world. And for furniture, you can't do a good job with cheap wood - if it twists or bows the doors won't close right, or the drawer will be tight. Need a hole in a particular position, but there's a knot? You're going to have a bad time. Wood with loads of knots doesn't look great. And of course, some types of wood cost a lot more than others. Chipboard with veneer, though? It's super cheap. You can have any colour you like. It machines consistently, with no knots or checks like that. The response to temperature and humidity is even and consistent. If you need more strength, you can just order thicker boards. Sure, you can't leave it outside in the rain - but so what? The main downside to flat pack furniture is a lot of people don't manage to assemble it right. A nightstand will end up in an awful state if the person who assembled it forgot to nail the back on properly, or used a short screw where a long screw was called for, or put a part in the wrong way around. reply FridayoLeary 2 hours agorootparentprevIt does make the furniture much lighter and therefore easier to move. I once had to move a plywood dresser and it was an experience i'd rather not repeat. Light furniture on the other hand is a pleasure to work with. reply datavirtue 3 hours agorootparentprevI bought a bed that when built according to instructions would end up broken. I tried to blame my son, then I dug in on the details. Absolute garbage. Through it in the box,sort of, hauled it back in and demanded my money back. While I was waiting in line I was staring at signs exclaiming the policy about no refunds. Dude saw the look on my face and didn't say one word, just gave me money back. I ordered a replacement from Amazon made out of steel. reply unkulunkulu 12 hours agorootparentprevIKEA? Thats a surprise, what happened? reply bityard 2 hours agorootparentSome IKEA furniture is great, some of it is terrible. 10-15 years ago, it was where you'd go when you needed a great-looking nightstand or coffee table for a fair price and didn't overly care how long it would last. These days, you can expect to pay a premium for the \"IKEA aesthetic\" and shopping experience. Personally, the main thing I can't stand is that you have only limited ability to \"choose your own adventure\" and just go straight to the thing you're there to buy. I don't want to spend 25 minutes wandering through their corporate-curated displays to get to the kitchen faucets. I think they still have a good price on AA NiMH batteries, though. Edit: I am speaking to the US stores, I have no idea what IKEA is like closer to their homeland. reply margalabargala 2 hours agorootparentprevThey probably noticed the material quality. reply reaperducer 2 hours agorootparentprevI made my daughter’s bed from scratch out of anger and spite toward IKEA. I would have used wood and nails. You must have terrifically strong emotions! reply bitcharmer 10 hours agoparentprevI love it too but this only becomes worthwhile if you manage to promote this post in social media somewhere. If you don't already have a strong social media presence or don't personally know anyone who does you can forget about it. And here on HN you really have to get lucky, post at the right time and hope the flagging gangs don't get you. reply JohnFen 3 hours agorootparentI could not disagree more. This sort of thing is a public service. Even if only a dozen people find it valuable, it can be exceedingly valuable to them. It's worth putting this sort of thing on your website for that reason alone. reply Cerium 2 hours agorootparentIn complete agreement, I will add an anecdote from my experience: I have a tiny hardly updated blog where I post stuff I do and assume nobody at all will ever read it. A month ago I got an email from somebody asking about a detail because her granddaughter's toy has the same problem that my daughter's did. It is so rewarding that some work I did for myself can continue to have value for people across the world. reply Etheryte 8 hours agorootparentprevThis is only the case if you blog for social media clicks and likes. Most people who write blogs don't do it for that reason. reply paranoidrobot 14 hours agoprevI installed AC in my home in the last year. I specifically went for units that were IR controlled rather than any proprietary smart B.S. For the smarts, I used cheap IR blasters from AliExpress and hooked them up to HomeAssistant. I just mounted cheap Lenovo tablets to the wall to do the room-dashboard thing to allow controlling lights/AC without a phone. These kind of horror stories only serve to reinforce my decision. reply e44858 3 hours agoparentSome units have a 5V UART port that's easy to connect to HomeAssistant and has two-way communication: https://static.xtremeownage.com/blog/2023/pioneer-mini-split... reply ryankshaw 1 hour agorootparentI did something very similar with my Pioneer minisplit. but i used this esp module you can just buy. Super simple and cheap: https://smartlight.me/smart-home-devices/wifi-devices/wifi-d... https://www.youtube.com/watch?v=f6GEfzVhwCE reply athrun 13 hours agoparentprevI was thinking of doing the same but IR control only allows for unidirectional communication with the unit. Since there's no feedback mechanism, how do you solve for when the state of the unit(s) gets out of sync with HomeAssistant's? reply paranoidrobot 25 minutes agorootparentFor me the only way it can get out of sync is from power failure in the AC, or someone using the remote. Putting the remote away solves the last. I have Zigbee contact sensors that provide on/off feedback to HA by detecting if the louvers are open. reply klausa 13 hours agorootparentprev(not OP) It just doesn't matter that much in my experience. If an issued command didn't work, it's easy to tell anyway (it's hot/cold), and you can just repeat it. HomeAssistant also has bits of special handling for items that don't communicate their state back, called \"assumed state\". For the rare times I want to control my AC when being away from home, I have an air monitor nearby. I can just check if the temperature/humidity has changed, and repeat the command if it didn't work. If you _really_ cared you probably could script it to do it automagically, but I didn't feel the need to bother. reply nucleardog 3 hours agorootparentYeah there’s very few edge cases, imo, where you need the feedback. I have home assistant controlling an air conditioner in one room. (Well, mostly Node-RED.) Every couple minutes it checks the temperature in the room and makes a decision on whether to call for cooling and tells the AC to turn on or off. If it’s already on and cooling and it tells it to turn on… it’s a no-op, nothing happens. If it tells it to turn on and the command doesn’t go through… the room will stay warm so it will try the same thing in a couple of minutes. Same thing the other way (turning it off). reply mianos 10 hours agorootparentprevThe remote has no feedback. I have found Tasmota IR 100% reliable over 3 years. It sends the whole state on every transmission so the IR has no receiver. https://tasmota.github.io/docs/Tasmota-IR/#sending-ir-comman... reply prmoustache 9 hours agorootparentprevAC is typically something you only need when you are inside the house so it is not like any freak situation would occur. If it happens only super occasionnally at worse you just set it the homeassistant state using the remote manually. I guess you should hide those remote in a drawer and remove the batteries when you start using homeassistant reply Krssst 12 hours agorootparentprevIf the message sent over IR always contains the full state, then it's only a matter of checking that the message was received. If you are in the room, you'll know soon enough, otherwise I guess it could be possible to rely on the audio feedback (a light beep) that the AC probably emits when it successfully receives a command. (and add a temperature sensor to check that it's working properly) reply skykooler 12 hours agorootparentNot all state is necessarily transmitted over IR. For example, my unit has a button on the remote to turn the LED on or off; over the air this is just a toggle, only the AC knows which state the LED is in. (That said, that particular issue is easy enough to handle since changing any other parameter turns the LED back on, putting it back in a known state; there's no way to keep it off.) reply ThatPlayer 12 hours agorootparentprevSimilar problem here. I've thought of getting IR receivers to also listen for the remote's IR signal, since you have to be able to encode the IR protocol anyways. But even then sometimes the AC unit doesn't get the signal from my remote, so I'm unsure if that's a remote issue or receiver issue. The completely overkill setup would be to get a different remote control, get my DIY receiver to accept that and convert it to my AC unit's IR code, updating HA while at it. The remote's state would be out of sync still, but it'll keep the units in sync with HA. reply mianos 10 hours agoparentprevI got the Daikin for the same reason. You have to pay extra for a wifi module but after reading the reviews on their app, they mostly said, it kinda worked but largely useless. I built an esp32 IR sender and put Tasmota IR on it. It has first class support for the Daikin. It can't receive but it seems no need as it's 100% reliable. reply rlpb 8 hours agorootparentFor Daikin, https://github.com/revk/ESP32-Faikin works well, and is tidier (and I think more featureful?) than an external IR port. Its existence is why I bought a Daikin! reply connicpu 3 hours agoparentprevI also just got AC last year, and while it doesn't have as many fancy features I'm glad I got one that works with standard 24V HVAC wiring. I built my own thermostat out of an ESP8266, I²C temperature sensor from adafruit, and three TRIAC circuits to control the fan, heat, and ac wires. Connected to MQTT and I can send control commands to it from my Home Assistant instance! reply bityard 2 hours agorootparentIf you have the code for this publicly (or would consider making it so) I would be quite interested in it. There are a fair number of DIY thermostat projects online, but all that I have found were one-offs by their creators, or were for specific kinds of systems like boilers. I've been batting around the idea of starting a general-purpose IoT thermostat that only uses cheap, widely-available components that anyone can easily duplicate with a BOM and 3D printer. reply yard2010 4 hours agoparentprevThis is the way. I'm buying stupid tech exclusively, and make it smart in my own terms. reply lgats 3 hours agoparentprevI did the same, i recommend getting the moes or similar IR blaster (tyua under the plastic). Treat yourself and get a combo temp/humidity sensor + IR. For one of the rooms i opted for a IR/RF transmitter and the RF covers any RF enabled devices in the house (433mhz + 315mhz[i think but haven’t tested]) reply Cthulhu_ 10 hours agoparentprevIR is fine for these things, it's not like they need much data. I have an IR ceiling fan, no issues there (even if the receiver is on a little wire that is supposed to stick to something but the sticktivity of the tape sucked), and a radio \"smart\" lighting system (just simple on / off switch on a plug socket). And some radio spots from IKEA, although I'm sure that can be hooked up to a \"smart\" system. reply dfox 13 minutes agorootparentIKEA has consistent smart system that has the annoying feature that it works the wrong-way around for my use-case. The cheap IKEA switches can control IKEA peripherals only directly, you can't use them to control something outside of the IKEA ecosystem. As most of the things I want to control are either HomeKit native things or digital outputs on PLCs it does not work for me. So in the spirit of true overkill I have few switches that contain OrangePi Nano (I had somehow absurd quantity of these laying around as leftover from previous even more misguided project) reply mrgaro 10 hours agoparentprevGree HVAC units have built-in wifi which supports fully local remote control and there are OSS packages (including home-assistant). reply rich_sasha 10 hours agoparentprevAh, do you have some tips for someone who wants to do something similar? I use AC units that come with IR remotes (Samsung maybe??) but the timers don't work for some reason. It would be great to hand roll some automation, but I never \"hacked\" IR remote/receiver systems. reply paranoidrobot 16 minutes agorootparentStart Simple is my suggestion. Home Assistant supports a huge range of integrations. Personally I am using Broadlink RM4 Mini IR blasters. One in each room. They get added to Home Assistant as devices. Then I use one of the climate add-ons that can send IR commands via the Broadlinks. reply BizarroLand 2 hours agoparentprevI have a lennox heat pump in my house and the main thermostat controller went out a few months ago. Lennox uses a proprietary system like this one but the old school controls were visible on the control boards and due to a freak accident when an installer was levelling the floors for new flooring and cut the old wire I had a 5 wire thermostat wire installed instead of the 4 wire it came with. Perfect. $50 thermostat, wired it in. Powers on. Fan powers on. A/C condenser? Nada. Official replacements were $700+, upgrades were $800. Checked around, found an offerup seller selling the upgraded model for $400. Deal. Met the guy, he gave strong, \"I stole this, don't ask too many questions\" vibes at first glance, and I was about to back out of the deal, but something clicked in my gut and I went with it. Got it home, wired it up. Fan turns on. No AC. @#$@!#$%@#$^ On a hunch, went outside and checked the power for the heat exchanger. I had unplugged it for safety reasons but plugged it back in afterward, but gave it the snuggy test just in case. Sparks shot out as it re-engaged. It's Alive! The $50 one might have done the job, but no point in re-rewiring the whole shebang as the money is already spent. If this system goes down, I'm going mini-split ductless. Forget this noise. reply davesmylie 12 hours agoparentprevfunny - I literally bought a broadlink ir blaster today and got it hooked up to HA about 15 minutes ago, looking to do this exact same thing. Out of curiousity, did you have any resources you were following to set this up? I'm pretty new to HA - basic devices etc seem fine, but I'm not entirely sure where to go next! reply paranoidrobot 3 minutes agorootparentWelcome to the club. I'm using Broadlink RM4 Mini's I got off AliExpress. They've got a powerful enough IR signal that I've found I don't need them sitting way out in the open and obvious. One is tucked behind a TV and not quite in direct LoS, one is behind, but it reflects off the wall just fine, another behind a bedside table. For the integration/Climate control thing I'm using SmartIR. Configuring it is a bit weird, you have to put it direct into the configuration.yaml file unlike other integrations. smartir: check_updates: true climate: - platform: smartir name: Bedroom AC unique_id: bedroom_ac device_code: 1293 # https://github.com/smartHomeHub/SmartIR/blob/master/docs/CLIMATE.md#available-codes-for-climate-devices controller_data: remote.mini4c_bedroom temperature_sensor: sensor.airquality_ikea_bedroom_temperature humidity_sensor: sensor.airquality_ikea_bedroom_humidity power_sensor: binary_sensor.contact_bed_ac reply 35mm 13 hours agoparentprevHow did you pick cheap blasters compatible with HA? I have a Broadcom one which works well but expensive. reply paranoidrobot 14 minutes agorootparentReddit and Google was how I chose which one to go with. The Broadlinks RM4 minis were pretty cheap on AliExpress. I think I paid about $15 each? Might have to wait for specials to come up to get the lowest price. reply cyberax 14 hours agoprevUgh. The whole \"smart aircon\" industry needs a good-sized asteroid wiping them out of the existence. There is a very real need for modern variable-speed units, and vendors just keep fucking it up by using proprietary protocols locked into their ecosystem. TRANE in the US is similar. And this is really annoying because variable-speed pumps solve all the problems with short cycling and oversized systems. reply bloomingeek 3 hours agoparentAlso there's the variable-speed furnace/AC fan. These heavy bastards, with an add-on brain, are very expensive when they go bad. In my case, the brain part was fine, but the fan motor died. They wouldn't sell me just the motor, just the combo for $900US! And, if I install the combo, it voids the warranty. (I did install it, I'm the homeowner not a repairman.) I was also told if my unit was a Trane, they weren't allowed to sell me the combo! (My unit is a Goodman.) What a rip off! reply kokey 10 hours agoparentprevI think there's probably a case for some regulation to force at least a minimum set of open standards, because that would make it possible to e.g. switch between systems based on intermittent renewable generation etc. reply datahack 14 hours agoparentprevYou think this is bad? Try swimming pool equipment. reply riskable 4 hours agorootparentAt least swimming pool equipment is mostly just turning things on and off. If you look at the controller board for any given pool \"timer\" it's just a bunch of relays (for the pump, lights, and valves/servos). Temperature sensors are all standardized for the most part (well, they don't seem to be anything special) but I'm not sure about chlorinators... Mine has a strange (electrical) connector and 100% proprietary threads on the PVC connectors (that were easy enough to reverse engineer in OpenSCAD: https://www.printables.com/model/24144-t-cell-cleaning-stand). Fortunately there's plenty of 3rd party competition for things like that. Even though I had a Hayward system I was able to purchase a compatible chlorinator off Amazon for a fraction of the price Hayward was charging. reply pzlarsson 14 hours agorootparentprevI think home EV charging equipment is heading in the same direction as well. Very few have local and open APIs and instead depend on the vendors cloud service for control. reply dacryn 11 hours agorootparentI don't know where you live, but in Europe there is a standardized backoffice management protocol that you can link up to basically anything in modern chargers. Except the cheapest of the cheapest. I have mine running through EVCC.io, setting it up was as simple as throwing that thing in a docker container and figuring out the IP address of the chargepoint. reply stavros 7 hours agorootparentDoes this necessarily go through a third party server, or can it all be run locally? reply jagheterfredrik 11 hours agorootparentprevAgreed, I couldn’t find a reasonable choice and ended up making https://github.com/jagheterfredrik/wallbox-mqtt-bridge reply erinnh 5 hours agorootparentprevThere is OCPP (Open Charge Point Protocol). There's quite a bit of choice in supported wallboxes. Here is Europe at least. reply torginus 10 hours agorootparentprevI am confused - aren't these boxes basically fancy three phase outlets? They probably have some safety fuses and some comms equipment, but the 'core' of the system is basically copper wire that connects you to the grid. reply lexicality 10 hours agorootparentHere in the UK at least they're generally single phase and required to moderate the power delivered to the vehicle based on the current electrical load in the house because most properties have quite low main cut-out fuse ratings. Bonus complications if you have solar or want any kind of access control. reply mschuster91 9 hours agorootparentprev> aren't these boxes basically fancy three phase outlets? That entirely depends LOL So for AC chargers you are correct - 1 or 3 phases that go through a relay and, where required by code such as in Germany, a DC-sensitive RCBO, plus a small control board negotiating with the vehicle and monitoring voltage/current on one side and, again depending on where required by code, negotiating with the grid operator. DC chargers are one hell of another beast, these have to contain all of the above plus powerful rectifiers, smoothing capacitors, EMI compliance... reply cyberax 13 hours agorootparentprevYeah, but EV chargers are not that complicated. They are just smart contactors, with maaaybe some load management (EVSE can command the vehicle to reduce the charging rate). Worst case, you just buy another one. It'll set you back a couple hundred dollars. Unpleasant, but not a big deal. Air conditioning systems can easily cost more than $10k. reply jwalton 5 hours agorootparentprevI just spent an afternoon recreating the custom threads on a Hayward chlorinator for my dad so I could 3D print a temporary replacement part. These don’t even use standard pipe fitting thread. -_- reply sarchertech 6 hours agorootparentprevYou think that’s bad? Try tanning bed control equipment. reply relaxing 9 hours agorootparentprevTell us about that! reply knowaveragejoe 12 hours agorootparentprevBoth of these examples, and others, sound like an underserved market. reply xvector 11 hours agorootparentExactly. This is what happens when a market is so small they can overcharge for terrible technology. I figure a couple of SWEs could make a startup that completely disrupts these industries with objectively superior technology. reply quickthrowman 4 hours agorootparentTechnology doesn’t matter, it’s all about relationships between dealers and manufacturers (or dealer/distributor/manufacturer, I am unfamiliar with this particular industry.) That holds true both for HVAC and pool equipment (and fire alarm systems, irrigation, etc etc) If you can’t sell your product to the dealers because there in bed with the incumbents and the incumbent products generate service call work for the dealer, it doesn’t matter how good the tech is. This is a people problem, not a technology problem. It can’t be solved by a couple programmers. reply xvector 1 hour agorootparentYou offer direct to consumer sales and cut out the dealer-distributor corruption pipeline - like Tesla, Nest, etc. reply rpcope1 3 hours agoparentprevI am looking at replacing my A/C system, and having worked on the single stage single speed one that's currently installed, and looking at the insane shit everyone ships that's more complicated than your basic gas forced air furnace coupled with a single stage 16 seer A/C unit, there's no way I would ever buy something else. Every parts house has got inexpensive replacements in stock for the simpler units and service is easy; good luck if you have go find the unobtanium variable speed motor or control board that Lennox or Trane just happened to stop making the moment your unit stopped working. reply tracker1 1 hour agorootparentLargely my take as well... I just want the simplest thing that works at this point... I'm heading in that direction as I need to replace appliances as well. So far this year, the microwave, range and dryer have all died. The microwave was the single biggest safety hazard I've ever seen, and they say you shouldn't work on them yourself... what happens when it turns on if the door is open? Or, you discover later, it's actually just on all the time even though the light is off and the fan isn't running. I'm all about stupid, but repairable appliances now. reply cyberax 3 hours agorootparentprevYep, and it's annoying because variable speed units themselves are _better_ than the old classic one or two-speed units. They are more economical, quieter, and mechanically more reliable. But the insane control systems compensate for it. reply yard2010 4 hours agoparentprevNo need for an asteroid. Just a few salty lawyers. reply liminalsunset 10 hours agoparentprevThe problem with having standards for this kind of thing is that different units have different needs for communication and different levels of being smart. For example, some units want 2 temperature sensors and some want 3. The method used to control the system can be relatively complex - some systems are using physical models of the characteristics and positioning of sensors to do fancy control, and there are probably at least 5-15 data points involved in a typical system. While it would be nice for the protocol to be documented (would realistically only be used by a very small number of users), the only real way you would be able to get a standard for something like this to work is if you went the Bluetooth route and did generic scenario-based profiles (e.g. HFP, A2DP, SPP), and optionally some \"GATT\" or \"generic attribute\" parameters. However, as we see with Bluetooth LE, everyone just uses GATT and implements their own little proprietary thing over it and you're back to the same problem. Some of these systems attempt to be \"smart\" and just use the 24V C/W/Y1/Y2 etc protocol as a \"standards compliant fallback\". You don't necessarily lose ALL of the smarts, but the unit has to essentially use physics magic to make an educated guess about the information (for example, if you use a on-off thermostat, you can't really measure the temperature of the setpoint, so you don't know how close you are unless you somehow make an observation over many cycles. I think that reasonable attempts to address this problem could involve some kind of extension to the old 24V interface - say, by offloading the actual \"policy\" part of system control to the \"thermostat\" i.e. have something that goes from 0-10V where 5V is off, 0V is full cooling and 10V is full heating. This allows you to choose your own temperature sensor situation, but complicates setups where more than one zone or thermostat is required. Of course, it will be very difficult for the industry to settle on a solution to this. Qualcomm's Quick Charge 2.0 was a very simple protocol similar to this, which was essentially self-documenting and not something that needed versioning, but of course, needs changed, 3.0 came and went, 4.0 came and went, and by the time USB C and USB PD came around you ended up with a full on data protocol API with all the OSI layers and of course, vendor specific extensions. You could define some complicated protocol where you don't conform to a standard but you publish an API for your system (of course, there is no incentive to do this), and larger vendors like Control4 or Lutron, Crestron can program their products to interface with it. Unfortunately this doesn't allow the customer full choice over thermostats, because now you have to deal with N vendors x N thermostat vendors, which isn't scalable and you'll end up in dependency hell. The closest thing I can think of to a standard, and the way it is solved in larger buildings, is through something called BACnet. It appears to use the Bluetooth model of \"scenario based profiles\", with all of the disadvantages that come with that, but the primary disadvantage is that it has to be to some degree manually configured to route data where it needs to go - and I don't think this is something installers are currently equipped to do at home scale. Realistically, the \"thermostat\" is just a vestigial component in modern terms and really, it's just a user interface and thermometer now. Without getting into the wish to have open sourced app control or whatever, it's hard to define what the \"thermostat\" does and what the \"system\" is doing, and whether the device that sits on the wall is really a \"thermostat\" deserving of being interchangeable anyway. I have heard from a friend that does home automation integration that many clients don't like the default thermostat because it doesn't look very aesthetically pleasing. In this case, I'm definitely sympathetic to the need for customizability but it seems difficult to achieve in practice. reply cyberax 2 hours agorootparent> The problem with having standards for this kind of thing is that different units have different needs for communication and different levels of being smart. There really is nothing complicated there. I have some background in lift (elevator) systems, and they have similar requirements. Modern lift systems use variable frequency drives for smooth start/stop, and they came up with compatible protocols that allow users to mix-and-match controllers. In the end, there just needs to be a simple protocol to command the motor to run at a certain speed. It can be CAN-based, it can be based on RS-485, etc. For additional smarts, throw in readings from the sensors inside the AC units (pressure, coils temperatures). Then the control units can be made by third parties. They can do all kinds of prediction-based logic, complicated PID controllers, whatever. > Some of these systems attempt to be \"smart\" and just use the 24V C/W/Y1/Y2 etc protocol as a \"standards compliant fallback\". You don't necessarily lose ALL of the smarts You actually do with TRANE units. They become completely dumb, not even 2-stage emulation. > The closest thing I can think of to a standard, and the way it is solved in larger buildings, is through something called BACnet. I have BACnet at home, for wired temperature/humidity sensors, the same RS-485 network is also used for Somfy shades ( https://github.com/Cyberax/py-somfy-sdn ). BACnet is a low-level system, and it needs higher-level profiles. But yes, exposing the motors and the sensors inside the AC units over BACnet would be a great start. reply TeMPOraL 9 hours agorootparentprevMake it a certification requirement (UL or whatever) for the manufacturer to maintain a gold-level OSS Home Assistant integration, and all those problems would solve themselves in a heartbeat. Alas, vendors that interface with customers do not sell appliances - they sell \"solutions\", specifically solutions to the problem of their own making, i.e. them inserting themselves between the buyer and the appliance they're buying. reply smolder 6 hours agorootparentprevThe idea of anything with permanence involving Bluetooth gives me a brain cramp. reply Hendrikto 9 hours agorootparentprevAre you a lobbyist? You spent so much effort arguing for something OP has shown to be just plain false. Any tablet worked. The only reason it die not work ootb were completely arbitrary restrictions. The control boxes can do whatever complicated things they want. But the interface to control them should and can be standardized. reply Snild 4 hours agorootparentI agree that it should be standardized, but not with your argument. Yes, any tablet worked, but it required running an app customized for the hardware. That only proves that we can standardize at the level of Android app APIs. reply lelandfe 16 hours agoprev> For whatever reason (I suspect some sort of storage failure) everyone’s tablets die around the same time. What a fun, completely coincidental quirk that that time appears to fall outside the warranty window, hey? reply Lammy 16 hours agoparentVery convenient for them and also easy to accomplish by buying the cheapest parts. It's probably eMMC-based and writing a logfile constantly. Source: every Android that has ever died on me in this exact way (four and counting) reply rx_tx 13 hours agorootparentIt's been a big pain for Tesla as well, where their tiny 8GB emmc on the center screen would fail since they logged to it too much... 134,000 vehicles recalled eventually after they denied it was an issue. https://www.tesla.com/support/8gb-emmc-recall-frequently-ask... reply consteval 4 hours agorootparentJesus Christ are they amateurs? These are steel boxes on wheels and we're dealing with the same issues as shitty 200 dollars android tablets from 10 years ago. reply xandrius 3 hours agorootparentThat's because all who gets hired at these hyper-fast startups are fresh graduates who can do leetcode by heart. The people who have been in the field for a decade or more can't be arsed putting up with all that and so you get stupid issues which were solved years ago but the devs were not aware of them. reply windowsrookie 15 hours agorootparentprevI recently had to fix the radio in my car for the same reason. Pioneer installed the firmware onto a cheap SD card that they have hidden inside the radio and requires disassembly to replace. Of course they don't offer the original firmware anywhere, luckily someone online has backed it up and I found the file on reddit. reply girvo 15 hours agorootparentprevYep this is nearly guaranteed. Kills so many IoT things, logging the world and eMMC write limits being garbage. reply TeMPOraL 12 hours agorootparentI feel this may be natural selection at play. With bottom-of-the-barrel (and/or \"value add\") IoT garbage, hardware suppliers are a commodity, and under competitive pressure, the winners will be ones that can make cheapest hardware that just about outlasts a typical warranty period of their customers' products. Shorter-lived parts will not bring repeat business; longer-lived parts will get value-optimized further. Failing just after warranty period is Just Right. reply jeremyjh 2 hours agorootparentI think its worse than that because they don't actually have to log so much. This is choice a developer made, but it would cost nothing (except salary for competent staff) to make the correct choice. reply nairboon 11 hours agorootparentprevDepending on the particular consumer group, this could also backfire in the long term. With consumer warranty being ridiculously short. They will increasingly notice the pattern, that devices from brand X always brick shortly after warranty is over. And maybe moving to more trusting, but pricey brands. reply TeMPOraL 10 hours agorootparentUnfortunately, there are almost no \"pricey brands\" left that serve the middle range of price/quality. Most of them sold out to or just became replaced by bottom-of-the-barrel shit sellers, that are happy to continuously cycle through dozens of fly-by-night brands. It's still possible to get quality work done, but that's one of the few very premium brands and/or bespoke work; if you have to ask, you can't afford it. (Just look at Amazon marketplace if you think I’m exaggerating.) Customers have been \"noticing\" this pattern for couple decades now; it's not just in tech, but everywhere across the board - from foodstuffs, through appliances, sports equipment, clothing, hygiene, all the way to computing. Unfortunately, this is a pattern in the same sense a tsunami is - you notice the wave is growing and about to flood everything around you, but there's fuck all you can do about it. reply nairboon 38 minutes agorootparent> you notice the wave is growing and about to flood everything around you, but there's fuck all you can do about it. In terms of online shopping, if the distributor cooperates with the consumer then there is something to do about it. One of the largest Swiss online shop started to share warranty statistics of all products. That information is quite useful to avoid the cheap and soon to break stuff. Of course it's not perfect, since it only tracks faults within the 2 year warranty period. But it provides a proxy signal for quality. But maybe that only works in smaller markets with less incentives to game the statistics. See https://news.ycombinator.com/item?id=34536344 reply mschuster91 9 hours agorootparentprev> you notice the wave is growing and about to flood everything around you, but there's fuck all you can do about it. Depends. For some product lines there's the \"commercial grade\" stuff available - for TVs, look into Digital Signage product lines and add some sort of TV stick (or an rpi) to them for the brains, for power tools look at what the tradespeople use (it's probably Bosch blue series, Makita or DeWalt), for kitchen equipment ask your nearest restaurant. For computing, I'd go to Apple (if your ecosystem supports it), Lenovo/Dell/HPs business line stuff (you don't need to buy the next day on-site package, but you want the models that do have that as an option because that's the ones that are both made for easy repair and have better components in the first place) or Framework. You pay quite the hefty premium over Chinesium stuff, but it's worth it. Only thing I'd stay far away from if you're not trained on how to use them is cleaning supplies of all kinds, hair and body shampoo as the commercial ones are way stronger concentrated and you can do serious damage to your (or your loved ones) bodies if you, say, leave them on too long. reply nairboon 11 hours agorootparentprevI recently had an otherwise perfectly fine eMMC-based Samsung phone degraded to unusable floppy disk speeds. My guess is that their \"RAM Plus\" feature (aka swap) combined with the memory hungry modern android apps turned out to be a nasty timebomb. Which has or still is bricking millions of smartphones after a few years of usage. reply amiga-workbench 13 hours agorootparentprevSurely it can't cost much more to go for a larger eMMC chip and have it massively over-provisioned with plenty of space for wear levelling? The underlying flash memory is trash and the controller already does a ton of heavy lifting to keep the data coherent. reply MaxikCZ 12 hours agorootparentBut then you are not only making your build price higher, you also have less revenue as year pass. And its hard to market. reply jandrese 5 hours agorootparentIt's a $1,700 bottom barrel android tablet, there is plenty of profit margin available. reply lintfordpickle 12 hours agorootparentprevI don't think the problem is necessarily space, but rather write-limits being used by superfluous logging reply amiga-workbench 10 hours agorootparentThat's where the wear levelling comes in, still expose 8GB of space to the host device, but internally have I dunno, twice that in cell capacity that you can move bits to as other cells wear out. Its a shame mobile devices don't have a SMART equivalent, would be nice to have some warning as something approaches the end of its life. reply jeremyjh 2 hours agorootparentWhy do you want to spend money on hardware to solve a software problem? The software doesn't have to write the logs to the SD card. reply Scoundreller 4 hours agorootparentprevDo you even have to limit the exposed space? It’s not going to write at twice the rate just because more space is available. reply amiga-workbench 3 hours agorootparentYou do, most SSD controllers already implement this. Have you ever wondered why most SSD's come in slightly odd sizes like 100GB instead of 128GB? The extra space is put aside and used for wear levelling and other maintenance tasks. You can find out a bit more here https://www.seagate.com/gb/en/blog/ssd-over-provisioning-and... I also remember a guide a while ago on how to reprogram a SSD to operate in SLC mode instead of MLC. You lost disk capacity but gained a large performance boost and a reduced error rate. reply user_7832 11 hours agorootparentprevIf I remember correctly it's also about eMMC having a much shorter life than UFS or similar storage. Though yes, unnecessary logging isn't helpful either. (Quick post-googling edit: apparently both use NAND, it's more about wear leveling apparently that makes the differences.) reply irjustin 16 hours agoparentprevknowing a lot of these companies. it wouldn't really matter if it fell inside of the warranty. they would simply screw a lot of people over until there's a class action lawsuit (or whatever equivalent is in that country) where they get a slap on the wrist for not honoring warranty claims. reply kmoser 14 hours agorootparentMy A/C unit is fairly new but there are signs the condenser unit fan is starting to go. Since it is still under warranty for parts (not labor) I thought I would be able to just get a replacement fan and install it myself. But no, the manufacturer will only deal with a \"certified technician,\" who of course charges an outrageous amount of money (many hundreds of dollars) to replace the fan. When I asked the technician why the labor cost so much, they gave me some song and dance about how the prices were set by their central office (true) and that the cost also included filing the paperwork to make a warranty claim (seriously?). At the end of the day, I could probably buy an aftermarket fan off the Internet and install it myself, spending far less than the certified technician would charge to install the \"free\" OEM replacement part. reply liminalsunset 11 hours agorootparentJust as a data point for those in Canada (maybe US, but I'm not sure if it's the same company), I have a Senville unit, bought from their website, and they sent a replacement plastic (yes, it's a plastic bead in a piece of rubber) bearing for the indoor fan for free with shipping free too a few years ago, after providing the unit's serial number and the original name on the receipt. The unit was in-warranty. They claim that you have to have the unit professionally installed to get the warranty, but nobody asked for this at any point (could have been due to triviality of the part). Either way I was pleasantly surprised by the willingness to provide parts, even though the documentation of part numbers and models/generations on their site isn't super clear. It's now out of warranty, but most of these units are built by either Gree (some Trane, Tosot, Gree, some Lennox iirc) or Midea (MrCool, Eco-Air, Senville, Pioneer, Carrier), so searching for the \"canonical name\" of your system can be helpful in finding parts. (usually, its of a pattern like \"M5OG-48HFN1-M\", can be found with meticulous googling for catalogs). There is a lot of parts commonality between units. You have to be creative with finding parts on AliExpress as they go by any number of names that you wouldn't expect, and a lot of this stuff is bought by eye (or random dimensions, of which there are some canonical ones for each part) and not by part number unfortunately. reply freetanga 12 hours agorootparentprevAlso, likely the technicians company paid big money to be an official provider (or pays a % of this job up) At least Ponzi had style. reply Gabrys1 13 hours agorootparentprevThis reads similarly to how with certain medical insurance you only pay a flat $5 (instead of the full price of $25+) for common meds that you can get for $1.50 outside of insurance... reply KennyBlanken 15 hours agorootparentprevCarrier back in the 2000's had a problem with their heat exchangers in their gas furnaces failing far more often than they should. They were sued, settled, and part of the settlement was an extended warranty of the heat exchanger, including labor. Great, right? The local carrier dealer lied and said the unit wasn't under warranty. They lied again when reminded of the class-action settlement, claiming only part were included and said would cost a fortune in labor. When I called Carrier and told them what their factory authorized gold/preferred/whatever-they're-called dealer was pulling, Carrier confirmed I was correct and even verified the unit's serial number and said that if the dealer had checked the SN, they would have found it was covered. The dealer then said 'fine, but those parts are going to take weeks to get from the warehouse' knowing damn well I had no heat, in the winter. They had us over a barrel and they fucking knew it, and I didn't have any way to prove that claim wrong. reply boopdewoop 16 hours agoparentprevI wonder if it could be they are logging and not clearing the logs, filling up the storage - since its happening around the same time for everyone. reply grishka 13 hours agorootparentMaybe not filling up but wearing out the flash chip itself. If it was filling up, then a factory reset should've helped. reply 1024core 15 hours agoparentprevI wish he had poked around the Java code and looked for what might be triggering that. reply thaumasiotes 15 hours agoparentprev> What a fun, completely coincidental quirk that that time appears to fall outside the warranty window, hey? Isn't that the point of the warranty? They tell you they think the product will last for X years, and then it lasts about X years, just like they warranted. reply thayne 14 hours agorootparentHVAC systems are usually advertised as lasting at least a decade, but the warranty is usually only a year or two. Honestly, I think something needs to be done so that companies are held liable for expensive products failing and needing expensive repairs after a year or two. reply devsda 16 hours agoprevUnfortunately, if/when someone from the manufacturer knows about it their first thought will not be \"How do we make it easier for our customers\". It will most likely be \"How do we restrict this hack\" and will eventually get into more restricted/quirky hardware & software. reply Gabrys1 13 hours agoparentI don't think they'll care about this. Probably only 1% of their customers are capable of \"hacking\" this. As long as the tablet replace is cheaper than getting a new AC unit from another company it's fine for them. reply OccamsMirror 13 hours agorootparentNot even 1%. It would be interesting if someone already in AC repair made it part of their business though. That's when you'd see the teeth come out. reply stuff4ben 3 hours agorootparentprevUntil someone decides to sell their fix at a cheaper price. Then lawyers will get involved and everyone will end up unhappy. reply zekrioca 13 hours agoparentprevYes, which is very sad. Nearly all things go into this direction. I still remember the old days of jail breaking the iPhone, and the cat and mouse chase with Apple. reply lawgimenez 11 hours agoparentprevThey would have to put the condition inside shared library .so and use Android JNI. Make it complicated and hide the string tablet model throughout the code, just enough time to frustrate whoever is decompiling the so file. reply rocqua 10 hours agorootparentIf they want to really do it wrong (or right, from their PoV), they require the communication with the base station to be signed with a certificate signed by their root CA, and put the private key of that certificate in the TPM. reply cududa 3 hours agorootparentI genuinely get the sense nobody there is capable of coming up with this on their own and are likely looking at this thread for ideas reply aledalgrande 16 hours agoprevThat \"not on AA hardware\" error from an app running on a plain Android tablet should be criminal. reply gwd 10 hours agoparentIn defense of this, remember that any random person can download and install this app on any android device. It does make sense to have a clear failure mode in this case. Anyone willing to pull out a soldering iron to attach a new tablet is perfectly capable of working around this. reply SahAssar 10 hours agorootparentIf that was the motivation it should be a warning, not a hard error. reply prmoustache 9 hours agorootparentprevWhat is the risk here? reply gwd 9 hours agorootparentConsider the following scenario: 1. Someone owns one of these systems which is functioning perfectly well. 2. They stumble across a link allowing them to download the controller app, and so they install it on their normal tablet, expecting to be able to control the system from their tablet 3a. It doesn't work, so they contact technical support. Technical support wastes a bunch of time before figuring out why the app isn't working, only eventually to realize what's going on. 3b. They can't get the app to work, and so slag the system on social media. Both have costs both to the people who end up downloading it, and to the company -- costs which could be avoided by having a simple error message. reply passwordoops 7 hours agorootparentThere's nothing wrong with this scenario per se, but there's a 100% chance this is not the reason for their decision reply gwd 4 hours agorootparentThere can be multiple reasons to do something. It's a simple, effective way to avoid some legit issues that doesn't require much if any testing; by itself it's a perfectly legitimate business decision and doesn't need to be illegal. Paired with their attitude towards repairing the broken tablets, it's clearly also a part of their \"planned obsolescence\" scam. reply anoother 6 hours agorootparentprevThis is pretty simple to solve for. Eg. Have the app provide an ID the customer can quote to the CS rep; Have the app also log this ID, along with the system it's being run on, to the cloud/an interface that pops up an \"unsupported system\" message to the CS agent on entering the ID. reply majewsky 4 hours agorootparentHow does this solve 3b? reply prmoustache 6 hours agorootparentprevBut you could have a warning at the start of the app without rendering it unusable that would pretty much solve old points. reply lolinder 6 hours agorootparentYou've clearly never worked in tech support. People who are likely to go through the steps that OP described aren't going to read the warning. reply cbanek 16 hours agoprevThis is when smart gets stupid. I'm a bit worried about this with my nest and other smart devices, but even with normal air conditioners there are a few stupid simple problems that will cost you hundreds of dollars! A couple of weeks ago my AC blower fan stopped working, the compressor would run. I went up and found out that the capacitor was bad, and took a picture of it, buying a replacement. Took about 15 minutes to replace and I probably saved myself at least $400 (no AC is an emergency in the desert, and they will charge you accordingly). Fixing household appliances can be fun too! reply ApolloFortyNine 4 hours agoparentEveryone reading this should find out what capacitor they need and buy one off Amazon, they're alland is almost impossible to mess up Just don’t cook yourself with the remaining good capacitance. Personally, I wonder what could be done to temporarily get the capacitor to “kick” for a few more times to get your home temperature down as you get your replacement. Chill the capacitor? reply BizarroLand 1 hour agorootparentIt depends on the failure mode of the cap. If it has blown its dielectric, then chilling it may cause the plates to separate enough to boost the capacitance, but it is more likely to just be a waste of time. Aside from that, you could strap on other capacitors as long as their voltage is the right value. A daisy chain of 50mf capacitors to shore up the blown capacitance might buy you a day or so of usage. Best bet, if you have an old broken microwave nearby, would be to pull the cap from it and wire it in. reply quickthrowman 3 hours agorootparentprevPlease don’t suggest buying electrical parts off Amazon, that’s criminal negligence. On second thought, please do not give any electrical advice on the internet. Buy it from McMaster Carr or Grainger, please!! If you do this repair yourself, short the contacts of the capacitor (ideally with a correctly sized resistor) to discharge it before handling it so you don’t electrocute yourself. Start caps: https://www.mcmaster.com/products/motor-starter-capacitors/ Run caps: https://www.mcmaster.com/products/run-capacitors/ reply jdc0589 3 hours agorootparentMcMaster will get it to your house next-day in lots of places too, and you don't have to deal with the local hvac supply house refusing to sell to a walk-in customer that isn't an employed hvac tech. reply Nursie 15 hours agoparentprevThe great thing about Australia is that that is probably illegal here. We've got some pretty fucked up protectionist rules about what you can and can't do in/to your own home. It's nuts. Now, nobody is actually watching most of the time, so you're usually fine, but it's as stupid as being illegal to replace a tap or existing light fitting. Every so often state governments review the rules and get swamped by trade associations who say the rules are there to prevent people being 'scammed' by untrained 'handymen' and are there for your own protection. This regulatory capture means that legally you need to complete a four year apprenticeship before you're allowed to change a plug! And another one if you want to do any basic water plumbing. I wouldn't be surprised if what the guy did in this blog is strictly speaking illegal - for instance when it comes to data cables, you need to be a qualified electrician with data specialty to install them. You can plug ethernet cables into your computers yourself (wow! such privilege!), but if you install them even by getting some stick-on plastic conduit and passing the cable through that, you're in contravention and could potentially be fined, up to thousands of dollars. For sticking some plastic tubes to the wall in your own house. reply SOLAR_FIELDS 15 hours agorootparentReminds me how, in USA, it’s the only civilized nation I’ve been to where you must have a prescription to purchase contacts and glasses. Everywhere else I’ve been will just sell you whatever magnification you need at the pharmacy. Obviously there is some acceptable line here, but I think the States handles this decently well enough. In Austin where I live you can get what is called a “homeowners permit” in a lot of cases. Meaning the city will come look at your work and as long as it’s up to code you get a legal permit just like a contractor would get (https://www.austintexas.gov/page/homeowners-permit). You can only do this to your own home so it’s not a shortcut to running a chuck in a truck business without a license. reply hunter2_ 15 hours agorootparentThere's an easy hack for the contact lens (and maybe glasses?) situation. There is a consumer protection law meant to ensure eye doctors can't stop you from using any retailer you want (otherwise they'd essentially make themselves your retailer), and it works like this: You place an order with the retailer (online retailers typically allow you to simply type in your prescription values when adding lenses to your online cart; you don't need to show an official written prescription) and specify your doctor's name and phone number. Upon receiving your order, the retailer must call the doctor to see whether the doctor objects (invalid prescription). The retailer is to ship the order only if there is no objection (including no response at all) within 8 business hours. So just give the retailer the name and number of someone who won't immediately object, which is quite easy (e.g. a permanently closed office). Of course, you need a refraction to know your prescription values. But once that's done, if your vision doesn't change over time, this allows you to ignore the expiration date of the prescription. reply Nemi 4 hours agorootparentMy first thought is - how do you get the contact information for a closed office? My current hack, which is not as great as yours, is to put a reminder on my calendar for a few days before my 1 year prescription ends. If I order new contacts in the one year period for another year’s worth of contacts (even if I am not out yet), I essentially get to go 2 years between visits. I will try your hack next if I can figure out a good way to get contact info for an office that won’t object. reply hunter2_ 4 hours agorootparentGoogle it. When places like this go out of business, local news articles get written. Or just pick randomly among ones still in business, worst case your order gets canceled? reply kevin_thibedeau 14 hours agorootparentprevUS based online contact vendors reject orders without a signed prescription. The doctors intentionally don't sign them. The workaround is to order them from Canada reply hunter2_ 14 hours agorootparentI couldn't find a Canadian (or any foreign) retailer that would ship to the US, but I found tons of US retailers that allow self-entry (as an alternative to uploading a signed prescription) as I described. reply kevin_thibedeau 1 hour agorootparentContactsExpress ships to the US. There is at least one other that escapes me. reply refurb 13 hours agorootparentprev1-800 contacts will write a prescription for you with a $20 online eye exam. Optomitrist asks if your current prescription is ok, asks you to stand 20ft back and read a few letters and you’ve got a script you can use wherever. reply hunter2_ 12 hours agorootparentAs will several other retailers, but only in some states. As someone in an excluded state, I considered whether enabling Mock Location on my phone would get me past that check (I think they require you to use a native mobile app, so I assume they use location from that?) but then thought of the method I mentioned earlier instead. reply TeMPOraL 11 hours agorootparentReading all that, I'm happy my part of Europe is a bit behind the tech curve here. I mean holy fuck, \"native mobile app\" and \"getting contacts\" do not belong in the same sentence in any sane universe. reply hunter2_ 4 hours agorootparentHaha well the thing is, a vision exam requires that you read letters of a certain height from a certain distance while proctored, and presumably this is quite difficult to achieve in telehealth with more open computer systems. Of course some folks can figure out how to break anything (I mean, just plug a projector/TV into your phone with a usb-hdmi adapter and now the letters are huge?) but I think it keeps things easy and reasonably accurate among normies. reply pavel_lishin 6 hours agorootparentprevI purchase my glasses from Zenni, and I don't believe I've ever had to give them the name of my doctor. On the other hand, maybe I typed that in when I was first signing up two decades ago, and the optometrist I gave them has long since gone out of business? reply glitcher 1 hour agorootparentI also order from Zenni and have never had to provide my doctor's info. They happily create lenses with whatever prescription I type in, and for me personally it usually takes a couple years for it to change enough to warrant new glasses. (I still get an exam annually) reply cruffle_duffle 14 hours agorootparentprevThis sounds too good to be true. Having to get a prescription to get contacts is insane… reply labcomputer 14 hours agorootparentBut how would you know what to order if you don’t have a prescription? Trial and error? I guess that might work if you have a simple correction (no astigmatism). reply hunter2_ 14 hours agorootparentGetting a prescription when you don't know what you need makes sense. Getting one just because your last one has expired (1 year) is the off-putting aspect. reply aledalgrande 3 hours agorootparentExactly. Mine hasn't changed for years, but I still need to pay this tax. reply Xcelerate 14 hours agorootparentprevOh wow... I'm totally going to try this next time just to see if it works reply SOLAR_FIELDS 14 hours agorootparentprevYeah my beef isn’t around the actual requirement of determining your prescription. Obviously you should wear eyeglasses/contacts that match your vision requirements. I think this is especially relevant when we are talking about usage with a drivers license. The ridiculous part is the arbitrary 1 year renewal. As you imply it is really only necessary to recheck that often when your vision is changing a lot which is usually not something that happens after some period in your 20’s. Neat trick though. I got lasik a few years ago but I would do this if I hadnt reply renewiltord 13 hours agorootparentprevThere's an even bigger hack: use photoshop to modify the prescription. My wife has been doing it for years. This is helpful since sometimes the prescription is over-specific and points to contacts you don't like. reply hunter2_ 12 hours agorootparentI considered that of course, but something about the signature on it (as opposed to self entry which has no signature) made me very uneasy. And doesn't the verification phone call (which fails unsafe, luckily) happen either way? Maybe not. reply renewiltord 12 hours agorootparentThey must not be making this verification call since we've been doing this for years. Yes, it's straightforward forgery, so your unease is warranted. But I have no problem breaking pointless laws. reply happyopossum 15 hours agorootparentprev> Reminds me how, in USA, it’s the only civilized nation I’ve been to where you must have a prescription to purchase contacts and glasses Anecdotally this is far from true. Canada, Australia, the Netherlands, and the UK for example require a prescription for anything more complicated than reading glasses. There are plenty of reasons why, mostly summed up by your comment about “whatever magnification you need” - eyeglasses for distance vision are infinitely more complex than “magnification” and if you’re buying anything other than reading glasses without a proper exam and matched lenses, you’re doing yourself harm. Unless of course you are talking about reading glasses, in which case you’re also wrong, as you can get those for a couple of bucks pretty much anywhere in the US with no prescription. reply domh 12 hours agorootparentI'm not sure that's true about the UK and prescription glasses. When I moved back here I packed my glasses up in storage so was going to be without for 6/8 weeks before our stuff arrived. I went onto Glasses Direct[1] and ordered 2 new pairs of glasses for £50 by putting in my prescription details from another country. The glasses themselves are regulated as medical equipment, but you could go on there and buy any prescription you want and nothing will stop you. [1]: https://www.glassesdirect.co.uk/ reply ossyrial 11 hours agorootparentprev> [...] the Netherlands, [...] for example require a prescription for anything more complicated than reading glasses. I have never needed a prescription to get (non-reading) glasses in the Netherlands. In fact, there are webshops where you can purchase any pair of glasses (obviously, you have to enter the values of an eye examination). reply happyopossum 3 hours agorootparentYou can order glasses from web shops in the US too - those “values of an eye examination“ come from your prescription. reply SOLAR_FIELDS 14 hours agorootparentprevI am not sure about Canadas situation since that is where I used to order my contacts from before I got LASIK several years ago. I don’t recall having to provide a script then. But Mexico and several other European countries I’ve been to (Sweden as an example) it’s absolutely the case you can just walk into the pharmacy and grab the magnification you need with no prescription. I am actually surprised you were able to provide that many counter examples but I’ve never tried to buy contacts in the countries you’ve listed outside of Canada reply labcomputer 13 hours agorootparent> it’s absolutely the case you can just walk into the pharmacy and grab the magnification you need with no prescription. I don’t understand how this could possibly work. Contact lenses have at least three parameters to define the lens. It’s not just “magnification”. If you have an astigmatism, there are two more, and a further two if you have presbyopia (for a total of up to 7). Almost everyone has presbyopia by the age of 65, so it’s not some rare condition. Do these pharmacies you speak of just have aisles upon aisles of contact lenses? reply shiroiushi 11 hours agorootparentWhen I was in Germany, I saw vending machines where you could buy contacts. Sure, there's a lot of possible values, but they probably only stock the most popular ones. Here in Japan, you can easily buy contacts from optical stores. They have several shelves behind the counters where they stock many varieties. Sometimes they even put a bunch of unsold/unpopular ones out front for 1/2 off (a lot of these are color contacts). I get mine online; I don't need a prescription. One thing I did notice, as someone with astigmatism, is that the number of possible values is less here. My axis back in the US was 100, but here I have to use 90; they just don't carry them in all the possible axis values here. reply SOLAR_FIELDS 6 hours agorootparentprevNot aisles upon aisles but yeah for instance in Apotek, a big pharmacy chain in Sweden, there is usually a whole wall of them with little drawers to pick from. As sibling comment mentioned there isn’t every combination available so presumably you have to special order some if you have some weird combination but for myself who never had astigmatism at all it was perfectly fine. reply userbinator 14 hours agorootparentprevIn the US, it's probably more of a \"don't ask, don't tell\" situation most of the time. Only the idiots get caught when they screw up. reply aledalgrande 3 hours agorootparentprevCanada enters the room reply Nursie 15 hours agorootparentprevYeah in the UK where I spent most of my life, it seems like you do whatever you want, pretty much. Golden rule - you don't touch gas plumbing. And you don't mess with your circuit breaker board/RCDs etc. I think installing new ring circuits may be off limits. Anything else? Go for it. I fitted a bunch of taps and a toilet, changed single sockets to double+USB sockets, changed light fittings, fixed poorly wired lighting circuits, installed Cat-6 through the walls to a few rooms, all sorts of stuff. And none of it was anyone else's business. You can (should?) get a professional inspection and safety certificate before you sell the house, but that's about it AFAICT. I'd be happy enough with the situation in Austin, so long as the city inspections were cheap or free. I'd be happy enough to do a short course in the basics before getting some sort of permit. Where we are now is nuts. (But at least I can buy a pair of generic reading glasses pretty much wherever here!) reply SOLAR_FIELDS 15 hours agorootparentThe inspections themselves here are reasonably priced, but it’s still annoying to deal with the city because they operate in 1995. There’s no portal for scheduling inspections for homeowners, you have to call them. They don’t tell you when they will show up on the day they will perform them, so you have to be available at home from 7-17 ready to instantly answer the door at a moments notice the second they knock or you will miss them and have to reschedule The pricing is reasonable enough - it’s cheap enough to actually be worthwhile to do several things yourself that normally you’d have to pay a contractor for. I did it when I ran some electrical conduit to my garage to add a few 120V receptacles in there. My general rule of thumb is also I won’t touch gas. But also anything like plumbing that is INSIDE walls I usually am looking to have a professional handle as well. It’s harder to fix knucklehead DIY mistakes when they are covered up behind drywall. It does make me want more plumbing setups like I’ve seen in Europe. When I lived in Sweden I loved for instance that a lot of bathroom plumbing is completely exposed, so DIY’ing plumbing work is actually pretty accessible. Here where you have to dig into the walls to get at it makes it much less appealing since not only do you have to be a a decent plumber you also have to be a decent drywall person as well. reply eesmith 13 hours agorootparentprevWatching \"Scrapheap Challenge\" has taught me the UK has a lot of regulations about steam engines. One of the behind-the-scene videos was something like \"that old steam-powered whatever they just happened to find in the scrapheap? Yeah, we've got the inspection certificate right here.\" Boiler explosions will do that to a country. reply jamil7 15 hours agorootparentprevAustralia is definitely one of the most rule-obsessed countries, even in comparison to Germany, where I’ve lived for the last decade or so. Parts of my parent’s house back home are heritage listed, some rules make sense and some are bizarre, especially regarding the garden. reply marcus_holmes 13 hours agorootparentI moved back to Perth from Berlin last year, and yeah, agree completely. Germans have a reputation for being rule-obsessed but they're lax compared to the Aussies, who have a reputation for being larrikins that is almost completely undeserved. It's all \"beer & bbq on the beach\" until you find out that's illegal and the police will pour out your beer on the sand and fine you for the bbq. reply arrowsmith 12 hours agorootparentlarrikin: 1. (Australia, New Zealand, slang, dated) A brash and impertinent, possibly violent, troublemaker, especially a youth; a hooligan. 2. (Australia, slang) A high-spirited person who playfully rebels against authority and conventional norms. Today I learned a new word. reply marcus_holmes 11 hours agorootparentcheck out \"Wowser\" - the Larrikin's mortal enemy. The Wowsers are winning :( reply Nursie 11 hours agorootparentprevSee also \"Wowser\", the opposite side of the coin. At some point it seems the wowsers gained the upper hand. What's left of larrikinism unfortunately seems to be cooked in the head these days. Australian politics is sorely in need of some decent larrikins, but they seem to be AWOL. reply marcus_holmes 11 hours agorootparentagree 100% reply jamil7 13 hours agorootparentprevYeah it’s striking whenever I visit again. I guess there’s that famous quote about Australians being the descendants of not just criminals but also jailers which makes sense. Germans tend to obsess over rules and processes in bureaucratic contexts and when it infringes on others but are very open with personal freedoms. reply XorNot 15 hours agorootparentprevHeritage listing is it's own thing. What I hate is the rules surrounding...essentially any home services. Like it took me a long time to realize when people in the US were saying they \"needed to get something up to code\" what they meant was, that they themselves didn't feel up to doing the work and it would cost them. But like...you can. You can just call the guys and double-check what needs to be done and do it yourself and get it inspected. Whereas in Australia the answer is, it's all illegal, and if you're not a licensed whoever then they don't want to tell you how it should be done in case gasp you do it yourself. So of course everyone does do it themselves, and lies about it. And the quality of workmanship from the trades is...poor. reply Nursie 12 hours agorootparentYeah it's not like the work done by the trades is always a shining example of competence. I can and often do do a better job on things myself, because I have more time and I care about getting it right. And with the apparent trade shortage (at least in part caused by how much you need them for real basic shit), it's expensive and half the time the bastards won't answer the phone or don't show up to appointments. So stuff gets done on the down-low or it just doesn't get done at all. Gotta love the signs at the hardware store saying \"You can buy this stuff but if you even think about installing it yourself, that's illegal!\" reply asah 16 hours agoparentprev+1. Repair all sorts of stuff... Capresso burr grinder, little plastic knob broke off inside, repaired with a 10c washer and glue... worked great for years and you'd never know... reply XorNot 15 hours agoparentprevThe nice thing about my Mitsubishi Heavy Industry units is I've got a bunch of MHI-AC-Ctrl[1] modules tucked into them talking to the service interface with Home Assistant. The neat thing is it doesn't just control it, it also makes all the internal sensors and codes available. What I think we really need to do though is make publishing these control standards mandatory under right-to-repair laws - no one should need to be reverse engineering them, you bring a product to market you have to provide the complete spec for it's software interface and data. Do that, and I bet we'd find in a few years every new appliance would support a common serial port standard and come with a code page in the manual for it (ironically the prevalence of Tuya-smart stuff has come very close to making this happen, but they go to absurd lengths to lock you out of the wi-fi microcontrollers). [1] https://github.com/absalom-muc/MHI-AC-Ctrl reply kbouck 6 hours agorootparentNetwork-connected home Mitsubishi units can be controlled with the MELCloud API (same api used by mobile app) which makes it easy enough to write scripts that grab current temp, settings, power usage. Perhaps someone has already made a home assistant plugin that does this? reply agos 2 hours agorootparentI keep thinking about doing this reply cbanek 15 hours agorootparentprevI'd love this, but right now I'd be happy with a team reverse engineering these things and not getting hit",
    "originSummary": [
      "The author faced a failed tablet in their air conditioning control system, which was six months past warranty, and was advised to replace the entire control system for $1697.",
      "Instead of paying for a full system replacement, the author successfully used an old Samsung Galaxy Tab 4 and modified the software to bypass device checks, saving money.",
      "This DIY solution highlights the potential for significant cost savings and the need for more flexible software options from manufacturers to accommodate older devices."
    ],
    "commentSummary": [
      "A user shared a workaround for a costly air conditioning control system issue, involving RS422 communication and an AES key, sparking significant community interest.",
      "The discussion includes technical details on replicating the interface using an ESP32, rooting tablets, and using converters, highlighting DIY solutions and reverse engineering efforts.",
      "The post underscores frustrations with proprietary systems and planned obsolescence, resonating with tech-savvy individuals seeking more control over their devices."
    ],
    "points": 1637,
    "commentCount": 421,
    "retryCount": 0,
    "time": 1724894881
  },
  {
    "id": 41389185,
    "title": "OpenAI is good at unminifying code",
    "originLink": "https://glama.ai/blog/2024-08-29-reverse-engineering-minified-code-using-openai",
    "originBody": "OpenAI is shockingly good at unminifying code Written by Frank Fiegel on August 29, 2024. engineering openai ai-use-cases While browsing the Internet for inspiration, I came across an interesting-looking component. I thought the block with the running ASCII art looked cool, but I couldn't quite figure out how it was implemented, so I started looking at the source code. I found the code that looked like it might be doing the job, but it was minified. const { floor: ra, abs: KE, min: QE } = Math, O5 = [\"reactive.network REACTIVE.NETWORK\", \"$@B%8&WM#*oahkbdpqwmZO0QLCJUYXzcvunxrjft/|()1{}[]?-_+~i!lI;:,^`'. .:â–‘â–’â–“â–ˆ\"], G7 = Date.now() % 3 ? O5[1] : O5[0], V5 = G7.length, JE = { fps: 60 }; function eT(e, t, n, r) { const i = t.time * 8e-5, s = QE(t.cols, t.rows), o = t.metrics.aspect * 0.2, l = { x: ((4 * (e.x - t.cols / 6.25)) / s) * o, y: (5 * (e.y - t.rows / 4)) / s }, u = ra(KE(YE(l) - i) * V5 + (ra(e.x / 1) % 2) * 2) % V5; return G7[u]; } const tT = () => { const e = j.useRef(null), [t, n] = j.useState({ height: null, width: null }); return ( j.useEffect(() => { function r() { n({ height: window.innerHeight, width: window.innerWidth }); } if (typeof windowwindow.removeEventListener(\"resize\", r); }, []), j.useEffect(() => { const r = e.current; if (!r) return; const i = 12, s = ra(t.width / i) * 1.6, o = ra(t.height / i), l = { aspect: s / o }, u = setInterval(() => { let c = \"\"; for (let d = 0; dclearInterval(u); }, [t]), a.jsx(\"div\", { style: { position: \"absolute\", top: 0, left: 0, width: \"100%\", height: \"100%\" }, children: a.jsx(\"div\", { ref: e, style: { width: \"100%\", height: \"100%\", whiteSpace: \"pre\", overflow: \"hidden\" } }) }) ); }; function nT(e) { return Math.cos(e.x * e.x - e.y * e.y); } const { floor: ia, abs: rT, min: iT } = Math, D5 = [\"reactive.network REACTIVE.NETWORK\", \"$@B%8&WM#*oahkbdpqwmZO0QLCJUYXzcvunxrjft/|()1{}[]?-_+~i!lI;:,^`'. .:â–‘â–’â–“â–ˆ\"], X7 = Date.now() % 3 ? D5[1] : D5[0], F5 = X7.length, sT = { fps: 60 }; function oT(e, t, n, r) { const i = t.time * 8e-5, s = iT(t.cols, t.rows), o = t.metrics.aspect * 0.2, l = { x: ((4 * (e.x - t.cols / 6.25)) / s) * o, y: (5 * (e.y - t.rows / 4)) / s }, u = ia(rT(nT(l) - i) * F5 + (ia(e.x / 1) % 2) * 2) % F5; return X7[u]; } const aT = () => { const e = j.useRef(null), [t, n] = j.useState({ height: null, width: null }); return ( j.useEffect(() => { function r() { n({ height: window.innerHeight, width: window.innerWidth }); } if (typeof windowwindow.removeEventListener(\"resize\", r); }, []), j.useEffect(() => { const r = e.current; if (!r) return; const i = 12, s = ia(t.width / i) * 1.6, o = ia(t.height / i), l = { aspect: s / o }, u = setInterval(() => { let c = \"\"; for (let d = 0; dclearInterval(u); }, [t]), a.jsx(\"div\", { style: { position: \"absolute\", top: 0, left: 0, width: \"100%\", height: \"100%\" }, children: a.jsx(\"div\", { ref: e, style: { width: \"100%\", height: \"100%\", whiteSpace: \"pre\", overflow: \"hidden\" } }) }) ); }, Usually, I would just powerthrough reading the minimized code to understand the implementation (or look for a .map file to restore the original code). However, I realized that I never tried asking ChatGPT to do it for me... So I copied all of the above code and asked ChatGPT to \"explain the code\". Here is the response: The provided code is quite complex, but I'll break it down into a more understandable format, explaining its different parts and their functionalities. Overview The code defines several functions and components using JavaScript, specifically in the context of a React application. It deals with generating some dynamic text content, presumably ASCII art or some kind of visual effect using characters from a predefined set. Additionally, it includes utility functions for event handling, performance timing, and HTML content conversion. Key Components and Functions Character Set Selection: const { floor: ra, abs: KE, min: QE } = Math; const O5 = [\"reactive.network REACTIVE.NETWORK\", \"$@B%8&WM#*oahkbdpqwmZO0QLCJUYXzcvunxrjft/|()1{}[]?-_+~i!lI;:,^`'. .:â–‘â–’â–“â–ˆ\"]; const G7 = Date.now() % 3 ? O5[1] : O5[0]; const V5 = G7.length; This part of the code imports some common Math functions (floor, abs, and min) and defines two sets of characters, stored in O5. Based on the current time (Date.now() % 3), it selects one of these sets (G7) to use later. The length of the selected character set is stored in V5. Dynamic Character Selection Function: function eT(e, t, n, r) { const i = t.time * 8e-5; const s = QE(t.cols, t.rows); const o = t.metrics.aspect * 0.2; const l = { x: ((4 * (e.x - t.cols / 6.25)) / s) * o, y: (5 * (e.y - t.rows / 4)) / s }; const u = ra(KE(YE(l) - i) * V5 + (ra(e.x / 1) % 2) * 2) % V5; return G7[u]; } The eT function generates a character based on the input position (e.x, e.y) and the current time (t.time). It adjusts the position using some aspect ratio calculations and selects a character from G7 based on a combination of the position and time. The purpose of YE function isn't directly clear from the code, but it seems to be a custom function used in this calculation. React Component (tT) for Displaying Dynamic Content: const tT = () => { const e = j.useRef(null); const [t, n] = j.useState({ height: null, width: null }); j.useEffect(() => { function r() { n({ height: window.innerHeight, width: window.innerWidth }); } if (typeof windowwindow.removeEventListener(\"resize\", r); } }, []); j.useEffect(() => { const r = e.current; if (!r) return; const i = 12; const s = ra(t.width / i) * 1.6; const o = ra(t.height / i); const l = { aspect: s / o }; const u = setInterval(() => { let c = \"\"; for (let d = 0; dclearInterval(u); }, [t]); return a.jsx(\"div\", { style: { position: \"absolute\", top: 0, left: 0, width: \"100%\", height: \"100%\" }, children: a.jsx(\"div\", { ref: e, style: { width: \"100%\", height: \"100%\", whiteSpace: \"pre\", overflow: \"hidden\" } }) }); }; This is a React component that sets up an interval to periodically update the content of a div element (e.current) with dynamically generated characters. It calculates the number of columns (s) and rows (o) based on the window size and then fills the div with characters generated by the eT function. The effect runs at a specified frames per second (JE.fps). I followed up asking to \"implement equivalent code in TypeScript and make it human readable\" and got the following response: import React, { useEffect, useRef, useState } from 'react'; const selectedCharacterSet = \"$@B%8&WM#*oahkbdpqwmZO0QLCJUYXzcvunxrjft/|()1{}[]?-_+~i!lI;:,^`'. .:â–‘â–’â–“â–ˆ\"; const characterSetLength = selectedCharacterSet.length; const calculateCharacter = ( x: number, y: number, cols: number, rows: number, aspect: number, time: number, ): string => { const timeFactor = time * 0.000_08; const size = Math.min(cols, rows); const aspectRatio = aspect * 0.2; const position = { x: ((4 * (x - cols / 6.25)) / size) * aspectRatio, y: (5 * (y - rows / 4)) / size, }; const index = Math.floor( Math.abs( Math.cos(position.x * position.x - position.y * position.y) - timeFactor, ) * characterSetLength + (Math.floor(x) % 2) * 2, ) % characterSetLength; return selectedCharacterSet[index]; }; type Size = { height: nullnumber; width: nullnumber; }; const AsciiArtGenerator: React.FC = () => { const textRef = useRef(null); const [size, setSize] = useState({ height: null, width: null }); useEffect(() => { const handleResize = () => { setSize({ height: window.innerHeight, width: window.innerWidth }); }; // Initial size setting handleResize(); window.addEventListener('resize', handleResize); return () => { window.removeEventListener('resize', handleResize); }; }, []); useEffect(() => { const element = textRef.current; if (!element || !size.width || !size.height) return undefined; const cols = Math.floor(size.width / 12) * 1.6; const rows = Math.floor(size.height / 12); const aspectRatio = cols / rows; const intervalId = setInterval(() => { let content = ''; for (let y = 0; y{ clearInterval(intervalId); }; }, [size]); return (); }; export default () => { return ; }; To my surprise, the response is not only good enough, but it is also very readable. Here is the above component in action: Comparing the outputs, it looks like LLM response overlooked a few implementation details, but it is still a good enough implementation to learn from. Definitely a neat use case I've not considered before! Update (2024-08-29): Initially, I thought that the LLM didn't replicate the logic accurately because the output was missing a few characters visible in the original component (e.g., ░▒▓█). However, a user on HN forum pointed out that it was likely a copy-paste error. Upon further investigation, I discovered that the original code contains different characters than what I pasted into ChatGPT. This appears to be an encoding issue, as I was able to get the correct characters after downloading the script. After updating the code to use the correct characters, the output is now identical to the original component. I apologize, GPT-4, for mistakenly accusing you of making mistakes.",
    "commentLink": "https://news.ycombinator.com/item?id=41389185",
    "commentBody": "OpenAI is good at unminifying code (glama.ai)704 points by punkpeye 8 hours agohidepastfavorite251 comments jehna1 6 hours agoAuthor of HumanifyJS here! I've created specifically a LLM based tool for this, which uses LLMs on AST level to guarantee that the code keeps working after the unminification step: https://github.com/jehna/humanify reply thomassmith65 3 hours agoparentWould it be difficult to add a 'rename from scratch' feature? I mean a feature that takes normal code (as opposed to minified code) and (1) scrubs all the user's meaningful names, (2) chooses names based on the algorithm and remaining names (ie: the built-in names). Sometimes when I refactor, I do this manually with an LLM. It is useful in at least two ways: it can reveal better (more canonical) terminology for names (eg: 'antiparallel_line' instead of 'parallel_line_opposite_direction'), and it can also reveal names that could be generalized (eg: 'find_instance_in_list' instead of 'find_animal_instance_in_animals'). reply jehna1 35 minutes agorootparentYes, I think you could use HumanifyJS for that. The way it works is that: 1. I ask LLM to describe what the meaning of the variable in the surrounding code 2. Given just the description, I ask the LLM to come up with the best possible variable name You can check the source code for the actual prompts: https://github.com/jehna/humanify/blob/eeff3f8b4f76d40adb116... reply bgirard 7 minutes agoparentprevHow well does it compare to the original un-minified code if you compare it against minify + humanify. Would be neat if it can improve mediocre code. reply sebstefan 3 hours agoparentprevWhat kind of question does it ask the LLM? Giving it a whole function and asking \"What should we rename ?\" repeatedly until everything has been renamed? Asking it to do it on the whole thing, then parsing the output and checking that the AST still matches? reply jehna1 27 minutes agorootparentFor each variable: 1. It asks the LLM to write a description of what the variable does 2. It asks for a good variable name based on the description from 1. 3. It uses a custom Babel plugin to do a scope-aware rename This way the LLM only decides the name, but the actual renaming is done with traditional and reliable tools. reply firtoz 5 hours agoparentprevMore tools should be built on ASTs, great work! I'm still waiting for the AST level version control tbh reply jansvoboda11 5 hours agorootparentUnison supposedly has an AST-aware version control system: https://www.unison-lang.org/ reply timcobb 4 hours agorootparentWow this looks so cool. reply LoganDark 3 hours agorootparentprevcontent-addressed too, I think! reply rightonbrother 1 hour agorootparentprevSmalltalk envy source controll reply thrdbndndn 2 hours agoparentprevDoes it work with huge files? I'm talking about something like 50k lines. Edit: I'm currently trying it with a mere 1.2k JS file (openai mode) it's only 70% done after 20 minutes. Even if it works therodically with 50k LOC file, I don't think you should try. reply jehna1 22 minutes agorootparentIt does work with any sized file, although it is quite slow if you're using the OpenAI API. HumanifyJS works so it processes each variable name separately, and keeps the context size manageable for an LLM. I'm currently working on parallelizing the rename process, which should give orders of magnitude faster processing times for large files. reply kingsloi 1 hour agorootparentprevIt has this in the README > Large files may take some time to process and use a lot of tokens if you use ChatGPT. For a rough estimate, the tool takes about 2 tokens per character to process a file: > echo \"$((2 * $(wc -cSo for refrence: a minified bootstrap.min.js would take about $0.5 to un-minify using ChatGPT. > Using humanify local is of course free, but may take more time, be less accurate and not possible with your existing hardware. reply thrdbndndn 1 hour agorootparentThis only talks about the cost. I'm more concerned about if it can actually deobfuscate such large file (context) and generate useful results. reply punkpeye 6 hours agoparentprevLooks useful! I will update the article to link to this tool. Thanks for sharing! reply boltzmann-brain 3 hours agoparentprevhow do you make an LLM work on the AST level? do you just feed a normal LLM a text representation of the AST, or do you make an LLM where the basic data structure is an AST node rather than a character string (human-language word)? reply jehna1 15 minutes agorootparentI'm using both a custom Babel plugin and LLMs to achieve this. Babel first parses the code to AST, and for each variable the tool: 1. Gets the variable name and surrounding scope as code 2. Asks the LLM to come up with a good name for the given variable name, by looking at the scope where the variable is 3. Uses Babel to make the context-aware rename to AST based on the LLM's response reply WhitneyLand 2 hours agorootparentprevThe frontier models can all work with both source code and ASTs as a result of their standard training. Knowing this raises the question, which is better to feed an LLM source code of ASTs? The answer is really it depends on the use case, there are tradeoffs. For example keeping comments intact possibly gives the model hints to reason better. On the other side, it can be argued that a pure AST has less noise for the model to be confused by. There are other tradeoffs as well. For example, any analysis relating to coding styles would require the full source code. reply dunham 2 hours agorootparentprevIt looks like they're running `webcrack` to deobfuscate/unminify and then asking the LLM for better variable names. reply KolmogorovComp 4 hours agoparentprevThanks for your tool. Have you been able to quantify the gap between your local model and chatgpt in terms of ‘unminification performance’? reply jehna1 12 minutes agorootparentAt the moment I haven't found good ways of measuring the quality between different models. Please share if you have any ideas! For small scripts I've found the output to be very similar between small local models and GPT-4o (judging by a human eye). reply fny 5 hours agoparentprevIs it possible to add a mode that doesn't depend on API access (e.g. copy and paste this prompt to get your answer)? Or do you make roundtrips? reply jehna1 4 hours agorootparentThere is a fully local mode that does not use ChatGPT at all – everything happens on your local machine. API access of ChatGPT mode is needed as there are many round trips and it uses advanced API-only tricks to force the LLM output. reply benreesman 57 minutes agoparentprevCame here to say Humanify is awesome both as a specific tool and in my opinion a really great way to think about how to get the most from inherently high-temperature activities like modern decoder nucleus sampling. +1 reply cryptoz 3 hours agoparentprevFinally someone else using ASTs while working with LLMs and modifying code! This is such an under-utilized area. I am also doing this with good results: https://codeplusequalsai.com/static/blog/prompting_llms_to_m... reply lifthrasiir 7 hours agoprevJS minification is fairly mechanical and comparably simple, so the inversion should be relatively easy. It would be of course tedious enough to be manually done in general, but transformations themselves are fairly limited so it is possible to read them only with some notes to track mangled identifiers. A more general unminification or unobfuscation still seems to be an open problem. I wrote handful of programs that are intentionally obfuscated in the past and ChatGPT couldn't understand them even at the surface level in my experience. For example, a gist for my 160-byte-long Brainfuck interpreter in C had some comment trying to use GPT-4 to explain the code [1], but the \"clarified version\" bore zero similarity with the original code... [1] https://gist.github.com/lifthrasiir/596667#gistcomment-47512... reply panda-giddiness 7 hours agoparent> JS minification is fairly mechanical and comparably simple, so the inversion should be relatively easy. Just because a task is simple doesn't mean its inverse need be. Examples: - multiplication / prime factorization - deriving / integrating - remembering the past / predicting the future Code unobfuscation is clearly one of those difficult inverse problems, as it can be easily exacerbated by any of the following problems: - bugs - unused or irrelevant routines - incorrect implementations that incidentally give the right results In that sense, it would be fortunate if chatGPT could give decent results at unobfuscating code, as there is no a priori expectation that it should be able to do so. It's good that you've also checked chatGPT's code unobfuscation capabilities on a more difficult problem, but I think you've only discovered an upper limit. I wouldn't consider the example in the OP to be trivial. reply lifthrasiir 6 hours agorootparentOf course, it is not generalizable! In my experience though, most minifiers do only the following: - Whitespace removal, which is trivially invertible. - Comment removal, which we never expect to recover via unminification. - Renaming to shorter names, which is tedious to track but still mechanical. And most minifiers have little understanding of underlying types anyway, so they are usually very conservative and rarely reuse the same mangled identifier for multiple uses. (Google Closure Compiler is a significant counterexample here, but it is also known to be much slower.) - Constant folding and inlining, which is annoying but can be still tracked. Again, most minifiers are limited in their reasoning to do extensive constant folding and inlining. - Language-specific transformations, like turning `a; b; c;` into `a, b, c;` and `if (a) b;` into `a && b;` whenever possible. They will be hard to understand if you don't know in advance, but there aren't too many of them anyway. As a result, minified code still remains comparably human-readable with some note taking and perseverance. And since these transformations are mostly local, I would expect LLMs can pick them up by their own as well. (But why? Because I do inspect such programs fairly regularly, for example for comments like https://news.ycombinator.com/item?id=39066262) reply cal85 4 hours agorootparentI feel you’re downplaying the obfuscatory power of name-mangling. Reversing that (giving everything meaningful names) is surely a difficult problem? reply chucksmash 4 hours agorootparentJSNice[1] is an academic project that did a pretty good job of this in the 2010s and they give some pointers on how it is accomplished[2]. [1]: http://jsnice.org/ [2]: https://www.sri.inf.ethz.ch/jsnice reply lifthrasiir 4 hours agorootparentprevI would say the actual difficulty greatly varies. It is generally easy if you have a good guess about what the code would actually do. It would be much harder if you have nothing to guess, but usually you should have something to start with. Much like debugging, you need a detective mindset to be good at reverse engineering, and name mangling is a relatively easy obstacle to handle in this scale. Let me give some concrete example from my old comment [1]. The full code in question was as follows, with only whitespaces added: function smb(){ var a,b,c,d,e,h,l; return t(function(m){ a=new aj; b=document.createElement(\"ytd-player\"); try{ document.body.prepend(b) }catch(p){ return m.return(4) } c=function(){ b.parentElement&&b.parentElement.removeChild(b) }; 0 player, c -> removePlayer, d -> playerDiv1, e -> playerDiv2, h -> playerVideo, l -> blob (we don't know which blob it is yet though). We still don't know about non-local names including t, aj, lc, Mia and m, but we are reasonably sure that it builds some DOM tree that looks like ``. We can also infer that `removePlayer` would be some sort of a cleanup function, as it gets eventually called in any possible control flow visible here. Given that `a.resolve` is the final function to be executed, even later than `removePlayer`, it will be some sort of \"returning\" function. You will need some information about how async functions are desugared to fully understand that (and also `m.return`), but such information is not strictly necessary here. In fact, you can safely ignore `lc` and `Mia` because it eventually sets `playerVideo.src` and we are not that interested in the exact contents here. (Actually, you will fall into a rabbit hole if you are going to dissect `Mia`. Better to assume first and verify later.) And from there you can conclude that this function constructs a certain DOM tree, sets some class after 200 ms, and then \"returns\" 0 if the video \"ticks\" or 1 on timeout, giving my initial hypothesis. I then hardened my hypothesis by looking at the blob itself, which turned out to be a 3-second-long placeholder video and fits with the supposed timeout of 5 seconds. If it were something else, then I would look further to see what I might have missed. [1] https://news.ycombinator.com/item?id=38346602 reply fkyoureadthedoc 3 hours agorootparentI believe the person you're responding to is saying that it's hard to do automated / programmatically. Yes a human can decode this trivial example without too much effort, but doing it via API in a fraction of the time and effort with a customizable amount of commentary/explanation is preferable in my opinion. reply cjf101 3 hours agorootparentprevThis is, IMO, the better way to approach this problem. Minification applies rules to transform code, if we know the rules, we can reverse the process (but can't recover any lost information directly). A nice, constrained, way to use a LLM here to enhance this solution is to ask it some variation of \"what should this function be named?\" and feed the output to a rename refactoring function. You could do the same for variables, or be more holistic and ask it to rename variables and add comments (but risk the LLM changing what the code does). reply refulgentis 2 hours agorootparentprevHow do we end up with you pasting large blocks of code and detailed step-by-step explanations of what it does, in response to someone noting that just because process A is simple, it doesn't mean inverting A is simple? This thread is incredibly distracting, at least 4 screenfuls to get through. I'm really tired of the motte/bailey comments on HN on AI, where the motte is \"meh the AI is useless, amateurish answer thats easy to beat\" and bailey is \"but it didn't name a couple global variables '''correctly'''.\" It verges on trolling at this point, and is at best self-absorbed and making the rest of us deal with it. reply mgkimsal 5 hours agorootparentprev> As a result, minified code still remains comparably human-readable with some note taking and perseverance. At least some of the time, simply taking it and reformatting to be unfolded and on multiple lines is useful enough to be readable/debuggable. FIXING that bug is likely more complex, because you have to find where it is in the original code, which, to my eyes, isn't always easy to spot. reply drakythe 4 hours agorootparentprevAs a point of order Code Minification != Code Obfuscation. Minification does tend to obfuscate as as side effect, but it is not the goal, so reversing minification becomes much easier. Obfuscation on the other hand can minify code, but crucially that isn't the place it starts from. As the goal is different between minificaiton and obfuscation reversing them takes different efforts and I'd much rather attempt to reverse minification than I would obfuscation. I'd also readily believe there are hundreds/thousands of examples online of reverse code minification (or here is code X, here is code X _after_ minifcation) that LLMs have ingested in their training data. reply jmb99 3 hours agorootparentYeah, having run some state of the art obfuscated code through ChatGPT, it still fails miserably. Even what was state of the art 20 years ago it can't make heads or tails of. reply johnfn 2 hours agoparentprev> JS minification is fairly mechanical and comparably simple, so the inversion should be relatively easy. This is stated as if it's a truism, but I can't understand how you can actually believe this. Converting `let userSignedInTimestamp = new Date()` to `let x = new Date()` is trivial, but going the other way probably requires reading and understanding the rest of the surrounding code to see in what contexts `x` is being used. Also, the rest of the code is also minified, making this even more challenging. Even if you do all that right, it's at best it's still a lossy conversion, since the name of the variable could capture characteristics that aren't explicitly outlined in the code at all. reply hluska 1 hour agorootparentAnd I can’t understand why any reasonably intelligent human feels the need to be this abrasive. You could educate but instead you had to be condescending. reply viscanti 2 hours agorootparentprevBecause of how trivial that step is, it's likely pretty easy to just take lots of code and minify it. Then you have the training data you need to learn to generate full code from minified code. If your goal is to generate additional useful training data for your LLM, it could make sense to actually do that. reply wwarner 1 hour agorootparentI suspect, but definitely do not know, that all the coding aspects of llms work something like this. It’s such a fundamentally different problem from a paragraph, which should never be the same as any other paragraph. Seems to me that coding is a bit more like the game of go, where an absolute score can be used to guide learning. Seed the system with lots and lots of leetcode examples from reality, and then train it to write tests, and now you have a closed loop that can train itself. reply viscanti 1 hour agorootparentIf you're able to generate minified code from all the code you can find on the internet, you end up with a very large training set. Of course in some scenarios you won't know what the original variable names were, but you would expect to be able to get something very usable out of it. These things, where you can deterministically generate new and useful training data, you would expect to be used. reply Max-q 6 hours agoparentprevConverting a picture from color to black and white is a fairly simple task. Getting back the original in color is not easy. This is if course due to data lost in the process. Minification works in the same way. A lot of information needed for understanding the code is lost. Getting back that information can be a very demanding task. reply lifthrasiir 6 hours agorootparentBut it is not much different from reading through badly documented codes without any comments or meaningful names. In fact, many codes to be minified are not that bad and thus it is often possible to infer the original code just from its structure. It is still not a trivial task, but I think my comment never implied that. reply Earw0rm 4 hours agoparentprevYep, I've tried to use LLMs to disassemble and decompile binaries (giving them the hex bytes as plaintext), they do OK on trivial/artificial cases but quickly fail after that. reply GaggiX 7 hours agoparentprevRandom try (the first one) with Claude 3.5 Sonnet: https://claude.site/artifacts/246c1b1a-3088-447a-a526-b1e716... I'm not on PC so it's not tested. reply lifthrasiir 6 hours agorootparentThat's much better in that most of the original code remains present and comments are not that far off, but its understanding of global variables are utterly wrong (to be expected though, as many of them serve multiple purposes). reply bdcravens 1 hour agoprevI'm sure there's some number greater than zero of developers who are upset because they use minification as a means of obfuscation. Reminds me of the tool that was provided in older versions of ColdFusion that would \"encrypt\" your code. It was a very weak algorithm, and didn't take long for someone to write a decrypter. Nevertheless some people didn't like this, because they were using this tool, thinking it was safe for selling their code without giving access to source. (In the late 90s/early 2000s before open source was the overwhelming default) reply ninetyninenine 2 hours agoprevThis is an example of superior intellectual performance to humans. There’s no denying it. This task is intellectual. Does not involve rote memorization. There are not tons and tons of data pairs on the web of minimized code and unminified code for llms to learn from. The llm understands what it is unminifying and it is in general superior to humans on this regard. But only in this specific subject. reply indoordin0saur 1 hour agoparentThis is just transforming text. > There are not tons and tons of data pairs on the web of minimized code and unminified code for llms to learn from. Are you sure about this? These can be easily generated from existing JS to use as a training set, not to mention the enormous amount of non-minified JS which is already used to train it. reply danbolt 1 hour agoparentprevI don’t claim expertise in AI or understanding intelligence, but could we also say that a pocket calculator really understands arithmetic and has superior intellectual performance compared to humans? reply ninetyninenine 54 minutes agorootparenthttps://chatgpt.com/share/a430518b-16f8-47bb-8cb7-d9b8518376... reply ozr 1 hour agoparentprevI'm bullish on AI, but I'm not convinced this is an example of what you're describing. The challenge of understanding minified code for a human comes from opaque variable names, awkward loops, minimal whitespacing, etc. These aren't things that a computer has trouble with: it's why we minify in the first place. Attention, as a scheme, should do great with it. I'd also say there is tons of minified/non-minified code out there. That's the goal of a map file. Given that OpenAI has specifically invested in web browsing and software development, I wouldn't be surprised if part of their training involved minified/unminified data. reply ninetyninenine 52 minutes agorootparentminification and unminification is a heuristic process not an algorithmic one. It is akin to decompiling code or reverse engineering. It's a step beyond just your typical AI you see in a calculator. reply gmd63 1 hour agoparentprev> Does not involve rote memorization. There are not tons and tons of data pairs on the web of minimized code and unminified code for llms to learn from. GPT-4 has consumed more code than your entire lineage ever will and understands the inherent patterns between code and minified versions. Recognizing the abstract shape of code sans variable names and mapping in some human readable variable names from a similar pattern you've consumed from the vast internet doesn't seem farfetched. reply okanat 24 minutes agorootparentAnd a human can do it without seeing that amount of code and consuming less energy. reply plaidfuji 1 hour agoparentprevI think I’d agree with your statement, in the same sense that a chess simulator or AlphaGo are superior to human intellect for their specific problem spaces. LLMs are very good at a surprisingly broad array of semi-structured-text-to-semi-structured-text transformations, particularly within the manifold of text that is widely available on the internet. It just so happens that lots of code is widely available on the internet, so LLMs tend to outperform on coding tasks. There’s also lots of marketing copy, general “encyclopedic” knowledge, news, human commentary, and entertainment artifacts (scripts, lyrics, etc). LLMs traverse those spaces handily as well. The capabilities of AI ultimately boil down to their underlying dataset and its quality. reply mplewis 1 hour agoparentprevYeah, ok. Now count the number of Rs in this word. reply albert_e 7 hours agoprevShould the title say ChatGPT or gpt-4 (the model) instead of OpenAI (the company)? reply dantondwa 6 hours agoparentThere is a certain justice in the use of OpenAI as a name for their product, given that OpenAI has turned the generic technical GPT name into a brand. reply j_maffe 4 hours agorootparentGPT is not a brand. A court ruling turned down that notion. It's a technology. reply latexr 4 hours agorootparentThat only means it’s not a legally recognised brand, but it is a brand nonetheless if people associate the two (and they do). A bit like the way people associate tissue paper with Kleenex, or photocopies with Xerox, or git with GitHub. reply j_maffe 2 hours agorootparentI wonder if OpenAI will stick with the GPT acronym, given that most people don't know what it's an acronym for and it's a bit of a mouthful. reply ChadNauseam 5 hours agorootparentprevThe generative pretrained transformer was invented by OpenAI, and it seems reasonable for a company to use the name it gave to its invention in its branding. Of course, they didn't invent Generative pretraining (GP) or transfomers (T) but AFAIK they were the first to publicly combine them reply cbm-vic-20 7 hours agoparentprevI left my Kleenex next to the Xerox. reply taneq 7 hours agorootparentBetter Hoover it up! reply dubcanada 5 hours agorootparentAll jokes aside, I've never heard anyone call vacuuming hoover. I wonder if that was a older statement? reply dmd 4 hours agorootparentEveryone I know from the UK says \"hoovering\" 100% of the time instead of vacuuming. reply commodoreboxer 5 hours agorootparentprevI have, but only as an idiom, never literally. E.g. \"Microsoft just keeps hoovering up companies\", but the literal act of vacuuming is only called vacuuming. reply justneedaname 5 hours agorootparentprevIn the UK it's very common reply joseda-hg 4 hours agorootparentprevIt might just be a regionalism, it's not uncommon that such genericization only applies to specific dialects (Like calling all sodas coke) reply bigstrat2003 4 hours agorootparentprevI've also never heard anyone call photocopying \"xeroxing\". I'm guessing maybe it's an age thing. reply albert_e 4 hours agorootparentgrowing up in India over past 4 decades .. 'Xerox' was/is the default and most common word used for photocopying ... only recently have I started using/hearing the term 'photocopy'. every town and every street had \"XEROX shops\" where people went to get various documents photocopied for INR 1 per page for example Most photocopy centers are still called XEROX Shops -- and their boards say that in big bold text: https://www.google.com/search?q=xerox+shop+india&udm=2 It doesnt matter if they use Canon, HP, or other brands of machines reply latexr 4 hours agorootparentprevIt depends on the region. In certain countries Gillette is used for any shaving razor. reply taneq 4 hours agorootparentprevIt was the fashion at the time, even if the hoover did keep bumping the onion. (This is actually really interesting, I had no idea that 'hoover' was specifically a U.K. thing that didn't make it to the U.S.) reply bdsa 5 hours agorootparentprevMore common in the UK reply BeetleB 3 hours agorootparentprevI got hurt doing it so applied some Bandaids. reply Stratoscope 3 hours agorootparentDon't say Velcro! https://www.youtube.com/results?search_query=don't+say+velcr... (Content warning: profanity. This search page is SFW, but the videos it links to may not be.) reply punkpeye 7 hours agoparentprevIt would have been a better title, yes. reply ubj 7 hours agoparentprevI agree, this would make the title more accurate. reply johnisgood 7 hours agoparentprevI think it should not say the name of the company, but either ChatGPT or GPT-x. reply whimsicalism 2 hours agoparentprevmore likely to get downvotes that way, potentially even downweighted reply j_maffe 7 hours agoprevLLMs are excellent at text transformation. It's their core strength and I don't see it being used enough. reply xanderlewis 7 hours agoparentIt’s not only their core strength — it’s what transformers were designed to do and, arguably, it’s all they can do. Any other supposed ability to reason or even retain knowledge (rather than simply regurgitate text without ‘understanding’ its intended meaning) is just a side effect of this superhuman ability. reply stavros 7 hours agorootparentI see your point, but I think there's more to it. It's kind of like saying \"all humans can do is perceive and produce sound, any other ability is just a side-effect\". We might be focusing too much on their mechanism for \"perception\" and overlooking other capabilities they've developed. reply mjburgess 6 hours agorootparentSure, but that claim wouldn't be true for humans, right? So it's a nonsequiteur. The relevant claim would be: all humans can do is move around in their environments, adapt the world around them through action, observe using adaptive sensory motor systems, grow and adapt their brains and bodies in response to novel and changing environments, abstract sensory motor techniques into symbolic concepts, vocalize this using inherited systems of meaning acquired as very young children in adaption within their environments, etc. In the case of transformers all they can do is, in fact, sample from a compression of historical texts using a weighted probability metric. If you project both of these into \"problems an office worker has\"-space, then they can appear simimlar -- but this projection is an incredibly dumb one, and offered as a sales pitch by charlatans looking to pretend that a system which can generate office emails can communicate. reply fenomas 4 hours agorootparent> all they can do is, in fact, sample from a compression of historical texts To me, results like the Othello paper make any sort of \"stochastic parrot\" thinking completely untenable. https://thegradient.pub/othello/ reply mjburgess 2 hours agorootparentAbstract functions are fully representable by function approximations in the limit n->inf; ie., sampling from a circle becomes a circle as samples -> infinity. This makes all \"studies\" whose aim is to approximate a fully representable abstract mathematical domain irrelevant to the question. This is just more evidence of the naivety, mendacity, and pseudoscientific basis of ML and its research. reply samatman 3 hours agorootparentprevThis result is an argument for the conclusion you are reading it as arguing against. reply diego_sandoval 5 hours agorootparentprev> all they can do is, in fact, sample from a compression of historical texts using a weighted probability metric. I don't think that's all they can do. I think they know more than what is explicitly stated in their training sets. They can generalize knowledge and generalize relationships between the concepts that are in the training sets. They're currently mediocre at it, but the results we observe from SOTA generative models are not explainable without accepting that they can create an internal model of the world that's more than just a decompression algorithm. I'm going to step away from LLMs for a moment, but: How are video generator models capable of creating videos with accurate shadows and lighting that is consistent in the entire frame and consistent between frames? You can't do that simply by taking a weighted average of the sections of videos you've seen in your training set. You need to create an internal 3D model of the objects in the scene, and their relative positions in space across the length of the video. And no one told the model explicitly how to do that, it learned to do it \"on its own\". I think the same principle applies to LLMs. reply carlmr 2 hours agorootparent>You need to create an internal 3D model of the objects in the scene, and their relative positions in space across the length of the video. And no one told the model explicitly how to do that, it learned to do it \"on its own\". Compression is understanding. If you have a model which explains shadows you can compress your video data much better. Since you \"understand\" how shadows work. reply baq 7 hours agorootparentprev> it’s all they can do this overlooks how they do it. we don't really know. it might be logical reasoning, it might be a very efficient content addressable human-knowledge-in-a-blob-of-numbers lookup table... it doesn't matter if they work, which they do, sometimes scarily well. dismissing their abilities because they 'don't reason' is missing the forest for the trees in that they'd be capable of reasoning if they were able to run sat solvers on their output mid generation. reply SiempreViernes 6 hours agorootparentDismissing claims that LLMs \"reason\" because these machines perform no actions similar to reasoning seems pretty motivated. And I don't think \"blindly take input from a reasoning capable system\" counts as reasoning. reply foobarbecue 6 hours agorootparent\"pretty motivated\"? Did you mean biased? reply ChadNauseam 5 hours agorootparentI assume they meant motivated as shorthand for \"motivated reasoning\" which implies a bias that's motivating them to reason a certain way reply hobs 6 hours agorootparentprevDoes it? I think Blindsight (the book) had a good commentary on reason being a thing we think is a conscious process but doesn't have to be. I think most people talking past each other are really discussing whether the GPT is conscious, has a mental model of self, that kind of thing, as long as your definition of reasoning doesn't include consciousness it clearly does it (though not well.) reply sitkack 3 hours agorootparentprevHinton claims they do reason. I am going to go with Hinton on this. reply PaulHoule 7 hours agoparentprevParticularly those that are basically linear, that don’t involve major changes in the order of things or a deep consideration of relationships between things. They can’t sort a list but they can translate languages, for instance, given that a list sorted almost right is wrong but that we will often settle for an almost right translation. reply worldsayshi 7 hours agoparentprevOne potential benefit should be that with the right tooling around it it should be able to translate your code base to a different language and/or framework more or less at the push of a button. So if a team is wondering if it would be worth it to switch a big chunk of the code base from python to elixir they don't have to wonder anymore. I tried translating a python script to javascript the other day and it was flawless. I would expect it to scale with a bit of hand-railing. reply adamdiy 7 hours agorootparentsee projects like https://github.com/joshpxyne/gpt-migrate think there's also a YC company recently focusing on the nasty, big migrations with LLM help reply worldsayshi 7 hours agorootparentIt seems that this kind of application can really change how the tech industry can evolve down the line. Maybe we will more quickly converge on tech stacks if everyone can test new one's out \"within a week\". reply scarface_74 7 hours agorootparentprevChatGPT is trained well enough on all things AWS that it can do a decent job translating Python based SDK code to Node and other languages, translate between CloudFormation/Terraform/CDK (in various languages). It does a well at writing simple to medium complexity automation scripts around AWS. If it gets something wrong, I tell it to “verify your answer using the documentation available on the web” reply kamaal 5 hours agorootparent>>ChatGPT is trained well enough on all things AWS It was scary to me how to chatting with GPT or Claude would give me information which was a lot more clear than what I could deduce after hours of reading AWS documentation. Perhaps, the true successor to Google search has arrived. One big drawback of Google was asking questions that can't be converted to a full long conversation. To that end. LLM chat is the ultimate socratic learning method tool till date. reply cdelsolar 4 hours agorootparentChatGPT is phenomenal for trying new techniques/libraries/etc. It's very good at many things. In the past few weeks I've used it to build me a complex 3D model with lighting/etc with Three.JS, rewrote the whole thing into React Three Fiber (also with ChatGPT), for a side project. I've never used Three.JS before and my only knowledge of computer graphics is from a class I took 20 years ago. For work I've used it to write me a CFN template from scratch and help me edit it. I've also used it to try a technique with AST - I've never used ASTs before and the first thing ChatGPT generated was flawless. Actually, most of the stuff I have it generate is flawless or nearly flawless. It's nothing short of incredible. Each of those tasks would normally have taken me hours and I have working code in actual seconds. reply kamaal 3 hours agorootparentAnd we are still at the beginning of this. Some what like where Google search was in early 2000s. As IDE integration grows and there are more and better models, that can do this better than ever. We will unlock all sort of productivity benefits. There is still skepticism about making these work at scale, with regards to both electricity and compute requirement for the larger audience. But if they can get this to work, we might see a new era tech boom way bigger than we have seen anything before. reply pton_xd 3 hours agorootparentI see your point but that specific analogy makes me wince. Google search was way better in the 2000s. It has become consistently dumber since then. Usefulness doesn't necessarily increase in a straight line over time. reply msp26 7 hours agoparentprevIsn't this already their main use case for business? We use them primarily for extracting structured data from other forms. reply greenthrow 7 hours agoparentprevThe problem is the use case is where you don't care about the risk of hallucinations or you can validate the output without already having the data in a useful format. Plus you need to lack the knowledge/skill to do it more quickly using awk/python/perl/whatever. reply j_maffe 4 hours agorootparentI think text transformation is a sufficiently predictable task that one could make a transformer that completely avoids hallucinations. Most LLMs have high temperatures which introduces randomness and therefore hallucinations into the result. reply worldsayshi 7 hours agorootparentprevThat's why having good test suites and tools are more important than ever. reply jackconsidine 5 hours agoprevThat's interesting. It's gotten a lot better I guess. A little over a year ago, I tried to use GPT to assist me in deobfuscating malicious code (someone emailed me asking for help with their hacked WP site via custom plugin). I got much further just stepping through the code myself. After reading through this article, I tried again [0]. It gave me something to understand, though it's obfuscated enough to essentially eval unreadable strings (via the Window object), so it's not enough on it's own. Here was an excerpt of the report I sent to the person: > For what it’s worth, I dug through the heavily obfuscated JavaScript code and was able to decipher logic that it: > - Listens for a page load > - Invokes a facade of calculations which are in theory constant > - Redirects the page to a malicious site (unk or something) [0] https://chatgpt.com/share/f51fbd50-8df0-49e9-86ef-fc972bca6b... reply fasteddie31003 3 hours agoprevI recognized this a few months back when I wanted to see the algorithm that a website used to do a calculation. I just put the minified JS in ChatGPT and figured it out pretty easily. Let's take this a few steps out. What happens when a LLM can clone a whole SAAS app? Let's say I wanted to clone HubSpot. If an LLM can interact with a browser and figure out how a UI works and take code hints from un-mimified code I think we could see all SAAS apps be commoditized. The backend would be proprietary, but it could figure out API formats and suggest a backend architecture. All this makes me think AI's are going to be a strong deflationary force in the future. reply sgt101 3 hours agoparentI was with you until: >If an LLM can interact with a browser and figure out how a UI works and take code hints from un-mimified code I think we could see all SAAS apps be commoditized. The backend would be proprietary, but it could figure out API formats and suggest a backend architecture. whoooha! that's a lot of probing and testing of the SAAS that would be required in order to see how it behaved. SAAS aren't algorithms, they operate over data that's unseen on the front end as well... >All this makes me think AI's are going to be a strong deflationary force in the future. I don't get this. I've literally never worked anywhere which had enough software engineers, we've been going on about software crisis for about 50 years and things are arguably worse than ever. The gap between the demand for good software (in the sense that allocating capital to producing it would be sensible) and the fulfillment of that demand is bigger than ever. We just don't have the mechanisms to make this work and to make it work at an economically viable level. Then we get AI to help us and everyone thinks that the economy will shrink? reply IncreasePosts 2 hours agorootparentYou wouldn't necessarily need to do much probing - consider that the documentation would provide numerous hints to the agent as to what each endpoint was actually doing. reply TheKarateKid 2 hours agoparentprevHonestly, the value in most business software isn't the actual technology. It's the customer base and data held by the platforms. Someone could already easily clone HubSpot relatively cheaply even if they hired developers, but that doesn't mean it will be anywhere near successful. reply eqvinox 7 hours agoprevOkay, but if the unminified code doesn't match the minified code (as noted at the end \"it looks like LLM response overlooked a few implementation details\"), that massively diminishes its usefulness — especially since in a lot of cases you can't trivially run the code and look for differences like the article does. [ed.: looks like this was an encoding problem, cf. thread below. I'm still a little concerned about correctness though.] reply jehna1 6 hours agoparentYou need to use another tool to do the actual renames, like HumanifyJS does: https://github.com/jehna/humanify reply lifthrasiir 7 hours agoparentprevIt does seem that the unminified code is very close to the original. In some cases ChatGPT even did its own refactoring in addition to the unminification: // ORIGINAL: j.useEffect(() => { function r() { n({ height: window.innerHeight, width: window.innerWidth }); } if (typeof windowwindow.removeEventListener(\"resize\", r); }, []), // UNMINIFIED: useEffect(() => { const handleResize = () => { setSize({ height: window.innerHeight, width: window.innerWidth }); }; // Initial size setting handleResize(); window.addEventListener('resize', handleResize); return () => { window.removeEventListener('resize', handleResize); }; }, []); Note that the original code doesn't call `handleResize` immediately, but have its contents inlined instead. (Probably the minifier did the actual inlining.) The only real difference here is a missing `if (typeof window > Repair Text Encoding\" in Firefox, it shows the block characters. But I have to admit, it's strange that Firefox does not choose UTF-8 by default in this case. reply punkpeye 6 hours agorootparentYes, turns out I was the one who made the mistake. I updated the article to reflect the mistake. > Update (2024-08-29): Initially, I thought that the LLM didn’t replicate the logic accurately because the output was missing a few characters visible in the original component (e.g., ). However, a user on HN forum pointed out that it was likely a copy-paste error. > > Upon further investigation, I discovered that the original code contains different characters than what I pasted into ChatGPT. This appears to be an encoding issue, as I was able to get the correct characters after downloading the script. After updating the code to use the correct characters, the output is now identical to the original component. > > I apologize, GPT-4, for mistakenly accusing you of making mistakes. reply dn3500 4 hours agorootparentprevIf no character set is specified, plain text content is assumed to be 1252. This probably extends to application/javascript as well but I'd have to check to be sure. The web pre-dates utf-8, although not by much. Ken Thompson introduced utf-8 at winter Usenix in 1993 and CERN released the web in April, but it would be several more years before utf-8 became common. The early web was ISO 8859-1 by default. But people were pretty lazy about specifying character sets back then (still are actually) and Microsoft started sending or assuming their 1252 character set where 8859-1 was required by the spec. Eventually the spec was changed to match de facto behavior. I guess the assumption was that if you're too stupid or lazy to say what character set you're using, then it's probably 1252. (Today the assumption would be that it's probably utf-8). I'm not sure what the specs say today, but I think html is assumed to be in utf-8, and everything else is assumed to be 1252 (if the character set is not explicitly declared). reply Mashimo 7 hours agoparentprevHe also told it to reimplement from JavaScript to TypeScript. I would guess if he just told it to rename the variables and method first, it would have been closer to the original. reply creesch 7 hours agoprevThis is very close to how I often use LLMs [0]. A first step in deciphering code where I otherwise would need to, to use the authors words, power through reading the code myself. It has been incredibly liberating to just feed it a spaghetti mess, ask to detangle it in a more readable way and go from there. As the author also discovered, LLMs will sometimes miss some details, but that is alright as I will be catching those myself. Another use case is when I understand what the code does, but can't quite wrap my head around why it is done in that specific way. Specifically, where the author of the code is no longer with the company. I will then simply put the method in the LLM chat, explain what it does, and just ask it why some things might be done in a specific way. Again, it isn't always perfect, but more often than not it comes with explanations that actually make sense, hold up under scrutiny and give me new insights. It actually has prevented me once or twice from refactoring something in a way that would have caught me headaches down the line. [0] chatGPT and more recently openwebUI as a front end to various other models (Claude variants mostly) to see the differences. Also allows for some fun concepts of having different models review each others answers. reply joshdavham 40 minutes agoprevAre there any serious security implications for this? Of course obfuscation through minification won't work anymore, but I'm not sure if that's really all that serious of an issue at the end of the day. reply redbell 3 hours agoprevThat's an interesting finding so far! > The provided code is quite complex, but I'll break it down into a more understandable format, explaining its different parts and their functionalities. Reading the above statement generated by ChatGPT, I asked myself: Will we live to the day where these LLMs could take a large binary executable as input, read it, analyze it, understand it, then reply with the above statement? > I followed up asking to \"implement equivalent code in TypeScript and make it human readable\" and got the following response.. To my surprise, the response is not only good enough, but it is also very readable. What if this day came and we can ask these LLMs to rewrite the binary code in [almost] any programming language we want? This would be exciting, yet scary to just think about! reply martythemaniak 3 hours agoparentYou should give it a try and report back! One easy way would be to take an open-source Android app, compile the APK, then decompile it and feed the bytecode to an LLM and ask it to write the java/kotlin equivalent and compare the source and LLM decoded one. reply Teever 3 hours agoparentprevhttps://sam.gov/opp/1e45d648886b4e9ca91890285af77eb7/view reply nutanc 6 hours agoprevHad tweeted about this sometime back. Found a component which was open source earlier and then removed and only minfied JS was provided. Give the JS to Claude and get the original component back. It even gave good class names to the component and function names. Actually this opens up a bigger question. What if I like an open source project but don't like its license. I can just prompt AI by giving it the open source code and ask it to rewrite it or write in some other language. Have to look up the rules if this is allowed or will be considered copying and how will a judge prove? reply lifthrasiir 6 hours agoparentAlmost likely you would be found guilty because the intent matters. It is easy to check that the generated code is much similar to the original code, and you surely had a reason to bypass the original license. The exact legal reasoning would vary but any reasonable laywer would recommend you to do not. In the historic Google v. Oracle suit, the only actual code that was claimed to be copied was a trivial `rangeCheck` function, but Google's intent and other circumstances like the identical code structure and documentation made it much more complicated, and the final decision completely bypassed the copyrightability of APIs possibly for this reason. reply gnutrino 3 hours agoprevThe site the post mentions for the original code (https://reactive.network/hackathon) is an accessibility nightmare. reply lelandfe 2 hours agoparentThe garbled text is included in the tree as relevant, pronounceable, and constantly changing text. Here's Chrome's accessibility tree: https://imgur.com/a/V1589Jr (I'd love if a screen reader user could upload some audio of how awful this sounds, by the by) Please use `aria-hidden=\"true\"` for stuff like this, it just removes the element from the accessibility tree. I've also emailed Reactive a link to this thread. Here is a decent intro to ARIA things: https://www.smashingmagazine.com/2022/09/wai-aria-guide/ reply interstice 7 hours agoprevHave used Claude to reverse engineer some minified shopify javascript code recently. Definitely handy for unpicking things. reply Tistel 3 hours agoprevThis might be fun: Train on java compiled to class files. Then go from class back to java. Or even: Train java compiled to class files, and have separate models that train from Clojure to class and Scala to class files. Then see if you can find some crufty (but important) old java project and go: crufty java -> class -> Clojure (or Scala). If you could do the same with source -> machine instructions, maybe COBAL to C++! or whatever. reply sitkack 3 hours agoparentI agree, it is fun! LLM source recovery from binaries is thing. The amazing part is that they are pretty good at adding back meaningful variable names to the generated source code. reply igorguerrero 3 hours agoparentprevThis is something you don't need AI for, there are many decompilers out there already as well. AI cannot even lint properly right now and you want it to decompile? good luck, there's too much hype going on people really think this is possible this year? In the end always remember it's just autocomplete, it's pretty terrible at translations that are not natural language to natural language. I worked on a natural language to SQL and it was impossible to make it consistently generate valid SQL for Postgres, and I'm talking about natural language to SQL not virtual machine instructions... reply atemerev 3 hours agoparentprevI think there are already decompilers and code analyzers at NSA like this. For 10 years or so. reply Mc91 5 hours agoprevIt is good at unminifying and \"minifying\" as well. I have been doing the Leetcode thing recently, and even became a subscriber to Leetcode. What I have been doing is I go through the Grind 75 list (Blind 75 successor list), look for the best big O time and space editorial answer, which often has a Java example, and then go to ChatGPT (I subscribe) or Perplexity (don't subscribe to Pro - yet) and say \"convert this to Kotlin\", which is the language I know best. Jetbrains IDE or Android Studio is capable of doing this, but Perplexity and ChatGPT are usually capable of doing this as well. Then I say \"make this code more compact\". Usually I give it some constraints too - keep the big O space and time complexity the same or lower it, keep the function signature of the assigned function the same, and keep the return explicit, make sure no Kotlin non-null assertions crop up. Sometimes I continually have it run these instructions on each version of the iterated code. I usually test that the code compiles and returns the correct answers for examples after each iteration of compacting. I also copy answers from one to the other - Perplexity to ChatGPT and then back to Perplexity. The code does not always compile, or give the right answers for the examples. Sometimes I overcompact it - what is clear in four lines becomes too confusing in three compacted lines. I'm not looking for the most compact answer, but a clear answer that is as compact as possible. One question asked about Strings and then later said, what if this was Unicode? So now for String manipulation questions I say assume the String is Unicode, and then at the end say show the answer for ASCII or Unicode. Sometimes the big O time is tricky - it is time O(m+n) say, but since m is always equal to or less than m in the program, it is actually O(n), and both Perplexity and ChatGPT can miss that until it is explained. People bemoan Leetcode as a waste of time, but I am wasting even less time with it, as ChatGPT and Perplexity are helping give me the code I will be demonstrating in interviews. The common advice I have heard from everywhere is don't waste time trying to figure out the answers myself - just look at the given answers, learn them, and then look for patterns (like binary search problems, which are usually similar), so that is what I am doing. Initially I was a ChatGPT and Perplexity skeptic for early versions of those sites, in terms of programming, as they stumbled more, but these self-contained examples and procedures they seem well-suited for. Not that they don't hallucinate or give programs that don't compile, or give the wrong answers sometimes, but it saves me time ultimately. reply flerchin 4 hours agoparentThis does seem to be a smart use of the tools available to skip the grind and get to the point of the leetcode questions. However, I wonder about this: What will you do in a live interview situation? Will you pull up ChatGPT? reply Mc91 3 hours agorootparentI have been told by people working in $200k+/$300k+ SWE jobs to look up at the answers and just be able to regurgitate something along the lines of the Grind 75 answers as a first step. As a next step - even within these 75 questions, Grind 75's eighth answer and fourteenth answer are answered essentially the same way, as are other questions in there. So the next step would be to see these patterns (binary search, priority queues, sliding window, backtracking) and how to answer them, and then be able to solve them in slightly novel problems (in the more complex questions I understand one might run into more than one of these patterns). reply shepherdjerred 2 hours agorootparentThis is a good way to do it IMO. Though I would say you don't want to just memorize answers; you want to fully understand them. Also, paying for LeetCode premium is very helpful since their official solutions are easy to understand and explain how you might arrive at these solutions yourself. reply sitkack 3 hours agorootparentprevYou are doing it right. Pattern matching and lightening fast regurgitation are what is needed. There isn't enough time to \"solve and implement\". reply bredren 2 hours agoprevWould have been cool if this had been used in that air con reverse engineering story yesterday. I noticed while reading the blog entry that the author described using a search engine multiple times and thought, \"I would have asked ChatGPT first for that.\" reply smusamashah 7 hours agoprevLLMS are trained to predict next text. But examples like these look like they have also 'learned patterns'. If rot13 is applied on this minified code, will LLM still find meaning in it? if it still could, its more than just next tokens. Need to try it. edit: chatgpt found out that its rot13 and couldn't explain the code directly without deobfuscating it first. reply Tiberium 7 hours agoparentClaude 3.5 Sonnet can natively speak double base64 encoded English. And I do mean it - you can double b64 encode something, send to it, and it'll respond as if it was normal English. Obviously base64 is a simpler transformation than rot13, but no GPT models can deal with double b64. reply mistercow 5 hours agorootparent> Obviously base64 is a simpler transformation than rot13 Is it? It’s probably more obscuring from an LLM’s perspective, assuming the LLM has seen enough rot13 text during training. Spaces and punctuation are untouched by rot13, unlike base64, which means that word and sentence boundaries will still be denoted by tokens that denote those boundaries in plaintext. reply knome 5 hours agorootparentprevit appears that openai's gpt-4 model can speak base64 as well. I jumped to your comment seeing if anyone else had tried it following the OP. double b64 I didn't try, but that is interesting. > $ ask4 ' what does dGhhdCBpcyBxdWl0ZSBpbnRlcmVzdGluZw== decode to? ' > A \"dGhhdCBpcyBxdWl0ZSBpbnRlcmVzdGluZw==\" is a Base64 encoded string. When decoded, It translates to \"that is quite interesting\" in English. reply GaggiX 7 hours agoparentprevI asked Claude 3.5 Sonnet a question in Italian in rot13 and it replied in Italian in rot13, there are a few typos but it's perfectly understandable. reply mewpmewp2 6 hours agorootparentI tried with GPT-4o and it also responded in rot13, the response was on topic, but quite non-sensical, like GPT-2 or lower level. However I can confirm that Claude was able to identify that it's rot13 and also respond properly. reply ziptron 6 hours agoprev>I apologize, GPT-4, for mistakenly accusing you of making mistakes. I am testing large language models against a ground truth data set we created internally. Quite often when there is a mismatch, I realize the ground truth dataset is wrong, and I feel exactly like the author did. reply SoftTalker 4 hours agoparentApologizing to a program seems rather silly though. Do you apologize to your compiler when you have a typo in your code, and have to make it do all that work again? reply digging 3 hours agorootparentIf the compiler could listen and update its functions based on the tone of what I said to it, yes I probably would. reply prologist11 1 hour agoprevI have to ask the obvious question: how do you know the unminified code is semantically equivalent to the minified code? If someone knows how to verify LLM code transformations for semantic fidelity then I'd like to know because I think that would qualify as a major breakthrough for programming languages and semantics. reply BeefWellington 6 hours agoprevYou can do this on minified code with beautifiers like js-beautify, for example. It's not clear why we need to make this an LLM task when we have existing simple scripts to do it? reply NohatCoder 16 minutes agoparentWhile this doesn't restore minified identifiers, like the LLM version claims to do, it tends to help a lot with understanding the code. Usually minified code still has the original identifiers in global function names, object attributes, DOM classes and a few other places where it is hard to guarantee no side effects of name mangling. This makes guessing the purpose of the remaining identifiers substantially easier to a human, and it is probably also the main reason why an LLM is capable of making reasonable guesses at what they could reasonably be called. reply mistercow 6 hours agoparentprevBeautifiers will restore whitespace, but they won’t rename variables by inferring their semantic meaning. reply ervinxie 7 hours agoprevLLMs are very good at text reading. LLMs read tokenized text, while human use eyes to view words. Another scenario is that ChatGPT is good at analyzing cpp template error messages, which are usually long and hard to understand for human. reply rpigab 6 hours agoprevI can see some ways to use this and easily check that the LLM is not hallucinating parts of it, because you can ask the LLM to unminify (or deobfuscate) some component, then request unit tests to be written by the LLM, then humanly check that the unit tests are meaningful and that they don't miss things on the unminified code, then run the tests on the original minified version to confirm the LLM's work, maybe set up some mutation testing if it is relevant. reply xanderlewis 7 hours agoprevIs there any reason why it’s ‘OpenAI’ in the title rather than ‘ChatGPT’? reply philipwhiuk 3 hours agoparentIt's the title of the blog post. reply antonoo 2 hours agoprevIs this code available in ChatGPT's training data? Tried hard, couldn't find any similar code. reply amelius 7 hours agoprevThis post basically says that I don't need to document my code anymore. No more comments, they can be generated automatically. Hurray! reply codr7 7 hours agoparentUnfortunately the comments that could be generated are exactly the ones that should never be written. You want the comment to explain why, the information missing from the code. reply maeln 6 hours agorootparentThis is something I always disagreed with. In my experience, I rather read a short comment explaining what is the purpose of a block of code, than trying to decipher it. Yes, code \"should speak for itself\", but reading a comment is almost always faster than reading blocks of code. And then there is also documentation (if you include it in what you define as comment). I much rather go through a website, with a search function, example, description, made with some docgen tool, than having to go through a library or programming language source code every time I need to remember how to do X, or if object B has implement function Y ... reply jerf 5 hours agorootparentIt's just a rule of thumb, like anything else. In most code, \"why\" is the hard part; I see that you are incrementing that account by a penny from out of the blue, but why? When you are in code where \"what\" is the hard part, like an implementation of a book algorithm or some tricky performance optimization, then by all means comment that. Really all this rule amounts to is // Increment by a penny accountValue += 1 is a pointless comment, please don't do that. Schools had a way of accidentally teaching that by too-rigidly requiring \"commented code\", in situations where there wasn't much else to say, or situations where the students themselves didn't necessarily have a strong sense of \"why\". Any comment that isn't just literally \"this is what the next line does\" is probably useful to somebody at some point. reply maeln 4 hours agorootparentI do agree that documenting the why is way more important than the how/what. But having a short comment to summarize a block of code like: // Parse the filename and remove the extension let fext_re = Regex::new(r\"(.\\*)\\.(.+)$\").unwrap(); let page_cap = fext_re.captures(fname).unwrap(); let page_base_filename = page_cap.get(1).unwrap().as_str(); Is still useful. Instead of having to read the next few line of code, I already know what they are suppose to do and expect. It makes discovery, later down the line, easier. reply meindnoch 1 hour agorootparentIf you didn't name you variables \"fext_re\" or \"page_cap\" you wouldn't need that comment to explain what the code does. reply thwarted 3 hours agorootparentprevThis would be entirely self-documenting by replacing that with a function named after what it does, then the comment isn't necessary. To boot, a unit test could be written that would reveal the bug in the regular expression that makes it only work with filenames that have an asterisk before the extension. Unless you intended that (unlikely), in which case the comment is wrong/not comprehensive and misdirects the reader. reply jffhn 3 hours agorootparentprevYou can put these comments into the name of a function, getting rid of the redundancy and having them read by whoever would just be reading the code not to be distracted by the comments. reply codr7 6 hours agorootparentprevBut the purpose is the Why; forced comments tend to tell you What the code does, which is better explained by the code itself. A comment that is incorrect can do a lot of damage, and they tend to get confused about implementation details over time. reply maeln 4 hours agorootparentFor forced comment I fully agree, especially for function or class when the name already says whats on the tin. reply amelius 6 hours agorootparentprevI suspect you work at OpenAI and you're afraid that you will run out of training data. reply rlpb 5 hours agorootparentprev> reading a comment is almost always faster than reading blocks of code Not to a competent programmer when reading well-written code. This also means that you read what the code does, rather than what a comment says the code does. Otherwise you will be blind to bugs. Any experienced developer will tell you that code very often doesn't do what the original programmer thought it did. reply maeln 4 hours agorootparent> Not to a competent programmer when reading well-written code. No, literally reading a one line about what the next 4 lines do is mechanically faster. It does not matter that you are good or bad, it is about simple reading speed. > This also means that you read what the code does, rather than what a comment says the code does. Otherwise you will be blind to bugs. Any experienced developer will tell you that code very often doesn't do what the original programmer thought it did. I am an experience developer. I have worked on several \"legacy\" projects, and started many from 0. 1. It does not make you blind to anything, it is just a way to learn/direct yourself in the code base faster. 2. Knowing what the original developer wanted is often as useful as knowing what the code actually does. More info is better than no info. Even outdated comment can be useful. For me, this type of thinking that comment are unnecessary, that competent ppl can just read the code, etc. is actually a sign of younger dev who never had to work on a long-lived codebase. reply rlpb 4 hours agorootparent> For me, this type of thinking that comment are unnecessary, that competent ppl can just read the code, etc. is actually a sign of younger dev who never had to work on a long-lived codebase. It sounds like you're conflating \"helpful comments that explain why\" with \"no comments are needed ever because read the code\", and we're talking past each other. reply maeln 3 hours agorootparentGoes to show that it can be hard to have a meaningful conversation via text. Maybe we should add support for audio comment in code! reply sherburt3 4 hours agoparentprev// This is an integer containing the accountId int accountId; We truly live in the future reply skirge 7 hours agoparentprevwhat if the comment doesn't match what you intended to write? reply elicash 6 hours agorootparentMaybe it's better for the comment to match the code you wrote, not the code you intended to write. reply shubhamjain 6 hours agoprevAn interesting use-case of this capability is refactoring, which, for me, ChatGPT has been unmistakably good at. It's amazing how I can throw garbage code I wrote at ChatGPT, ask it to refactor, and get clean code that I can use without worrying if it's going to work or not, because in 99% of cases it works without breaking anything. reply Sharlin 6 hours agoparentWhat language(s), out of interest? reply shubhamjain 6 hours agorootparentI use node.js, but I think it will work for anything. I recommend trying small chunks first vs dumping your whole file. reply Sharlin 3 hours agorootparentNo, most other languages absolutely don’t work as well as JS, simply because there’s been less training material available. It’s useless with Rust, for example (hell, I’d be totally impressed if it has any idea how to appease the borrow checker!) reply spacebanana7 6 hours agorootparentprevI've had pretty good results dumping entire files in to Sonnet3.5. For example, \"Here's my app.js file, please add an endpoint for one user to block another. Feel free to suggest schema changes. Please show me the full app.js with these changes implemented\" The model seems to be great at figuring out frameworks and databases just by seeing the contents of a full app.js file. I do find this type of prompt works much better with Sonnet3.5 than GPT4o. reply fergie 7 hours agoprev* takes out soap box and stands on it * We should go back to uncompiled JavaScript code, our democracy depends on it. reply lifthrasiir 7 hours agoparentOr learn to read minified JS code, which is actually not that difficult! (But you do have to take notes to track identifiers.) reply nashashmi 3 hours agoprevLooks like the end is here for security via obscurity. reply VMG 7 hours agoprevit is also pretty good at decompiling - try feeding it the output of https://godbolt.org/ reply netsec_burn 7 hours agoparentI recently learned this too, just a few months ago. Ended up making a frontend so I could do it automatically: https://decompiler.zeroday.engineering/ reply api 7 hours agoprevAnyone working on decompiler LLMs? Seems like we could render all code open source. Training data would be easy to make in this case. Build tons of free GitHub code with various compilers and train on inverting compilation. This is a case where synthetic training data is appropriate and quite easy to generate. You could train the decompiler to just invert compilation and the use existing larger code LLMs to do things like add comments. reply BluSyn 7 hours agoparentThe potential implications of this are huge. Not just open sourcing, but imagine easily decompiling and modifying proprietary apps to fix bugs or add features. This could be a huge unlock, especially for long dead programs. For legal reasons I bet this will become blocked behavior in major models. reply roflmaostc 7 hours agorootparentI've never seen a law forbidding decompiling programs. But, some programs forbid to decompile applications by the license agreement. Further, you still don't have any right on this source code. It depends on the license... reply lifthrasiir 7 hours agorootparentA mere decompilation or general reverse engineering should be fine in many if not most jurisdictions [1]. But it is a whole different matter to make use of any results from doing so. [1] https://www.law.cornell.edu/wex/reverse_engineering reply poikroequ 7 hours agorootparenthttps://en.m.wikipedia.org/wiki/Clean-room_design reply lifthrasiir 6 hours agorootparentIt is true that at least some jurisdictions do also explicitly allow for reverse engineering to achieve interoperability, but I don't know if such provision is widespread. reply DonHopkins 7 hours agorootparentprevUsing an LLM (or any technique) to decompile proprietary code is not clean room design. Declaring the results \"open source\" is deception and theft, which undermines the free open source software movement. reply poikroequ 6 hours agorootparentOnly if you use the decompiled code. But if one team uses decompiled code to write up a spec, then another team writes an implementation based on that spec, then that could be considered clean room design. In this case, the decompiler would merely be a tool for reverse engineering. reply jraph 7 hours agoparentprev> Seems like we could render all code open source Unfortunately not really. Having the source is a first step, but you also need the rights to use it (read, modify, execute, redistribute the modifications), and only the authors of the code can grant these rights. reply torginus 7 hours agorootparentDoesn't it count as 'clean room' reverse engineering - or alternatively, we could develop an LLM that's trained on the outputs and side-effects of any given function, and learns to reproduce the source code from that. Or, going back to the original idea, while the source code produced in such a way might be illegal, it's very likely 'clean' enough to train an LLM on it to be able to help in reproducing such an application. reply jraph 6 hours agorootparentIANAL but if your only source for your LLM is that code, I would assume the code it produces would be at high risk of being counterfeit. I would guess clean room would still require having someone reading the LLM-decompiled code, write a spec, and have someone else write the code. But this is definitely a good question, especially given the recent court verdicts. If you can launder open source licensed code, why not proprietary binaries? Although I don't think the situation is the same. I wouldn't expect how you decompile a code matters. reply johndough 7 hours agoparentprev> Anyone working on decompiler LLMs? Here is an LLM for x86 to C decompilation: https://github.com/albertan017/LLM4Decompile reply aengelke 7 hours agoparentprevThere was a paper about this at CGO earlier this year [1]. Correctness is a problem that is hard to solve, though; 50% accuracy might not be enough for serious use cases, especially given that the relation to the original input for manual intervention is hard to preserve. [1]: https://arxiv.org/abs/2305.12520 reply croes 7 hours agoparentprevUnminifying isn't decompiling. It's just renaming variable and functions and inserting line breaks. reply j_maffe 7 hours agorootparentMinifying includes way more tricks than shorter variable names and removing white-space reply api 7 hours agorootparentprevNo but it’s a baby brother of the same problem. Compiling is a much more complex transform but ultimately it is just a code transform. reply jraph 7 hours agorootparentIt is true that compilation and minification are both code transformations (it's a correct reduction [1]), but this doesn't seem a very useful observation in this discussion. In the end, everything you do to something is an operation. But that's not very workable. In practice, compilation is often (not always, agreed!) from a language A to a lower level language B such that the runtime for language A can't run language B or vice-versa, if language A has a runtime at all. Minification is always from language A to the same language A. The implication is that in practice, deminification is not the same exercise as decompilation. You can even want to run a deminification phase after a decompilation phase, using two separate tools, because one tool will be good at translating back, and the other will be good at pretty printing. [1] https://en.wikipedia.org/wiki/Reductionism reply js8 5 hours agoparentprev> Seems like we could render all code open source. I agree. I think \"AI generating/understanding source code\" is a huge red herring. If AI was any good at understanding code, it would just build (or fix) the binary. And I believe how it will turn out to be, when we really have AI programmers, they will not bother with human-readable code, but code everything in machine code (and if they are tasked in maintaining existing system, they will understand in its entirety, across the SW and HW stack). It's kinda like diffusion models that generate images don't actually bother with learning drawing techniques. reply Vampiero 5 hours agorootparentWhy wouldn't AIs benefit from using abstractions? At the very least it saves tokens. Fewer tokens means less time spent solving a problem, which means more problem solving throughput. That is true for machines and people alike. If anything I expect AI-written programs in the not so distant future to be incomprehensible because they're too short. Something like reading an APL program. reply js8 2 hours agorootparentI agree, they might create abstractions, but I doubt they're going to reuse the same abstractions as human programming languages. reply layer8 7 hours agoparentprevIt can’t really compensate for missing variable and function names, not to mention comments. reply poikroequ 7 hours agoparentprevI think there's actually some potential here, considering LLMs are already very good at translating text between human languages. I don't think LLMs on their own would be very good, but a specially trained AI model perhaps, such as those trained for protein folding. I think what an LLM could do best is generate better decompiled code, giving better names to symbols, and generating code in a style a human is more likely to write. I usually crap on things like chatgpt for being unreliable and hallucinating a lot. But in this particular case, decompilers already usually generate inaccurate code, and it takes a lot of work to fix the decompiled code to make it correct (I speak from experience). So introducing AI here may not be such a huge stretch. Just don't expect an AI/LLM to generate perfectly correct decompiled code and we're good (wishful thinking). reply DonHopkins 7 hours agoparentprev>Seems like we could render all code open source. That's not how copyright and licensing works. You could already break the law and open yourself up to lawsuits and prosecution by stealing intellectual property and violating its owners rights before there were LLMs. They just make it more convenient, not less illegal. reply l5870uoo9y 6 hours agoprevIt is also shockingly good at converting/extracting data to CSV or JSON, but not JSONL. Even the less capable model, `gpt-4o-mini`, can \"reliably\" parse database schemas in various formats into CSV with the structure: ```csv table_name,column_name,data_type table_name,column_name1,data_type table_name,column_name2,data_type ... ``` I have been running it in production for months[1] as a way to import and optimize database schemas for AI consumption. This performs much better than including the `schema.sql` file in the prompt. [1]: https://www.sqlai.ai/app/datasources/add/database-schema/ai-... reply tanepiper 7 hours agoprevI find LLMs good at these kind of tasks, also converting between CSV to JSON for example (although you have to remind it not to be lazy and do the whole file) reply nwoli 7 hours agoprevHopefully it can help do this on emscripten files too and help adblockers dechipher obfuscated code for that purpose reply firtoz 7 hours agoparentLikewise for css class names reply tgv 7 hours agorootparentI can imagine that finetuning a model for this task could be very successful. Time for another AI startup. reply runiq 7 hours agoprevPlease let this one have knock-on effects on reverse engineering. reply skirge 7 hours agoparentSee Binary Ninja's Sidekick plugin reply Tepix 7 hours agoprevpunkpeye could also have asked the LLM to replace the cryptic function and variable names with nice ones. I'm hopeful it would have done a good job. reply camillomiller 4 hours agoprevMost expensive unminify software in history reply GaggiX 4 hours agoparentA human would be even more expensive. reply foxhop 6 hours agoprevHere's a hint, STOP MINIFYING CODE! gzip over transport is enough. reply lifthrasiir 6 hours agoparentNot exactly, because you still have to pay any distinct identifier present in your code. Also many minifiers do constant folding and inlining and remove comments, any of which almost surely remove redundant or unused information to compress. reply mistercow 5 hours agorootparentI don’t think they’re saying that minifying provides no additional space savings, but rather that those additional savings are small and not worth the tradeoffs. reply lifthrasiir 5 hours agorootparentNot even that is true in my knowledge. For example a particular benchmark [1] demonstrates that many popular libraries benefit much from minification even after gzip compression, with the saving ranging from 35% to 75%. Sure, a small library would be fine without any minification or even compression, but otherwise minification is clearly beneficial. [1] https://github.com/privatenumber/minification-benchmarks reply mistercow 5 hours agorootparentI think you have to look at this in the context of an entire bundle or project, and then you have to weigh it against the download speeds you’re generally expecting for the users of your site or app. I agree that as a blanket statement “gzip is enough” is not technically correct, but I think it’s largely correct in spirit, in that people tend to reach for minification by default, without really thinking about what they’re gaining. If minifying saves you 200 KB overall, for example, and you expect your average user to have a 200 Mbps connection, you’re saving a grand total of 8 ms on page load, which is an imperceptible difference on its own. In exchange, you’re getting worse debugging, and worse error reporting. reply lifthrasiir 5 hours agorootparentMinification would be indeed useless under that set of assumptions, but the real world is much more variable and you need a comfortable margin. For example, mobiles rarely have that large bandwidth sustained all the time. Comprehensively speaking, the minification is only a small step in building a performant website or web application. You have way more things to do, for example choosing a correct image compression format and method would have much more impact in general. But not everyone can be expected to understand them in depth, so we have best practices. Doing the minification therefore qualifies as a good best practice, even though it would be just a single one out of many others. reply andrewf 3 hours agorootparentprevI wonder if 200 KB is small enough that TCP slow start will be the constraint on a download over a new connection, rather than the bandwidth. reply mistercow 3 hours agorootparentI think probably not, if the assets are coming from the same place, since the connection will be reused in most modern situations. Maybe if you’re loading the JS from a CDN though, and there are no other large resources, or those resources come from a different server. reply spacecadet 7 hours agoprevI use LLMs to assist with reverse engineering all the time right now. From minified, to binary, alongside Ghidra, its very helpful. reply GaggiX 6 hours agoparentCan you provide more details? I'm curious about the performance and limitations of these models. reply spacecadet 5 hours agorootparentLike all LLMs you greatly benefit from prior experience or you risk just falling for hallucinations which is a limitation of a non-deterministic black box, and degrades performance relative to the task. Ive commented in other threads, LLMs are great at amplifying my output in an area I already have domain knowledge in. I think this is why people fail to realize any gains or give up, they think it will unlock areas they dont fully understand themselves. Blind leading the blind problem. reply bravetraveler 7 hours agoprevLLMs are good at modeling and transforming text, news at 11. AI proponent hypes AI. I could go on, but I shouldn't have been this sarcastic to start with reply chx 7 hours agoparentYou should be. I am facepalming at the topic and every single comment in here. It's so full of holes, the Swiss dairy industry went out of business. reply MetaverseClub 2 hours agoprevwow, is openAI such a great magic to you? reply andrewmcwatters 5 hours agoprevI’ve tried using LLMs to deobfuscate libraires like fingerprintjs-pro to understand what specific heuristics implementation details they use to detect bots. They mostly fail. A human reverse engineer will still do better. reply samstave 7 hours agoprevDont know if this will apply directly here, but -- As someone who is \"not a developer\" - I use the following process to help my: 1. I setup StyleGuide rules for the AI, telling it how to write out my files/scripts: - Always provide full path, description of function, invocation examples, and version number. - Frequently have it summarize and explain the project, project logic, and a particular file's functions. - Have it create a README.MD for the file/project - Tell it to give me mermaid diagrams and swim diagrams for the logic/code/project/process - Close prompts with \"Review, Explain, Propose, Confirm, Execute\" <-- This has it review the code/problem/prompt, explain what it understands, propose what its been asked to provide, confirm that its correct or I add mroe detail here - then execute and go with creating the artifacts. I do this because Claude and ChatGPT are FN malevelant in their ignoring of project files/context - and their hallucinate as soon as their context window/memory fills up. Further they very frequently \"forget\" to refer to the project context files uploaded/artifacts they themselves have proposed and written etc. But - asking for a readme with code mermaid and logic is helpful to keep me on track. reply viraptor 6 hours agoparentAgents like Aider or Plandex wrap that up nicely. They do the automatic review and have a very verbose description of the edit format. If you do that often manually, it may be worth testing their prepackaged approach. reply Julesman 3 hours agoprev\"Usually, I would just powerthrough reading the minimized code...\" Huh? Is this a thing? There are endless online code formatting sites. It takes two seconds. Why would anyone ever do this? I don't get it. reply nprateem 5 hours agoprevAnd shockingly shit at writing articles that don't sound like essays. reply nnurmanov 7 hours agoprevYet another surprising side effects of LLMs. reply _joel 6 hours agoparentIf the training data's included both unminified and minified libs, then is it such a stretch? reply 8ndow 7 hours agoparentprevIs it though? The developer tabs have an unminify button which yields similar results. JavaScript minification is not hard in any way and the guessing of variable names is not that hard given such a simple code example. reply 1 more comment... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "OpenAI's ChatGPT demonstrated its capability to unminify and explain complex JavaScript code, specifically for generating dynamic ASCII art in a React application.",
      "The AI provided a clear breakdown of the code's key components, including character set selection, dynamic character selection function, and a React component for displaying the content.",
      "The code was successfully converted to TypeScript, making it more readable and maintainable, showcasing the practical utility of AI in code comprehension and transformation tasks."
    ],
    "commentSummary": [
      "OpenAI's tool HumanifyJS uses Large Language Models (LLMs) to unminify code, ensuring it remains functional and readable by renaming variables contextually.",
      "Users are considering additional features like renaming from scratch and handling large files, indicating ongoing development and interest.",
      "The broader implications of LLMs in code transformation, such as decompiling and refactoring, are discussed, emphasizing their increasing utility in software development."
    ],
    "points": 705,
    "commentCount": 251,
    "retryCount": 0,
    "time": 1724926490
  },
  {
    "id": 41389931,
    "title": "Low Cost Mini PCs",
    "originLink": "https://lowcostminipcs.com/",
    "originBody": "While searching for mini PCs for my home server, I figured I&#x27;d use the eBay API to find the cheapest ones. Inspired by diskprices.com, I built a static site using Eleventy and a python script that uses regex to parse the data. I tried to include as many filters as possible like OS, Wifi, HDMI etc.I would like to add power usage, noise levels, PCIe slots but that data is hard to find.Please let me know if you have any feedback &#x2F; suggestions.Thanks!",
    "commentLink": "https://news.ycombinator.com/item?id=41389931",
    "commentBody": "Low Cost Mini PCs (lowcostminipcs.com)501 points by mjcurl 6 hours agohidepastfavorite237 comments dotBen 5 minutes agoLenovo ThinkCentre M Series (minis) are an absolute sleeper and way better value than Raspbery Pis. I run one in my home network closet with a bunch of docker containers on for home networking, crawler projects that need to run from a non-datacenter IP address, homelab experiments, etc. Cost me $100 'used' (open box), SSD, decent RAM and even a copy of Windows I didn't need. Install *nix, run it headless, good to go. You can go cheaper but at a certain point who cares if it's $80 for an unknown brand or $100 for Lenovo, etc. Eg https://www.ebay.com/itm/186591932407 - this is a great project server that can probably run tons of docker containers (depending on what you are doing). Small form factor, it can tucks in with wherever you store your router, or buy an aftermarket rack kit and rack it if you run rackmount network components like I do. reply windexh8er 3 hours agoprevThis is great! The one thing I'd say is that the market is rife with non-mainstream brands. As an example \"Beelink\" [0] and \"Minisforum\" [1] are very commonly referred to and have a lot of great models, but they're not well represented here and often times offer better value depending on what the buyer is looking for. My recommendation would be to expand the vendors into the popular non-mainstream brands. Easy ask, but harder to execute on your side - so I get it. Also, AMD is crushing this market - but AMD is pretty under-represented here. There are also some great N-series Intel machines that are highly popular and you can get on AliExpress [2]. Or even more US focused brands under this umbrella like Protecli [3] [0] https://www.bee-link.com/ [1] https://www.minisforum.com/ [2] https://www.servethehome.com/fanless-intel-n200-firewall-and... [3] https://protectli.com/ reply internet101010 13 minutes agoparentLove my Minisforum MS-01. 3x m.2 slots, supports 96gb ram, 2x 10g ports, 2x 2.5g ports, and has a pcie slot for things like external hba or small gpu. A lot of people buying mini pcs would rather go with AMD but are stuck with Intel due to the need for Quick Sync in order to transcode Plex. reply JamesSwift 19 minutes agoparentprevHad good experiences with a few beelinks, but recently picked up a minisforum and have had a bunch of weird BIOS issues (and their BIOS is a really bizarre custom UEFI thing). Waiting to RMA now, but I've seen a lot of similar \"weird BIOS bugs\" after searching for help on my issue. reply squarefoot 1 hour agoparentprev> The one thing I'd say is that the market is rife with non-mainstream brands. Brands in the far east are quite different and less important than in western markets; to me it seems there are say 5 manufacturers that build OEM products that 30 will relabel with their brand and put into their box, then give to 1000 sellers, each one running like 30 shops on Aliexpress, Ebay and Amazon. Numbers are totally made up of course, the point is that the name isn't that important over there as the very same product can be (and often is) rebranded in many different ways. reply tonymet 2 hours agoparentprevI took a risk on a Beelink and so far it's been the best piece of hardware I've owned. Affordable, quiet, reliable, excellent performance, versatile for development & light gaming. I did a thorough audit for bloat- spam- & mal-ware due to their reputation, and it came up much cleaner IMO than my HP. Given that they compete in price with Raspberry pi with far more capability, everyone should have one. reply biomcgary 52 minutes agorootparentThe daily driver I am using to write this post is a Beelink with Linux installed. Very happy with it. Switched out the original 128GB SSD with a 1TB SSD. FFMPEG and light gaming run fine. My only minor regret is not starting with more memory, but I could probably switch that if I was motivated enough. reply rfoo 1 hour agorootparentprevThey are simply not competent enough to install spam-ware. reply dangus 3 minutes agorootparentIt’s interesting to me how when a Chinese company makes a great product at a great price they get accused of being too incompetent to rip their customers off with customer-hostile features like their Western brand counterparts. But when Western companies load up their hardware with spyware and adware they are smart and savvy at business. Isn’t this a little bit backwards? The correct statement is that Dell and HP too incompetent to make money off their computers without spying on their customers. Maybe at some point we have to just drop the dogwhistling and admit that the Chinese hardware market is a dynamic, competitive market that seems to focus on delivering useful products to their customers rather than trying to make public shareholders happy by squeezing every last time out of them to the edge of their tolerance for such inconveniences. reply sam2426679 1 hour agorootparentprevAgreed! Using a beelink as an htpc, and its been phenomenal. reply kjs3 41 minutes agoparentprevI have a Protecli 4-port firewall. It's the second one I've bought for this. It's really been excellent from a cost/performance standpoint. reply xhrpost 5 hours agoprevI've been loving the recent attention to mini PCs here. I've had hobby projects put off for a while as I tried to find the best R-Pi clone, only to buy one and struggle just to get it to boot. Then I pick up a used mini PC on ebay for like $42 shipped, power cord and everything and even a 500gb SSD. Now I have a server running at home and am actually working on projects again, oddly for probably less than what a Pi clone costs after you buy enough accessories to use it. reply roflmaostc 4 hours agoparentdifference might be that a Raspberry Pi consumesI've had to do some ridiculous things to get them to behave after installing Linux, like tricking the BIOS to deal with UEFI correctly I would suggest going for a couple of generations newer - the M92p is from an era before UEFI became really stable. For automated testing of my startup's product we have a testlab of tens of older USFF desktops and the M700/M900/M910 machines are some of my favorites. They're also just before the cut-off for Windows 11 support so they're still available dirt cheap. Two things to watch out for - the M700 lacks a PCI-E M.2 slot - the internal M.2 slot supports only SATA M.2 drives. Second, the front USB ports failing is a really common failure mode. reply mydriasis 3 hours agorootparentOoo that's _gotta_ be what it is. Just the most bizarre UEFI issues. I luckily found an incantation that works in a pretty general way for M92ps, but had I not I'd have some bricks laying around. Those M900s look REALLY nice! reply swills 1 hour agorootparentI have some M910q that I am very happy with. UEFI is well supported, I was able to upgrade them to 32gb of RAM, i7 7700t and both a 512gb SSD and NVMe for mirrored storage. Highly recommended. Sure, it would be nice to get something newer than 7th gen, but it's still highly capable, small, quiet and fairly low power usage. reply haunter 5 hours agoparentprev> I've had to do some ridiculous things to get them to behave after installing Linux, like tricking the BIOS to deal with UEFI correctly Strange. I use Dell Optiplex Micros which are pretty much the same. I’ve never had a problem installing any Linux distros or hypervisors (Proxmox and XCP-NG) reply vladvasiliu 4 hours agorootparentSame experience as you with HP Elitedesks. At work we used to use those for people doing regular office things. I have a few G2s (i5-6500) and they work flawlessly with Linux, including using my own secureboot keys. reply bitmasher9 5 hours agorootparentprevI’ve bought 3 used Dells, mostly Optiplexes, over the decades for dedicated hardware for Linux based projects. They always seem like a good deal, and I surprisingly never have problems with them. These are fleet computers that get gently used during business hours that have IT departments that replace computers on a time schedule. Outside of one HDD that didn’t last a year of heavy file traffic I haven’t had really good luck with these machines. reply haunter 5 hours agorootparent>These are fleet computers that get gently used during business hours that have IT departments that replace computers on a time schedule Yeah these are the ones I'm buying too. Lot of banks have these for example as an all-in-one docked into a monitor. Sometimes they even have a small amount of Dell warranty left, though I've never ever had a problem with them. reply ilikepi 2 hours agorootparent> Sometimes they even have a small amount of Dell warranty left, though I've never ever had a problem with them. Yes, though technically any add-on warranty coverage or service plans are only available to the registered owner. I bought a couple Dell OptiPlex micros last year that were originally owned by a large organization. They were clearly being resold on eBay by someone who had acquired them in some sort of bulk purchase. Dell has a form you can submit to request that the registration be updated, but it requires you to provide contact information for the original owner. I asked the eBay seller if they for this contact information, but they said they did not. I was able to open a support request with Dell and have their records updated to show me as the owner after showing evidence that I had acquired the machines. This included a photo of them showing their asset tags along with a hand-written note that showed my support case number, as well as a copy of the eBay listings. I believe Dell checked with the original owner (a US federal agency) to verify the machines had been sold. reply haunter 1 hour agorootparentThanks that's helpful. I still have two with warranty until January so I might try my luck with Dell reply mydriasis 3 hours agorootparentprevIt was so bizarre. I'd get a \"No Operating System Found\" message, and had to go toy with the UEFI config. Eek! reply VikingCoder 4 hours agoprevETA Prime has some advice on making a gaming machine out of cheap old PCs: \"You Can Build This Powerful Ultra Low Cost SteamOS 3 Gaming PC For Only $150\" https://www.youtube.com/watch?v=jFIgQ9zgXOk Optiplex 7020 with a tower - not a \"Small Form Factor.\" \"This Super Low Cost PC Runs SteamOS 3 Better Than The Steam Deck!\" https://www.youtube.com/watch?v=myye5o0y2Jw reply detritus 2 hours agoparentThanks for this! I've been meaning to get back into games but only keep a laptop at home and I had no idea that I could make a machine that could capably serve my needs forbenchmarks. reply nfriedly 5 hours agorootparentI like passmark / cpubenchmark.net to get a good ballpark idea of CPU performance, because it covers a wide range of CPUs, and because it has both single-core and multi-core scores. reply mjcurl 5 hours agorootparentI prefer that too. Now to get data for all the listed CPUs! reply whywhywhywhy 4 hours agoprevYou should have a filter for processor, feel the difference between ones like N100 and usual low end Intel processors is huge. Might be cool to list them with benchmarks too for people who don’t want to do research. reply eskibars 6 hours agoprevThis is awesome. I used to build a lot of stuff with various single-board computers (Raspberry Pis, etc) but realized I could get way more performance and expandability with these mini PCs if the form factor didn't require it. One other thing I'd be interested in: not just mini PCs but used office workstations. I realized that many offices were selling old workstations that were often just a few years old with things like dual Xeon chips and 64GB of RAM or more with support for a few hundred GB for only a few hundred $. Things like 2ish generation old HP Z400/Z600/Z800 series. They make for great home lab virtualization machines and can often support 2+ GPUs and a boatload of additional peripherals. I'd love to see something like this that lets you find those as well reply shmoogy 6 hours agoprevBeing able to filter by CPU (and model i.e. optiplex 3010 or whatever) would be useful here. I'm looking for a sff that has 13th gen intel cpu, supports 64gb ram as an example. reply someone13 5 hours agoparentIt’d also be neat if there was a way to sort by the passmark CPU benchmark score: https://www.cpubenchmark.net/ reply mjcurl 6 hours agoparentprevSince there's hundreds/thousands of cpus and models, how about a keyword filter field? reply roger_ 6 hours agoparentprevCame to suggest the same thing. I’d love to be able to filter by CPU and generation. Maybe using an LLM could help with the parsing? reply tracker1 3 hours agoprevA lot of these things are pretty great for general use, home server, game emulation and htpc duties. From the N100 at the relatively inexpensive, to the Ryzen 8000 series at the mid-range with top tier cpu capabilities and decent igpu to the relatively high end monsters. Except for gaming duties, if someone wants a desktop experience, monitor, kb, mouse then mini pcs are awesome. reply butz 52 minutes agoprevIt would be very helpful to know which PCs support power over USB-C and video, e.g. I can connect it to display with single cable. reply layer8 4 hours agoprevThis is only of limited usefulness if you want to buy a new mini PC (rather than specifically a used unit from eBay). For example, many current fanless models are not listed. Just searching for “fanless mini pc” on Amazon.com gives many more (and some cheaper) results. This might be a task for an LLM-supported scraper looking at a number of online marketplaces, retailers, and manufacturer sites. Then, conversely, you could link to matching eBay listings. It would also need a mechanism for users to submit spec corrections. reply bArray 5 hours agoprevFor UK shoppers looking for a cheap laptop, the Dell Latitude E7240 is a solid machine [1]. For about £50-£60 delivered you can get a 12.5\" machine with a ~4th gen i5, 4-8GB of RAM and an SSD. It's great for Teams/Zoom and the keyboard is very nice to type on. My personal one has 12GB of RAM (4+8) and two SSDs (there is a spare slot for a half size M.2. inside). You can abuse the hell out of them and they take it. [1] https://www.ebay.co.uk/sch/i.html?_from=R40&_nkw=Dell%20Lati... reply bityard 3 hours agoprevI'm guessing this was inspired by https://labgopher.com? A lot of these are not what I would call \"mini,\" but I like the idea. Is it a static list of manufacturers/models? If so, I feel like it would be worth putting that on GitHub so that the community can help maintain it. For example, I know there many fanless PCs on the market but the site is only showing me three and they are all fairly expensive. Any plans to add websites besides eBay? When I am hunting down a SFF PC for a project, I generally try to at least look over what is on offer from AliExpress, NewEgg (clearance), Dell Refurbished, Lenovo Refurbished, Microcenter, and a variety of websites for second-hand business IT recyclers. reply wscott 4 hours agoprevOn the website itself, \"OS\" \"Included\" and \"Not Included\" is strange. I don't see that I need \"Not Included\", unchecking \"Included\" should show you everything but instead it shows you nothing. I don't see the value of \"no os included\" verses a copy of Windows that I will overwrite. So I would just have an \"OS Included?\" checkbox. reply transpute 6 hours agoprevUseful index! Suggestions: 1. encode search filters in URL, for sharing/bookmark 2. Add \"Intel vPro\" as a filter. reply mjcurl 5 hours agoparentGood call, I'll encode the state in the URL. Did not come across a lot of Intel VPros in my searches. What's the use case for them? reply transpute 1 hour agorootparentMany of the Dell/HP mini PCs with Intel i5 or higher are vPro, because they were used in corporate environments, but it looks like this is rarely part of the eBay item description. Thanks for checking. vPro devices support Intel TXT (DRTM) to verify firmware integrity on each boot, based on user/OS policy. TXT can be used with QubesOS (\"Anti Evil Maid\"), Windows Virtualization-Based Security (VBS) or upcoming Linux Secure Launch in mainline Linux. vPro also supports optional remote KVM/serial management over LAN with Intel AMT, which could be considered a feature or anti-feature, depending on use case. reply bloomingeek 1 hour agoprevI wonder if this is kind of a semi-panic selling because of Windows 10 supposedly going away next October 2025? (Except MS holding us hostage for a yearly fee!) Fantastic gathering of used PC's, but buyer beware, there are a lot of options that are worth studying before purchasing. reply htk 3 hours agoprevI had a laptop running Windows for 12 years as my home server, hidden in a closet. It ran a couple of c# apps as a service and was an ftp server as well. Last month I decided to buy a raspberry pi (4B 2GB) to scratch multiple itches (arm processor, linux, low power consumption) and it replaced the server without a hitch, and better than I thought! No weird splash screens from windows after updates, 2GB is vast for me when running headless, dotnet apps ported with minimal effort, and the list goes on. Only downside is the USB can only power one external 2.5\" hdd, and I didn't want to add a powered usb hub. reply riledhel 5 hours agoprevI've recently bought this Intel N100 mini pc https://es.aliexpress.com/item/1005006727722225.html and it's amazing. It even came with win11 preinstalled, an unexpected surprise for me. 16G RAM and 512G SSD for 100 euros, great deal. reply wan888888 6 hours agoprevThe joy of living in Australia: $38.00 + $710.23 shipping reply haunter 5 hours agoparentDon't bother with eBay, you can get refurbsihed ones in Australia too A$115 example, https://www.australiancomputertraders.com.au/hp-elitedesk-80... reply amelius 5 hours agoprev> I would like to add power usage, noise levels, PCIe slots but that data is hard to find. Maybe you can use an LLM to extract that data from reviews? Anyway, I'd like to know if I can use the system for a home cinema, so it should be able to decode 4k resolution in real time (and shouldn't be too noisy). It would be nice if there was a checkbox for that usecase. reply mjcurl 5 hours agoparentReviews aren't common due to many listings having 1 item in stock. What would the requirements for your decoding be? reply amelius 4 hours agorootparent> What would the requirements for your decoding be? Well, it should just play 4k content from various sources (and so various formats), using Vlc. > Reviews aren't common due to many listings having 1 item in stock. I suppose you could use a (Google) search to find reviews elsewhere on the internet, based on the product name. Then feed them to ChatGPT, and ask it to summarize various things and build a JSON structure out of its findings. Maybe ChatGPT can even do the search for you. reply thelastgallon 5 hours agoprevAn option to filter by ECC RAM would be super helpful. reply mjcurl 5 hours agoparentI wanted to add this, but that data is almost never entered by sellers. reply simplecto 5 hours agoprevWebsites like this talk to my heart. Strong early 2000s vibes of nerds just putting it out there. Love this, thank you! reply shortformblog 3 hours agoprevGiven how dominant AMD-based options are from a new machine standpoint (you can get a pretty good 5000-series U-grade processor for less than $250 on Amazon) I’m kind of surprised by the lack of AMD options on the list. This is a useful idea though, but I wonder if the lack of AMD may be hinting at some variable that hasn’t been considered? reply supertrope 46 minutes agoparentMost used PCs for sale started off as business machines. They usually buy from the big brands that can provide enterprise warranty support and volume discounts. AMD released Ryzen in 2017. Add up the time for AMD to convince Dell/HP/Lenovo to design, qualify, and release an AMD model. Add the time for significant uptake into the market. Finally add three years for the AMD PCs to get retired from office use. reply agg23 5 hours agoprevThis is really nice, and I just did this analysis myself. It seems like the tool is missing some of the better deals, like Optiplex 3070 with 9th gen i5s for ~$100, entire working system included (this is what I ended up buying). reply mjcurl 5 hours agoparenteBay uses a 'best match' sort on the results, perhaps that's why it was missed. What did you search for when you found this one? reply agg23 4 hours agorootparentI believe I looked up common machines with good prices, then searched for those individually, which obviously isn't going to work very well for this tool. reply j0d1 6 hours agoprevThis is really neat! I would love to see something similar for laptops. I bought a used Lenovo T80s (8th generation i5 CPU / 8GB of RAM / 256GB SSD) for 150$cad on eBay to work on my product (web app) and it is working flawlessly with Debian. reply NelsonMinar 3 hours agoprevNeat! I'd love a column for external disk I/O type. I've been trying to build a NAS on a new N100 miniPC but am foiled by the fact that the devices all only have USB ports for I/O. And USB is not reliable enough to run ZFS with a heavy load (kernel errors). I'd love to have something with eSATA or some sort of PCI option. reply iforgotpassword 6 hours agoprevMaybe consider adding Fujitsu as a manufacturer. At least here in Europe they're fairly common in business environments so get tossed on ebay quite frequently. I've had very good experience with their stuff over the past decade. reply weweweoo 2 hours agoparentDefinitely do that. Old Fujitsu thin clients make awesome DIY routers. reply overcast 6 hours agoprevBeen using a Beelink SER6 Mini PC, AMD Ryzen 5 6600H, 16GB DDR and 500GB NVME for the last year or so with PopOS as my daily driver and loving it. With a portable monitor makes remote work great for $351 and $100 for the monitor! reply InMice 5 hours agoparentI have a beelink, have had no problems except the original SSD in mine failed suddenly in <1 year. I'd recommend anyone getting a beelink to swap out their SSD with a crucial, kingston, samsung brand etc before putting the pc to use. reply indigodaddy 5 hours agoprevThe eBay sellers who do the customization/price thing makes some of your price results misleading/unreliable as the price will be more on those than the base you have listed. reply mjcurl 5 hours agoparentI found that to happen sometimes, so I marked customizable listings. But I think I was able to parse most of them to show the specs for the selected variation, not the parent or the title. reply blueferret 3 hours agoprevWhat a great idea! I love checking DiskPrices; the structure does lend well to mini-PCs (another interest of mine). Bookmarking this for my next shouldn't-grab-this-but-price-is-too-good impulse buy. reply gizmo 5 hours agoprevThat's very cool. I ultimately concluded that those mystery brand Chinese fanless mini pcs from Amazon (essentially laptop hardware in a tiny enclosure) offer a better deal. Minimal power usage, fast networking, real USB-C, and NVMe drive support. Old hardware is bulky, makes noise, and outputs too much heat. Even the truly tiny mini pcs -- the kind that fit in your back pocket -- are fast enough for a NAS or TV media player. reply kyriakos 5 hours agoparentThey are usually a lot more expensive because they come with newer CPUs. reply kylecazar 6 hours agoprevI had largely written off eBay some years ago after some bad experiences -- but this tool just showed me some pretty insane deals on custom PC builds over there.. Neat. reply bluepuma77 4 hours agoprevIt would be great if it would support other eBay sites than just .com, not everyone is in the US :) reply throwaway4220 1 hour agoprevI’m fascinated that a static site generator makes this! Is this a new concept? reply pjc50 5 hours agoprevSite is currently timing out. If it's actually static, stick it behind free Cloudflare. But still - nice idea, thanks for the Show HN. Does anyone know what the right searchplace is for media storage PCs? I'm considering getting something in this area that's a bit more sophisticated than a NAS but not a huge project to maintain. reply mjcurl 5 hours agoparentActually I did stick it behind Cloudflare..not sure why it would time out, since it's just an html page. reply pjc50 4 hours agorootparentHuh, turns out to be a problem at my end, probably due to corporate firewall. reply sodimel 5 hours agoprevThis is cool! It reminds me of when I got my own web \"server\"; I purchased it (for ~50€) after reading this post[0] back in 2017. The optiplex fx160 is still running to this day. [0] http://thesizzlewo.webflow.io/blog/get-a-dell-optiplex-fx160... reply chazeon 4 hours agoprevCore count is something I would add to the table. These mini PC are good for hobbyists, they are cheaper, stable, faster and easier to maintain than Arm SBCs I have get four of them since pandemic. I can’t wait to see what happen when hyperscaler retire their A100s/H100s. reply breakds 5 hours agoprevI am currently using a Beelink SER8, a very decent powerful mini PC for its price. It is also the most quiet mini PC I have used. reply winrid 2 hours agoprevI've always wanted to do something like this but for laptops too, and allow sorting by passmark score to find the best values. reply nashashmi 5 hours agoprevI have been looking into mini pcs. The niche I want is a USB c powered hand sized pc. I have only found two on Amazon so far, one has a small screen and another close to the size of a small dock. But they are both underpowered with Celeron processors. I just need something that i can take from one desk to another that carry docking stations. reply universa1 49 minutes agoparentI wanted to recommend Minisforum, as I have a um560, that is powered through usb-c. But that is not available anymore... So those kind of machines exist... You could get a frame.work laptop in an external case, slightly larger than hand-sized, though. reply ethanpil 4 hours agoprevThis is wonderful i'll be using this a lot. Would be great to see a filter for Tiny vs Mini as well as CPU. AMD/Intel and i3 i7 i9, etc, maybe even generation, etc reply sulandor 5 hours agoprevYES!!!! Usable ebay interface - very nice! would be great to have a filter for country of origin/shipping reply InMice 5 hours agoparentMakes you think about how most website are just junky interfaces atop relatively simple tables of data. reply mjcurl 5 hours agorootparentOh, how I wish I had better access to the eBay data .. currently they limit you to 5k requests per day. reply sulandor 4 hours agorootparentprev\"value added and removed here\" reply steeleyespan 5 hours agoprevWould have loved to see this site a few months back. I ended up buying Dell optiplex refurbs thinking they were minis, but they were big lol. Edit: Nevermind - mine are the same size as many of the listings here with DVD drives. I was thinking of micros. reply atlgator 3 hours agoprevA filter on socket/gen would be useful. Otherwise, it's a great tool! Thanks for sharing. reply amelius 5 hours agoprevIs it possible to run Linux on all of them (so remove existing Windows)? If not, maybe add a checkbox for it. reply bityard 3 hours agoparentLinux will run on basically any x86 box. The question of \"how well?\" is mostly down to the fact that some GPUs and wifi chips have substandard support due to their manufacturers' refusal to document their driver interfaces. reply pdimitar 5 hours agoprevInstant bookmark, thank you! Wishlist: please allow filtering by Intel / AMD CPUs and Intel / NVIDIA / AMD GPUs. It's IMO important to know how many open drivers can the buyer use on Linux / BSD. reply mjcurl 5 hours agoparentAnother person mentioned this, so I will add this as soon as I can. reply bloqs 5 hours agoprevCant recommend anything based on intel N100 enough. Power draw is about 13w but absolutely excellent performance. Bought several \"Firebat\" ones from AliExpress reply eternauta3k 5 hours agoprevAre you the same guy from https://diskprices.com ? Awesome tools! Would be nice to have ebay.de as well. reply mjcurl 5 hours agoparentNo, just was inspired by diskprices, thought it's great UX. I will be adding more marketplaces, .de included. reply Tepix 5 hours agoprevVery cool. Can you add support for eBay Germany (ebay.de)? reply DownrightNifty 4 hours agoprevThis is super cool! Now if only my ISP would give me a static IP address so I could expose port 51820 on one of these things and life would be perfect. reply dbs 2 hours agoprevNeat. Can you add a filter for international buyers? Non-us reply catchmeifyoucan 2 hours agoprevThis looks great! I love the Cragislist like UI for this! reply martin_a 3 hours agoprevAre those boxes powerful enough and a sensible solution to get a little NAS up and running? reply bityard 3 hours agoparentDepends on what \"a little NAS\" means to you, and what interfaces you need. But in general, most any PC made in the last 20 years would work for as simple and small storage server. reply martin_a 11 minutes agorootparentWell, something like network mounted 4 TB of space for photos, some movies, stuff like that?!? reply ornornor 3 hours agoprevPretty neat! Any plans to make it work for people not living in the US too? reply atentaten 4 hours agoprevThis is great. I wish there were something similar to find hardware to run AI models locally. reply preciz 5 hours agoprevProbably GMKtec is cheaper and better. I own one. https://www.gmktec.com reply baggachipz 4 hours agoprevVery cool. It would be helpful to allow search on processor architecture and power draw as well. reply whiterock 6 hours agoprevCould you add Geekbench scores? I‘d love that :) reply RobotToaster 4 hours agoprevdata on ECC ram support would be helpful, since it's needed for ZFS. reply gboone 6 hours agoprevWould be nice if links opened a new tab. Good job. reply mjcurl 6 hours agoparentThanks! I think it's a better practice to not open links in a new tab i.e users should have control over their experience. But it can be subjective. reply achow 6 hours agorootparentOpening in a new tab has become some kind of standard UX. Regardless of that, for this kind of site it would be very useful for product spec comparison. reply Scoundreller 6 hours agorootparentI’m a Ctrl-click kinda guy for these scenarios. reply josefresco 6 hours agorootparentprevThink about it this way: Will the user \"lose their place\" on your page if they click a link and go back? Will the user lose any filtering or search options? If the answer is yes to either, open in a new tab. I personally make this determination all the time, especially on social media after I've scrolled a lot and don't want my \"progress\" to be lost. reply mjcurl 5 hours agorootparentThat makes sense to me, thank you. I have changed links to open in a new tab. reply nfriedly 5 hours agorootparentprevI think not forcing links to open in a new tab is the right call. However, the point about losing one's place is a valid one, and I agree with the other commenter that said it would be good to encode the state in the URL to solve that. reply samstave 6 hours agorootparentprevAlways open in new tab. Ill keep track of the 437 I have open in 7 different FF windows, and the couple Edge tabs to hide cookies ThankYouVeryMuch EDIT: Yes ctrl-click is too much effort. Middle-click even. (Many forget a middle click on a mouse-wheel is also a ctrl-click/new-tab button, and the thumb button MOUSE4 is back) reply haunter 5 hours agoprevYou can probably find better deals from PC shops selling refurbuished enterprise PCs (Lenovo, Dell, HP) reply davidjade 5 hours agoprevCool. It would be great to be able to filter Intel vs AMD. Or perhaps even by processor family. reply mjcurl 5 hours agoparentSure, how about a keyword filter instead? That way you can filter by whatever instead of big filter lists cluttering the UI. reply davidjade 4 hours agorootparentThat would be good. Easy enough to filter Intel vs AMD that way as well as a particular CPU. reply whall6 2 hours agoprev+ $45 shipping :/ reply guelermus 4 hours agoprevNice. Could you please add also the postal costs to the sort? My very first trial showed me a 38$ PC with 500$ postal cost. I'm located in Europe, but still ??? reply skadamat 5 hours agoprevI love how simple this site is. It's fast, no navigation, etc. Kudos! reply darkstar_16 5 hours agoprevthe data needs a bit of a cleanup. I see N100 showing up with \"Intel 100\", Intel Alder Lake N100\" and just \"3.4 GHz\" in various places. reply mjcurl 5 hours agoparentIs this for the CPU column? That's actually one I spent the least time on, since there was so much variation with how sellers entered processors. I'll take a look at it, thanks. reply voidUpdate 6 hours agoprevoooo, this is useful! It's a pain trying to search for these kinds of things manually, and it would be nice to get a whole stack of the kind of lenovo I have haha. Just need the UK region support :P reply FloatArtifact 4 hours agoprevsorting based on the processors, release date, or by performance single slash multi-core would be interesting. reply rmac 2 hours agoprevcan we get a highcostminipcs plz reply j45 2 hours agoprevThis is a great idea. I ahve a similar set of searches on eBay for when I was buying these things. You should consider putting some affiliate links in so this continues to exist and grow. You are helping people save money, which doesn't cost them anything, and if anything makes ebay make less. I have a ton of ideas for htis that I use to narrow it down even more - starting with the CPU can be a good place. Generation, wattage, etc. reply bschmidt1 3 hours agoprevI've been using a $35 rpi4 for years, it's been a significantly better experience and cost ($0 after initial purchase) than any abstracted PaaS/IaaS I ever tried, and performance is significantly better than the free or hobby tiers. With no need for regional deploys or to have devs contributing from all over, there's not a huge need for cloud. Also kinda nice knowing all my customer data and other PI is at my house instead of at Google's or Amazon's house. Remember when Twitter and GitHub were storing passwords in plain text for years? So yeah... the peace of mind of knowing a 22 y/o at their first job is not making security decisions with my data and infra! Let alone the fact these companies sell your data including your IP - you agree to it in their terms. Beyond this stuff, I always found the UX of IaaS like AWS/GCP/etc. to be a nightmare, particularly the IAM experience. Not just navigating their awful dashboard pages, but learning their brand-specific jargon, managing service accounts, staying up-to-date on latest marketing and service breakdowns for every little thing - it quickly takes over your attention (and budget). Not to mention, using IaaS feels like devolving from a modern developer to an early 00s IT specialist. AWS feels less like \"infrastructure\" and more like a modern take on cPanel but with far less visibility/control over the server. I digress... in 2021 I copy/pasted my \"mono-server\" setup from Heroku over to the Pi 4 with vanilla Raspbian and it's been running 24/7/365 ever since. It powers 15+ APIs/backends including a booking engine for a local business in SF, some real-time socket servers for games, and there's both a SQL (postgres) and NoSQL (mongo) server running too. I attached a touch screen that shows the console output in fullscreen, and I velcro it to my wall. It looks like a smartphone charging on my wall or a smart thermostat or something, but it's nice to be able to walk up and see how things are doing. Feels better than checking any dashboard. I've had to restart it only twice over the years. A couple times it just stopped responding to requests, though didn't appear to be frozen. I could stop it and npm start again but nothing. When this happens, have to fully restart and run IPTABLES stuff again to put it back online. However - that's mere minutes spent each year rather than spending significant time every single day in an IaaS or PaaS. Thanks for sharing this awesome list, I'm due for an upgrade pretty soon and I am so glad to see so many low cost options. My hope is that more developers get into these mini PCs around the world, and I imagine a future where the Big Cloud providers play a much smaller more specific role (government data, public domain computing) rather than being the de facto platform for hobby/startup projects. Even things like regional deployments and distributed/\"serverless\" computing can be accomplished with networks and proxying without giving it all away to a major cloud provider. reply ck2 3 hours agoprevAre old capacitors still a problem on modern PC motherboards? A decade ago they would only last a decade which would make some of these boxes near EOL reply renewiltord 4 hours agoprevThis is cool. I frequently have a need for this. I also would love if there were a site for low power PCs. reply botro 4 hours agoprevI have found that laptops with cracked or scrached screens offer a much better value in terms of newer hardware. The battery acts as a built in UPS. For example this laptop: Dell Latitude 7400 Intel i7-1165G7 16GB 256GB NVMe SSD Is $180 shipped. https://www.ebay.com/itm/266969891671?mkcid=16&mkevt=1&mkrid... reply smashah 6 hours agoprevAmazing! A few more filters (e.g location) and this would be an amazing tool for buying locally. bookmarked! reply drcongo 6 hours agoprevA CPU arch filter would be useful (I've been on the lookout for an ARM based one), as would the ability to choose a different eBay region (I'm in the UK). Nice work though! reply amiga-workbench 6 hours agoparentA friend of mine has a few Dell Kace M300's which they run Linux on. Would that kind of thing be what you're looking for? It was originally an asset management appliance for businesses. https://sudos.wordpress.com/2022/05/27/dell-kace-m300-or-fan... reply heraldgeezer 5 hours agoprevI love it. But its been a bit of a \"secret\" that office PCs that are 3 years old are still very very good. I hope tech bros dont ruin this. Also lol at power consumption voes. reply tracker1 3 hours agoparentThere are some refurbers that will take office PCs and put a modern-ish GPU, upgrade the PSU etc. That said, Mini PCs don't offer PCIe expansion most of the time, so a GPU upgrade isn't an option. Less appealing compared to new options. reply distant_travelr 4 hours agoprevDude, why are the filters not url encoded??? This makes sharing a specific config to my mates so annoying reply bflesch 4 hours agoprev [–] now do the same for europe with € prices... reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author used the eBay API to find affordable mini PCs for a home server and built a static site with Eleventy and a Python script for data parsing.",
      "The site includes filters for operating system, WiFi, and HDMI, with plans to add power usage, noise levels, and PCIe slots, though this data is challenging to obtain.",
      "The author seeks feedback and suggestions for improving the site."
    ],
    "commentSummary": [
      "Mini PCs, particularly used ones, are gaining attention for their value and versatility, often outperforming Raspberry Pi clones in cost and performance.",
      "Brands like Lenovo, Beelink, and Minisforum are highlighted for their affordability and reliability, with users sharing positive experiences and specific use cases such as home servers and HTPCs (Home Theater PCs).",
      "The discussion includes recommendations for various models, tips on configurations, and the importance of features like power consumption, noise levels, and expandability, making it a valuable resource for those looking to invest in mini PCs."
    ],
    "points": 501,
    "commentCount": 237,
    "retryCount": 0,
    "time": 1724933021
  },
  {
    "id": 41392128,
    "title": "Bypassing airport security via SQL injection",
    "originLink": "https://ian.sh/tsa",
    "originBody": "Introduction Like many, Sam Curry and I spend a lot of time waiting in airport security lines. If you do this enough, you might sometimes see a special lane at airport security called Known Crewmember (KCM). KCM is a TSA program that allows pilots and flight attendants to bypass security screening, even when flying on domestic personal trips. The KCM process is fairly simple: the employee uses the dedicated lane and presents their KCM barcode or provides the TSA agent their employee number and airline. Various forms of ID need to be presented while the TSA agent’s laptop verifies the employment status with the airline. If successful, the employee can access the sterile area without any screening at all. A similar system also exists for cockpit access, called the Cockpit Access Security System (CASS). Most aircraft have at least one jumpseat inside the cockpit sitting behind the flying pilots. When pilots need to commute or travel, it is not always possible for them to occupy a revenue seat, so a jumpseat can be used instead. CASS allows the gate agent of a flight to verify that the jumpseater is an authorized pilot. The gate agent can then inform the crew of the flight that the jumpseater was authenticated by CASS. The employment status check is the most critical component of these processes. If the individual doesn’t currently work for an airline, they have not had a background check and should not be permitted to bypass security screening or access the cockpit. This process is also responsible for returning the photo of the crewmember to ensure the right person is being authorized for access. So how does this work, when every airline presumably uses a different system to store their employee information? That is what we were wondering, and where it gets interesting… ARINC ARINC (a subsidiary of Collins Aerospace) appears to be contracted by the TSA to operate the Known Crewmember system. ARINC operates a few central components, including an online website for pilots and flight attendants to check their KCM status, and an API to route authorization requests between different airlines. Each airline appears to operate their own authorization system to participate in KCM and CASS, and it interacts with the “hub” of ARINC. The TSA and airlines can send requests such as CockpitAccessRequest and CrewVerificationRequest to ARINC, which then routes it to the appropriate airline’s system and receives the response. There are 77 airlines currently participating in KCM. While larger airlines have likely built their own system, how do smaller airlines respond to these requests to participate in KCM or CASS? FlyCASS.com In our search for vendors that actually run the authorization systems, we found a site called FlyCASS which pitches small airlines a web-based interface to CASS. Intrigued, we noticed every airline had its own login page, such as Air Transport International (8C) being available at /ati. With only a login page exposed, we thought we had hit a dead end. Just to be sure though, we tried a single quote in the username as a SQL injection test, and immediately received a MySQL error: Uh oh. This was a very bad sign, as it seemed the username was directly interpolated into the login SQL query. Sure enough, we had discovered SQL injection and were able to use sqlmap to confirm the issue. Using the username of ' or '1'='1 and password of ') OR MD5('1')=MD5('1, we were able to login to FlyCASS as an administrator of Air Transport International! KCM and CASS Admin It turns out that FlyCASS also operates both KCM and CASS for its participating airlines. Now that we are an administrator of Air Transport International, we are able to manage the list of pilots and flight attendants associated with them. Surprisingly, there is no further check or authentication to add a new employee to the airline. As the administrator of the airline, we were able to add anyone as an authorized user for KCM and CASS. To test that it was possible to add new employees, we created an employee named Test TestOnly with a test photo of our choice and authorized it for KCM and CASS access. We then used the Query features to check if our new employee was authorized. Unfortunately, our test user was now approved to use both KCM and CASS: At this point, we realized we had discovered a very serious problem. Anyone with basic knowledge of SQL injection could login to this site and add anyone they wanted to KCM and CASS, allowing themselves to both skip security screening and then access the cockpits of commercial airliners. We ended up finding several more serious issues but began the disclosure process immediately after finding the first issue. Disclosure We had difficulty identifying the right disclosure contact for this issue. We did not want to contact FlyCASS first as it appeared to be operated only by one person and we did not want to alarm them. On April 23rd, we were able to disclose the issue to the Department of Homeland Security, who acknowledged the issue and confirmed that they “are taking this very seriously”. FlyCASS was subsequently disabled in KCM/CASS and later appears to have remediated the issues. After the issue was fixed, we attempted to coordinate the safe disclosure of this issue. Unfortunately, instead of working with us, the Department of Homeland Security stopped responding to us, and the TSA press office issued dangerously incorrect statements about the vulnerability, denying what we had discovered. The TSA press office said in a statement that this vulnerability could not be used to access a KCM checkpoint because the TSA initiates a vetting process before issuing a KCM barcode to a new member. However, a KCM barcode is not required to use KCM checkpoints, as the TSO can enter an airline employee ID manually. After we informed the TSA of this, they deleted the section of their website that mentions manually entering an employee ID, and did not respond to our correction. We have confirmed that the interface used by TSOs still allows manual input of employee IDs. Several other attacks were also likely possible. Since our vulnerability allowed us to edit an existing KCM member, we could have changed the photo and name of an existing enrolled user, which would likely bypass any vetting process that may exist for new members. If you are able to obtain an unenrolled KCM barcode, you can also enroll it to an employee ID yourself on the KCM website. Timeline 04/23/2024: Initial disclosure to ARINC and FAA 04/24/2024: Subsequent disclosure to DHS via CISA 04/25/2024: DHS CISO confirms they are working on a resolution 05/07/2024: DHS CISO confirms FlyCASS was disconnected from KCM/CASS 05/17/2024: Follow-up to DHS CISO about TSA statements (no reply) 06/04/2024: Follow-up to DHS CISO about TSA statements (no reply) Collaborators Ian Carroll (https://twitter.com/iangcarroll) Sam Curry (https://twitter.com/samwcyo)",
    "commentLink": "https://news.ycombinator.com/item?id=41392128",
    "commentBody": "Bypassing airport security via SQL injection (ian.sh)465 points by iancarroll 3 hours agohidepastfavorite114 comments UniverseHacker 1 hour agoHilarious that the entire TSA system is vulnerable to the most basic web programming error that you generally learn to avoid 10 minutes into reading about web programming- and that every decent quality web framework automatically prevents. It is really telling that they try to cover up and deny instead of fix it, but not surprising. That is a natural consequence of authoritarian thinking, which is the entire premise and culture of the TSA. Any institution that covers up and ignores existential risks instead of confronting them head on will eventually implode by consequences of its own negligence- which hopefully will happen to the TSA. reply VyseofArcadia 1 hour agoparent> Hilarious that the entire TSA system is vulnerable to the most basic web programming error that you generally learn to avoid 10 minutes The article mentions that FlyCASS seems to be run by one person. This isn't a matter of technical chops, this is a matter of someone who is good at navigating bureaucracy convincing the powers that be that they should have a special hook into the system. What should really be investigated is who on the government side approved and vetted the initial FlyCASS proposal and subsequent development? And why, as something with a special hook into airline security infrastructure, was it never security audited? reply shuntress 1 hour agorootparentThe problem is deeper and simpler than that. Authentication should not need to be re-implemented by every single organization. We should have official auth servers so that FlyCASS doesn't need to worry about identity management and can instead just hand that off to id.texas.gov (or whatever state they operate from) the same way most single-use tool websites use Google's login. reply bborud 1 minute agorootparentAuthentication and authorization, and especially on the web, is one of those things that has never been implemented well. I hate every single piece of software, every standard, every library, every approach I have come into contact with from this domain. I am so glad I have nothing to do with this field anymore. It makes me angry even thinking about it. reply d1sxeyes 28 minutes agorootparentprevThis exists in some European countries, in Hungary for example you have an identity service (KAU) which authenticates you and operates as an SSO provider across a number of different government properties. reply reaperducer 6 minutes agorootparentThis exists in some European countries, in Hungary for example you have an identity service (KAU) which authenticates you and operates as an SSO provider across a number of different government properties. The United States has it, too: https://login.gov But with a government as large as America's it's going to take time to get everyone converted to the new system. reply VyseofArcadia 56 minutes agorootparentprevThis seems like exactly the sort of work the US Digital Service should take on. Would still need an audit to make sure sites are actually using the shared auth and not rolling their own. reply shuntress 50 minutes agorootparentI'm not saying anyone should be disallowed to run their own authentication. I'm saying we need the digital equivalent of \"show me your driver's license\". reply AceJohnny2 12 minutes agorootparentWould that be https://id.me ? It's what the IRS uses. reply groby_b 0 minutes agorootparentThat's of course the stupidest possible domain for a government website. (Or at least it's up there) Fundamentally, it has given control over the DNS records to a different country (.me == Montenegro). It's training people that really, any domain could be a government domain, you'll never know. elliottcarlson 15 minutes agorootparentprevI think that is the goal of https://id.me reply brendoelfrendo 7 minutes agorootparentprevAh, but there are third-party services that provide identity verification, such as id.me. And now that there are for-profit entities involved in a government service, you will never be able to convince the government to implement their own solution. It's telling that id.me is headquartered in McLean, Virginia; gotta be in the DC metro area so your lobbyists have easy access to Congress. reply preciousoo 1 hour agorootparentprevSometing I’ve been thinking about, esp since that crowdstrike debacle. Why do major distributors of infrastructure (msft in case of crowdstrike, DHS/TSA here) not require that vendors with privileged software access have passed some sort of software distribution/security audit? If FlyCASS had been required to undergo basic security testing, this (specific) issue would not exist reply woodruffw 40 minutes agorootparentThey often do. The value of those kinds of blanket security audits is questionable, however. (This is one of the reasons I'm generally pro-OSS for digital infrastructure: security quickly becomes a compliance game at the scale of government, meaning that it's more about diligently completing checklists and demonstrating that diligence than about critically evaluating a component's security. OSS doesn't make software secure, but it does make it easier for the interested public to catch things before they become crises.) reply bronco21016 58 minutes agorootparentprevMoney. Eventually the lobbyists would make it so cumbersome to get the certification that only the defense industry darlings would be able to do anything. Look at Boeing Starliner for an example of how they run a “budget”. reply sandworm101 25 minutes agorootparentprevThey do. But market forces have pushed the standards down. Once upon a time a \"pen test team\" was a bunch of security ninjas that showed up at your office and did magic things to point out security flaws you didn't know were even a thing. Now it is a online service done remotely by a machine running a script looking for known issues. reply bbarnett 15 minutes agorootparent\"I made my fortune with nmap, you can too.\" reply vips7L 53 minutes agorootparentprevIn the case of msft/crowdstrike isn't this exactly the opposite of what HN rallies against? The users installed crowdstrike on their own machines. Why should microsoft be the arbiter of what a user can do to their own system? reply preciousoo 22 minutes agorootparentMicrosoft determines who they give root access signing keys to reply mrbluecoat 43 minutes agorootparentprev> FlyCASS seems to be run by one person Is their name Jia Tan, by chance? reply hn72774 1 hour agorootparentprevWe know that backdoors can be intentional for use by 3-letter agencies. And there is plausible deniability of the bureaucracy when they can pass blame onto a single individual. Or it's beuracracy being beuracracy. The TSA is a lot of security theater anyways. reply seanthemon 52 minutes agorootparentThis is a bit of ridiculous comment. Who in the right mind would say a sql injection is a backdoor for a 3LA? Added, why would they use FlyCass when they could just access the data directly? reply hn72774 42 minutes agorootparentTo move someone from one place to another without an official record of the person? Honeypot? Legit logins are logged differently than non-legit? reply woodruffw 8 minutes agorootparentThe US (and almost every government) has reliable ways to covertly move a person that don't involve putting SQLi in their own codebases. The classic way to covertly move a person is to give them a new passport to travel under, and have them move around like every other schlub on the planet. Competent intelligence services make sure that this isn't easy to detect by making the fake passport's identifier indistinguishable from real ones. Russia has prominently failed to do this several times[1][2]. [1]: https://www.bellingcat.com/news/uk-and-europe/2019/11/07/how... [2]: https://www.bellingcat.com/news/2022/08/25/socialite-widow-j... reply seanthemon 40 minutes agorootparentprevyes, they _definitely_ need to access flycass to achieve this. Almost certainly no other way. reply Simon_ORourke 1 hour agoparentprevFor an overtly authoritarian institution it actually surprises me they do the old delete and pretend it never happened approach to basic security. reply oceanplexian 53 minutes agoparentprev> Hilarious that the entire TSA system is vulnerable to the most basic web programming error Because it's a scam and the system is a grift. I'm a pilot and own a private aircraft. Landing at any airport, even my home airport which is restricted by TSA is legal without any special requirement or background check. In fact, I have heard horror stories where TSA wouldn't let a pilot retrieve their aircraft for some bullshit administrative reason or another, so they enlisted a friend with a helicopter to drop them into the secure area to fly it out. Perfectly legal. The fact that the system can be brought down with a SQL attack is the least of it. reply yieldcrv 36 minutes agoparentprevHaving done software development with other federal agencies, they probably outsourced maintenance of critical national security mandates to Deloitte who has a team with managers in India running everything with a completely counterproductive culture of hubris solely to make the two managers look good, and anybody that questions that gets terminated in a week reply pstuart 6 minutes agoparentprevBeing that CISA is under the same parent org of TSA that there should be ongoing internal evaluation/remediation of sibling services. https://www.cisa.gov/ reply woodruffw 2 hours agoprevThe TSA's response here is childish and embarrassing, although perhaps unsurprising given the TSA's institutional disinterest in actual security. It's interesting to see that DHS seemingly (initially) handled the report promptly and professionally, but then failed to maintain top-level authority over the fix and disclosure process. reply macNchz 1 hour agoparentWhat was surprising to me was that they didn't immediately do pre-dawn raids on the pentesters' homes and hold them without a lawyer under some provision of an anti-terror law. reply woodruffw 1 hour agorootparentThat's not really how this works. TSA is maliciously incompetent, but there is a reporting pipeline and procedure for these things that's formalized and designed to protect exactly this kind of good-faith reporting[1]. (It's very easy to believe the worst possible thing about every corner of our government, since every corner of our government has something bad about it. But it's a fundamental error to think that every bad thing is always present in every interaction.) [1]: https://www.cisa.gov/report reply macNchz 27 minutes agorootparentIs there any sort of assurance that this wouldn't turn into a prosecution, though? It's not obvious to me on that site. Perhaps the CISA doesn't want to deter researchers, but do they get to make the final call? The DoJ announced in 2022 that they would not prosecute \"good faith\" security researchers, but it's not binding, just internal policy: https://www.scmagazine.com/analysis/doj-wont-prosecute-good-... The policy (https://www.justice.gov/jm/jm-9-48000-computer-fraud) explicitly states at the end that it's for guidance only / does not establish rights, and it includes a provision for additional consultation on cases involving terrorism or national security–terms which have both been overloaded by the government to justify overreach in the past. Personally, given the history of the CFAA, I wouldn't want to be in a position to test out this relaxed guidance on prosecuting good-faith researchers, but perhaps I'm unnecessarily averse to the idea of federal prison. reply woodruffw 15 minutes agorootparent> Is there any sort of assurance that this wouldn't turn into a prosecution, though? It's not obvious to me on that site. Perhaps the CISA doesn't want to deter researchers, but do they get to make the final call? I don't think any sort of absolute assurance is possible, and if it was given I wouldn't trust it to be permanently binding :-) This is my intuition from having interacted with CISA, and my impression from talking to policy people: it's not 1993 (or even 2013) anymore, and there's a much better basal understanding of security researchers vs. someone trying to secure a \"get out of jail free\" card for doing something they shouldn't have. That doesn't mean the government can't mess up here, but I can't remember a prominent example of them throwing the book at a good faith report like this in the past decade. (Swartz is who I think of as an example of an extreme miscarriage of justice under an overly broad interpretation of the CFAA. And, of course, there could be facts in this situation that I'm not aware of that would motivate a criminal or civil CFAA investigation here. But \"pre-dawn raids\" aren't really it in situations like this one.) reply garyfirestorm 1 hour agorootparentprevthat is apparently not a popular move anymore since people keep logs and have credentials, strong social media presence and readily available cloud enabled cameras. one email to any news org and whoever authorizes the raid will probably face some music. but knowing TSA, we can expect this any minute now... reply smsm42 1 hour agorootparentWhy bother if they could just put everyone involved on the \"dangerous terrorist\" list which has zero controls and zero accountability because \"national security\"? That's what happened to Tulsi Gabbard: https://www.racket.news/p/the-worm-turns-house-senate-invest... reply tracker1 1 hour agorootparentprevThey just add you to a secret watch list to annoy you when you travel when you're critical of them... or the current administration, so it would seem. reply noinsight 1 hour agorootparentprevYeah, I don't know if I would go testing such systems and then reporting the results under my own name (presumably)... I didn't see any comment about them being contracted to do this at least. reply garyfirestorm 1 hour agoparentprev> It's interesting to see that DHS seemingly (initially) handled the report promptly... I think DHS mid level manager yelled at a TSA mid level manager who reported this to the senior TSA officials and then their usual policy kicked in... deny/deflect/ignore reply laweijfmvo 36 minutes agorootparentTSA is DHS, though. At some point, it's the same high-level manager... reply dylan604 1 hour agoprevSince they actually went past the SQL injection and then created a fake record for an employee, I'm shocked that Homeland did not come after and arrest those involved. Homeland would have been top of the list to misinterpret a disclosure and prefer to refer to the disclosure as malicious hacking instead of responsible disclosure. I'm more impressed by this than the incompetence of the actual issue. reply aftbit 1 hour agoparentYou're not wrong, but I would have a hard time as a jury member convicting them of a CFAA violation or whatever for creating a user named \"Test TestOnly\" with a bright pink image instead of a photo. If they had added themselves as known crewmembers and used that to actually bypass airport screening, then yeah, they'd be in jail. reply smsm42 47 minutes agorootparentThat's what jury instructions are for. The judge can instruct the jury to ignore pretty much any facts and consider any subset of what really happened that they want. So they'd just instruct \"did they access the system? Were they authorized? If the answer to the first question is yes, and to the second is no, the verdict is guilty, ignore all the rest\". The jury won't be from the HN crowd, it would be random people who don't know anything about CFAA or computer systems, it will be the easiest thing in the world to convict. Those guys got so lucky DHS exhibited unusually sensible behavior, they could have ruined their lives. reply mariodiana 29 minutes agorootparentAs my good fortune would have it, I'm called to jury duty two weeks from now. I doubt I'll be sat though. Should I be, I'll keep the above in mind. reply SpaceNoodled 4 minutes agorootparentThey tend to specifically choose against people with critical thinking skills. reply linuxftw 8 minutes agorootparentprevIf it's a criminal case, be sure to checkout the innocence project to inform yourself on some of the junk science police and prosecutors like to use. reply beaglesss 1 hour agorootparentprevWhat if they incremented a number in a url on a publicly available website? reply debo_ 1 hour agorootparentIs this a reference to a past event? I don't get it. reply beaglesss 1 hour agorootparentIn part yes but inevitably devolves into an ad hominem attack against the most high profile case of a guy who did it, who is now hiding in Ukraine on a Prednistrovian passport after having his conviction overturned (temporarily) giving him an escape window. reply fnfjfk 36 minutes agorootparent> hiding in Ukraine Huh. Uh, weird choice, given, well, you know… reply qup 1 hour agorootparentprevYes. https://www.reddit.com/r/IAmA/comments/1ahkgc/i_am_weev_i_ma... reply debo_ 1 hour agorootparentprevThanks for all the references / replies, folks. I appreciate it. reply hyperhello 1 hour agorootparentprevIt's an incredibly basic form of pen testing. For example, this reply page URL refers to id=41393364, which is presumably your comment. So what happens if I replace it with a different number? Probably something innocent, but maybe not. reply aftbit 51 minutes agorootparentprevYeah I wouldn't have convicted weev either. There is a difference though. He used that incremented number to access actual user PII. These guys created a user with no PII and no actual malicious use. reply RHSeeger 43 minutes agorootparentprevBut would it really matter if they were convicted, after being in jail for who knows how long awaiting trial, losing their job, etc? reply mrguyorama 1 hour agorootparentprev>You're not wrong, but I would have a hard time as a jury member Which is why Jury selection usually removes people who understand the situation. reply IshKebab 1 hour agorootparentprevYeah so best case you spend tens of thousands on lawyers and probably win. Doing this under your own name is insane. reply aftbit 24 minutes agorootparentBest case, assuming you even get charged, your case gets picked up by the EFF, ACLU, IFJ, etc. You spend nothing, you win, and you get a lot of free publicity for your pen testing company. Worst case, nobody comes to help you, you spend all of your money, still lose the case, end up in a shitty US prison, and get stabbed in the shower by some guy driven crazy by spending months in solitary. Personally, I would not mess with security research on anything even distantly related to US Gov. reply cabaalis 1 hour agoparentprevIf anyone from there reads the parent, they should know they have created an atmosphere where the worry of possible prosecution over responsible disclosure has the potential to scare away the best minds in our country from picking at these systems. That just means the best minds from other, potentially less friendly countries, will do the picking. I doubt they will responsibly disclose. reply smsm42 42 minutes agorootparentI personally don't comprehend how these people are taking such a huge risks. Once bureaucrat wakes one morning in the wrong mood and your life is ruined at least for the next decade, maybe forever. Why would anyone do it - just for the thrill of it? I don't think they even got paid for it? reply neilv 31 minutes agoparentprevGood catch. Of course, different people wear different shades of hat, and I guess the author might have good rationale for going quite as far as they did, I don't know. Kudos to the author for alerting DHS. Methodology questions aside, it sounds like the author did a service, by alerting of a technical vulnerability that would be plausible for a bad actor to seek out and successfully discover. But regardless, I hope any new/aspiring security researchers don't read this writeup, and assume that they could do something analogous in an investigation, without possibly getting into trouble they'd sorely regret. Some of the lines are fuzzy and complicated. BTW, if it turns out that the author made a legality/responsibility mistake in any of the details of how they investigated, then maybe the best outcome would be to coordinate publishing a genuine mea culpa and post mortem on that. It could explain what the mistake was, why it was a mistake, and what in hindsight they would've done differently. Help others know where the righteous path is, amidst all the fuzziness, and don't make contacting the proper authorities look like a mistake. reply beaglesss 1 hour agoparentprevThe statute of limitations is long and HSI often delays their indictment until the investigation is mostly wrapped up. reply dylan604 1 hour agorootparentSo you're suggesting they're not out of the woods? reply beaglesss 1 hour agorootparentDepends. If no one currently cares, there is no significant structure or personnel or political change in the future several years, and they don't have any assets worth taking, and the government doesn't get any more desperate for assets to seize -- then they're out of the woods. reply dylan604 1 hour agorootparentI doubt asset seizure is what they'd be after. I was thinking more of the \"make an example out of them\" mentality as an attempt to prevent others from being curious. Government entities don't tend to do well with knowing the difference of malicious hacking and responsible disclosure. The infamous governor and the View Source is a fun one to trot out as exhibit A. reply smsm42 39 minutes agorootparentAsset seizure is not because the government needs the money. It's because you need the money to pay for lawyers, legal experts, etc., and if your assets are seized, you can't - so you are much easier to pressure into making a quick guilty plea and get another successful prosecution added to the list. Of course, the whole process is the punishment as usual, but the asset seizure also plays an important coercive role there. reply garyfirestorm 1 hour agorootparentprevdon't even need to make an example... they probably have a warning/welcome pop up that says 'unauthorized access to this system will result in...' because the TSA lawyer is going to follow this simple train of thought - were the 'accused' authorized to access the system - gotcha! reply beaglesss 1 hour agorootparentprevBoth are definitely valid. I think saving face and cash grabs are the two fastest way to get in deep shit with the government. reply mpaco 1 hour agoparentprevThe timeline mentions the disclosure was made through CISA, and on their website there is an official incident report form. I can imagine an email to some generic email address could have gone down the way you describe, but I guess they look at these reports more professionally. https://myservices.cisa.gov/irf reply Enginerrrd 1 hour agoparentprevI mean... they still might if the wrong people end up getting embarrassed by this. The wheels of bureaucracy are slow. reply bambax 35 minutes agoprevThis shows that anyone with the slightest motivation to do harm would have zero difficulty replaying 911. The reason there aren't more terrorist attacks isn't because various security agencies around the world protect us from them. It's because there are extremely few terrorists. reply cg5280 2 minutes agoparentMaybe I am a naive idiot, but I would assume that other agencies like the FBI provide some protection even if TSA is not great. I occasionally see notable examples, like the CIA being responsible for discovering planned attacks on the recent Taylor Swift concert in Vienna that was then canceled. reply dawnerd 25 minutes agoparentprevIt’s also just one of those hard things to prove: is TSA actually stopping attacks like 9/11? The simple presence of them might be enough of a deterrent or we might just be extremely lucky. Seems these days the real threat is drunk passengers attacking flight attendants. reply macNchz 4 minutes agorootparent> The simple presence of them might be enough of a deterrent The planning for 9/11 took several years, $500k in financing, and had a lot of moving parts between recruiting, research, travel/visas, flight training etc. It's hard to believe that people motivated at that level would truly be deterred by what you see happening at the typical American airport these days. reply mikeocool 10 minutes agoprev> We did not want to contact FlyCASS first as it appeared to be operated only by one person... It seems pretty remarkable that airlines are buying such a security sensitive piece of software from a one person shop. If you make it very far into selling any piece of SaaS software to most companies in corporate America, at the absolute minimum they're going to ask you for your SOC2 audit report. SOC2 is pretty damn easy to get through with minimal findings as far as audits go, but there are definitely several criteria that would should generate some red flags in your report if the company is operated by a single person. And I would have assumed that if your writing software that integrates with TSA access systems, the requirements would be a whole lot more rigorous than SOC2. reply jerf 1 hour agoprevYou know it's bad when it's so bad that as I write this no one has even bothered talking about how bad storing MD5'd passwords is. This even proves they aren't even so much as salting it, which is itself insufficient for MD5. But that isn't even relevant when you can go traipsing through the SQL query itself just by asking; wouldn't matter how well the passwords were stored. reply rachofsunshine 24 minutes agoparentThis used to be a question on the Triplebyte interview almost verbatim, and a huge percentage of (even quite good) engineers got it wrong. I'd say probablyKCM is a TSA program that allows pilots and flight attendants to bypass security screening, even when flying on domestic personal trips. This seems like the root cause of the security issue. (Outside of the US) I've often gone through security screenings just before or after crew groups in fast track security screening lanes. reply voiceblue 2 hours agoprevNot surprised that they deny the severity of the issue, but I am quite surprised they didn't inform the FBI and/or try to have you arrested. Baby steps? reply woodruffw 1 hour agoparentThe author made the right move by doing this through FAA and CISA (via DHS), rather than directly via TSA. It's not inconceivable that a direct report to TSA would have resulted in legal threats and bluster. reply dmd 1 hour agoparentprevThose kind of wheels turn very slowly. I will bet any takers $50 that Ian will be prosecuted. reply reaperman 28 minutes agorootparentI'll take that bet. How long of a time window? 1 year, 2 years? reply dmd 22 minutes agorootparentLets say 2 years. Email in profile. reply preciousoo 2 hours agoparentprevThis should be news lol, I’m surprised a bored year 17 year old with a fake id hasn’t made a TikTok sneaking on board a plane. Sql injection ffs reply justmarc 2 hours agoprevA good old SQL injection negates the entire security theatre worth probably billions a year, hilarious, but probably not all too surprising. reply aftbit 1 hour agoparentDoes anyone remember Bruce Schneier and his faked boarding passes? The TSA scribble used to be the weak point of the entire system. reply preciousoo 2 hours agoprevThis was a wild read, that something like this could be so easy, but the later part describing the TSA response is incredibly alarming reply magic_man 46 minutes agoprevThe dudes who did this are going to probably be visited by homeland security or FBI. Not sure what they thought they will get out of this. I don't think the government cares about security, but they are vengeful. reply defparam 3 minutes agoparentAnd what will homeland security or the FBI get out of it after concluding that that these \"dudes\" are two well known talented security researchers trying to conduct responsible disclosure to make air travel safer? reply qazxcvbnmlp 17 minutes agoprevAccessing CASS is a big deal, and should be fixed but you’re gonna need more than this to board an aircraft. Also… you can fix all the SQL issues, but you’re still not going to be able to fix the “men in hoodies with a big wrench talk to an authorized administrator (while their kids are kidnapped in Mexico)” reply mariodiana 20 minutes agoprevSo, the trick here would be to purchase a ticket with a major airline, pack a no-no in your carry-on, and then bypass TSA security by adding yourself to the Known Crew Member list of a small airline using the third-party FlyCASS system, via the SQL-injection. You'd then board the major airline with the no-no. Is that the vulnerability? reply wkirby 1 hour agoprevHonestly, this is the most shocking part: > We did not want to contact FlyCASS first as it appeared to be operated only by one person and we did not want to alarm them It’s incredible (and entirely too credible) that this kind of “high security” integration could be built in such an amateur way: and a good reminder why government projects often seem to be run with more complexity than your startup devs might think is necessary. reply SG- 44 minutes agoprevi wonder if TSA will audit the entire list, also it opens up more questions too like how long accounts remain active? are they simply assuming each airline will update pilot status? they clearly haven't been treating this sytem as important it seems. reply jrochkind1 1 hour agoprev> We had difficulty identifying the right disclosure contact for this issue. We did not want to contact FlyCASS first as it appeared to be operated only by one person and we did not want to alarm them. Wait, what? Is this a euphemism for they didn't believe they would take it seriously? Reporting it over their heads to DHS was probably not less \"alarming\" to anyone... reply mdorazio 1 hour agoprevDoes anyone know how the KCM barcodes differ from employee IDs? Seems like TSA is indexing pretty heavily on those. reply dtx1 37 minutes agoprev> 05/17/2024: Follow-up to DHS CISO about TSA statements (no reply) > 06/04/2024: Follow-up to DHS CISO about TSA statements (no reply) There should be a public Shitlist of Organisations that don't get the Benefit of Responsible Disclosure anymore, just a Pastebin drop linked to 4chan. reply OneLeggedCat 35 minutes agoprev... and that was the last time Ian was allowed to fly without a printed boarding pass with SSSS on it. reply 4gotunameagain 1 hour agoprevThe safety of airports and air travel compromised by a simple SQL injection ? What is it, the year 2000 ? It should be a criminal offence for whoever developed that system. reply sergiotapia 20 minutes agoprevyeah i would not mess around with this and get put into a for-life no fly list dude. you even wrote data to the prod system, christ! reply hypeatei 1 hour agoprevI hate the TSA with every ounce of my being and these articles reinforce why. Incompetent and useless agency that only serves to waste people's time. Can't believe it still exists; 9/11 and the Bush administration really did a number on this country. reply rootusrootus 1 hour agoparentIt doesn't seem particularly unique to TSA. Flying elsewhere in the world has essentially identical security screening, with all the same stupidity. I'm a little butthurt right now, in particular, about the security at Heathrow. They confiscated a bottle of whisky that we got in Edinburgh. After 10 minutes of head-scratching and consulting with a supervisor, they concluded that \"it does not say 100ml\" (it had \"10cl\" cast into the glass) and \"even then, that is just the size of the bottle, not the liquid inside it.\" What an incredible demonstration of intelligence there. They gave us a receipt and said we could have it shipped. We checked when we got home. 130 GBP with shipping. Ended up just buying a 700ml bottle from an importer, cost about half as much. reply anal_reactor 1 hour agorootparentThe problem boils down to two issues: 1. Ok, security is bad, what are you going to do? Go to different, competing security? 2. Nobody wants to be the politician that relaxes the security right before an accident, even if the accident wouldn't be prevented with tighter security anyway. reply cyberax 1 hour agorootparent> 1. Ok, security is bad, what are you going to do? Go to different, competing security? Amazingly, you can do that. SFO doesn't use the TSA, for example. reply rachofsunshine 21 minutes agorootparentDoes it not? I fly out of SFO all the time and the experience is very similar. I guess I never checked if it was officially the TSA, but I never noticed any difference. reply grishka 1 hour agoparentprevWe as a civilization are terrible at getting over things, it seems. reply dgfitz 1 hour agorootparentOh it gets even more amusing. By the logic of the GP, Bush must have impersonated every member of the house and senate because they're not aware of how the TSA came into existence/how a law is created. The Aviation and Transportation Act garnered broad bipartisan support. reply hypeatei 1 hour agorootparentIt was referring more to the time period and general power grab that the federal government was involved in (Patriot Act, Protect America Act, etc..) Also, Bush had to sign the ASTA into law (checks and balances) which he did so he's part of the problem. reply bigstrat2003 0 minutes agorootparentHe certainly was part of the problem, but I think that the way it was phrased originally implied he was the majority of the problem. In truth, these measures had broad support from not only our elected representatives, but from the people themselves. Turns out that people do not actually give a shit about civil liberties, and our representative democracy acted accordingly. ravenstine 1 hour agoparentprevThey're one of the most seemingly incompetent agencies I am forced to deal with every year. For one, why does is it that every TSA checkpoint feels like it was scrambled together? 9/11 was a long time ago. There's no reason why checkpoints can't have better signage, clearer instructions for what should or shouldn't go on a conveyor belt, an efficient system for returning containers (I've lost count of how many times the line was held up because employees didn't feel like bringing over a stack of containers in clear view), and so on. The checkpoints do seem to go a bit faster than they used to a long time ago, but it's still a frustrating process that makes me feel like an imbecile every time I use it. I do my best to follow directions, but directions are often lacking so I have to use my best judgment from past experience, and often get yelled at anyway. Do does the TSA want to be hated? Secondly, there's been multiple occasions where I've made it through the security checkpoint with items that should obviously set off red flags. I recently made it through with a humongous center punch which, while not sharp like a knife, could do some serious damage to another person if used as a weapon. Got it through with no questions asked. I've also gotten through with scissors, knives, strangely shaped electronics, a custom build electronic device that a naive person could see as suspicious, and so on. Never have I been stopped for those things. But laptops and e-readers? I'd better not forget one of them in my carry-on bag or I'm gonna get shouted at and be forced to re-run the bag through the scanner again. I can get through with sharp metallic tools and weird unlabeled boxes with wires hanging out of them, but I can't leave my kindle in my backpack? And what about the humongous battery packs I carry? No problem having 2 or 3 of those in my bag. I guess my Macbook Air or my e-reader possess uniquely dangerous powers I don't comprehend. Even if I try to comply with the \"laptops out of your bag\" rule, I might still get shouted at if I place it in a container instead of right on the conveyor belt... or if I place it in a container with some other belongings next to it. Maybe the TSA stops terrorists that are as stupid as they are, which I guess is a good thing. But how good can stupid people be at catching other stupid people? Is it really worth it to waste everyone else's time and to treat them like crap in the process? Yup, not surprised that the TSA also reacts with as much stupidity to cybersecurity flaws. If I became supreme leader overnight, I would work to completely dismantle the TSA and rebuild it from scratch. There doesn't appear to be any value in that agency that can't be easily replaced with something better. reply pwg 22 minutes agorootparent> I can get through with sharp metallic tools and weird unlabeled boxes with wires hanging out of them, but I can't leave my kindle in my backpack? Because all airport security is reactionary. They don't try to anticipate what an attacker might do, and how they could prevent that. They simply add one more item to a check-list of \"no good\" items or of \"must be separately screened\" items. Therefore, because, one time, someone tried to ignite their shoes, there's now a checkbox that says: \"shoes must be scanned separately\". As well, because, one time, someone purportedly tried to mix together two liquids into an explosive that they brought on board in bottles, you are now limited to 100ml max in any bottle, but you can freely walk in with a 7-11 64oz Big Gulp cup and they won't blink an eye. The \"bottles\" are on the check-list, but the check-list has no entry (yet) for \"64oz 7-11 Big Gulp\". reply rez0__ 2 hours agoprev [–] > Now that we are an administrator of Air Transport International... LOL > Unfortunately, our test user was now approved to use both KCM and CASS smh... reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Researchers discovered a vulnerability in FlyCASS.com, a system used by smaller airlines for pilot verification, which allowed unauthorized access to TSA's Known Crewmember (KCM) and Cockpit Access Security System (CASS).",
      "The vulnerability was disclosed to the Department of Homeland Security (DHS), leading to the disconnection of FlyCASS from KCM/CASS, but the TSA issued incorrect statements about the issue and did not respond to follow-up corrections.",
      "The timeline of events includes initial disclosure on April 23, 2024, and subsequent actions, highlighting the importance of timely and accurate communication in cybersecurity."
    ],
    "commentSummary": [
      "A security researcher discovered that the TSA's FlyCASS system is vulnerable to SQL injection, a basic web programming error that allows unauthorized access to the system.",
      "The vulnerability highlights significant security lapses, as FlyCASS, a critical system for airport security, appears to be managed by a single individual and lacks proper security audits.",
      "The incident has sparked discussions about the need for better security practices and oversight in government systems, emphasizing the importance of rigorous security audits and shared authentication services."
    ],
    "points": 465,
    "commentCount": 116,
    "retryCount": 0,
    "time": 1724946788
  },
  {
    "id": 41388888,
    "title": "UK rail minister got engineer sacked for raising safety concerns",
    "originLink": "https://www.politico.eu/article/uk-rail-minister-peter-hendy-fired-gareth-dennis-engineer-safety-concerns-trains-london-euston-station/",
    "originBody": "News Politics UK rail minister got engineer sacked for raising safety concerns Peter Hendy threatened to withhold public contracts while seeking disciplinary action. Listen Share Share options Copy Link EMail Twitter WhatsApp Linkedin As a minister at the Department for Transport, Peter Hendy is now in charge of reforming the U.K.’s railways and determining their future structure.Carl Court/Getty Images August 29, 2024 4:00 am CET By Jon Stone LONDON — The U.K. government’s new transport minister got an award-winning railway engineer sacked for speaking to the media about safety concerns at one of Britain’s busiest stations, POLITICO can reveal. In his previous role running government-owned infrastructure manager Network Rail, Peter Hendy threatened to withhold public contracts from the man’s employer while urging disciplinary action — and asked officials to “deal with him.” Hendy was angered after the engineer, Gareth Dennis, told a journalist that overcrowding at London’s Euston station was “unsafe” because it could result in a crush — despite concern also having been voiced by the official rail regulator. Advertisement Advertisement A letter from Hendy to the engineer’s employer SYSTRA, obtained by POLITICO under freedom of information laws, warned that “finding a potential supplier criticising a possible client reflects adversely on your likelihood of doing business with us or our supply chain.” The email to the transport consultancy said that “the allegation that Network Rail is running an unsafe operation is a serious one” and added: “Employees here know that what they say in the media reflects on their employment, and I should like confirmation that your employees understand that too.” Hendy, who sent the letter in May this year, was chair of Network Rail from 2015 until he was brought into Keir Starmer’s new Labour government last month. As a minister at the Department for Transport, Hendy, who sits in parliament’s House of Lords, is now in charge of reforming the U.K.’s railways and determining their future structure — a major government priority. ‘How did we deal with him?’ Internal Network Rail emails seen by POLITICO show Hendy took issue with a quote from Dennis to the Independent newspaper in April which warned: “You’re talking about thousands of people squished into that space. It’s not just uncomfortable, it’s not just unpleasant, it’s unsafe.” After seeing a summary of the article prepared by Network Rail’s press office, the emails show Hendy told his communications chief: “Please check whether we have … and or are currently employing him as we should stop. Accusing [Network Rail] of operating the station unsafely is unacceptable.” Advertisement Advertisement When it emerged that the engineer was employed by SYSTRA, which works with Network Rail, Hendy told his officials to “write directly to their CEO” with “a request for disciplinary action as this is a serious and completely unproven allegation.” He followed up his email a week later, asking officials “How did we deal with him?” — followed weeks later by a letter to SYSTRA in which he warned the company might be passed over for future work. Dennis was suspended on May 20, according to a suspension letter from his employer seen by POLITICO, citing Hendy’s complaint. The engineer, Gareth Dennis, told a journalist that overcrowding at London’s Euston station was “unsafe” because it could result in a crush.Justin Tallis/AFP via Getty Images In September 2023 the government regulator, the Office of Rail and Road (ORR), had issued an improvement notice to Network Rail about overcrowding at the station, warning: “You have failed to implement, so far as reasonably practicable, effective measures to prevent risks to health and safety of passengers (and other persons at the station) during passenger surges and overcrowding events at London Euston Station.” Dennis, who regularly comments on railway matters in the media, told his employer’s disciplinary panel that he was merely re-stating the publicly available concerns of the regulator for a wider audience. As minister for rail, Hendy’s responsibilities now include overseeing the ORR. Network Rail told POLITICO in a statement that it had already addressed the regulator’s concerns about overcrowding. The ORR notice had told the government-owned company to do a proper risk assessment of potential crushes at the station and to draw up adequate crowd control plans to mitigate them. Advertisement Advertisement A spokesperson added that decisions regarding the engineer’s employment were a matter for his employer. Yet after SYSTRA’s CEO Nick Salt initially responded to Hendy’s email by apologizing “for any alarm this may have caused in your organisation after reading the article,” referencing the regulator’s report on safety at the station, Hendy on May 19 said he was “not convinced” by the “unsatisfactory” response and threatened to “take it up with your head office and shareholders” unless further action was taken. ‘Unsatisfactory’ Further emails show that on May 24 Dennis was offered a financial settlement to leave SYSTRA on the condition that he sign an agreement with a confidentiality clause. He did not sign it and was on July 8 dismissed with four weeks notice, following a disciplinary hearing. Dennis, who has a 1-year-old child, won the 2024 Young Rail Professional Distinguished Service Award. The email confirming his dismissal states: “As a result of the article, on the 14th May 2024 SYSTRA Ltd received a complaint from Lord Peter Hendy, Chairman of Network Rail (a SYSTRA Ltd key Client). To this end, your conduct has brought the name / reputation of SYSTRA Ltd and Network Rail into disrepute.” A spokesperson for SYSTRA Ltd told POLITICO: “We are unable to comment on individual staff matters other than to confirm that a thorough investigation was carried out.” Advertisement Advertisement Approached for comment, a spokesperson for Network Rail said: “The rail regulator’s concerns raised in September 2023 about passenger congestion at Euston station were addressed and put to bed in December 2023, months before [the article to which Dennis contributed] was published. Decisions on how employee conduct is handled is a matter for employers – in this case, Systra.” Asked whether the minister’s conduct had been appropriate, the Department for Transport declined to comment. Update: This story has been updated to clarify a reference to Hendy’s appointment as rail minister. Related Tags Infrastructure Railways Transport Related Countries United Kingdom Related People Keir Starmer Our readers read next Keir Starmer doesn’t want the UK to end up like Germany Aug 28 10 mins read The Latino vote could decide the US election. Kamala Harris knows it. Aug 26 11 mins read Greece ― the country that lets people escape justice Aug 26 10 mins read Trump has far less campaign money and infrastructure than Harris Aug 21 4 mins read More from Jon Stone UK snubs EU over rejoining popular Erasmus student swap scheme Government spokesperson says the U.K. has “no plans” to rejoin European program. Aug 28 4 mins read Brexit Britain creeps back into Brussels’ orbit under Labour A bill which paves the way for closer regulatory alignment with the European Union almost slipped under the radar. Aug 12 5 mins read Is Brexit Britain about to turn into Switzerland — without the fondue? As the U.K. and the EU enter a new era, their relationship is likely to gradually become more Swiss. Jul 29 7 mins read Germany wants a Brexit mega deal Berlin wants to expand the British prime minister’s proposed security pact into a broader EU-UK “reset.” Jul 25 6 mins read",
    "commentLink": "https://news.ycombinator.com/item?id=41388888",
    "commentBody": "UK rail minister got engineer sacked for raising safety concerns (politico.eu)423 points by scrlk 9 hours agohidepastfavorite214 comments michaelt 8 hours agoThe article that got the guy fired is [1] apparently. If you search for \"Gareth Dennis\" - honestly his criticisms seem pretty mild. My experience is the UK rail network targets truly patronising levels of safety. Signs and announcements on the dangers of running. Announcements on the dangers of slippery floors in wet weather. Announcements and signs about the importance of holding the handrail on stairs. Special extra video screens and announcements about the dangers of taking luggage on escalators. Announcements and warning signs that a flight of stairs is particularly long and tiring. Announcements on the dangers of using your phone while walking. Announcements that it's good to carry a bottle of water in hot weather. I'm surprised this guy got fired - in the rail network I know, they'd have addressed his concerns by adding even more posters and announcements. [1] https://web.archive.org/web/20240414153709/https://www.indep... reply chgs 8 hours agoparentEuston is a special case. The lack of training/concern (depending on your level of cynicism) of ticket validity of the barrier staff isn’t unique (Paddington had this problem too), but the unique problem is the way the operator (network rail) do not announce platforms until the last minute leading to stampedes to the barriers. The announcements are just there to sell more noise cancelling headphones in the on-station shops. reply masfuerte 4 hours agorootparentThey delay platform announcements because they believe that a platform crammed full of waiting passengers will become a crush risk when the arriving passengers start to disembark. When they announce the platform there is often enough time to stroll, but people rush because they want a seat. It's a hard problem to solve in the short term. reply ralferoo 3 hours agorootparent> there is often enough time to stroll, but people rush because they want a seat. I'm someone who used to frequently catch the last train north to Birmingham on a Saturday night (9:40pm), and it was usually full and so some people were without a seat. Of course we all rushed to try to get a seat. IMHO, it's foolishness to think people would do otherwise in that situation - after all who wants to stand for over an hour and a half when you've paid over £30 for the ticket? reply bee_rider 2 hours agorootparentMaybe they need reserved seating, haha. reply lol768 3 hours agorootparentprevAnyone in the know knows where to look to find out the platform before it's \"sanctioned for the public to be informed about it\". And no, there isn't always time to stroll to the train, I've seen some really, really late announcements. Couple this with very large countdown timers that they actually added recently to each platform and you can see exactly why people feel stressed and rush. > They delay platform announcements because they believe that a platform crammed full of waiting passengers will become a crush risk when the arriving passengers start to disembark. The alternative is forcing them all to wait in the same cramped concourse area (with most space lost to retail units). During disruption, it gets genuinely difficult to move through this area. It has felt unpleasant in normal use for a while, but when there are cancellations and delays it feels positively dangerous. I am not exaggerating when I say that it feels very much like it's only a matter of time before something happens and someone gets crushed or trampled. There's none of this nonsense at some other London termini, and Birmingham New Street manages to let people wait on the platforms. Why can't Euston? reply pm215 7 hours agorootparentprevI think at Kings Cross also they have a tendency to not announce platforms until quite soon before departure. reply michaelt 5 hours agorootparentUnlike Euston, Kings Cross was extensively renovated for the 2012 olympics, which by the standards of UK rail stations is a very recent upgrade. They seem to have built it with enough capacity that they can announce platforms at the last minute and send everyone scurrying without causing any great danger. reply tialaramex 4 hours agorootparentKings Cross is a mess of different systems, especially as the whole Kings Cross/ St Pancras complex rather than solely Kings Cross (which is only a dozen platforms). The low numbered Kings Cross platforms (zero through seven) are all accessed via a sideways entrance gate line, which is not good at all and you'd clearly never do that unless there's no economic alternative. reply michaelt 2 hours agorootparentOh absolutely. The underground bit is a total maze. Crossings on all the nearby roads are a nightmare. Nowhere near enough seating. But that gate line you mention has loads of ticket barriers - there's zero crush risk. reply FridayoLeary 2 hours agorootparentprev10-15 minutes in my experience. reply SllX 3 hours agorootparentprev> The announcements are just there to sell more noise cancelling headphones in the on-station shops. This is a good—albeit shameless—business model. They could probably do the same thing in San Francisco’s MUNI stations. reply yodelshady 7 hours agoparentprevInteresting, \"the Office of Rail and Road ... issued Network Rail with an improvement notice\" For the benefit of readers not versed with UK regulation, an improvement notice is a formal instrument under the powers of the Health and Safety Executive. Whilst short of a prosecution notice, it definitely indicates that the powers that be are Officially Not Happy with, in this case, Network Rail. reply whatshisface 3 hours agoparentprev>Signs and announcements on the dangers of running. Announcements on the dangers of slippery floors in wet weather. Announcements and signs about the importance of holding the handrail on stairs. Special extra video screens and announcements about the dangers of taking luggage on escalators. Announcements and warning signs that a flight of stairs is particularly long and tiring. Announcements on the dangers of using your phone while walking. Announcements that it's good to carry a bottle of water in hot weather. I don't think there is a shred of evidence that being bombarded with neurotic fretting improves safety - here in the states this is usually recognized as limitation of liability. Juries will accept \"we warned you,\" as a counterbalance to their universal tendency to want to side with the little guy against the giant corporation. reply lesuorac 3 hours agorootparentWell, it could be liability related. But, falls are basically the only way people get injured at DC's Metro so it seems to make sense to have significant signage about that. I'd have to imagine there's nothing unique about DC so it's probably the same story for the UK. \"96% of the customer injuries were related to slips and falls within rail stations, and about 52% of those were on escalators.\" [1]. The stat for employees was 40% with being struck by an object in #2 at 25%. [1]: https://wmata.com/about/calendar/events/upload/3A-Metro-s-Sa... reply techwizrd 1 hour agorootparentI work in transportation safety, primarily aviation but we also support WMATA. We usually define barriers which prevent, control, or mitigate an accident or undesired state [0]. Safety systems often require warning signage. Anecdotally, I find that regulators, companies, etc. use signage or safety bulletins than active barriers [0] because they are cheaper and quicker to implement. Even when they implement something like, say, abrasive floor treatments [1], that is only one barrier and likely imperceptible to the public. Warning signage may be helpful, but I am skeptical of its effectiveness (especially as implemented). For example, \"ice-warning signs do not have a statistically significant impact on the frequency or severity of vehicular accidents that involve ice.\" [2] (Disclaimer: Opinions are my own.) [0] https://www.wolterskluwer.com/en/solutions/enablon/bowtie/ex... [1] https://www.nata.aero/data/files/webinar_documents/preventin... [2] https://doi.org/10.1016/S0001-4575(00)00020-8 reply hex4def6 2 hours agorootparentprevI'm not sure being reminded not to slip would reduce my likelihood of slipping. Seems like things like making sure floor transitions are mild, adequate drainage, textured floors would be more effective. (polished stone and concrete are a nightmare with some shoes that I own in wet weather). reply whatshisface 2 hours agorootparentprevWhat's the connection between signage talking about falls and the rate of falls? I don't see any. reply sealeck 8 hours agoparentprevI genuinely don't see the harm of these things – I often think the issue is that lots of measures improve safety at the margins (e.g. if someone is drunk and stumbling down the stairs this announcement might help them) rather than on average. That is: many safety features will produce limited tangible benefit to the average person most of the time, but they do reduce accidents which normally happen at the tail end of the distribution in more extreme circumstances. reply cwillu 8 hours agorootparentBanner blindness. If 95% of safety signage is banal and useless to most people, then most people will simply stop paying attention to signage. Putting up a sign is not a free action! reply jasoncartwright 7 hours agorootparentI saw myself doing this in realtime when visiting California for the first time. The initial shock of seeing signs that warned of cancer causing chemicals in buildings quickly faded when I realised they were on every building - soon becoming as blind to them as the locals. reply short_sells_poo 7 hours agorootparentprevTo be honest this is a general problem with the UK. Try driving on any major street and you'll realize it's plastered with mostly useless signs. A dozen warnings assault your senses at any one time, which makes it very difficult to pick out what is actually important. This is compounded by sometimes completely braindead implementation of rules. E.g. most bus lanes in London can be used by motorcyclists, but some cannot. There's no rhyme or reason, the entire thing is decided by a small blue sign at the start of a particular stretch which may or may not have an even smaller motorbike icon on it - among an icon for a bus, taxi and pushbike. Whoever thought this is a good idea is either a moron or deliberately wanted to extract fines from motorcyclists who accidentally use the wrong bus lane. reply logifail 7 hours agorootparent> To be honest this is a general problem with the UK Hotel lifts would appear to be another example of this. Automated \"doors closing\" / \"doors opening\" announcements seem to be present almost everywhere. Presumably a significant number people suffer appaling crush injuries from lift doors in other countries ... or maybe they don't, and companies across the UK just let their Health and Safety conslutants get the upper hand. reply hnlmorg 6 hours agorootparent...or visually impaired and thus use those announcements to understand what state the lift is in. reply miki123211 4 hours agorootparentBlind person here, I find the \"doors closing\" / \"doors opening\" announcements pretty tiresome, and I don't think they provide any benefit to us. They sometimes even make things worse. Especially on bilingual elevators (not that uncommon in European countries where English isn't an official language), there are so many announcements that the elevator just can't keep up when there's a lot of traffic. I've seen a few elevators that were always a few announcements behind during periods of high activity. The \"lift (elevator) going up / down\" announcements, on the other hand, are quite helpful, and I vastly prefer the European system than the American mess of ADA-compliant beeps. reply lupusreal 2 hours agorootparentWhy is the American system a mess? One chime for up, two for down. It's simple and doesn't bother anybody. reply vizzier 1 hour agorootparent(speaking as a person who isn't blind) The biggest omission seems to be that there is nothing to tell you what floor you've arrived at. This is probably fine for an empty elevator but as soon as it gets busy and there are 10s of floors I'd imagine it gets hard to navigate. reply jakey_bakey 6 hours agorootparentprevLol yeah of all the examples to choose Why are the pavements at crossings so bumpy?! It's political correctness gone mad! reply logifail 5 hours agorootparentprev> ...or visually impaired and thus use those announcements to understand what state the lift is in ...but only in lifts in the UK? No, that's not a credible hypothesis. reply hnlmorg 4 hours agorootparentThey’re not only in UK lifts and even if they were, that still wouldn’t change the intention of those announcements. reply joshuaissac 2 hours agorootparentprev> Try driving on any major street and you'll realize it's plastered with mostly useless signs This is not in line with my personal experience. Can you provide some examples of useless signs on typical roads in the UK? reply cameronh90 1 hour agorootparentThe \"tunnel ahead\" sign always struck me as particularly pointless. Who needs that sign? Surely if you're driving towards a tunnel, the enormous tunnel itself is the indication you need that you're heading towards a tunnel? Honourable mentions for \"humps ahead\". reply gambiting 3 hours agorootparentprevI'm sorry, but UK is positively devoid of road signs compared to some other countries lol, I've been driving here for well over a decade and it's really nice how few signs are here and it mostly relies on common sense. Compare to your average road in Poland: https://motofakty.pl/co-5-metrow-znak/ar/c4-16143839 67 road signs on a 360 metre long stretch of road - and to me, what's shown in the picture is very typical, especially in big cities. There are soooo many signs it's close to impossible to read all of them and still look at the road. reply graemep 4 hours agorootparentprevI agree. Trying to track it all can be distracting. reply robryk 6 hours agorootparentprevIs it still not a free action if it replaced an ad? reply philipov 5 hours agorootparentThat makes it literally not free - it was paid for with the opportunity cost of the ad. reply Phemist 3 hours agorootparentAt a society level, ads are paid for with the opportunity cost of other things that people could be thinking about, e.g. cancer-curing drugs. We can therefore say that ads cause cancer. reply SllX 3 hours agorootparentBoth are at the cost of a generally more tranquil and quiet environment. I would take the most boring, crack-filled and grayest concrete wall over someone else’s messaging whether it is paid for or the agency’s own propaganda. reply jellicle 2 hours agorootparentOne of the reasons that people like many tourist destinations is that many tourist destinations forbid most outdoor advertising. It's subtle, probably many tourists don't even realize it, but it changes the entire feel of a place. reply Phemist 3 hours agorootparentprevAdditionally, the ones, whose ad-induced distraction would most benefit society, will not see these ads as they will likely not take the subway. reply logifail 7 hours agorootparentprev> I genuinely don't see the harm of these things [..] they do reduce accidents It would be good to see actual data backing up this hypothesis. The cynic in me says another equally plausible hypothesis would be that this is entirely about the owner/operator/landlord avoiding any legal responsibility for accidents than actually reducing the number of accidents. reply tim333 4 hours agorootparentMy mother had a job coming up with such warnings. She was a 'home safety technician' for the local council, advising people not to fall off ladders and the like. It seems to work like there are statistics that so many people end up in hospital after falling of a ladder or whatever and the council thinks we must fix this, we'll hire someone to educate the public. The odd poster probably doesn't make much difference to the number of people falling but it was quite an easy and entertaining job for my mum. reply MrBuddyCasino 8 hours agorootparentprevBehold, the last man. reply 2-3-7-43-1807 7 hours agorootparentprevit's not so much \"harmful\" as it is a symptom of and also reinforcing a society mentality of immature and infantile irresponsibility. but one might also argue it is harming visual and acoustic silence by constantly announcing something and hanging signs everywhere. reply newsclues 8 hours agorootparentprevYou think stumbling drunk people are helped by signs and announcements? reply justinclift 7 hours agorootparentSometimes, probably yes? :) reply newsclues 6 hours agorootparentI'd love to see the research that would substantiate that, from anecdotal evidence, stumbling drunks don't read or listen to anyone. reply truculent 7 hours agoparentprevThe most egregious ones were ubiquitous signs on the London Underground stating that travellers should take care on the escalators; there were 111 accidents on the escalators last year, after all. There are over 4 million tube journeys a day[1]. [1]: https://tfl.gov.uk/info-for/media/press-releases/2023/novemb... reply PaulRobinson 2 hours agorootparentThose accidents can be life changing, and often cause delays to services or dangerous levels of congestion during rush hour. I also suspect TfL are motivated to reduce liability - if they can show on CCTV somebody walking past a sign saying to take care, and then not taking care, TfL's coffers (i.e. the public's, it's not a private profit making entity), can be protected a little more from egregious legal claims. reply closewith 6 hours agorootparentprevSo the signs work! reply jdietrich 3 hours agoparentprev>My experience is the UK rail network targets truly patronising levels of safety. It's clearly working, because the British railway network is the safest large network in Europe, despite some pretty dilapidated infrastructure. https://international-railway-safety-council.com/safety-stat... reply DrBazza 7 hours agoparentprevYou're talking about railway lines and stations with ad-hoc upgrades that are as much as 200 years old (yes). Most of the network is comfortably over 100 years old and trains were slower, and frankly, people were less mollycoddled. But, with regards to the article, he's 100% correct, Euston is dangerous. And it's currently one of the worst central London stations for things going wrong. It's pretty much every other week at the moment. London Bridge used to be as bad with overcrowding until they rebuilt most of it. Then again, Euston was supposed to be redeveloped for HS2, and that's been kicked into the long grass, even though all the hard work has been done. I don't think there's anyone truly as stupid as the UK government. reply rootusrootus 2 hours agoparentprevWhat stuck out to me wasn't the signage, but \"See it, say it. Sorted.\" Right along with \"mind the gap!\" that is going to be my enduring memory of UK rail. reply cameronh90 1 hour agorootparent\"If you see something that doesn't look right, speak to staff or text British Transport Police on 61016. We'll sort it. See it, say it, sorted.\" It haunts my dreams. reply philjohn 4 hours agoparentprevBut then trains highly overcrowded so in the case of another Greyrigg the death and injury toll would be far higher. But affording to a train company there is \"no upper limit on the number of passengers in a given train carriage\". I did point out that the laws of physics, and basic human physiology would refute that assertion. So, maybe safety theatre rather than patronising levels of safety. reply dazc 5 hours agoparentprevI believe the purpose of these safety warnings is more about mitigating liability for accidents rather than any true concern for traveller's well being. reply red_admiral 5 hours agoparentprevThe UK rail network is in the unhappy position of getting sued whenever someone gets hurt, however stupid they're being. I think there was a case where some youths cut through the fencing around a depot, climbed on a train and got killed by the overhead wire - and then Network Rail got fined for not having a more vandal-proof fence or something like that. reply aix1 3 hours agorootparentThis? https://www.orr.gov.uk/search-news/fine-for-network-rail-fol... reply jnsaff2 8 hours agoparentprevThe posters and announcements won't make anything safer. They are CYA for the time the risk materializes. reply zero_k 7 hours agorootparentExactly. See Sidney Dekker's Field Guide to Understanding Human Error. The posters do (almost) nothing -- other than covering the backside of those who put them up, and doing safety theatre. Looks good, does nothing for safety. The same author, Sidney Dekker, has a very good book about how to deal with someone like this whistleblower. It's called \"Just Culture\". Well worth a read. Spolier: It's not to silence them, not this way. You can silence the person by, you know, actually doing something useful. But that requires actual change, and more importantly, a change in attitude. And you need to convince the crowds that you are doing better by NOT putting up posters. You'll be surprised how many people really think the posters help. reply ReptileMan 1 hour agoparentprev>My experience is the UK rail network targets truly patronising levels of safety. Signs and announcements on the dangers of running. Announcements on the dangers of slippery floors in wet weather. Announcements and signs about the importance of holding the handrail on stairs. Special extra video screens and announcements about the dangers of taking luggage on escalators. Announcements and warning signs that a flight of stairs is particularly long and tiring. Announcements on the dangers of using your phone while walking. Announcements that it's good to carry a bottle of water in hot weather. Everything wrong with the UK today can be summarized as society going from \"Mind the gap\" to this insanity. reply foldr 10 minutes agorootparentI agree that the announcements are annoying, but isn't this an overly emotional response? UK railways are extremely safe (as shown in the following link that someone else already posted here), and the annoying announcements might just be one of the less appealing aspects of an overall safety culture which is working as designed. I certainly don't see any connection between annoying announcements and any of the real problems facing the UK at present. E.g. what do they have to do with the housing crisis, or the social care crisis, or ...? https://international-railway-safety-council.com/safety-stat... reply GoToRO 6 hours agoparentprevthose are just to limit their liability: we told them not to so it's not our fault. The real safety, the one that they should provide is somewhere else. reply throw73748 8 hours agoparentprevPosters are just a charade. Try to remove dangerous aggressive dog from transport, and see what happens. reply halicarnassus 7 hours agoprevIn the comments here I read a lot about if this is whistleblowing or not, or if disciplinary measures are warranted for an employee \"badmouthing\" an employer's client while not having an official mandate to speak in public, while mostly ignoring the threats made by a government official. This is exactly the problem why the world sucks so hard. The engineer, certainly knowledgeable in this field, made a measured public remark, which could have saved lives. He has done nothing wrong, because he didn't claim to speak on behalf of his employer, and has the right to speak his mind as a person. In public, and with a lot of reach. The government official, however, applied unconstitutional pressure to get the engineer fired and threatened his employer to lose business. Humanly very low and damaging to future public rail infrastructure, if a capable company is not allowed to provide services anymore and therefore most likely to increase prices through diminished competition. If anyone should lose their job over this matter, it clearly should be the UK rail minister. reply smcl 7 hours agoparent> while not having an official mandate to speak in public Gareth Dennis has been a public figure for a while, appearing on BBC News a few times. So there was apparently a provision for this in his contract with Systra: https://x.com/GarethDennis/status/1829053692508623154 reply keyshapegeo99 5 hours agorootparentSystra also lauded his media appearances on their website: https://web.archive.org/web/20240829120751/https://www.systr... > [Gareth's] passion and enthusiasm for all things rail are well-known across the sector through his weekly #Railnatter podcast and as a regular national press rail commentator reply smcl 5 hours agorootparentAh that's an interesting revelation. But yeah totally unsurprising really, he's very good at talking in plain, accessible English about rail-related matters that might otherwise cause people to glaze over and ignore. And it's not like he's ever been a shit-stirrer either - in the interview in question he was pretty reasonable. It's just that this guy Lord Hendy has taken a dislike to NR being called out and started a little vendetta against Dennis. reply XCabbage 5 hours agoparentprevWhat aspect of the UK's nebulous \"constitution\" do you claim was violated here? (Or are you just reflexively/thoughtlessly saying \"unconstitutional\" because it would be a First Amendment violation in the USA?) reply rsynnott 7 hours agoparentprevI suspect the minister may be an ex-minister soon, alright; it’s not a good look, and he’s only been in the job a month or so, so replacing wouldn’t be a huge deal. reply jonp888 6 minutes agorootparent> he’s only been in the job a month or so, so replacing wouldn’t be a huge deal He's way, way than more than just some guy who has been rail minister for a month, he's one of the most respected, perhaps the most respected transport executive in Britain(at least until yesterday). He's not an elected politician, he has worked professionally in rail transportation since 1975. For 10 years he was Chief Executive of Transport for London which runs all public transport in London. Following that, for the past 10 years he was and still is Chairman of Network Rail, the organisation which is responsible for the entire British Railway Network. It's in this capacity that he sent the letter, not as a minister. Unless this turns into some huge scandal, which seems unlikely, he'll be fine. reply alephnerd 6 hours agorootparentprevHe's also a mid-level minister, so it's pretty easy to can him. Most Ministers are just political appointees anyhow - the actual work is done by the Civil Service. reply callamdelaney 7 hours agoparentprevThere is no constitution here, your existence and rights as a British citizen is at the convenience of the state. reply jonp888 0 minutes agorootparentIf you're trying to compare Britain unfavourably to the US with this comment then that doesn't really hold up. People are sacked all the time in the US for bringing their employer into disrepute, and it doesn't even matter whether they actually did or not, since the employer doesn't have to give a reason anyway. reply graemep 6 hours agorootparentprevIts not that simple. There is a body of constitutional law. There is extensive law governing what powers ministers have - powers are granted to them by legislation. There are human rights granted by law and treaty. Everything from some clauses of the Magna Carta that are still in force https://www.parliament.uk/about/living-heritage/evolutionofp... to the European Convention on Human Rights. reply philwelch 6 hours agorootparentAnd thanks to parliamentary supremacy any and all of those protections can be repealed by a simple majority of the House of Commons. reply graemep 4 hours agorootparentTrue, but that is a long way from how I read the comment I replied too reply philwelch 4 hours agorootparentIn countries that actually have a strong constitution—the US is the primary example though I hope others exist—the Constitution itself is the supreme law of the land and is, by design, difficult to amend. When legislatures pass laws that exceed the bounds of the Constitution, the courts strike down those laws as null and void. In that sense, Britain does not have a constitution. Obviously it has a constitution in some sense, because there is always some set of laws, norms, traditions, and historical precedents that constitute the basis of government. But this is a much weaker sense of the term. For instance, the Fixed-term Parliaments Act 2011 was a “constitutional” law that supposedly made it impossible to call a snap election, but a snap election was nonetheless called in 2019 via the Early Parliamentary General Election Act 2019, which only required a simple majority because it had equivalent authority to the FTPA itself. reply foldr 4 minutes agorootparentI'm not sure the US is currently a particularly great advertisment for its model of constitutional government. In place of acts of Parliament that have a relatively clear interpretation (and that can be undone or modified by elected representatives), there is legislative deadlock and an endless series of judicial séances attempting to determine whether or not Ben Franklin would have supported gay marriage and abortion rights if he'd been born 300 years later. lesuorac 2 hours agorootparentprev> When legislatures pass laws that exceed the bounds of the Constitution, the courts strike down those laws as null and void. Well, that's not actually in the US constitution. And, the Executive branch is free to ignore what the Judicial branch [1] does since ya know, it's the Executive branch that would execute any decisions. [1]: https://en.wikipedia.org/wiki/Cherokee_Nation_v._Georgia#Aft... reply tengwar2 4 hours agorootparentprevNo, in that sense the UK does not have an American-style constitution - no more, no less. It is not accidental that Parliament can reverse any decision taken by an earlier Parliament: in fact it is one of the most important parts of the constitution that no Parliament can take a decision which binds a later one. It is different from the American design, yes, but the way in which the American constitution is used does not seem praiseworthy, not does it suggest that it would be wise to copy it. reply immibis 3 hours agorootparentprevThe same as an American citizen, then. That piece of paper locked up in the national archives (or wherever) didn't come running, armed with a gun, to save the life of George Floyd or anyone else. reply callamdelaney 2 hours agorootparentNo but it is a basis in law for eg freedom of speech, that sort of right is none existent here. Id much rather have a formal, immutable constitution. reply londons_explore 9 hours agoprevThis guy will get 1 years salary as compensation after winning an unfair dismissal case, and then he will never work in rail again. He'll have to pay much of those winnings back to his legal team. Over his life, he will almost certainly earn less. Shouldn't have spoken out. Had he kept quiet, a crush would have happened, a few people would have been pushed off a platform and died under a train, and it would be a \"tragedy\" - but he'd get to keep his livelihood. reply scrlk 9 hours agoparentSee Roger Boisjoly, an engineer at Morton Thiokol who tried to blow the whistle on design flaws in the Space Shuttle's solid rocket boosters before the Challenger disaster: https://en.wikipedia.org/wiki/Roger_Boisjoly > Boisjoly sent a memo describing the problem to his managers, but was apparently ignored.[8] Following several further memos, a task force was convened to investigate the matter, but after a month Boisjoly realized that the task force had no power, no resources, and no management support. In late 1985, Boisjoly advised his managers that if the problem was not fixed, there was a distinct chance that a shuttle mission would end in disaster. No action was taken. > After President Ronald Reagan ordered a presidential commission to review the disaster, Boisjoly was one of the witnesses called. He gave accounts of how and why he felt the O-rings had failed, and argued that the caucus called by Morton Thiokol managers, which resulted in a recommendation to launch, was an \"unethical decision-making forum resulting from intense customer intimidation.\" > According to Boisjoly, Thiokol unassigned him from space work, and he was ostracized by his colleagues and managers. reply vegardx 8 hours agoparentprevI get the point you're trying to make here, and the sarcastic undertone, but I'd have issues living with myself if people died because of something that I was able to identify and that was preventable, and I did nothing. The whole case strikes me as odd. Not only did the higher ups know about the problem, they also left a paper trail about keeping a lid on it and getting rid of the guy. This opens them up to a lot of scenarios, like: - As demonstrated by this case, the information came out because of the wrongful termination - If an accident had happened there's a fairly high chance that the investigators would uncover it, either because the engineer in question came forward or because they think they should have known about this, and cracks appear when they start asking questions. An unspoken rule in a lot of fields is that you make sure that this kind of information never reaches the people that could be held liable for it. The people that are likely to be held responsible at least have to make it appear that they're not trying to suppress information like this. You quickly lose that ability if you actively try to get rid of people that tries to raise an issue. So they surround themselves with middle management that knows to not bring things up to them, without being explicitly told so. reply yieldcrv 8 hours agorootparentThe point is that there are many people sleeping fine or not, that kept their livelihood by not whistleblowing. solely due to the misaligned incentives and lack of accountability reply blitzar 7 hours agoparentprevThe maximum unfair dismissal compensatory award (in the UK) is £105,707. Imagine if the maximum you had to pay if you stole from or defrauded your employer was £100k ... The legislation tends to protect the paper entity 'the corporation' rather than the living breathing human. reply RyanHamilton 7 hours agorootparentWow, I didn't believe you so googled and I'm stunned. There is a limit for unfair dismissal. Thanks. reply londons_explore 5 hours agorootparentprevYou can still sue the company for other reasons - for example if they stole from you the employee. reply seanthemon 9 hours agoparentprevIronically: The Trolly Problem [0] except the singular person is you. [0] https://en.m.wikipedia.org/wiki/Trolley_problem reply tsimionescu 9 hours agoparentprevI bet even if your predictions are right, he'll still live a happier life knowing he has saved some lives. reply iudqnolq 8 hours agoparentprevHe's just published a book that looks quite interesting: https://www.amazon.co.uk/How-Railways-Will-Future-Rediscover... reply HPsquared 8 hours agoparentprevSociety depends on these kinds of people. reply gsky 4 hours agoparentprevNo good deed goes unpunished sadly. what a f..d up world we live in reply glitchc 5 hours agoparentprevYeah, I mean, why even become an engineer? Why work in safety? Let's rubber-stamp everything the manager says it's good. It must be good, they said it! Think about your words the next time you or a relative or a friend is hurt or dies in a preventable accident. Thank god you're not an engineer. reply datavirtue 6 hours agoparentprevThe system is what it does. And that's the system. reply surfingdino 8 hours agoparentprevHe'll find a job as a security consultant abroad. He'll be fine. reply fragmede 8 hours agorootparentBeing forced from your home and into moving abroad and into a new career might work out for him, but it's still seems like a lot of unnecessary turmoil for him and and his familybecause he chose to do the right thing. reply 2-3-7-43-1807 7 hours agoparentprevthis is the right attitude - exactly. reply hwhwhwhhwhwh 8 hours agoparentprevYou will at max live another 100 years. Where will he take all these extra savings to? reply ninininino 1 hour agorootparentThis is going to surprise you, but having more money enables you to spend more of your finite lifespan working on your own initiatives/goals in life (whether they are financially rewarding or not) without needing to persuade someone wealthier than you that they want what you want and are willing to pay to do it. reply hwhwhwhhwhwh 8 minutes agorootparentI believe there is a non zero probability that you(awareness) are eternal and what you do in this life has consequences in subsequent lives. It's okay for you to disagree. That's just my belief system. reply dobladov 9 hours agoprevPeople whose job is managing and not understanding issues does not want to deal with issues, it’s in their interest to always give the impression of everything working smoothly, that's why engineering driven companies fail the moment that managerial people takes over. reply khafra 8 hours agoparentExecutives and managers do actually contribute useful things to large-enough firms. But the failure mode of engineer-driven companies is Juicero; the failure mode of MBA-driven firms is killing people for profit (lying in order to sell poison to third-world mothers, sending death squads after labor organizers, lowering passenger airliner quality until they start falling out of the sky, etc.). reply maeil 8 hours agorootparent> But the failure mode of engineer-driven companies is Juicero; the failure mode of MBA-driven firms is killing people for profit. This is one to hang on the wall as an office poster! reply rqtwteye 6 hours agorootparentprevI wouldn’t call Juicero engineering driven. More over-engineering driven. Similar to software developers creating hyper scalable microservice architectures for even the most trivial systems. True engineering is to understand the requirements and creating an efficient solution for those, not just throwing every possible technology at the project. reply regularfry 48 minutes agorootparentThat's why it's a failure mode. reply phanimahesh 7 hours agorootparentprevJuicero feels like a manager or growth hacker or hype person driven thing. I find it hard to imagine juicero being an engineering team. reply khafra 6 hours agorootparentI'm not a mechanical engineer, so I base my \"overly engineer-driven\" impression of the company almost solely on this video: https://www.youtube.com/watch?v=_Cp-BGQfpHQ reply blitzar 7 hours agorootparentprevJuicero feels like a failure mode of grindset. reply mindslight 5 hours agorootparentprev... and the Juicero type failure is worse from the perspective of most investors. reply Rinzler89 9 hours agoparentprevEmployees: - It's 3.6 Röntgen, but that's as high as the meter... Management: - 3.6 Röntgen, not great not terrible. reply gaius_baltar 3 hours agorootparentA more fitting quote would be \"They gave them the propaganda number\". reply ChrisMarshallNY 4 hours agorootparentprevWas that from HBO's Chernobyl? reply ThePowerOfFuet 3 hours agorootparentYes. reply cedws 8 hours agoparentprevIt’s a very HN thing to say, but god, the world would be so much better if we kicked these parasites out and engineers ran the show. reply dagw 7 hours agorootparentLots of people with engineering degrees and backgrounds hold very senior positions at large companies and happily make short term, profit driven, decisions every day. Unless you want to play a game of \"no TRUE engineer\" I don't think it would make a huge difference. reply hermitcrab 6 hours agorootparentThe UK is full of stuff, built by Victorian engineers. Quite a lot of it is still working. Some of it is quite beautiful. I doubt anything built by private equity backed companies will still be working in 100 years. reply JTbane 4 hours agorootparentprevI don't know about your tastes, but personally (as an individual contributor) the idea of classic manager work (dealing with vacations, perf reviews, hiring, firing, etc) are extremely unappealing to me. reply Rinzler89 8 hours agorootparentprevGood engineers don't have the neccesariy personality traits to climb over corpses of others to get into upper management. So those who end up in upper management are always the worst sociopaths who only know how to play the politics game as their main goal is just climbing the ladder, not developing good products/services. Exceptions do exist (Jensen Huang, Lisa Su, etc) but that's why they are the exceptions. reply ashkankiani 8 hours agorootparentI get nervous reading when people write exceptions and name \"good\" CEOs or \"good\" celebrities. Lots of skeletons come out later. I don't like to put people on a pedestal, especially those we don't know intimately well. reply nordsieck 8 hours agorootparent> I get nervous reading when people write exceptions and name \"good\" CEOs or \"good\" celebrities Good CEOs are good at being CEOs. That doesn't mean that they're good people. Steve Jobs was pretty famously an a-hole, and did a number of morally questionable things. But he also took Apple from the verge of bankrupcy to one of the most valuable companies in the world. OJ Simpson was a fantastic football player. And he murdered (my opinion) Nicole Brown Simpson and Ron Goldman. It's OK to acknowledge that some people are good at one thing and are also terrible in other ways. reply HPsquared 8 hours agorootparentFunnily enough that's also often the issue with engineers - good at technical things but not so good elsewhere. There's a reason we all have different jobs. reply lupusreal 8 hours agorootparentprevBetter to acknowledge that you are speaking in generalities and exceptions exist, but not to name those exceptions. reply benterix 8 hours agorootparentprevThat's a vast overgeneralization. Sometimes instead of being sociopath the opposite is needed: the so-called emotional intelligence and knowing where the wind blows from so that you can act accordingly. I good example is Mira Murati whom I definitely wouldn't call a sociopath and instead is very flexible in her position, something that would be quite painful for many engineers (at least the ones I know). reply blcknight 9 hours agoprev> In 2013, Peter Hendy, who was then the Commissioner of Transport for London, was accused of engaging in a nine-month extramarital affair with Rachael Grundy, a call girl who charged £140 per hour. Grundy alleged that Hendy provided her with several Oyster cards loaded with £10 as gifts https://en.m.wikipedia.org/wiki/Peter_Hendy reply rwmj 8 hours agoparentThe author name that added this section is interesting too. Way to get your own back ... https://en.wikipedia.org/w/index.php?title=Peter_Hendy&diff=... reply smcl 8 hours agorootparentHope that doesn't come back to bite him, I'm sure if he mentioned it in one of his streams any one of us in the community would've happily updated the page. reply janice1999 8 hours agoparentprevHis brother's a Baron. Of course this class fails upwards. Only the poor plebs will pay the price while those in power award each other CBEs and ignore warnings from the working class about impending disaster. See also the post office injustice and the Grenfell Tower fire. reply DoctorOetker 7 hours agorootparentCheck out \"The Fool\" (2014): https://www.imdb.com/title/tt3560686/ reply janice1999 5 hours agorootparentThanks, I'll check it out. One of my friends and his brothers all left Russia (before the recent war) because of the corruption. The most depressing part of his stories is how apathetic most people are and how there is so little hope for change there. reply mschuster91 8 hours agoparentprevLol, there's even more classy things about him on there: > During 2014, Hendy reportedly spent over £1,200 in taxpayer-provided money on lunches and dinners, including on one occasion more than £90 in alcohol. And that despite a 650k salary - as if he couldn't afford to get wasted on his own. What a disgrace. reply morsch 8 hours agorootparentOtoh regular public sector employees (from what I hear) don't even get free coffee at the office. reply hermitcrab 6 hours agorootparentprevAnd us plebs are still massively subsiding the food and drink of UK MPs and Lords. As well as paying their rent and loads of other expenses, on top of a pretty decent salary. Why should they get drunk at tax payers expense? Funny how austerity always affects the poorest, but doesn't touch the politicians. reply blitzar 7 hours agorootparentprev£90 won't get you wasted in a restaurant in London. reply insane_dreamer 9 minutes agoprevAs a general rule, don't talk to the media -- there's little upside and a lot of potential downside. reply alexchamberlain 9 hours agoprevAs long as it's done in the right way, I think a supplier raising safety concerns should be a reason to do _more_ business with them, not less. reply blcknight 9 hours agoparentThere’s rarely a “right” way to whistleblow. Most of the official channels in any bureaucracy exist to both sound nice and simultaneously sweep everything under the rug reply acdha 6 hours agorootparentYes: it takes an extraordinary amount of cultural back-pressure to counter out the tendency to protect the organizational hierarchy. This can be slightly better in the public sector when laws require disclosure but it's usually still too easy to obscure matters or, especially, rely on complex organizational structures and outsourcing to diffuse responsibility to the point that it’s hard to hold any one person accountable. reply crimsoneer 9 hours agoparentprevIt's notable here that he didn't engage as a representative of the company, but more as an \"engineering writer\", probably after the newspaper reached out for comment. But yes, not exactly a fan of people this senior sticking their nose in misconduct matters, but also, if you're employed by a company, you probably shouldn't badmouth their clients in the national papers and not be aware that's risky. It's not exactly whistleblowing. reply etiennebausson 8 hours agorootparentRaising safety issues is part of a senior engineer's duties (or any engineer, really). Since railways through Europe are a state monopoly, it's not like there are tons of people in the industry that do not work for said 'client'. Who is supposed to pull the alarm in this case? No One? That's how you end up with Boeing-adjacent engineering. reply pjc50 8 hours agorootparent> railways through Europe are a state monopoly The situation is much more stupid than that: there's a set of \"private\" companies, some of which are substantially owned by states and some are not, all of which are quasi-monopolies. reply londons_explore 9 hours agoparentprevSounds like it was done via the media, not the correct internal channels. reply Pingk 9 hours agorootparentMaybe, but it was already public knowledge: > In September 2023 the government regulator, the Office of Rail and Road (ORR), had issued an improvement notice to Network Rail about overcrowding at the station, warning: “You have failed to implement, so far as reasonably practicable, effective measures to prevent risks to health and safety of passengers (and other persons at the station) during passenger surges and overcrowding events at London Euston Station.” It's concerning to me that Hendy was the chair of Network Rail from 2015 before becoming Transport Minister, and here he is sacking someone after a comment about his former workplace. Should definitely be an investigation into his motives/incentives IMO reply londons_explore 9 hours agorootparent\"public\" via a set of documents hidden deep on an official webpage is very different to \"public\" as a news headline. reply Doctor_Fegg 8 hours agorootparentHere's the news headline from the time for you: https://news.sky.com/story/network-rail-failing-to-stop-unac... reply rcxdude 9 hours agorootparentprevBut it is presumably the \"Correct internal channels\"? reply pastage 8 hours agorootparentprevI wonder if there are still overcrowding at that station, or if it really was fixed in 2023. A bit of a Streisand effect going on here. reply luke-stanley 6 hours agorootparentWell, when I was in Euston rail station a few weeks ago, it was very overcrowded. It seemed worse in the day than the night. Seems like the minister is missing the necessity of acting with integrity and transparency, a lesson they frequently need reminding of. Surely there must be better person the PM could find for the job, that don't feel a need write harassing letters, bullying train companies into firing staff? reply dathinab 9 hours agorootparentprevbut do \"correct internal channels\" exist, are accessible by the people people in raising concerns (especially potentially anonymously) and are not ignored? because most times they aren't really usable if they even exist and raising concerns on such channels can often get you in as much trouble as doing so publicly -- but without you concerns being pretty much guaranteed ignored reply lawn 9 hours agorootparentprevThat's usually the only option when nobody listens. reply penguin_booze 21 minutes agoprevI'm surprised (or should I?) that this wasn't picked up by the BBC - at least didn't show up on my feeds. reply Kydlaw 9 hours agoprevI personally find this information frightening... we are now in a world where management no longer even listens to its engineers or technical experts when they warn of serious dangers. Obviously everyone thinks of Boeing, and today it's “only” a train station, but imagine if the same culture developed in an industrial chemical plant or a nuclear power station? Where do you go? What do you do? Unless you have an Engineer Association or an Union to back you up, you are doomed to be crushed by your upper management and beyond... reply blcknight 8 hours agoprevThe engineer has a lengthy thread on Twitter https://x.com/GarethDennis/status/1829036280996315637 reply ZeroGravitas 6 hours agoparentAnd mastodon: https://mas.to/@GarethDennis/113043981557507889 reply arder 6 hours agoprevThis really sets the government up for failure. The next time there's a tragedy on our rail system the question I'm going to ask is \"Would this have happened if the person in charge took safety concerns seriously\". This just makes Hendy's position totally untenable. reply percevalve 8 hours agoprevAm I correct to say the sacked engineer has a regular show on Youtube ? https://www.youtube.com/@GarethDennisTV reply smcl 8 hours agoparentYou are correct, he's also been a guest on \"Well There's Your Problem\" (an engineering disasters podcast/channel) and TRASHFUTURE (UK tech/politics podcast) a few times. reply gchadwick 8 hours agoprevWorth noting the story here has subtly that the headline cannot accurately capture. For one I wouldn't say this is about raising safety concerns or whistle-blowing, it's about how the employer views employees talking to the media. The engineer in question was sacked for stating 'You’re talking about thousands of people squished into that space. It’s not just uncomfortable, it’s not just unpleasant, it’s unsafe.' in a media interview (see https://www.independent.co.uk/life-style/euston-trains-stati... looks like the unsafe part of that quote made the headline). Here he was just amplifying already public information that the Office of Rail and Road had raised concerns and issued an improvement notice (which is reference in the article before he is quoted). I guess they hadn't actually declared it 'unsafe' though. I think it is reasonable for employers to require employees don't go making negative comments in the media, though that is tempered by the public interest in raising the profile of safety concerns. Perhaps here the engineer felt no-one was taking the improvement notice seriously and needed more incentive to do so? Could also be he felt he wasn't trying to cause any upset at all and was simply stating what was already public known. It does feel here that the minister that triggered the sacking was just being thin-skinned. He saw a newspaper headline that angered him and sought to take it out on someone. Perhaps some disciplinary action was warranted (maybe improvements were indeed underway and the engineer shouldn't go causing extra needless public alarm) but sacking him looks to be a big overreaction. reply smcl 8 hours agoparentIn this case it's a little more than just an employer/employee relationship. It's the head of a non-departmental government body (at the time Hendy lead Network Rail, he's now Minister for Transport) threatening to not award contracts to a railway services provider unless they terminate an employee who voiced safety concerns publicly. Notably these concerns were shared by the Office of Rail and Road (i.e. ... the government). reply XCabbage 2 hours agorootparentA \"non-departmental government body\" - more usually known in the press as a \"quango\" or \"quasi-autonomous non-government body\", because we cannot make up our mind in the UK about what things are part of the \"government\" and which are not. :) reply b800h 7 hours agoparentprevThe other point worth raising is that the employee has stated on Twitter that he had a media agreement with his employer that allowed him to speak independently (presumably because he runs a YouTube channel, as per the comments elsewhere on this thread). reply red_admiral 4 hours agoprevThis is what we got the last time safety culture in UK railways was in a serious mess: https://en.wikipedia.org/wiki/Ladbroke_Grove_rail_crash Some in the industry think the next such accident isn't too far off. Stampedes at Euston are a manageable problem by comparison. reply stuaxo 8 hours agoprevStarmers promise of very similar policies to the Tories, but operated more competently playing out. On the other hand he doesn't handle bad press well, let's see how this goes. reply smcl 7 hours agoparentThis occurred before Labour took office - Hendy was the chair of Network Rail at the time. However as Starmer appointed him Transport Minister it'll be interesting to see what he does. I think it'll just be swept aside and ignored because they're too focussed on Austerity 2.0 reply rsynnott 7 hours agorootparentHonestly I’d expect they just fire Hendy; only in the job a month, so low cost of replacement, and it’s a bad look. reply smcl 7 hours agorootparentYou'd hope so but Starmer's a bit weird - seems to want to look like he's in charge (suspending the seven who voted against the government on the 2 child cap) so it wouldn't surprise me if he tries to brush it off and do nothing. The papers are largely all still with him and I haven't seen this story getting picked up outside Politico so it's possible they'll just agree to spike it and move on :-/ reply keyshapegeo99 6 hours agorootparentGuardian are reporting on it now, so it's slowly trickling out. reply smcl 6 hours agorootparentYeah I just saw now, that's good. reply mjburgess 5 hours agoprevOne of the reasons I'm against nationalisation, is that when the government contracts out services to the private sector it hold them to a high standard -- and regulates in lots of saftey/etc. conditions. When the gov runs services there's a massive conflict of interest in regulating them properly: its embarrassing for the gov, there's no accountability for profitability/sustainable-use-of-resources/etc. So whilst centrist (and center-left on some matters), I'm largely in favour of a gov which runs via contracted services with significant regulation and oversight. Lots of cover-up stories have come out recently which show that political control over key services undermines their accountability, not improves it. reply h1fra 5 hours agoparentYou are not from Britain (or Europe), no? Privatisation of the rail in UK is a nightmare, the government is not holding the private sector to a high standard at all. High profit and High standard are barely compatible, I'm not sure they are even good examples in the world. reply tim333 4 hours agorootparentI'm a Brit and would say the privatised rail works ok. The main gripe is it can be overpriced. If you look at the Wikipedia on it, rail use dropped off under nationalization and then pretty much doubled after it was privatised. https://en.wikipedia.org/wiki/Impact_of_the_privatisation_of... My local line / stations have been hugely upgraded over the period though I'm not sure you can put that down to privatisation. (Thameslink/Kings Cross St Pancras) reply ApolloFortyNine 5 hours agorootparentprevJapan's bullet trains, JR East is private, and the Shinkansen has one of the lowest average delays in the world (literally less than a minute). reply amiga386 5 hours agorootparentThe pressure and bullying to achieve Japan's train promptness sometimes kills hundreds of people, though. https://en.wikipedia.org/wiki/Amagasaki_derailment > Drivers for JR West face financial penalties for lateness as well as being forced into harsh and humiliating retraining programs known as nikkin kyōiku (日勤教育, \"dayshift education\"), which include weeding and grass-cutting duties during the day. The final report officially concluded that the retraining system was one probable cause of the crash. This program consisted of severe verbal abuse, forcing the employees to repent by writing extensive reports. Many experts saw the process of nikkin kyoiku as punishment and psychological torture, not retraining reply ApolloFortyNine 4 hours agorootparentA 19 year old example doesn't seem great, surely things can change in 20 years. Also that derailment was truly caused by surpassing the speed limit, which shouldn't even be possible (even more so today). Enforcing a speed limit by block is trivial. Which it looks like is what they did after. reply mjburgess 5 hours agorootparentprevYes, I'm from the UK. 1. Compare and contrast the privately run phase of rail service with the public version before the early 90s. It was low-use by the public and in a decrepit state. 2. The form privatisation took in the UK kept the most expensive, old, difficult to maintain etc. parts of the rail networks under public control. You saw what happened (HS2) when that public control was actually used to improve the infrastructure. ... We'll have to see what happens when MPs are suddenly setting budgets for rail companies, and whether you think you'll get what you want. I doubt it. reply smcl 5 hours agorootparentWith 1) you're comparing apples to oranges and you're still wrong. The turnaround in rail use in the UK began in the 1980s before the private train operating companies got involved. And if you're referring to the network itself being in \"a decrepit state\" before and now being improved to the point where it can sustain higher capacities ... well you can thank Network Rail for that (note: not a private company). The TOCs are headed for nationalisation anyway, leaving the ROSCOs as the big privatisation \"success\" (in that they've extracted enormous profits while not exactly contributing anything particularly novel). What we saw with HS2 is a large (and frankly completely necessary) engineering project getting fucked around with and repeatedly chopped down until it no longer satisfied its original plan (providing greater capacity for both local and national services by providing a new North-South line that happened to be \"high-speed\") and became exactly what those wielding the axe that killed it accused it of (\"just a way for some to get to London slightly faster\"). reply pjc50 5 hours agorootparentprev> We'll have to see what happens when MPs are suddenly setting budgets for rail companies Good rail outcomes were obviously impossible under a Tory government regardless of how the control worked, but they might be possible under a Labour government. We'll have to see. reply youngtaff 3 hours agorootparentprevIn the 70's and 80's the train system was deliberately underfunded and rundown so it's no wonder it got worse during that time reply nayroclade 5 hours agoparentprevThe current state of the UK water industry doesn't seem to support this theory. Privatisation has only lead to water companies like Thames Water taking on unsustainable debt while paying out billions in dividends, underinvesting in infrastructure, and polluting like crazy. Now they are demanding permission from the regulator to massively hike prices, because the foreign investment funds that own them are apparently unwilling to countenance the idea of losing any money on their investments. Infrastructure like public transport and utilities are not, and never will be, functional markets, and regulation is always captured or ineffective in the long term. Privatisation is only a method to let financial markets pillage public goods. reply mjburgess 5 hours agorootparentSure, I believe these dividend policies used to be illegal. I would certainly make it illegal to do share buybacks, and to issue dividends on credit. Privitisation doesnt really work with the private equity model that has been developed over the last decade, ie., buy a biz on credit and raid its resources. But i think it's easier to get these laws passed than require a politican investigate resource waste, bad service, etc. in services they are responsible for. The UK gov is structured to disable accountability at every level -- that's a much harder fix. reply phatfish 5 hours agoparentprevThe private sector pumps sewage into UK rivers while paying billions in dividends to their global investors. Then when the government tries to reign them back in the excuse is their company is \"neither financeable nor investible\" without customers footing the bill. No shit, it was loaded with debt and money syphoned out of it for 30 years. https://www.theguardian.com/business/article/2024/aug/28/tha... Exactly the same happens with private train companies in the UK, though hopefully not for long. reply mjburgess 5 hours agorootparentSure, and what would happen if the gov ran the system? It's a 300bn fix. The only difference would be that you wouldnt know about it. Thankfully MPs are incentivised to publish this stuff against private companies. reply smcl 5 hours agorootparentWell \"the gov\" does run the system in Scotland. Scottish Water, which didn't suffer privatisation, ticks over nicely - providing high quality service at low cost and reinvesting any profits. You're inventing a hypothetical nightmare scenario while ignoring a very real and positive one because it's inconvenient for your \"privatisation = good\" argument. reply phatfish 5 hours agorootparentprevHow would the government be able to hide that? There is oversight of the Treasury by the OBR and there is more than one political party in the UK, opposition MPs happily point out all the failures of the party in power. My view is that it is easy to accuse government services of being dysfunctional because there is far MORE transparency than for private companies. Bankrupting a water company can happen in plain sight by a private company because money that was supposed to be used to, you know, build a functioning sewage system is fed through a maze of offshore accounts for years. reply pjc50 5 hours agoparentprev> when the government contracts out services to the private sector it hold them to a high standard PPE Medpro? The fundamental problem with this kind of neoliberalism is that if you don't trust government to manage something directly, then outsourcing it doesn't help, because the management oversight still has to be done, but now it happens indirectly. It only works if you can have an actual market with actual market forces. What tends to get built is a \"fake\" market, where instead of individual service users picking their preference you get a tendering process. The rail tendering process is a fake market: the trains are owned by ROSCOs (banks), the rails are owned by the state (Network rail) because the private operator skimped on safety then collapsed, and the TOCs transfer all their staff through TUPE every time the franchise changes. All that changes is the livery. Specifying through contract is a lot less efficient than direct management (see Coase, theory of the firm). This is why Tube privatization failed; they got up to hundreds of thousands of pages of contract before realizing it wasn't going to work. reply beeboobaa3 5 hours agoparentprevbritish rail is privately owned. this seems to undermine your whole argument. reply smcl 5 hours agorootparentBritish Rail has ceased to exist for quite some time reply XCabbage 4 hours agorootparentprevNot really true. National Rail, which owns the tracks is a quango, not a private company. The actual train operators are truly privately owned but it is important to understand that they are not privately making any major strategic decisions about the network, just maintaining the rolling stock and providing staff; their routes, times, prices, and profits are mostly set by the state (with some narrow room for discretion) and not by the private sector. reply jl6 8 hours agoprevOut of interest, what would the right resolution have been to reduce the risk of a crush due to overcrowding? Close the station entrance when at capacity? reply pjc50 8 hours agoparentLondon Underground does close access to platforms when they are at capacity. The station itself is probably running the maximum number of trains possible. The plan for increasing throughput northwards is HS2, which the previous government put on hold. reply rwmj 8 hours agoparentprevThey do close the station entrance at Euston with some regularity when trains are not running (which happens annoyingly often because of the parlous state of the railways). reply waiwai933 8 hours agoparentprevMy understanding is that the crush risk at Euston is entirely an operational issue of Network Rail's making (NR being the station facility owner), by deliberately not announcing platforms until the last moment, causing passengers to run to the platform en masse. If platforms were announced earlier, the crush risk would be seriously mitigated. The obvious next question is whether platforms _can_ be announced earlier - to which the answer is, as I understand it, yes. The platforms are known about much further in advance and the reason for the delay appears to be a combination of intransigence by Euston management and a lack of sufficient ticket gateline staff by the train operators. reply lupusreal 8 hours agoparentprevRun more trains so the station never reaches capacity. Or expand the station. reply michaelt 8 hours agorootparent> Or expand the station. According to [1] nineteen national rail trains will depart from Euston in the next hour. And according to [2] Euston has 16 platforms. Can a station platform really only dispatch 1.2 trains per hour? Fifty minutes per train? Seems kinda low to me. I guess they need time to clean the trains, and space for trains that arrive well before their scheduled departure time. But still, it seems like a lot of platforms for the number of trains. [1] https://www.nationalrail.co.uk/live-trains/departures/london... [2] https://www.networkrail.co.uk/wp-content/uploads/2020/10/Eus... reply smcl 7 hours agorootparentPlatforms != distinct rail lines. Now, if only there were plans to run a new national, let's say high speed, rail link from the North of England into Euston which would improve this capacity ... reply shaoonb 7 hours agorootparentprevThe capacity limit is the number of tracks. There are 4 AC and 2 DC tracks on the line out of Euston and they are also used for freight trains as well as the Bakerloo line. reply blitzar 7 hours agorootparentprevHeathrow has 115 gates but only does 50 departures an hour. reply stuaxo 8 hours agorootparentprevNot sure there is more capacity for trains there. reply smcl 8 hours agorootparentThere were plans to expand Euston, then the Tories cancelled those plans and sold off the land that was acquired to accommodate said plans to make sure it wouldn't ever happen in the future (by this point they were already collapsing in popularity and clearly going to lose the election). reply HenryBemis 8 hours agorootparentprevBoth solutions would take months/years to implement. \"More trains\" mean they need to radically improve service/repairs and/or purchase of new trains. \"Expand the station\" would mean that they would have to shut down all-of or large-parts of it while works take place. I remember being impacted of the London Bridge train station de-spaghetti-fying the tracks. I moved out of the area I was living so eventually I was impacted for only 4-5 months. I will not touch the matter of costs. reply stuaxo 8 hours agorootparentLondon bridge tracks untangled is so much better for throughput - I remember so many long waits as a Brighton train blocked the whole station crossing the tracks. One surprising good thing the gov did at that time was insist on the rebuild of the station itself, it was particularly grim, and just a mess. I've lived nearby the whole time and the new station is a nice space, generally efficient with good throughput for the trains. I'm pessimistic, but really hoping they don't stick with plans to build a too small terminus in London for HS1, not too optimistic as we have Rachael Reeves as a continuity austerity Chancellor - lets see. reply smcl 7 hours agorootparent> plans to build a too small terminus in London for HS1 You're talking about HS2 and Old Oak Common, right? Yeah that's a peculiar choice of terminus reply lupusreal 8 hours agorootparentprevNobody said all problems have cheap solutions. reply boomskats 6 hours agoprevWould anyone care to speculate how something like this would potentially play out in another Western European country? If all the abuse of power and overstepping/targeting was unchallenged public knowledge, would there be more of a reaction? reply Havoc 6 hours agoprevPolitics seems to attract the worst type of people reply flanked-evergl 4 hours agoprevUK seems like one of the absolute worst places in the world to live. Why are there not more people moving out of the UK? Do they still think it can get better? reply tim333 4 hours agoparentIt's a bit like that quote about democracy - it's the worst place apart from all the other ones. Not where really is perfect. The population keeps going up here with people immigrating for what it's worth although we've had quite a lot of millionaires leaving and African asylum seekers arriving on dinghies which is perhaps not ideal. reply flanked-evergl 4 hours agorootparent> It's a bit like that quote about democracy - it's the worst place apart from all the other ones. No, it's way worse than most of the others. Anywhere in the Anglosphere or other parts of Europe is better. Most of Asia is better. Most of South America is better. Even some African countries are probably better. I would definitely move to Uganda, Botswana or South Africa before I ever set foot in the UK. > The population keeps going up here If you promise anyone who arrives at your shore free healthcare, accommodation, food and some spending money, then of course your population will go up. Not sure how that makes anything better. reply tim333 3 hours agorootparentI guess worse is in the eye of the beholder but on the \"List of countries by Human Development Index\" we're #15, ahead of the US (#20). https://en.wikipedia.org/wiki/List_of_countries_by_Human_Dev... Dunno. Are you a Brit? Think of moving anywhere? reply badpun 3 hours agoparentprevI’d say uk is probably in top10-top20 places in the world to live. reply anentropic 4 hours agoprevThis Hendy guy sounds like a classic shit manager, only concerned with saving face reply XCabbage 2 hours agoprev [–] Obviously, the retaliation is bad. Should disqualify Lord Hendy from his role. But I would also like to make sense of what the actual risk alleged to exist in Euston is, and how Gareth Dennis or the ORR inspector thinks it should be mitigated. And I cannot figure it out, at all. In Dennis's comments quoted in The Independent, for which he was fired, he attributes the risks at the station to the increased number of trains coming in and out of the station. That seems to imply that the crush or trample risk he perceives to exist is in the main lobby area of the station, not on the platforms or the ramps leading down to the platform gates, since if it were the latter then the risk would exist regardless of the number of trains coming in and out of the station. This seemed surprising/implausible to me because all the dense crowds I've ever seen (and felt concerned about) in Euston have been on the ramps or the platforms, NOT in the lobby area which is massive. I struggle to imagine how a crush or stampede could ever happen anywhere besides the ramps and platforms. So I dug a bit further. The press release associated with the improvement notice (https://www.orr.gov.uk/search-news/rail-regulator-requires-c...), on the other hand, says that over summer 2023, there were three instances of \"crowding reaching unacceptable levels and a lack of crowd control in place\" resulting in \"minor injuries\" with potential for worse. They also complain of a lack of risk assessments for two unspecified \"pinch points\" in the station \"where crowding is most concentrated\", inadequate \"control measures\", and unacceptably poor \"layout\" and \"signage\" to help with flow control. The actual improvement notice, meanwhile, contains essentially no detail (https://orrprdpubreg1.blob.core.windows.net/docs/I-NWM-20230...), just some fairly meaningless boilerplate. The entire explanation of the problem is \"You have failed to implement, so far as is reasonably practicable, effective measures to prevent risks to health and safety of passengers (and other persons at the station) during passenger surges and overcrowding events at London Euston Station\" and the remedy demanded is that the station needs to do a risk assessment and then implement whatever measures they come up with in the risk assessment. My best guess at what this is all about, possibly completely wrong, is as follows: * the two \"pinch points\" are two of the ramps, probably the one leading down to platforms 8/9/10/11 and the one leading down to platforms 12/13/14/15, which in my personal experience of the station are where most of the big surges happen * the injuries happened due to crowds running down the ramps to the platforms once the platform number for their train got announced, either to beat other passengers to the seats or out of fear that they would not get on a late-arriving train before it departed at all * the risk assessment concluded that the station should put up signs telling people not to run, and then they did that (I can't find any reporting about it, but if my memory serves me right, then those signs on the ramps at Euston appeared late last year which fits with the timeline) So, IF I'm guessing correctly, there's probably a real stampede risk, with minor examples having already played out, but it's totally unrelated to the number of trains or the crowding in the lobby, the fired \"whistleblower\" is basically full of shit for suggesting a problem stemming from a larger number of trains, and the supposed \"fix\" is also meaningless compliance bullshit that will have no effect. Of course, again, I could be guessing totally wrong; there isn't enough detail in the public documents or reporting for us to tell. So I publicly asked Gareth, the guy who got fired, to explain his concerns in more detail or point me to somewhere with detail. He... responded with indignation and contempt, pointed me to the Improvement Notice for one reason (the document with no detail about the problems, just a one sentence description that is probably copied and pasted boilerplate and makes no reference to any of the specific circumstances at Euston), then suggested I was mentally unwell in some way and blocked me. What a dickhead. Here's the end of the thread; I'd be grateful if someone not blocked by Gareth would stick it into Threadreader and post a link here so people not on X can read it: https://x.com/GarethDennis/status/1829179489043226778 I find it hard to fathom why someone sincerely concerned with safety would behave in this way - making unactionably vague complaints that a station is unsafe, then refusing to elaborate and lashing out at anyone interested in the detail for daring to question him. After the displeasure of interacting with the guy, it seems to me that this story has no heroes. But still, no matter how much of a dick he is or how useless his criticism was, it doesn't justify the firing. If you want a culture in which people feel safe speaking up about concerns, you have to indulge even stupid and incoherent concerns made by dicks; if you don't, everybody with something substantive to say will quite reasonably fear they will be viewed and treated in the same way you treated the dick. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "UK rail minister Peter Hendy influenced the dismissal of engineer Gareth Dennis for raising safety concerns about overcrowding at London’s Euston station.",
      "Hendy threatened to withhold public contracts from Dennis's employer, SYSTRA, and urged disciplinary action, leading to Dennis's dismissal after he refused a financial settlement with a confidentiality clause.",
      "Dennis's warnings to the media about safety risks were in line with concerns from the official rail regulator, despite Network Rail addressing these concerns."
    ],
    "commentSummary": [
      "UK rail minister allegedly got an engineer, Gareth Dennis, fired for raising safety concerns, despite his criticisms being relatively mild.",
      "The UK rail network is known for extensive safety measures, including numerous signs and announcements, which some find excessive and patronizing.",
      "The incident highlights ongoing issues with safety and management practices at major UK rail stations, particularly Euston, which has been criticized for overcrowding and last-minute platform announcements."
    ],
    "points": 424,
    "commentCount": 215,
    "retryCount": 0,
    "time": 1724923176
  },
  {
    "id": 41386667,
    "title": "HDMI Forum rejects AMD's HDMI 2.1 open-source driver",
    "originLink": "https://www.tomshardware.com/pc-components/gpus/hdmi-forum-rejects-amds-hdmi-21-open-source-driver",
    "originBody": "PC Components GPUs HDMI Forum rejects AMD's HDMI 2.1 open-source driver News By Anton Shilov published 29 February 2024 No 4K@120Hz and 5K@240Hz via HDMI 2.1 for Linux users with Radeon. Comments (71) When you purchase through links on our site, we may earn an affiliate commission. Here’s how it works. (Image credit: Shutterstock) AMD's open-source Linux graphics driver has hit a roadblock in adding HDMI 2.1+ due to the HDMI Forum's legal requirements. Despite lengthy attempts to find a solution, the HDMI Forum has rejected AMD's proposal, leaving users of some of the best graphics cards without the ability to use advanced features like 4K@120Hz and 5K@240Hz via HDMI 2.1. As a result, AMD recommends Linux users to switch to DisplayPort instead. \"The HDMI Forum has rejected our proposal unfortunately\" said AMD Linux engineer Alex Deucher in a statement published in the bug report. \"At this time an open source HDMI 2.1 implementation is not possible without running afoul of the HDMI Forum requirements.\" For three years, AMD has been grappling with a bug report indicating the absence of 4K@120Hz and 5K @ 240Hz support through HDMI 2.1for Linux users. This occurred because in 2021 the HDMI Forum restricted public access to its specifications. This move was to ensure that only authorized manufacturers and developers can access the technical details required to implement HDMI features in their products (and pay royalties to developers of respective technologies). On the one hand, this move ensures the quality and consistency of HDMI experience. But on the other hand, this greatly hindered open-source driver support. In response, AMD and the X.Org Foundation engaged with the HDMI Forum to devise a solution that would allow open-source implementations of the now-private HDMI specifications. AMD's Linux engineers, in collaboration with the company's legal team, dedicated months to evaluating all of the HDMI features to determine if they could be exposed in the open-source Radeon driver. They have reportedly developed internal code and awaited approval from the HDMI Forum. Unfortunately, the HDMI Forum ultimately denied AMD's request for open-source driver support. The rejection is especially frustrating considering the months AMD spent engineering and prototyping code for HDMI 2.1+ features within its internal open-source AMDGPU codebase, notes Phoronix. This effort, aimed at showcasing HDMI 2.1+ capabilities for review by the HDMI Forum, now appears to be a largely wasted investment of significant resources. In light of these challenges, AMD may need to explore alternative solutions, such as incorporating more features into its closed-source firmware or utilizing their PSP IP block to protect certain aspects of the HDMI specification. However, for the time being, the lack of HDMI 2.1+ feature support in open-source drivers remains reality. Consequently, open-source supporters are advised to use DisplayPort for the best experience. Stay On the Cutting Edge: Get the Tom's Hardware Newsletter Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors By submitting your information you agree to the Terms & Conditions and Privacy Policy and are aged 16 or over. Anton Shilov Contributing Writer Anton Shilov is a contributing writer at Tom’s Hardware. Over the past couple of decades, he has covered everything from CPUs and GPUs to supercomputers and from modern process technologies and latest fab tools to high-tech industry trends. SEE MORE GPUS NEWS MORE ABOUT GPUS TinyBox AI accelerator now available starting at $15k, available in AMD 7900XTX and Nvidia RTX 4090 variants AMD Radeon RX 8000 GPU emerges in Geekbench benchmarks — Navi 48 GPU with 56 RDNA 4 CUs at 2.1 GHz and 16GB VRAM LATEST Best Tech and PC Hardware Deals SEE MORE LATEST ► TOPICS HDMI SEE ALL COMMENTS (71) 71 Comments Comment from the forums ThomasKinsley I anticipate a lone wayward AMD engineer will 'leak' the driver, against all orders from AMD, of course, and anonymously so they cannot find out who it was. Reply snemarch Yet another reason to abolish HDMI and only purchase DisplayPort-capable hardware. Greedy royalty rent-seekers and Digital Restrictions Management supporters should be shipped off to Siberia. Reply ezst036 This is one of those things that through-no-fault-of-their-own advertently or inadvertently ends up holding back open source. *Boots to black screen* \"Well it works on Windows, so I don't want to use Linux. None of this junk works.\" \"But works just fine on Windows or my Mac\" Yes, but it's not that the driver makers could not figure out how to do it, didn't have the time to do it, etc etc. \"Well, it doesn't work.\" &%@##! It's the continual fight against both the chicken and the egg at the same time. AMD are trying to \"do the right thing\" here. HDMI forum are plain and simply saboteurs. The industry is fraught with them from this standpoint. Reply Zaranthos ezst036 said: This is one of those things that through-no-fault-of-their-own advertently or inadvertently ends up holding back open source. *Boots to black screen* \"Well it works on Windows, so I don't want to use Linux. None of this junk works.\" \"But works just fine on Windows or my Mac\" Yes, but it's not that the driver makers could not figure out how to do it, didn't have the time to do it, etc etc. \"Well, it doesn't work.\" &%@##! It's the continual fight against both the chicken and the egg at the same time. AMD are trying to \"do the right thing\" here. HDMI forum are plain and simply saboteurs. The industry is fraught with them from this standpoint. True. On the bright side at least some companies are trying now. I read articles like this and make a mental note, go display port for all hardware and stay away from HDMI whenever possible. It only hurts the HDMI spec in the long run, but there is collateral damage to open source along the way like you said. I also watch and see AMD putting in real $ and effort to support open source so I'll buy their products as well. This from someone who barely uses Linux but still wants the option to. Reply kanewolf So, AMD pays fees for their Windows driver, but won't pay fees for the open source? Probably not the case. OR was their open source driver rejected because it gave away too many of the proprietary details that AMD had reverse engineered ? My guess is the latter. Reply setx kanewolf said: was their open source driver rejected because it gave away too many of the proprietary details that AMD had reverse engineered ? AMD bought the license, they didn't reverse-engineering anything. But they can't publish the code because it would \"leak information\" on that proprietary garbage. Reply thisisaname HDMI is dead long live Display Port! Reply kanewolf setx said: AMD bought the license, they didn't reverse-engineering anything. But they can't publish the code because it would \"leak information\" on that proprietary garbage. Just like other \"open source\" drivers, there are some parts that are only released as compiled binaries. WIFI radio drivers are this way to comply with the FCC, for example. Reply Order 66 thisisaname said: HDMI is dead long live Display Port! It's a shame that TVs don't use DisplayPort though. If you want to use a tv as a monitor, you have to use HDMI. Reply Joseph_138 ThomasKinsley said: I anticipate a lone wayward AMD engineer will 'leak' the driver, against all orders from AMD, of course, and anonymously so they cannot find out who it was. AMD would still be held responsible for the leak, and be sued. They have a duty to lock down the driver, now that they've been told not to release it, and failure in that duty will result in a lawsuit, even if a lone employee takes it on themselves to release it, anyway. Reply VIEW ALL 71 COMMENTS Show more comments",
    "commentLink": "https://news.ycombinator.com/item?id=41386667",
    "commentBody": "HDMI Forum rejects AMD's HDMI 2.1 open-source driver (tomshardware.com)283 points by FleetAdmiralJa 16 hours agohidepastfavorite150 comments broodbucket 14 hours ago>On the one hand, this move ensures the quality and consistency of HDMI experience. Does it though? Does it really? I don't understand this move from HDMI Forum. They're handing a win to DisplayPort. reply kelnos 13 hours agoparent> Does it though? Does it really? Of course not. It's just protectionism and rent-seeking. > I don't understand this move from HDMI Forum. They're handing a win to DisplayPort. I don't think so, at least at this point. Most people don't have hardware that requires HDMI 2.1 in order to get full use out of them, and of those who do, not all of them use Linux and/or care about open source drivers. Sure, that situation may change, and the HDMI Forum may walk back these requirements. At any rate, for some reason DisplayPort has just not caught on all that much. You very rarely see them on TVs, and a good number of mid-/lower-end monitors don't have them either. It's bizarre, really. reply arghwhat 10 hours agorootparent> At any rate, for some reason DisplayPort has just not caught on all that much. DisplayPort won everything, except not becoming the physical connector for home cinema. Heck, even within those HDMI-exposing devices, DP won. The vast majority of display drivers speak eDP. Few things actually implement HDMI, and instead rely on DisplayPort to HDMI converters - that's true whether you're looking at a Nintendo Switch or your laptop. Heck, there is no support for HDMI over USB-C - every USB-C to HDMI cable/adapter embeds a HDMI converter chip, as HDMI altmode was abandoned early on. The only devices I know of with \"native\" HDMI are the specialized TV and AV receiver SoCs. The rest is DP because no one cares about HDMI. However, seeing that home cinema is pretty much purely an enthusiast thing these days (the casual user won't plug anything into their smart TV), I wonder if there's a chance of salvation here. The only real thing holding onto DisplayPort is eARC and some minor CEC features for AV receiver/soundbar use. Introducing some dedicated audio port would not only be a huge upgrade (some successor to toslink with more bandwidth and remote control support), but would also remove the pressure to use HDMI. With that out of the way, the strongest market force there is - profitability - would automatically drive DisplayPort adoption in home cinema, as manufacturers could save not only converter chips, but HDMI royalties too. reply superhuzza 8 hours agorootparent>home cinema is pretty much purely an enthusiast thing these days (the casual user won't plug anything into their smart TV) Except a gaming console, a laptop, a roku, apple TV... Every single person I know has some external media source plugged into their TV, even my tech illiterate mother. reply arghwhat 7 hours agorootparentYou’d be surprised by the number of users who are satisfied with the built-in media experience. I’d say it’s most likely a large majority. Google TV is common, but people with an Android-powered TV are not the main target for those until the TV gets old and out of date. Apple users on Samsung TV’s might also get far with the built in AirPlay support. Heck, even within enthusiasts there is a strong push to use the built-in media features as it often handles content better (avoiding mode changes, better frame pacing). Even I only use an external box after being forced due to issues when relying on eARC. Very few people plug in their laptop to a TV, and laptops are not normally HDMI. Some laptops have a dedicated port with a built-in converter, but all modern laptops are USB-C which only exposes DisplayPort. reply treis 6 hours agorootparentI'm in this crowd. The TV apps work well enough and it's one less remote. The only thing I use the attached Chromecast for is to (rarely) mirror my phone screen. reply pjc50 10 hours agorootparentprev> Introducing some dedicated audio port would not only be a huge upgrade I'm not sure about that - suddenly there's a cost in board space and BOM, and they're not automatically linked together. Or do you just mean for audio output from TV to soundbar? I feel like USB would suffice for that if anyone could be bothered. Personally I use regular TOSLINK to a stereo amplifier and accept having another remote. reply arghwhat 7 hours agorootparentHeh, good point, USB 2.0 would absolutely suffice. You'd hardly need more than a standard audio profile either. Some TVs even support this already - recent Samsung models at least. A specialized port could theoretically have a lower BOM cost through simpler silicon or port design, but USB 2.0 is free at this point so why bother. > Personally I use regular TOSLINK to a stereo amplifier and accept having another remote. The problem with TOSLINK is not only the remote scenario (which I do think is absolutely a necessary feature for any kind of adoption), but also lack of bandwidth for uncompressed surround sound. Large surround setups at home are uncommon these days, but soundbars with virtual surround is common, and some of us still manage to squeeze in a simple 5.1 setup. reply dathinab 7 hours agorootparentprev> The only real thing holding onto DisplayPort is eARC and some minor CEC features for AV receiver/soundbar use. Introducing some dedicated audio port would not only be a huge upgrade (some successor to toslink with more bandwidth and remote control support), but would also remove the pressure to use HDMI. USB-C I mean think about it USB-C/DP alternative mode is good enough as upstream for most use cases (including consoles)and has some additional future feature potential, and still has some USB bandwidth left usable for various things including CEC for eARC-like use-cases (i.e. sometimes audio+video upstream, sometimes audio downstream) you have a few choices (one needs to be standardized): - always create a DP alt mod channel upstream, use audio over USB for downstream, technically that already can work today but getting audio latency synchronization and similar right might require some more work - switch the DP alt mode connection direction or have some audio only alt mode, which either requires a extension of the DP alt mode standard, or a reconnect. But I think the first solution is just fine as an added benefit stuff like sharing input devices became easier and things like Roku TV sticks can safe on some royalties ... which is part of where the issue is there is a huge overlap between big TV makers and HDMI share holders, I mean have you ever wondered why most TVs don't even have a single DP port even through that would be trivial to add? which is also why I think there is no eARC like standard for USB-C/DP alt mode, it only matters for TVs and TVs don't have DP support honestly I believe the only reasons why TVs haven't (very slowly) started to migrate to USB-C/DP alt mode is that most of their producers make money with HDMI and lastly there is some trend to PCIe everything in both consumer and server hardware. In the consumer segment it had been somewhat limited to the \"luxury\" segment, i.e. Thunderbolt. But with USB4 it slowly ends up in more and more places. So who knows PCIe based video might just replace both of them (and go over USB-C) reply arghwhat 5 hours agorootparent> and lastly there is some trend to PCIe everything in both consumer and server hardware. In the consumer segment it had been somewhat limited to the \"luxury\" segment, i.e. Thunderbolt. But with USB4 it slowly ends up in more and more places. So who knows PCIe based video might just replace both of them (and go over USB-C) Thunderbolt/USB4 is not PCIe. It's a transport layer that can run multiple applications at once, sharing bandwidth based on use. This is opposed to USB-C Alternate Mode, where pins are physically reassigned to a specific application, which uses the pins regardless of whether it needs the bandwidth. PCIe is then one of the supported applications running on top of the transport. reply dathinab 5 hours agorootparentI know, but this isn't relevant for the argument, if anything it's in favor of some future protocol replacing HDMI/DP/USB-C+DP alt while using the USB-C connector. reply arghwhat 4 hours agorootparentI was just pointing out specifically that there is no such thing as PCIe-based video - nor is there any need for that. Support for USB4/Thunderbolt DP will proliferate, but there is still benefit to a DP altmode as it's free to implement (the host controller just wires its existing DP input lanes directly to the USB-C connector) and allows for super cheap passive adapters. If USB-C ends up becoming the standard video connector as well, it will most likely be DP altmode as you then only need a cheap USB-C controller to negotiate the mode. There isn't really any pressure to invent a new protocol. https://xkcd.com/927/ reply matja 12 hours agorootparentprev> Most people don't have hardware that requires HDMI 2.1 in order to get full use out of them, and of those who do, not all of them use Linux and/or care about open source drivers. Arguably true, but I think that is changing all the time while there is a push towards open-source drivers regardless of the average user knowing/caring what that is, along with resolutions and refresh rates increasing. I was affected by HDMI Forum's decision by buying an off-the-shelf 4K 120Hz monitor which refused to work at that resolution/refresh rate on an HDMI cable. I was not expecting an arbitrary decision affecting software to be the cause instead of a hardware problem - which took me a while to figure out. Now I know if I want to use my hardware to the full capacity, I need DisplayPort in future. reply Hendrikto 9 hours agorootparent> off-the-shelf 4K 120Hz monitor which refused to work at that resolution/refresh rate on an HDMI cable. I run a 4K 144Hz monitor over HDMI. Are you sure you don‘t just need a better cable? reply matja 8 hours agorootparentMy HDMI cables work at 4k 120Hz with the same monitor with an NVidia card using closed-source drivers, not with AMD open-source drivers, because of the issue in the article. reply Cu3PO42 12 hours agorootparentprev> I don't think so, at least at this point. Most people don't have hardware that requires HDMI 2.1 in order to get full use out of them, and of those who do, not all of them use Linux and/or care about open source drivers. I do, but this hardware doesn't have DisplayPort. I switched from Nvidia to AMD specifically for the open source Linux drivers, so I'm quite mad at the HDMI forum for this. On the other hand, my next TV likely won't have DisplayPort, either, because almost none of them do, so it is indeed questionable whether this is going to loose them any mind share. reply Rinzler89 13 hours agorootparentprev>Of course not. It's just protectionism and rent-seeking. Don't know why you're being downvoted but it's true. Especially when you see that the HDMI standard was developed by the cartel of TV manufacturers and major movie studios[1] when DVI and Display Port already existed but those didn't generate royalties or have DRM. Despicable standard. There wasn't even a standards \"war\" like in VHS vs Betamax, or SD vs MemoryStick, or USB vs Fire Wire, to say that HDMI won over DisplayPort, it was simply shoved down consumers' throats since every TV, media player and games console only shipped with that port alone as they were manufactured by the same cartel that developed the HDMI standard. So much for the so called \"free market\". [1] https://en.wikipedia.org/wiki/HDMI#History reply somat 11 hours agorootparentTo be fair, and note that I think of the hdmi foundation as the bad guys. hdmi was not an alternative to display port, display port did not exist yet. it was an alternative to dvi, really hdmi is dvi with a sound channel and drm. And as much as I dislike the hdmi foundation I can see the benefit here. as to hdmi vs display port... I have no idea why you don't see more display port, VESA has a proven track record as the nicer standards body, display port is a better system. probably just inertia at this point. reply atoav 10 hours agorootparentAs a media tech guy (running the media tech department of a university, which includes a DCI conform cinema): absolutely everybody hates HDMI. It is unreliable as hell, both physically and as a protocol. It tries to be too much to too many people and most devices, including expensive \"pro\" gear includes unchangeable random weirdness like ignoring EDIDs or forcing them onto you, that is documented nowhere and you can only find these things out when you buy it. Add to that the fact that consumers/users can break the picture/sound in 100 different ways on their devices and you get a veritable support nightmare. I wish it was just DVI+ but it does so much more. reply Rinzler89 10 hours agorootparentIsn't this why VGA is still widely used everywhere? It always just works no matter what even when connector or pins are damaged since there's no digital handshake or error correction just a basic analog pipeline. reply atoav 8 hours agorootparentI don't know, at least here (Europe) VGA has pretty much died out in all but legacy applications. The true pro format would be SDI using BNC connectors. But I guess HDMI is going to be replaced by USB-C in the long run. Especially since the \"everything-connector\" also doing Video makes more sense than the video-connector also doing everything. reply paulmd 2 hours agorootparentprev> unchangeable random weirdness like ignoring EDIDs or forcing them onto you, that is documented nowhere and you can only find these things out when you buy it. FWIW: https://www.store.level1techs.com/products/p/5megt2xqmlryafj... Sadly this is not entirely a HDMI-specific problem either, he has a displayport feeder too. Also DisplayPort had many problems with disconnects/sleep state for many years, especially surrounding EUP Compliance/EUP Deep Sleep mode. I wouldn't say DisplayPort monitors were relatively bulletproof until the GSync Compatible generation finally rolled around in 2019-2020. reply cardiffspaceman 1 hour agorootparentprevI used a plasma panel, vintage 2004 (retired in 2016 with no noticeable burnin), that had a DVI connector with HDCP support. If it had not supported HDCP, I could not have connected my cable box to this panel. reply godzillabrennus 11 hours agorootparentprevI think interface change fatigue is real. DisplayPort has been around but there wasn’t a compelling reason to use it when displays had hdmi ports. People are also looking to USB-C as the next iteration in display connectivity because it does “all of the things” from a consumers perspective. reply seba_dos1 8 hours agorootparentAt least video over USB-C is DisplayPort, so there's hope. reply Dalewyn 10 hours agorootparentprevMost people will use the path of least resistance. Many people/organizations still use VGA and ketchup-mustard-onion cables to this day if they still do the job, let alone HDMI. reply account42 10 hours agorootparentShouldn't it be mayo if you are going with a condiment theme? reply Dalewyn 5 hours agorootparentVery fair point and duly noted! reply trilbyglens 12 hours agorootparentprevWorks exactly as a free market is designed to. The strong and coercive win. That's what market dynamics are really about. Monopolies form easily and naturally unless regulation stops them. reply account42 9 hours agorootparentActually these monopolies are enforced by the state via IP laws. Without IP laws any upstart could reverse engineer the protocols and provide an implementation with less limitations. But of course free market enthusiasts like to ignore that part and only rant against the government when it protects consumers from companies. reply roenxi 9 hours agorootparentThere are a huge number of free market types who are against IP laws and they're a big part of computing culture. Names like the FSF [0] spring to mind. A market can't expose a fraction of its potential if people are banned from competing because someone else got there first. The only reason the software world did so well was because the FSF managed that inspired hack of the copyright system known as the GPL that freed up the market, in fact. [0] https://www.fsf.org/ reply rini17 9 hours agorootparentprevYes, if there were no IP anyone could cheaply make a single-digit-nanometer-node custom ASIC to provide the alternative 4K-capable video hardware implementation. /s reply miki123211 7 hours agorootparentAnyone? No, probably not. Some enterprising company in Shenzhen, who would sell the thing for $.25 a piece due to fierce competition driving prices down to cost of materials? Now that's more likely. reply ozfive 8 hours agorootparentprevSingle-digit-nanometer-node custom ASICs aren't really required to achieve this. Although there is higher latency this can and has been done on FPGAs at a company I worked for which designed and built custom AVOD systems for private jets and helicopters. reply drchaos 11 hours agorootparentprevOne could argue that at least this specific tactic would not be possible without the state granting a monopoly on \"intellectual property\". Without that, nothing would hinder AMD from just shipping their already existing implementation. reply hulitu 55 minutes agorootparent> One could argue that at least this specific tactic would not be possible without the state granting a monopoly on \"intellectual property\". Microsoft ? RIAA ? MPAA ? Google (AI, books) reply Certhas 11 hours agorootparentprevThe irreducible state role in a free market is to enforce property rights. Almost all free market fans I have seen think that this should extend to some notion of intellectual property. reply Y_Y 10 hours agorootparentI think the standard answer to your point is that you can recognise \"intellectual property\" without granting a (limited) monopoly. There are plenty of proposals floating around for copyright and patent reform that curtail or replace the ability of the creator/owner to unilaterally set the price and decide who can license the material and how they can use it. reply AstralStorm 8 hours agorootparentThing is, HDMI forum is not a monopoly. It's a literal cartel of a few corporations and other cartels. Other cartels pushing for it include MPAA. reply Y_Y 8 hours agorootparentThe monopoly here is HDMI LA, who provides the required licenses. > HDMI® Licensing Administrator, Inc. (HDMI LA) is the agent appointed by the HDMI Forum to license Version 2.1b of the HDMI Specification and is the agent appointed by the HDMI Founders to license earlier HDMI Specifications. https://hdmi.org/adopter/index See also: https://www.symmetryelectronics.com/blog/what-are-the-licens... reply Certhas 8 hours agorootparentprevMostly I think the person who mentioned that this is free markets working as free markets is largely right. You can't defend free markets on the basis that property rights are enforced by the state, and thus somehow changing the free market outcome. I also think critizising intellectual property on grounds of granting a monopoly is muddling the language. If I write a novel I have exclusive rights to the novel. But I am not the only supplier of mediocre novels. I don't have a monopoly in a relevant market. None of this contradicts the point that IP and patent rights are in desperate need of reform, or that they can play a central role in abusing a monopoly position (e.g. https://en.wikipedia.org/wiki/Orange-Book-Standard). Edit: Maybe my post was unclear: I would agree that IP should be abolished. But this is not a position I have seen classical market liberals and other free market advocates take. Instead, they tend to favor strengthening all forms of property rights. If I am wrong on this point, I'd be happy to read some examples. reply Y_Y 7 hours agorootparentI don't think we disagree, I would just like to add that this subtlety about \"monopoly\" depends on the (subjective) existence of substitute goods. Maybe as a consumer I just want any old book to read and so an individual author has no market control. On the other hand you can imagine, say, a technology that's practically or actually unavoidable as an input for a particular business (suppose HDMI had no viable alternative), then the IP holder could extract super-normal profit and make the economy less efficient. reply obirunda 11 hours agorootparentprevMonopolies form easily? That's funny, you should try and start one, seems quite profitable. Seriously though, this is an oft repeated fallacy, and frankly irrelevant to the discussion. IP laws are the actual culprit in facilitating the apparatus of the state for the creation of monopolies. Most people seem to embrace this double-think that IP laws are good while monopolies are bad. You simply don't get monopolies without IP laws. IP laws are the ultimate king maker and exclusively exist to perpetuate profits of the IP owner. If your proposition of regulation is to disband the patent offices and repeal the copyright act, my sincere apologies. reply atoav 10 hours agorootparentGetting rich is easy. You just need rich parents. Two things can be true at the same time. The truth is, if you are in the position to make the step towards becoming a monopolist especially in a new market it is not impossible to do so (and by the rules it should be). Getting to that position isn't easy tho. But from a consumer standpoint the only thing that matters is if you have monopolists or not — we don't care how hard it was for them to become one other than it might change the number of monopolists that force their crop down our throats. reply Rodeoclash 10 hours agorootparentprevIf only the free market was even more free, all our problems would be solved! reply atoav 9 hours agorootparentThe invisible hand of the free market will come and fix all the things! /s If you talk to people who still subscribe to that notion, it quickly becomes clear that they value their miniscule chance to win the capitalist lottery more than the wellbeing of the many — the idea that markets balance everything to the advantage of everybody then seems to be just an excuse to be egoistic and without any care for others. Don't get me wrong, nobody has to care for others and I am not going to be the person to force you, but if you don't care about others please stop pretending you are doing it for the greater good. reply obirunda 1 hour agorootparentYou're conflating several schools of thought. Utilitarianism, which appears to be your basis for defining ethical behavior, underlies this reasoning behind compulsory government action. This line of thinking is often repeated in election cycles and mindless online discussions, with mantras like \"We justify doing something heinous because it serves 'American Interests'\" or \"We'll coercively tax one group and redistribute funds to another because they'll do something dubiously for the 'greater good'\". However, Utilitarianism is not a foundational principle of libertarian ideology. In fact, libertarianism often refutes and rejects it as applied to governments. It doesn't prioritize egalitarianism or rely on public opinion when defining citizens' rights. The argument for a free market unencumbered by protectionist policies isn't about the greater good; rather, it's an argument for an ethical government grounded in first principles. The \"greater good\" argument tends to crumble under close examination and logical scrutiny. Its claims on reason collapse as soon as you scrutinize them more deeply. Notably, Utilitarianism has been the basis for nearly all modern-day dictatorships, which rely on a monopoly of violence to enforce the \"greater good\". It's possible to support free markets while still caring for others – this is called altruism. It's similar to utilitarianism but without coercion and fallacies. reply mindslight 7 hours agorootparentprevWithout imaginary property, AMD would have signed a similar contract - they would rather focus on their own products rather than reverse engineering the HDMI standards to create their own implementation. At which point AMD would be in the same position, unable to reverse engineer HDMI or adopt solutions from other companies who did. Imaginary property laws most certainly encourage and facilitate monopolies and collusion, but they are not necessary to the dynamic. Such laws are essentially just the norms of business that companies would be insisting on from other businesses anyway, for which it's much more lucrative to assent and go along with rather than attempt to defect and go against them. Another example of this effect is the DMCA - the tech giants aren't merely following its process verbatim, but rather have used it as basis for their own takedown processes with electively expanded scope - eg why we see takedown notices pertaining to \"circumvention\" code, or the complete unaccountability of Content ID. Google and Microsoft aren't significantly hurting themselves by extralegally shutting down a tiny contingent of their customers, meanwhile the goodwill they garner from other corporations (and possible legal expenses they save) is immense. The loser is of course individual freedom. reply mobiuscog 10 hours agorootparentprevLinux gamers with modern TVs wanting VRR. Maybe that's still a tiny amount, but it's likely the most common 'need'. reply account42 10 hours agorootparentprev> Most people don't have hardware that requires HDMI 2.1 in order to get full use out of them. Most people maybe not but a simple 4K TV that can do > 60 FPS fits that criteria. Those aren't that rare anymore. reply lexicality 8 hours agorootparentprev> At any rate, for some reason DisplayPort has just not caught on all that much. You very rarely see them on TVs, and a good number of mid-/lower-end monitors don't have them either. I suspect all the nice features that make DisplayPort a better standard are harder to implement cheaply, eg chaining reply 2muchcoffeeman 13 hours agorootparentprevI have fewer display port devices now than 8 years ago. reply KeplerBoy 11 hours agorootparentDon't forget about usb-c. Video over usb-c is almost always display port in disguise. reply squarefoot 9 hours agorootparentWhat about latency? Is it on par or at least in the same league compared to direct connection? Not an issue for most people, but gamers could disagree if it is too high. reply duskwuff 9 hours agorootparentPerformance is identical. DisplayPort Alternate Mode (which is what most displays use) isn't transmitting video data over USB; it's agreeing to use some of the high-speed wire pairs in the cable to transmit DisplayPort data instead of USB. reply seba_dos1 7 hours agorootparentprevIt's still direct connection, so there's nothing to compare there. reply shmerl 13 hours agorootparentprevMay be it can change if USB 4 will sneak in and supplant HDMI in those devices, since it can route both HDMI and DP. reply account42 9 hours agorootparentIs HDMI over USB even a thing that any real devices support? But yeah, demand for mobile phone support might force TV manufacturers to adopt DP over USB. reply duskwuff 9 hours agorootparent> Is HDMI over USB even a thing that any real devices support? No. A spec for HDMI Alternate Mode was written, but almost nobody (possibly nobody at all?) implemented it, and it was eventually withdrawn. https://arstechnica.com/gadgets/2023/01/hdmi-to-usb-c-spec-a... reply ignaloidas 7 hours agorootparentprevIt cannot route HDMI, partly because HDMI is built upon antiquated principles and doesn't really fit besides more modern protocol designs. USB4 would need to get entirely redesigned for tunneling native HDMI. Having a DP to HDMI converter on one end though, that's easy. reply Pet_Ant 4 hours agorootparent> HDMI is built upon antiquated principles I'm interested in learn more, in what way are they antiquated? reply adrian_b 3 hours agorootparentHDMI uses a digitalized form of the traditional TV signals. The format of the transmitted data still depends on the parameters that defined traditional TV signals, like video frame frequency, video line frequency, vertical and horizontal retrace intervals and so on. Such parameters are no longer essential for digital television and there is no longer any need to constrain the transmission of video signals with them. DisplayPort uses a typical communication protocol that can carry arbitrary data packets, not much different from the protocols used on USB or Ethernet. reply sitkack 12 hours agoparentprev> They're handing a win to DisplayPort. And that would be bad how? DP is an excellent standard and royalty free. reply eqvinox 11 hours agorootparentI don't think there was an implication that this would be bad reply repelsteeltje 11 hours agorootparentI guess, bad for the HDMI patent pool members. reply merlindru 8 hours agorootparentprevNot bad, but it's hard to think of a reason why they're doing this It's protecting your standard from being used by others when wide adoption is the only thing that differentiates your standard from others i.e. they're shooting themselves in the foot reply paulmd 4 hours agorootparent\"by failing to give away their product for free, this IP-licensing organization is really only losing in the end!\" reply HeckFeck 10 hours agorootparentprevIt's like what FireWire was to USB, but hopefully it has a better fate. reply cassianoleal 9 hours agorootparentWasn't FireWire also massively encumbered in patents and very expensive licenses? I may be misremembering... reply HeckFeck 1 hour agorootparentIf so it'd be different in that regard. I was thinking of it more as the better-engineered underdog that lost out to the more corporate-friendly option. IIRC it had full duplex unlike USB 1/2, it launched well before USB with a fast 400Mbps transfer speed and its hardware controller was sophisticated enough that it could work without much intervention from the OS. But looking into the history, the patent situation was indeed grim. Likely that's what kept it in an Apple and DV niche until USB caught up. reply sitkack 1 hour agorootparentJobs wanted too much money for firewire and Intel wanted to get PC dominance by having USB everywhere. The lack of firewire adoption is mostly afaik on Jobs. reply shiroiushi 13 hours agoparentprev>They're handing a win to DisplayPort. Is this useful, if all the relevant devices only have HDMI ports and not DP? reply eqvinox 11 hours agorootparentFYI: USB Type-C ports are DP ports on most modern laptops. You just need the correct cable (or a display with Type-C connector.) I have one of these https://www.club-3d.com/en/quick-view/2470/ (actually works both directions, e.g. if you have a portable display with only Type-C connectors like this https://www.hp.com/us-en/shop/pdp/hp-e14-g4-portable-monitor — BUT it can't power the display, you need to use another connection on the display for that.) There is no HDMI over Type-C (there was an attempt at it, but it died. Probably for the better of not having even more Type-C confusion and interoperability issues.) reply globular-toast 9 hours agorootparentThe \"relevant devices\" is surely referring to the displays here. I would love to go DP for everything but the best I can seem to find is computer monitors with 1 DP input and usually 2 or more HDMI. For living room type displays you won't find DP at all. reply eqvinox 7 hours agorootparentFor PC displays on geizhals.eu, out of 3327 products: 157 (4.7%) have 2 DP inputs 2446 (74%) have 1 DP input 724 (22%) have no DP input Including USB-C ports, 949 (29%) have ≥2 DP inputs 1806 (54%) have 1 DP input 572 (17%) have no DP input Compare HDMI: 1350 (41%) have ≥2 HDMI inputs 1791 (54%) have 1 HDMI input 186 (5.6%) have no HDMI input I agree it could be better but I don't think it's as bad as you make it out to be. Looking through the devices that have no DP input at all, 488 of the 572 have VGA inputs, which I'd say indicates an older generation of devices. \"Consumer\" electronics (i.e. TVs) is a problem though, I'll agree. reply adrian_b 13 hours agorootparentprevWhat I find very annoying is that a very large number of small computers and laptops have both DisplayPort and HDMI, but they have full-size HDMI connectors and only USB Type C DisplayPort. Using Type C for DisplayPort instead of the good full-size DisplayPort connectors is less reliable (easy to disconnect accidentally) and it permits only shorter video cables. More importantly, this blocks the Type C connector, which I need for other purposes, e.g. an external SSD. I do not want to carry a Type C dock, so I end using HDMI, even if I do not need HDMI and I do not want HDMI and even if in almost all cases the devices had enough free space for a full-size DisplayPort connector. Even replacing the HDMI connector with a DisplayPort connector (so that the devices would have only full-size and Type C DisplayPort) is always a better solution, because there are a lot of cheap adapters from DisplayPort to HDMI, which do not need a separate power supply and they can even be incorporated inside the video cable. The reverse adapters, from HDMI to DisplayPort, are much more expensive and much bulkier, so usually they are not acceptable. reply eqvinox 11 hours agorootparent> The reverse adapters, from HDMI to DisplayPort, are much more expensive and much bulkier, so usually they are not acceptable. That's because those are active converters — contrast DisplayPort has \"DP++\" which means the source port is electrically capable of transmitting either DP or HDMI signals; the graphics card can switch modes. The adapter is a tiny IC to signal doing that switchover and just wires the data lanes through. HDMI has no such thing, you need an active protocol converter IC to get DisplayPort. (NB: there are also active DP→HDMI converters, they have a bit longer range than the passive ones. I had to use one of them for my home projector, it's on a 10m HDMI cable which only worked on a blue moon with a passive DP++ adapter. Funnily enough it doesn't work on my native HDMI port either, only the active converter gets it running reliably… might be a poor 10m cable ;D) DP++ wasn't part of the original DP spec, but I don't believe any DP source hardware that doesn't support DP++ is being manufactured at this point. reply adrian_b 9 hours agorootparentThe DisplayPort connector includes a supply voltage. While it is weaker than in USB, it is strong enough to provide power to an active DisplayPort to HDMI converter, which can have the appearance of a video cable that can connect a DisplayPort source to an HDMI sink. On one of the HDMI pins there is a DC voltage, but it has other purposes and it is too weak to provide power for a video converter. This is why an HDMI to DisplayPort converter always requires an additional external power supply. reply shiroiushi 13 hours agorootparentprevIt seems the issue with this open-source driver is supporting some of the highest-performance modes of HDMI (like 4K @ 120Hz). Would that even work in a DisplayPort-to-HDMI adapter? reply adrian_b 13 hours agorootparentWhile there are no fundamental reasons for any video mode to not work, most of the DisplayPort to HDMI adapters that are currently on the market do not support the latest standard versions of DisplayPort and/or HDMI, so when a very high performance mode is desired, it might not work. However, the main use of adapters is when you travel and you find in your temporary office an HDMI-only monitor, or when you must use a meeting room projector. Such monitors or projectors seldom support high performance video modes. reply account42 9 hours agorootparentA problem is also that many video cards that do support HDMI 2.1 only support display port DisplayPort 1.4 which has less bandwith. This makes the sitution with the open source AMD drivers even more annoying because even with an active adapter that supports all the required features (which most don't) you can't get the full HDMI 2.1 resolutions/refresh rates that way. reply agilob 13 hours agorootparentprevWell, yes. The only relevant device with HDMI that I have is a raspberry pi. reply Fnoord 9 hours agorootparentYou don't own any monitor or TV? reply agilob 9 hours agorootparentEvery of them runs on DP reply amelius 8 hours agoparentprev> quality and consistency of HDMI experience For me the experience is not so good, given that HDMI signals always require at least 2 very long seconds to be recognized by a monitor, often even more. reply sgjohnson 7 hours agoprevI feel like the only thing HDMI has going for itself is ARC. DisplayPort is superior in every other way imaginable. Except for the fact that almost no TV supports it. Low-end monitors also don't usually have them, but as far as computer monitors go, I'm not interested in the low-end ones. As for TVs - just give me a dumb screen with ports. I'm going to attach Apple TV to it anyway. reply nolok 6 hours agoparentHDMI is ruling because of momentum and ubiquity in the tv room. No device output in DP, no device accepts it, so no pressure on device to accept/output it. I guess the license price is low enough. On computers, it sort of evolved where DVI was, you get mort port, you get better feature set, it's just superior. But in the non-tech market I think the \"real\" fight will end up being hdmi vs usb-c, both of them are evolving to the point where they feed everything ethernet included. HDMI has ARC and waayyyy simpler cable and port compatibility (one version to check), usb-c has power output and every single pocket device and laptop/tablet/... reply toast0 4 hours agorootparent> But in the non-tech market I think the \"real\" fight will end up being hdmi vs usb-c, both of them are evolving to the point where they feed everything ethernet included. HDMI ethernet and HDMI eArc use the same pins. eArc won, HDMI ethernet is pretty much dead. reply sgjohnson 5 hours agorootparentprev> No device output in DP Yeah, if we exclude basically every half decent GPU and ~70% of laptop USB-C ports in existence. reply rahimnathwani 3 hours agorootparentI use an HDMI to HDMI cable to connect my MBP to my 38\" monitor (3840 x 1600, @ 85Hz). Would I get any benefit from using a USB-C to DP cable instead (e.g. running at the monitors maximum refresh rate)? reply rowanG077 2 hours agorootparentUnanswerable without specifying what laptop you have. reply rahimnathwani 2 hours agorootparentSorry, I should have Googled before asking the question. I just did, and see that my monitor (Dell AW3821DW) supports only 85Hz over HDMI, but up to 144Hz over DisplayPort. The laptop's spec page doesn't say what refresh rates are supported for external displays (except saying at least 60Hz): https://support.apple.com/en-us/111901 I'll buy a new cable right now :) reply rowanG077 1 hour agorootparentYes that macbook pro supports outputting even 4K @ 144hz over displayport so it should work easily. reply nolok 4 hours agorootparentprevI was talking about the TV room device, as opposed to the computer devices. reply ai_ 4 hours agorootparentprevThose generally aren't in the living room reply bryanlarsen 5 hours agoparentprev> Except for the fact that almost no TV supports it. So frustrating. I'm using a 42\" LG OLED TV as a monitor right now. Very nice monitor at half the price of the same panel in a \"real\" monitor. I'm driving it with an AMD card at 60 Hz for exceedingly stupid reasons. reply macNchz 4 hours agorootparentFWIW after reading though lots and lots of posts in the original bug report thread for this issue, I bought a Cable Matters “8K DisplayPort 1.4 to HDMI 2.1 Adapter” and it works perfectly to drive my Sony TV at 4K/120 from an AMD 6900XT on Ubuntu 24.04. reply xnyanta 6 hours agoparentprevSo true, I picked up the Samsung G80SD \"Smart Monitor\" and the deciding factor was literally just that it supports eARC, allowing me to use my Sonos Beam soundbar with my computer and supporting compressed audio formats like Dolby Atmos. To make things even worse, this monitor supports sending back the ARC audio over DisplayPort, but only in stereo. If I use HDMI between the monitor and the computer, I get all of audio channels. reply vzaliva 11 hours agoprevThere was a post here on HN some time ago ( https://news.ycombinator.com/item?id=36681814 ), basically explaining that HDMI is terrible and DisplayPort is a much better technical solution. So, perhaps people should favour DP instead of HDMI and gradually switch? reply ThatPlayer 11 hours agoparentI don't think it's quite that simple. DP is still missing HDMI features like ARC and CEC, which are important for TVs. Even on my personal computer setup, I use the HDMI 2.1 ports on my monitor/GPU over the DP 1.4 ports because the DP port just doesn't have the bandwidth for 2560x1440 @ 240hz with 10-bit colour. That requires ~30 Gbit/s, more than DP1.4's ~26 Gbit/s. Neither my monitor nor my GPU support DP2.0 which does have enough bandwidth. So until I upgrade both, I'm using HDMI. My computer is not outdated either, there's just nothing to upgrade to. None of Nvidia's consumer GPUs support DP2.0, and I can only find 2 monitors that support DP2.0. Anyone getting new hardware now will be in a similar situation to use HDMI2.1 over DP1.4 until their next upgrade. reply gond 9 hours agorootparent> DP is still missing HDMI features like ARC and CEC, which are important for TVs. ARC could also be considered as a bug, a hindrance, or both. ARC and its various implementations would not exist if the HDMI Forum would not be so fanatically force copy protection on everything. The whole problem, or feature that ARC is or is not, would disappear with the reliance of protecting every stream. The alternative would be a full datastream, decoded, going back to the device in question. The prerequisite would be to remove the shitshow that HDCP is and allow full-blown HDMI-in and outputs, which is the exact opposite of what the Forum wants. HDMI in its current implementation hinders technological progress in the audio segment by forcing everyone to output analogue signals after the decoding stage or not allow decoding at all. reply gizmo 8 hours agorootparentDon't you also need ARC because of video post-processing that adds frames of latency? The TV needs to send audio back to the receiver otherwise video and audio will not be in sync anymore. Receivers/amplifiers can process audio with practically no latency so it makes sense for them to be at the end of the chain. reply toast0 4 hours agorootparentYou don't need ARC to address a/v sync. HDMI has (optional) metadata somewhere (edid?) where the display device indicates its delay and the audio device can adjust accordingly. It's helpful if the display device has fixed delay for this feature to be most effective; it's fine if there's different modes with different delays and the current delay is communicated, but some modes have variable delay depending on content which is terrible in several ways. IMHO, ARC is primarily useful when the display device is also acquiring the content: it's running the TV tuner or internet streaming or content off a usb drive. It's also useful if you have a 1080p capable receiver and upgrade to a 2160p(4k) display and sources: if you put the receiver in the middle, you lose on video quality, but with eARC the display can route full quality audio from all your sources. Some sources do have two HDMI outs, so you could wire to the display and the receiver, but that's not very common. reply AstralStorm 8 hours agorootparentprevUgh, DisplayPort already has the audio channel. As far as sync, neither protocol provides for effective reclocking or supplies the audio clocks, and you need VRR to provide sort of display clocks. reply alt227 7 hours agorootparentI admire your exasperation on this issue :) reply eqvinox 11 hours agorootparentprevI agree, but I also think your illustration of the problem is a bit off. The 90% gauss curve center part of customers doesn't need the tail end of display connector bandwidth. However, devices have a lifecycle, and a lot of this hardware will still be in use in 2-3 years, where this will have moved into the center part of the gauss curve. Higher resolutions and HDR (which may push 10bit) will trip this much more than a 240Hz display [which ain't ever gonna' be mainline, really, considering we went down to 60Hz from CRTs with faster refresh rates] CEC can be done over the DisplayPort AUX channel. I think there were attempts at an ARC equivalent but they floundered. Another interesting question though is how much A/V connections in general will still be used in the \"TV world\" down the line… with everything moving towards more integrated networked appliances instead. E.g. streaming service \"HDMI sticks\" are now apps on the TV instead… reply ThatPlayer 7 hours agorootparentI agree that it's an issue very few customers are going to run into. But also that's where the differences in DisplayPort and HDMI are. For those 90%, they're equally served by HDMI and DisplayPort and will just use whatever they have. Another 10% feature difference I do like on DisplayPort is Multi-stream transport for multiple monitors over a single cable. I don't think many people are looking to daisy chain big screen TVs. reply globular-toast 9 hours agorootparentprevARC and CEC are only necessary because of this stupid situation where TVs are like displays with shitty media centres built in. ARC is only a tiny bit more convenient anyway; it's not that hard to run an audio cable back from the TV to an audio receiver and you'll be hiding the cable anyway so it matters not the slightest what it looks like. In 2002 there was XBMC (later renamed to Kodi). Microsoft even had Windows XP Media Centre Edition in 2005. At that time it was perfectly possible to set up a media centre that could do everything. No need for shitty TV remotes and CEC. You would use a much higher quality remote of your choice. Oh how far we've come in 20 years... reply toast0 4 hours agorootparent> it's not that hard to run an audio cable back from the TV to an audio receiver and you'll be hiding the cable anyway so it matters not the slightest what it looks like. That's fine for regular ARC which is basically the same capability as spdif, ATSC audio and DVD audio. But there's no consumer audio cable that has the capacity for lossless surround except for HDMI, and then you really want eARC because otherwise you have one HDMI running from the receiver to the TV for video (and maybe audio) for sources that can go through the receiver, and a second HDMI that runs from the TV to the receiver for audio only for sources that can't go through the receiver (built into the tv like the tuner, network streaming, and playback from USB; and also devices that exceed the HDMI bandwidth of the receiver or don't negotiate to an appropriate video and audio format unless going direct --- I have a 4k Roku and a 1080p BluRay player that need different settings on the TV to work through my receiver, or I can wire one source direct to the TV and use eARC) reply icar 8 hours agorootparentprevIt's still a perfectly valid choice. reply xnyanta 6 hours agorootparentprev>it's not that hard to run an audio cable back from the TV to an audio receiver Wait until you find out that many consumer sound bars (Sonos comes to mind) only support the latest and greatest digital audio formats over eARC. reply RegnisGnaw 6 hours agoparentprevHow do I switch? My TVs only have HDMI, should I spend another 5K+ to buy DP TVs? reply gnabgib 14 hours agoprevDiscussions (290 points, 6 months ago, 164 comments) https://news.ycombinator.com/item?id=39559318 (394 points, 6 months ago, 237 comments) https://news.ycombinator.com/item?id=39543291 reply account42 10 hours agoparentAnd the source for all these articles: https://gitlab.freedesktop.org/drm/amd/-/issues/1417 reply eqvinox 11 hours agoprevWhile we're here, does anyone know why professional displays [e.g. https://www.usa.philips.com/c-p/27B1U7903_27/professional-mo... ] frequently have 2 HDMI ports and only 1½ DisplayPort? (½ for the Thunderbolt port) This feels like some kind of standard port combination… do the display driver ICs only have one DP port? Are they using TV silicon? I know HDMI is used in some AV production setups, but that feels like a very small niche to justify having 2 HDMI ports on a display like this? [I'd rather have 2 DP ports and only 1 HDMI… or no HDMI at all] reply kristjank 9 hours agoprevI really hope HDMI snags hit some critical mass and it gets reliquished to the dying TV/home theatre domain where it can rot into obscurity. DisplayPort has its own issues, but they're much smaller than the constant industry fuckups HDMI produces. It's Oracle: the interface. reply pella 9 hours agoprevArticle date: February 29, 2024 Related phoronix threads - 6 months ago - 394 points https://news.ycombinator.com/item?id=39543291 reply 0points 12 hours agoprevBye HDMI. You will not be missed. reply WithinReason 11 hours agoparentwe can only hope... reply Kon5ole 12 hours agoprevBummer - some TV's are tremendous value for money as computer monitors (Small 8K tv's that sometimes sell for sub-1000 usd) but they tend to only have HDMI. I got 8k/60 working in Linux using an nvidia card and a dp-to-hdmi adapter cable, but I have a feeling it's not meant to be supported (the same cable does not work in windows). reply langsoul-com 9 hours agoprevIsn't amd in a pretty bad position with display related tech? Hdmi rejected them, display port isn't ubiquitous enough, thunderbolt (usb c) is owned by Intel. reply xxpor 14 hours agoprevNote this is from February reply shiroiushi 13 hours agoprevAMD should just leak the code and disclaim responsibility. reply preisschild 13 hours agoparentEven if they were to do that, it wouldn't really be a long term fix. Who would maintain this \"unofficial\" GPU driver? AMD themselves can't. reply shiroiushi 13 hours agorootparentIf it has that much interest, someone will put it on GitHub and maintain it. Of course, it'd be unofficial, but so was support for MP3s in Linux distros for many years: you had to download software from outside the US to make it work. reply taneliv 12 hours agorootparentIncompatible licenses would mean that no distribution would have kernels that support it, though. It would be a second class citizen, compiled via DKMS or something, and often broken on a lot of hardware. The difference to broken MP3 support is that if your music file does not play, you can still browse the Internet and write emails and play games, but if your graphics driver is busted, you can do none of those things from GRUB menu. In the worst case recovery mode does not work either, and you just converted your laptop into a headless server. Troubleshooting it by browsing instructions on the mobile is no fun. reply shiroiushi 11 hours agorootparentWhy would the licenses be incompatible? AMD owns the code, so they can release it under whatever license they want, including GPL or BSD. They could even put into the public domain if they wanted. AFAICT, the code has not been released at all, so this point about licenses is simply wrong: it doesn't have a license at all right now. As for a broken driver, that's an easy fix I think. From my reading of the article, there's already an existing driver, but it doesn't support HDMI 2.1 features. So it's simple: provide a fall-back driver, and require users to separately download the new driver (or maybe distros can package it themselves, I'm not sure about the legality). If something goes wrong with the unsupported driver, leave an option in the boot menu to boot in a \"safe mode\" that uses the old driver. So they won't get 4K @ 120Hz, but I'm sure they can live with that. reply taneliv 9 hours agorootparentExactly like you are saying, if I'm not misunderstanding the situation: the code is unlicensed for anyone who is not AMD. That is incompatible with GPL2 license of the kernel. Without HDMI Forum's approval it can not be licensed, either, since the point is that AMD does not own the secrets contained within. (If the driver is leaked, I would imagine it to be illegal to distribute it. Companies might elect to not actively support even the fallback mechanism, if it has no other use cases. Probably not a big hurdle and something an installation package should be able to solve, but a hurdle nevertheless.) reply steelframe 3 hours agoprevCool. Then I suppose I'll buy my dumb DisplayPort screens from rando Chinese knockoff companies that siphon off R&D that suckers like Sony and Samsung fund. reply wvh 9 hours agoprevIf possible, they should add a hook and individual download script like for DeCSS back in the day. Let them come at each of us individually for wanting to use the ports in our own hardware. reply shmerl 14 hours agoprevHDMI forum is a corrupt cartel which sole existence is to make sure they can continue fleecing everyone on patent fees. reply supermatt 9 hours agoprevWhat exactly does this mean? Isn't it just a case that the driver wouldn't be HDMI-certified, or are they actively prevented from distributing the driver? reply layer8 8 hours agoparentMy reading: AMD signed a contract with the HDMI Forum in order to get access to the HDMI specification and be allowed to create HDMI products (and use the HDMI trademark), which includes an NDA regarding the specification. An open-source driver would violate that NDA. reply Sakos 14 hours agoprevFeels like it's time for governments to get involved. It's not reasonable for a ubiquitous format like HDMI to be restricted like this. reply kelnos 13 hours agoparentI agree. It should be illegal to restrict people from making open source implementations of industry standards like this. I don't expect that to ever happen, of course. But I can dream... reply jakeogh 10 hours agorootparentI'm with you in principal, but cleanroom reverse engineering is legal. The issue here is AMD signed the NDA's to read the secret spec and write the code, hence they cant release it. The solution is to not buy proprietary standards[0], in this case, I'm looking for DisplayPort when I buy... and a big + to AMD for trying. Hey Intel! Come back! [0] Pile of comments here pretending it's sooo difficult. reply account42 9 hours agorootparent> in this case, I'm looking for DisplayPort when I buy That's an option if what you are looking for is a normal computer monitor. If you want a big TV then good luck finding one with DP, especially if you have other requirements (emissive pixels with real blacks, HDR, etc) that further limit your options. reply jakeogh 8 hours agorootparentAre you saying it's a lost cause? If so i'm totally switching back to Windows 2033 so I can play Simnpc in full res and buying one of those smart cars. reply jeroenhd 10 hours agoparentprevI wonder if the HDMI forum can be considered a gatekeeper in terms of the EU's DMA. Their influence on the market is rather indirect, but I wouldn't be surprised if 80% of the EU uses HDMI every single day. reply wmf 14 hours agoparentprevBetween patents, trade secrets, and DMCA, the government is the source of the problem here. Arguably the FTC could step in here but I think they have bigger problems to tackle. reply shiroiushi 13 hours agorootparent>Between patents, trade secrets, and DMCA, the government is the source of the problem here. The government created the playing field. The only entity that can fix the situation is the government: they created a bad playing field, and they need to fix it. reply anordal 13 hours agorootparentprevBut not all governments, thankfully. Remember DVD-Jon? He won the trial for breaking DVD crypto, because consumer rights stood above trade secrets. reply elihu 10 hours agoparentprevI think it's actually pretty typical for important electrical interfaces to not be public or royalty-free, as much as I wish that wasn't the case. That's not to say the government shouldn't get involved. I think the bigger thing here is that if an industry group is specifically setting things up so that Linux is shut out of having high-end video support, then it looks an awful lot like cartel behavior -- industry incumbents are working together to lock out a competitor. Maybe it could be the basis of an anti-trust lawsuit? Presumably Apple and Microsoft would have the most to gain. Microsoft is a member of the forum. Apple doesn't appear to be, but an Apple guy is on their board of directors. I'm not a lawyer and I don't know how such a lawsuit would work. Who represents Linux in this case, since it's not owned by any one company. Linus Torvalds? AMD? And would all the companies involved in the HDMI forum be liable for the behavior of the forum (which would include AMD)? Does intentionality matter? I.e. if Linux was excluded accidentally rather than deliberately? https://hdmiforum.org/about/hdmi-forum-board-directors/ https://hdmiforum.org/members/ reply anal_reactor 12 hours agoparentprevSeriously, we managed to standardize charging ports by law, maybe we can also agree on using an open standard for displays. reply jakeogh 11 hours agorootparentThat is the real issue, because ultimately, this is about the memory hole. A re-upload of a camcorder copy of a VHS is no threat; it will be degraded (again) when the digital archivist who saved it's re-encoded copy[1] (from whatever video platform deleted it) posts it again. Intercepting a exact bitstream circumvents this modern camcorder copy deliberate problem, and would ultimately obliterate the non-arguments to keep the original file unavailable. On the other hand, a signed sha3-256 digest along with the original[0] file before YT re-encoded it (and stripped it's metadata) is unobtanium for the plebs. It is the _most_ important data for the host. It's the first thing they backup. As far as I know, they (YT/Rumble/Tora3) never talk about it. Some would love to only serve hallucinated (when convenient) upscaled derivatives. Power is threatened by persistent lossless public memory. [0]: https://news.ycombinator.com/item?id=20427179 [1]: (Mr. Bean, 2024) https://www.youtube.com/watch?v=xUezfuy8Qpc reply anotherhue 5 hours agoprevSubmitted slightly earlier https://news.ycombinator.com/item?id=41386037 reply MPSimmons 7 hours agoprev>This occurred because in 2021 the HDMI Forum restricted public access to its specifications Oh, okay. Fuck the HDMI forum, then. reply sylware 8 hours agoprevEverybody knew that could happen with HDMI based on their legality setup. And it did. That said, those guys usually play a \"back and forth\" game on the long run... so stay tuned. You should have an eye on MPEG too, because those are the same \"type\" of people (and ARM ISA is not far behind...) Even if I despise big tech on nearly all fronts, sometimes we can agree, and this is AV1 and DisplayPort. And this type of behaviour namely not having a DisplayPort port could be a perfect regulatory (anti-competitive) project for EU, like they did with apple... reply roshankhan28 9 hours agoprev [–] with DP cable i can get 144 hz on my benq xl2411p. but with hdmi i can go max 90hz. i cant own 2 144hz display just because there is no way i can use two DP cables on my rtx 20270 super. reply ThatPlayer 9 hours agoparent [–] That's an issue with the monitor only supporting HDMI 1.4. A monitor that supports HDMI 2.0 would work with 144hz fine. I have the opposite issue where I run my 240hz monitor on HDMI 2.1 because it has more bandwidth than my RTX 4080's DisplayPort 1.4 ports. It seems a common issue enough with that that model is specifically called out sometimes: https://forums.tomshardware.com/threads/how-to-connect-to-a-... reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "AMD's open-source Linux graphics driver is blocked from adding HDMI 2.1+ support due to legal requirements from the HDMI Forum, affecting features like 4K@120Hz and 5K@240Hz for Radeon GPU users.",
      "The HDMI Forum rejected AMD's proposal, suggesting users switch to DisplayPort, as confirmed by AMD's Linux engineer Alex Deucher.",
      "The HDMI Forum's restrictions on public access to specifications since 2021 ensure quality but hinder open-source support, prompting AMD to consider alternative solutions."
    ],
    "commentSummary": [
      "HDMI Forum has rejected AMD's open-source driver for HDMI 2.1, leading to debates about the decision's impact on HDMI quality and the potential benefits for DisplayPort.",
      "Critics claim the rejection is protectionist, but note that most users may not be affected as they do not require HDMI 2.1 or use Linux.",
      "The situation underscores frustrations with HDMI's dominance and raises discussions about DisplayPort and USB-C as potential alternatives."
    ],
    "points": 283,
    "commentCount": 150,
    "retryCount": 0,
    "time": 1724898534
  },
  {
    "id": 41384144,
    "title": "Skip – Build native iOS and Android apps from a single Swift codebase",
    "originLink": "https://skip.tools/",
    "originBody": "Hello Hacker News. I&#x27;m Marc, one half of the team that created skip.tools. Skip is a tool that transpiles your SwiftUI iOS app into a Kotlin Jetpack Compose app, and enables you to use a single language to create a complete app that reaches the entire mobile marketplace.What it is: Skip stands in contrast to other cross-platform development tools like Flutter, React Native, and Xamarin, in that it enables the creation of genuinely native applications for both of the dominant mobile platforms. It doesn&#x27;t embed a separate engine or runtime into your app, but instead lets you use pure Swift and SwiftUI to create the iOS side of the app (as per Apple&#x27;s recommended best practices for creating iOS apps), and transpiles it into a pure Kotlin and Jetpack Compose app for the Android side (which is Google&#x27;s recommendation for building Android apps). So your application will use platform-native controls and will automatically have all the affordances provided by the platform vendor: animations, accessibility, and future-proof evolution alongside OS updates.How it works: you build a Skip app using the same tools that you use to create a standard iOS app: Xcode, Swift, and SwiftUI. Skip augments this workflow with a Swift Package Manager plugin called \"skipstone\", which transpiles your Swift into Kotlin each time you build your app, and launches the Android app side-by-side with the iOS app each time you run the app. The transpilation works not just on your primary app module, but also transitively processes all your dependent SwiftPM modules, so you can break complex projects down into individually testable sub-modules containing business logic or UI code. In fact, this is how our own adaptor modules for the standard frameworks are structured: SkipFoundation adapts the Foundation framework and SkipUI adapts the SwiftUI framework, so the same familiar API can be used when building the app. And there&#x27;s a GitHub ecosystem of open-source modules supporting popular frameworks, including SQLite, Firebase, Lottie, and many other common building blocks of modern apps.Over the past year Skip has evolved into a fully-capable solution for creating best-in-class apps for both iOS and Android. And today we are delighted to announce the release of version 1.0, meaning that it is ready for production use.We have a wealth of videos and documentation available at https:&#x2F;&#x2F;skip.tools, and I&#x27;ll be around to field any questions that any of you might have. Thanks in advance for taking a look!Home: https:&#x2F;&#x2F;skip.toolsFAQ: https:&#x2F;&#x2F;skip.tools&#x2F;docs&#x2F;faq&#x2F;GitHub: https:&#x2F;&#x2F;github.com&#x2F;skiptools&#x2F;",
    "commentLink": "https://news.ycombinator.com/item?id=41384144",
    "commentBody": "Skip – Build native iOS and Android apps from a single Swift codebase (skip.tools)269 points by marcprux 22 hours agohidepastfavorite97 comments Hello Hacker News. I'm Marc, one half of the team that created skip.tools. Skip is a tool that transpiles your SwiftUI iOS app into a Kotlin Jetpack Compose app, and enables you to use a single language to create a complete app that reaches the entire mobile marketplace. What it is: Skip stands in contrast to other cross-platform development tools like Flutter, React Native, and Xamarin, in that it enables the creation of genuinely native applications for both of the dominant mobile platforms. It doesn't embed a separate engine or runtime into your app, but instead lets you use pure Swift and SwiftUI to create the iOS side of the app (as per Apple's recommended best practices for creating iOS apps), and transpiles it into a pure Kotlin and Jetpack Compose app for the Android side (which is Google's recommendation for building Android apps). So your application will use platform-native controls and will automatically have all the affordances provided by the platform vendor: animations, accessibility, and future-proof evolution alongside OS updates. How it works: you build a Skip app using the same tools that you use to create a standard iOS app: Xcode, Swift, and SwiftUI. Skip augments this workflow with a Swift Package Manager plugin called \"skipstone\", which transpiles your Swift into Kotlin each time you build your app, and launches the Android app side-by-side with the iOS app each time you run the app. The transpilation works not just on your primary app module, but also transitively processes all your dependent SwiftPM modules, so you can break complex projects down into individually testable sub-modules containing business logic or UI code. In fact, this is how our own adaptor modules for the standard frameworks are structured: SkipFoundation adapts the Foundation framework and SkipUI adapts the SwiftUI framework, so the same familiar API can be used when building the app. And there's a GitHub ecosystem of open-source modules supporting popular frameworks, including SQLite, Firebase, Lottie, and many other common building blocks of modern apps. Over the past year Skip has evolved into a fully-capable solution for creating best-in-class apps for both iOS and Android. And today we are delighted to announce the release of version 1.0, meaning that it is ready for production use. We have a wealth of videos and documentation available at https://skip.tools, and I'll be around to field any questions that any of you might have. Thanks in advance for taking a look! Home: https://skip.tools FAQ: https://skip.tools/docs/faq/ GitHub: https://github.com/skiptools/ rock_artist 14 hours agoAs others, from the videos, I really like the tight Xcode integration. Reading the FAQ I do have few concerns, 1. Open-source, it mentions GPL forms, is there a reason MIT not mentioned? is that not considered open-source (especially with many iOS/Swift using MIT to be compliant with store distribution). 2. Packages, how does it handled packages? or the cases when you need to have branching for iOS/Android? the FAQ does not address this. 3. How Apple service APIs being handled on Android? I didn't look at the example weather app, but as an example, Apple got WeatherKit. or in my case case I use the built-in geolocation APIs. My concrete example, I have a small app I've made. It uses geolocation from Apple (to detect country city, etc), It uses AdMob and Apple's built-in In-App / Subscription services. I think this is a fair example of simple commercial product, and it'll be nice if you have some example for ads and in-app/subscription which might be important for closed/paid monetized projects... reply abewhite 8 hours agoparent- The LGPL license for Skip's libraries is the same license used in projects like WebKit. It does not interfere with using Skip in commercial, closed-source apps. - Skip is based on Swift Package Manager and fully both dual-platform and iOS and Android-specific dependencies. - Skip has a suite of dual-platform libraries, and for anything that isn't covered, multiple techniques for integrating platform-specific code and libraries. These include being able to use Kotlin right inline with your Swift and mix Compose code in with your SwiftUI. https://skip.tools/docs/platformcustomization/ https://skip.tools/docs/dependencies/#implementation reply LifeUtilityApps 20 hours agoprevLoving this so far, I've been working with it for a week now. I have a personal app, DownPay for iOS, that is built with SwiftUI that I want to bring to Android. I tried going the React Native route to build an android-only version but the context switching between SwiftUI, React Native, and then my day job made it challenging. I also tried Ionic and Ignite and wasn't successful with those either. After testing the feasibility of other cross-platform frameworks, I landed on Skip. I LOVE that I don't have to break out of the \"Swift\" mental context, I just have to focus on writing an app in 1 language. So before I commit fully I've been testing it out (building a demo app this week) and so far I am very impressed. The syntax to write platform-specific code (#if !SKIP #endif) is very easy to use once you get the hang of it. It's amazing I don't have to learn Android to get something up and running at this speed with Skip. Hitting run in xcode and watching both emulators open feels like magic. I want to put this to the test so I plan to build a complete App with it from start to finish, ship it to both App Stores, and if all that goes smoothly I will proceed to migrate my main app using Skip. reply AnonHP 14 hours agoparent> It's amazing I don't have to learn Android to get something up and running at this speed with Skip Any thoughts on how you would debug issues on Android that don’t show up on iOS? reply abewhite 8 hours agorootparentSkip generates native code, so you can open it in Android Studio and use all the native debugging tools reply nprateem 5 hours agorootparentIf you know how given the point of this is not having to learn android reply mad_tortoise 10 hours agoprevI'm not sure I see the point, other than this being aimed at first world (see US/EU) businesses who solely have iOS application's and want to convert those to Android. So if you only have Swift developers and didn't have the forethought to want an Android version of the app going forward then this is a product for you. I would recommend, going pure native android or starting again with Flutter. Whereas the rest of the world is Android dominant, and there is no real reason to do this when there's multiple better frameworks for cross platform development. Flutter, React Native and Kotlin MP are and always will be miles ahead. Let alone those framework's being free whereas here there is a cost for professional development. As someone that has written various projects in Kotlin (including multiplatform), Swift, Dart/Flutter for over a decade I don't see the point. And I would be exactly the target market for this kind of product. The transpiling is the big issue for me, you will have to tap into every single Android API, write code to transpile those and then maintain across every Android version going forward. Let alone the denigrating of cross platform frameworks and promotion of yours due to \"animations, accessibility, and future-proof evolution alongside OS updates\" doesn't sound like much of a win, when the quality of these in cross platform is already at a very high level. Secondly \"And there's a GitHub ecosystem of open-source modules supporting popular frameworks, including SQLite, Firebase, Lottie, and many other common building blocks of modern apps.\" all of which exist in cross platform and kotlin multi platform. I'm sorry to the developers and team to knock it, but just my 2 cents coming from a more third world perspective. reply cvwright 7 hours agoparentThe problem with this perspective is that iOS is where the money is. Almost ALL the money. So if western B2C companies have to pick just one platform to start with, it will almost always be iOS. This lets them then port that initial app to Android once they are established with western audiences, so they can also serve the (much larger, much less profitable) rest of the world. reply mad_tortoise 7 hours agorootparentMy problem with this is that it show's almost no forethought by those creating the app. If your goal is first an iOS app that you will develop into an Android app. Then why go this route? It doesn't solve any of the bigger cross platform problems, is a far less mature ecosystem, and will seemingly only paper over the basic needs - but in-depth development will become an issue. But if you're only porting an \"initial app\" and expecting the next iteration to be either native or cross platform, then start like that rather than waste 6-12 months on transposing the code to a different language. To me this presents as something a business person with very little knowledge of app development will be drawn to. But the long term drawbacks of this approach far outweigh the short term gains from trying to quickly port an existing iOS app to Android. Sure there's more money in the Western app ecosystem for iOS apps, but that doesn't mean your app should inherently cater for iOS first. In fact that's a very first world and reductive approach, when there's billion's of people that don't interact in the same way. reply joshuakcockrell 2 hours agorootparent> Sure there's more money in the Western app ecosystem for iOS apps, but that doesn't mean your app should inherently cater for iOS first That's exactly what it means. When I was at Twitter, the Android app generated 1/10th the revenue of iOS. If you care about building a business that generates revenue, you should definitely cater to iOS first. reply isodev 6 hours agorootparentprev> iOS is where the money is. Almost ALL* the money. * All the money made through an app store. For everyone and everything else, apps are utility helpers for physical goods and services paid for externally. You setup your router, the app for your door lock, the app to hold your Carrefour discount codes, the app setup your printer etc. reply anakaine 10 hours agoparentprevI thoroughly disagree with your positions about foresight, multiple specialists, a lack of need in this space, etc. There is space in the market for something like this, and it would suit small teams who may be lean, single devs who are starting out, and those who would like to use native code with few if any dependencies. You may not see the point because you are deeply experienced with the existing tools. I see the point as someone who has struggled to get deep with the existing tools. reply isodev 6 hours agorootparent> it would suit small teams who may be lean, single devs who are starting out, and those who would like to use native code with few if any dependencies I think that's already covered by Kotlin Multiplatform, Flutter, React Native and others. It's extremely easy to get started and they all have a vibrant and thriving ecosystem. I'm not blind to your use of \"native\" here, but again that's a descriptor typical for the iOS/macOS dev bubble to imply \"build with Apple tooling\" vs. \"build with a 3rdparty/cross-platform framework\". It was mentioned in another reply - the years when that was noticeable in any meaningful way are long gone. reply mad_tortoise 10 hours agorootparentprevIn terms of forethought, I can't imagine anyone outside of the US/EU developing an app solely for an iOS user base other than creating an MVP. And then even still, once you have proof it can work why build something that intentionally shuts off the majority of your userbase, or provides a lower quality product to the user base? If you are lean and starting out, don't put all your eggs in a Swift/iOS basket and then hope for a tool like this to sort out your problems. It may be an easy quickfix for a basic app, but once you go even a little bit deeper than surface level you're going to run into problems, have to backtrack and start over with either native Android code, or a cross platform framework. That said the cost is also something that is odd, when you have free alternatives that provide far more mature ecosystem. In terms of getting deep with existing tools, what is the difference here when using XCode as to Android Studio or VSCode? The tools aren't difficult to use, at least any more so than XCode. If you're not a developer then sure, but if you are then AS or VSCode should be a breeze. We're far removed from the days of Eclipse and Notepad++ where you didn't have the tooling, online resources or automatic fixes that these tools come with today. So yeah maybe my experience doesn't see the need for this, which is exactly the issue here. Who is making the majority of the apps we use today? Who is paying to use tools that speed up development? Engineers like myself. reply ElFitz 8 hours agorootparent> In terms of forethought, I can't imagine anyone outside of the US/EU developing an app solely for an iOS user base other than creating an MVP. And then even still, once you have proof it can work why build something that intentionally shuts off the majority of your userbase, or provides a lower quality product to the user base? I can see a simple reason for solely targeting the iOS user base, wherever one comes from: on average they earn more and spend more, making them better targets for both advertising and in-app purchases business models. Apple’s AppStore represents 65% of global app stores consumer spend, and ~7% of iOS users spend some amount of money on apps, while on Android it’s ~4.5%. On top of that, the hardware is much less diverse, making it easier have a consistent experience across devices. I still remember a client building an internal bar-code scanning app for their warehouse, then complain it didn’t work well enough, only to realise they had equipped their staff with the cheapest crap they could find, which had a terrible camera. Back on topic, perhaps yhis kind of tool can be useful for teams who didn’t intend to or couldn’t afford to invest any effort into making an Android app. reply BodyCulture 4 hours agoparentprevYour criticism is very interesting, but instead of just presenting some abstract ideas of potential problems it would give much more impact to your argument to present some hard evidence that your way of thinking is better. Can you show an example of an app that will generate more problems for developers with this approach than with other platforms? BTW do not forget to add some possibilities to pay you for your work with such a publication, I would certainly be willing to pay for a good in-depth analysis. reply abewhite 8 hours agoparentprevBeing able to share any parts of your business logic and UI that you want between iOS and Android versions is a huge win for companies of any size. Traditionally this has been a PITA, has added significant performance overhead and bloat (JS runtime, added garbage collector, etc depending on the framework), and on the UI side, has often given you non-native UIs. Skip solves all of these problems, and because it uses your code as-is on iOS and generates native code on Android, you can trivially and directly mix in platform-specific code wherever you need to, without any bridging. reply mad_tortoise 7 hours agorootparentEdit: I see you work for Skip, which I think you should state upfront. But I do understand your bias or blinders in assessing the tool. I get the benefit of being able to share business logic. That's not the issue at stake here. If it was, this wouldn't be a company in the first place as there's multiple frameworks that enable this and do this better - at zero cost. I don't believe performance issues is a relevant metric anymore, having dealt with them on RN, KMP, Flutter. Non-native UI, is also quite irrelevant these days. Perhaps if we were having this conversation 2-3 years ago I would agree with you. But with how RN/Flutter UI's are now, and the native aspect of KMP it's a non-issue. > Skip solves all of these problems, and because it uses your code as-is on iOS and generates native code on Android, you can trivially and directly mix in platform-specific code wherever you need to, without any bridging. I will believe it when I see it. You say \"Skip solves all of these problems\", when Kotlin multi-platform was essentially doing the same thing in reverse, but with far larger backing and it took years before it was production ready. It is not trivial to keep up with ever changing Android ecosystem, multiple API levels that need to be catered for, differing UX interactions, different native API's e.g databases, push notifications, permissions etc. Again you say trivial, not sure what is trivial about this. I feel like you've either never tried cross platform work on a (large) production project? This is solving an aspect of mobile development that personally I don't see a need for. But if it's for you go for it, in my experience across languages and platforms, I would recommend against this option unless you solely only have iOS Engineers, no ability to cater for a native Android experience and hadn't thought of having an Android app before starting development. Then sure, use it. Any project I plan would be both platforms and wouldn't require this level of abstraction. reply fifafu 13 hours agoprevI recently stumbled upon this (and it sounded great!), but was already too far in the development cycle of a medium sized Swift UI iOS app. Instead I used ChatGPT & Claude to convert the SwiftUI Code to Kotlin & Jetpack Compose & Material3. This worked crazy well. The generated code worked almost instantly and basically just needed small modifications for the styling /theming. I think the similarities in SwiftUI and Jetpack Compose make this a great match for LLMs reply abewhite 7 hours agoparentSuper happy this worked out for you! But I could never trust an LLM to maintain my app over time reply fifafu 6 hours agorootparentthe code I got is pretty maintainable and it’s all standard kotlin & jetpack compose. Even the ui tests converted nicely. The big effort was the initial conversion of the app to Android, for maintenance I won’t necessarily use LLMs reply amehregan 21 hours agoprevCan vouch- been using this tool the last couple months and it's been magic. It's new so there is definitely a learning curve, but once you get things working it solves the cross-platform problem completely. reply isodev 6 hours agoparentDoes it really? The layouts on Android seem very iOS-y unless you apply \"platform customisation\" but that seems to defeat the purpose of this framework. I think it's a nice toy experiment to cross-compile things but not really transformative enough to be a viable option. Also becoming dependant on a for-profit company to build your app on top of the platform, I think there are others who have tried this as well. reply itake 17 hours agoparentprevwhy is this better than RN or Flutter? Does it make styling easier? like android app can have a material design. reply dkga 17 hours agorootparentI would guess the apps are much lighter and less buggy. reply itake 13 hours agorootparentMaybe? The docs say you have to build the swift app in a weird way (meaning you can't just convert your existing code to the new framework). Doing something non-standard hints bugs to me. reply abewhite 6 hours agorootparentNothing non-standard about it, and you can certainly convert existing code. But if you want to convert an app - as opposed to a framework - you should start with our template and move your code over. The Xcode app project file format is opaque, making it very hard to migrate, and we rely on it being set up in a certain way to be able to build for Android reply banashark 21 hours agoprevLooks very cool! Looking at the docs gives a good overview of how it works. Regarding transpilation and the tradeoffs (https://skip.tools/topic/transpilation-tradeoffs/), does the limitation of certain Swift features cause any significant friction with using parts of SwiftUI or other core libraries? Wondering how much those (understandable) limitations on the transpilation limit what a random iOS dev might be able to do compared to what they can do in iOS land. Also, using SwiftUI cross-platform makes me think that many android libraries would be a no-go. One of the reasons that Xamarin development was painful (other than the numerous bugs in trying to target 2 foreign platforms) was that you couldn't _really_ utilize the large native ecosystems of either platform, and you would end up spending a lot of time \"rewriting\" libraries in dotnet. reply marcprux 21 hours agoparentThanks for the positive words! Any limitations in the transpiler (such as some advanced generics) will only be limitations on the Android side – the iOS side can still do anything that is support in Swift. We discuss this a bit at https://skip.tools/docs/platformcustomization/ > Also, using SwiftUI cross-platform makes me think that many android libraries would be a no-go. A unique feature of Skip is that the Kotlin/Android side is free to integrate with whatever gradle libraries it wants (see https://skip.tools/docs/dependencies/). Similarly, the Swift side can have any SwiftPM dependencies it wants. Only your own transpiled modules, and the core Skip modules, will need to support transpilation. You can then include any native dependencies via your app's transpiled code that branches based on which platform/language you are targeting. So, for example, the Swift/SwiftUI side of the project can depend on the SwiftPM \"https://github.com/firebase/firebase-ios-sdk.git\" dependency, and the Kotlin/Compose side can depend on the Gradle \"com.google.firebase:firebase-bom\" dependency. This is what we ourselves do in the various integration modules we have (such as SkipFirebase, for this particular example). reply dang 21 hours agoparentprev(We moved this comment from https://news.ycombinator.com/item?id=41258356, since that thread didn't get much attention and we invited marcprux to repost this one.) reply wirelesspotat 20 hours agoprevGood to see Skip on the home page! We were evaluating Skip just a couple weeks ago for a side project. The issue we ran into is that we've already built a native iOS app with SwiftUI + a bit of UIKit. Integrating Skip with an existing app seemed like a significant task Does that hold true in your experiences? Do you have any examples of small- or medium-sized existing apps that have migrated to Skip? reply abewhite 20 hours agoparentYes, the docs even say that integrating into an existing app is way harder than starting with a new one! https://skip.tools/docs/gettingstarted/#existing_development reply yumraj 19 hours agorootparentHave not read the docs, but what’s the reason for that? Is it not just a transpiler, since then it should work at any stage. No? reply wahnfrieden 18 hours agorootparentIt’s missing things that are harder to work around if you already have code relying on those missing bits or done in an architecture it can’t transpile reply flawn 20 hours agoprevDamn, this sounds too good to be true. Really nothing to add here except than keep pushing! This fixes the big painpoint that nowadays' cross-platform frameworks come with performance tradeoffs as they have a unified presentation layer! reply happybuy 13 hours agoprevMost existing iOS apps are likely to use a suite of Apple platform frameworks beyond simply pure Swift and SwiftUI. For those cases, Skip's approach seems to be a range of Skip* frameworks that are minimal implementations of the Apple or Android versions. This will likely grow over time, but for most apps it would likely be very limiting at this stage. For instance in my iOS app I use StoreKit, WebKit, SafariServices, UserNotifications and CryptoKit amongst others that have no current implementation when using Skip. reply marcprux 6 hours agoparent> This will likely grow over time This is indeed our primary focus, now that Skip 1.0 is released. We already have a bunch of open-source frameworks that bridge common libraries like WebKit, Firebase, Lottie, SQLite, and more. We expect this ecosystem to grow quickly and organically along with the Skip community. If there are any other frameworks that you commonly use, please let us know (either here, or via any of our support channels) – we will definitely add them to the roadmap. reply isodev 11 hours agoprevI can appreciate the effort of trying to make it easier for iOS developers to also target Android. However, there is no magic solution to cross-platform development. The effort required for the second platform doesn't disappear, it just moves. In the case of this tool, the complexity seems to move into a completely new layer of \"re-implement Apple frameworks\" of libraries + transpiled Swift code to Kotlin. Given that the audience for this framework is mainly iOS developers, support and maintenance for the Android side of things will become an increasing challenge. Perhaps it's easy to get started, but I can't possibly imagine this being easy to maintain several first party releases down't the road. Also, I did a quick look into the transpiled Kotlin code, the output is not at all optimal. reply nivertech 11 hours agoprevCan this tool be combined with LiveView Native (LVN)[1]? LiveView Native has good SwiftUI support on iOS[2], but only basic Jetpack Compose support on Android[3] (I'm not up to date, so things may have changed now). Is it possible to use this project to help with conversion of LVN SwiftUI apps to Jetpack Compose? --- 1. https://github.com/liveview-native 2. https://github.com/liveview-native/liveview-client-swiftui 3. https://github.com/liveview-native/liveview-client-jetpack reply giamma 11 hours agoprevHello, this looks like a cool product, congratulations. How does it handle the different UI guidelines on the two platforms? I have not been using Android for some years, but the first example that comes to my mind is that as far as I remember Android has a platform-level back button, while on iOS each application provides a \"back\" link to be tapped to go back to its previous screen. If I wanted a single code base that followed the recommended UI approach on each platform in order to be as user friendly as possible, would I need to write certain parts twice using #IFDEF or similar blocks? reply abewhite 7 hours agoparentMost Android apps also now include an on-screen back arrow similar to iOS's standard. Designs have converged a lot... probably due to big companies wanting to unify the designs of their iOS and Android apps as much as possible for simplicity. That said, yes, you can easily use #if blocks to write iOS and Android-specific code: https://skip.tools/docs/platformcustomization/ reply sharp11 13 hours agoprevThis looks super interesting, congrats on reaching 1.0! If you do a lot of customization on the Android side, do merge conflicts become a headache? Also, does the Skip plugin assume that you're using Xcode's built-in git? reply Cloudef 13 hours agoprevInteresting. One thing I don't like about flutter is the management of platform specific meta files. How does skip handle this? Do I still have to write bunch of .manifest, res and .plist files per platform? How about screenshot and all the other crap appstore and playstore wants? The flutter projects usually start clean, but then these platform specific hacks start to pile up and it's ugly and annoying to update to later flutter skeleton. reply marcprux 7 hours agoparentWhile the core of your Skip code and resources exists in one or more Swift Package Manager module (which will be transpiled into corresponding Gradle modules), the scaffolding of your actual app is still an Xcode project on the iOS side, and an Android Studio/Gradle project on the Android side. When you create a new project with `skip init`, it will create the two projects for you, along with fastlane configurations for each of the projects. From there, you'll proceed with all the deployment-specific stuff (screenshots, preview videos, metadata, content ratings, etc.) as per each individual store's guidelines. Each side of the project is always an individually valid project, following the corresponding platform's recommended conventions. There aren't any bespoke plist formats or any Skip-specific manifests to deal with, with the exception of one small central \"Skip.env\" file, that contains basic shared information like the app name and version number. reply cmt8 14 hours agoprevThis is really really awesome. The only thing is I feel like it would be heavily reliant on SwiftUI/Jetpack Compose and so breaking changes would break the entire codebase until the tool is updated since there is no 'runtime'. I'm also curious how hacky workarounds would be transpiled over to Compose, since in my experience SwiftUI can involve lots of hacks in order to get something more unconventional working properly. reply jamil7 14 hours agoparentYeah, we still leverage UICollectionView a lot even in SwiftUI as there’s no suitable replacement, grids have a bunch of downsides still right now. reply jamil7 15 hours agoprevGreat work. Cool to see this here, I’ve been meaning to try it. We have two large Swift apps at work that wouldn’t be a good fit but I’ll check it out for a side project. The bulk of our Swift code is actually non-ui code as we have a somewhat complicated data and offline sync layer. We’re actually more interested in the Swift on Android and Wasm developments for this reason which (I saw you’ve also been contributing to the Android Swift toolchain Marc). reply piyushtechsavy 11 hours agoprevThis sounds very cool. We have tried hybrid apps in past and reverted to native implementations due to various issues. Maintaining two code bases was always a problem. Although React native provides way to add native code as well. This can be a changer. reply josh_carterPDX 15 hours agoprevI was just looking through everything and didn't see much when it came to scale. Having been the founder of a devtool platform in the past, one common question we had was what would happen to the platform if someone built the next Flappy Bird. Would we be able to keep up with the insanely fast growth? Have you addressed that with Skip? Looks incredible, btw. :) reply jamil7 14 hours agoparentOne big advantage here is you can “eject” at any point and have two functioning, normal native apps. If you’re talking about scaling a team then you can simply eject and hire for each platform if you outgrow the tool. reply abewhite 15 hours agoparentprevSkip is a locally installed and run dev tool. It is infinitely scalable! :) reply 8mobile 13 hours agoprevHi, Congratulations on the project. I'm trying to port my app to android and skip is making my life easier. Some things are broken but otherwise it works like magic. I'll start testing it with a more complex project. Thanks a lot reply langcss 20 hours agoprevSounds amazing. From a career point of view it is good for a dev as they click up native skills instead of some abstraction layer, while being able to do cross platform. Been a long time since I worked on mobile (pre Kotlin!) but how does it handle differences in the UIs. Do you need \"is android\" directives. Are there Swift objects in your library that are android specific. reply marcprux 19 hours agoparentSince both SwiftUI and Jetpack Compose are declarative and semantic user-interface frameworks, components are generally presented in what the system believes to be the \"correct\" layout. So if you have a `SwiftUI.VStack` (which translates to a Compose `Column`) of buttons and text fields, then they will generally be presented with the \"correct\" spacing and alignment for the platform. That being said, there is often plenty of need for customization with any but the most trivial app. So Skip has a lot of options for that, which is covered in the Platform Customization guide at https://skip.tools/docs/platformcustomization/. reply abewhite 19 hours agoparentprevSkip is definitely a great way to ease into the Android dev world. Lots of options for adding platform-specific code - including being able to directly call Kotlin/Java APIs from your Swift, move back and forth between SwiftUI and Compose, etc. https://skip.tools/docs/platformcustomization/ reply charliesbot 15 hours agoprevHow does it handle cases like Material You Dynamic Colors? I am thinking about making an app, and we want to support the best offerings from each OS. So the dynamic colors is important on the Android side We’ve been thinking about KMP til I read about this, which sounds promising! reply abewhite 15 hours agoparentSkip translates your SwiftUI into Compose, so it uses your Material theme just like any other native Compose app would reply badoongi 13 hours agoprevNice, this somewhat reminds Apportable: https://www.ycombinator.com/companies/apportable reply smusamashah 19 hours agoprevI am not into mobile dev and was just having a look and don't have anything to say on the project itself. The website is very slow to scroll on phone for some reason. Feels like scrolling has smoothing effect applied on it which does not work well everywhere and ends up slowing down scrolling (feels like 10 fps or something). reply marcprux 19 hours agoparentIt's fast for me my on my iPhone 12 Mini (Safari) and Pixel 6 (Chrome). What device and browser are you using? Are any particular pages slower than others? reply vinibrito 16 hours agoprevHow do you handle the minimum denominator issue that is invariably present in all cross platform tools? In other words, what are the sacrifices you made in each platform to make it all work? And why each of these specifically? reply abewhite 14 hours agoparentSkip isn't a minimum denominator framework. With Skip, you write normal iOS code. So you legitimately make zero sacrifices to your iOS app. Now of course Skip can't have complete Android coverage for every iOS framework - far from it. So if you use something on the iOS side that has no Android coverage, you have to create a separate code path for Android, where typically you'll utilize an equivalent Android framework/function. Skip has several mechanisms for integrating Android code, including being able to call Kotlin and Java API directly from your Swift. These mechanisms are also how you can differentiate parts of your Android app as desired, and how we create our own cross-platform libraries. reply dkga 17 hours agoprevExcellent development in the direction of reducing the browser+JS/TS apps! Congratulations! reply gavinh 20 hours agoprev> first-class development environment (Xcode) Are you sure reply scosman 20 hours agoparentAlso giggled at calling Xcode “an Idyllic IDE“. I guess one ugly mobile app IDE is better than two. reply pzo 10 hours agorootparentAndroid studio is miles ahead from xcode this days - I'm envious ios dev. Wouldn't call android studio crappy reply lawgimenez 18 hours agoprevOur Jetpack Compose app is almost done, while our iOS app written in SwiftUI was released earlier this year. I would love to try this but I'm afraid it is too late in the development cycle. I would just like to ask, what Material version are you using? reply pushupentry1219 18 hours agoparentIt looks like 3.0 from the screenshots? But I'm not sure. reply abewhite 18 hours agoparentprevMaterial 3 reply lawgimenez 18 hours agorootparentThanks for making Skip! I will try to contribute to your repo. I lead the mobile team so definitely will evaluate this. reply atentaten 19 hours agoprevHow can I load a library in C or c++ with this in a way that will work in both Android and iOS? reply marcprux 19 hours agoparentGlad you asked! We have an FFI framework (https://skip.tools/docs/modules/skip-ffi/) that enables you to use the same native code on both iOS and Android. I wrote a blog post about it at: https://skip.tools/blog/sharing-c-between-swift-and-kotlin/ . It is what powers some of our own frameworks like SkipSQL (https://skip.tools/docs/modules/skip-sql/). On the Swift/iOS side, it simply uses Swift's excellent C integration; on the Java/Android side, it uses the venerable JNA library to handle loading and calling into embedded native libraries. reply pzo 11 hours agorootparentWill this work seemlesly with C only or C++ as well? I know swift this days have good c++ interop but not sure about jni/jna reply marcprux 7 hours agorootparentYou are correct that JNA's C++ integration – while possible – is not exactly seamless. It is an area that we are actively researching better solutions for. reply grounder 16 hours agoprevLooks interesting. Does it support things like the device camera? reply dilliwal 12 hours agoprevI was following your youtube videos and was quite excited for the release, going to give it a try. reply billylo 17 hours agoprevPricing link: https://skip.tools/pricing/ reply yumraj 17 hours agoparentSo far all looks interesting. The only thing that I’m still wrapping my head around is the pricing/licensing for “indie” If I may suggest, instead of 6 month audit and machine locked license, perhaps something like where license is needed IFF the app is launched. This will reduce friction for individuals and pre-funding startups. I believe Unity and Unreal use this kind of licensing. reply pzo 9 hours agorootparentFor me for \"Indie\" pricing is not clear what it means \"members with less than 30K USD related annual revenue\" Does it mean less than 30k revenue from app using Skip? Or any revenue such developer has? If the latter then any freelancer or indie will not qualify if have monthly salaries >2500usd doing any IT stuff or app dev using different frameworks. reply yumraj 1 hour agorootparentYes, their pricing/licensing is not ideal at the moment, IMHO of course. They need to build critical mass and hence initial tinkering should be as friction free as possible. Landscape is full of alternatives so people need to get started as quickly as possible. They seem to have a valuable product, but this initial friction might reduce traction, again IMHO. reply s_dev 6 hours agoparentprevIf I learned anything from expo -- get signed up so you can get grandfathered in to future plans. They're almost gonna certainly increase prices. reply yumraj 1 hour agorootparentFirst they have to gain critical mass. Not sure what was Expo’s initial pricing like. reply mariocesar 20 hours agoprevAre there showcase apps? A \"Built with Skip\" list? reply marcprux 19 hours agoparentWe do have a showcase app, literally called \"Showcase\": https://skip.tools/docs/samples/skipapp-showcase/. It is available on both the Apple App Store and Google Play Store, so you can compare the two experiences side-by-side, if you have both an iOS and Android device. No \"built with\" list yet, but coming soon… reply nyrulez 19 hours agorootparenttbh this is the main thing I was looking for on the webpage. It's hard for me to jump ship from my existing workflows unless I see a professional and highly sophisticated app example. I am sure it works for simple cases but I am concerned about limitations that one hits as one does more complex things reply marcprux 19 hours agorootparentOut of curiosity, what are your existing workflows? Note that Skip doesn't put any constraints on the iOS side of your app at all: if it can be expressed with SwiftUI or UIKit, then you can do anything. If there are bits that SkipUI doesn't translate to your liking (or at all), you can always drop down directly into Kotlin and Jetpack Compose to implement those any way you want. See https://skip.tools/docs/platformcustomization/ for details. reply yumraj 18 hours agorootparentHow does it work in practice? In other words the Swift app will keep developing, requiring constant Android app generation via transpilation. Does it keep track of generated and manually edited parts or will that step on each other? reply abewhite 18 hours agorootparentTo answer the other part of your question: you don’t manually edit the generated Kotlin. Instead there are mechanisms for writing Kotlin inline in your Swift, dropping Kotlin files into the project, and other platform customization options: https://skip.tools/docs/platformcustomization/ reply marcprux 18 hours agorootparentprevThe Skip transpiler runs locally on every build. It is implemented as an Xcode build plugin, so it is transparent and instantaneous. Every change you make to the Swift code is immediately converted into Kotlin, so each time you launch the app in the iPhone Simulator, the Android app will launch next to it in the Android Emulator. For a good overview of this process, take a look at: https://skip.tools/tour/skip-showreel/ reply yumraj 17 hours agorootparentThat I had understood, I was looking for what @abewhite replied. reply yumraj 19 hours agoprevGiven that this is now production ready, any limitations one needs to be aware of? Please feel free to point to a doc that may already answer that. reply marcprux 18 hours agoparentTo put the question in context, I'll preface by saying that Skip is unique among cross-platform app development solutions in that it isn't imposing an \"alien\" language or runtime on your app. It uses Swift on iOS, and Kotlin on Android, which are both the first-class recommended development languages for the respective devices. Any translation limitations can always be overcome by branching on the platform/language you are using, and just writing custom code for the platform in question. That being said, while we have good translation coverage at both the lower levels (Foundation to the Android SDK) and higher levels (SwiftUI to Jetpack Compose), there are many Apple frameworks that we simply don't have any compatibility frameworks for yet. One commonly-request example is maps: we don't have anything that takes the MapKit API and converts into the Google Maps equivalent. However, this doesn't prevent you from implementing it yourself. For a simple example, see the Travel Bookings sample demo at 2:15 at https://skip.tools/tour/skip-showreel/, where you can see how you can drop MapKit and Compose Maps inline into your code. As time goes on, Skip's community ecosystem of compatibility frameworks will grow and expand. But until then, there aren't any barriers to simply implementing them yourself. reply yumraj 17 hours agorootparentMakes sense.. so any limitations are going to be on Android side, which if I understand correctly can just be implemented directly in Kotlin. reply thomasswift 20 hours agoprevThis looks great! Thanks for sharing here. reply thomaskang08 16 hours agoprevThis is magical. Almost too good to be true. I hope this is indeed production ready. reply preciousoo 15 hours agoprevI was wondering a while back if a tool like this existed. Good job! reply neil459 6 hours agoprev [–] Sorry, but I don't have and won't install brew. It is just too undesciplined. Otherwise, looks like a good tool I could use. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Skip.tools, co-created by Marc, transpiles SwiftUI iOS apps into Kotlin Jetpack Compose apps, enabling the use of a single language for both iOS and Android.",
      "Unlike other cross-platform tools, Skip generates genuinely native apps for both platforms without embedding a separate engine, ensuring platform-native controls and features.",
      "After a year of development, Skip has released version 1.0, ready for production use, and includes support for popular frameworks like SQLite, Firebase, and Lottie."
    ],
    "commentSummary": [
      "Skip.tools has released version 1.0, enabling developers to build native iOS and Android apps from a single Swift codebase by transpiling SwiftUI into Kotlin Jetpack Compose.",
      "Unlike other cross-platform tools, Skip creates genuinely native applications without embedding a separate engine or runtime, allowing the use of native debugging tools.",
      "The release includes a Swift Package Manager plugin called \"skipstone\" and supports popular frameworks like SQLite, Firebase, and Lottie, with extensive documentation and open-source modules available on GitHub."
    ],
    "points": 269,
    "commentCount": 97,
    "retryCount": 0,
    "time": 1724877869
  },
  {
    "id": 41385546,
    "title": "A post by Guido van Rossum removed for violating Python community guidelines",
    "originLink": "https://discuss.python.org/t/should-we-consider-ranked-choice-voting-for-sc-elections/61880",
    "originBody": "Gregory P. SmithgpsheadSteering Council Member 5d Speaking for myself: Summary I propose changing our Steering Council election process from simple approval voting to a ranked choice system to better capture voter preferences and provide more meaningful feedback to candidates. I want your input to know if this is worth pursuing. Background Our PEP-13 7 voting method has remained unchanged since late 2019. While functional, the simple approval voting system has limitations we should address. Current Limitations No Preference Expression: Voters can’t express preferences among approved candidates. Encourages Strategic Voting: The current system incentivizes limiting approvals, potentially distorting true preferences. Here’s why: In simple approval voting, each approved candidate gets equal weight. To give stronger support to preferred candidates, voters may withhold approval from candidates they actually find acceptable but less preferable. This creates a dilemma: approve more candidates and dilute the impact of your vote, or approve fewer to strengthen support for top choices but potentially harm acceptable alternatives. As a result, voters might not express their true preferences, instead engaging in strategic approval to maximize their vote’s impact. Limited Feedback: Candidates receive only binary “approval” feedback, which can be discouraging and doesn’t reflect actual voter sentiment. Proposed Solution: Ranked Choice Voting Ranked choice voting would allow voters to rank candidates in order of preference, offering: Better Preference Capture: Voters express their full range of preferences. Less Strategic Voting: Reduced need to “game” the system by selective approval. Nuanced Feedback: Candidates receive more detailed information about their support. Implementation Considerations Voters would rank only as many candidates as they wish. The PSF already handles the implementation and administration of the current SC voting process. They would likely extend this role to manage the ranked choice voting system, given sufficient notice. I would not assume such a change is possible for this years election. Historical Context While we used ranked choice voting to select our governance model (PEP 8001 3), as far as my limited searching could find, we haven’t discussed it for Steering Council elections. Please link to more context if that isn’t true. Next Steps Gather community feedback on this proposal. (that’s you!) If there’s sufficient interest, conduct a straw poll here. If supported, draft a formal proposal to vote to adjust PEP-13’s voting method. Questions for y’all Is this change worth pursuing? What benefits or drawbacks do you see in switching to ranked choice voting? Should we consider other voting methods? If so, why? I encourage everyone to share their thoughts. I wouldn’t want to move forward with this without obviously clear support. My take: I don’t believe it is knowable if this would change the outcome of our elections or not, but if nothing else it should be a better experience for voters and candidates alike. While the topic has come up in passing at times, I have not discussed this proposal with the rest of the steering council. The SC doesn’t decide this anyways - thus taking it directly to all of you. 1 Reply 13 9.7k views 105 likes 30 links 11 users 2 2 2 2 read 6 min Top replies",
    "commentLink": "https://news.ycombinator.com/item?id=41385546",
    "commentBody": "A post by Guido van Rossum removed for violating Python community guidelines (python.org)221 points by oblvious-earth 19 hours agohidepastfavorite211 comments oblvious-earth 19 hours agoThe original text stated: > I don’t know much about voting systems, but I know someone who does. Unfortunately he’s currently banned. Maybe we can wait until his 3-month ban expires and ask him for advice? Currently, the text reads: > This post was flagged by the community and is temporarily hidden. Since it has been hidden for more than 24 hours, this suggests that a moderator action has marked it as permanently hidden. Due to a recent decision, this means no one outside of the moderators or admins can view it: https://discuss.python.org/t/moderated-posts-are-no-longer-p... Edit: I meant to post slightly more direct link in title: https://discuss.python.org/t/should-we-consider-ranked-choic... Edit 2: Some comments suggest that Guido was banned from posting, but this is not accurate. I have edited the title from \"Guido van Rossum's Post Removed for Violating Python Community Guidelines\" to \"A Post by Guido van Rossum Removed for Violating Python Community Guidelines\" to clarify what actually happened. reply EvanAnderson 19 hours agoparentI'm an outsider who only knows Guido van Rossum by way of interviews his writing. Assuming your quote is what the original text said (I don't disbelieve you-- but nobody can see it to confirm) why would this have violated community standards? Is there some rule about not mentioning \"un-persons\" or something? It's very confusing. Edit: Answering my own question. There appears to be a kerfuffle afoot. Apparently the Steering Council has suspended a core developer for 3 months[0] but isn't naming the suspended developer or citing specific reasons why (per [1] and sparking a call for a vote of no confidence in the council which did not succeed). Apparently even mentioning the suspended person (without naming them) is enough for even Guido van Rossum to be censored. Wow. Edit 2: The suspended developer is Tim Peters[3]. Edit 3: Altered paragraph \"Edit:\" from \"...or the reason why[1] (\" to \"...or citing specific reasons why (per [1]\". Edit 4: Added \"which did not succeed\" after \"...vote of no confidence in the council\". [0] https://discuss.python.org/t/three-month-suspension-for-a-co... [1] https://discuss.python.org/t/calling-for-a-vote-of-no-confid... [3] https://chrismcdonough.substack.com/p/the-shameful-defenestr... reply krick 17 hours agorootparentThat's kinda nuts, but kinda absolutely in line with all trends of the last 5 years. I remember similar shit happening in Linux community (the shit won, naturally). But, anyway, who is the \"Steering Council\" and how come they have more influence than the 2 people who basically created python the language and python the community? reply zitterbewegung 17 hours agorootparentWhen Guido stopped being the sole leader (BDFL) he was replaced by the steering council which is elected and has the purpose of doing the following (Defined in PEP 13 which is the current governance model of Python. Right now Guido is a core developer at this time. See https://peps.python.org/pep-0013/#the-steering-council reply krick 17 hours agorootparentThat's pretty obvious. The question was, who are these people, specifically, and why they were chosen and given that much power. I mean, I can see the names, but while I don't have to be told who Tim Peters or Guido van Rossum are, I have no clue who these guys are and what their actual contributions are. reply dekhn 2 hours agorootparentGregory P. Smith Emily Morehouse Barry Warsaw Thomas Wouter I've worked with gps and twouter before at Google; they were two of the leaders of the python ecosystem. twouter is a highly technically skilled contributor- when I found a 2 bugs in the Python runtime, he was the person who helped me fix them (bug 1: RPC calls from C++ to Python delivered during interpreter shutdown caused crash, bug 2: importing the same library twice with two different names caused crash) upstream. gps apparently is a core contributor to cpython but I he did mainly administrative work afaict when I was at Google. From what I can tell, gps is the primary instigator in this incident. Barry Warsaw: was lead maintainer of jython, I think also involved in the guts of cpython for some time. Emily Morehouse: I hadn't heard of her before but it looks like she is a core python developer: https://emilyemorehouse.com/blog/015-my-path-to-becoming-a-p... who implemented some key PEPs. reply stogot 15 hours agorootparentprevIn line with the trends, as the grandparent said. People who claim tolerance are intolerant reply joshuamorton 37 minutes agorootparentprevThere is an election process, and all core python team members vote on the SC (https://peps.python.org/pep-8105/#results) for a 1-year term. Greg, Thomas, and Barry are all old guard (20+ years as core devs), Emily and Pablo are relatively more recent, but still have 5+ years as core devs and are I believe more actively doing python feature development. All of these folks have served on the steering council before, some for 3-4 years. Guido has served on the SC before, but has been stepping back recently. reply zahlman 2 hours agorootparentprev> The question was, who are these people, specifically, and why they were chosen and given that much power. They are core developers elected by an internal process among the developers. See PEP 13 for details: https://peps.python.org/pep-0013/#the-steering-council > I have no clue who these guys are and what their actual contributions are. Barry Warsaw (https://barry.warsaw.us) is another of the \"old guard\" who can be pictured standing next to Peters and GvR fairly easily. He gained the title of \"Friendly Language Uncle For Life\" (FLUFL), and has previously been the project lead for Mailman and lead maintainer for Jython. He was the release manager for Python 2.2 (as far as I can tell, the first time this position existed), 2.6 and 3.0, and shared the role for 2.3. His name is all over 2.x-era process documentation. Prior to GvR's actual retirement in 2018, there was an April Fools' Day announcement of his resignation in 2009, authored by Barry Warsaw and Brett Cannon. This was accompanied by a hidden option (still available!) which changes the `!=` syntax to ``. Refs: https://stackoverflow.com/questions/4007289/ ; https://peps.python.org/pep-0401/ . Emily Morehouse (https://emilyemorehouse.com/) was the PyCon co-chair for 2019 and chair for 2020 and 2021. She has done project management for Axios and mentoring for PyLadies (https://discuss.python.org/t/steering-council-nomination-emi...). Gregory P. Smith has been a core dev since about 2003 and has notably worked on `hashlib` and `subprocess` (https://discuss.python.org/t/steering-council-nomination-gre...). Pablo Galindo Salgado (https://github.com/pablogsal) was the release manager for 3.10 and 3.11, and Thomas Wouters was/is the release manager for 3.12 and 3.13. Wouters has also previously served as a PSF Board member and was a PSF founder (https://www.python.org/nominations/elections/2020-python-sof...). reply plg94 9 hours agorootparentprevI don't have a factual answer for you (be interested in one, too), only a cheek-in-tongue one: It's like politics, the only thing you have to do to get elected is to get people to vote for you. And often the vote is only among people who _want_ to be elected (and in a position of power), massively reducing the pool of good candidates. reply germanjoey 18 hours agorootparentprevLooks like some kind of power play... Originally discussed here: https://news.ycombinator.com/item?id=41234180 reply PaulHoule 18 hours agorootparentMy experience is that discussions of bylaw changes tend to get heated and that trying to change your bylaws is like Russian Roulette, that is maybe 1/6 of the time there is some disaster which is either the end of he organization or that results in a major loss of members. reply lovecg 18 hours agorootparentprevWow, just wow. Reading all these makes me really worried about supporting anything built on Python long term. This creates an impression of a self-destructing dying community. reply BadHumans 17 hours agorootparentThis is silly. The Python Foundation could die tonight and people will still build in Python for years to come because believe it or not, most people do not know or care about the happenings of these organizations. reply kamaal 9 hours agorootparentYeah, but my experience with Perl shows, once something like this happens, its pretty much downhill from there. Not saying Python is going away tomorrow, in fact it might remain actively developed and used for decades to come. But with proactive thought, improvement and initiative gone. Competition will replace you in time. That's just how it works. reply gtirloni 17 hours agorootparentprevnext [3 more] [flagged] tourmalinetaco 17 hours agorootparentNo, it is pure 1984. Censorious nonsense spearheaded by those who are held unaccountable for their actions. The fact that this came about on a topic of voting systems is even more ironic. reply gtirloni 8 hours agorootparentI was replying to the comment, not the whole thread. reply bun_terminator 10 hours agorootparentprevAlso see for the last python release notes for some hardcore politics injected right into your tooling language. Python is unfortunately radioactive and can't be used responsibly anymore. They're halfway to selfdestruction reply xigoi 9 hours agorootparentWhat specifically are you talking about? I couldn’t find anything political in the Python 3.12 release notes. reply gaganyaan 9 hours agorootparentThey probably mean the poem at the bottom here: https://www.python.org/downloads/release/python-3120/ Under \"And now for something completely different\" reply xigoi 8 hours agorootparentAh. That’s really inappropriate for a technical document. reply srid 4 hours agorootparentUnnecessary politics in certain tech spheres is still a norm. For example, here's GNOME the desktop being concerned about climate change: https://discourse.gnome.org/t/question-to-candidates-the-boa... reply consteval 4 hours agorootparentOh come on guys, this is silly. We're all gonna stop using a tool because they offhand mentioned something we don't agree with? I mean, these tools are developed by people - people have opinions. I understand politics is very divisive, but why is everyone acting like a baby? Just move on. Who cares. Python is a language, who gives a fuck they included a poem about immigration? I'm convinced nobody even found this poem organically anyway, rather one person found it and then sent it around to all their like-minded friends so they can sit around and point and laugh and complain together. You're telling me y'all ACTUALLY found this webpage and scrolled through it organically? Come oooooon. reply zahlman 2 hours agorootparent> We're all gonna stop using a tool because they offhand mentioned something we don't agree with? No. Well, I'm not, anyway - despite my skin in the game (https://zahlman.github.io/politics/the-psf/2024/07/31/an-ope...). But I am going to offer harsh criticism of those who abuse their platforms. This sort of thing is nothing new in Python circles. It notably led to Jack Diederich's resignation from the PSF in June 2020 (https://discuss.python.org/t/the-psf-should-be-less-politica...) and may have contributed to the mass exodus of core devs in November 2020. > why is everyone acting like a baby? Just move on. Who cares. Python is a language, who gives a fuck My understanding is that a higher standard of discourse is expected on HN. Also, I rather suspect your tone would be different if you didn't happen to agree with the message. Please consider that such bias is not in keeping with the spirit of the free exchange of ideas or the core principles of open source. > You're telling me y'all ACTUALLY found this webpage and scrolled through it organically? Yes. This page is the official, primary means by which the Python team announces a new release of Python. That's kind of a big deal. reply xigoi 1 hour agorootparentprevA programming language is a tool. It should not have an official stance on political issues, whether you agree with it or not. reply bun_terminator 2 hours agorootparentprevWould you feel the same way if the message was \"make America great again\"? And yes I did remove python from a big private repo and will argue against it at work when the question arises. reply bun_terminator 2 hours agorootparentprevThe spicy bit is that this is the first release that contained such a political message. And also the first one that is managed by the guy who started the mess of this post, too! Not exactly sure if he's the one who put it in there, but it's one heck of a coincidence. reply zaptheimpaler 18 hours agorootparentprevRe: the vote of no confidence [1]. Looks like most devs disagreed with the vote and have opted to let the council continue but transfer the \"HR\" Code of Conduct duties to the PSF. [1] https://discuss.python.org/t/calling-for-a-vote-of-no-confid... reply dilap 16 hours agorootparentprevThey suspended Tim Peters? That is insane. reply threatofrain 15 hours agorootparentThe Python steering committee also threw the kitchen sink of accusations at him. IMO it speaks to character when you throw arguments like an adversarial lawyer. Not the kind of person you want to be around for work or life. reply zahlman 2 hours agorootparentTo be clear, the accusations in question came from the Code of Conduct Work Group; the Steering Council simply \"acted on their recommendations\". I don't expect any positive changes if said Work Group becomes directly responsible for such disciplinary actions. reply rjmorris 18 hours agorootparentprevI don't understand why you said they didn't explain the reason for the 3-month ban. Your link [0] lays out the reasons. reply EvanAnderson 18 hours agorootparentI badly paraphrased what citation [1] said. I've dropped on an edit. (I have no dog in this race, other than thinking that Python is a pretty important software project. I didn't mean to editorialize.) reply mc32 18 hours agorootparentprevWhat the hell, has everyone caught and gone gung-ho on censorship? What the actual f*** is this? How in the hell do you have the balls or ovaries to ban the creator --for something so inane. It's like a highscool supe who gets no respect and will at every chance show you the little power she has in such a classless way. So utterly petty defying belief. I hope those dweebs get voted out pronto. That's an absurd abuse of power. People who trip like that have no business having any power or control. reply zaptheimpaler 18 hours agorootparentMost people haven't gone crazy, the kinds of people on this board are experts in silencing dissent and making it appear that way. I really hope the Python community can hold an open poll or discussion on a forum not controlled by the fascists and force the board to resign. reply khazhoux 18 hours agorootparentprev> gung-ho on censorship? What the actual f** is this? Unintenti**l irony reply the_real_cher 17 hours agorootparentthere's a difference between being polite and having your post removed entirely reply tourmalinetaco 17 hours agorootparentOf course, but it still elicits a reasonable chuckle. reply mc32 18 hours agorootparentprevI hope that's just a rib. Else, one should be able to tell self control over stamping authority over others. Very few people openly speak their inner monologue, uncensored just releasing their stream of consciousness like a delirious hobo down a stench filled alleyway. reply beedeebeedee 17 hours agorootparentI speak my \"inner monologue\" and it is nothing like delirium or stench. Not sure who you are or who you're hanging out with, but better to get the stench out than let it fester. reply khazhoux 17 hours agorootparentprevIt was funny that you censored yourself, in a comment about censorship, that's all :-) reply plg94 9 hours agorootparentprevYou did have any opportunity to rewrite your sentence to use any other word than f**, one that did not require self-censoring. Yet you did not. Why? reply FireBeyond 17 hours agorootparentprev> It's like a highscool supe who gets no respect and will at every chance show you the little power Sayre's Law, effectively, the smaller the stakes the bigger the fights/politics. See also: HOAs, academia. reply yarg 18 hours agorootparentprevnext [15 more] [flagged] khazhoux 17 hours agorootparentYou are making a general point, but does it apply specifically? Here's the Python Code of Conduct for communication on official Python forums, and comm+behavior at official Python events: https://policies.python.org/python.org/code-of-conduct What specific items do you disagree with? * The top section \"Our Community\" is just general stuff like \"be respectful.\" Is that a problem? * The list of \"Inappropriate Behavior\" for meatspace Python events, what is wrong with it? Harassment, Deliberate intimidation, stalking, Incitement of violence, Insults, put downs, or jokes that are based upon stereotypes... I'm sure we will all find some items we disagree with (really, no reference to \"hugs\"???) but you are challenging the very premise of a CoC. reply tfhag 17 hours agorootparentThe problem is selective enforcement and different interpretation of the listed terms. The Steering Council itself has been guilty of at least (verbal) harassment, insults, put downs and sarcastic jokes. But they are safe. reply zahlman 1 hour agorootparentprev> You are making a general point, but does it apply specifically? Yes. What you are missing is the separate \"Enforcement Procedures\" section: https://policies.python.org/python.org/code-of-conduct/Enfor... . Some quotes: > If the incident occurred outside the community, but a community member's mental health or physical safety may be negatively impacted if no action is taken, the incident may be in scope. IOW: they hold themselves free to go after people for stating political opinions entirely outside of any Python-related context, if someone else in a Python space deems those opinions sufficiently traumatizing. > Does this pose a safety risk? Does the behavior put a person's physical safety at risk? Will this incident severely negatively impact someone's mental health? Again, getting \"triggered\" by something is considered a matter of \"safety\". Some people are apparently fragile, and not responsible for their own actions, while others have a moral duty not to offend them. > A person who makes a report should receive a follow-up email stating what action was taken in response to the report. If the work group decided no response was needed, they should provide an email explaining why it was not a Code of Conduct violation. Reports that are not made in good faith (such as \"reverse sexism\" or \"reverse racism\") may receive no response. IOW: you have no recourse if people discriminate against you for being white or for being male. Not only that, but proposing that such a thing occurred is considered inherently \"bad faith\". And they will stuff terms in your mouth for this that you didn't actually use. [0] But not only that, when I was banned, they held up such an argument (by the way, the accusation that I even made such an argument was completely false) as itself a Code of Conduct violation, despite no language in that document which could possibly support such a claim. Speaking of which, they don't even follow these procedures if they're inconvenient. See the \"Follow up with the reported person\" section? None of that bears any resemblance to how I was treated. (Not that it could, because I did nothing wrong and my \"behaviour\" had no reasonable \"negative impact\". [1]) There are tons of other \"cultural\" aspects you seem to be unaware of here. For example, defenders of the Work Group and their policies will constantly bring up (without naming names, as if anyone were unaware) the Adria Richards \"Donglegate\" incident from PyCon 2013. This is always described as a cautionary tale about what might happen to others like Richards without their CoC enforcement. It is never mentioned that Richards eavesdropped on a private conversation, took offense to a joke not intended to cause harm to anyone (and not even jokingly proposing any harmful idea!), and then ignored all the incident reporting procedures in the newly written PyCon CoC, opting instead to skip straight to social media for a round of public shaming. [0] It's people with this political position who use the terms \"reverse sexism\" and \"reverse racism\"; people who correctly recognize the fact that racism can victimize white people (and be directly the fault of people who are not white, acting fully on their own agency) also correctly just call it \"racism\". Similarly for sexism. [1] If you don't take that at face value, you are welcome to read my own backup of my posts related to the banning: https://zahlman.github.io/dpo_archive/ . reply tourmalinetaco 17 hours agorootparentprevI am challenging the very premise of a CoC. They are useless newspeak documents made only to enforce the ideology of those in positions of power and not benefit the project. “Don’t be an ass” is standard fare in polite society. Do you need to be told “don’t scream at people” every day when you leave the house? Perhaps those with low inhibition and self-control need such a reminder, but I would argue those are the ones enforcing them the hardest. They are redundant in every form and your argument is reductive. “See? You can’t complain about this part, it’s standard etiquette! And even if you do disagree, don’t we all find things we disagree with?” It ignores the entirety of the point, which is that the sum of a CoC is torturous to a project, and makes it unlikely people will want to play ball with a project due to their loaded nature. CoCs were invented by non-programmers to push ideological beliefs to programmers, and was accepted because they weren’t immediately toxic to the community. Akin to a cancer taking time to spread. reply userbinator 17 hours agorootparentprevIt's starting to swing back already, as people are beginning to realise where this ~decade of identity-over-competence is leading us. reply yarg 16 hours agorootparentI think people are starting to see the long term consequences now; but the problem has been building for decades. You don't get every university across every ostensible democracy banning free speech yet permitting physical violence against 'the far right' over night. You need to subvert and replace the establishment piece by piece. What we're seeing now is what happens when that sort of incompetence starts to impact manufacturing, engineering, production and the training the people in the field. So the whole damned thing is turned on its head; Here's an example: during Covid, the only people who were not purged from the medical establishment were those who adhered to the narrative. That's disturbing - the so called health care system intentionally purged of any person critical enough to question that narrative. And even now that health care system retains the same personal and repeats that same line. (If you really wanna know what the actual numbers look like the only people with numbers that can be trusted are funeral homes and insurance providers.) But right now (in the middle of a health care crisis) some of the most competent doctors, nurses, etc remain unable to work because of mandates for them to undergo an invasive experimental procedure (from some of the least trustworthy companies in the world). (That is to say, any bloody doctor I'd be even remotely inclined to trust with my wellbeing.) Competency purged; 100 flowers pruned. I could go on and on, but I shouldn't, so I won't. Adios. reply canadianfella 17 hours agorootparentprevTry posting something critical of the cult on r/conservative. There’s nothing uniquely leftist about censorship. reply yarg 17 hours agorootparentI can't; I got permabanned from the site for hate speech. What did I say? That it's unfair for men to compete in women's sports and that TRAs use bad faith tactics like deplatforming as a means to silence their critics and avoid debate. The weaponisation of censorship is predominantly a far left tactic. reply bb88 16 hours agorootparent> The weaponisation of censorship is predominantly a far left tactic. Incorrect. It's an authoritarian tactic, which can either be left or right. On the right today is Idaho with their new book banning law prohibiting minors from accessing books with LGBTQ+ themes (regardless of whether there was any sex or not). On the left, you have Tipper Gore which was famous for advocating for the sticker placed on CD's to alert people of potentially terrible lyrics. reply Izkata 15 hours agorootparent> On the right today is Idaho with their new book banning law prohibiting minors from accessing books with LGBTQ+ themes (regardless of whether there was any sex or not). This is misleading. It's against anything pornographic being made accessible in schools / to people under 18 years old, LGBT or otherwise. \"Homosexuality\" is mentioned only once: > 3. \"Sexual conduct\" means any act of masturbation, homosexuality, sexual intercourse, or physical contact with a person's clothed or unclothed genitals, pubic area, buttocks or, if such person be a female, the breast. In a section that's 11 points long. Besides which, this whole section already existed, it was just amended recently and this part I quoted wasn't changed. reply bb88 13 hours agorootparentThere is nothing that in the law that allows the libraries to defend whether a book is harmful to minors once the challenge is made. So any challenged books have to go into the adults-only section. 26% of books challenged in 2023 had no sexual content. Since the library has their hands tied, those books must go into the adults only section. Including the books on Rosa Parks. https://idaholibraries.wildapricot.org/resources/Documents/C... reply yarg 16 hours agorootparentprevI'm sorry, do you really need to be so damned pedantic? Today - in the present, given the relative levels of influence of the different authoritarian groups, it is predominantly the far left that is engaged in the weaponisation of censorship. I can't take the children's library arguments seriously any more. Right now there are books in school libraries that are too obscene to be read from in council meetings. reply bb88 15 hours agorootparent> do you really need to be so damned pedantic? This is HN. Pedantry is a badge of honor. /s Seriously though the facts aren't in your favor. I call BS on your primary thesis. reply yeahwhatever10 18 hours agorootparentprevDown voting this comment is burying your head in the sand. Censorship has been and will continue to be one the primary political fights of the 20s. They just arrested the Telegram founder a few days ago... reply zahlman 3 hours agorootparentprev> why would this have violated community standards? Is there some rule about not mentioning \"un-persons\" or something? Flags may be cast by anyone, and this will eventually result in automatic hiding - flags on Discourse are weighted according to the \"trust level\" of those raising them. My guess is that people perceived this as a passive-aggressive objection to Tim Peters' suspension. It has definitely been permitted up until now to refer to this (although everyone seemed to be avoiding the name on principle), but there seems to be an expectation that people should \"read the air\" now and stop talking about it - hence posts like https://discuss.python.org/t/moderated-posts-are-no-longer-p... and https://discuss.python.org/t/pr-disaster-surrounding-recent-... . > and sparking a call for a vote of no confidence in the council which did not succeed The call was retracted, which is not surprising. The Steering Council isn't the root of the problem, anyway. That would be the Code of Conduct Work Group (https://www.python.org/psf/workgroups/#code-of-conduct-work-...), which is not elected (https://wiki.python.org/psf/ConductWG/Charter#Membership), has membership overlapping other important groups (4 of them are on the PSF Board of Directors - https://www.python.org/psf/board/#id3 - and Brett Cannon and Łukasz Langa are Discourse forum moderators) and enforces the Code of Conduct according to hidden rules that betray the neutrality of that document (https://policies.python.org/python.org/code-of-conduct/Enfor...) counter to the wishes of one of the original drafters of said document (https://discuss.python.org/t/why-i-am-withdrawing-fellowship... ; https://discuss.python.org/t/why-im-leaving-discuss-python-o... etc.). It's also noteworthy that the Steering Council - consisting of 5 core devs - apparently also now requires a \"communications liaison\" (https://www.notion.so/46aec24028fd4e8dbdba003097c18b5b?pvs=2...) who gets a glowing write-up in official updates on the forum (such as https://discuss.python.org/t/steering-council-updates-for-ju...) - which are not posted by said liaison. I have no idea why this should be necessary, nor is there anything in PEP 13 (https://peps.python.org/pep-0013/) about this position existing. It seems that this person was selected entirely out-of-process. reply holsta 8 hours agorootparentprevnext [3 more] [flagged] bitcharmer 2 hours agorootparentWhat does reverse racism mean? reply zahlman 1 hour agorootparentThere exists an argument that people who are not white are, in fact, capable of saying or doing things which tend to discriminate against white people; and furthermore that such speech and action is harmful and morally offensive. \"reverse racism\" is a term used by people who find that position disagreeable or inconvenient, to mislabel, misrepresent and mock it. The argument is not at all \"far right\"; it's centrist, and obvious. But certain extremist identity-based ideologues have manage to sell that nonsense with their propaganda based on the label. Occasionally you will see people who don't know any better use the term unironically, because of the dominance its derogatory use has achieved; but serious opposition to so-called \"progressive\" identity politics does not actually use the term. reply rdtsc 18 hours agoparentprevWonder if the moderators heard about the Streisand Effect. It’s a good time to learn about it. > I don’t know much about voting systems, but I know someone who does. Unfortunately he’s currently banned. Maybe we can wait until his 3-month ban expires and ask him for advice? So he was banned for asking about someone who knows about voting. Transitive meta banning? I guess anyone asking about Guido’s post will also get banned. reply _0ffh 19 hours agoparentprev> this means no one outside of the moderators or admins can view it Imo that kind of deliberate intransparency is a massive red flag. Here for example I can choose to see hidden comments and make up my own mind about the content, which is excellent. Even if I don't use the feature, the fact that I could if I wanted to is a massive plus for trust in the process. reply Dotnaught 19 minutes agoparentprevFWIW, the post appears to have been restored. The cited original text is visible presently. reply Lockal 13 hours agoparentprevThis post was unflagged few moments ago, also received 20 likes (from 7 to 27) for last hour. reply srid 2 hours agorootparentProbably because it gained attention on HN? The same cannot be said for in-numerous other acts of flagging and hiding. Almost all posts from Clay in this thread has been flagged and hidden; you can't even make sense of Guido's replies to him because of that. https://discuss.python.org/t/approval-voting-vs-instant-runo... reply oblvious-earth 12 hours agorootparentprevThanks for the update, unfortunately I can no longer edit my top comment or title to reflect this. Would be happy for admin to do so, if that's something that's done on this site. reply rich_sasha 12 hours agoparentprevAre we all going to get banned for mentioning a post that mentions a ban? reply lupire 17 hours agoparentprevYour two versions of the title say the same thing. reply aldfgH 18 hours agoprevThese are not \"Python community guidelines\". These are the guidelines of a tyrannical clique who have grabbed power and control the access to the infrastructure. They abuse their power by banning any opposition and then using said infrastructure to libel and defame their opponents. Google already fired one or two of them. I do not know what is required to restore the health of Python. reply zahlman 1 hour agoparent>Google already fired one or two of them. I would appreciate more information about this. reply mixmastamyk 18 hours agoparentprevFired who? reply bitcharmer 11 hours agoparentprevIt's funny how drama, toxicity and speech suppresion ensues as soon as you establish a CoC and let a bunch of SJWs enforce it. Every. Single. Time. reply at_a_remove 9 hours agorootparentI would like to see more instances of this kind of thing going on, the fallout, and so on. reply DoctorOetker 10 hours agorootparentprevSimilarly (un)funny how the technology behind blockchains, formal verification, and decentralization is ridiculed on the basis of inefficiency etc., Every. Single. Time. given such a governance structure would be so much harder for the legalese power trippers to regulatory capture... reply infamia 16 hours agoprev\"We've found a witch may we burn her?!\" -- Monty Python and the Holy Grail (also the PSF lately) https://youtu.be/X2xlQaimsGg?feature=shared&t=13 FYI, Python is named after Monty Python , who got into all kinds of trouble making fun of and saying things that upset basically everyone (religion to LGBT), which is ironic considering the circumstances. reply nromiun 15 hours agoprevVery sad to see this happening to the Python community. Maybe we need a fork with only technical discussion allowed. This CoC/vote stuff seems to poison every community it touches. reply gorgoiler 14 hours agoparentI think the politics of power is unavoidable no matter how well you silo your technical work from your people work. Ten years ago, Debian saw three well respected members of the Technical Committee resign — including two former project leaders, one of whom designed the .deb packaging system — during what I see as a similarly heated vote/counter-vote power struggle. This Python saga feels similar. reply plg94 9 hours agorootparentI believe if things get too heated, all the parties involved should be forced to meet in person for a weekend to talk things out. I'm sure it would solve like 90% of these stupid conflicts, because people rarely get _that_ riled up when in the same room. Written communication, especially asynchronus ones like email or forums, are just unsuitable to capture all nuances of human behaviour. Someone is tired or hungry and makes a bad joke; next thing you know there's a witchhunt… (I also don't think they should be allowed to cite things said 5 years ago as a reason to ban someone today. How could that still be relevant?) reply squigz 1 hour agorootparent> (I also don't think they should be allowed to cite things said 5 years ago as a reason to ban someone today. How could that still be relevant?) Out of curiosity, since similar arguments come up fairly regularly: What is the appropriate time limit, do you think? reply nromiun 13 hours agorootparentprevBDFL model seems to have worked pretty well for so many decades. Guido should have just transferred power to someone he trusted. Now look at him, he can't even comment freely. reply benterix 11 hours agorootparentThis is a tough one. Guido was excellent at his role, and his decision to hand it over was a mature one. It was everybody's hope it would help to guarantee long-term future for Python, independent from corporate greed. Now these new folks seems to be failing at the only job they had. Maybe they need more time to mature, or maybe the Python Community should take a more decisive stance towards this kind of abuse of power. reply _0ffh 11 hours agorootparentprevI think the lesson is, if you should ever find yourself in the role of a BD and plan to give up control in favour of a committee or suchlike, always retain the option to throw them out and re-assume control, in case of need. reply EasyMark 2 hours agorootparentYeah because after that you just have 5-10 dictators which inevitable build up cliques with their own personal grievances rather than any ideas to benefit the good of the community. reply cooperadymas 8 hours agorootparentprevAh the old Oliver Cromwell approach! reply ThinkBeat 17 hours agoprevThis type of behavior is abusing the members of the community. Code of conducts should contain language to dissuade bureaucrats from participating and especially from attempts at grabbing power. As well as a straightforward way to report bureaucrats and have them removed from the community. Based on the same process as other abuses that may already be included int the code of conduct. reply 0xbadc0de5 9 hours agoprevYou can vote your way into a CoC but you need to fork your way out. When Codes of Conduct were first introduced, they sounded like a benign concept. But now it's becoming increasing clear that they're the Trojan horse that allows the inmates to take over the asylum. reply potsandpans 18 hours agoprevThis kind of drama seems to exist very specifically to programming language design and implementation. Probably has something to do with the codified formal structures necessary for various committees/ decision making groups. But it's interesting. This kind of stuff happens in ECMA, Rust, Python and a few others. Go seems to have escaped. Maybe because it's a corporate owned Lang? Similarly no drama in the Typescript world. reply dumbo-octopus 17 hours agoparentCorporate drama happens behind closed doors. It’s in the best interests of everyone at the company to present a unified vision, so that’s what happens. Additionally, corporate structure is typically much more hierarchical. If someone has a complaint they can take it up with Anders, if he disagrees that’s it (unless your name happens to be Scott G or Satya N). This is, by and large, a good and efficient way to structure things. reply zellyn 17 hours agoparentprevA prominent and influential Go developer was effectively banned for life from Go community forums some years back. I honestly don't remember enough of the details to have a clear opinion on whether it was ultimately warranted, but I still feel sad that it happened when I think about it from time to time. The fact that it's legitimately unwise to discuss and decide CoC violations in public can make the resulting disappearances relatively invisible. reply bgentry 17 hours agorootparentI actually just re-read that whole thread earlier this evening for unrelated reasons: https://news.ycombinator.com/item?id=31508000 In short, the Go module proxy causes an excessive traffic volume on git VCS sources with frequent clones of unchanged repos. Regardless of whether or not the developer is/was always reasonable in how he discussed this, he was absolutely right about this being a hostile behavior from the official Go proxy that is the result of bad/insufficient engineering. The team's suggestions to simply stop refreshing his one domain were also not sufficient given that the problem clearly impacts all Go module VCS hosts. The developer also appeared to be banned in a way that violated the Go CoC's own provisions around fair notice and a proper hearing, which is super disappointing to see. reply zellyn 17 hours agorootparentOh man, was Drew banned from all Go spaces, or just from the issue tracker as he mentioned? He seems to draw ire, although whenever I actually read what he writes, he usually makes a lot of sense. I imagine there are examples of him being abrasive, but it usually seems like he values being thoughtful and kind. I was actually thinking of someone else: https://news.ycombinator.com/item?id=34311643 reply 015a 17 hours agoparentprevTo take a stab at my perception of why this is: Its the same reason why everyone and their mother has an opinion on note taking; programming language design is a topic that has a comparatively low skill floor to have an opinion on. Its difficult to have an opinion on how, I don't even know, drivers should communicate with each other in the linux kernel, see I can't even come up with a great example of the kinds of discussions they have because the skill floor is reasonably high. Its more common to hear \"We gotta bring Rust to linux\"; even more common still is \"Rust is too complicated\" \"too verbose\" \"we should change X Y Z\" whatever. reply stackghost 18 hours agoparentprev>This kind of drama seems to exist very specifically to programming language design and implementation. There's that saying about the inverse correlation between impact of the project/the stakes, and people being drama lords. reply marcus_holmes 16 hours agorootparentI saw this in the re-enactment scene in the UK in the 80's and 90's [0], where there were endless schisms and political dramas. The same is true of any \"scene\" where the consequences of drama are minor and the participants have the scene as a core part of their identity. I would expect there to be a class of admin in here that do not actually contribute code but have created positions of authority over the project based on \"community contribution\" only. There's a particular type of person that does this and derives great satisfaction from it. I'm not going to criticise this - often the \"community contribution\" is real and beneficial - but I don't think it helps when the focus of the team managing the project moves away from the purely technical. [0] I'm sure it still happens, but I no longer witness it. reply userbinator 17 hours agoparentprevNo drama in C that I can remember either, because there is not much of a \"community\" in the first place. reply alexey-salmin 16 hours agorootparentThere's a community, just too busy with the actual programming. reply jart 15 hours agorootparentThere's an online community for Cosmopolitan C on places like Discord. Everyone who's there, is there because I welcome them and want them to be there. The code of conduct is you have to behave like Mr. Rogers. There's no sexism, racism, name it. The C developers in our community don't even use swear words. reply EasyMark 2 hours agoparentprevThis drama exists in nearly every human committee in existence. reply throwawa14223 17 hours agoparentprevMy personal conspiracy theory is that it is the corporations demanding the codes of conduct as a form of sabotage for products that they can't control. reply bfrog 18 hours agoprevThis seems to be a repeating theme lately. NixOS went through something incredibly similar lately. reply scientist4397 18 hours agoparentI miss that information, have you a link to share ? reply aendruk 2 hours agorootparent> This is a repository that aims to concisely explain the issues in Nix community https://github.com/KFearsoff/nix-drama-explained reply nick__m 18 hours agorootparentprevhttps://www.theregister.com/2024/05/14/nix_forked_but_over_p... reply aidenn0 16 hours agorootparentNote that that is from very early on in the process. The last I heard (about a month ago?) the final result was several (many of? more than 3, less than all?) people who signed the letter mentioned in the Reg article left for various reasons, several right at the point when a certain person had their commit-status re-enabled after a ban. I believe said person was eventually banned at a later point. There are at least 2 forks that happened seemingly as a result of these disputes (Aux, as mentioned in the Reg article and Lix) reply srid 4 hours agorootparentprevA 5 minute overview, https://chrismcdonough.substack.com/p/the-nixos-conflict-in-... Another overview (easy to understand, but some non-central information is inaccurate), https://lunduke.locals.com/post/5819317/nixos-commits-a-purg... Concrete events & evidences, https://github.com/nrdxp/rfc-evidence/blob/master/rfc_eviden... reply bigbones 18 hours agoprevSeems like someone's been reading How To Have AWS Announce A Fork Of Your Project In 21 Days on the toilet reply hughesjj 2 hours agoparentAmazon wouldn't even officially fund python development internally (thankfully Chris Rose is a gem along with others so most never noticed), and they don't care about this kind of drama reply randomcarbloke 10 hours agoprevwhy do steering committees for languages always devolve into this absurdity, usually by people with comparatively little technical capability. Drama Driven Development is truly the paradigm of the last 5 years. reply TimK65 10 hours agoprevGvR's first comment, mentioning (but not naming) the banned person, is now visible to me, at least. reply jsyang00 18 hours agoprevAmazon Meta or Google should please create and maintain a corporate fork. The performance fixes could happen faster and would probably pay for themselves. No more problems with issues like this. Would provide some people with good jobs. reply bouncing 4 hours agoparentWhat performance fixes do you think were being slowed down by the community? reply jamesfinlayson 15 hours agoparentprevI'm pretty sure Amazon does at least - I thought that the Python version that runs in Lambda had a few features on top of CPython (mainly around relative imports but possibly other things too). reply ggm 18 hours agoprevOne post. His posting rights haven't been withdrawn, it's one message in context which was elided out. [edit: I am somewhat surprised people want to down-vote a factual statement, which in part aligns to the OP who changed the title of the post since it was being wrongly inferred his posting rights had gone, not a single post was being hidden. As the saying goes \"you do you\"] reply basementcat 14 hours agoparentI also don’t fully understand why some folks are worked up. We all have posts that are downvoted and removed even here on HN. If you don’t like the steering committee or whatever, just elect a new one. reply port19 4 hours agorootparentBecause this is not like any one of us having their comment removed on HN. This is like Paul Graham having their comment removed on HN. A more drastic analogy, this is like getting kicked out of your house by your kids. Altough I see that this one is flawed and exaggarated reply thinkingemote 10 hours agorootparentprevDo you understand but just don't agree? Can we help in increasing understanding on why people have certain opinions in this topic? Or do you kinda know why and are expressing a kind of disagreement and disapproval of holding the opinions? reply basementcat 10 hours agorootparentYes, please help me understand why this is a big deal! A committee that was chosen by a community decided to remove a post. It looks like the removal was well within their authority. If the community disagrees with the committee, they can move discussion to another venue, elect a new committee, and so on, no? None of this adversely affects the performance or reliability of software written in python. reply thinkingemote 9 hours agorootparentThis doesn't directly affect the software as it currently stands. It's mainly about the organisation. The people in charge have some a sequence of things that have increasingly alarmed people who care about the organisation of the project. More people are getting interested in what has happened with each step. This is one of the latest actions where even the key person who started Python has been impacted. This shows that the actions they were doing are important and worthy of attention as anyone who interacts within the organisation is within the reach of potential impact. No-one is untouchable. Outside though to the rest of us it's not directly impactful currently. So then there is the impacts on wider things like software. As you say the community can just vote out the ones they dislike and vote in a new bunch. To me and many others, this sounds it should solve the situation. However I think some others see the problems as systemic, where the actions taken are a result of how the management organisation is structured and so the problems will occur again even if new people were in charge. If that's the case then more of a change might be demanded which could affect the software. (But in what ways is unclear) On a HN scale, there's a wider sociological and cultural issue of how large open source software projects should be organised. And this is an example showing the problems of certain approaches especially as certain things were directly for reducing abuse and yet seem to be used in an abusive way. For many here on HN who are in various communities with similar structures, seeing what happens here is very important to them. There is a varying amount of personal investment in this story about the users own lives more than Python itself. reply hughesjj 1 hour agorootparentprevYup, and while I don't know the overlap between the committees, it seems like the CoC committee gave a recommendation to the Steering Committee, and the Steering Committee acted on the findings, and it wasn't just an instant ban hammer on Tim either. Hiding Guido's comment I could see being controversial, but I also believe allowing relitigation or reinsertion of harmful drama in governance discussions as being disruptive. Hiding the comment wasn't punitive. Also the project shouldn't go into freeze mode because a valuable contributor is doing time for a crime, such a practice would be super destructive to the project. It'd basically give filibuster power to any contributor of sufficient 'clout' to derail and delay any steering committee decisions indefinitely reply em-bee 8 hours agorootparentprevIt looks like the removal was well within their authority this is what i'd like to know more about. should they have this authority? especially to remove any posts in a non-transparent way? such a level of authority should be limited to removing obviously illegal or age-restricted content, but not the kind of message in question. and even then, it should require oversight from someone outside the committee, ideally people specifically trained for handling such messages. reply scoofy 18 hours agoprevI prefer the Jimmy Wales version of authority. The project operates democratically, but Jimmy always retains the ultimate authority to act as a sovereign at the end of the day because he built it, has the reputation of the project to protect, and it's his legacy. The option to fork the project will always be there if the people want new leadership. reply debacle 18 hours agoparentGuido did that for a long time, but I think he reached a point where he wanted to transition. reply scoofy 18 hours agorootparentAgain, I would prefer he retain an unused veto. Who knows, perhaps he's entirely fine with his comment being removed. The benefits of a sovereign are that they limit the amount of privileges that can be extracted from an political system. Obviously monarchs have their downsides, but if people can just up and fork the project, those downsides are limited. reply lazyasciiart 18 hours agorootparentThe downsides can be pretty high for the chosen monarch. reply scoofy 18 hours agorootparentI obviously can't speak to the politics of the Python Foundation (my favorite language and would buy every single person in this governance discussion a beer), but my point is that these types of monarchs generally have more (Taleb-style) skin in the game than someone who shows up later. More to lose (everything they've built), and so I would generally trust their judgement to care more about the institution as a whole, than about exercising power (which is the entire reason they have effectively given up power in the first place). reply toofy 17 hours agorootparentpreva wannabe king is more than welcome to fork this project as it sits, right now, today. and they can be as non-democratic as they want with their own little fifedom. reply FireBeyond 17 hours agoparentprev> The project operates democratically I have not paid attention in years, and with the acknowledgment that some of the contributors there were their own worst enemy and/or not without sin, but you should really poke around http://wikipediareview.com/ - to see just how untrue that often is. (I'm talking confidential email lists, whose existence is not to be confirmed, IRC channels, brigading, and far worse). reply mark-r 17 hours agoprevWow. If you needed proof that Guido isn't BDFL anymore, this is it. reply ckemere 16 hours agoprevWhy has no one pointed out that GvR posted a second time on the thread. That seems to suggest he is still actively engaged in the community? reply mixmastamyk 17 hours agoprevMy spidey sense first got tingling a few years ago when the Python powers decided they were going to rename their git master branch to something else. Caused them unnecessary work and to this day it's not certain any developer or user actually asked for it. The word has multiple meanings of course; yet felt like a symbolic gesture to alleviate guilt totally unrelated to Python. I didn't complain without a dog in the hunt, but I noticed those that did were implied to be monsters, and told that their mild disagreement \"would not look good to history.\" Unfortunately a few years later I can say the opposite. Well, Guido made his bed, now it's time to lie in it. ;-) reply zahlman 1 hour agoparentSee also: https://mail.python.org/archives/list/python-dev@python.org/... reply cool_dude85 15 hours agoparentprev>Unfortunately a few years later I can say the opposite. It's your contention that people getting up in arms about not changing the name of the 'master' branch specifically look good now, with hindsight? Can't say I agree. reply Izkata 14 hours agorootparentThat the people implying they were monsters were the actual monsters. reply consteval 4 hours agorootparentI don't think a single soul implied they were monsters. There's nothing wrong with having your branch named \"master\" if, coincidently, that's what you have. However it's weird if you say master is the \"one true name\" and it HAS to be master. Like, why do you care? That's odd. That's what some people point out. Nobody is calling anyone a monster. To me, I think changing master -> main is a nothing burger. Doesn't accomplish much. It's neutral, or vaguely positive. That, to me, is a reasonable position. For some people changing master -> main isn't a nothing burger, it's actively harmful. This is a different opinion and one that makes no sense to me. Some people genuinely love the name master and want it to stay and yes, that is weird. reply eadmund 2 hours agorootparent> For some people changing master -> main isn't a nothing burger, it's actively harmful. I constantly have pain — years after the Summer of Floyd — from repos I follow which change the name of their master branch from ‘master’ to ‘main,’ which breaks all sorts of tooling, sometimes silently (my local copies stay on ‘master,’ and never get updates), sometimes noisily. That switching is actively harmful. > Some people genuinely love the name master and want it to stay and yes, that is weird. I don’t particularly love it, but it is the correct name for the master version (as opposed to a local copy, or a remote copy, or a feature branch, or a custom branch, or whatever) of a repo. reply mixmastamyk 2 hours agorootparentprevIt broke scripts and docs. Funny enough I never liked that name early on, in preference to to hg’s default. But once done for years, no point in changing it. reply zahlman 1 hour agorootparentprev> I don't think a single soul implied they were monsters. There's nothing wrong with having your branch named \"master\" if, coincidently, that's what you have. It takes no effort to find arguments such as https://medium.com/let-s-begin/how-to-rename-your-master-bra... . Github themselves tried to push the change on people, and reporting on the issue used phrasing describing the original choice as \"no longer appropriate\" as if this were some authoritative consensus (e.g. https://www.theserverside.com/feature/Why-GitHub-renamed-its... ). Github's change was disruptive because repositories created on GitHub wouldn't work properly locally in Git (depending on various details) and this was happening to users with very little technical understanding and no reason to care about the underlying political issue. But aside from that, it's very obvious that many people think there's \"something wrong with\" using master as the default name. If they didn't, there never would have been an issue in the first place because nobody would have proposed to change it. There is nobody out there advocating for the change without bringing up some strange hand-waving argument about colonialism. Not a single one of these people can demonstrate how using the name \"master\" actually causes harm - because it doesn't. But hordes of them are willing to argue for making the change anyway. > However it's weird if you say master is the \"one true name\" and it HAS to be master. Nobody says this. They say that they don't want others pushing (or literally pull-requesting, in many cases) changes on them for ideological reasons that have nothing to do with the business of their project. > Like, why do you care? That's odd. That's what some people point out. No, there's nothing strange about it at all. What is \"odd\" is the rhetorical strategy of trying to shame people for a benign choice, gaslight that they're the ones being insistent and ideological, and then gaslight that no such shaming is occurring. > For some people changing master -> main isn't a nothing burger, it's actively harmful. No, what's \"actively harmful\" is the idea that people should be compelled to change things because outsiders don't like them (https://en.wikipedia.org/wiki/Entryism). Also the compatibility break mentioned above. reply mixmastamyk 3 hours agorootparentprevYou’ve reframed the disagreement about unnecessary work as “up in arms.” They look like sane folks who recommended not doing purely symbolic work. Something substantial perhaps, say promoting under-represented folks within psf would be something. You can’t eat branch names. reply zahlman 1 hour agorootparentFor what it's worth, David Mertz would agree with you (https://discuss.python.org/t/why-im-leaving-discuss-python-o...). He got kicked out, too. reply gnabgib 18 hours agoprevArticle title: Should we consider Ranked Choice voting for SC elections? reply ece 18 hours agoparentVeritasium's latest video is on voting systems: https://www.youtube.com/watch?v=qf7ws2DF-zk reply AlbertCory 18 hours agoprevSo his original comment isn't on Internet Archive somewhere? reply scoofy 17 hours agoparentIt only got snapshot once so far, and the comment is not showing up: http://web.archive.org/web/20240829000336/https://discuss.py... http://web.archive.org/web/20240829004501/https://discuss.py... reply ein0p 18 hours agoprevHe should have stayed on as BDFL. Now in the power vacuum a bunch of “activists” and political enthusiasts will take over and ruin the whole thing for everyone, or at least significantly slow down the progress reply bb88 16 hours agoparentI'm glad he's stepped down. His opinion matters to be sure, but python needs to be a community developed language. He's a smart guy, and he matters still to the python community. There was a tremendous amount of frustration around the walrus operator, which led to him stepping down. reply bouncing 4 hours agorootparentIt was happening a lot under Guido too, but IMO, Python was arguably a better language (at least in some ways) 10, 15, even 20 years ago. Python's three super powers were readability, simplicity, and a vast standard library that negated the need for most projects to seek out third party modules. All three of those have declined. It's less readable than it used to be, it's definitely more complicated (not just complex, complicated), and the standard library is declining rapidly in relevance as it ages. And it wasn't just Guido. Tim was a big advocate for all three of those super powers when he was more influential. They banned Tim and they censored Guido, so go figure. reply zahlman 1 hour agorootparent> All three of those have declined. It's less readable than it used to be, it's definitely more complicated (not just complex, complicated), and the standard library is declining rapidly in relevance as it ages. I find it much more readable, and more importantly more expressive. Certain new features are missteps IMO, but I just don't use them. But more importantly, the language has been moving away from cryptic %-encodings and other C idioms. As for the standard library, that was already happening for a long time, and is inevitable. The world has fundamentally changed. In Python's heyday it was much harder to download and install and use a third-party library, so a rich standard library was an asset. Now it's full of specialized code that handles obscure and increasingly irrelevant data formats; multiple overlapping hacks for binary data; terrible and confusing date support; awkward interfaces that haven't stood the test of time (particularly all the networking stuff; Requests is one of the most downloaded PyPI packages, along with its dependencies which are probably almost never downloaded for any other reason); etc. Lots of people still seem to think that the 2->3 migration was a mistake. They couldn't be more wrong. The old way of handling \"strings\" was abysmal, and spit in the face of the Zen. Error messages were confusing and implicit conversions abounded. Also, just for the record: Guido van Rossum was in favour of the walrus operator. In fact, he co-authored the PEP (https://peps.python.org/pep-0572/), along with Tim Peters. reply bouncing 38 minutes agorootparentThe walrus operator is nice, except in comprehensions. f-strings are great, except for the `=` debugging operator. Dictionary merging and update operators contradict the \"one way to do it\" with weird and confusing syntax that's completely redundant to methods that already exist. Type hints are a sore spot for me. They're good enough when you just don't remember whether an argument is an object or a string, for example, but once you start type hinting deep into data structures, your hints become a mangled soup of nonsense for basically no real benefit. Typing errors are a rare occurrence—perhaps once a year in most projects—yet we clutter our codebases with verbosity to satisfy type checkers instead of prioritizing clarity for developers. There's a lot that's just straight up redundant. Dicts are ordered now, but is OrderedDict deprecated? No, because it's just slightly different in weird and mostly unimportant ways. `frozenset` is a builtin, for all 3 programmers worldwide who use it. Python resisted match/case syntax for decades, but when it finally arrived, it did so in a way that’s anything but standard—good luck figuring it out without consulting the documentation. Obviously some improvements are real. Every new version of Python brings valuable enhancements. But just go back to Python as it used to be -- pseudocode that runs. That's just not true anymore. The simplicity has slipped away and will never ever come back. And the standard library? A very real problem, right now, in computer security is the software supply chain. Remember polyfill from like, yesterday? This is the era when we should double down on having a million dependencies from all over GitHub, from unknown developers with no commitment, because ... npm's hellscape is a model to follow? I would argue the contrary. There's dependency hell, of course, but there's also dependency risk. If you were evaluating a product right now, and you saw its lockfile depended only on a specific version of the Python Standard Library, that gives you exactly 1 product to evaluate, exactly 1 team of developers to depend on. pip is great and all, but dependency resolvers have quietly let in a hundred trojan horses and a thousand unmaintained dependencies into tons of projects, and no one noticed it was even happening. Python in 2005, when everyone depended on the standard library, was a safer place than npm is today. reply jart 15 hours agorootparentprevGuido is the community. He's the one with the most legitimacy to represent it. To imply that Guido is something separate and divorced from the community is textbook subversion. I can't imagine any reason that others leaders in the Python community would have irreconcilable differences with Guido than if their interests were to corrupt the project. reply bb88 15 hours agorootparentGuido is part of the community, not the community. At least not anymore. Go to pycon and try to talk to him. He doesn't want to talk to just anyone. And he's not great at accepting feedback. We love him, of course. But there are reasons maybe that the community of users should have a strong voice in where python goes as well. reply bitcharmer 10 hours agorootparentprevCan you people just make your own projects and then ruin them in any way you want? reply edward28 10 hours agorootparentThey can't. That's why they latch on like parasites to working projects. reply ein0p 16 hours agorootparentprevThe walrus operator doesn’t seem like such a big deal now given these developments, and no doubt future developments of the same sort. The permanently offended aren’t going to just go until everything is in ruins and all the main contributors are gone. reply bb88 15 hours agorootparentWell, on the other hand, the only way out for a \"Dictator\" in the \"BDFL\" is to resign or be overthrown. He decided to resign, which is probably for the best. Otherwise a fork would have forced the decision, and been worse for the community as a whole. Packaging and the 2.x to 3.x migration were both nightmares under his stewardship. Keep in mind that the leaders of the PSF can be voted out, if so chosen by the community. And the community may have a different opinion on the election cycle and want to take python a different direction. reply Ferret7446 11 hours agorootparentSo BDFLs are immortal apparently. Maybe that can be a good motivation for people to contribute to open source. reply at_a_remove 18 hours agoprevAaaah, once again community guidelines and codes of conduct reveal their nature as the thin edge of the wedge, the camel's nose in the tent. reply bitcharmer 10 hours agoparentEverything these people touch turns to shit. Look at the movies industry or gaming. reply at_a_remove 10 hours agorootparentI wonder if there is a good list of these kinds of incidents going on in open source. It might be helpful in trying to figure out exactly what kind of clauses and verbiage, precisely, invite these kinds of takeover attempts like some kind of demon-summoning invocation. reply jgalt212 18 hours agoprevWho's the un-person you're not allowed to name? I want to register and post his / her name and get banned myself. Perhaps, we should all do this. reply mananaysiempre 18 hours agoparentTim Peters, author of Timsort and the Zen of Python. He might be less of a public face of Python than GvR, but he was just as instrumental to its design all the way from the early years to its coming into the mainstream. However, I don’t think reflexive actions like what you’re suggesting will sway anybody who’s not already convinced, or really help in any other way. Disruptive demonstrations can occasionally work IRL when they can serve to convey a concern to people who wouldn’t otherwise notice it, or to assure like-minded people that they’re not alone. Online forums, by contrast, are both lacking in passersby and plentiful in tools for suppressing disruptions. Furthermore, I don’t think you can really outpolitick a politician on this low a level. Well-motivated and well-publicized forks could work. General apathy and nonparticipation could work. Other ways of voting with your feet could also work, if you can think of one. But you can’t argue (collaborate on converging to the truth) with an opponent who’s completely convinced of their own rightness and righteousness, only debate them (attempt to expose each other’s faults to an audience). Debating a politician won’t work, because they’ll crush you. It’s a large part of what being a good politician is, after all. reply emmelaich 17 hours agoparentprevhttps://chrismcdonough.substack.com/p/the-shameful-defenestr... reply bluedino 18 hours agoparentprevhttps://news.ycombinator.com/item?id=41212788 reply ansible 18 hours agoparentprevWhy do you want to stick your opinion into something that you hadn't previously known about? What are you going to positively contribute to the discussion that will move things forward? How does that help? reply alexey-salmin 16 hours agorootparentNot OP, but stating that \"ban for merely mentioning an un-person\" is nuts looks like a positive contribution to me. Policies like this often stand because no one openly disagrees and no one openly disagrees because no one else does so you just assume everyone is OK with it. Until a child blurts out that the king is naked. > Why do you want to stick your opinion into something that you hadn't previously known about? What are you going to positively contribute to the discussion that will move things forward? How does that help? A prudent response, the revised ending of \"The Emperor's New Clothes\". reply jgalt212 6 hours agorootparentprevI want to shine more light on the nonsense. reply lupire 16 hours agoprevIt's easier to run a Model UN game than develop a programming language. reply kofejnik 7 hours agoprevI'm sorry but I have to reuse an old comment: Pournelle's Iron Law of Bureaucracy states that in any bureaucratic organization there will be two kinds of people: First, there will be those who are devoted to the goals of the organization. Examples are dedicated classroom teachers in an educational bureaucracy, many of the engineers and launch technicians and scientists at NASA, even some agricultural scientists and advisors in the former Soviet Union collective farming administration. Secondly, there will be those dedicated to the organization itself. Examples are many of the administrators in the education system, many professors of education, many teachers union officials, much of the NASA headquarters staff, etc. The Iron Law states that in every case the second group will gain and keep control of the organization. It will write the rules, and control promotions within the organization. reply smitty1e 18 hours agoprevI think that Ranked Choice Voting might be helpful in an insular, knowledgable case like the PSF. Its knowledge requirements of the voters are such that I would opposed it for general, political cases. reply colechristensen 18 hours agoprevThis raises legitimate concerns for the long term viability of Python. reply OutOfHere 18 hours agoprevnext [29 more] [flagged] AlbertCory 17 hours agoparentMaybe look at how it's worked out in practice, instead of just giving the theory. We have a two-party system, and that's just the way it is. https://alaskapublic.org/2024/05/29/ranked-choice-voting-tha... Gamesmanship: Alaska is a red state. Only RCV would result in a Dem being elected. https://www.wsj.com/opinion/alaska-ranked-choice-voting-mary... (not on archive, sorry. Here's the relevant part) Republicans have learned from what happened last time, when they remained split. Looking only at first-choice votes in the 2022 special election that Ms. Peltola won, she had 40.2%. The GOP’s contenders, Sarah Palin and Mr. Begich, had 31.3% and 28.5%, respectively. Under the RCV rules, Mr. Begich was eliminated, and his supporters were reshuffled to their subsequent preferences. Enough of them didn’t like Ms. Palin that the victory went to Ms. Peltola, with 51.5%. Strangely, though, this result was sensitive to the order of elimination, meaning that the final No. 1 depended on who was the initial No. 3. If Ms. Palin had been dropped instead, a strong majority of her ballots would have gone to Mr. Begich, who would have beaten Ms. Peltola. Not only that, he’d have won about 52.5%, a bigger victory than Ms. Peltola’s ranked-choice majority. Doesn’t that seem . . . odd? What if some Democrats ranked Ms. Palin first on their ballots to ensure that the most polarizing GOP opponent made the final round? reply shiroiushi 16 hours agorootparentThis is actually a really interesting real-life instance showing that, in this particular case, RCV didn't achieve an optimal outcome. But what's a better voting system that would have achieve the presumably optimal outcome here (the less-polarizing GOP candidate Begich getting elected)? If we just compare to simply plurality voting, the outcome seems the same: Peltola got the highest vote of the 3, so in regular FPTP voting, she would have won. Or if we compare to FPTP party-based elections as is normally done in the US, I think again it would have been the same: the GOP vote was split between Palin and Begich, and presumably Palin would have narrowly won that party's primary, and then enough GOP voters hated her enough to list Peltola 2nd-choice in the RCV, so presumably they would have also voted for Peltola in a regular party-based election, so again the outcome would have been the same. If anything, I think this shows that these multi-candidate elections have odd-looking results when there's uneven numbers of candidates for the different parties. If there had been 2 DNC candidates, this might have played out quite differently. But maybe not: in this particular election, one of the candidates (Palin) was extremely polarizing and many voters truly hated her, but she had enough support from the right-leaning voters to get a majority on that side, over the more moderate Begich. But that was unique to the GOP side; there's no reason to think that the left-leaning voters of Alaska would have similarly voted in high numbers for an extremely polarizing candidate like AOC: Alaska just doesn't have many far-left voters the way some other states do. So it seems like the right outcome may have been reached here, because so many GOP voters in Alaska are willing to support a very extreme and polarizing candidate, rather than a more moderate one: they ended up making themselves irrelevant. reply Izkata 14 hours agorootparent> But what's a better voting system that would have achieve the presumably optimal outcome here (the less-polarizing GOP candidate Begich getting elected)? One I don't think gets talked about enough is approval voting. Vote for as many candidates as you like, whoever gets the most votes wins. Voting for all of them is effectively the same as voting for none of them. It also has the massive benefit for the general population that it's simple to explain. Even gives third-party candidates and moderate candidates a real chance at winning, since no one would feel like they're throwing their vote away by including them. reply em-bee 8 hours agorootparenti like this. i think it even works for electing multiple candidates. we need 5 people in a committee. everyone list their preferred 5 or 10 or more choices. add up all the votes and the 5 top get chosen. reply AlbertCory 16 hours agorootparentprevI think \"begging the question\" describes your answer, in the classical sense of \"assuming what you need to prove.\" You are assuming that a multi-party, multi-candidate election is a desirable norm. But that needs to be proven by you, not assumed. In a pre-RCV system, the parties would choose their candidates, however they do it, and then the general election would pit one candidate of each party against each other, plus whatever other parties qualify for the ballot. The public has not accepted that that must be eliminated. It did make things hard for third parties, but so it goes. Prove that that's a bad thing. reply bb88 15 hours agorootparent> The public has not accepted that that must be eliminated. RCV will be on the ballot this fall in Ruby Red Idaho. Let's see what happens. > You are assuming that a multi-party, multi-candidate election is a desirable norm. Easy. Both Trump's and Biden's approval numbers are both in the toilet. Yet they both easily won their primaries. reply AlbertCory 15 hours agorootparentIf that's your idea of \"proof\" I think we're done here. reply bb88 15 hours agorootparentSo you'll take your arguments and go home, and not even try to convince me otherwise and potentially win me over with your candor and intellect and personality? That seems like the problem with politics as a whole these days. reply AlbertCory 3 hours agorootparentNo, citing one example of the current system as \"proof\" that the whole system must be thrown out is the problem with \"politics as a whole.\" Also: thinking that a few paragraphs on Hacker News constitutes sufficient wisdom is another problem with \"politics as a whole.\" It is not going to convince you no matter what I or anyone else says. Do some research. That probably means reading some books, hate to warn you. reply bb88 16 hours agorootparentprev> We have a two-party system, and that's just the way it is. Some argue that our current voting system creates the two party system we all know and hate. Derek from Veritasium did a video about this the other day. Really good stuff. No need to come to Palin's or the Republican's defense here. Candidates are more than capable of trying to campaign for the second place votes. reply AlbertCory 15 hours agorootparentYou hate it. Don't generalize to \"we all.\" reply bb88 15 hours agorootparentCheck out this IPSOS poll that says otherwise. That was run in January. Yet somehow by May both of the upopular candidates won their national primaries. https://www.ipsos.com/en-us/most-americans-are-dissatisfied-... reply AlbertCory 3 hours agorootparentThe only polls that matter happen at the ballot box, and in the legislatures. You have one meaningless data point. reply dllthomas 18 hours agoparentprevIt's not just how much information you extract, but also what you do with that information. RCV, in the most common form of IRV, has a problem that I think is relevant. If we accept the truism that the appropriate compromise won't be anyone's first choice, then the very first thing IRV does is throw out any appropriate compromise, leaving it to make a decision between inappropriate options. I think we need to be more able to pick a compromise, not less. reply natosaichek 2 hours agorootparentRated voting methods are great, but more complicated than simple choices. Given how challenging it is to get people to just pick the thing they want in very simple situations, I would not be optimistic about their implementation. reply lazyasciiart 18 hours agorootparentprevThat truism seems pretty unacceptable to me. reply dllthomas 3 hours agorootparentI don't think it's strictly true, and a system built around it as a rule would be easily manipulated and a bad system. I'm not proposing it as a rule within any system, though, and my analysis generally holds so long as it's true a meaningful chunk of the time - it doesn't even need to be a majority of cases. reply mindslight 18 hours agorootparentprevYeah, it's painful seeing all the enthusiasm IRV gets. I've come to the conclusion it's how people think they want to be able to express support for third party candidates due to their frustration with the current system, but not actually seeing down the line to what happens when non-duopoly options gain some popularity. Basically it's still hopelessly wed to the two party model after the less-popular third parties are run off. It's only redeeming feature is that the same choices can serve as the input to a Condorcet decision process when the failures of IRV become apparent. reply dllthomas 3 hours agorootparent> It's only redeeming feature is that the same choices can serve as the input to a Condorcet decision process when the failures of IRV become apparent. I think the concern raised by PaulHoule is very important. Assuming, for the sake of this particular digression, that it can be sufficiently satisfied by IRV in a context under consideration, BTR-IRV seems like an easy sell over IRV. It's like IRV, but instead of discarding the candidate with the least first place votes, you do a head-to-head runoff (looking at the rank ballots you already have) and discard the loser. Not much more complicated to understand or administer, and you can never discard a Condorcet winner (or a member of the Smith set, except in favor of another member of the Smith set). reply PaulHoule 17 hours agorootparentprevI think the worst thing about U.S. national elections is that the winner of the electoral vote might not be the winner of the popular vote. Whether or not that is right is beside the point but anything complicated about the results that make them hard to understand will subtract legitimacy. I’d go so far to say that the system will not survive if we got several elections where one particular party consistently loses one vote but wins other. The last thing we need, seen through that lens, is a complex system where people don’t understand the results or how exactly their vote will affect those results. reply naniwaduni 17 hours agorootparent> The last thing we need, seen through that lens, is a complex system where people don’t understand the results or how exactly their vote will affect those results. And this is one of the best features of approval voting compared to any form of ranked choice! reply mindslight 15 hours agorootparent\"The winner is preferred to each other candidate, by the majority of voters\" seems pretty straightforward to me. The problem with Approval is that we're right back at the Faustian bargain of needing to fully support the lesser evil at the expense of your preferred option. And the only thing Range adds is allowing you to moderate the amount of that bargain. reply dllthomas 3 hours agorootparent> \"The winner is preferred to each other candidate, by the majority of voters\" seems pretty straightforward to me. It is, but 1) the public needs to be sufficiently convinced that all of the bookkeeping reliably determines which candidate that applies to in the face of possible error or malfeasance, and 2) sometimes there is no such candidate (cycles are possible) and what happens then can be complicated. (And sure, ties are possible in ~any system, but if we treat cycles as ties we've made ties much more likely.) reply naniwaduni 17 hours agoparentprevIronically, \"dumb\" approval voting, by virtue of using additive aggregation, extracts more information from ballots than ranked choice. It's a reduced-resolution form of continuous range voting, just like discrete range voting (approval voting is literally {0,1} range voting!), that approximates it arbitrarily closely with sufficiently many voters. (Approval voting also literally expresses more information about small numbers of candidates: there are 7 distinct approval ballots of three candidates, and only 6 distinct ranked ballots. In particular, it expresses more raw information about preferences between the top 2-3 candidates, which are the most important rankings in a single-victor election!) reply aidenn0 16 hours agorootparentThe primary downside to approval voting over a good ranked-choice-voting system (IRV is poor, yet is often considered synonymous with RCV), is that it encourages strategic voting. Let's take the 3 person example and assume I like candidates A, B, C, in that order. With RCV, I would just rank them in that order. With approval voting, I might want to withold my approval for the most popular opponent to A, in order to boost A's chances of winning. I like approval voting for large democracies because of the reasons you mention and the fact that it is very simple. Trust in the voting system is paramount for a healthy democracy, and requiring algebra knowledge to understand the how your vote is counted is counterproductive for generating such trust. reply naniwaduni 0 minutes agorootparentThe main reason \"strategic voting\" is a big deal when evaluating ranked-choice voting systems is that they actually experience spoiler effects (which more or less follows from Arrow's theorem, no amount of epicycles will totally mitigate them). Approval voting essentially pulls the bottom out of the two most impactful forms of strategic voting by satisfying independence of irrelevant alternatives and structurally enforcing use of the full range. > Let's take the 3 person example and assume I like candidates A, B, C, in that order. With RCV, I would just rank them in that order. With approval voting, I might want to withold my approval for the most popular opponent to A, in order to boost A's chances of winning. In a 3-candidate election, the bullet vote for A is not a strategic ballot, it honestly expresses your preference A > B,C. It would be strategic to vote A,C (instead of A,B,C), but it turns out that in elections of up to 3 (relevant) candidates, one of the honest ballots is always optimal. (This is not to dismiss the impact of voting \"for A\" vs \"against C\", because that does matter. But there's a real trade-off there if you aren't fully informed on other voters' (adversarial!) ballots to discourage being the first to actually run that campaign unless you're sure you have a genuine majority.) OutOfHere 16 hours agorootparentprevEven so, why not use full range voting (0-100) instead? Wouldn't it extract more information? reply naniwaduni 38 minutes agorootparentAn arguable disadvantage of full range voting is that it overweights people who vote binary 0/100 and underweights people who vote 80-100. Since the former is almost always strategically advantaged, it seems fairer to just cut out the middle. reply jrockway 18 hours agoprevI'm going to be contrarian here and say, maybe it's the right choice. Bringing up already-litigated drama in an unrelated thread is not particularly constructive. If Guido thinks this person's opinions are relevant, he can send them and email and ask for them, right? To some extent, the moderators are obligated to treat everyone equally. If they wouldn't let you or me relitagate past drama here, why should they let anyone? The core team should be setting the example for how other people should behave. If the core team doesn't agree with the values that they claim to agree to, and show this disdain by not enforcing their own rules, then why would they bother creating that governance structure in the first place? They are just being consistent with the processes that they agreed to and subjected themselves to. That's governance. Personally, I think it would be more alarming to the community if certain people didn't have to follow the rules. As far as I can tell, there is no mention of not discussing the original decision in general. If there was, nobody seems to be following the rules as there are 8 billion Reddit threads on the topic. I knew nothing about this and had Names Named in about 3 seconds of searching. As a result, I don't think there is some sort of conspiracy taking place. Enough ink has been spilled on this issue; does it really need to be brought up again in a thread about voting systems? reply basementcat 19 hours agoprev [–] Isn’t it good to see that no one is \"above the law\", even if they’re a benevolent dictator? reply rdtsc 19 hours agoparentThe question is always who enforces the law and if and how they choose to enforce it. reply II2II 17 hours agorootparentIf the comment was the reference to a banned member, was the action actually inappropriate? If the banning of the member alluded to was inappropriate, there is a time, place, and tact to address that. If the process does not allow for that, then you work towards changing the process. If the governing body doesn't allow for that, then why the heck would you make a comment that could derail a discussion regarding how that governing body is elected? reply rdtsc 15 hours agorootparent> If the comment was the reference to a banned member, was the action actually inappropriate? Yes > why the heck would you make a comment that could derail a discussion. Banning the poster derailed the discussion even more. So much so, it made it to front page of HN. I am not arguing they shouldn't have banned Guido because of who he is; I am arguing banning anyone should have a pretty high threshold, and when it happens it should be done with extreme transparency. Asking to wait for a member to join the discussion later about a relevant topic shouldn't come anywhere near that threshold. reply OhMeadhbh 18 hours agoparentprevI agree. But didn't he give up the Benevolent Dictator for Life moniker? Sounds like a King Lear situation... Since now we will divest us both of moderation authority, Interest of ban-hammering, cares of tweets,-- Which of you shall we say doth love us most? That we our highest privilege in the comments forum may extend Where nature doth with merit challenge. Tim, Our eldest-born, speak first. reply riknos314 18 hours agoparentprev\"the law\" is always subject to interpretation in a given context. The entire concept of case law is that \"the law\" has been interpreted in a certain way in a similar context before. reply gedy 18 hours agoparentprevSure if he was being hurtful, hateful, etc. But is comment hardly seems wrong in light of the community guidelines: https://discuss.python.org/guidelines More seems it's just embarrassing to the committee so they banned it. reply __d 18 hours agorootparentYou could read Guide's message (assuming the first comment is quoting it accurately) as being sarcastic about Tim Peters' banning. The mods probably feel like this is undermining their authoritah, and dropped the banhammer. reply kadoban 18 hours agorootparentIt reads to me as kind of petty sniping that's unlikely to really contribute anything useful to the conversation. But not something that really seems worth hiding either... reply __d 18 hours agorootparentprevI guess it could be considered to breach the Code of Conduct, disrespecting the decision to ban Tim? Being respectful. We're respectful of others, their positions, their skills, their commitments, and their efforts. reply dm270 14 hours agorootparentThis seems to be the perfect pretense to justify any sort of banning an organized majority would want. reply bsder 18 hours agoparentprevWhen two of the most important people to a project get banned, who is more likely incorrect? The bannors or the bannees? reply breck 18 hours agoparentprev [–] Just because it is a well known quote, doesn't mean it's a good idea. No one is above god's law (aka physics). No one is above the _spirit_ of [man's] laws. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A proposal has been made to switch from simple approval voting to ranked choice voting for the Steering Council elections to better capture voter preferences and provide more meaningful feedback to candidates.",
      "The current voting method, PEP-13, has limitations such as no preference expression, encouragement of strategic voting, and limited feedback for candidates.",
      "Ranked choice voting is proposed to offer better preference capture, reduce strategic voting, and provide nuanced feedback, with implementation managed by the PSF and community feedback being sought before any changes."
    ],
    "commentSummary": [
      "A post by Guido van Rossum was removed for violating Python community guidelines, mentioning advice from a banned expert.",
      "The removal has led to discussions about the suspension of core developer Tim Peters and the governance of the Python community, including the role of the Steering Council.",
      "The incident has sparked a debate on censorship and the enforcement of community guidelines within the Python community."
    ],
    "points": 221,
    "commentCount": 211,
    "retryCount": 0,
    "time": 1724887951
  },
  {
    "id": 41384118,
    "title": "Twenty Years of Valgrind (2022)",
    "originLink": "https://nnethercote.github.io/2022/07/27/twenty-years-of-valgrind.html",
    "originBody": "Twenty years of Valgrind Jul 27, 2022 It has been twenty years since Valgrind 1.0 was released. The Valgrind website says: Valgrind is an instrumentation framework for building dynamic analysis tools. There are Valgrind tools that can automatically detect many memory management and threading bugs, and profile your programs in detail. You can also use Valgrind to build new tools. – I first met Julian Seward in late 2001. I had moved from Australia to Cambridge in the UK to pursue a PhD on the topic of “cache optimizations for functional languages”. The Cambridge Computer Laboratory is literally next door to a Microsoft Research office, and I was soon interacting with the people there working on the Glasgow Haskell Compiler. Julian was one of them. Shortly after that, Julian’s stint working on GHC came to a close. On his last day he dropped by my office in the Computer Laboratory to say goodbye. I asked what he would be doing now, and he said he was going to spend some time on a project of his called Valgrind. “What’s Valgrind?” I asked. It was one of those this-will-change-your-life moments. – In the mid-90s Julian wrote the bzip2 compression utility. He had spent some time investigating its cache behaviour in order to make it faster. While doing this he created a cache profiling tool called cacheprof. It parsed and annotated assembly code in order to add instrumentation code, gave line-by-line annotations of cache misses in your source code, and came with a wrapper around gcc to make its usage straightforward. (Section 7 of the cacheprof docs have more details about its origins.) Julian was also a fan of Purify, a commercial tool that detected memory errors in programs at runtime and ran on Solaris. He hoped that someone would make an open source version for x86/Linux, but eventually decided to do it himself. He had some experience with an x86 binary interpreter called Heimdall, but knew that binary interpretation was too slow to be practical. Perhaps JIT compilation could help? After a great deal of effort he had a working memory error detector, which ended up with the name Valgrind. It was language independent and didn’t require any pre-instrumentation of source code. It worked pretty well, could handle large programs, and was getting some use from KDE developers. All this was an impressive achievement, because Valgrind has to do a lot of clever and/or nasty low-level things to work. It has to intercept every instruction executed by a client program without ever losing control, even in the face of syscalls, signals, and longjmp. And on top of that it has to add large amounts of instrumentation to maintain metadata about literally every bit of data the client program manipulates. – When Julian showed me Valgrind I thought it was pretty cool. I got a copy of the code and submitted a few small improvements. I had been using cacheprof myself, but its assembly annotation approach was fragile and didn’t provide any coverage for system libraries. Not long after learning about Valgrind I realised its dynamic binary instrumentation could provide a more robust foundation for a cache profiling tool. I wrote Cachegrind and it was committed into the repository in April 2002. In July 2002, Valgrind 1.0 was released. The SlashDot post said: Valgrind is a C/C++ programmer’s dream come true: effortless memory allocation checking, uninitialised memory access, leaks etc. Purify for Linux has arrived, only better: contrary to its commercial (non-Linux) sibling, checking is performed directly on the executable, no re-linking necessary. At this point Valgrind did two things. By default it would look for memory errors, but you could invoke Cachegrind with the --cachesim option. The integration between the two modes was clunky, but both were useful. I then realised there was a potential clean split between the generic instrumentation code and the tool-specific code. A few months later I made this split, which opened up a new world of possibilities. Memcheck was born: it became the name of the tool that did the original memory checking, and Valgrind became the name of the entire system. (Having said that, even today “Valgrind” and “Memcheck” are basically synonymous.) And Cachegrind was no longer bolted on as an awkward extra piece. We called this the “core/skin split”. These names were my choice, inspired by the custom UI “skins” you could put on software MP3 players at the time. A while later we realised “skin” was a dumb and confusing name, and we switched to “tool”. The name “core” has stuck, although we changed the name of the directory holding the core code from core to coregrind after learning that some Linux systems were configured to periodically delete any file named core, on the assumption that such files are core dumps! Around this time we were joined by many talented folks who made important contributions. In particular, Jeremy Fitzhardinge greatly improved the tricky intersection point of threads, system calls, and signals, and Tom Hughes fixed many early bugs and improved debuginfo reading. More tools followed. Julian wrote a data race detector called Helgrind. Josef Weidendorfer wrote a souped-up version of Cachegrind called Callgrind. In 2003 I wrote Massif, a heap profiler. In 2007 Bart Van Assche wrote DRD, a different kind of race detector. In 2010 Julian wrote DHAT, a different heap profiler. It could do some incredible stuff but the text-based output was clunky. In 2019 I overhauled it to have a much nicer UI. Various other lesser-known tools have been written, some of which were used as the basis for research papers. – After the core/tool split I switched the topic of my PhD away from functional programming. I finished my dissertation, entitled Dynamic Binary Analysis and Instrumentation, in late 2004. I wouldn’t recommend reading it today, except perhaps chapter 3 which is a decent description of how Cachegrind works. However, it was enough for me to graduate and forevermore tell people that, literally, “I have a PhD in Valgrind”. (This was a three year UK PhD, rather than a brutal six-or-more year US PhD. To any potential graduate students reading this: 10/10, would recommend.) In 2005 we published a paper at USENIX entitled Using Valgrind to detect undefined value errors with bit-precision. We only learned about the conference two days before the paper deadline, when an organiser of the co-located FREENIX workshop suggested we submit an abstract for a paper about Valgrind to FREENIX. We proposed submitting a paper to USENIX instead and were told “it’s not possible to do a USENIX paper in two days”. Forty-eight frantic hours later we did and it was accepted, hooray! That paper focused Memcheck’s definedness checking. This is the part that tracks the definedness of every bit of data that a client program touches, and determines if the client program does anything dangerous with undefined or partially-defined values, such as branching on a condition that uses an undefined value, or passing an undefined value to a system call, or using an undefined value as an address in a memory operation. It’s a very elegant system that Julian invented, combining both speed and precision. Even today, it’s still a unique advantage of Memcheck over similar checking tools. In 2007 we published two papers. The first paper was at PLDI, entitled Valgrind: A Framework for Heavyweight Dynamic Binary Instrumentation. This one took a lot longer than two days. It’s still the best overview of Valgrind’s internals, and the most cited paper about Valgrind. Ten years later, it won a most influential paper weapon award. I sure wasn’t expecting that. The second paper was at VEE, entitled How to Shadow Every Byte of Memory Used by a Program. It gives a nice overview of how Memcheck tracks extra state about every value in memory. There were some other awards, too. In 2004 Valgrind won a merit (bronze) Open Source Award. (This interview with Julian from the time has some good historical information.) In 2006 Julian won a Google-O’Reilly Open Source Award for “Best Toolmaker”. In 2008 Valgrind won TrollTech’s inaugural Qt Open Source Development Award for the best open source development tool. – By 2010 I was fully out of academia and no longer writing research papers. Julian and I had both ended up at Mozilla, where I worked for twelve years and where Julian still is. Our involvement in Valgrind has gradually declined—mine much earlier than Julian’s—and our statuses today would best be described as “emeritus”. There have been many other contributors over the years, and Mark Wielaard is today the lead maintainer. – It’s both delightful and surreal to see that Valgrind is still in wide use today. Julian’s original goal was to raise the bar when it came to correctness for C and C++ programs. This has clearly been a huge success. Memcheck has found countless bugs in countless programs, and is a standard part of the testing setup for many of them. It did take a while to penetrate, though. In 2005 I did a postdoc where I worked on a project involving novel hardware design. There were several C programs that simulated the hardware being designed. Students would run the programs overnight to simulate a small amount of machine time. Sometimes when they returned in the morning the simulations would have crashed, which was a big time waster. I suggested they try Memcheck, which found a few problems that they fixed, and the programs stopped crashing. But the response wasn’t a “that fixed the problem!” so much as a “huh, that problem seems to have gone away”. Thankfully, with time, the value of Memcheck has become more deeply appreciated. I’m pretty sure that ASan was directly inspired by Memcheck. ASan uses static instrumentation, which means it is faster than Memcheck but has incomplete coverage, e.g. for runtime generated code and system libraries. For this reason it does what Memcheck does except the definedness checking, because that part requires 100% instrumentation coverage to work reliably. Speaking of software quality, I think it’s fitting that I now work full time on Rust, a systems programming language that didn’t exist when Valgrind was created, but which basically prevents all the problems that Memcheck detects. As a result, I don’t have much use for Memcheck, but I still use Cachegrind, Callgrind, and DHAT all the time. I’m amazed that I’m still using Cachegrind today, given that it has hardly changed in twenty years. (I only use it for instruction counts, though. I wouldn’t trust the icache/dcache results at all given that they come from a best-guess simulation of an AMD Athlon circa 2002.) And DHAT is an ongoing source of joy: I’ve never used any other profiler as good at telling me precisely what I want to know. – These are some of my Valgrind stories from the past twenty years. It’s far from a complete account, but I hope it has been interesting. To finish, I’ll quote the first entry in the Valgrind FAQ, which I wrote a long time ago: 1.1. How do you pronounce “Valgrind”? The “Val” as in the word “value”. The “grind” is pronounced with a short ‘i’ – ie. “grinned” (rhymes with “tinned”) rather than “grined” (rhymes with “find”). Don’t feel bad: almost everyone gets it wrong at first. Happy birthday, Valgrind!",
    "commentLink": "https://news.ycombinator.com/item?id=41384118",
    "commentBody": "Twenty Years of Valgrind (2022) (nnethercote.github.io)221 points by fanf2 22 hours agohidepastfavorite54 comments theideaofcoffee 21 hours agoIn a complex C codebase, valgrind is absolutely indispensable for finding the last few bits of memory that may have leaked out because you got lazy and didn't free() or maybe you wrote somewhere in memory you shouldn't have, it really is like magic sometimes. I know that more recent languages (and some not so recent, looking at you, Ada!) have a lot of this built in by default, but when you need to do these things, you know you need to and it's nice to have a handy all-in-one tool to help out. It's saved me many times from myself when I was writing network code in C and I couldn't figure out where the leaks were coming from, or a performance regression by inspecting the code alone. A quick run of valgrind had that fixed in minutes. reply flohofwoe 11 hours agoparentIME the main problem with Valgrind is that it reduces performance too much (I remember something around 10x slowdown or worse). Clang's address sanitizer OTH finds most of the same problems, but with much a smaller performance hit, which makes it also useable for things like games. Also for leak detection, some IDEs have excellent realtime debugging tools (for instance there a very nice memory debugger in Visual Studio since VS2015, and XCode has Instruments). reply turtledragonfly 19 hours agoprevI like Valgrind, but day-to-day, I find myself typically reaching for Sanitizers[1] instead (ASan, et. al.), especially since they're built-in to many compilers these days, and are a bit faster IME. Are there any use cases that people here have experienced where Valgrind is their first choice? [1] https://github.com/google/sanitizers reply lbrandy 17 hours agoparentFor uninitialized memory reads, which is one of the biggest classes of issues, valgrind can still be invaluable. MSAN is one of the more difficult things to get setup and remove all the false positives. You typically need to transitively compile everything including dependencies, or annotate/hint lots of things to get the signal-to-noise ratio right. Sometimes its just easier/better/faster to run it under valgrind. reply rwmj 9 hours agoparentprevI think they are complementary. Valgrind is especially useful because you don't need to recompile everything. In other words, you can test what you ship (albeit slowly), and that includes dependent libraries that may have their own bugs. On the other hand, ASAN is essential for fuzzing code. reply nickelpro 12 hours agoparentprevCallgrind is indispensable for performance profiling and has no compiler-based equivalents reply Sesse__ 11 hours agorootparentCallgrind is certainly dispensable; just use a profiler. They are much, much faster, and more accurate as well. (Callgrind is using an idealized model of CPUs as they were around 1995, which doesn't match up all that well with how they work today.) There are some situations where I find myself using Callgrind, in particular in situations where stack traces are hard to extract using a regular profiler. But overall, it's a tool that I find vastly overused. reply nickelpro 3 hours agorootparentperf does not provide me with the complete callstack, it's a sampling profiler. In effectively all latency-sensitive contexts, sampling is worthless. 99.999999% of the time the program is waiting for IO, and then for a handful of microseconds there's a flurry of activity. That activity is the only part I care about and perf will effectively always miss it and never record it to completion. I need to know the exact chain of events that leads to an object cache miss causing an allocation to occur, or exactly the conditions which led to a slow path branch, or which request handler is consistently forcing buffer resizes, etc. I never need a profiler to tell me \"memory allocation is slow\" (which is what perf will give me). I know memory allocation is slow, I need to know why we're allocating memory. reply dennis_moore 11 hours agorootparentprevWhich profilers in particular are you referring to because I've always thought that Callgrind is a profiler? perf? reply Sesse__ 6 hours agorootparentperf or Intel VTune are the two standard choices AFAIK. Both have a certain learning curve, both are extremely capable in the right hands. (Well, on macOS you're pretty much locked to using Instruments; I don't know if Callgrind works there but would suspect it's an uphill battle.) Callgrind is a CPU simulator that can output a profile of that simulation. I guess it's semantics whether you want to call that a profiler or not, but my point is that you don't need a simulator+profiler combo when you can just use a profiler on its own. (There are exceptions where the determinism of Callgrind can be useful, like if you're trying to benchmark a really tiny change and are fine with the bias from the simulation diverging from reality, or if you explicitly care about call count instead of time spent.) reply rwmj 9 hours agorootparentprevperf on the whole system, with the whole software stack compiled with stack pointers, flamegraphs for visualisation, is an essential starting point for understanding real world performance problems. reply cozzyd 12 hours agoparentprevLots of third party libraries have valgrind suppression files for false positivity. reply patrick451 13 hours agoparentprevIME, sanitizer don't find enough issues compared valgrind, and valgrind doesn't require me to recompile the world. If I have anything that feels like UB, especially that I can trigger in a unit test, I run it through valgrind first. If the issue can only be triggered by running the whole system and valgrind slows it down too much, there's a good chance that sanitizers will also slow it down too much. reply synergy20 19 hours agoparentprevsame here, also for embedded systems valgrind is too heavy to run natively reply jmclnx 21 hours agoprevA great tool, I hope these fortune 500 Companies that are involve with Linux are supporting the Valgrind Developers. In reality I really doubt they are. reply orochimaaru 21 hours agoparentFortune 500’s rarely contribute but use a lot. I work for one. It’s usually a tussle between which vendor has managed to convince c-suite that software engineering is a dying discipline and their new genai tool is the utopia. Most Fortune 500 c suite are bean counters with abysmal engineering or product know how. They can’t see past the next quarter earnings report. I doubt long term contribution to meaningful open source is on their list. reply bluGill 9 hours agorootparentEventually they brought in a tool so bad that we were able to show how much less productive it was. I'm not supposed to talk about it publically though. reply Foobar8568 12 hours agoparentprevF500 are the cemetery of IT people. reply ellis0n 14 hours agoprevI remember adding 64-bit fixes to Valgrind to run it on the iOS Simulator when Macs went 64-bit, and I succeeded, it was incredible. Valgrind is one of the wonders created by humans. reply moomin 21 hours agoprevAs for the pronunciation, thanks for the tooling, but we’ll take it from here. reply ahartmetz 18 hours agoparentNo trouble at all here (German) - it's simply pronounced as if it was a German word. reply ahartmetz 12 hours agorootparent(Well, its original nordic pronunciation probably has a more o-like or anyway different 'a', a pointier 'i' sound, and a stronger 'r' than in German. But it seems to be accepted practice between Germanic languages to pronounce everything as if it was your native language - it's easy and ~always intelligible.) reply Sesse__ 11 hours agorootparentprevIf the “a” is supposed to be as in “value” (i.e. closer to ä in some but not all German dialects), that doesn't match typical German pronunciation, does it? (The -grind part is fine.) reply jepler 19 hours agoparentprevat $OLD_JOB I literally joked that we used a fork of valgrind just to fix the pronunciation. of course, our fork was also years behind the official version. these days, since I am doing bare metal embedded, I barely use valgrind; but it is game changing in the situations where it's useful. reply kimixa 20 hours agoparentprevAnd the times you end up needing tools like valgrind very much feel like a grind reply cortesoft 19 hours agoparentprevYeah, I feel like this is like GIF… the word takes on a life of its own, and the creator of the name does not get final say. reply nirvdrum 44 minutes agorootparentA key difference, to me at least, is that it's not a made up word (well, no more than any other established word). Ambiguity over its pronunciation comes from lack of familiarity with the source language. That's fine, we all need to learn, but to insist the native speaker is pronouncing it wrong seems a bit odd to me. reply mistrial9 21 hours agoparentprevagree - \"grinned\" is not at all the feeling I get..\"grind\" on the other hand, like skating.. yes more like it reply Sesse__ 11 hours agorootparentAFAIK it's from the old Norse word “grind” meaning fence or gate. It's the entrance to Valhalla. reply ChrisArchitect 21 hours agoprevtwenty-four years (2022) Some discussion then: https://news.ycombinator.com/item?id=32245136 reply munchler 21 hours agoparent2024 - 2022 + 20 = 22 years, not 24 years. reply o11c 19 hours agoprevOne thing I've never understood regarding valgrind - other than intentional leaks, are suppression files ever actually used due to an actual false positive, or is it just due to the bug being in someone else's code that's annoying to fix? \"We implement our own memory allocator\" is no excuse; the primitives you use should be hooked by valgrind so at most there should be false negatives due to your allocations being larger than the user-facing ones ... reply wavesquid 18 hours agoparent> are suppression files ever actually used due to an actual false positive, There used to be one in LuaJIT because it had an optimized string comparison that compared outside of the allocation (which is allowed by the OS as long as you don't cross a page boundary, which LuaJIT's allocation algorithm made sure it never did) The suppression was removed in https://github.com/LuaJIT/LuaJIT/commit/ff34b48ddd6f2b3bdd26... when the string hashing got a new implementation reply rwmj 9 hours agoparentprevYes, we use suppression files to cover expected leaks, as well as bugs in other code that is annoying to fix. For example the OCaml suppressions here are because OCaml (as expected) doesn't free static allocations at program exit. You can also see some real bugs we found: https://gitlab.com/nbdkit/nbdkit/-/tree/master/valgrind?ref_... reply glandium 19 hours agoparentprevFirst and foremost, suppressions can be used for more than leaks. For example, for \"Conditional jump or move depends on uninitialised value(s)\", which yes, there are very much false positives for because of e.g. tricky optimizations LLVM performs and that valgrind can't handle. But even for leaks, you can also have intentional leaks that valgrind will flag but that you can't really do anything about. One example is how using `putenv` can lead to you having to leak memory on purpose. There are many other cases. reply ggm 19 hours agoprevMaybe it's just me, but I think people tend to drive by memory leaks nowadays because the footprint of binaries has grown, but the size of ram has grown more-erly. Proper big. I routinely run on 1TB memory 128 core racks, and I don't worry about free() much. I'm not humblebragging, I actually think this is lazy (!) and I would benefit from more explicitly thinking about the memory consequences of what I do but there are some things which I used to freak out about growing to GB and now, I regard it as an investment on the future me, running the same thing: It's very likely I've got it in a hash structure of some kind already. I just add columns to the dict() elements. Down the other end, I recall some friends getting code which I expected to have to run on a major rack host to build onto a small memory model rPi and they said rust did that: allowed them to get rid of the overhang of other languages expectations to runtime size and be explicit about use and free in the heap. reply bayindirh 19 hours agoparentIn short, in my discipline, if you don’t free your memory you can eat a TB in 10 minutes. Moreover, if you fragment memory too much, then you’ll start to get segfaults when you want large segments of contiguous memory. Lastly, the same fragmentation will cause advanced libraries like Eigen to use many small memory areas, and jumping between them kills locality, hence causing you performance losses. I’m running tasks on (and administering) clusters with similar resources to yours, yet I always treat them like 486DXs with 4MB RAM, because I can’t restart them every week. reply kstrauser 18 hours agoparentprevI get it. And I do wish some systems were quicker to let the OS clean up after them on exit. For instance, the other day loaded a CSV with about 20 columns and 10M rows into a list of Python tuples so I could poke at them a bit. That took a short while and I was ok with that. I was more surprised when I closed the REPL and it hung for way longer than expected as it freed a couple hundred million objects. Now it could’ve been the case that some of those objects had a __del__ method that needed to be called or something. Absent that case, I’d have preferred the process just exited and been done with it. If that were a program that ran synchronously from a shell script, the shutdown GC time would’ve been nearly as long as the data loading time. Maybe Python could benefit from a fast_shutdown_GC function that only calls free() if an object is something with a non-trivial delete method. Otherwise, skip it and let the OS do its voodoo it does so well. I’m picking on Python here because that’s where I last saw this. The basic idea applies in lots of other cases though. reply loeg 19 hours agoparentprevI think the relative popularity of managed memory languages has grown and continues to grow. Even C++ is largely \"managed\" via mechanisms like unique_ptr, shared_ptr, or the standard collections. (Using new/delete directly is more or less a code smell these days.) C will always have a place, but despite working in it from 2011-2021 or so, I just don't use it at all these days. With \"owned\" allocations, you just don't need explicit free(). You're more likely to see memory leaks via unbounded collection size than actual unreferenced pointers. reply adrianN 12 hours agorootparentEvery correct program manages memory. Doing it in a structured way just makes it less bugprone. reply whiterknight 16 hours agoparentprevLuckily for us C programmers do care and track down leaks aggressively. reply minkles 12 hours agoparentprevWell not at that scale, but it isn't uncommon just to malloc/HeapAlloc a whole pile of RAM up front, spew your data structures into it and free it when it crashes / exits. It is a perfectly valid strategy. In fact I did this a couple of years back on a project I was working on maintaining in win32. It had a complicated memory management scheme for a GUI process that kept screwing up. Turned out it couldn't ever use more than 2MB of RAM so I just allocated 10MB up front at the start of the process and wrote a simple incrementing pointing counter in that allocated block and free'd it at the end like a short life pool. Solved all the issues. Machines it's running on all have at least 16GB of RAM so it's not exactly breaking the bank! reply rwmj 9 hours agorootparentFor short-lived programs perhaps. For things like servers that may run for months, leaks are absolutely important. Even memory fragmentation is a problem for us. We once had a chat server that would crash every 3 months, which we tracked down to memory being fragmented by a less than optimal malloc implementation in glibc. (Since the glibc fix was in the \"too hard\" category, we reluctantly decided to schedule a restart every month.) reply vinkelhake 19 hours agoparentprevTracking down memory leaks is just one of things that valgrind can do. reply michael1999 20 hours agoprevI remember how much my work improved when I got to use Purify. The pager just stopped going off after a while. reply ta8645 19 hours agoparentDid you find it superior to Valgrind in some way? reply michael1999 19 hours agorootparentNo. Purify was the commercial software that inspired Valgrind. It was Reed Hastings' first company, and I came across it working at a bank in 1996. I moved to Java with the millennium, and missed the rise of Valgrind. I'm just happy that everyone has good tools now. Writing C in those days was a rough business. reply dang 17 hours agoprevDiscussed at the time (of the article): Twenty years of Valgrind - https://news.ycombinator.com/item?id=32245136 - July 2022 (112 comments) reply inglor_cz 3 hours agoprevOnce upon a time, I worked on a mathematical project that hit a SIGSEGV after about 10 hours of running. Unable to find the problem, I ran the task on valgrind. Took almost a week, but it showed me the reason nice and clear. reply aptitude_moo 16 hours agoprev> As a result, I don’t have much use for Memcheck, but I still use Cachegrind, Callgrind, and DHAT all the time. I’m amazed that I’m still using Cachegrind today, given that it has hardly changed in twenty years. (I only use it for instruction counts, though. I wouldn’t trust the icache/dcache results at all given that they come from a best-guess simulation of an AMD Athlon circa 2002.) The few times I used the cache simulator and compared it to (Linux) Perf I found reasonable results. Someone can recommend a better cache simulator? reply brcmthrowaway 18 hours agoprev [–] Has anyone tried to Valgrind the rust runtime? reply pornel 17 hours agoparentIt works okay with Rust, but it's not really needed, except when integrating C code with Rust. For verifying unsafe code, Rust has a MIRI interpreter that catches UB more precisely, e.g. it knows Rust's aliasing rules, precise object boundaries, and has access to lifetimes (they don't survive compilation). Non-deliberate leaking of memory in Rust is not possible for the majority of Rust types. In safe Rust it requires a specific combination of a refcounted type that uses interior mutability which contains a type that makes the refcounted smart pointer recursive. Types that meet all three conditions at once are niche. The only annoyance/incompatibility is that Valgrind complains that global variables are leaked. Rust does that intentionally, because static destructors have the same problem as SIOF[1] in reverse, plus tricky interactions with atexit mean there's no reliable way to destruct arbitrary globals. [1]: https://en.cppreference.com/w/cpp/language/siof reply vlovich123 16 hours agorootparentHard disagree that it’s not needed. MIRI’s ability to verify non-trivial examples of code is quite limited so I generally just discount it. Valgrind goes beyond just asan+msan with heap and CPU profiling which can be useful if you’re trying to extract every last bit of performance. reply rwmj 9 hours agoparentprev [–] Yes we do, regularly, and unlike the other response, it's necessary as you can have leaks in C libraries even if they happen to be called from rust. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Valgrind, an instrumentation framework for dynamic analysis tools, celebrated its 20th anniversary since its initial release in July 2002.",
      "Created by Julian Seward, Valgrind was inspired by the commercial tool Purify and aimed to be an open-source solution for x86/Linux, detecting memory management and threading bugs.",
      "Over the years, Valgrind has evolved with contributions from the community, adding tools like Cachegrind, Helgrind, and Massif, and has become a standard for bug detection in C and C++ programs."
    ],
    "commentSummary": [
      "Valgrind, a memory debugging tool, has been essential for C programmers for 20 years, known for detecting memory leaks and performance issues despite slowing down performance.",
      "Alternatives like Clang's address sanitizer and built-in IDE tools are faster but may not catch all issues, making Valgrind's ease of use without recompilation valuable.",
      "Despite the rise of managed memory languages and large memory capacities, Valgrind remains crucial for long-running applications and precise memory management."
    ],
    "points": 221,
    "commentCount": 54,
    "retryCount": 0,
    "time": 1724877723
  },
  {
    "id": 41383126,
    "title": "Companies Lobby Against Giving the Military the Right to Repair",
    "originLink": "https://www.404media.co/appliance-and-tractor-companies-lobby-against-giving-the-military-the-right-to-repair/",
    "originBody": "Lobbying groups across most of the device manufacturing industry—from tractor manufacturers to companies that make fridges, consumer devices, motorcycles, and medical equipment—are lobbying against legislation that would require military contractors to make it easier for the U.S. military to fix the equipment they buy, according to a document obtained by 404 Media. The anti-repair lobbying shows that manufacturers are still doing everything they can to retain lucrative service contracts and to kill any legislation that would threaten the repair monopolies many companies have been building for years. In a May hearing, Sen. Elizabeth Warren explained that “contractors often place restrictions on these deals [with the military] that prevent service members from maintaining or repairing the equipment, or even let them write a training manual without going back to the contractor.” “These right to repair restrictions usually translate into much higher costs for DOD [Department of Defense], which has no choice but to shovel money out to big contractors whenever DOD needs to have something fixed,” she added. Warren gave the example of the Littoral combat ship, a U.S. Navy vessel that costs hundreds of millions of dollars per ship. “General Dynamics and Lockheed Martin consider much of the data on the ship to be proprietary, so the Navy had to delay missions and spend millions of dollars on travel costs just so that contractor-affiliated repairmen could fly in, rather than doing this ourselves,” she said. To solve this problem, Warren and other lawmakers introduced something called Section 828 of the Defense Reauthorization Act, a must-pass bill that funds the military. Section 828 is called “Requirement for Contractors to Provide Reasonable Access to Repair Materials,” and seeks to solve an absurd situation in which the U.S. military cannot always get repair parts, tools, information, and software for everything from fighter jets to Navy battleships, because the companies want to make money by selling their customers repair contracts. Section 828 states: “The head of an agency may not enter into a contract for the procurement of goods or services unless the contractor agrees in writing to provide the Department of Defense fair and reasonable access to all the repair materials, including parts, tools, and information, used by the manufacturer or provider or their authorized partners to diagnose, maintain, or repair the good or service.” Manufacturers are not happy about this prospect, and are aggressively opposing it. But, interestingly, it’s not just major military contractors who build warships who are mad. Some of the groups opposing the legislation in the letter we obtained are things like the “Institute of Makers of Explosives” and the Aerospace Industries Association. But others opposing it include, for example, the Irrigation Association, whose members make irrigation equipment, the Motorcycle Industry Council, the North American Equipment Dealers Association (who represents John Deere and other tractor manufacturers), the Plumbing Manufacturers Association, AdvaMed (which represents the medical device industry), TechNet (whose members make consumer tech), various state groups like Wisconsin Manufacturers & Commerce and the Arizona Manufacturers Council, and dozens of others. In the letter to lawmakers, these groups and dozens of others argued that being required to sell repair parts to the military “would impose significant burdens on contractors throughout the country, including the many small and medium-sized businesses and commercial suppliers that contractors rely on to support the Department’s operational readiness and effectiveness.” The letter states that the companies themselves “are critical to the Department’s ability to repair and maintain its assets,” which the military Warren has said is exactly the problem: the military is often stuck relying on the original manufacturer of a product to either do the repair or send through critical repair information, which can be expensive and cumbersome. The letter argues that the legislation “would undermine the principle underpinning existing technical data rights statutes, which are designed to balance the government’s technical data needs against contractors’ need to protect sensitive proprietary and trade secret information.” This idea that device repair information cannot be provided without giving away trade secrets and proprietary data is one that manufacturers have been making for years at the state level to kill right to repair legislation for consumers. State lawmakers largely have stopped buying this argument, but anti-repair lobbyists are still trying this line of attack with Congress and the military. The letter also takes issue with the idea that there would be cost controls for the military, which Warren said are necessary to prevent “price gouging.” The fact that groups who represent companies that have nothing to do with the military have lined up to oppose this suggests that device manufacturers more broadly are worried about a national right to repair law, and that the entire sector is trying to kill repair legislation even if it would not affect them. “The goal of this legislation is to ensure that the lives of our service members, and their operations, are protected from repair restrictions gumming up the works. Incredibly, most of the signers don't even make military equipment! They range from motorcycles, to farm equipment to consumer devices,” Nathan Proctor, senior director of consumer rights group US PIRG’s campaign for the right to repair, told me. “Why are appliance manufacturers against the military buying equipment they are allowed to fix? Are the profits from additional service revenue, or more frequent device replacements, more important than the safety of our military personnel?” About the author Jason is a cofounder of 404 Media. He was previously the editor-in-chief of Motherboard. He loves the Freedom of Information Act and surfing. More from Jason Koebler",
    "commentLink": "https://news.ycombinator.com/item?id=41383126",
    "commentBody": "Companies Lobby Against Giving the Military the Right to Repair (404media.co)212 points by worik 23 hours agohidepastfavorite96 comments squarefoot 20 hours agoWhat a bunch of greedy bastards. Not being able to repair an appliance/device/tool/whatever in some contexts could make the difference between life and death. And not just in combat. Imagine if the air filter on the Apollo 13 couldn't be hacked with what the astronauts had at hand up there because it was driven by closed electronics whose brain was sandwiched in multiple layers of DRM, NDAs, stupidity and lawyers: the guys would have been doomed. reply akira2501 19 hours agoparent\"We're sorry this Lithium Hydroxide canister does not appear to be genuine or has been refilled. Please contact Boeing for assistance and to order genuine parts.\" As an aside one of the things I love about old school military equipment is the \"battle short.\" It effectively disables all the safety equipment and limit switches and allows the device to run even though the device believes it should not. There's an extra measure of confidence you get just from seeing that option available to you. \"No, damnit, RUN!\" https://en.wikipedia.org/wiki/Battleshort reply foobarbecue 14 hours agorootparentCuriosity (the Mars rover) has a battleshort mode and when we use it there's a message that says \"putting my battle shorts on.\" Never fails to crack me up. reply pcdoodle 18 hours agorootparentprevThis is why I miss Visual Basic 6: On Error Resume Next reply avgDev 5 hours agoparentprevWhat I hate the most is when companies will come out and say they don't want people touching things due to safety concerns. The awful thing is that it is working. More and more I see people saying \"Oh I won't touch the brakes on my car because what if I mess up\". I am confident most people could replace the brakes on their car. reply MaxPengwing 3 hours agorootparentIt's not just repairing cars, I told a coworker I replaces the fuse in my Bosch blender and he looked at me as if I was insane. \"But what if it catches fire?\" was his reply. Dragging my team to the nearest maker space for a teambuilding exercise as soon as I figure out how to convince HR to pay for it. People need to know things do not catch fire if you repair it. reply tracker1 34 minutes agorootparentI dunno... I had a microwave that came on when you opened the door... turns out it would boil water with the door closed without entering time too... Thanks GM, love the \"safe\" microwave that nobody can service. Replaced with the dumbest microwave option I could find. reply squarefoot 1 hour agorootparentprev> due to safety concerns Seems just a rehash of the same old excuse: \"someone think of the children!\" which usually comes from people not giving a damn about children but worried about their own interests. reply Brian_K_White 17 hours agoparentprevEver since the first time I encountered HDCP I have had a little fantasy about the bridge screen on the Enterprise refusing to display anything because of an hdcp glitch. These days the imaginary recalcitrant screen isn't simply blank though, now there are ads which never fail. I was at a local gyro shop a few weeks ago and all their menu displays were showing Amazon ads over their menus. I gave up on humanity right then. reply squarefoot 9 hours agorootparent> Ever since the first time I encountered HDCP I have had a little fantasy about the bridge screen on the Enterprise refusing to display anything because of an hdcp glitch. Speaking of SciFi, I fantasized about a novel in which an alien species visiting our long dead planet in the future can't recover what's left of our culture because it had been all wrapped in DRM whose keys died with us. By extension, if the Rosetta Stone makers adopted the same practices, we would know squat about ancient Egyptian language. https://en.wikipedia.org/wiki/Rosetta_Stone reply ryukoposting 20 hours agoprevIt makes sense that the military would be the first organization to get widespread federal R2R protections. The US Gov't basically uses the DoD as a funding firehose for private sector R&D, so it's only natural that there would be some ground rules for companies that want to \"take a drink from the hose,\" so to speak. Hopefully this will serve as a \"Eureka\" moment for the powers that be in DC. Just cut out the part that says \"but only when the military is the customer.\" reply noobermin 10 hours agoparentMany of the powers that be, particularly those with positions of influence in the DoD make their riches off exclusive contracts with the DoD with private companies they own or are invested in. Not to mention lawmakers themselves who invest in such contractors. The powers that be in DC are the problem, they don't want to fix it. reply fransje26 11 hours agoparentprev> Hopefully this will serve as a \"Eureka\" moment for the powers that be in DC. And who do you think has been lining the pockets of said powers in DC, to get the military in that situation in the first place? reply jabroni_salad 20 hours agoprevIf my exmil co-workers have taught me anything its that anything and everything can be macgyver'd in a pinch. If jerry rigging was a sport these guys would be ranked competitive players. In this case, your 'threat actor' is servicemen and 'arms race' is like, their whole thing. These guys are bored out of their mind for 95% of their career and will take anything apart if the activity gets them 2 hrs closer to a break. reply lotsofpulp 20 hours agoparentI bet they cannot macgyver it if it’s software locked. reply dismalpedigree 19 hours agorootparentYou drastically overestimate the vast majority of military systems. reply lazide 8 hours agorootparentprevScrewdrivers and duct taped on wires can be remarkably effective at bypassing switches and relays. And having a random private stand around and poke something with a screwdriver when you want something to explode is, well, pretty much how much of the military works anyway. reply fragmede 20 hours agorootparentprevbecause they can't run Ida pro and hack it? reply lotsofpulp 19 hours agorootparentNot “in a pinch”. reply aleph_minus_one 19 hours agorootparentprevThere exists Ghidra ... :-) reply transpute 17 hours agorootparentCreated by ... the military. reply aleph_minus_one 10 hours agorootparentIt is debatable whether you consider the NSA to be part of the military or to be something separate. reply M95D 7 hours agorootparentBut the reply is so much more fun if we consider it part of the military. reply plussed_reader 19 hours agorootparentprevAnd the years of prep work to be able to run the software effectively.....? reply transpute 17 hours agorootparentCall bored reverser colleague who helped test Ghidra. reply plussed_reader 14 hours agorootparentWhere do I get one of those in a public Edu? reply transpute 10 hours agorootparentThis sub-thread is about \"your 'threat actor' is servicemen and 'arms race' is like, their whole thing\", but academic researchers at TU Delft, TU Dresden, ETH Zurich & peer institutions might have relevant skills. See the top story on HN front page: air conditioner customer bypasses software-locked broken tablet to run Android control panel app on generic hardware, avoiding $1600 extortionate \"repair\" fee. Not only did they learn an entirely new reversing toolkit just to solve this one problem, they did a 10-year upgrade of their blog so they could tell the world how they did it. Macgyver would approve. https://news.ycombinator.com/item?id=41386319 reply jprd 21 hours agoprevEisenhower warned us about this kind of eventuality, and I personally never thought it could ever get this far. Outrageous. reply krapp 20 hours agoparentIf you're referring to the military industrial complex, I don't think this is what Eisenhower was warning about. reply plussed_reader 19 hours agorootparentAn easy litmus test if a company is part of the complex is whether they're a defense contractor or not. The companies in TFA don't pass this smell test. reply worik 19 hours agorootparentprev> If you're referring to the military industrial complex, I don't think this is what Eisenhower was warning about. The opposition to the \"right to repair\" is coming from the \"military industrial complex\" That complex is the nexus of industrial players who have become to feel entitled to anything they want That is what they are doing with the opposition to \"right to repair\" and that is what, in general terms (he was predicting the future - cut him some slack) Eisenhower was warning about. reply taejo 15 hours agorootparentThe military-industrial complex is a complex of the interactions between the military and the industry that supplies it, not just the latter. It's the industry side of the complex that is opposing it, the military is asking for it. reply kiba 15 hours agorootparentprevIt is just business in general that opposes the \"right to repair\" . Military contractors are not exception to the rule and there's no need to single them out specifically. We have a business culture that unhealthily prioritize short term profit at the expenses of product excellence and stakeholders. reply NalNezumi 10 hours agoprevSlightly tangential, but I would love to see a scifi scenario of (fictional) USA vs something like Russia, where the premise is that the \"rugged, lower economic power\" enemy beats the US because complacency that lead to buerocratic mess, such as army of lawyer the size of the military, no right to repair, privatized medical care for military and heavy lobbying & private media propaganda creating a political gridlock. I think there's many underdog scifi stories of the guerilla freedom fighter vs big (inflexible) government, but most of them from the pov of the underdog. I'd love to see a from the view of a corporate middleman seeing the house of card crumbling, not because military but because buerocratic mess, and they would've won the war decades ago if the army of lawyers wasn't there reply spacebanana7 9 hours agoparentYou might get something similar from reading accounts of the Chinese intervention in the Korean war. They were actively winning territory against the UN/US forces. The (CCP) Chinese were a \"rugged, lower economic power\" opponent and the UN/US had much better tech, including nukes. A lot of the Chinese ruggedness came in the form of being willing to tolerate immense casualties and having strong internal media control. Sad but effective solutions to the healthcare and propaganda issues. reply science4sail 3 hours agoparentprevI think that's a common scenario in historical fiction depicting conflicts between upright barbarians and decadent empires. The empire could easily crush the barbarians, but it's too preoccupied with internal politics and power struggles to do so. reply WatchDog 17 hours agoprevRight to repair legislation makes more sense to me for consumer products, where the individual bargaining power is quite low. The military has a much much stronger bargaining position, why don't they already require that their contractors provide repairable equipment? reply zdragnar 16 hours agoparentSimple answer: the people doing the buying aren't the people that are using. Slightly less simple answer: the amount of red tape around getting contacts is obscene, so the DOD has severely limited the number of places it can go to buy many bits of kit. There's a lot of incestuous relationships between the military and the companies that supply it as well. On the one hand, that's not strictly a bad thing. A former soldier knows rather well what it's like to be in the field, and supporting veteran run businesses is a good thing to do. On the other hand, what's more often the case is desk jockeys move into lobbying positions and / or join the large corporations after they put in some time and the network effect takes over in a rather invirtious cycle. There are literally consulting companies that exist to help you navigate the red tape to get contacts, because doing it on your own means losing to the big names (often for whom the very contacts themselves are tailored to). reply andrewflnr 16 hours agorootparent> Simple answer: the people doing the buying aren't the people that are using. This doesn't work at all. The logistics desk jockeys also benefit financially from right to repair. The rest of your post doesn't really have anything to do with the user/buyer divide, at least not the way we usually think of it. reply zdragnar 12 hours agorootparentThe rest of the post absolutely does, in that it explains why the people doing the buying aren't considering the needs of the people doing the using. It goes further to explain why their interests actively work against the kind of competition that might be inclined to offer right to repair as a selling point. I also highly doubt anyone doing the buying are having either their performance or their budget impacted by the cost of repairs. Those are certainly separate budgets, and the DOD has never passed a financial audit; for the last six years, it hasn't been able to provide auditors with enough information about its $4 trillion in assets to even form a qualified opinion. reply noobermin 10 hours agoparentprevDid you know medicare is unable to negotiate drug prices and usually pays through the nose to pharma companies on behalf of medicare beneficiaries? The Biden admin managed to negotiate down less than 20 drugs and this was hailed as a progressive victory which just highlights how broken it is. This for me is the strongest argument against single payer healthcare in America. As long as bribery is considered free speech, nothing where the government is the single payer (like the DOD is for military equipment and goods) can ever work without extensive graft. Repeat for things like roads, geneal infrastructure, the list goes on. reply rqtwteye 17 hours agoprevWhat are they going to do when they are in a real war with a capable enemy? In the midst of battle call the manufacturer and request a service tech to fly in while bombs are flying? Or maybe spend a few hours calling customer service? reply hunter-gatherer 17 hours agoparentThat's exactly the scheme for for defense contractors, actually. They'll happily send technicians to an austere environment to do maintenance for an extra fee. This has been going on for years, but it is just getting worse. reply rqtwteye 14 hours agorootparentThat's not going to work in a real battle. reply dotnet00 17 hours agoparentprevThey get to extort more money at that time for \"lost revenue\" as the cost of allowing field repairs. reply SideQuark 19 hours agoprev\"The Section would require Department of Defense procurement contracts to be contingent on a contractor's agreement to continually provide access to all repair materials and information, with no carve-outs or limitations to protect sensitive trade secret information.\" \"To enable access to sensitive proprietary and trade secret information beyond that necessary for standard repair and maintenance, customized license agreements can be tailored on a case-by-case basis to achieve specified repair and maintenance objectives. reply NegativeK 16 hours agoparentI assume that doesn't apply to source code? It seems somewhat absurd to suggest, but it's less absurd if a defense company provided binaries and then suddenly goes out of business. reply M95D 7 hours agorootparentIs it even possible for a defense contractor company to go out of business? Aren't they in the \"too big to fail\" category? reply ungreased0675 19 hours agoprevFor some time, a contract winning strategy has been to underbid on the hardware and make most of the profit on the long-tail service contract. Eliminating that business model will raise prices a little bit on hardware, but net savings would likely be significant. reply robwwilliams 22 hours agoprevWith Warren on this proposed legislation whatever the pain for vendors. Lock-in on service might be acceptable during peace but not at all in combat. Slightly ironic that this should apply with equal force to code. reply passwordoops 21 hours agoparentLock-in on service should never be acceptable under any circumstances, war, peace, military, civilian reply crest 20 hours agorootparentLock-on instead of lock-in? reply blooalien 19 hours agorootparentPretty sure they mean what they said. \"Lock-in\" in this context typically refers to \"vendor lock-in\" which is a common practice among unethical corporations selling products or services. They will often use underhanded tactics and \"dark patterns\" to psychologically or physically (through hardware means) to lock an \"end user\" into the forced usage of that vendor's product, while making it as painful / inconvenient as possible to switch to any possible competitor. reply notinmykernel 19 hours agoprevHow is this legal in the USA today? With a debt of $34 trillion, and military being the primary financial burden? Get all the way out of here with this. Any company that is lobbying against right to repair should have to pay a fine per item that breaks. After a certain breakage percentage, their ability to obtain future government contracts is revoked for a period of 1 year, and for repeated infractions revocation is 5 years. reply growthwtf 19 hours agoparentThe Military is actually the ~5th biggest contributor to the current national deficit, behind social security, interest on the debt, and various health programs. The largest contributors to the debt over the last couple decades have been stimulus packages and tax cuts. reply somenameforme 14 hours agorootparentInterestingly, you're both right, but most people don't understand how government spending works. There's two main categories of spending - discretionary and mandatory. Discretionary spending is the budget submitted by Congress where they allocate money to various things. Mandatory spending is compulsory and done without a vote or manual appropriations. Things like social security, pensions, medicare, and so on are mandatory. Discretionary is military, education, housing, transportation, and so on. And, of this spending, military is, by far, the lion's share of it all. So each dollar spent on a bomb half-way around the world is one less dollar that could have been spent on e.g. education, infrastructure, or housing - which are predominantly discretionary. And notably, discretionary budgets are relatively small, contrasted against the overall budget. In 2024 the entire discretionary budget was \"only\" $1.8 trillion. So things like \"just\" a hundred billion might seem fairly small, but are in reality a substantial chunk of all our discretionary allocations. Then there's the military, which eats up nearly a trillion dollars of this spending. In 2024 it was $886 billion, which does not include the spending on various wars around the world. reply joebob42 12 hours agorootparentI think the naming on the split is a little disingenuous. It's \"mandatory\", but it's still just laws. I get that the funding is decided differently, and I'm not making any claim one way or the other regarding whether Medicare, ss, etc should be changed, but it isn't like there's some law of nature we can't adjust if we wanted. reply IX-103 5 hours agorootparentIf you think of the government like a business, Social Security and Medicare are like pensions. Should companies be allowed to include pensions in their operations budget, or should pension planning be entirely separate? I can guarantee you that if companies were able to include the pension fund in their operations budget there would be a massive increase in pension shortfalls as their reserves get raided for operations expenses. The whole strategy of including \"entitlement\" spending in the budget conversation is a part of a conservative plot to get rid of Social Security and Medicare. That's why we shouldn't include it as part of the budget. reply BenjiWiebe 16 hours agoparentprevHey, I like that concept! Maybe it could apply to everyone. Make a product that doesn't break, you can ignore right-to-repair. It broke anyways? Fine, pay this fine. I don't care much about right to repair on things that work flawlessly for decades. reply jmclnx 21 hours agoprevOf course they are :) Military Vendors lap up Gov. money like a Camel in a desert at an oasis. Without that money, the US economy would collapse over night. I hope the Military is allowed to repair their equipment. In a war, that ability is mandatory. reply blooalien 19 hours agoparent> \"I hope the Military is allowed to repair their equipment. In a war, that ability is mandatory.\" Even more than the right to repair, a lot of stuff designed for use in war should be designed right from day one with easy repairability (and if necessary \"Jerry-rigging\" it) in the field first and foremost in mind during the design process (as often was the case at some point in the past). Anything less risks human lives. reply floxy 20 hours agoparentprev>Without that money, the US economy would collapse over night. But that money would just get spent by other government agencies, or the taxpayers, right? And if the military vendors aren't efficiently using that money, then society would end up better off if they (the military vendors) weren't spending it. reply janalsncm 19 hours agorootparentDepends on how the money was disseminated. Money only goes into the economy if it’s spent. If you give 1 person 2x as much money they don’t buy 2x as many cars, pairs of shoes, and iPhones. Wealthy people tend to save their money. reply dgfitz 19 hours agorootparentprevImagine if Boeing, Northrop, Lockheed, Raytheon, general Dynamics (I could keep going) all shut down. Ignoring the what, million+ people out of jobs, the second and 3rd order effects would be astronomical. Vendors of contractors, vendors of vendors of contractors, internationally, all lose their revenue streams. There would be no time to recover. Phase it out over 10 years, I mean maybe then it wouldn’t be a complete collapse, but fuck would It be ugly. Oh and at year like… 8, the USA gets okie-doke’d and in 3 generations everyone is speaking !english. reply darth_avocado 21 hours agoparentprev> like a Camel in a desert at an oasis Well the camels stop after 30ish gallons. Military Vendors lap up Gov. money like a blackhole laps up pretty much everything in it's vicinity. reply blooalien 19 hours agorootparent> ... \"like a blackhole laps up pretty much everything in it's vicinity.\" That right there might be just about the most accurate analogy for unchecked greed I've read in quite a long while. reply dgfitz 19 hours agorootparentprevI can fix this for you with a sed s/Military// Military vendors are why the government is a bad steward of money, that explains everything! /s reply blahyawnblah 21 hours agoprevSo the companies are going to send repair people all over the world, have people that have clearance, and potentially go into actively hostile areas? reply ptero 20 hours agoparentThat's what companies already do, charging the government a pretty penny for being in theater. reply bityard 20 hours agoparentprevIt's not unheard of. The contractors are generally former military. reply psunavy03 20 hours agoparentprevContractor tech reps have been doing this already since the Cold War. reply firesteelrain 19 hours agoparentprevYes, we had them in Iraq helping us. reply Doches 20 hours agoparentprevPalantir has been doing exactly this for more than a decade... reply istultus 20 hours agoparentprevNice, you've found a pathway to hiring more veterans reply Rebelgecko 18 hours agoparentprevYes, and they'll be well paid for it reply evanjrowley 3 hours agoprevThe military should factor the positions of companies like this into their supply chain risk assessments. reply a3n 20 hours agoprevSimple solution: Only let contracts where verifiably senior company technical employees are to accompany equipment in war and peace, and to have all technical data in their possession, verified unencrypted. After they're all dead, the president signs an executive order confiscating all on-site data and equipment, and authorizing military to repair. This would also be spelled out in the contract. reply WillAdams 20 hours agoparentAdmiral Rickover's solution for the U.S. Navy submarine program was to write into the contract having company executives on the boat for its first dive. reply benreesman 20 hours agoprevElizabeth Warren being in the DoD’s corner on basic serviceability of equipment critical to the sustained warfighting capability of our military against an industry flexing DRM was not on my late capitalism bingo card. reply DoctorOetker 10 hours agoparentFor those who believe in the politics circus, wouldn't this be a much better female president candidate compared to Hillary Clinton (first declare independence from Britain then go back to kings and queens?), or Kamala Harris? reply autoexec 11 hours agoparentprevIt's very much in character for her. She's been supportive of consumer rights and protections for long time. She's got a long history of being anti-DRM and pro-right to repair. reply djaouen 21 hours agoprevThe CEOs proposing such ideas should be locked up as traitors lol reply ravenstine 20 hours agoparentI didn't expect someone else to say this, but that is my first thought. If I became supreme leader overnight, I would place a lot of people behind bars, and these guys would be among the first. It's pretty outrageous how much society tolerates the leadership class. reply blooalien 19 hours agorootparentI vote ravenstine for \"Supreme Overlord of Earth\" 2024! (Be awfully hard to really do much worse than the \"leaders\" we've currently got in charge or on offer to choose from, yeah?) reply shiroiushi 18 hours agorootparentWhoever s/he is, ravenstine couldn't possibly be worse than the world's current crop of leaders. It's not a bad idea; perhaps just make it a limited 5-year (or 10-year, or whatever) term, so that if the power goes to his/her head, the damage will be limited. reply djaouen 17 hours agorootparenthttps://www.youtube.com/watch?v=gpH_PIqT-q8 reply ansmithz42 20 hours agoparentprevNah! I think the CEOs should be the first ones sent into the combat front line zones. reply blooalien 19 hours agorootparent> \"Nah! I think the CEOs should be the first ones sent into the combat front line zones.\" At least then they'd be able to (somewhat) justify their insane \"pay packages\", \"golden parachute\" and \"bonuses\". CEO: \"I risked my life for that money!\" reply mc32 21 hours agoprevThis is ridiculous. Imagine you're in the middle of a battle and you need to get an okay to fix something outside of an approved/certified repair outfit? That would be a physical DDOS attack with severe consequences. I hope, one can hope, the brass, despite any consequence to their kickbacks, care a little about the grunts on the ground who would be exposed to the consequences of this nonsense and quash this unpatriotic grift. This is mercenary attitude --which if you're dealing with mercenaries, you can expect, but your own people and companies? That's... insane. reply dismalpedigree 19 hours agoparentNo need to imagine. It happens. There are plenty of stories from GWOT where field reps evaced to Dubai while the parent company negotiated new terms. Its a complete disgrace. reply ein0p 13 hours agoprevI’m not sure why anyone would want to handle field repairs where a rocket can blow up your entire operation at any time. Or maybe have some other type of repair in mind. In for a penny, in for a pound, bros. reply trhway 20 hours agoprev[saying without prejudice, just using real example to illustrate the power of tech company, or even a single person like in this case, behind locked-in tech] Back then Elon Musk refused to turn the Starlink on on the Black Sea and the Ukrainian drones weren't able to perform the planned attack on the Russian Navy ships there (the situation later was rectified by Pentagon itself directly contracting some of the Startlink terminals or something along these lines) In general the modern weaponry is very complicated and Western tanks and artillery systems would be transported to Poland from Ukraine for service and repair. I think recently they tried to establish a repair base in Ukraine, yet i'm wondering whether the growing complexity of the hardware may make the \"right-to-repair\" issue closer to moot in larger part. I mean the right-to-repair in civilian case allows independent companies to provide repairs, while i don't see any practical way for such independent companies in the military case. reply worik 19 hours agoparent> In general the modern weaponry is very complicated No It is bad design As another commenter commented the ability to repair in the field, in adverse conditions, should be a design criterion. reply trhway 19 hours agorootparentThe way things go there would be almost no people in the field, just drones of all kinds and occasional stormtrooper teams in extremely expensive stealth cloaks. Basically no human would be able to exist in the environment with several thousand drones per kilometer. And I don’t think much of these drones are going to be repaired , more like smartphones - nobody repairs them. By the way, extremely important part, becoming even bigger and more important - the massive scale battlefield data intelligence gathering, including from all those drones, processing and targeting is done in Ukraine by Palantir in major part by their people deployed there. There is no real right-to-repair or ability to repair in the field when it comes to such software (or to communication networks like Starlink). With that background it is really small peanuts, which will take all the attention away from important things, whether soldiers can replace on their own an RFID-ed DRM-ed valve in the howitzer blowback hydraulics. reply jauntywundrkind 21 hours agoprev [–] It feels like the military is well into pushing back in a lot of ways. \"Modular Open Systems Architectures\" ((M)OSA) is a buzzword you can't go ten pages through a proposal or strategy doc without running into, after years of the military enduring the same locked down IP shit the rest of the world has been mixed in for decades now. And the military seems to be one of the few places opening up expectations that this unevolvable hell isn't good enough. One particular write up that really got me was just a brief part of the extremely long & sad ProPublica write-up on the Litoral Combat Ship (LCS). The part about the sailors not even having physical access to a computing center was off the wall madness to me, really epitomized & made real to me a certain despairing level of madness that unregulated capitalism tries to steer humanity into. https://www.propublica.org/article/how-navy-spent-billions-l... It's not entirely clear how much remedy we're getting from this (M)OSA kumbaya, what are the bigger successes & failures or what technically it looks like (would so love to be able to see how the Arsenal of Democracy is coping with the corporate raiders within), but there's at least strong lip service to change, mutual recognition that systems need to be flexible & reconfigurable & adjustable & modular, which is something. reply georgeplusplus 20 hours agoparent [–] >>>> that unregulated capitalism tries to steer humanity into. What part of this economy seems unregulated to you? What a ridiculous notion talking about military contracts no less. You couldn’t be more far off from finding the source of problem then just mindlessly throwing in a dig at capitalism, the way the government awards contract is anything but competitive or capitalistic reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Lobbying groups from various device manufacturing sectors are opposing legislation that would facilitate the U.S. military's ability to repair their equipment, aiming to retain lucrative service contracts and prevent repair monopolies.",
      "Sen. Elizabeth Warren and other lawmakers introduced Section 828 of the Defense Reauthorization Act to mandate contractors provide reasonable access to repair materials, citing high costs and delays due to proprietary data restrictions.",
      "Opposition from manufacturers, including those unrelated to military equipment, suggests broader concerns about a national right to repair law, prioritizing service revenue over military safety."
    ],
    "commentSummary": [
      "Companies are lobbying against granting the military the right to repair their equipment, citing potential dangers.",
      "Critics argue that the inability to repair devices in the field could be life-threatening, referencing historical examples like the Apollo 13 mission.",
      "The debate highlights broader issues such as the right to repair, corporate greed, and the influence of the military-industrial complex."
    ],
    "points": 212,
    "commentCount": 96,
    "retryCount": 0,
    "time": 1724872431
  },
  {
    "id": 41389176,
    "title": "Homemade Automated Solar Concentrator",
    "originLink": "https://github.com/remipch/solar_concentrator",
    "originBody": "Hi HN!I quit my job two years ago to have more time to work on my side projects.The main one is an automated solar concentrator.I&#x27;ve just open-sourced it, it&#x27;s not perfect nor finished, and I still have a lot of ideas for further development, but I&#x27;m interested in knowing what you think of it.There are many applications where concentrated solar power could be a viable environmental and economic solution, I hope this technology will one day be more widely used.Feel free to give any feedback and ask questions.",
    "commentLink": "https://news.ycombinator.com/item?id=41389176",
    "commentBody": "Homemade Automated Solar Concentrator (github.com/remipch)201 points by remipch 8 hours agohidepastfavorite57 comments Hi HN! I quit my job two years ago to have more time to work on my side projects. The main one is an automated solar concentrator. I've just open-sourced it, it's not perfect nor finished, and I still have a lot of ideas for further development, but I'm interested in knowing what you think of it. There are many applications where concentrated solar power could be a viable environmental and economic solution, I hope this technology will one day be more widely used. Feel free to give any feedback and ask questions. hakonjdjohnsen 7 hours agoCool work! I do research in nonimaging optics, the optics of achieving high concentration ratios (or wide tolerances to errors) in solar concentrators. I like that you are implementing closed-loop control. This is all the rage also in large-scale heliostat fields. Most traditional heliostats are controlled using open loop, which places very strict requirements on both the mechanical structure, the actuators, and on the kinematic model, leading to expensive and very stiff heliostats. People are therefore moving towards cheaper heliostats where the tracking precision is achieved through closed-loop control. Implementing closed-loop control is a little bit more tricky when you have overlapping focal spots from thousands of mirrors, but there are approaches that are being developed, e.g. having cameras around the target looking back out over the heliostat field (developed by Heliogen among others). You mention the challenge of light only being focused for a few hours per day. This is also a problem with large helisotat fields, and is also a field of active research. There's a group at University of Arizona with Professor Roger Angel developing heliostats that actively deform through the day to keep the perfect shape, and there's also an Australian company (Heliosystems) building heliostats that passively deform from gravity to keep as correct shape as possible. When you are only using a single heliostat, as in your project, you could also consider building it as a Scheffler reflector - placing it on a single-axis polar-aligned tracking axis that passes through your target. Then it only requires single-axis tracking through the day, with some (possibly manual) seasonal adjusting. I am very happy to see that you are highlighting the inherent risks in concentrated sunlight. There are lots of stories about people accidentally settings stuff on fire if the tracking doen't track correctly. reply remipch 6 hours agoparentThank you very much for your kind and detailed reply! Indeed, the closed-loop control was the initial idea which convinced me that it would be possible to build the mechanical parts by hand with common tools. In other words, the software \"smartness\" compensates for the mechanical \"ugliness\". Another initial idea was to do multi-panels (several orientable panels) with a single camera looking at the target. Indeed, it's not easy, so I finally went back and decided to finish and release something with a single panel. Nevertheless, I have some ideas to do multi-panels with a few more cameras. I would like to work on them in the near future. Thank you for all the references, I will spend time to explore them. There is also a company that uses vacuum to adjust the mirror shape, I'll try to find it and post it here. I wanted to emphasize the inherent risk because my project is not a finished product, but a work-in-progress/proof-of-concept. reply remipch 5 minutes agorootparentFYI, this is the \"vacuum adjustable focus mirror\" I mentioned: https://lm.solar/order/4-square-rigid-aluminum-composite-mir... reply hakonjdjohnsen 4 hours agorootparentprevYeah exactly! I like your cable-drive concept by the way. Did you describe it in more details anywhere? Heliogen were also developing a cable-drive system for their commercial heliostats, but I don't know if they are still working on it. How are you getting the right mirror orientation for each mirror (aka canting)? Custom spacers for each mirror? One trick for closed-loop control with many heliostats/panels is to have a few cameras surrounding the receiver. When they look back at the mirrors, they will see the circumsolar radiation (how the sky gets brighter as you get closer to the sun). By comparing the brightness of the sky at different cameras, you can estimate which cameras is \"closest\" to seeing the real sun, and get an estimate for the real position of the sun. reply remipch 3 hours agorootparent> I like your cable-drive concept by the way. Did you describe it in more details anywhere? I didn't take the time to describe the cable-bot concept in detail. I modeled almost all the mechanical parts with OpenSCAD, but I struggled to model the cable itself. In the \"mechanics\" README [0] you can click on any image to view it in an online 3D viewer. The following note in the same README tries to explain how the cable is used : Each cable is actually wrapped around the motor axis, then passed through the pulley and tied to a fixed ring in the corner of the panel. English is not my first language, is this sentence clear enough ? You can see these elements in the main 3D viewer [1] > How are you getting the right mirror orientation for each mirror (aka canting)? I use one bolt that pulls the mirror holder in the center and 3 bolts that push it in the corners. By screwing or unscrewing the corner bolts you can precisely orient each mirror independently. The \"panel_board_exploded\" view tries to show this [2] > One trick for closed-loop control with many heliostats/panels is to have a few cameras surrounding the receiver. Super clever, thanks for the explanation! I think it might be tricky to calibrate. [0] https://github.com/remipch/solar_concentrator/blob/master/me... [1] https://remipch.github.io/solar_concentrator/view_3d.html?mo... [2] https://remipch.github.io/solar_concentrator/view_3d.html?mo... reply hakonjdjohnsen 2 hours agorootparent> Each cable is actually wrapped around the motor axis, then passed through the pulley and tied to a fixed ring in the corner of the panel. Thanks, when seeing the video again now it makes sense! I didn't catch the counterweight the first time I saw it. Nice! In the Heliogen concept I mentioned previously they got around having to use a counterweight by attaching the other side of the cable to another part of the panel, such that the cable length stays approximately constant. Then they used a spring to compensate for the small changes in cable length that are inherent to the geometry. > I use one bolt that pulls the mirror holder in the center and 3 bolts that push it in the corners. By screwing or unscrewing the corner bolts you can precisely orient each mirror independently. Nice! Even in large heliostat fields it is often done in a similar way. It becomes quite labor intensive when you have thousands of heliostats in a field, with 10+ segments each, so there are ongoing efforts to find ways to do it automatically or to get around the need for doing it in the first place. reply foobarian 4 hours agoparentprevSpeaking of risks and fire, is there a known limit to the temperature achievable by concentration? I was wondering if I could melt a piece of tungsten with this method. reply hakonjdjohnsen 3 hours agorootparentYes, and it is super-interesting! The fundamental limit is given by the 2nd law of thermodynamics - you can never reach higher temperatures than the surface of the sun, or around 5800 K. We have the atmosphere that absorbs and scatters some of the light, so on the surface of the earth it is a bit lower, but not by a huge amount. This means that there is a fundamental limit to how small and intense you can make the focal spot in a solar concentrator. The limit is around ~45 MW/m² or 45000 \"suns\" (which is plenty high, but far from infinite). Concentrators used for eletricity generation use much lower concentration than this, on the order of 25 suns to 1000 suns depending on the type. There are also solar furnaces designed for reaching much higher concentration by using a different type of optics. The most impressive one is the huge Odeillo solar furnace [1]. I would guess that they could melt tungsten, but I have not actually run the numbers. I did a talk last week about a concept we are developing for reaching furnace-level concentration ratios with conventional heliostats [2]. [1] https://en.wikipedia.org/wiki/Odeillo_solar_furnace [2] https://folk.ntnu.no/haakonjj/talks/2024-08-19-nonimaging-fr... reply foobarian 2 hours agorootparentThe thing that I can't wrap my head around is that if the concentrator \"pumps\" power into an object, and say you can somehow insulate it to stop the losses, how is this limit not unbounded? Where does the energy go once we reach the cap? Does the black body radiation send the energy back out? reply hakonjdjohnsen 2 hours agorootparent> Does the black body radiation send the energy back out? Exactly, this is the issue. If an object is able to absorb sunlight, it is also able to emit blackbody radition back towards the sun. When the temperature limit is reached, these two exactly cancel each other. The object will emit blackbody radiation with the same brightness as the surface of the sun. Another way to look at it is to imagine yourself standing at the center of the concentrated sunlight and looking out towards the concentrator. The concentrator makes the sun look \"bigger\" from your perspective, and this is what makes the sunlight concentrated. The limit to this effect is if the sun fills all directions in the whole hemisphere above you. Now it will be as if you are standing on the surface of the sun, and all you can see in any direction is sunlight. Normally, the solar disc fills 1/45000th of the hemisphere above you here on earth, thus the limit of 45000 suns concentration. reply micw 21 minutes agorootparentThank you so much. It's the first time I do understand the _why_ of that fact. But I could build up a lot of solar panels and use the electricity to heat up an oven more than the surface of the sun, right? Is that \"cheating\" in terms of thermo dynamics? reply foobarian 2 hours agorootparentprevThat's a very insightful way to look at it, thank you! ps. It's like making a VPN tunnel to the surface of the sun :-) reply hakonjdjohnsen 2 hours agorootparent> ps. It's like making a VPN tunnel to the surface of the sun :-) Wow, I love that! Great analogy! reply remipch 55 minutes agorootparentprevNice explanation, thanks reply IncreasePosts 45 minutes agorootparentprevYes...in the situation where somehow the oven became hotter than the surface of the sun, then the oven would start heating up the sun. reply adrianN 12 minutes agorootparentprevPlatinum was first melted using concentrated solar iirc. reply dekhn 2 hours agorootparentprevCheck out: https://what-if.xkcd.com/145/ reply remipch 4 hours agorootparentprevI think it depends on the mirror area. The more mirrors, the more power. The more power, the higher the temperature will be. Anyway, tungsten melts at 3422°C, I don't know if it's feasible. reply foobarian 2 hours agorootparentImagine we built a giant concentrator in space so we can melt tungsten without having to worry about containment! reply SoftTalker 3 hours agoprevConcentrated sunlight is deceptively powerful. We probably all have played with small handheld magnifying glasses to focus the sun to a small spot, burning paper or small wood blocks. When I was a kid I had a Fresnel lens, probably 2' in diameter, out of an old projector or some similar thing. It would set asphalt on fire. Almost instantly. You could probably weld steel with sunlight, though not very conveniently. reply regularfry 3 hours agoparentThere was a project a few years back to demo 3d printing with solar sintering of desert sand: https://www.sciencedirect.com/science/article/abs/pii/S09596... - very neat idea. reply remipch 3 hours agorootparentVery interesting, do you know if there are any actual applications today? reply regularfry 3 hours agorootparentI've not heard of it since, no. It's got some steep hills to climb as a concept before it's a better option for building materials than just pouring more concrete. reply photonthug 2 hours agorootparentNot sure what those hills are, but it’s always surprised me that this type of hobby project hasn’t been ever been scaled up industrially. Setting aside applications for moon base 1 and other sci-fi, there’s a lot of desert on earth. If the construction method is automatic or even semi automatic, and costs almost no energy, then who cares if it’s slow? A legion of robots that can’t even make other robots but can make glass bricks from sand seems like it could be paving the Empty Quarter one decade, finishing the glittering glass towers in the next. reply bufferoverflow 3 hours agoparentprevHere's a huge solar concentrator that melts thick steel in seconds: https://youtu.be/8tt7RG3UR4c Action around 1:25 reply LikeBeans 53 minutes agorootparentI can imagine this would be very useful for water desalination. reply remipch 2 hours agorootparentprevExcellent! Do you know the mirror area used here? reply Log_out_ 1 hour agoparentprevYou can also sinter sand into 3d structures. https://www.youtube.com/watch?v=ptUj8JRAYu8 In theory if you could manufacture lenses and optical fibers, you could 3d print active solar powered structures anywhere where there is enough sun. Imagine a 3d printed little bottlegarden, with a water collector using a heated silicagel cycle printed in situ on mars. Still low atmospheric pressure, but warm and wetter. reply mapt 1 hour agoprevUnfortunately in 2024 with extremely inexpensive solar cells, I don't see much future for this technology. Even fixed latitude tilt angles are coming into question given the modest cost increases that they create versus a flat or a vertical panel. It costs more to blow glass into vacuum panels than to acquire PV area. Much of the developing world latched on to solar concentrator water heaters 10, 20, or 30 years ago, and they were common in a backpacking trip through China a decade back. It's good tech, depending on your climate, but it seems to have been superseded. reply datadrivenangel 44 minutes agoparentThe thermal 'inertia' of concentrated solar power may be cost competitive with PV solar and batteries. You can use the mass of the concentrator target as a thermal battery effectively, as the conversation of sunlight to electrical energy is not instantaneous like solar PV. reply wycx 4 hours agoprevLots of interesting experiments with solar collection here: https://www.youtube.com/@sergiyyurko8668/videos reply remipch 4 hours agoparentWhaoo, super interesting, thanks for the link. Some of their projects follow the same idea of a grid of small square mirrors. However, they choose to put the mirrors on the ground (which is simpler) and move the target at the focal point (which is not simpler). Good source of inspiration, I will watch their videos. reply cheschire 7 hours agoprevIf you make a large (1+ meter diameter) curved lump out of wet sand, you can use that to lay a fiberglass parabola which could then be chrome plated, painted, or otherwise finished on the inside of the parabola after it’s cured. This would allow you to further concentrate the solar power beyond the current 48x limitation. reply phkahler 47 minutes agoparentDecades ago, my brother used the inside of a large umbrella covered in aluminum foil. A small grill attached to the handle was used to grill hotdogs. Not sure how he had it mounted in the correct orientation though. In this case, imperfect surface shape may have been a good thing. reply remipch 6 hours agoparentprevGood idea, thank you! However a 20cm x 20cm square spot can be better for some applications. If you want to cook something it's best to spread the heat over the entire baking sheet to ensure even cooking. reply cheschire 5 hours agorootparentFor the specific use case of cooking, I think the problem you will run into is that solar power is inconsistent which is problematic for cooking via direct heat as you tend to need consistent temperatures. So instead I would look at indirect heat. By super-concentrating the full parabolic area into a single point, you can heat cooking stones which will radiate heat more consistently even when clouds momentarily block the sun. Using a simple store-bought pizza stone suspended at a 45-degree angle above your food, the homemade solar \"laser\" (said in Dr. Evil's voice) could be targeted on the underside, directly above the food. Placing firebrick or other insulating stone directly on the opposite side of the pizza stone would help ensure that minimal energy is lost through the rear. reply ryandvm 5 hours agoprevVery cool. Curious if you have looked into non-imaging (anidolic) solar collectors? My understanding is that they are actually more efficient than mirror or lens based collectors as they do not require precise aiming and are able to collect indirect sunlight as well. reply remipch 3 hours agoparentI wasn't aware of such systems. If I understand correctly, their main feature is that they do not focus on a focal point, but instead diffuse the light. So I'm not sure if it would be applicable to my project. I need to dig deeper to fully understand how it works exactly, thanks for the hint. reply conkeisterdoor 8 hours agoprevThis is so cool, thanks for sharing! If I had a yard/space to build one of these, I would totally try rigging one up to drive a little heat engine. reply remipch 7 hours agoparentThanks for your nice comment. Yes it's definitely fun to build one and use that free energy from the sun. I was particularly happy to eat my first solar gratin :-) reply fuzzy_biscuit 5 hours agoprevHopefully this isn't a stupid question as I know very little about solar, but could the risk/danger be reduced with some kind of diffusion layer behind the target to \"de-concentrate\" the light in the event of a failure? reply pjc50 5 hours agoparentThe risk includes targeting the wrong thing, or stepping into the beam in front of the target. A non-flammable backstop for the target is kind of a base level safety measure. reply londons_explore 8 hours agoprevAm I understanding correctly that the angle between each mirror segment and the backboard is fixed once during construction and then not dynamic? reply remipch 8 hours agoparentExactly This has the advantage of requiring fewer motors (only two motors for the entire panel) instead of two motors per mirror. The disadvantage is that the light is only focused for a few hours a day. reply phkahler 42 minutes agorootparentIt is possible to make a mechanical angle bisector. Think of a compass for drawing circles but with a 3rd arm bisecting the angle. If you attach the bisector normal to a mirror, you can point one leg at the sun and the other at a target. An array of these would require linkages to aim all inputs parallel toward the sun and all outputs fixed toward the target - the outputs don't have to be parallel just have each pointing at the target. 2-axis actuation to move all mirrors as needed. Not sure if this has ever been tried, it's just an idea I had some time ago. reply cheschire 7 hours agorootparentprevAnother disadvantage being that your distance between the mirror system and the target must be fixed the same each time you setup. This isn’t an inherently bad thing. As a marketable product this would imply a one-time manual alignment for all 48 mirrors but cheaper lifetime maintenance costs. reply regularfry 3 hours agorootparentIf you were going to sell a kit, having 48 sets of 3d printed mirror mounts of the right length for each position wouldn't be out of the question. Just a screw-on clip with the right length standoff for each mirror corner would be all you'd need. You could conceivably have different sets with different focal lengths. I don't think it would be too fiddly done that way but it might take some work to make fine adjustments straightforward. reply zo1 7 hours agoprev [–] Awesome project OP! Especially the power comparison. Who would have thought that you can achieve 1kW of energy from 1m2. On a side note and in a similar direction. Would it be feasible to make a solar concentrator that heats a molten-salt reactor that powers a turbine engine? On a small-ish scale though, such that it'd be achievable as a back-yard reactor? So the description I used above was my memory-driven understanding of it. But here is what I actually meant: https://en.wikipedia.org/wiki/Solar_power_tower Edit. I went down a little rabbit-hole, HN. This is what I eventually found about small-scale energy generation using solar-concentration. https://en.wikipedia.org/wiki/Solar-powered_Stirling_engine https://en.wikipedia.org/wiki/File:Dish-stirling-at-odeillo.... Could be a semi-viable alternative to solar, perhaps? Though cost-wise, it's probably quite high now that solar-panels and their auxillary hardware have been commoditized so much. reply remipch 5 hours agoparentYes, there are several industrial applications that use a solar concentrator to drive a turbine engine or a Stirling engine. I'm not sure it's a viable way to produce electricity on a small scale because: - high thermodynamic efficiency requires high temperature difference - photovoltaic panels are mass-produced and increasingly efficient Personally, I think small scale concentrated solar power is most useful for applications that require direct heat (cooking, desalination, foundries). In these cases, photovoltaics have a lower efficiency and a shorter lifetime. reply argiopetech 5 hours agoparentprev1kw/m^2 is the \"standard\" rule of thumb for heat energy from solar irradiation. I'm unsure whether OP has done the calculation (in which case, credit to a well built system) or simply cited the standard rule. There are some large Stirling engines out there that operate on hot oil. With a large diameter piston, quite a bit of torque can be generated with even small ∆T. Oil can be heated as with traditional solar water heaters (i.e., with no concentration), though concentration doesn't hurt. reply remipch 5 hours agorootparentI have developed a simple simulator [0] to estimate the theoretical power received by the target for a given hardware configuration: - the global position on the planet - the date and time - the size and position of some background elements - the number, size and position of the panels in the grid The solar power estimation uses : - the Python code provided in this article [1] to estimate position of the sun (thank you John Clark Craig) - the simplified formula [2] to estimate the direct insolation from the sun position - a custom light projection implemented using Panda3D game engine [3] [0] https://github.com/remipch/solar_concentrator/blob/master/so... [1] https://levelup.gitconnected.com/python-sun-position-for-sol... [2] https://en.wikipedia.org/wiki/Direct_insolation#Simplified_f... [3] https://www.panda3d.org/ reply pjc50 5 hours agoparentprev [–] Solar panels are really cheap. Like, comparable to a mirror of the same size cheap. reply remipch 4 hours agorootparent [–] A 15cm x 15cm mirror used in this project cost 1€. That's 48€/m2, I couldn't find a photovoltaic panel at that price. Add to that: - photovoltaic efficiency is about 20%, while such mirrors reflect 90% of the energy - photovoltaic panels have an average lifespan of 20 years, while mirrors do not wear out. Anyway, we're comparing apples and oranges, because we have to add the mechanical installations, which are very different depending on the specific application. I'm not against photovoltaic in general, I just think that for some applications there are some interesting alternatives. reply lm28469 3 hours agorootparent> That's 48€/m2, I couldn't find a photovoltaic panel at that price. Still apples to oranges but, $68 for > 2sqm at the factory, probably closer to $100 at retail: https://www.alibaba.com/product-detail/144cells-Jinko-Solar-... And in Europe: https://venturama-solar.de/produkt/ja-solar-jam54s30-425w-lr... reply newprint 3 hours agorootparentprev [–] Oh mirrors do wear out... reply remipch 3 hours agorootparent [–] Oh yes, they do. I can be a little naive sometimes :-) I still naively think that we could make mirrors completely encased in glass to limit their degradation (pure speculation here). reply monkmartinez 1 hour agorootparent [–] Which would make the cost of each mirror higher, right? Additional processing will naturally increase the cost per unit. By the way, super cool project and thank you for sharing. My experiments with concentrating sun power when I was a child were directly related to the spontaneous combustion of insects. Still making amends for the number of ant hills my brother and I cooked with the sun. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A developer has open-sourced an automated solar concentrator project after quitting their job two years ago to focus on it.",
      "The project is still in development, with many potential improvements and applications in environmental and economic sectors.",
      "The developer is seeking feedback and questions from the community to further refine and enhance the technology."
    ],
    "commentSummary": [
      "The author open-sourced an automated solar concentrator project, seeking feedback and collaboration from the community.",
      "The discussion included technical insights on nonimaging optics, closed-loop control, and various methods to improve tracking precision and mirror adjustments.",
      "Users shared related projects and debated the efficiency and durability of concentrated solar power versus photovoltaic panels, highlighting the potential for diverse applications like cooking, heating, and 3D printing."
    ],
    "points": 201,
    "commentCount": 57,
    "retryCount": 0,
    "time": 1724926440
  },
  {
    "id": 41392142,
    "title": "New 2GB Raspberry Pi 5 has 33% smaller die, 30% idle power savings",
    "originLink": "https://www.jeffgeerling.com/blog/2024/new-2gb-pi-5-has-33-smaller-die-30-idle-power-savings",
    "originBody": "August 29, 2024 Raspberry Pi launched the 2 gig Pi 5 for $50, and besides half the RAM and a lower price, it has a new stepping of the main BCM2712 chip. This is the BCM2712 D0 stepping. Older Pi 5's shipped with a C1. In their blog post, they said: The new D0 stepping strips away all that unneeded functionality, leaving only the bits we need. Steppings are basically chip revisions where they don't change functionality, and usually just fix bugs, or tweak the layout. But even tiny design changes could have unintended consequences. I wanted to see exactly what happens when I push one of these new chips to the limits. First, I wanted a performance baseline, so I ran Geekbench with the latest Pi OS and all the defaults. Except... apparently Geekbench likes more than 2 gigs of RAM. I couldn't get past the multicore Photo Filter test, since the OS kept running outta memory. A lotta software nowadays is built for an absolute minimum of 4 or 8 gigs. So keep that in mind when you're buying a Pi. Without adding swap, Geekbench was out, but I still wanted to get some raw numbers, so I ran sysbench. It's lighter weight, it runs with limited memory, and it still gives me CPU numbers to compare. Using a combination of this 10W peltier cooler and the bottom heatsink from an EDAtec fanless case, I ran through a number of overclock scenarios: Clock Speed (MHz) sysbench result 2400 4155 3000 5175 3100 5315 3200 5505 3300 5715 3400 5804 3500 6068 I ran the command sysbench --test=cpu --cpu-max-prime=20000 --num-threads=4 run. At 3.6 GHz the Pi wouldn't boot—there were always memory errors and it would completely freeze. At 3.5 GHz, there were still some stability issues, and I couldn't get the Pi to reboot cleanly. For any speeds above 3.1 GHz, I also used my pi-overvolt hack, which I cover more in depth in my blog post Hacking Pi firmware to get the fastest overclock. There's still a hard limit of 1.1V from the PMIC, so besides splicing in higher voltages direct into the SoC, the only other hardware-level modification I hadn't tried was delidding the Pi's processor. Theoretically, this would allow the Peltier cooler to pull heat off the silicon even faster. Delidding But there was another reason I wanted to delid a 2 gig Pi 5. Raspberry Pi mentioned in their blog post the D0 stepping was simpler and cheaper to make, since they removed 'dark silicon'. That just means there were portions of the BCM2712 that Broadcom put in but Raspberry Pi never used, like the built-in Ethernet controller. Raspberry Pi built their own Ethernet into the RP1, so they didn't use the controller in the main SoC. What this means for the D0 is the actual CPU die is smaller. A smaller die fits more chips on a single wafer, meaning individual chips cost less, assuming chip production yields are the same. I already have a delidded C1 chip from back when I worked with John McMaster and Kleindiek on my Pi 5 silicon deep-dive, so I just need to delid the D0 chip. I placed the 2 GB Pi 5 on my workbench, and worked at the corners with a razor blade: The heat spreader popped off, and I took some measurements, comparing the C1 to the D0 stepping: Stepping Width Height Die area BCM2712 D0 6.30mm 5.98mm 37.674mm2 BCM2712 C1 6.47mm 8.63mm 55.836mm2 The D0 is 32.5% smaller than the older version, which would definitely bring down the price per chip, assuming the same yield on a given silicon wafer. It seems they're still using the 16nm process node, so that's a good chunk of 'dark silicon' removed! Direct Die Cooling I powered up the Pi, with the new direct-die cooling arrangement, but still had stability issues at 3.6 GHz. Maybe even a little more at 3.5, it was hard to tell. Just for fun, I pulled off the cooler entirely, and let the Pi run with just the die exposed to the air. It was happy running like this, even running sysbench at 2.8 GHz for 10 seconds without throttling. So could you run a Pi completely naked? Sure, but the heat spreader does a good job getting more heat off the whole package, so I'd just leave it on. My takeaway is the Pi's 16 nanometer chip seems to max out around 3.5 Gigahertz. Thermals and Efficiency - The Goldilocks Pi The other big question though, is whether the smaller design is any better for efficiency or thermals. CNX Software did some testing and published a chart, showing a significant difference, 2.7W to 3.5W, for idle power consumption. I haven't done exhaustive testing, but I did run through my stress benchmarks, monitoring power and heat. I ran it on all the Pi 5 models, with identical test parameters. I have more in this GitHub issue, but this chart sums it up:Pi 5 2GB D0 Pi 5 4GB C1 4GB Delta Pi 5 8GB C1 8GB Delta Idle power 2.4W 3.3W 0.9W (+32%) 3.2W 0.8W (+29%) Idle temp 30°C 32°C 2°C (+6%) 32°C 2°C (+6%) stress-ng power 8.9W 9.8W 0.9W (+10%) 9.8W 0.9W (+10%) stress-ng temp 59°C 63°C 4°C (+7%) 64°C 5°C (+8%) For idle power draw, the improvement almost mirrors the chip size reduction. The chip is 33% smaller, and the idle power draw is almost that much better. And here are the thermals for my test runs, for completeness: Some of the power savings could be chalked up to less RAM, because more RAM requires more power. But that doesn't explain all the results. Thomas Kaiser also found the OPP tables are different with the new chip. The 2 gig model doesn't need as much voltage to hit certain clocks, like it uses 805 mV at 2.1 GHz versus 850 mV for the 8 gig model. As a final efficiency test, I ran my top500 HPL benchmark on the 2 gig Pi 5. HPL is a memory-intense benchmark, and because the 2 GB model only has 2 GB of RAM, the overall efficiency for this test was worse, coming in at 2.07 Gflops/W. The 8 GB Pi 5 gets 2.75 Gflops/W. For now, the biggest difference between the 2, 4, and 8 GB PI 5s for most people would still be having more RAM. If you know you can run your apps in 2 GB, this is a great little Pi for that. If you can't, then I think Raspberry Pi set up the 4 GB Pi 5 as the 'goldilocks': Not too expensive, with just enough RAM for most uses. Conclusion So is it worth stepping down to a 2 GB Pi 5 just to get the simpler D0 chip? No. But is it cool to have a cheaper 2 gig option exist? Yes. Just make sure you have a use case for it that doesn't need a ton of RAM. Further reading Overclocking and *Underclocking* the Raspberry Pi 5 The Raspberry Pi 400 can be overclocked to 2.2 GHz An important consideration about Pi 5 overclocking raspberry pi silicon bcm2712 youtube video broadcom Add new comment",
    "commentLink": "https://news.ycombinator.com/item?id=41392142",
    "commentBody": "New 2GB Raspberry Pi 5 has 33% smaller die, 30% idle power savings (jeffgeerling.com)166 points by ingve 3 hours agohidepastfavorite50 comments alxjsn 2 hours agoI rather just buy used Lenovo Thinkcentere PCs on eBay. Way more power, cheaper and relatively small. There’s a lot of different CPU/RAM/DISK configurations you can find. I’ve been buying these, throwing Fedora IoT, docker, and Tailscale on them and running them from different locations for personal projects. reply bri3d 1 hour agoparentA few notes (as someone who is pretty staunchly anti-Pi-as-a-server, I end up having this debate often, and I do think there are reasons to do both): * A Pi will sit much lower in total power consumption than almost any used PCs if both are doing effectively nothing (ie - simple, spiky tasks like filtering DNS, serving static content from RAM, etc.). You need to be doing something with the system before a PC server comes out ahead, and most people using a Pi as a home server... aren't. Compared to a modern low-power x86 PC system, the difference isn't meaningful, but if you're buying used stuff 3 generations back, the difference becomes somewhat meaningful in terms of electric cost (on the order of tens of dollars per year, which is significant for hardware which cost tens of dollars to start with). * The Pi of course has GPIO, SPI, etc. exposed, so you can use it as a nice \"hybrid-IoT\" device where it's a home server _and_ a sensor aggregator, for example. And the hat ecosystem, while generally insanely overpriced, is convenient. Now, the moment you're running K8s/Docker or a real compute workload (security camera image recognition, etc.) you should probably move off of the Pi and onto something nicer, indeed. I absolutely never understood people running clusters of Pis or those goofy multi-Pi carrier boards. Just buy a real PC. reply Aachen 1 hour agorootparent> A Pi will sit much lower in total power consumption than almost any used PC For electricity consumption, beyond the wallet, it actually seems that hardware should have a lifespan on the order of decades before electricity consumption savings offset the environmental impact: \"For laptops and similar computers, manufacturing, distribution and disposal account for 52% of their Global Warming Potential (i.e. the amount of CO₂-equivalent emissions caused). For mobile phones, this is 72%. The report calculates that the lifetime of these devices should be at least 25 years to limit their Global Warming Potential.\" —https://wimvanderbauwhede.codeberg.page/articles/frugal-comp... Rather than buying a new Pi, repurposing a 5-year-old laptop has advantages if this something one cares about. Desktops are quite a bit more hungry (I've heard this got better in recent years), but I can attest that a 2012 laptop still functions very well as a server, easily better than a 2024-era Pi. Probably I'll replace it in the next 2-4 years (so at ~15yo) when my current laptop finally will have given me enough grief (my inner grandpa complains they don't make 'em like they used to), and I'm not saying others must optimise for climate alone either, but it's something to consider when deciding on a good balance reply k_bx 58 minutes agorootparentEnvironmental impact is not the main concern when it comes to power consumption. Main concern is how long will it work on a battery before a maintenance person can come by and switch the battery or if the sun will come out and start charging it again. reply AshamedCaptain 1 hour agorootparentprev> * A Pi will sit much lower in total power consumption than almost any used PCs if both are doing effectively nothing (ie - simple, spiky tasks like filtering DNS, serving static content from RAM, etc.). You need to be doing something with the system before a PC server comes out ahead, and most people using a Pi as a home server... aren't. That's not necessarily true since the Pis are particularly terrible at idle power consumption. E.g. the \"power off\" state consumption shown in the article is actually higher than the idle consumption of some low-power Atom/Celeron x86 chips. The Pi is just terrible at power management. reply sofixa 1 hour agorootparentprev> I absolutely never understood people running clusters of Pis or those goofy multi-Pi carrier boards. Just buy a real PC. A bunch of Pis allow you to run multi-node clusters on the cheap. If you're just experimenting with Kubernetes/Nomad/whatever, you don't need a lot of resources, just multiple nodes. It's easier and depending on config potentially cheaper than getting a beefier mini PC, throwing lots of RAM, and running VMs. reply supertrope 1 hour agorootparentprevTo illustrate a Lenovo Thinkcentre m720s idles at 9W! Intel i5-8500 (6C/6T), 8GB DDR4, 256GB NVMe SSD. It cost $120. reply ssl-3 42 minutes agorootparentIn order to begin to make a valid price comparison to this used (ie, not new) PC, we'd also need to know how much a used Raspberry Pi system would cost. reply supertrope 37 minutes agorootparentGo to ebay.com. Search for Raspberry Pi 5 or 4. See actual market prices by filtering to sold listings. Add cost of case, power supply, storage, maybe even active cooler. reply sgt 6 minutes agoparentprevI just bought one! It's brilliant, I had no idea. Cost almost nothing, and I removed the HDD and put an SSD in there, extra RAM and it's lightning quick. Right now I have Windows 10 on it as I needed to run some old proprietary software, but it's a proper gem of a machine. I got the one without touch screen. reply geerlingguy 2 hours agoparentprevThere's also the Radxa X4 — Pi 4/5 form factor (tiny bit larger but not substantial), has a PoE HAT available, has 40-pin GPIO (with caveats, but it's basically a Pico strapped on the same board), and the N100's built-in GPU can run circles around the Pi or even RK3588 boards. The efficiency isn't there, and you'll need to figure out a better cooling/case solution than the one Radxa ships, but I'm impressed by this little board. If you can stretch your budget past $100 you can get a good brand new N100 or N305 system that will go further. Used gear is fine, but the power efficiency for anything in the $50-80 range used is pretty rough. Some people don't worry much about that, but in some parts of the world it can be $5+/month more to run older machines! reply throwup238 38 minutes agorootparent> Some people don't worry much about that, but in some parts of the world it can be $5+/month more to run older machines! California being one of the worst offenders, ironically. In SoCal my family and I pay (across several households) between $0.50/kWh and $0.99/kWh, so even a 15W idle can cost us at least $5 a month. reply PedroBatista 2 hours agoparentprevSure, if you need a machine to do \"normal\" PC/server things, buying a computer would be the natural path. reply jchw 1 hour agoparentprevEmphasis on way more power. Granted, power draw isn't a huge problem for price reasons, since the cost of electricity is usually not that huge of a factor, but if you wind up running a lot of these, it can add up. More power draw is also a detriment if you want to keep things lean for longer battery, which makes me hesitant to put many older stock computers in the critical path of my network. Don't get me wrong, though. Old stock computers are excellent for a wide variety of tasks, it's just that they definitely don't encroach on a lot of the use cases of modern SBCs. You needn't buy a Raspberry Pi 5 either; plenty of use cases like Home Assistant will run pretty well on a Pi 4 or even a Pi 3, and that's not getting into the many other reasons why a Pi may be interesting (like HATs, being able to use PoE power, GPIO, or even just the I/O in general.) reply autoexec 1 hour agoparentprevI can't bring myself to buy Lenovo anything since they've repeatedly shipped products infested with malware, sometimes doing it in exchange for money. Once a company sinks that low and treats users with such disrespect I don't know how or why they should be trusted again. reply sgt 4 minutes agorootparentThe ThinkCentres kinda look like \"evil\" IBM corporate machines out of a Star Wars movie. I wish I could put an IBM logo on mine to complete the picture. reply gosub100 1 hour agorootparentprevI tried buying a used one on eBay and was disappointed to find it used a proprietary SATA power cable or connector,I can't recall. I hope they stopped doing that. reply 0cf8612b2e1e 2 hours agoprevSome of the power savings could be chalked up to less RAM, because more RAM requires more power. But that doesn't explain all the results. Is there a calculation to estimate RAM power consumption? I keep wanting to get a low powered N100, and have been wondering if I use say 8 vs 16GB RAM, would that make a measurable power difference? reply hajile 2 hours agoparentTheir numbers seem to indicate that Pi disabled parts of the chip in firmware instead of physically lasering them out. This leaves those parts still leaking some current and explains the power difference. reply moffkalast 1 hour agoparentprev> 8 vs 16GB RAM, would that make a measurable power difference? I think the short answer is.. it depends. Current draw depends on usage, supposedly from 10% at idle up to full when doing massive read/writes. But it should be in the two to three digit miliwatt range which isn't much compared to the N100 itself which pulls 6W at idle, being an inefficient x86 space heater. The Pi 4 4GB can idle at 1W using LPDDR4, the Pi 5 8GB using 50% more efficient LPDDR4x idles at... 3W. Meanwhile the average 12GB LPDDR5X Android phone can idle a whole week on a tiny 1 cell lipo (with power saving mode on), making this look so bad it's actually funny. The long standing problem with Pi Foundation products is a complete disregard for any low power states, sleep or hibernation, so they probably don't do any RAM related power optimization either. It's only now with the RP2350 that they've finally implemented some kind of working sleep mode for the very first time in anything at all. reply Marsymars 15 minutes agorootparent> N100 itself which pulls 6W at idle That's not right - my entire N305 system takes 4-5W at idle. reply moffkalast 7 minutes agorootparentFair point, N100 systems do differ quite a bit generally, the numbers I've got in my head are what I've seen people quote for the Radxa X4 recently. Some might be more, some less. reply Mistletoe 2 hours agoparentprevA small amount. > As a rule of thumb, you can expect to allocate around 3 watts of power for every 8GB of DDR3 or DDR4 memory. reply mallets 1 hour agorootparentThat's a ridiculous amount of power, is that answer from a LLM? It's in the range of ~150mW for LPDDR4. Around half that in idle. reply hnuser123456 45 minutes agorootparentYou specified LP, they didn't. reply 0cf8612b2e1e 2 hours agorootparentprevSimilar for DDR5? In the context of a N100, 3W is actually pretty high. Many of these systems idle around 10W. reply spockz 2 hours agorootparentMy N100 from minisforum runs on 3.6W idle with 4-8W for medium to high cpu usage to 20W on full load with SSD, CPU, and integrated encoder loaded. It is way more powerful than a pi and in low power mode as efficient. reply snovv_crash 2 hours agorootparentprevThat's why many laptops run LPDDR these days. reply flyingpenguin 2 hours agorootparentprevYeah but unless you are deploying a bunch of them, its only like $3/year each reply quaintdev 2 hours agoprevGenuine question what is the use case for such configuration I mean less RAM and powerful CPU? I use my Pi for self hosting so I need more memory and more CPU is always better for my case. If they need less power consumption then they could have used Pi 4 or other lower version. Besides low cost I don't see other advantage of such configuration. Please enlighten me. reply justin66 15 minutes agoparentFor an embedded application involving signage or a kiosk, 2GB is probably plenty, and if you're doing enough of them the money saved would be worth it. For a home user with one, or only a handful of, machines I don't think you'd necessarily need to save a few bucks this way. Although people obsessing over pennies is a theme in most Raspberry Pi threads, so there is clearly appeal for some. reply mlyle 2 hours agoparentprevPi 5's peak consumption is higher, but if you are doing the same amount of computational work (but a bit above idle) it is less. Now this uses even less, and even the idle powers are comparable to 4. This wins in every way over Pi4, except cost. reply tonymet 2 hours agorootparentGiven people typically use these for a home server or embedded controller, who cares about saving a couple watts? 1 watt savings idle? .72 kwh a month? in my area that's about 5₵ , even in california that's 40₵ / month / device ? Are 1000-instance Pi arrays common? i can think of 100 better ways to get that amount of computing resources. reply byteknight 2 hours agorootparentI think you are applying your usecase and thinking that is everyone's use case. Think battery power. reply mlyle 1 hour agorootparentYup. I had students running a machine learning model on a Pi attached to a scooter. The power draw of the computing system was significant, and the performance limitations were too. The existence of commodity, well-documented, well-supported SBCs offering more computing in less power is exciting. (Also, using less power means you can put it in more places without worrying about getting rid of the heat, or can go longer before throttling). reply Max-q 1 hour agoparentprevMaybe real time image processing from a camera. 2GB would probably be more than enough, and less power draw is nice when running continuously. reply Aachen 1 hour agoparentprevIf your needs are greater than a Pi but not at the level where you want to be buying professional server hardware, I can recommend checking if you or a family member still has a laptop they're not using anymore. Free hardware that would otherwise end up going to waste, and anything that had good performance in 2012 is still faster than a new Pi today. The older, the more likely it is to have replaceable RAM so you can stick in 16GB easily (older RAM types are also cheaper) reply pseudosavant 1 hour agoprevIf they are using a standard 300mm wafer and have similar yields, the D0 stepping will allow them to get ~50% more chips per wafer than the C1 stepping. reply hcfman 35 minutes agoprevNice comparison. Looking forward to the 4nm version reply GGO 2 hours agoprevis there going to be D0 stepping for the 8GB version? reply jsheard 2 hours agoparentI don't see why there wouldn't be, it's cheaper to manufacture with seemingly no downsides. They probably won't revise the 4GB and 8GB versions until their stocks of the original stepping are used up though, and once they do introduce revised versions it may be a lottery which version you get for a while. reply AstroJetson 1 hour agorootparentI'll bet they just slipstream them in. There was a huge backlog of the 8GB, that now looks pretty much cleared out. So it could be awhile before the D0 show up. reply hajile 1 hour agoparentprevTSMC charged just a hair under $4000 per 16nm wafer in 2020. Wafer calculators at 0.2 defect/cm2 on a 300mm wafer gives 950 fully-good dies out of 1061 for the old die (~89% good) and 1469 fully-good dies out of 1584 (~93%) for the new dies. Dividing that out gives $4.21/chip for the old chip and $2.72/chip for the new chip. At $80 for an 8gb board, that represents a ~1.9% increase in profit per board. For the $60 4gb version, it's more like 2.5% increase in profit per board. In real-world terms, if they sell 10M Pi5 units with the new chip, they'll have an extra $15M in the bank in saved production costs alone (minus whatever costs to strip everything out and tape out again). Furthermore, the new chip gets cheaper with every chip they make as the R&D costs get more and more diluted. reply rjsw 2 hours agoprevYou had speculated in a previous thread that the new die could result in power savings, good to see some real measurements. reply kobieps 2 hours agoprevIs the firmware still closed source? reply written-beyond 2 hours agoparentThey've improved a lot, it's mostly the broadcom graphics firmware that still requires blobs. Probably because they've licensed the IP from somewhere else and the effort to reward ratio is too low. reply mort96 1 hour agorootparentIn other words: yes, the firmware is still closed source. reply autoexec 1 hour agoparentprevI wouldn't mind them not using open firmware as much if we had unofficial alternatives that worked without sacrificing functionality, but I don't think anyone has managed that even after all this time. reply PedroBatista 2 hours agoprevMore memory also needs more power. Not sure what percentage of those gains can be attributed to less memory and what can is due to better die/process. reply toastau 2 hours agoprev [–] Nice work! reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "On August 29, 2024, Raspberry Pi launched the 2GB Pi 5 for $50, featuring a new D0 stepping of the BCM2712 chip, which is simpler and cheaper to produce.",
      "The D0 stepping removes unused functionalities, making the chip 32.5% smaller and more efficient, with lower idle power consumption and slightly better thermals.",
      "Despite the 2GB model's limited RAM affecting performance in memory-intensive tasks, the 4GB Pi 5 is recommended for most users due to its balance of cost and functionality."
    ],
    "commentSummary": [
      "The new 2GB Raspberry Pi 5 boasts a 33% smaller die and 30% idle power savings, making it more efficient for low-power applications.",
      "While Raspberry Pis are ideal for hybrid IoT applications due to GPIO (General-Purpose Input/Output) and SPI (Serial Peripheral Interface) exposure, older PCs like Lenovo Thinkcentres may offer better performance for intensive tasks.",
      "The debate on environmental impact and power consumption continues, with some advocating for repurposing old laptops as a more eco-friendly alternative to buying new hardware."
    ],
    "points": 166,
    "commentCount": 50,
    "retryCount": 0,
    "time": 1724946899
  },
  {
    "id": 41389806,
    "title": "Farewell Pandas, and thanks for all the fish",
    "originLink": "https://ibis-project.org/posts/farewell-pandas/",
    "originBody": "TL; DR: we are deprecating the pandas and dask backends and will be removing them in version 10.0. There is no feature gap between the pandas backend and our default DuckDB backend, and DuckDB is much more performant. pandas DataFrames will still be available as format for getting data to and from Ibis, we just won’t support using pandas to execute queries. Most of the rationale below applies to the Dask backend since it has so much in common with pandas. Dask is a great project and people should continue to use it outside the Ibis context. Why pandas? And a bit of Ibis history Way back in the early days of Ibis, there was only one backend: Impala. Not everyone used Impala (mindblowing, we know), and so it wasn’t too long until the Postgres backend was added (by the inimitable Phillip Cloud). These two backends were both featureful, but there was a big problem with adoption: Want to try out Ibis? You need to install Impala or Postgres first. Not an insurmountable problem, but a LOT more work than “just pip install ” – which prompted the question, how can a prospective Ibis user take the API for a spin without requiring a DBA or extra infrastructure beyond a laptop? The obvious answer (at the time) was to use the only in-memory DataFrame engine around and wire up a pandas backend. The agony and the agony pandas was the best option at the time, and it allowed new users to try out Ibis. But, it never fit well into the model of data analysis that Ibis strives for. The pandas backend has more specialized code than any other backend, because it is so fundamentally different than all the other systems Ibis works with. Deferred vs Eager pandas is inherently an eager engine – every time you hit Enter you are computing an intermediate result. Ibis uses a deferred execution model, similar to what nearly all SQL backends use, that enables query planning and optimization passes. Trying to make a pandas interface that behaves in a deferred way is hard. One of the unfortunate effects of this mismatch is that, unlike our other backends, the pandas backend is often much slower than just using pandas directly. And to provide this suboptimal experience, we have a few thousand lines of code that are only used in the pandas backend. NaN vs NULL The choice was made a long time ago to accept using NaN as the marker for missing values in pandas. This is because NumPy has a notion of NaN, but a Python None would lead to an object-dtype and poor performance. Practicality beats purity, but this is a horrible decision to have to make. Ibis doesn’t have to make it with any other backend, because NULL indicates a missing value, and NaN is Not a Number. Those are fundamentally different ideas and it is an ongoing headache for Ibis to try to pretend that they aren’t. Data types The new Arrow-backed types in pandas are a great improvement and we’ll leave it at that. Misleading new users People reach for what is familiar. When you try Ibis for the first time, we’re asking you to both a) try Ibis and b) pick a backend. We have defaults to try to help with this, but it can be confusing at first. We have many reports from new users that “Ibis is slow”. What this almost always means is that they tried the pandas backend (because they know pandas) and they are having a less-than-great time. If they tried DuckDB or Polars, instead, they would have a much easier time getting things going. Feature parity This is the one of the strongest reasons to drop the pandas backend – it is redundant. The DuckDB backend can seamlessly query pandas DataFrames, supports several flavors of UDF, and can read and write parquet, CSV, JSON, and other formats. There is a reason DuckDB is our default backend: it’s easy to install, it runs locally, it’s blazing fast, and it interacts well with the Python ecosystem. Those are all the reasons we added pandas as a backend in the first place, but with the added benefit of blazing-fast results, and no type-system headaches. Back to top",
    "commentLink": "https://news.ycombinator.com/item?id=41389806",
    "commentBody": "Farewell Pandas, and thanks for all the fish (ibis-project.org)160 points by nojito 7 hours agohidepastfavorite100 comments riezebos 10 minutes agoNice to see, over the past months I've replaces pandas with ibis in all new projects and I am a huge fan! - Syntax in general feels more fluid than pandas - Chaining operations with deferred expressions makes code snippets very portable - Duckdb backend is super fast - Community is very active, friendly and responsive I'm trying to promote it to all my peers but it's not a very well known project in my circles. (Unlike Polars which seems to be the subject of 10% of the talks at all Python conferences) reply mananaysiempre 4 hours agoprev> NULL indicates a missing value, and NaN is Not a Number. That’s actually less true than it sounds. One of the primary functions of NaN is to be the result of 0/0, so there it means that there could be a value but we don’t know what it is because we didn’t take the limit properly. One of the primary functions of NULL is to say that a tuple satisfies a predicate except we don’t know what this one position is—it’s certainly is something out in the real world, we just don’t know what. These ideas are what motivates the comparison shenanigans both NaN and NULL are known for. There’s certainly an argument to be made that the actual implementation of both of these ideas is half-baked in the respective standards, and that they are half-baked differently so we shouldn’t confuse them. But I don’t think it’s fair to say that they are just completely unrelated. If anything, it’s Python’s None that’s doesn’t belong. reply miohtama 2 hours agoparentRelated to this, below someone posted a link to the blog post of Wes McKinney where he discussed Pandas limitations and how PyArrow works around these > 4. Doing missing data right > All missing data in Arrow is represented as a packed bit array, separate from the rest of the data. This makes missing data handling simple and consistent across all data types. You can also do analytics on the null bits (AND-ing bitmaps, or counting set bits) using fast bit-wise built-in hardware operators and SIMD. > The null count in an array is also explicitly stored in its metadata, so if data does not have nulls, we can choose faster code paths that skip null checking. With pandas, we cannot assume that arrays do not have null sentinel values and so most analytics has extra null checking which hurts performance. If you have no nulls, you don’t even need to allocate the bit array. > Because missing data is not natively supported in NumPy, over time we have had to implement our own null-friendly versions of most key performance-critical algorithms. It would be better to have null-handling built into all algorithms and memory management from the ground up. https://wesmckinney.com/blog/apache-arrow-pandas-internals/ reply jononor 1 hour agorootparentNote that the post is from 2017, and pandas now has (optional) support for PyArrow backed dataframes. So there is movement away from the critiques that were presented there. reply miohtama 38 minutes agorootparentYes I think that early post discussed about upcoming Pandas 2.0 which now realised 7 years later. reply OptionOfT 1 hour agoparentprev> One of the primary functions of NULL is to say that a tuple satisfies a predicate except we don’t know what this one position is—it’s certainly is something out in the real world, we just don’t know what. I'm not sure I understand this. Can you explain it with an example? I'm thinking something like: let (x, y) = NULL; But then I'm stuck. reply kstrauser 1 hour agorootparentIn the broader DB theory context and not strictly Pandas, think of a `users` table with a `middle_name` column. There's a difference between `middle_name is null` (we don't know whether they have a middle name or what it is if they do) and `middle_name = ''` (we know that they don't have a middle name). In that case, `select * from users where middle_name is null` gives us a set of users to prod for missing information next time we talk to them. `...where middle_name = ''` gives us a list of people without a middle name, should we care. Edit: A related aside is that Django's ORM's handling of NULL gives me freaking hives. From https://docs.djangoproject.com/en/5.1/ref/models/fields/#nul...: > If a string-based field has null=True, that means it has two possible values for “no data”: NULL, and the empty string. In most cases, it’s redundant to have two possible values for “no data;” the Django convention is to use the empty string, not NULL. I've been around numerous Django devs when they found out that other DBs and ORMs do not remotely consider NULL and empty string to be the same thing. reply mananaysiempre 39 minutes agorootparentprevWhat I mean is, the ivory-tower relational model is that each table (“relation”) represents a predicate (Boolean-valued function) accepting as many arguments as there are columns (“attributes”), and the rows (“tuples”) of the table are an exhaustive listing of those combinations of arguments for which the predicate yields true (“holds”). E.g. the relation Lived may contain a tuple (Edgar Codd, 1923-08-19, 2003-04-18) to represent the fact that Franklin was born on 19 August 1923 and died on 18 April 2003. One well-established approach[1] to NULLs is that they represent the above “closed-world assumption” of exhaustiveness to encompass values we don’t know. For example, the same relation could also contain the tuple (Leslie Lamport, 1941-02-07, NULL) to represent that Lamport was born on 7 February 1941 and lives to the present day. We could then try to have some sort of three-valued logic to propagate this notion of uncertainty: define NULL = x to be (neither true nor false but) NULL (“don’t know”), and then any Boolean operation involving NULL to also yield NULL; that’s more or less what SQL does. As far as I know, it’s possible to make this consistent, but it’ll always be weaker than necessary: a complete solution would instead assign a variable to each unknown value of this sort and recognize that those values are, at the very least, equal to themselves, but dealing with this is NP-complete, as it essentially amounts to implementing Prolog. [1] http://www.esp.org/foundations/database-theory/holdings/codd... reply aeonik 3 hours agoparentprevWhy don't we build a portable numeric system that just has these mathematical constants and definitions built in, in a portable and performance manner? reply verandaguy 3 hours agorootparentWe just don’t have the technology for that, else there’d be libraries floating around that let you do that. reply cpcloud 4 hours agoparentprev100% this. We'd love to have a docs contribution that lays this out in detail if you'd be up for it! Disclaimer: (I lead the project and work on it full time). reply __mharrison__ 3 hours agoprevNot surprising. There are much better compute engines than pandas. Folks then ask why not jump from pandas to [insert favorite tool]? - Existing codebases. Lots of legacy pandas floating about. - Third party integration. Everyone supports pandas. Lots of libraries work with tools like Polars, but everything works with pandas. - YAGNI - For lots of small data tasks, pandas is perfectly fine. reply 0cf8612b2e1e 2 hours agoparentEven medium tasks, the slow step is rarely computations, but the squishy human entering them. When I work on a decent 50GB+ dataset, I have to do something fairly naive before I get frustrated at computation time. Edit: pandas is now Boring Technology (not a criticism). It is a solid default choice. In contrast, we are still in a Cambrian explosion of NeoPandas wannabes. I have no idea who will win, but there is a lot of fragmentation which makes it difficult me for to jump head first into one of these alternatives. Most of them are faster or less RAM pressure which is really low on my list of problems. reply cpcloud 3 hours agoparentprevAll great reasons to stick with Pandas. If a thing works for you, then that's one less thing to manage. Fully agree that if pandas is working for you, then you're better off sticking with it! reply whimsicalism 2 hours agoparentprevIf your task is too big for pandas, you should probably skip right over dask and polars for a better compute engine. reply __mharrison__ 2 hours agorootparentJump straight to cluster and skip Dask? Not sure what \"big\" means here, but a combination of .pipe, pyarrow, and polars can speed up many slow Pandas operations. Polars streaming is surprisingly good for larger than RAM. I get that clusters are cool, but I prefer to keep it on a single machine if possible. Also, libraries like cudf can greatly speed up Pandas code on a single machine, while Snowpark can scale Pandas code to Snowflake scale. reply cpcloud 2 hours agorootparentIn my experience, Polars streaming runs out of memory at much smaller scales than both DuckDB and DataFusion and tends to use much more memory for the same workload when it doesn't outright segfault. Polars is faster than those two once you get to less than a few GB, but beyond that you're better off with DuckDB or DataFusion. I would love for this to improve in Polars, and I'm sure it will! reply ritchie46 2 hours agorootparentDo you mean segfault or OOM? I am not aware of Polars segfaulting on high memory pressure. If it does segfault, would you mind opening an issue? Some context; Polars is building a new streaming engine that will eventually be ready to run the whole Polars API (Also the hard stuff) in a streaming fashion. We expect the initial release end of this year/early next year. Our in-memory engine isn't designed for out-of-core processing and thus if you benchmark it on restricted RAM, it will perform poorly as data is swapped or you go OOM. If you have a machine with enough RAM, Polars is very competitive in performance. And in our experience it is tough to beat in time-series/window functions. reply cpcloud 1 hour agorootparentSegmentation violations are often the result of different underlying problems, one of which can be running out of memory. We (the Ibis team) have opened related issues and the usual response is to not use streaming until it's ready, or to fix the problem if it can be fixed. Not sure what else there is to do, seems like things are working as expected/intended for the moment! We'll definitely be the first to try out any improvements to the streaming engine. reply ritchie46 1 hour agorootparentThey have different implications for us. An abort due to an OOM isn't a bug in our program, as SEGFAULT is a serious bug we want to fix. reply __mharrison__ 2 hours agorootparentprevMy understanding is that the Polars team is working on a new streaming engine. It looks like you will get your wish. reply frakt0x90 3 hours agoprevCurious if you considered Polars. That's become the defacto standard in my group as we all dislike pandas. reply codyvoda 3 hours agoparentPolars is a great choice but, like pandas, locks you into its execution engine(s). Polars is a supported backend for Ibis, though depending on your use case DuckDB or DataFusion may scale better. we did some benchmarking recently: https://ibis-project.org/posts/1tbc/ reply cpcloud 3 hours agoparentprevWe support Polars as a backend. DuckDB was chosen as the default because Polars was too unstable to be the default backend two years ago. reply amelius 3 hours agoparentprevGood riddance. Pandas turns 10x programmers into 1x programmers. reply data-ottawa 3 hours agorootparentI've been using pandas for over a decade and I'm very efficient with it. The Modern Pandas blog series from Tom Augsburger is excellent, and the old Wes McKinney book (creator of pandas) gave a good glimpse into how to effectively use it. I don't think many people learn it correctly so it gets used in a very inefficient and spaghetti script style. It's definitely a tool that's showing it's age, but it's still a very effective swiss army knife for data processing. I am glad we're getting better alternatives, Hadley Wickams tidyverse really showed what data processing can be. reply throwway_278314 2 hours agorootparentJust imagine how much more efficient you would be if you were using R's DataTable. Look, I applaud your skill, but at some point even a master craftsman realizes that the swiss army knife may not be the best tool, and a leatherman offers certain advantages. reply data-ottawa 2 hours agorootparentI really like R’s library and I’ll use them any chance I get (libraries like lmer are still orders of magnitude more efficient than the same model in Statsmodels). From my experience the biggest impediment to using R in production is many orgs don’t have a blessed way to run it. R is my favourite language for data processing, the manual section Computing on the Language[1]is why R is such an ergonomic tool. I had hoped Julia would catch up, but Julia’s macros are not comparable in their depth. I think pandas is probably the data equivalent of editing files using default vim or processing data with awk. [1] https://rstudio.github.io/r-manuals/r-lang/Computing-on-the-... reply cpcloud 1 hour agorootparentAs a joke, I wrote an Ibis backend (https://github.com/cpcloud/ibish) that processes expressions using shell commands strung together with named pipes. It supports joins using the coreutils join command, projections, filters and some aggregations with awk. It's faster than pandas in some cases and folks should put it into production immediately! reply cpcloud 2 hours agorootparentprevSometimes I write data analysis code in R to make myself aware of how it is occasionally possible to have nice things. reply scrlk 2 hours agorootparentprevI also recommend Matt Harrison's talks (\"Idiomatic Pandas\") and book (\"Effective Pandas\"). Once I adopted method chaining, a lot of the issues that I had with pandas in the past due to poor style (e.g. SettingWithCopyWarning) pretty much disappeared. reply codyvoda 3 hours agorootparentprevfun fact if you weren't aware, Ibis was also originally created by Wes McKinney and takes a lot of inspiration from the tidyverse reply data-ottawa 2 hours agorootparentI was not aware of that, the influence from the tidyverse is very clear I’ve tried to make mockups of similarly inspired API and I think they did a great job with clever tricks like the `_` reference (does that clash with IPython/Jupyter’s use?). I do wonder how they manage compatibility with so many backends, it seems like many features will be directly tied to your backend (e.g. Trino using Java Pattern for regex vs BigQuery using Re2) in hard to explain ways. But maybe that’s not a big concern, because very often you’re only going to be using a couple of backends. I’ll have to try Ibis out for myself, it looks like it can unify a lot of the work I have to do. I’ve moved away from pandas for all but the last mile of computation, so this might be a direct good SQL replacement. reply cpcloud 2 hours agorootparent`_` definitely clashes with IPython and Jupyter's use of it. However, if you import it from Ibis then it ceases to be used as \"most recent result\" and remains the ibis underscore object (unless of course you explicitly assign it to something else). Regarding backend compatibility, there are definitely a few kinds of things that we don't currently abstract over. One is regular expression syntax and another is floating point math (e.g., various algebraic properties that are violated that result in slightly different outputs). Hope you give it a go, and please report issues at https://github.com/ibis-project/ibis. reply data-ottawa 2 hours agorootparentThanks for the reply! I think that’s the right policy to take, and I did notice the support matrix on your website which addresses my earlier question: https://ibis-project.org/backends/support/matrix reply Kalanos 44 minutes agorootparentprevLol. As if different tools for filtering rows/columns determines a programmer's capability. reply __mharrison__ 3 hours agorootparentprevCurious if you could expand on this? reply fifilura 3 hours agoparentprevWhat is the difference, other than parallel execution? reply magnio 3 hours agorootparent- Much faster and more memory efficient. - Consistent Expression and SQL-like API. - Lazy execution mode, where queries are compiled and optimized before running. - Sane NaN and null handling. - Much faster. - Much more memory efficient. reply fifilura 3 hours agorootparentDo you use it over many machines (RAMs)? I dont care so much about the memory and CPU stuff, I mostly leave the heavy lifting to an SQL engine. Although the Null handling seems very compelling, I guess it comes at a cost of incompatibility with existing libraries, otherwise Pandas would have implemented it as well? I am curious about the SQL api though. reply cpcloud 2 hours agorootparentPolars' support for SQL is pretty nascent and missing a lot of functionality. If it were better, we'd use it internally in Ibis for the Polars backend implementation. If you're going down the mixed SQL, DataFrame API route then Ibis is probably the best solution out there for that. I work on Ibis, so take what I say with a grain of salt. There may yet be other libraries out that there that have similar functionality. reply cpcloud 3 hours agorootparentprevDid it get more memory efficient during the time between authoring point 1 and authoring the last point? reply dgfitz 3 hours agorootparentYou may think this was clever, but it is a common literary technique to emphasize a point. I'd suggest less snark, you're not doing yourself any favors. reply itsoktocry 2 hours agorootparent>I'd suggest less snark, you're not doing yourself any favors. Why do people feel the need to jump in and police tone like this? Who are you? You're not doing yourself any favours, either. >common literary technique to emphasize a point. \"Common\" is a stetch, and who cares. reply temp_praneshp 2 hours agorootparent> Why do people feel the need to jump in and police tone like this? From the community guidelines(https://news.ycombinator.com/newsguidelines.html): \"Be kind. Don't be snarky. Converse curiously; don't cross-examine. Edit out swipes.\" > Who are you? A member of the community. reply dgfitz 1 hour agorootparentprev> Why do people feel the need to jump in and police tone like this? Did you know that more information is communicated via tone than words? reply ang_cire 2 hours agoparentprevI wouldn't switch to Polars as a replacement to Pandas, given that Polars also seems likely to die soon. I'd also recommend avoiding Manatees. reply cpcloud 2 hours agorootparentOn the flip side, Ibises (Ibisii ??) have been around for years and aren't going anywhere. reply highfrequency 1 hour agorootparentprevWhy do you think polars is likely to die soon? reply dr_mee6 27 minutes agorootparentGlobal warming... reply Kalanos 52 minutes agoprevI've only heard about Ibis maybe three times in the past two years and I pay pretty close attention to the space. If Ibis moves away from pandas, then it just means that I am less likely to try Ibis because there is no bridge. Sure, hip new frameworks are moving away from pandas/numpy, but I'll wait 5 years for the dust to settle here while the compatibility and edge cases sort themselves out. The pydata/numfocus ecosystem is extensive. It's just tabular data. So what if I have to wait a few more milliseconds to get my result. reply codyvoda 46 minutes agoparent> If Ibis moves away from pandas, then it just means that I am less likely to try Ibis because there is no bridge. the bridge is that Ibis accepts pandas as input and has a `to_pandas()` method as output Ibis also still depends on pandas (and thus numpy) internally. also, Ibis was created by the creator of pandas, and the lead developer (and other contributors) have also worked on pandas. the Ibis team understands pandas and the broader Python data ecosystem very well > It's just tabular data. So what if I have to wait a few more milliseconds to get my result. usually as scale grows, milliseconds -> seconds -> minutes -> hours -> days. at some point along the way having a dataframe library that can scale up without rewriting your code might be useful. but if you're dealing with small tabular data and pandas meets your needs, it's a great library to use and stick with! reply cpcloud 46 minutes agoparentprevSounds like a solid plan. No reason to incur switching costs if things are working! I think you're misunderstanding what \"removing pandas\" means. You can still compute on DataFrames, it'll just be with something other than Pandas itself, probably DuckDB, Polars, or DataFusion. So, the bridge was there, is there, and isn't going anywhere. reply softwaredoug 6 hours agoprevOne thing I do like about pandas is it’s pretty extensible to columns of new types. Maybe I’m missing something, but does Polars allow this? Last time I checked there wasn’t a clear path forward. reply porker 5 hours agoparentI'm curious, when do you want to add a new column type? It's not a situation I've been in. reply softwaredoug 3 hours agorootparentGeoPandas is one popular library (https://geopandas.org/en/stable/) I added a column type for full text search, searching tokenized text (https://github.com/softwaredoug/searcharray) The pandas support for extensions is very robust with extensive testing to make sure you can do all the data aggregations functionality you expect in and pandas column. reply deadlypointer 3 hours agoparentprevOTOH the list and struct types allow lots of complex operations, e.g with `.eval`, which run blazingly fast. reply datadrivenangel 5 hours agoparentprevIbis allows this with custom datatypes. reply kremi 2 hours agoprevPandas has been working fine for me. The most powerful feature that makes me stick to it is the multi-index (hierarchical indexes) [1]. Can be used for columns too. Not sure how the cool new kids like polars or ibis would fare in that category. [1] https://pandas.pydata.org/docs/user_guide/advanced.html#adva... reply cpcloud 2 hours agoparentMulti-indexes definitely have their place. In fact, I got involved in pandas development in 2013 as part of some work I was doing in graduate school, and I was a heavy user of multi-indexed columns. I loved them. Over time, and after working on a variety of use cases, I personally have come to believe the baggage introduced by these data structures wasn't worth it. Take a look at the indexing code in pandas, and the staggering complexity of what's possible to put inside square brackets and how to decipher its meaning. The maintenance cost alone is quite high. We don't plan to ever support multi-indexed rows or columns in Ibis. I don't think we'd fare well _at all_ there, intentionally so. reply kremi 42 minutes agorootparent> Take a look at the indexing code in pandas As the end-user, not quite my concern. > and the staggering complexity of what's possible to put inside square brackets and how to decipher its meaning I might not be aware of everything that's possible -- the usage I have of it doesn't give me an impression of staggering complexity. In fact I've found the functionality quite basic, and have been using pd.MultiIndex.from_* quite extensively for anything slightly more advanced than selecting a bunch of values at some level of the index. reply jononor 1 hour agoparentprevI work a lot with IoT data, where basically everything is multi-variate time-series from multiple devices (at different physical locations and logical groupings). Pandas multi index is very nice for this, at least having time+space in the index. reply highfrequency 1 hour agoparentprevIs your workload mostly single-threaded? If so, is that due to dataset size, or machine core count? reply kremi 35 minutes agorootparentSorry I don't know what to answer. I don't think what I do qualifies as \"workload\". I have a process that generates lots of data. I put it in a huge multi-indexed dataframe that luckily fits in RAM. I then slice out the part I need and pass it on to some computation (at which point the data usually becomes a numpy array or a torch tensor). Core-count is not really a concern as there's not much going on other than slicing in memory. The main gain I get of this approach is prototyping velocity and flexibility. Certainly sub-optimal in terms of performance. reply joelschw 4 hours agoprevHuge fan of Ibis, the value isn't that you can now use DuckDB... it's that your syntax will work when the next cool thing arrives too reply thsgtu 3 hours agoprevAbout time. It always surprises me how long pandas has been able to hold on. Wes McKinney talked about pandas' limitations back in 2017 https://wesmckinney.com/blog/apache-arrow-pandas-internals/ reply dammaj 2 hours agoprevPersonnally, I tend to use Pandas because it is integrated everywhere, because of the ecosystem that uses it. Let's say I want to read data from json file (csv file, python dict, etc.) and I want to plot it using plotly. If Ibis is compatible with whatever Pands dataframe is compatible with, then for most of my usage I don't really care much about the \"backend\". reply infecto 4 hours agoprevI will try it out but honestly the pain-point for me is the library api to pandas is not always intuitive/natural to how things should be in Python. The NaN/None bit is annoying but I find that to be a minor annoyance. reply mrguyorama 3 hours agoprevPandas made me think I hated python. reply e10v_me 1 hour agoparentFunny, the same) When I was switching from R (data.table) to Python, it was painful. Not only because it was slow, but because of the API. At that time, I thought that maybe it's because of switching to something new. Several years later, switching from Pandas to Polars API was a real joy (Ibis is also good is that sense). So, I learned that it had been Pandas fault all along)) reply spywaregorilla 5 hours agoprevWhat is this exactly? The front page doesn't make it clear to make what ibis is besides being an alternative to pandas/polars. reply prepend 4 hours agoparentCheck the project’s left nav, https://ibis-project.org/why I didn’t know either. It’s a python dataframe library/api. reply smu3l 4 hours agoparentprevNever heard of ibis before but the front page give a pretty good overview of what it is to me at least. Looks like a dataframes api that can be executed on a variety of backend engines, both distributed and local. Somewhat analogous to how the pandas api can be used in pyspark via pyspark pandas, but from the api -> implementation direction rather than (pandas) implementation -> api -> implementation maybe? reply whimsicalism 2 hours agoprevFrankly, pandas/dask/polars - all are trying to recreate something that has existed for years (ie. sql, spark) and with a terrible API. I truly thought I was terrible at python for a long time because of pandas - turns out it just has an absolutely terrible API surface reply tech_ken 2 hours agoparentI would not say pandas is a recreation of SQL/Spark, they have very different use-cases in my experience. SQL/Spark is like a bulk data management tool: I use it if I need to load massive data from some remote store, perform light preprocessing, join up a couple dimension tables, etc. Having normalized and joined my data, then pandas enters as a 'last-mile' processing engine, particularly when paired with ex. SKLearn or whatever other inference lib you're using. Pandas is awesome if you need to ex. apply string manipulation to a data table or daisy-chain some complicated computations together. Honestly in my opinion the API is really nice, I came over from R tidyverse and the 'chained methods' approach to pandas let's me carry over all my old patterns and paradigms. I find it far easier to use that approach than having to write like 20 dependent subqueries or staging tables reply cmollis 1 hour agoparentprevtrue spark has existed for years and is a great toolset.. i use it ever day. it's also a huge hassle spinning clusters up and down and configuration is complex. I can execute some pretty hairy scans against a huge s3 parquet dataset in Duckdb that I would typically have to run in either spark or athena.. it's a little slower, but not ridiculously slower. And, it does all of that from my desktop.. no clusters, no mem or task configs.. just run the query. Being able to integrate all of the expensive historical scanning and knitting that back into an ML pipeline with desktop python is pretty nice. reply maxdo 5 hours agoprevcurious to know what they use instead of Dask ? reply datadrivenangel 5 hours agoparentDuckDB. It's faster on a single computer than Dask. reply codyvoda 5 hours agorootparentIbis still supports over a dozen backends, including DuckDB and DataFusion and Polars (all great single-node OLAP query engine options that are often faster than trying something distributed) and PySpark, Snowflake, BigQuery, Trino, ClickHouse, Druid, and more plenty of options for fast and scalable computation. in the fullness of time, it would be great to have a Dask backend but it'd need to be rewritten to use dask-expr, which isn't something the core Ibis team has the capacity for reply lopatin 5 hours agorootparentprevAs a potential user of Ibis, how do I know they won't eventually drop support for other backends until it just becomes a frontend for DuckDB? reply codyvoda 5 hours agorootparentGreat question, a bunch of reasons: 1. The value prop of Ibis is to avoid vendor lock-in and allow users to more easily swap out execution engines that meet their needs. So it's valuable to the project to have \"competing\" backends supported (e.g. DuckDB, DataFusion, and Polars for local, and Snowflake, ClickHouse, PySpark, Databricks, etc. for distributed) -- the idea is a standard like Apache Arrow that everyone adopts to stop this cycle of tightly coupling a dataframe interface to an execution engine 2. Ibis is primarily supported by Voltron Data (my employer) which is itself a vendor, so the real worry would be that Ibis drops all backends until it only support Voltron Data's engine (Theseus)... 3. ... but Voltron Data cannot do that for a number of reasons. First, Ibis is an independently governed open source project. Second, it would not make any business sense. You can read some more on that here: https://ibis-project.org/posts/why-voda-supports-ibis. The general idea is to add more backends, not remove them, but pandas is a special case where it introduces a lot of technical complexity with (arguably) negative benefit to potential users -- the DuckDB backend can do everything the pandas backend can do, but better reply 2-3-7-43-1807 4 hours agorootparentpreveven vanilla is faster than dask on a single computer ... _OFFICIALLY_ ... cause dask is and only is for clusters reply whimsicalism 2 hours agorootparentif you’re at cluster scale, i would skip right over dask and go to spark reply 2-3-7-43-1807 1 hour agorootparentor hadoop reply cpcloud 1 hour agorootparentI'll also suggest inscribing stone tablets with a chunked version of your computation and distributing the described chunked computation to your friends, and then gathering the tablets and finishing up the compute. It's scalable to ~billions of nodes. reply 2-3-7-43-1807 58 minutes agorootparentbut that exists already and it's called databricks reply mistrial9 4 hours agorootparentprevcan you expand or give more context on this ? reply datadrivenangel 52 minutes agorootparentDask is designed for scaling to multiple compute nodes, and is often slower than vanilla pandas on a single machine because of the overhead. If your data is larger than memory though, at a certain point Dask is faster than pandas (which will often just fail), and DuckDB (Which is super fast for in-memory data, and still quite fast for out of memory data). Rule of thumb these days though is that if your data isn't in the terabytes per run, a single processing node is probably best. reply mrbluecoat 3 hours agoprevDask was really cool back in the day. Farewell, friend. reply lmc 2 hours agoparentBack in the day? What are people using now instead? reply cpcloud 1 hour agorootparentI've been working with pencil and paper recently. Thinking about starting an Ibis backend for it. reply ZeroCool2u 2 hours agorootparentprevRay seems to be a popular choice now if you need multi node. But Polars is really nice if you're okay with just vertically scaling on one machine. reply dr_mee6 40 minutes agorootparentprevAbacuses? reply ironmagma 4 hours agoprevMan, these frontend people are constantly churning through dependencies, a new framework every year. Don't reinvent the wheel, just be like backend folks and pick a dependency and stick with it. Oh wait... reply vundercind 4 hours agoparentETL and data analysis “notebook” world been warming up for years and now it’s red-hot due to every company down to Grandma’s Cookie Bakery LLC wanting to “do AI”. And most of the standard tools are surprisingly terrible so churn is increasing for reasons similar to why that happened in frontend (the underlying tools are ass and the existing interfaces bad and almost all of it’s being overcomplicated for bad reasons and a million more developers just jumped into the pool) reply ironmagma 3 hours agorootparentYes, and so really what we are seeing is just the effects of a high quality bar. If you want high-quality software, you do more iterations. And iterations produce breaking changes. reply vundercind 3 hours agorootparentMmm. A lot of it’s motivated by pain, with the output filtered through a web of organizational friction, principal agent problems, self-promotional nonsense, and other harmful factors. If the web’s any indication, there’s no guarantee this activity is efficient at getting us closer to meeting a high quality bar. reply dr_mee6 3 hours agoparentprevJust as an FYI Ibis is being around for 10 years approximately... reply UncleOxidant 1 hour agoprev [–] Related to this pandas?: https://pandas.pydata.org/ reply cpcloud 1 hour agoparent [–] On the contrary, very related to that pandas! reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The pandas and dask backends are being deprecated and will be removed in version 10.0 of Ibis.",
      "DuckDB will become the default backend due to its superior performance, ease of installation, local operation, speed, and compatibility with the Python ecosystem.",
      "This change aims to resolve issues such as pandas' eager execution model, NaN vs NULL handling, and user confusion about performance."
    ],
    "commentSummary": [
      "Ibis is gaining popularity as a replacement for Pandas in data projects, praised for its fluid syntax, portable code snippets, and fast DuckDB backend.",
      "The community around Ibis is active and supportive, making it an attractive option for new users despite its lower recognition compared to Polars.",
      "The discussion highlights the limitations of Pandas, such as handling missing data, and mentions that Pandas now has optional support for PyArrow-backed dataframes, addressing some of these issues."
    ],
    "points": 161,
    "commentCount": 100,
    "retryCount": 0,
    "time": 1724932033
  },
  {
    "id": 41390219,
    "title": "Threads Enables Fediverse Replies",
    "originLink": "https://blog.karliner.net/posts/threads-enables-fediverse-replies/",
    "originBody": "Threads Enables Fediverse Replies Last night Adam Mosseri, Head of Instagram, quitely announced the next step in the integration of Threads into the Fediverse. In addition to being able to follow Threads accounts from Fediverse/Mastodon accounts, we can now reply to and like Threads posts. Threads are taking a quiet, incremental approach to Federation, but seem genuinely commited. Why is this important? Because I believe that Meta as a whole is moving to an open systems approach, not because Mark Zuckerberg is a nice guy, but because he is smart enough to go open before he is forced to by regulators, (or broken up). The reaction to the announcement on Threads was a huge shower of ‘What is the Fediverse?’. I suspect a big rock has just started to move… And it has, since I originally posted this, I spotted that Tumblr has announced that it’s moving completely over to run on Wordpress. So, what’s this got to do with the first bit of news? Wordpress already has very good plugins for working with the Fediverse… Tumblr announced a move to the Fediverse over a year ago, but didn’t make good on it. Now they are changing platforms they’ll get Federation for free. Standby for half a billion Tumblr blogs to turn up on the Fediverse. This also means Threads users liking Tumblr posts and probably reviving a struggling platform. The true power of open social media is about to become apparent.",
    "commentLink": "https://news.ycombinator.com/item?id=41390219",
    "commentBody": "Threads Enables Fediverse Replies (karliner.net)157 points by mkarliner 6 hours agohidepastfavorite72 comments lolinder 5 hours ago> Because I believe that Meta as a whole is moving to an open systems approach, not because Mark Zuckerberg is a nice guy, but because he is smart enough to go open before he is forced to by regulators, (or broken up). I think it's both more than that and less than that. Unless I missed some news, Meta's newfound love for product openness has only really manifested in Llama and Threads—I haven't seen any evidence of shifts in their core products. I think what's happened is that in both cases Meta knows that they don't really stand a chance of actually unseating the big players in that segment on their own, but that Meta can make a dent in their profit margins if they can dilute the value of owning that segment. Llama is squarely targeted at preventing anyone from owning AI. I think Threads is doing the same thing with microblogging. If Meta can't own a segment they're going to make darn sure that no one else can own it and use their profits from it to push Meta out of their core. If it also makes the company look more palatable to regulators, that's a nice side effect, but I'm not sure it would work as the primary goal. reply onlyrealcuzzo 5 hours agoparent> If Meta can't own a segment they're going to make darn sure that no one else can own it and use their profits from it to push Meta out of their core. I think it's more about trying to keep your competitors busy defending their moat - so that they don't go on the offense and attack your moat. reply theptip 4 hours agorootparent“Commoditize your complements” is a related point. Content is the input to the Meta ad engine. You can generate it on-platform, or you can bring it in from elsewhere if it is commoditized. (And commoditizing your complements often looks like breaking down your competitors’ moats.) I don’t think it’s as cynical as a “salt the earth” strategy though, surely they (plan to) make profit from Threads and LLaMa regardless of what their competitors do? Threads users will drive ad revenue, Llama (theoretically, eventually) increases the quality bar for content, driving their main flywheel. reply Hoasi 54 minutes agorootparentprevIf Mark went scorched earth on AI, you can bet it is not for the sake of generosity. reply lolinder 5 hours agorootparentprevYeah, that also works as an explanation. Same principle—defend yourself by going on the offensive. There's a reason why Threads was only conceptualized after Musk acquired Twitter and started talking about building an everything app. Pre-Musk Twitter was very content with its market and so wasn't a threat to anyone else. Musk's X was a different story (if he could execute on it, which at the time seemed more likely than it does now). reply ZeroGravitas 4 hours agorootparentI may be wrong but I remember it almost exactly the opposite i.e. that Musk was clearly flailing with Twitter and Meta saw that as an opportunity to move into Twitter's market, which they would have struggled to do with competent management at Twitter. reply sangnoir 55 minutes agorootparentI'll also note that Twitter was pretty open and had lots of goodwill, which would have made competing against it really hard. Twitter getting rid of 3rd party clients (pre-Musk), and shutting down API access (post-Musk) burned a lot of goodwill, leading to large spikes of growth of the Fediverse, and creating a window of opportunity for a microblogging service from Meta. reply nordsieck 4 hours agorootparentprevExactly. I don't think Meta would have been so keen to launch a competitor if people weren't so desperate to leave x (nee twitter) for another platform. reply JohnMakin 3 hours agorootparentprevYea, lol, Musk's twitter was never, ever a clear threat to any competitor and Zuck smelled blood in the water. Elon fanboism has spun it the other way for obvious reasons. reply mikae1 3 hours agoparentprevHe’s already forced to by regulators[1]. That’s the reason he did this. No love involved, rest assured. [1] https://digital-markets-act.ec.europa.eu/gatekeepers_en reply lolinder 3 hours agorootparentI don't see \"Threads\" on the list of \"Core platform services\", and I see no evidence of the services that are so designated becoming part of the fediverse. reply mikae1 3 hours agorootparentMeta is a gatekeeper, it applies to their services. This (or an alternative) will have to be rolled out to Instagram. I guess now the smaller Threads is testing ground. reply solarkraft 5 hours agoparentprev> Meta's newfound love for product openness has only really manifested in Llama and Threads They’re also paying lip service to openness by spinning off their VR OS. Of course that doesn’t mean it’ll become any less proprietary, only available on more hardware. It’s smart to join up with others when you’re the underdog. I think that’s all they’re doing. reply mkarliner 5 hours agoparentprevWell, personally I think that Meta is taking the threat of regulator action very seriously. You only have to look at how Google and Apple are in trouble. Owning WhatsApp, Threads and Instagram makes them a big target for breakup. And an open system defuses that significantly. reply lolinder 5 hours agorootparent> And an open system defuses that significantly. I'm not sure that it has as much of an impact as you think it does. Threads would not be a significant target for regulator action regardless of openness—it doesn't have enough share of the market to be interesting. Meanwhile, the openness of Threads does nothing to alleviate the concerns of their dominance in every non-microblogging social media category. reply sangnoir 53 minutes agorootparent> Threads would not be a significant target for regulator action regardless of openness—it doesn't have enough share of the market to be interesting Zuckerberg thinks Threads could be Meta's next billion-plus-user product. reply mkarliner 5 hours agorootparentprevMeta could link Threads and Instagram in a heartbeat if they chose, and were't scared of the consequences. Threads is small fry at the moment, but a very good test and precursor to making the same play across the other properties. I respect your opinion BTW, I don't like flame wars. :-) It's worth remembering that the Fediverse is not just microblogging, there are platforms for pretty much every kind of social media play. reply cooljacob204 5 hours agoparentprevThey have been doing a lot of open source work in the frontend world for a while. Biggest example is React. reply lolinder 5 hours agorootparentYes, there's a reason I specified \"product openness\". React isn't a product and never could have been, so while I'm grateful to them for releasing it open source it doesn't really represent the same kind of play as Threads or Llama. reply breezeTrowel 4 hours agorootparentHow is Llama a product? It's more like React, PyTorch, GraphQL, etc. reply dagmx 4 hours agorootparentMeta’s AI offerings are products. They’re featured in Instagram, Facebook and Messenger. They’re part of the Rayban partnership. Imho definitely a product. reply breezeTrowel 4 hours agorootparentYes and Facebook uses React and GraphQL. Meta AI uses PyTorch. Does that make them all products? reply dagmx 4 hours agorootparentNo, because they’re not exposed to users as features that they interact with. From a user perspective, they don’t ever see if it was made using those tools. They see the AI front and center. I feel like thats a pretty strong distinction. reply breezeTrowel 3 hours agorootparentThey see AI features front and center. They dont see the backend (which may or may not be running Llama). Same goes for React although, with React, the framework is what the end user directly interacts with. So, by that logic, React is more of a product than Llama. reply dagmx 3 hours agorootparentLet me flip this around. If you are a user, what feature is react giving you? Pre and post react, Facebook is largely the same to a user. Pre and post graphql, Facebook is also the same. To the user, neither of those are expressed as features. Llama / Meta AI is a feature that changes how a user interacts with the system. When it was added, it’s noticeable. If it were to be taken away it would be noticeable. Nobody was boycotting react. That is the difference between an implementation detail and a product/feature. reply tomjen3 4 hours agoparentprevYou are not wrong, but I also think there is another part at play here: Facebook started out quite open and then gradually became closed (just like reddit and twitter). This is a new product, so they start out open and then slowly close down as they acquire marketshare. reply JohnMakin 3 hours agoprevI think this is great. I've been using threads for 6 months, and while I was never a prolific twitter user - I thought it sucked even before the elon purchase, now, it's entirely unusable to me (and I've tried) - I do like its interface, a seemingly \"light\" (by meta standards) approach to moderation, and now a step in this direction I think is a really good thing. As to the \"why\" I think it's fairly obvious. If they integrate with everything, they'll eventually become the defacto platform and/or steer users and engagement to their other platforms with less friction. reply downWidOutaFite 1 hour agoparentAs an advocate for peace in Gaza the moderation has been anything but light. Can't even use the word zionist on there. reply JohnMakin 1 hour agorootparentYea, this is a platform-wide thing and across most other platforms as well - I meant in terms of like, forcing you to edit posts with \"forbidden\" keywords like they love to do on IG (but never tell you exactly what you said wrong), tone policing, hiding comments between users arguing with each other, etc. reply ChrisArchitect 3 hours agoprev(tries to find keystroke for Fediverse symbol) ⁂ https://news.ycombinator.com/item?id=41327567 reply proactivesvcs 20 minutes agoparent(tried to use Compose key, had to find out how to add Compose sequences) ⁂ reply bee_rider 2 hours agoparentprevSpiky therefore symbol? reply Zefiroj 1 hour agoparentprevstar-triforce reply bcye 3 hours agoprevhttps://en.wikipedia.org/wiki/Embrace,_extend,_and_extinguis... reply idatum 1 hour agoprevIf I understand Threads adoption, it is quite large compared to Mastodon. Will Mastodon be able to handle the load if Threads -- a commercial entity -- is not blocked? I'm holding off on making the cynical conclusion about Threads' motivations. reply draxil 5 hours agoprevOFC most of the fediverse has blocked threads already. reply bitcharmer 2 hours agoparentAnd for a very good reason reply xyst 4 hours agoprevWhat's the true goal here? Given the decentralized aspect of the fediverse, facebook won't be able to sell ad space here. Is threads hoping to become \"the\" instance in the fediverse? Then they can impose their will across the rest of the fediverse. threads: \"oh, you have a single user instance and want to federate with us? Pay us $500 per user/year, and use our preferred server which allows us to sell ad space on your server\" reply nunobrito 4 hours agoparentAlgorithms. Right now fediverse is growing and has very honest algorithms. Once Meta is on the scene, their \"decentralized\" timeline will look more enticing than others. It will be captivating and you'll prefer to hangout on their server with all nice extensions that just work there. With time, +90% of users won't bother looking on small isolated islands and you'll have facebook 2.0 in place. Anyways, it is a fair fight. Meta coming to fediverse already means that things on this side are interesting. reply takeda 3 hours agoparentprevThe goal is basically repeating what Google did with XMPP/Jabber: https://ploum.net/2023-06-23-how-to-kill-decentralised-netwo... reply sangnoir 41 minutes agorootparentIronically, Facebook was also involved with Google defederating from XMPP, according to an explanation I read many years ago (IIRC, from Larry Page when he was CEO). FB messenger could connect to Google Talk users, but not the other way around - so Google wasn't pleased about freely exporting users' \"social graph\"[1] to Facebook, and getting nothing in return. 1. The \"social graph\" was the new hotness then, everybody had to have it, just like AI now. An exec at Google convinced the company that Facebook was an existential threat, leading to some very questionable decisions bourne of a self-induced siege-mentality. reply samatman 30 minutes agorootparentIt remains baffling and sad that Google's first response to this was to murder their best social graph in cold blood. Between giving Reader the axe, and the real names fiasco on Google+, the company has destroyed the necessary trust to ever operate a social graph worth having. Please don't tell me that YouTube is a social graph, by the way. Words should mean something. If YouTube were a social graph, I'd see videos from the accounts I follow. reply theptip 4 hours agoparentprev> facebook won't be able to sell ad space here Why not? The Threads client will run ads. If users prefer the experience (integration to other Meta products, QoL, etc.) then they will use it and watch the ads. If they prefer other clients they will use those. reply nordsieck 4 hours agoparentprev> Is threads hoping to become \"the\" instance in the fediverse? Probably > Then they can impose their will across the rest of the fediverse. Nah. The play at that point would be to just discontinue support for federation and lock all their users inside the new walled garden. reply klysm 4 hours agoparentprevEmbrace extend extinguish ? reply takeda 3 hours agorootparentExactly https://ploum.net/2023-06-23-how-to-kill-decentralised-netwo... reply dahauns 4 hours agorootparentprevEntice, Entrench, Enshittify. reply crowcroft 4 hours agoprevWould love to know how many people on threads interact with the fediverse beyond threads. I know it’s still early and features are being built out, but my guess is the number is close to 0. reply mkarliner 4 hours agoparentAgain, not really the point. So long as Meta can say their platforms are open, they have a bulwark against regulators and/or being broken up. It really doesn't matter to them if it's popular or not. reply crowcroft 3 hours agorootparentI would go as far as to say they don't really want it to be popular, but I would love to see enough integration for there to be at least some attempt at competition. reply renewiltord 4 hours agoprev> not because Mark Zuckerberg is a nice guy Mark Z was clear on Dwarkesh's podcast that when he has things open he does so because he thinks it will benefit Meta and he explicitly says it's not altruistic and that if it stops being useful he'll stop making things open. reply kmfrk 4 hours agoprevTumblr's been talking about the move for ages, but does anyone knoe what progress is being made towards it? reply jmyeet 4 hours agoprevI've been intrigued by Threads since it launched last year. Succeeding where there's a competitor as entrenched as Twitter is nigh on impossible. The network effect is massive. But of course there are chinks in TWitter's armor, specifically the whole blue check debacle and that Twitter itself is rapidly becoming 4chan (or even 8chan) and advertisers are understandably fleeing. Still, the chance of success isn't great. Launching it under the iG brand was probably a good idea, better than under Facebook at least. Still, when it comes to open source and integration with third-parties I keep thinking of the quote \"open source is for losers\" (that might come from this [1]), meaning all but the dominant player embrace interoperability and open source in a desperate attempt to topple the dominant player. I have no idea what usage looks like but I'm glad they haven't given up. I know Google would've canceled it by now (and probably replaced it with something that looks kinda similar, has a different name/branding but no compatibility with the old thing, if chat apps are anything to go by). I still say federation is something tech people care about but offers nothing of tangible value to end users. There hasn't been a successful federated technology since email. For a reason. [1]: https://siliconangle.com/2014/05/29/only-loser-vendors-are-t... reply mkarliner 4 hours agoparentThe entire mobile phone network? reply loeg 3 hours agorootparentThat predates email and is ... not really a counterpoint to federation sucking for end-users? There's so much spam/phishing and somehow it's no one's legal responsibility. reply theanonymousone 5 hours agoprevStill not in Europe? reply hn1986 5 hours agoparentThese fediverse changes in Threads are in Europe but not in the EU yet. Threads itself is available worldwide, including the EU. reply mkarliner 5 hours agorootparentYes, I'm in the UK, works here. I'd give up Threads to be back in the EU :-) reply red_trumpet 5 hours agoparentprevCare to elaborate? It looks like Threads is available in Europe. reply wazoox 4 hours agoprev\"Embrace, Extend, and Extinguish\". reply mort96 5 hours agoprevnext [11 more] [flagged] jensensbutton 5 hours agoparentHow is that your takeaway? Seems like the opposite of what's being said. reply mort96 3 hours agorootparentYou're right, I read it as \"disables\" rather than \"enables\". That's on me, sorry. reply empath75 5 hours agoparentprevThey're taking it slow at least in part because there were concerns about threads traffic overwhelming mastodon servers. reply krapp 5 hours agorootparentThat shouldn't be a huge problem - many Mastodon servers are already blocking Threads by default. reply dewey 5 hours agorootparentMost people are probably on the 3 biggest instances and the \"official\" instances don't have it blocked as far as I can see (https://blog.joinmastodon.org/2023/07/what-to-know-about-thr...). Blocking also seems like a silly thing for a network that is about being open and interoperable. reply mkarliner 4 hours agorootparentQuite, and, as I said in my post, I think we (the Fediverse) owe it to the rest of the Internet to enable the deconstruction of the current social media landscape as much as possible. reply krapp 4 hours agorootparentprevThe protocol is open and interoperable. I can't build a Facebook but nothing is stopping Mark Zuckerberg from building a platform on ActivityHub. But there would be no point to a federated network if every node were required to accept traffic from all other nodes. That's just centralization with extra steps.. and centralized social media is what most people who move to federated networks are trying to avoid, to say nothing of the cost burden on smaller instances to handle all of that traffic. A lot of people block the big instances as well for similar reasons. reply immibis 3 hours agorootparentprevIs blocking spam a silly thing? (Google Groups was to Usenet what Threads is to ActivityPub, and it got collectively blocked by all Usenet servers for spam, then decided to shut down.) reply immibis 3 hours agorootparentprevIs blocking spam a silly thing? reply dewey 3 hours agorootparentNo, but \"spam\" is subjective and while you can decide that for your own instance, doing it for a bigger instance on behave of your users seems a bit overreaching...but luckily I can just move to an instance where I agree with the rules or host my own. reply nunobrito 4 hours agoprev [–] Just wait until they discover NOSTR. reply greentea23 3 hours agoparent [–] Nostr makes so much more sense to me than the fediverse because your account is not bound to a particular server, so if your admin gets bored you can simply use other relays or host your own instead of being kicked off. And with this you get pretty significant fediverse interop: https://gitlab.com/soapbox-pub/mostr reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Adam Mosseri, Head of Instagram, announced that Threads now allows users to reply to and like posts from Fediverse/Mastodon accounts, marking a significant step in integrating Threads into the Fediverse.",
      "This move indicates Meta's shift towards an open systems approach, possibly to address regulatory pressures, and has sparked curiosity about the Fediverse.",
      "Tumblr's announcement to run on WordPress, which supports Fediverse plugins, means it will join the Fediverse, potentially revitalizing the platform and highlighting the benefits of open social media."
    ],
    "commentSummary": [
      "Threads now supports Fediverse replies, leading to discussions about Meta's true intentions behind this move.",
      "Critics argue that Meta's openness is a strategic effort to avoid regulatory scrutiny and weaken competitors, rather than an act of goodwill.",
      "While some see potential benefits in the integration, concerns remain about Meta's long-term goals and the effect on smaller platforms."
    ],
    "points": 157,
    "commentCount": 72,
    "retryCount": 0,
    "time": 1724935392
  },
  {
    "id": 41387922,
    "title": "Docusaurus – Build optimized websites quickly, focus on your content",
    "originLink": "https://docusaurus.io/",
    "originBody": "Build optimized websites quickly, focus on your contentDocusaurusfunction insertBanner(){var n=document.createElement(\"div\");n.id=\"__docusaurus-base-url-issue-banner-container\";n.innerHTML=' Your Docusaurus site did not load properly. A very common reason is a wrong site baseUrl configuration. Current configured baseUrl = / (default value) We suggest trying baseUrl = ',document.body.prepend(n);var e=document.getElementById(\"__docusaurus-base-url-issue-banner-suggestion-container\"),s=window.location.pathname,o=\"/\"===s.substr(-1)?s:s+\"/\";e.innerHTML=o}document.addEventListener(\"DOMContentLoaded\",(function(){void 0===window.docusaurus&&insertBanner()}))function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag(\"js\",new Date),gtag(\"config\",\"G-E5CR2Q1NRE\",{})!function(){function t(t){document.documentElement.setAttribute(\"data-theme\",t)}var e=function(){try{return new URLSearchParams(window.location.search).get(\"docusaurus-theme\")}catch(t){}}()||function(){try{return window.localStorage.getItem(\"theme-189\")}catch(t){}}();null!==e?t(e):window.matchMedia(\"(prefers-color-scheme: dark)\").matches?t(\"dark\"):(window.matchMedia(\"(prefers-color-scheme: light)\").matches,t(\"light\"))}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith(\"docusaurus-data-\")){var a=t.replace(\"docusaurus-data-\",\"data-\");document.documentElement.setAttribute(a,e)}}catch(t){}}(),document.documentElement.setAttribute(\"data-announcement-bar-initially-dismissed\",function(){try{return\"true\"===localStorage.getItem(\"docusaurus.announcement.dismiss-189\")}catch(t){}return!1}())Skip to main content🎉 Docusaurus v3.5 is out! 🥳DocusaurusDocsAPIBlogShowcaseCommunity3.5.1Canary 🚧3.5.13.4.03.3.23.2.13.1.13.0.12.xArchived versions2.3.12.2.02.1.02.0.11.x.xAll versionsEnglishEnglishFrançaisPortuguês (Brasil)한국어中文(中国)Help Us TranslateSearch🎉 Docusaurus 3.5 is out! 🥳Build optimized websites quickly, focus on your contentGet StartedTry a DemoPowered by MDXSave time and focus on text documents. Simply write docs and blog posts with MDX, and Docusaurus builds them into static HTML files ready to be served. You can even embed React components in your Markdown thanks to MDX.Built Using ReactExtend and customize your project&#x27;s layout by writing React components. Leverage the pluggable architecture, and design your own site while reusing the same data created by Docusaurus plugins.Ready for TranslationsLocalization comes out-of-the-box. Use git, Crowdin, or any other translation manager to translate your docs and deploy them individually.Document VersioningSupport users on all versions of your project. Document versioning helps you keep documentation in sync with project releases.Content SearchMake it easy for your community to find what they need in your documentation. We proudly support Algolia documentation search.Check it out in the intro videoLoved by many engineersMark Erikson@acemarkeWe&#x27;ve been using Docusaurus for all the Redux org docs sites for the last couple years, and it&#x27;s great! We&#x27;ve been able to focus on content, customize some presentation and features, and It Just Works.Oct 26, 2021Supabase@supabaseWe&#x27;ve been using V2 since January and it has been great - we spend less time building documentation and more time building 🛳Thanks @docusaurus team 🦖Nov 18, 2020Dr.Electron@Dr_ElectronThe #IOTA wiki is now part of the @docusaurus showcase. We even have the honor of being a favorite. We are really happy that we found this project. It helped us a lot to improve the documentation. And we still have a lot of plans with things like tutorials, versioning and i8n.Oct 11, 2021Maël@arcanisI&#x27;ve used Docusaurus for two websites this year, and I&#x27;ve been very happy about the v2. Looks good, and simple to setup.Jan 20, 2021Paul Armstrong@paularmstrongContinue to be impressed and excited about Docusaurus v2 alpha releases. Already using the sidebar items generator to help monorepo workspace devs create their own doc pages without any configuration needed.Apr 27, 2021Kent C. Dodds@kentcdoddshttp://testing-library.com just got a nice update! We&#x27;re now on the latest version of @docusaurus thanks to @matanbobi, @TensorNo, and @nickemccurdy 💙My favorite new feature: dark mode!! 🌑/☀Nov 4, 2020Max Lynch@maxlynchDocusaurus v2 doubles as a really nice little static site generator tool for content-focused sites, love it 👏Mar 25, 2021Debbie O&#x27;Brien@debs_obrienBeen doing a lot of work with @docusaurus lately and I have to say it is really fun to work with. A lot of really cool features. I love that you can easily reuse content by creating a markdown file and importing it as a component. 🔥Mar 24, 2021swyx@swyxHappy to share Temporal&#x27;s first open source sponsorship — of @docusaurus!@temporalio uses it for http://docs.temporal.io, and it has been a huge boon to our docs team. @sebastienlorber is an incredible steward of the project, support it if you can!Jul 23, 2021Christopher \"vjeux\" ChedeauLead Prettier DeveloperI&#x27;ve helped open source many projects at Facebook and every one needed a website. They all had very similar constraints: the documentation should be written in markdown and be deployed via GitHub pages. I’m so glad that Docusaurus now exists so that I don’t have to spend a week each time spinning up a new one.Hector RamosLead React Native AdvocateOpen source contributions to the React Native docs have skyrocketed after our move to Docusaurus. The docs are now hosted on a small repo in plain markdown, with none of the clutter that a typical static site generator would require. Thanks Slash!Ricky VetterReasonReact DeveloperDocusaurus has been a great choice for the ReasonML family of projects. It makes our documentation consistent, i18n-friendly, easy to maintain, and friendly for new contributors.LearnIntroductionInstallationMigration from v1 to v2CommunityStack OverflowFeature RequestsDiscordHelpMoreBlogChangelogGitHubTwitterLegalPrivacyTermsCookie PolicyCopyright © 2024 Meta Platforms, Inc. Built with Docusaurus.",
    "commentLink": "https://news.ycombinator.com/item?id=41387922",
    "commentBody": "Docusaurus – Build optimized websites quickly, focus on your content (docusaurus.io)152 points by yamrzou 12 hours agohidepastfavorite39 comments Growtika 8 hours agoThe first time I heard about Docusaurus was when someone mentioned on Hacker News that they had ruined their SEO: https://news.ycombinator.com/item?id=34389421 I helped him in recovering from a Google SEO penalty, and he documented his journey on his blog: https://johnnyreilly.com/how-we-fixed-my-seo This might be helpful for those using Docusaurus, as some default settings, like pagination and tag pages, can generate thousands of non-helpful pages. These issues can be easily fixed with noindex tags and a sitemap/structure cleanup. Overall, I think Docusaurus is great. It's clean, flexible, and the community is very responsive, so it's constantly improving at a fast pace reply cpursley 6 hours agoparentThis post in particular helped me fix seo as well for https://appraisalinbox.com (the design still needs a lot of love). These days I'd probably start off using astro for a static site. They've got a docs starter, too. reply d4rkp4ttern 8 hours agoparentprevI like it too but it doesn’t have auto-docs based on docstrings, which Material for MkDocs has: https://github.com/mkdocstrings/mkdocstrings reply matsemann 5 hours agoparentprevAww man I hate clicking on a result on google, taking me to a pagination page where the content I'm looking for is no longer on that page. reply actionfromafar 8 hours agoparentprevOh, Reilly? He should write a book. :) reply Jakob 10 hours agoprevI wish all API doc generators test the doc code examples like this https://rust-lang.github.io/mdBook/cli/test.html Even if the code example works today, it might not in the future and tests prevent people getting stuck on outdated docs like we often see. reply jillesvangurp 8 hours agoparentI actually wrote a kotlin library (https://github.com/jillesvangurp/kotlin4example) a while ago to help me write documentation that is generated from code that actually compiles and runs. Instead of embedding code in markdown, I actually generate the markdown from code. Which with Kotlin is easy because you can write your own DSLs. And I get to refactor my code and documentation at the same time. It has some other nifty features like capturing output that you can show in the Markdown and a few other things. If you want to see it in action, check out the documentation for my kt-search project. There are probably a lot of other libraries out there that do similar things. But it's a thing that most projects don't seem to rely on for their documentation. And breaking code samples are a major hurdle for writing documentation to begin with. I find that addressing that gets you in a mode where you are documenting things by default. And good documentation also reveals design flaws because you are kind of forced to eat your own dog food by writing working code that shows how you would use a particular feature. I'm basically constantly trying to make life easier for both myself and my users. reply mkesper 7 hours agorootparentReminds me of Knuth's literate programming: https://www-cs-faculty.stanford.edu/~knuth/lp.html reply jillesvangurp 6 hours agorootparentThat was a direct inspiration. reply boxed 6 hours agoparentprevI wrote a ton of custom code to do this for iommi (example: https://docs.iommi.rocks/en/latest/tutorial.html). I went further than any other library I've seen and made it so that the views in the examples produce static html files that are embedded in the resulting output via iframes. reply sixhobbits 11 hours agoprevI've tried most of these and this is definitely one of the best, especially since the latest version. It's not too heavy but includes all the features you don't know you need at the start, and a good ecosystem of plugins and extensions. Other notable mentions are - mkdocs-material, if you prefer python to js - astro starlight, not quite as mature and a bit heavier but looks nicer out the box and includes built-in search reply reacharavindh 11 hours agoparentMkdocs-material has been my go to for this use case. However, I once made a document website using MDbook(the thing that Rust uses for their own documentation and book), and have a lot of happy consumers. reply lloydatkinson 10 hours agoparentprevWhat makes starlight heavier? If anything its the opposite, it's not client side rendering pages like Docusaurus... https://starlight.astro.build/environmental-impact/ reply thibaultamartin 9 hours agorootparentLikewise, I've been happy with Starlight and trust Astro products to be lightweight and efficient. I'm interested in knowing what makes it heavier reply FireInsight 9 hours agorootparentprevThe comparisons-page clearly highlights that Docusaurus is way heavier. https://starlight.astro.build/environmental-impact/#comparis... reply FireInsight 10 hours agoparentprevmkdocs-material is fine if you prefer Python to JS, but I personally very much dislike how it looks, and as everything else it uses a weird custom Markdown flavor where indentation is handled weirdly which can create edge-cases where for example a valid GFM list is not rendered properly by MkDocs. +1 on Starlight, though, it is my go-to and I absolutely love it. reply Onavo 10 hours agoparentprevAre there any good open source documentation chatbots that you can integrate into the search function of docusaurus? If you see commercial offerings like mintlify, they all come with a Q and A chatbot built-in. It’s not very hard to build, you just need to generate the RAG chunks at build-time but this is best implemented as part of the documentation software, rather than as a third party plugin since it heavily ties into the search feature. reply bnlxbnlx 1 hour agorootparent+1! I'd love to know, too! reply johnny_reilly 9 hours agoprevLong time user of (and contributor to) Docusaurus. I use it to build my markdown powered tech blog. https://johnnyreilly.com/ It is very much a Goldilocks product for me (\"just right\") in that it has React support, Markdown support, TypeScript support and a good amount of customisation is possible (good underlying APIs). It also has a great community. Props to Sébastien Lorber for leading the project so well! reply anon1094 7 hours agoparentHey John, thanks for your contributions! Also gotta give a big shoutout to Sébastien and the crew for creating and constantly updating Docusaurus - it's one of my favorite docs software. reply anon1094 8 hours agoprevDocusaurus shines in docs-as-code scenarios. I used it for Amplication, Februar, and other technical docs projects. The SEO features, integrated Algolia search, and built-in components save a lot of time and help you focus on writing markdown. The plugin system and React-based customization is powerful, but for most projects you should be fine with the provided components and editing the custom css file. For a look at how a dev tool company uses Docusaurus to implement its docs, check out this article on Amplication's approach: https://medium.com/abundant-dev/amplication-documentation-ca... This might help those wanting to use Docusaurus with a docs-as-code workflow, especially when using GitHub or other git platforms for reviews. reply oliwarner 2 hours agoprevThere are a lot of these documentation-geared SSGs. I've tried a few and Starlight is what rang least annoying of the bunch. No library lock-in, a sane theme, client-side search, a much smaller dependency tree than many, and quite fast to build. https://starlight.astro.build/ reply lioeters 9 hours agoprevOne of my favorite features of Docusaurus is integration with TypeDoc to generate API docs for TypeScript definitions. It makes for a useful overview of all available classes, functions, etc. It's not sufficient by itself as documentation, but it covers an important aspect as reference. reply synergy20 3 hours agoprevI wish all those static site generators, and docusaurus alike doc sites, can add a login feature if they do not have one still. what I want is a simple CMS basically, not as complex as drupal etc, but at least support login to view when I need it. reply ruuda 3 hours agoprevIf you don't like to run javascript outside of a browser, MkDocs is a great Python-based alternative: https://www.mkdocs.org/ reply AUnterrainer 10 hours agoprevI have been using docusaurus for my tech blog (www.defconq.tech) and it's easy enough to use for a non front end dev. reply lukcybrain 9 hours agoparentGlad to hear it's work without a front-end development background. reply anon1094 7 hours agorootparentYeah, it's great for non-front-end folks! The default themes look pretty good, and you can use a bunch of pre-made components right in your markdown. reply sir-dingleberry 1 hour agoprevWhen I see React in 2024 I get uncomfortable. reply archibaldJ 6 hours agoprevSo how does astro's Starlight compare to it as of Sep 2024? I've invested a bit time to configure Starlight for a new proj but now I'm a bit tempted to switch over Would love feedbacks from anyone who have been with both Starlight and Docusaurus; thanks! e.g. are there anything great about Starlight that I should stick to it? SEO-wise, etc. reply microflash 5 hours agoparentWhy are you tempted? Personally, I like Starlight's use of web components. It is much more lightweight and since it is based on Astro, you can use whatever framework you want / need. reply _chimmy_chonga_ 4 hours agoprevwe use Docusarus at work for our internal documentation sites and its okay. It gets the job done and it beats manually making a nice website for docs by hand reply drdrek 4 hours agoprevWhy are there so many site publishing solutions? Is it that good of a business? Is it advantageous to smaller players? reply sir-dingleberry 1 hour agoparentThey're relatively easy to make. reply DilutedMetrics 7 hours agoprevI love Docusaurus. I use it for personal web projects as a static site. There's a surprising number of sites I see nowadays that you can tell are also built on Docusaurus. reply I_am_tiberius 6 hours agoprevMaybe not fitting to mention that here, but Typora still doesn't support .mdx files out of the box. This makes maintaining docusaurus sites a hassle. reply newusertoday 11 hours agoprevfor some reason most of the docs site themes have anemic support for blogs and if you are developing something you almost always want landing+blog+docs, yet its either fixated on docs or blogs but rarely both. I wonder why? reply preommr 11 hours agoparentBecause it's trivial to mix-and-match specialized products in a single project. It's trivial to install docusaurus, and a ssg like eleventy in the same project, and configure it so that they have some shared components by setting configuration details to point to the right directory, all within one repo, same package manager, etc. reply TDM_x 10 hours agoprev [–] Sounds really interesting to build it with Markdown that's cool, especially to make web pages thanks to AI ^^. Thanks for sharing this. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Docusaurus helps build optimized websites quickly, focusing on content creation by converting MDX (Markdown with JSX) into static HTML files.",
      "Key features include localization, document versioning, and content search with Algolia, making it highly customizable and efficient for documentation.",
      "Praised for ease of use and flexibility, Docusaurus allows embedding React components in Markdown and supports a pluggable architecture."
    ],
    "commentSummary": [
      "Docusaurus is a popular tool for building optimized websites quickly, with a focus on content, but some default settings can negatively impact SEO.",
      "Users have shared experiences and solutions for SEO issues, such as using noindex tags and sitemap cleanup to avoid non-helpful pages.",
      "Docusaurus is praised for its flexibility, responsive community, and features like React, Markdown, and TypeScript support, making it suitable for both front-end and non-front-end developers."
    ],
    "points": 152,
    "commentCount": 39,
    "retryCount": 0,
    "time": 1724912856
  }
]
