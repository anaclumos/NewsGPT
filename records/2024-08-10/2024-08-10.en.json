[
  {
    "id": 41207415,
    "title": "Susan Wojcicki has died",
    "originLink": "https://twitter.com/sundarpichai/status/1822132667959386588",
    "originBody": "Unbelievably saddened by the loss of my dear friend @SusanWojcicki after two years of living with cancer. She is as core to the history of Google as anyone, and it’s hard to imagine the world without her. She was an incredible person, leader and friend who had a tremendous…— Sundar Pichai (@sundarpichai) August 10, 2024",
    "commentLink": "https://news.ycombinator.com/item?id=41207415",
    "commentBody": "Susan Wojcicki has died (twitter.com/sundarpichai)595 points by grandmczeb 13 hours agohidepastfavorite313 comments lchengify 11 hours agoWas shocked to hear this news. I worked for Google years ago but I was in the NYC office, so we didn't run into the YouTube folks much. Opinions about YouTube may be mixed here on HN, but it is objectively one of the most successful businesses in tech or media to emerge in the past 15 years. If it weren't buried inside Alphabet, Youtube would be worth on the order of $400 billion, more than Disney and Comcast combined. It's a weird mix of a huge creator monetization network, a music channel, an education platform, a forever-store of niche content, and a utility. It's also not a business that rested on it's laurels. It's easy to forget how novel creator monetization was when YouTube adopted it. They do a lot of active work to manage their creators, and now have grown into a music and podcast platform that is challenging Apple. To top it off, YouTube TV, despite costing just as much as cable, is objectively a good product. Few products have the brand, the reach, monetization, and the endurance that YouTube has had within Google. And I know for a fact that this is in no small part due to the way it was managed. I've probably watched tens of thousands of hours of YouTube at this point. Some of it sublime, some of it absurd, some of it critical for my work or my degree. I couldn't imagine a world without it. RIP. reply dotnet00 2 hours agoparentYouTube has very much been resting on its laurels, they were innovative 20 years ago when they started. For the past decade or so they have mostly just rested on their laurels allowing the auto-moderation to rampage and destroy people's livelihoods. They've been way behind on adding standard features that their competitors see lots of benefit from. For example, YouTube was years late to the 'channel memberships' game despite the popularity of Twitch and Patreon. YouTube still lacks many of the popular streaming features from Twitch, and only relatively recently got around to adding stuff like polls. I can't think of any feature in the past decade that was a YouTube innovation rather than an innovation from competitors that was copied over years later. reply dylan604 2 hours agorootparentI've often wondered why YT hasn't released a subscription fee or donate type button where they could easily take a small nominal processing fee while removing the friction of forcing use of 3rd party services. Is liability from that kind of money movement too much for them to care with all of the much less risky money they are making? reply trogdor 1 hour agorootparentThey have both. Subscription fee is channel memberships, and donation is the “Thanks” button. reply sulam 1 hour agorootparentprevThey have Memberships now and I wouldn’t be surprised if they don’t have a donate button hidden away somewhere. reply mrkramer 7 hours agoparentprev>Opinions about YouTube may be mixed here on HN, but it is objectively one of the most successful businesses in tech or media to emerge in the past 15 years. I was always critical of YouTube from the sort of technical perspective than just pure UX. The core product and the core UX are great and I'm even considering getting YouTube Premium because I use YouTube so much. All in all, YouTube was and still is internet phenomena and they definitely dominate internet video, imo one of the best internet product ever created. reply ChrisMarshallNY 6 hours agorootparentYouTube has worked well. However, I did try their YT Premium, for a while, and was incredibly disappointed in their UI. I assume that the Premium UI was designed for people that use their free tier, but is very strange, to folks like me, who come from other paid services. But I am likely not their target audience. I suppose that YT Premium does well. reply paxys 6 hours agorootparentThere is no \"Premium UI\". Premium is simply regular YouTube without ads. reply darby_nine 5 hours agorootparentI think maybe the above poster is referencing the music product, but that's just a guess. reply ChrisMarshallNY 5 hours agorootparentNo, it was the movie channel. I tried it out, because YT Premium had a particular show I wanted to see. The biggest issue that I had, was that I couldn't find shows that I wanted to see. YT kept shoving a bunch of stuff into the UI that I wasn't interested in. All my searches were littered with results that were not relevant to me. I suspect they were paid. The Apple App Store has the same problem. It's infuriating. Listen, I apologize for diverting from the real issue, that a tech luminary died young. I did not know her, but it sounds like she was popular, and did well. reply lokar 4 hours agorootparentDo you mean YouTube tv? reply ChrisMarshallNY 25 minutes agorootparentSorry. I thought they were the same. Anyway, yes. YouTube TV. reply nnf 6 hours agorootparentprevI’m not sure what you mean about the UI, but I pay for YouTube Premium exclusively so I don’t have to see ads, and for that purpose alone, to me it’s worth it. reply tahoeskibum 5 hours agorootparentAlso useful to be able to download videos for offline viewing, e.g., on a plane or when internet is spotty. reply yyyfb 4 hours agorootparentAlso for background playback on mobile reply Physkal 4 hours agorootparentprevWhy not just use an ad blocker? reply Jensson 4 hours agorootparentWhy not pay for a product you use instead of being a leech? It is perfectly fine if you wanna leech, but understand not everyone wanna do that. reply cnasc 3 hours agorootparentNot looking at an advertisement is not “being a leech.” I glance away from billboards, I refill my drink during commercial breaks, I show up when the movie starts instead of when the preview starts. These are normal behaviors, not leech behaviors. The ads are not very sophisticated, so I don’t need sophisticated measures to avoid them. On the web, the ads have ratcheted up the intensity (tracking, targeting) with technology and in response I have augmented my ability to ignore with technology. That’s fair. You have framed this as a contrast between leeches and normal people, but this is actually a contrast between normal people and bootlickers. It is perfectly fine if you want to guzzle Kiwi Black, but understand not everyone wants to do that. reply fragmede 2 minutes agorootparentThat's a false dichotomy. Rationalize not paying for content with whatever logical contortions you can come up with, leeching content and not paying for it clearly isn't going to encourage the creation of additional content. Pay for it via Patreon or some other platform if you don't want to give money to Google, but the leech problem is why so many things suck. Even BitTorrent sites hate leeches. samatman 3 hours agorootparentprevReminder, or new thing for those not already aware: there was already a lawsuit about automatically skipping commercials, and the broadcaster in that lawsuit lost. https://en.wikipedia.org/wiki/Fox_Broadcasting_Co._v._Dish_N... > Additionally, Fox alleged that Dish infringed Fox's distribution right through use of PTAT copies and AutoHop. However, mentioning that all copying were conducted on the user's PTAT without \"change hands\" and that the only thing distributed from Dish to the users was the marking data, the Court denied Fox's claim. Citing Sony Corp. of America v. Universal City Studios, Inc., the Court concluded that the users' copying at home for the time shift purpose did not infringe Fox's copyright. Then, Dish's secondary liability was also denied. reply kbolino 2 hours agorootparentprevI'd rather move towards a web (largely) without ads than continue to be the product sold to advertisers rather than the consumer served by the platform. The constant escalation of the ad blocker-ad server war has also contributed greatly to ballooning complexity in all sorts of technologies. I hope YT Premium is a step in that direction, but only time will tell. reply SoftTalker 1 hour agorootparentWell you are both the customer and the product with YT Premium. Yeah you don't see ads, but they are still tracking everything you watch and using that to deliver targeted ads to you on other platforms. reply Novosell 4 hours agorootparentprevWell, YouTube premium will work on every device you can sign in to YouTube on. Adblock is available for the most part, but isn't easily available everywhere. reply browningstreet 3 hours agorootparentprevI, for one, will pay for good things.. but also, it’s worth it if you watch a lot of YouTube on things like AppleTV or Fire Cube. Ad blockers won’t work there. reply pokerface_86 1 hour agorootparentprevalso YT on a tv is difficult to set up an ad blocker for reply pokerface_86 1 hour agorootparentprevdon’t know any for YT ioS, i used to live with ads on mobile but after getting premium, even though i use an ad blocker + firefox on desktop, i never canceled it for a reason reply talldayo 2 hours agorootparentprev> and I'm even considering getting YouTube Premium Why? Serious question, too. You can sideload clients that give you every single feature of YouTube Premium for free. Unless you're expressly lazy, like being taken advantage of or enjoy watching advertisements, there's really no excuse. YouTube Premium is the \"I'm trapped in this place and you people have finally gotten me\" fee - you can circument it all together by just, not using YouTube's software. Newpipe is must-have on Android, I'm certain something similar exists for iOS. I run SmartTube on my dirt-cheap Amazon FireTV and don't get a single ad when browsing. Subtotal is $0.00 for the installation and usage of Open Source software. I use YouTube a lot, but between uBlock Origin and SponsorBlock (which I set-and-forget like 4 years ago) I don't have a single gripe with the experience. I hear people contemplate paying YouTube for a worse experience and it gives me hives. The content is on a server; you are making yourself miserable by acquiescing to a harmful client. Paying for YouTube Premium is your eternal reward for submission to the Walled Garden. reply kubectl_h 19 minutes agorootparent> I run SmartTube on my dirt-cheap Amazon FireTV and don't get a single ad when browsing. Subtotal is $0.00 for the installation and usage of Open Source software. I have YT Premium and it works perfectly on every device I have and I have never had to configure anything nor research anything to not see an ad. I only vaguely understand some of the phrases or words you are using (have no clue what a newpipe is, but kind of understand what sideloading) is. I do not care to ever fiddle with my devices, there are more important or at least gratifying things in this world then futzing around with and tweaking devices. > Paying for YouTube Premium is your eternal reward for submission to the Walled Garden. If this is the great battle you have chosen to wage with your precious, fleeting time on earth, by all means, go with God -- but a lot of people really don't give a damn about Walled Gardens. reply sulam 1 hour agorootparentprevWhy do I pick up trash off the floor that I didn’t put there? Why do I tip for good service? Why do I bother responding to posts like this? The answer is the same to all these questions: because I’d rather not live in a world where everyone is a taker. reply talldayo 1 hour agorootparentYou're not picking up trash. You're paying for trash and encouraging the ad-littering business by even acknowledging it exists. If you consider advertising bad enough to pay money to get rid of it, why would you pay that money to the business putting up ads? Because you refuse to leave their client? Because you don't want to acknowledge the scary world of choosing something better? I see a lot of people say this, where they despise YouTube and it's advertisement scheme but somehow mentally justify it to themselves that Google deserves their $10/month. Before any of you ask \"What's wrong with the world these days!?\" again, reflect on what you're paying for and how these companies sucker you into buying it. The free market can pound sand, Google has you right where they want you. reply tshaddox 1 hour agorootparentprev> Unless you're expressly lazy Yes, that’s me. I sometimes even pay other people to prepare meals and manufacture clothing for me! reply ghaff 5 hours agoparentprevTo a fairly casual observer like myself, YouTube early on looked like mostly a platform for massive video copyright infringement--especially before home video became so relatively cheap and easy. I don't use it nearly as much as some here but it definitely transformed into something much different for the most part and managed to make it work as a business (at least as part of Google). reply ethbr1 4 hours agorootparentYounger folks forget that YouTube launched (2005) a few years before both the iPhone launched and Netflix pivoted to streaming (2007). In that weird era, (a) average home Internet connections became fast enough to support streaming video (with a healthy adoption growth rate), (b) the most widely deployed home recording device was likely still the VCR (digitizing analog video from cable to burn to DVD was a pain), (c) there was no \"on demand\" anything, as most media flowed over centrally-programmed cable or broadcast subscriptions, and (d) people capturing video on mobile devices was rare (first gen iPhone couldn't) but obviously a future growth area. So early YouTube was literally unlike anything that came before -- watch a thing you want, whenever you want. reply kylec 3 hours agorootparentThat was also an era where bandwidth to serve content was extremely expensive, I still don't know how 2005 YouTube was able to find a way to make serving user-uploaded videos for free financially viable, but that was a HUGE component of their success. reply takinola 1 hour agorootparentI think the secret was being acquired by Google. Without the deep financial pockets and strategic patience of Google, I doubt they would have been able to become what they are today. reply hedora 3 hours agorootparentprevAlso, the DMCA had just passed, which basically eliminated liability for hosting copyrighted video content as long as the infringement was laundered through a service provider. I honestly don’t think YouTube would exist without that particular piece of regulatory capture. Contrast the video and podcast ecosystems. Podcasts are arguably much healthier (the publishers maintain creative control), and are certainly decentralized. reply ghaff 3 hours agorootparentprevSelf-hosting video at scale is still pretty expensive although using CDN can reduce it. reply treyd 4 hours agorootparentprevThe slogan \"Broadcast Yourself\" was really inspiring at the time, because it actually was kinda hard to do that at scale in video. reply lawgimenez 4 hours agorootparentprevWow I just realized how old YouTube is. My video on YouTube was uploaded on 2006 and it is still there. I remember uploading it from my Sony handcam, then editing it in Sony Vegas and exporting it to make sure it hits the required YT file upload limit. reply ghaff 4 hours agorootparentprevAnd Cisco didn't acquire Flip until 2009. Really most of the content that YouTube had available was material recorded off of broadcast/cable which was mostly not available otherwise unless you had recorded it or gotten it off a torrent. reply coffeebeqn 4 hours agorootparentprevYeah I remember watching Seinfeld and full seasons of cartoons on early YouTube. People basically just uploaded their whole pirated video collections there reply marcuskane2 4 hours agorootparentprevTo a less casual observer like myself, early YouTube looked like a bastion of protection for fair use of copyrighted material. Sadly, the copyright cartel swiftly attacked and all the regular people lost their rights. It seems like the lesson learned is that the copyright-owning corporations can't be trusted to play fairly or meet in the middle on fair use. We really need to just abolish copyright laws entirely. reply yas_hmaheshwari 1 hour agoparentprevWell said! Having used almost all video learning platforms (Oreilly, skillshare, pluralsight, Coursera etc.), I now believe that YouTube is the superset of all platforms. > Whatever is here, is found elsewhere. But what is not here, is nowhere reply georgel 11 hours agoparentprevAgreed, I have gotten insane amount of value from YouTube. reply xnx 1 hour agoparentprevThe way YouTube was caught offguard by TikTok is even more significant than than the way Google was caught offguard by ChatGPT. reply yzydserd 5 hours agoparentprev> I've probably watched tens of thousands of hours of YouTube at this point. More than 20,000 hours over at most 18 years is at least 3 hours per day on average. That’s a lot of watching. reply loloquwowndueo 5 hours agorootparentThe average person spends 5 hours/day on their phone and it’s likely most of it is passive watching (YouTube, TikTok, etc). So 3 hours/day doesn’t sound like too much. reply swalsh 6 hours agoparentprevI think googles peering agreements are possibly the only reason YouTube is viable as a free service. Hard to compete against a company who basically doesn't have to pay for bandwidth. reply newshackr 6 hours agorootparentGoogle also invests many billions of dollars to build their internet network and parts of the public Internet so it is hardly free reply bushbaba 4 hours agorootparentEh close to free. This is the Google edge nodes in ISPs. But Google isn’t the only one with such an arrangement. Akamai, Netflix and a few others have same cost structure for in isp nodes. reply gloryjulio 9 hours agoparentprevYouTube is how I got the education I needed to get into the tech industry. reply lasc4r 2 hours agoparentprevMy dad uses it to get fascist/right-wing propaganda for about 4 hours every night. All nicely monetized for any grifter willing to debase themselves for a potential fortune. Truly novel, but not well thought through or done with any care at all besides profits which is par for the course in silicon valley. reply vsuperpower2021 8 minutes agorootparentTech companies should spend more time banning people from talking about things I would personally prefer they didn't. reply tourmalinetaco 2 hours agorootparentprevYour idea of fascism must be rather tame, considering YouTube’s active censorship of anything even slightly right-of-center. reply lasc4r 1 hour agorootparentIt hardly needs to be violently racist or whatever conception you have in your mind to be fascist propaganda. Rather the opposite if you take a minute to consider what makes for effective propaganda. reply cityofdelusion 1 hour agorootparentThe word fascism needs to stop being tossed around so carelessly. Words ought to be precise and meaningful. reply AmericanChopper 7 hours agoparentprev> It's also not a business that rested on it's laurels. I would say it’s more a business that rests on its monopolization of the market. As a product there’s plenty I like about YouTube, but it dominated the market through the use of many highly anti-competitive strategies, and has what many would consider (and what may well be proven to be) an illegal monopoly. You can’t deny its impact, but to give such high praise to the management seems rather misguided to me. reply edanm 6 hours agorootparentIn what way is YouTube an illegal monopoly? reply AmericanChopper 6 hours agorootparentAlphabet has engaged in many anti-competitive business practices to promote YouTube's monopoly. To name a few, Alphabet is currently being sued by the DoJ for illegally monopolising digital advertising technology. That technology, which directly integrates with youtube (and which you or I could not integrate with our own competing youtube-like product), is one of the key reasons that youtube has become as successful as it is. https://www.justice.gov/opa/pr/justice-department-sues-googl... They have also recently lost a lawsuit regarding the legality of their search monopoly, which likely also contributed to the success of youtube. https://www.theverge.com/2024/8/5/24155520/judge-rules-on-us... The way they leverage the OHA to ensure YouTube is shipped with every Android phone is also highly anti-competitive, and isn't too different from the IE case against Microsoft. https://arstechnica.com/gadgets/2018/07/googles-iron-grip-on... The same concern exists in the smart TV market. While it's not illegal (as far as I know), the practice of burning through billions of dollars until your competitors are gone and you have an unassailable market dominance is also certainly anti-competitive, and that really has been one of the other key ingredients in youtube's success. None of these are management practices that I would consider worthy of congratulating. reply tourmalinetaco 2 hours agorootparentThe irony is that despite all of this monopolization and lying to advertisers about the reach of their ads YouTube is still not profitable. reply AmericanChopper 1 hour agorootparentAlphabet don’t publish YouTube’s profit margins, so I don’t think you know that to be a fact. I’d personally be rather surprised if it wasn’t profitable though. reply supertrope 5 hours agorootparentprevLeveraging YouTube's market share to hobble Windows Phone. https://www.pcmag.com/news/google-orders-microsoft-to-remove... Carriage dispute with Roku. https://www.cnbc.com/2021/12/08/roku-reaches-agreement-with-... reply zht 7 hours agoparentprevI hope that when I die no one spends so much focus on the business aspects of what I built or the valuations reply sramam 7 hours agorootparentDoesn't that depend on what context a person knew you at - personal or professional? The personal side typically will center on emotional aspects of being human. However what you do with your intellect is also a major part of being human. And that part is most often expressed only in our professional lives. Celebrating a job well done and an outsized impact is a good thing - and if I may, the most \"human\" of things to do? RIP. reply katzinsky 7 hours agorootparentprevHN is essentially a business development forum so it makes sense that's what people here would focus on. reply Blot2882 3 hours agorootparentIt's also a science forum and a tech forum. reply layer8 7 hours agorootparentprevLuckily, you will never know, so I wouldn’t place much weight on it. reply TMWNN 9 hours agoparentprev>Opinions about YouTube may be mixed here on HN Who? Who has a negative opinion about YouTube? The occasional \"My kids watch too much of it\" != \"mixed opinions\" about the site in general. reply pavlov 8 hours agorootparentYouTube’s algorithm feeds increasingly radicalizing content to young people. It makes celebrities of people like Andrew Tate and is a primary enabler of fringe belief bubbles. Any time someone posts a YouTube link to a political discussion, it’s guaranteed to be the worst nonsense that pries on people who “do their own research.” (No matter if they’re left or right on the political spectrum, there’s endless junk on YouTube for both.) There’s surely good stuff on YouTube, but as a parent I honestly wouldn’t miss it if it disappeared overnight. reply kbolino 2 hours agorootparentAs targeted towards young people, YouTube's algorithm serves up a lot more Mr. Beast than Andrew Tate. reply lotsofpulp 7 hours agorootparentprevThat is not an “algorithm” unique to YouTube. See 24/7 news channels for a much earlier example. It is simply the nature of loosening standards on broadly available media, and throughout history, even strict standards have not always prevented the “bad” stuff from getting through. reply pavlov 7 hours agorootparentNews channels don’t show random 30-minute programs created by viewers themselves. YouTube does. Fox News and CNN may have low journalistic standards, but at least they have some. They also have liability. (Fox paid $787 million to a voting equipment manufacturer as settlement for lies they published in relation to the 2020 election.) YouTube has neither. Their algorithm will happily promote any nonsense that has traction. The lies that cost Fox $787 million continue to circulate on YouTube unabated — and an untold number of other lies too. Alphabet has no reason to prevent this. reply CamperBob2 3 hours agorootparentHow do you fix this without doing something even worse? reply ethbr1 4 hours agorootparentprevThe greatest sin of YouTube's current recommendation algorithm is its optimization for eyeball time (aka more ad capacity). Any tweaks around the edges will never be able to compete with that. And unfortunately that central tenet incentivizes creators to make clickbait content that plays on emotions, because that's the most reliable way to deliver what YouTube wants. (YouTube could decide it was optimizing for something else, but that would put a big dent in ad revenue) reply jart 6 hours agorootparentprev> It makes celebrities of people like Andrew Tate By banning Indian school children and sucking the oxygen out of competing influences like Pewdiepie. reply smcin 5 hours agorootparentWho's banning Indian school children? reply xanderlewis 9 hours agorootparentprevA lot of YouTubers have been very critical of YouTube’s approach to things and treatment of creators in the past. Also, just as an example, YouTube demonetises (and therefore effectively punishes) you for using words like ‘suicide’ so now we have to say silly things like ‘unalive’ — at least until Google/the advertisers catch on. These days YouTube is more censored than traditional TV. reply Aunche 5 hours agorootparentYouTube doesn't print money out of thin air. They make money by making advertisers happy, and advertisers will only buy ads if their customers are happy. This isn't anything new either. Creatives have always been beholden to censorship boards in traditional media too, which are typically much stricter. The fact that you so many YouTubers make money from criticizing YouTube is evidence of how much YouTubers don't understand their own privilege. reply specialist 4 hours agorootparentAre their advertisers happy? reply Jensson 4 hours agorootparentThey continue to pay for ads, so yeah for now. That is the kind of \"happiness\" companies care about. reply mewpmewp2 3 hours agorootparentprevDemonetisation is not the same as censoring though. reply sunaookami 1 hour agorootparenthttps://en.wikipedia.org/wiki/Chilling_effect reply throw0101d 5 hours agorootparentprev> These days YouTube is more censored than traditional TV. This is evident in (e.g.) WW2 documentaries where an old 4:3 television broadcast is simply put online, and the original footage had perhaps footage of corpses but on Youtube it is blurred. reply TMWNN 9 hours agorootparentprevI think the \"unalive\" nonsense is idiotic too, especially when it increasingly bleeds into elsewhere online (and probably offline, too). But that's not the same thing as \"mixed opinions\" in general on HN. That would be more accurate of, say, Twitter (where we are nearing two years and counting of the imminent collapse of the site any day now post-Musk acquisition, as opposed to seemingly every news event proving that it is more important than ever). reply xanderlewis 8 hours agorootparentI think perhaps what there are ‘mixed opinions’ on is the actual management and day-to-day practice of YouTube as a company, rather than the site itself. We’re all very, very grateful to have such an amazing place to learn and be entertained. And, in my opinion, the website and apps are very nicely designed and work better than anything else. I do wish the TikTokification would stop, though. But that’s never going to happen, given how effective it is at holding our eyeballs hostage. reply kortilla 3 hours agorootparentprevHow are you still digging in here? There are very clearly mixed opinions in these threads about youtube. reply ChrisNorstrom 7 hours agorootparentprevWhich is interesting because the news and media and movies and music videos can be as \"advertiser unfriendly\" as they want and still get ads to support the corporation that produces it. But indie content creators and the general public are punished for talking about the same topics. Corporations get freedom of speech, freedom of reach, no consequences. The people do not. To the HN crowd, sorry but I'm not going to hold back. Death does not turn you into a saint. Susan is the one who turned YouTube into the censored mess it is today, pushed for unliked mainstream channels over popular organic content creators (changed the algorith to push late night talk shows), ruined the algorith to always push \"authoritarian\" channels (CNN, CBS, MSN, NBC, PBS, etc), gave creators the option to disable the dislike button, permanently banned thousands of channels that even mentioned \"pedophilia\" like Mouthy Buddha's channel during the Q-anon nonsense. Creators at the time made 30 minute long videos analyzing data and proving that the recommended mainstream channels being pushed were inorganic. She helped ruin YouTube. I will not apologize. Bye Susan. Come back in your next life and help fix it. Downvote away. I do not care. reply mihular 9 hours agorootparentprevMy complaint is that there isn't a family subscription option in my country. Also without Music. It's either personal with Music or damn annoying commercials. Another complaint would be non transparent and sometimes wrong censorship. reply cheeseomlit 6 hours agorootparentprevI like a lot of content hosted on YouTube but that doesn't mean I like YouTube, especially under Google. reply CPLX 8 hours agorootparentprevThe fact that it’s a linchpin component of an illegal monopoly is one good reason. reply briandear 8 hours agorootparentprevGovernment-coordinated censorship during Covid. That’s my negative opinion. Covid vax concerns were allowed during the last months of the Trump administration, but it suddenly became censored after Biden was elected. reply pavlov 8 hours agorootparentThe timeline of the election coincides with the development of the vaccines. Moderna reported positive phase 3 trial results in November 2020. FDA’s review was completed in December and an emergency authorization was granted. The full trial results were published in medical journals a few months later, around the same time as Biden entered office. So maybe it had nothing to do with Trump/Biden and simply was a reaction by YouTube to the proven efficacy of the new vaccines. reply philwelch 2 hours agorootparentThat’s not a coincidence—they deliberately delayed reporting the trial results until after the election because they were worried that good news would help Trump. reply pavlov 2 hours agorootparentHaven’t heard this conspiracy theory before. So which is it: 1) The mRNA vaccine was rushed out without sufficient clinical trials; 2) The results from the clinical trials were delayed to hurt Trump. You can’t have both you know. So far the far-right argument has been entirely based on scenario 1, but it’s certainly interesting to know that scenario 2 also exists for some people. reply philwelch 1 hour agorootparentHere’s reporting from MIT Technology Review, a bastion of far-right conspiracy theories: https://www.technologyreview.com/2020/10/19/1010646/campaign... Operation Warp Speed was a signature effort of the Trump administration. As a result, the claim that the vaccine was being “rushed out without sufficient clinical trials” was made by just about all of Trump’s critics. reply pavlov 1 hour agorootparentNine months from formulating the vaccine to a successful Phase 3 trial is record speed. There’s no way the vaccine was held up to somehow politically hurt the president. I’m a Trump critic and I was happy with the priority given to Operation Warp Speed. It’s the only thing he did right during the pandemic. But a lot of the MAGA crowd are anti-vaxxers, so he’s been trying to distance himself from the successful vaccine operation. reply Nemrod67 7 hours agorootparentprevnext [5 more] [flagged] pavlov 7 hours agorootparentWhat’s your specific beef with Moderna’s three-phase clinical trials? The New England Journal of Medicine in February 2021 published Moderna’s results indicating 94% efficacy. Further studies confirmed it. If you know better than the reviewers at a leading medical journal, it would be interesting to know why you’re so qualified. reply stufffer 6 hours agorootparent>Moderna’s results indicating 94% efficacy Yet strangely every person I know vaccinated or not still got COVID. YouTube banned people for even simple observation like this. reply mynameisvlad 2 hours agorootparentEvery person you know. Anecdotes are worthless in a scientific setting, or literally any setting with the slightest amount of rigor. More often than not, we do not have anywhere near a representative sample in the people we know or hang around. reply pavlov 2 hours agorootparentI got the Moderna vaccine in May 2021 and a booster in December that year. The first time I got Covid was a year later, December 2022. Exactly as predicted by the vaccinations. I don’t go around pretending that this anecdote is worth anything. That’s why companies like Moderna do clinical trials with 30,000 people. Somehow lots of people whose experiences are slightly outside the median are convinced that everything is a lie. “Statistics are hard, let’s go shopping?” reply sytelus 6 hours agoparentprevYouTube is absolutely the business that is resting on laurels, just like Google Maps and Gmail. Sometime I wonder if these products have any real active development teams at all besides ads. YouTube massively screwed with users by forcing poorly executed botched migration to YouTube Music. Even outsiders can see that this was entirely internal Google politics which powerful people like Wojcicki should have been able to avoid but she didn't. It just makes me wonder if these billionaire leaders of Google products really care anymore about anything. There is visibly an utter lack of hunger at the top and these people clearly should have been spending more time with family leaving these products with more hungry minds. YouTube recommendations are crap and it's still amazing that in 2024 just clicking one video will fill up most of recommendations with same thing. It never got around to incentivize creators to produce concise content and to this day creators keep producing massive 30 min diatribe that could have been done in 3 mins. TikTok took full advantage of this but YouTube CEO just kept napping at the wheel. Ultimately, the original product mostly just kept going but the measure of success is not about retaining audience but what it could have been if there was an ambitious visionary leader at the helm. reply tsimionescu 6 hours agorootparent> It never got around to incentivize creators to produce concise content and to this day creators keep producing massive 30 min diatribe that could have been done in 3 mins. Why on Earth would you want shorter videos? The best thing about YouTube is that it's one of the only places you can find quality medium-to-long-form content. reply Blot2882 3 hours agorootparentMaybe not what the commenter was saying, but there is a difference between great multi-hour essays and pointless rants stretching out their length to meet a minimum ad requirement. I like watching a lot of multi hour videos, but you can tell the difference between one with substance and one repeating the same thing over and over so they can \"clock out.\" That's all due to changes by YouTube to reward length and frequency, which of course makes sense for maximizing their ad revenue. But the result is creators are incentivized to pump out 20-minute fluff videos, not well edited/written videos. People on here complain about SEO sites being filled with meaningless garbage. That's what YouTube is starting to be. The difference is their search bar still works whereas Google's will only give you the garbage. Though I still get \"such and such breaks down their career\" even though I've never clicked on that. reply tsimionescu 1 hour agorootparentI agree that there are a lot of inflated videos to hit some ad target. But the solution is not to encourage people to create short videos, or at the very least, not the way TikTok did, making it almost impossible to popularize anything longer than 3 minutes. And despite all the dredge, there is a lot of good content on YouTube, at least in certain niches. Video essays on media and politics, lots of video-game analysis and other fan communities, history content, lots of e-sports to name just a handful that I personally enjoy. reply SoftTalker 1 hour agorootparentprevYouTube videos were originally limited to 5 or 10 minutes I think. And probably 480p or so. You have to remember when it started, video on mobile didn't exist and there was absolutely no bandwidth for it. So people watching YouTube were watching it on their PC, probably with a 1024x768 CRT screen, and that's assuming they had something faster than dial-up internet. reply tsimionescu 1 hour agorootparentOh, I do remember, I was around in the early days. I think (but maybe that came later?) longer form videos did exist, but only paying accounts could post them. reply sytelus 6 hours agorootparentprevWhy on earth you want 10X longer video with same information content as the shorter video? reply tsimionescu 3 hours agorootparentI find it a small price to pay if a few videos are too long (you can usually tell within three minutes anyway), to have a platform that generally encourages 30 minute videos and even 3 hour videos that do have content. There's almost no meaningful 3 minute content possible, so a platform like TikTok that only works for short videos is basically condemned to be meaning-less, to be pure entertainment. reply polotics 6 hours agorootparentprevClearly the add-supported side, that likes to pad and pad and show more adds, is working against the premium/fee-supported side, that wants to maximise value and engagement. Premium subscribers should be able to give feedback on a video's density IMHO... reply HPsquared 5 hours agorootparentLength is shown in the thumbnail. Too long, no click, less views. I also wouldn't be surprised if the recommendation algo uses premium status as an input reply rajup 5 hours agorootparentprevWhy on earth would you watch a 1.5 hour movie when you can watch a 2 min TikTok that explains the entire story? In a world full of distractions I for one love the more slow-paced videos than “shorts” churned out by content mills designed to feed the modern day digital ADHD… reply johnisgood 2 hours agorootparent10 minutes of a shitty movie is too long, but one great movie might be not enough and I want a TV series out of it! reply nextlevelwizard 2 hours agorootparentprevFew years ago “long burn” story telling was hot and we are still feeling the effects. Take any show on Netflix and it will be 8 45min episodes from which first 3 are absolutely garbage filler. Youtube learned the wrong lesson and started to optimize the algorithm for retention and length. It is annoying to click for a review of some product that looks like a lengthy one with probably tests and what not only to see painfully slow unboxing and a wikipedia read of the history of the product and company and then sponsor read and then they turn on the device for a minute and give arbitrary score. Exact same info could have been communicated in 30seconds, but then they wouldn’t get sponsor money and mid video ad roll reply yyyfb 12 hours agoprevNext time you're thinking \"I wish I was the one who had made a billion dollars with my startup idea\", remember that only health and family matter, and to have fun while you're alive. RIP. Edit: some people misinterpreted my comment. I'm just one anonymous voice on the Internet, but am deeply saddened by the passing of Susan Wojcicki, who meant a lot to me as one of the many people who crossed paths with her professionally. I wish her family strength in a very trying moment. She did not deserve this. I've not met another business leader demonstrate everyday kindness to the degree that she did. Her untimely passing is also a reminder to those of us who sometimes look up to such successful businesspeople that we should all appreciate our luck to be alive and enjoy it to the fullest, as I hope that she did as well, and as I'm sure that she'd prefer we did. RIP reply santiagobasulto 11 hours agoparentThis has nothing to do with business or entrepreneurship. It's cancer, it's a bitch. It can take a 10 year old boy, or an elite athlete. reply jszymborski 4 hours agorootparentI took that to be OPs point in a way. Death comes to us all, rich and poor. True wealth is your good health and the relationships it lets you foster. reply toomuchtodo 3 hours agorootparentAbsolutely this. reply troll_v_bridge 10 hours agorootparentprevYou can’t really say it does or doesn’t. Research shows stress can be a contributor though. https://med.stanford.edu/survivingcancer/cancer-and-stress/s.... reply cpncrunch 8 hours agorootparentMain factors are sleep, sunlight, diet and exercise as well as stress. You can see her schedule here: https://press.farm/susan-wojcickis-daily-routine-youtubes-ce... Sleep about 6hr, which isnt ideal. Not much chance to get sunlight which significantly reduces cancer incidence. Not much relaxing time. The question becomes, is the work worth it? reply A_D_E_P_T 8 hours agorootparentThat's probably not her real schedule. It looks like clickbait and was probably invented by the author. (Who might be our prolific friend Chat-GPT.) Besides 10:00pm to 5:30am is 7.5 hours, which is either optimal or (arguably) too much. Lastly, there's no clear evidence tying sleep duration to cancer incidence. See, e.g.: https://bmccancer.biomedcentral.com/articles/10.1186/s12885-... reply cpncrunch 4 hours agorootparentShe starts exercising at 530 and goes to bed at 10. Im assuming she wakes up 30 mins before, and it takes her an hour to get to sleep. reply svnt 4 hours agorootparentThey weren’t arguing the specific times, but the article itself reads as if AI generated and not as a real report of someone’s schedule, by someone who would know that person’s schedule. The follow-on conclusion from that is that the times are highly suspect. reply cpncrunch 3 hours agorootparentYes, i think youre correct. I cant find an original source. reply turtlesdown11 3 hours agorootparentprevarguably too much sleep? what world are you living in that seven and a half hours of sleep is too much? reply mewpmewp2 3 hours agorootparentprevYeah, that article definitely looks like ChatGPT imagination. reply melling 6 hours agorootparentprevWhere’s your scientific report that says sunlight significantly reduces lung cancer? We shouldn’t have people making such claims on HN without providing references. She was also home having dinner with her family by 6:30pm. reply cpncrunch 4 hours agorootparenthttps://onlinelibrary.wiley.com/doi/10.1111/joim.12251 reply melling 3 hours agorootparentThis seems key: “ Following sun exposure advice that is very restrictive in countries with low solar intensity might in fact be harmful to women's health.” Thanks for the link. Now we know with certainty that lack of sunlight wasn’t a cause. reply FireBy2024 6 hours agorootparentprevFunny that watching YouTube was not one of the things she did, whereas most people spend hours on YouTube/social media. reply Mistletoe 4 hours agorootparentprevI’ve tried to google with no success but is it known if she smoked or ever did? Or is she part of the unlucky cohort (~12.5%) of non-smokers that get lung cancer? reply amelius 8 hours agorootparentprevBeing on the wrong side of the wealth-gap can also induce stress ... reply roenxi 9 hours agorootparentprevWell, yeah. For the sort of people who have \"Title: CEO\" on their Wikipedia page I suspect we're overdrawing from the pool of people where mission implicitly matters a little more than taking it easy. One way or the other you're going to die, but if your response to that is to relax and try to eke out a few years by keeping your stress down then CEOing is probably not for you. reply cpncrunch 8 hours agorootparentYou can change it if you want to. An extra 25 years seems worth it to me. reply magic_man 4 hours agorootparentprevBut it is more likely when you are old. It is you your immune system unable to kill mutations. reply chr1 8 hours agoparentprevHealth is only temporary, and everyone in your family is going to die, until someone makes a trillion dollar startup to cure aging. So it is fundamentally wrong to put health, family, and work as things opposing each other, ultimately they are all needed on a way to get all of the galaxy filled with life. And as Susan have shown one can both do great work, and have a big family with 5 children. reply RobertDeNiro 7 hours agorootparentHigh levels of stress (often related to work) have been shown to impact health. So I think it’s a fair thing to oppose them. reply boringg 6 hours agorootparentIsn't that person and stress source dependent. Also working until late in life actually improves mental acuity and fights off dementia. So maybe work but not in excessively high stress loads is your point? Though i think your implied underlying assumption that because she was a leader in tech and under a high workload somehow caused this is unfounded and unnecessary. reply anon7725 3 hours agorootparentThere must be a difference between the stress experienced by a financially independent CEO and a marginally-employed gig worker. One is the stress of essentially playing a game or working on a challenge and the other is existential. reply gunapologist99 52 minutes agorootparentThis sample size of one would seem to disagree. Stress is stress, and the outcome can certainly be the same in the end. RIP reply melling 5 hours agorootparentprevCure aging? We could relieve a lot of pain in the world by just curing cancer(s), or at least make them treatable like HIV. Jake died yesterday. I don’t even think he was 40 years old. https://news.ycombinator.com/item?id=41201555 Susan was only 56. Let’s at least give everyone a chance at a full life. reply mewpmewp2 3 hours agorootparentYeah, but magnitude wise it doesn't seem like a huge difference of 56 vs 90. 56 to me now looks way early, but I assume when I get 70 then I start to think that 90 looks way too early. When I was 10 years old, 56 seemed miles away though. So there's always going to be this problem. Especially since supposedly the older you get the faster time seems to go. So the fact that I and we are all going to die at some point not too far away is still something that is constantly in the back of the mind and frequently on the front. E.g. compared to being able to live more than 1,000 years or forever and with body in its prime condition recovery etc wise. E.g. having a 25 year old body for 1,000+ years. reply melling 2 hours agorootparentSure, I’m all for living to 1000. Curing cancer(s) likely needs to happen first. The war on cancer started in 1971. We’d likely need trillions of dollars of investment, and a lot more people working on it, to increase our lifespan/healthspan. But hey, we can hope together, for what that’s worth. reply yyyfb 5 hours agorootparentprevIt's not about them opposing each other, it's about priorities. reply badpun 7 hours agorootparentprevWhy it's a good idea to fill galaxy with life? Why should we care about it? Also, seeing that our current civilization-system is already at the brink of catastrophe, we should focus on less ambitious goals, such as preserving life on Earth. reply boringg 5 hours agorootparentAbsolutely worth it. We wont fill the galaxy filled with life because the galaxy is huge and we are but one tiny tiny portion of it. For us to survive and do anything impressive takes all of human ingenuity. Also those two items aren't mutually exclusive. Both can and should happen in tandem. Anyone arguing otherwise is just a mentally lazy person. reply theGnuMe 5 hours agorootparentprevLiving in poverty and Being broke is stressful too. Living in a shit family as well. reply coffeebeqn 4 hours agorootparentYes the upside of being rich and stressed is that it’s all your choice. You could retire at any moment if you wished to reply Cookingboy 11 hours agoparentprevAs far as net worth figure goes your health is the first significant digit, everything else come after. reply ithkuil 11 hours agorootparent> first significant digit Big endian reply wslh 5 hours agoparentprevYour message is very powerful, for the good, and I think people nowadays are used to extremes instead of the balance when they read something like your comment. reply noncoml 10 hours agoparentprevThat’s BS. Yes, both rich and poor die of cancer. But being rich or even just comfortable gives you a completely different experience during the end of life. You can afford to quit your job and be with your friends and family. You can afford to see that best doctors that will ensure you have as comfortable as possible end of life. Your kids can afford to take a sabbatical to come spend time with you. You can be sure that no matter what your kids will be financially secure. You know that you got the absolute best care that you could. The list goes on. Cancer is horrible and everyone who loses someone hurts the same. But you absolutely cannot keep saying that being poor and rich doesn’t make a difference during the progress of this awful disease. Only someone who has never been poor would ever say that. reply jart 10 hours agorootparentIf you're poor you won't even officially have cancer, because no one will diagnose you, since then you'd be entitled to services. Someone who's actually been poor would understand this. reply p3rls 3 hours agorootparentEh, I made 75k on my IRS forms last year and don't have health insurance. The poor people I know all have way better access to treatment through medicare/medicaid and various subsidies, and all use the medical system multiple times a year while I look up videos on YouTube (thanks susan!) to learn how to perform minor surgeries on myself When my mother died of cancer (also in her 50s, still working as a public teacher in NYC so should have had great insurance for this) the hospital went after the estate with a million dollar bill. I couldn't even afford a lawyer to contest it at the time and ended up not inheriting anything except what I could take out of the house. The only people with good outcomes are the rich who can afford it, and the poor who couldn't afford anything yet are still being treated because other tax payers are paying into this system. reply somenameforme 10 hours agorootparentprevLots (if not all?) of hospitals offer free care options for patients in poverty. I grew up poor and had a family member who was able to be diagnosed, for free, a university clinic that offered free care, and then was able to receive free care through a program offered at one of top 5 ranked cancer systems in the US. Although the premium quality wasn't even that big of a deal. The overwhelming majority of care can be provided pretty much anywhere. It's not like a premium hospital offers super chemo or super radiation. The treatment is what it is, and all the money in the world isn't going to significantly change your odds of survival relative to basic treatment provided at any clinic anywhere. The US healthcare system is broken beyond belief, and I do think there is some degree of managerial sociopathy around profit (particularly in the pharmaceutical and insurance wings), but by and large there still remain options for people even if they may be arduous, and I do think that hospitals and doctors are still significantly motivated just to provide good care. reply armada651 9 hours agorootparentThe problem is that, for patients in poverty, the chance that cancer will be detected early enough for treatment is much, much lower. Cancer is often detected during check-ups for vague symptoms that most people can't afford to go visit a doctor for. By the time the symptoms become alarming or even debilitating it is often already too late. reply yyyfb 9 hours agorootparentprevTwo things can be true. Money does buy comfort and care. Also, it does not make one immortal. We can choose what we take away from events. I could choose to feel unlucky that I haven't made as much money as someone else, and I would be justified in it, because being rich absolutely makes a difference. I just choose to feel lucky to be alive instead, and I'm just as justified. You are free to choose your own perspective. reply noncoml 8 hours agorootparent“remember that only health and family matter” Those were your exact words. But nice backpedal. Edit: I don’t want to get into an argument but just beware that your original post rubs a lot of people the wrong way. I respect that’s the pain and sorrow of a loss are the same but please don’t dismiss the power and need of money. It makes a world of a difference in the process of dying. You don’t want to sound like someone living on an ivory tower. reply yyyfb 1 hour agorootparentLet me put it this way. I don't think you and I are fundamentally disagreeing: money matters, to the extent that it allows to buy statistically better health outcomes and quality time with family. I don't personally think it matters more than that. reply vsuperpower2021 8 hours agorootparentprevIn general if you want people to take you seriously, don't make statements like \"Two things can be true.\" It reeks of reddit condescension where they can't make a simple statement without implying the other party is stupid enough to think that only one thing can ever be true at once. reply mynameisvlad 2 hours agorootparentI mean, considering that people harped on about one specific thing being more true than the other, it certainly seems like people think that only one thing (being rich) can ever be true at once. Stupidity is entirely your implication, but people generally like to see things in binary. It’s far easier than acknowledging that most things live on a spectrum. reply sebzim4500 7 hours agorootparentprevFor what it's worth, I thought his comment was fine whereas yours is insufferable. reply vsuperpower2021 5 minutes agorootparentIt's not worth much! asah 11 hours agoparentprevnext [3 more] [flagged] topkai22 11 hours agorootparentI think you are interpreting the comment rather ungenerously. This sounds far more like finding common humanity with the deceased then somehow correlating cancer to wealth. reply vsuperpower2021 11 hours agorootparentprevWhat's with all the pearl clutching today? If you want to act morally outraged, at least find something even mildly offensive to respond to. reply geodel 12 hours agoparentprevnext [3 more] [flagged] presentation 11 hours agorootparentSo this comment applies to people who are at least somewhat affluent and career-ambitious. Perhaps this person does not need to be addressing everybody on the planet to be making a valid statement. reply thrownawaysz 11 hours agorootparentprevBoth this and the other posts are full of rich people apologists, “remember billionaires are humans too!”. So out of touch when billions live in poverty but imagine telling them, “remember have fun money doesn’t matter” when they can’t even have basic clean water or clothes reply dyauspitr 2 hours agoparentprevSusan didn’t start YouTube. reply paxys 5 hours agoprevPeople of course associate her with YouTube, but Susan Wojcicki has had an overall fascinating career. Page and Brin started Google in her garage. She was employee #16 at the company. She was behind the Google logo, Google Doodles, Image Search, AdSense, then all of advertising, and ultimately YouTube. Safe to say Google would not be where it is today without her role. RIP. reply igetspam 4 hours agoparentI personally wouldn't be where I am without her. Google wasn't my first job but it was the first one that mattered and I was there pretty early (2004). The founding team set Google up for success. The tech was obviously key but you can still ruin good tech by running a bad business. She earned her success, multiple times and I have a deep appreciation for what she did and what she was part of. It's a sad day, for sure. reply cmrdporcupine 4 hours agoparentprevYeah it's interesting to see the press and others really pushing on the YouTube thing when it is AdSense that made Google what it was and is still today. An advertising revenue money machine. And it was in many ways her baby. reply strikelaserclaw 3 hours agoparentprevI always wonder how many people could have replicated similar successes if put in similar positions and i always feel like it is a lot. Like i can't imagine you taking someone from the same time period as newton or einstein and replacing them and seeing similar success but in a rich environment surrounded with bright people like early google, i feel like just being early to google is enough to guarantee that you'll have some good ideas. Using advertising to make money has always existed that is what tv channels and magazines did for a long time before the internet, i'm sure google would have been just as successful without google doodles or put another way - google's success allowed it to be whacky and not vice versa. reply daveed 12 hours agoprevI'm not a Googler, but would still ask commenters to show some respect for the person who died, and save your opinions about youtube for another day. reply tomohelix 11 hours agoparentMaybe I am a callous person, but I have never agreed to this \"don't speak ill of the dead\" thing. People live and die. It is inevitable. To the grieving family, I can understand why refraining from insulting the dearly departed is necessary. They are grieving and can be irrational. No need to make things worse for them. But between unrelated people? Why can't I discuss the legacy of the dead? We are defined by our deeds in life. It is only natural that in death, people will talk and opine about what we have done. Nothing wrong with it. reply DannyBee 4 minutes agorootparent\"We are defined by our deeds in life\" We are but most folks here basically know nothing of her deeds, or really anything about her. They see one piece of a thing she was a face of for some time period, and that they also knew mostly nothing about, but appear to love to have strong opinions on! If you want to speak of her deeds then go and learn about them. Otherwise, people aren't speaking of anything other than some small myopic view of a human being they knew nothing about. Folks don't get to say that she is defined by the small piece of stuff they saw, just because they want to have an opinion on it. Besides being disrespectful, it's not even interesting, and it says more about the people doing it than the person they are talking about. reply cowsup 8 hours agorootparentprevI feel like there's an unwritten \"recently\" in there. If you were to speak ill of Colonel Sanders, nobody would berate you for speaking ill of the dead. But when a CEO like Wojcicki, who made changes that were unpopular to the end-users (but helped turn YouTube into an actual profitable company) dies, it's considered very impolite to use that opportunity to bad-mouth decisions she made. When her son died earlier this year, that would've been a bad time to speak ill of her, as well, even though she herself was still alive. A better phrase may be \"Don't say things that will hurt the feelings of those who are grieving,\" but that doesn't roll off the tongue so easily. reply zarzavat 3 hours agorootparentShe was a public figure. If millions of people around the world know your name then when you die, people will have things to say. Some will be good, some will be bad. The custom about “not speaking ill of the dead” makes sense in a small IRL community, not for internationally famous people. reply meiraleal 7 hours agorootparentprev> \"Don't say things that will hurt the feelings of those who are grieving\" I for one would prefer \"don't get attached to evil people\" reply nozzlegear 4 hours agorootparentFew people are comically evil enough that you can look at them and say \"Ah, yes. You are evil. I will not get attached.\" reply meiraleal 3 hours agorootparentYep. Feathers of the same birds flock together so one is just a little bit worse than the other and nobody feels ashamed. reply sigmar 5 hours agorootparentprev>But between unrelated people? Why can't I discuss the legacy of the dead? We are defined by our deeds in life. It is only natural that in death, people will talk and opine about what we have done. Nothing wrong with it. unless you have a magical way to make your comment here invisible to her family and friends, posting it to the internet is not keeping the comment exclusively \"between unrelated people.\" Many of those replies to Pichai are vile. reply dotnet00 2 hours agorootparentThere's an implied \"reasonable chance\" in there. reply dotnet00 2 hours agorootparentprevAgreed, I don't get it either. I also wonder how many people saying this sort of thing expressed the same sentiment when someone they had a strong dislike of passed or had a close brush with death. We've had many such incidents over the recent years and at least in my anecdotal observations, people do not consistently apply this. reply somenameforme 8 hours agorootparentprevSocrates never wrote a single thing down and was, somewhat ironically, opposed to writing. The reason is that he felt that words cannot defend themselves. They can be twisted, taken out of context, and misrepresented, with none there to defend them, provide that missing context, or what not. Fortunately his student Plato disagreed so here we can discuss him 2400 years after his death. With a dead person, I think this logic holds to an even higher degree. Personally I'm not really sure whether I agree or disagree with it, but it seems pretty reasonable, especially if we don't hyperbolically immediately leap to absurdly extreme examples like Hitler or whatever. reply kubb 10 hours agoparentprevI’d take it as a time to reflect that no matter how much profit you make, people will remember you for what you’ve accomplished. Think about that when you get to your coveted position of power in the industry. reply toomuchtodo 2 hours agorootparentThose people won’t matter. Your loved ones do and will though, and they won’t measure you by your accomplishments and net worth. reply asah 11 hours agoparentprevIn particular, Susan was a lovely soul and specifically deserves all of our respect. If you want to hate, then hate the game, not the player (especially in this case). reply vintermann 9 hours agorootparentI'm sure she was, but I did not personally know her and I'm pretty sure few others here did as well. It's newsworthy for what she was, her role, not really for who she was as a person. I certainly wouldn't mind reading some personal eulogies about what a great mentor her was etc., or about how she influenced your life with her work even if you didn't know her. But I also don't mind reading critical posts about the role she played, I think that's part of the picture for someone who's famous as a business leader. If people weren't willing to speak freely about the dead, we wouldn't have had the Nobel prizes. reply somenameforme 10 hours agorootparentprevThis saying never made sense to me as a game is only a game if there are players. reply matwood 5 hours agorootparentA good example is taxes. Many people think the 'rich', including the rich, should pay more. Every tax form in the US has a spot where you are free to write in a larger amount to send, but I wonder how many actually do? Unless the game ends collectively, it doesn't make sense to stop playing. I will continue to pay as little taxes as possible until the game is changed. reply lotsofpulp 9 hours agorootparentprevThe point of the saying is that the player is not necessarily in position to change the rules, or at least not in the immediate short term. How far one wants to accept this as acceptable reasoning is a subjective matter. reply sleeplessworld 6 hours agorootparentOr maybe not that subjective when looked at closer. It may just as well be a saying that the entitled classes use to defend their selfish and less than good behaviour. Beacause the classes of the not-entitled buy this as somehow having reasonable meaning. The entitled classes have no reason to change rules that are clearly stacked in their favour. But it sounds way better to say the rules cannot be changed. But it is hard to see why this should be self-evidently true. reply wruza 1 hour agorootparentprevYou can offset basically anything with it. It's another way to say \"it's just a collection of atoms working by the laws of nature\". Most of these proverbs are just selling bs. reply nailer 6 hours agorootparentprevThe people in this thread and elsewhere online are generally arguing that she was not a lovely soul. reply briandear 8 hours agorootparentprevShe censored things because of politics. That’s not “lovely.” YouTube has videos on the dangers of GMO crops, despite the scientific consensus for their safety and utility. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8959534/#cit000... YouTube has plenty of videos about electromagnetic sensitivity about which the WHO says: “EHS has no clear diagnostic criteria and there is no scientific basis to link EHS symptoms to EMF exposure.” https://www.who.int/teams/environment-climate-change-and-hea... And more stupidity: “Eating these foods kills cancer” https://youtu.be/WGbFnp56csg?si=t54Pcr3uqjrXRx9f “12 foods that can fight and cure cancer” https://youtu.be/FdlKCpEzSAE?si=J6rtKs6valWnamBP Interview with Robert DeNiro 8 years about his concerns about vaccines and autism and his doubts about the vaccine effectiveness statistics. https://youtu.be/FJ7iPn39i08?si=mRYD3a3y9HdMPMQ8 Covid censorship was political and not from some altruistic “goodness.” And YouTube experienced very significant growth during the pandemic. So that “lovely” soul was profiting because of the lockdowns. Lockdowns that were possible due to fear and a lack of any permissible public debate — partially thanks to YouTube. Would lockdowns have ended sooner if there was more debate on the topic allowed? Definitely. What about school closures? Absolutely. But videos debating these things weren’t allowed. So no, the game and the player in this case are one and the same. I’m not going to respect anyone that supported lockdowns or supported suppressing scientific debate. Curating opinion (and facts) while pretending to not to isn’t worthy of respect. And, YouTube still allows those addictive kid videos where the narrator says “If you love your parents, like and subscribe. If you don’t love your parents, don’t like and subscribe.” reply peterfirefly 3 hours agoparentprevI associate her with censorship. Should I respect her for that? reply sneak 11 hours agoparentprevWhen is there a better time to discuss the works of a famous person than when they are in the news? reply meiraleal 7 hours agoparentprevYou know that Google has an intranet, right? The CEO of a division that extracts rent from almost every living person doesn't deserve more respect than a homeless person in SF reply surgical_fire 8 hours agoparentprevI have no dog in this game - literally no opinion on what kind of person she was. I use YouTube, even though I don't particularly like it, much like every other Google product. Not sure how much of what I dislike on YouTube is her fault or not,and it doesn't really matter anyway. It is not like I hold any hopes of YouTube becoming any better now. But I find this kind of comment curious. Someone noteworthy and controversial dies, critical comments are sure to follow. Happened when people such as Kissinger or Chomsky died. No one was saying \"show some respect to the person who died, save your opinions for another day\". It would be fairly ridiculous to say so. reply meiraleal 7 hours agorootparentDon't kill Chomsky, he is still alive reply surgical_fire 6 hours agorootparentOh lol. I thought he was dead. The point still stands reply quonn 5 hours agorootparentThe point doesn‘t stand, because you made a claim about what people supposedly said or didn’t say after Chomsky passed away. And he didn‘t even pass. reply mynameisvlad 2 hours agorootparentThis is pedantry at its finest. You can remove the name and still have a point left there. Just pretend the comment only said Kissinger, it’s really not that hard. reply meiraleal 1 hour agorootparentHonestly if you are 50% wrong about a point you are trying to make that doesn't look great. reply peterfirefly 3 hours agorootparentprevA lot of people thought he did die and they did say things about him. reply meiraleal 5 hours agorootparentprevHe is living in Brazil, but unfortunately it seems to be his ending days too. Every other week there is a fake news about his death. reply grandmczeb 13 hours agoprev> Unbelievably saddened by the loss of my dear friend @SusanWojcicki after two years of living with cancer. She is as core to the history of Google as anyone, and it’s hard to imagine the world without her. She was an incredible person, leader and friend who had a tremendous impact on the world and I’m one of countless Googlers who is better for knowing her. We will miss her dearly. Our thoughts with her family. RIP Susan. Posted by Sundar Pichai. reply akchin 12 hours agoparentThis sucks. I was at Google many years back and I remember her to be an awesome product leader. In fact even though I was another org, she was helpful and really helped me and our team. reply pas 6 hours agorootparentexcuse me for this offtopic (?) tangent, but can you please expand on what does being a good/amazing product leader mean? every kind of context helps, as I have no experience working inside these huge super-successful corps. thanks! reply richrichie 1 hour agorootparentFeel good adjectives. reply DanielleMolloy 10 hours agoprevRIP. Her son just died early this year, from a drug overdose. https://eu.usatoday.com/story/news/nation/2024/05/31/marco-t... reply sva_ 7 hours agoparent> Troper's autopsy found high concentrations of cocaine, amphetamine, alprazolam (Xanax), What a strange mix. reply s1artibartfast 5 hours agorootparentThe amphetamine is almost assuredly from the cocaine, so that just means they were doing coke and Xanax. Xanax as a party drug is just strange in general. reply coffeebeqn 3 hours agorootparentMaybe it was the end of the night? People take benzos to calm down and/or sleep. And I guess some people to just feel like zombies reply fsckboy 40 minutes agorootparentprevperhaps he took prescription xanax on the regular, and, feeling anxiety, popped some reply AbstractH24 6 hours agorootparentprevnext [7 more] [flagged] shortrounddev2 6 hours agorootparentThey weren't being funny, that is a strange mix to OD on reply AbstractH24 5 hours agorootparentBy and large overdose is a result of irrational thinking, or misguided attempts to apply logic. So it doesn’t make sense to make judgements about or apply ration to the drugs someone ODs on. Also, it doesn’t seem so weird for someone to try and mix uppers and downers. And those are all commonly abused drugs. For those reasons, I can only assume this comment was a poor attempt at sarcasm and/or humor. reply s1artibartfast 5 hours agorootparentCocaine and Xanax is a strange combination. I have never heard of their mixing before. reply johnisgood 2 hours agorootparentIt depends, taking caffeine and alprazolam together does not make much sense, but it can reduce the jittery feeling of caffeine, for example. It may not have been mixed either, it is common to take benzos when coming down. reply AbstractH24 1 hour agorootparentMy point exactly More people than should take stimulants to get going and sleeping pills to come down reply kamikaz1k 6 hours agorootparentprevWere they being sarcastic? Why is it funny/not? Thank you reply 00_hum 16 minutes agoprevit looks like she resigned as soon as she got cancer. crazy that it ended in such a similar way to so many ordinary people reply postatic 10 hours agoprevWe argue about agile processes, front end frameworks, languages, microservices, revenues, fundings, options, shares, hustles and all and at the end of the day we return back to the earth. reply silisili 1 hour agoparentThe thought helps ground me(no pun intended), whether during aforementioned battles at work or worrying over something in life. Not really religious, but always liked the short line 'For dust you are, and to dust you shall return' reply aerodog 1 hour agoprevSusan Wojcicki, who killed free speech on Youtube while sponsoring the \"Free Expression Awards\" that she granted to herself in 2021. What reply bundie 1 hour agoparentCan you go for 10 minutes without bringing up some stupid culture war stuff? Are you really that weird? reply NelsonMinar 3 hours agoprevI admired Susan in the early days, long before Youtube. She did a remarkable job earning respect and leadership roles in a company that mostly only valued engineers. Also she was kind and humane in a way that was not entirely common at the company. reply georgel 11 hours agoprevThis is a very sad day. For her to also lose her son in February too. reply whyenot 1 hour agoprevI went to school with her starting in elementary school on the Stanford campus through high school at Gunn. My mom was one of her teachers and just told me “this is so sad, she was such a beautiful kid. She went on to do amazing things.” Yes, she did. reply danjl 1 hour agoparentSusan lived four houses away from me on Tolman Dr.and I remember walking to Nixon elementary school carrying our instruments for music on Thursdays. Such a rough final year and such a wonderful life. RIP reply toomuchtodo 3 hours agoprevRelated: https://news.ycombinator.com/item?id=41208582 reply mrkramer 7 hours agoprevSuch a devastating news from the human therefore emotional perspective; just 6 months after her freshman son overdosed, now she is gone too. I hope they will be reunited in the afterlife. reply gjsman-1000 4 hours agoparentnext [3 more] [flagged] CoastalCoder 3 hours agorootparentI'm not a Christian, but IIUC (apologies if I get this wrong): They hold that none of us can ever be good enough for God's standards. That's why Jesus' atoning sacrifice is such a big deal. So pick the person you hold in highest regard, and they're still too sinful to merit eternal life. And pick the worst person you can imagine, and Jesus' sacrifice is enough to cover them too. reply mrkramer 3 hours agorootparentprevYea, God will judge her because she banned XY content or whatever....Google is liberal company which operates in the capitalistic liberal democratic USA and that's how YouTube is run. It's very hard to balance the freedom of speech and the artistic expression or whatever else you want to balance, there is no silver bullet. reply LZ_Khan 12 hours agoprevWow. Terribly sad series of events for that family. Life is not fair. reply LoveMortuus 8 hours agoprevRest in peace Susan reply omot 1 hour agoprevare we not going to put a black bar on HN for her? reply bushbaba 4 hours agoprevSusan not only built up YouTube but also the community around her. She will be missed but not forgotten reply Balgair 3 hours agoprevShe was someone who left a huge mark on my life. Though not in the forefront, but in the backend, so to speak. Fuck cancer. reply mupuff1234 3 hours agoprevI always assumed that ultra wealthy people can utilize preventive medicine to the max and catch stuff like cancer as soon as it appears - but i guess not? reply deadbabe 8 hours agoprevCrazy how so many young people are just dying of cancer these days. reply sumedh 7 hours agoparentYou are getting aware of it more due to social media. reply shortrounddev2 6 hours agorootparentNo, there is a rise in colon cancer among people in their 20s and 30s, and scientists are saying it's probably ultra processed foods reply MajimasEyepatch 1 hour agorootparentOverall, the incidence of cancer in the US among people under the age of 50 rose from 95.6 per 100,000 to 103.8 from 2000 to 2021.[ Colon cancer is one of the biggest drivers, but there are also a few others like kidney and thyroid that have seen big increases. Some of this, like thyroid cancer, might just be due to better detection of smaller, less serious cases. Fortunately, there are also some positive trends, like much lower rates of lung cancer (due to less smoking and cleaner air, presumably) and a decline in melanoma (skin) cancer after an increase in the early-to-mid 2000s (related to the rise and fall of tanning salons, I assume). https://seer.cancer.gov/statistics-network/explorer/applicat... reply jasonvorhe 7 hours agorootparentprevThat must be it. Nothing of relevance that could point in any other direction happened over the last 4 years. Sure. reply halfmatthalfcat 7 hours agorootparentOh brother. reply blangk 5 hours agorootparentIt does seem somewhat relevant reply halfmatthalfcat 4 hours agorootparentIt's a doomer, conspiratorial take without any evidence, especially when it's a vailed insinuation. reply gjsman-1000 4 hours agorootparentAll evidence starts as anecdotal observation. Even the world’s most groundbreaking papers are, at their root, a collection of anecdotal observations others look into. Secondly, absence of evidence, is not evidence of absence. Just because there’s no evidence for something being harmful, doesn’t mean there’s any evidence proving the something isn’t harmful. So look, I’m not an antivaxxer, but I say, “prove it.” Instead of saying “there’s no evidence it’s causing cancer,” write papers proving that it can’t be. I have no problem with the burden of proof being on for-profit billion-dollar companies repeatedly convicted of wrongdoing. reply mynameisvlad 1 hour agorootparentYou just spent an entire paragraph pointing out a logical fallacy and then immediately follow up by trying to have someone prove a negative? Come on. And the burden of proof generally is on the person making a claim. If someone says or implies that a vaccine causes cancer, then it’s on them to prove that, not on the vaccine maker to magically prove a negative. reply gjsman-1000 1 hour agorootparent> If someone says or implies that a vaccine causes cancer, then it’s on them to prove that, not on the vaccine maker to magically prove a negative. This does not make any sense, because the vaccine maker is also making a claim: “This drug is safe, effective, does not cause cancer or other harm in either the short term or the long term, and is in every way trustworthy.” In which case, the burden is on them to prove it, just like any claim from any company about any product. Even more so when they have convictions and a $2.3 billion fine historically for lying. It’s also realistic, I believe, to say that when you are in a rush against competition combined with the world being in a panic, that is a perfect atmosphere for lies and omission. reply mynameisvlad 1 hour agorootparentYou can’t prove a negative. It’s impossible to prove that something is 100% safe in all possible cases forever and always and will never cause cancer or interact with another drug or cause some unknown rare side effect. It’s impossible to predict every single interaction and edge case. We all know this, it’s basic logic, so I don’t know why I have to repeat it. Furthermore, their claim is not and has never been “This drug is safe, effective, does not cause cancer or other harm in either the short term or the long term, and is in every way trustworthy.” as an absolute. They explicitly release numbers such as effectiveness, efficacy, etc which show how safe, how effective, etc a drug/vaccine is. Just because you ignore those numbers and choose to believe your own absolute interpretation of what they say doesn’t somehow mean that is what was said. reply gjsman-1000 1 hour agorootparentEgh… no. They wanted the FDA to put it under NDA for 75 years. Which a judge said was bull. https://www.reuters.com/legal/government/paramount-importanc... https://news.bloomberglaw.com/health-law-and-business/why-a-... I don’t have to be anti-vax at all (and I’ve got the full regular schedule) to say that’s acting suspicious and like you have something to hide. reply halfmatthalfcat 1 hour agorootparentNowhere does it say \"NDA\" in the articles you posted. That year number is derived from the number of pages the FDA can produce a month with current staffing levels, as funded by the federal government. If you wan the FDA to become more efficient, maybe we should lobby the federal government to provide more funding so it can act quicker. reply gjsman-1000 1 hour agorootparentAs though Pfizer didn’t have quite a few of the documents already and could have released them themselves… And as though $7.2 billion a year isn’t enough to get the job done. reply mynameisvlad 1 hour agorootparentprev> Egh… no. They wanted the FDA to put it under NDA for 75 years. Which a judge said was bull. Cool, how does that any way shape or form relate to this discussion? Did they make the claim that they are 100% safe and will never cause interactions ever? If so, show me the exact quote where they said that. There are many reasons to ask for an NDA, and lying is only one of them. Hanlon’s razor and all that. Are the numbers incorrect? That is what actually matters, in the end. > I don’t have to be anti-vax at all (and I’ve got the full regular schedule) to say that’s acting suspicious and like you have something to hide. Just because something looks suspicious doesn’t mean that it is. You are choosing to believe that it is, and that is influencing your response. You still haven’t shown any sort of study or proof that vaccines (or even this vaccine specifically) cause cancer, by the way. If you’re so sure they do, I’m sure there’s something to back that up. After all, Moderna has provided the data to back their own claims up already. reply gjsman-1000 1 hour agorootparentA. I didn’t say they did cause cancer. I don’t believe they do. I am sympathetic to those who want more investigation. B. Hanlon’s razor is flawed, as well-executed malice is indistinguishable from stupidity. C. Contrarywise, you are choosing to believe that it is not suspicious behavior; when being suspicious of a company with decades of fines and convictions is arguably quite reasonable. D. There are many reasons for your wife to not be talking to you, have a dating profile, and have legal letters in the mail. Divorce planning is just one of them. reply rchaud 6 hours agoparentprevShe was the same age as Steve Jobs when he passed. reply robertoandred 2 hours agoparentprev56 isn't young. reply jasonvorhe 7 hours agoparentprevCrazy, right? reply 54 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "Susan Wojcicki, a prominent figure in the tech industry, has passed away, as confirmed by Sundar Pichai on Twitter.",
      "Wojcicki was instrumental in YouTube's success, transforming it into a multifaceted platform worth an estimated $400 billion, surpassing the combined value of Disney and Comcast.",
      "The discussion highlights YouTube's evolution, from pioneering creator monetization to becoming a significant player in music and podcasting, despite criticisms of stagnation and delayed feature rollouts compared to competitors like Twitch and Patreon."
    ],
    "points": 595,
    "commentCount": 313,
    "retryCount": 0,
    "time": 1723265909
  },
  {
    "id": 41207221,
    "title": "Defcon stiffs badge HW vendor, drags FW author offstage during talk",
    "originLink": "https://twitter.com/mightymogomra/status/1822119942281650278",
    "originBody": "Haha, wtf, Defcon apparently stiffed the hardware company who designed the cool badges for this year, and physically booted the guy who wrote the software because he mentioned it in an easter egg https://t.co/k8i5TPrh4V pic.twitter.com/T76Kvkbulq— Mogomra (e/acc) (@MightyMogomra) August 10, 2024",
    "commentLink": "https://news.ycombinator.com/item?id=41207221",
    "commentBody": "Defcon stiffs badge HW vendor, drags FW author offstage during talk (twitter.com/mightymogomra)440 points by dmitrygr 14 hours agohidepastfavorite111 comments yyyfb 9 hours agoStreisand effect strikes again Option A: let the dude have his talk. Nobody hears about it beyond the walls of defcon. Move along. Option B: uninvite and call security. Guy becomes instant personality on reddit and hn. I didn't know that defcon had become a shitty, small minded operation that abuses volunteer time and can't take an Easter egg, well now I do! Well played... reply katzinsky 7 hours agoparentI stopped paying attention a few years ago because their leadership was visibly heading in this direction. It's always kind of frustrating to see programmers and other software people participating/defending that kind of thing considering logic is our whole game to begin with. reply threatofrain 8 hours agoparentprevI think this was going to blow up no matter what. Every single badge... reply yyyfb 5 hours agorootparentI'm pretty sure it would've stayed a defcon thing reply rwl4 12 hours agoprevHere's a direct link to him being dragged off the stage: https://x.com/dmitrygr/status/1822124650547257637 It's definitely somewhat aggressive. Way to burn bridges. reply jmprspret 11 hours agoparentIs there a non-twitter link? Blocks me because I have DNS adblock+using mobile browser. reply swores 11 hours agorootparentWhile it doesn't show you any thread context, for media tweets like the video one linked if you paste the URL into a site like https://savetwitter.net/en it will spit out the video file to watch as well as telling you the text of that tweet (although, testing it with that tweet on my phone just now I had to select the title and paste it elsewhere to see as the page truncated the visible amount to fit phone width). reply 1vuio0pswjnm7 11 hours agorootparentprevhttps://nitter.poast.org/dmitrygr/status/1822124650547257637 reply UberFly 10 hours agoparentprevLooked the opposite of aggressive to me. Smiles all around. reply rcxdude 9 hours agorootparentHe's being carried off. He's only smiling because of how ridiculous it makes the organisers look reply peterpost2 9 hours agorootparentprevHe is rudely forced down a stair. That could have gone very wrong. reply CodesInChaos 11 hours agoprevIANAL, but I'm skeptical that Dmitry's interpretation that Defcon has no license is correct. It sounds like Dmitry sent them firmware images with the mutual expectation that those will be used on badges, and they invited him to the Badge talk which could be considered consideration. That should constitute a contract, either verbal, or through concludent acts. This should give Defcon the right to use Dmitry's on the badges, but not modify it. So legally the whole thing would probably be considered a contract dispute, not use of unlicensed software. Defcon will probably argue that including the easter egg was some kind breach of duty of Dmitry's part, and gave them the right to remove him from the talk, and modify the firmware to remove the easter egg. My expectation is that courts would decide that Defcon has the right to use the firmware, but will require them to pay some kind of compensation for not living up to their side of the bargain. reply robxorb 10 hours agoparentIMO the thing that may matter most here is the PR effect on Defcon. It's the badge - every attendee takes this thing home and engages with it. It's a talking point, memento and representation of the spirit of the conference. That's an unmitigated PR disaster for Defcon. It doesn't matter to this who was right or wrong or what laws were broken, even if somehow all legally ended up in Defcon's favour, the damage to the brand is huge, enduring and set aside from those issues. To address this, whoever at Defcon ultimately actioned this series of events should be held to account, for this PR aspect, and the matter immediately and publicly handed to someone with an appropriate understanding of Defcon's culture & reputation. reply clwg 7 hours agorootparentIt seems to have been Dark Tangent[0] (aka Jeff Moss), the creator and organizer of Blackhat and Defcon. https://x.com/dmitrygr/status/1822126826606739678 reply kaliqt 11 hours agoparentprevYou can rescind license to use the software if you haven't been paid consideration, you do not and should not have to wait for a court to say so. reply SR2Z 1 hour agorootparentThis is a silly take. Unless there was a contact written down, DefCon gets to remove this guy for any reason or even no reason. The incentive to not do it is because it makes them look like power-tripping maniacs, which is what happened. I've never been to the conference but now I think I'll never want to go. reply olliej 1 hour agorootparentUm, removing a person who’s giving a talk is a completely different action from the distribution of (potentially) unlicensed software. DEFCON may well have many reasons and legal recourses to stop a talk from occurring. But if they do not meet the terms of the contract for the IP, then the author/developer/manufacturer is entirely free to pursue action against them. Now it’s possible the developers had not watched Mike Monteiro’s “fuck you pay me” talk (https://creativemornings.com/talks/mike-monteiro--2/1), but assuming that the claims in this tweet are remotely accurate you can bet that - assuming they can get someone to do it at all - next years defcon badge will be produce by someone with a contract that has the only sane language: “no transfer of any IP or right to distribute occurs until receipt of full payment” reply madaxe_again 10 hours agoparentprevIf including an Easter egg voids the contract, then they should also start a class action against Microsoft for frivolously including a flight simulator in excel. reply gavinhoward 14 hours agoprevI followed the link, and while there is a video of someone getting dragged off stage, I can't really verify the other claims. But even so, dragging a presenter off stage is sus. And doesn't seem smart because even if the other claims are not true, I'm tempted to never attend Defcon if that's what they do. reply dmitrygr 14 hours agoparentI can verify. I was the one dragged off. I wrote the firmware for the badge. All of it. reply bingo-bongo 12 hours agorootparentI think it’s so amazingly awesome that you just went outside and held an unofficial talk! Read your blog/article about the badge project yesterday and it was such a good read, even for a not-much-of-a-hardware-guy like me. reply nipponese 13 hours agorootparentprevCan you please explain the timeline of events here? reply Y_Y 10 hours agorootparenthttps://old.reddit.com/r/Defcon/comments/1eoe4u7/so_the_guy_... reply soraminazuki 4 hours agorootparentOof, Defcon organizers even SWATted him? reply olliej 1 hour agorootparentIt sounds like they called the police, that is not swatting. Swatting is a specific tactic where you abuse the minimal training and disposition to violence of US police forces to attempt to murder people by reporting that they’re armed and/or threatening violence. Claiming the calling the police on someone is swatting, even though US police routinely execute people unprovoked attacks, is not swatting. The difference is the intent - the intent of swatting is terrorism and murder. reply brunoqc 2 hours agorootparentprevCome on. Calling the cops is nothing like Sweating. reply soraminazuki 2 hours agorootparentIt's SWATting when you try to pit the cops against innocent people. reply brunoqc 1 hour agorootparentI don't think so. When people get SWATed, usually a fake call is made, were the police are told that a murder was already committed by the caller and that we will kill everyone on sight. Thus the police expect real danger, brings the big guns and their trigger happy attitude, kick the door in and are more likely to kill the victim. It's not SWATing if the police come to handle a disturbance. The SWAT team need to be deployed for a SWATing. Anyone could have called the cops too. A gathering of 100 people can make people nervous. But I wouldn't be surprised if Defcon called them too. reply dmitrygr 13 hours agorootparentprevEdit: someone summarized it better: https://www.reddit.com/r/Defcon/comments/1eoe4u7/so_the_guy_... Approx: Entropic is engaged to make hw. I am asked (unofficially) to do sw. Entropic works for free but does charge for parts and subcontracted stuff . Eventually defcon stops paying. Entropic is uninvited from badge talk. Their logo is ground out of plastic case. Their logo hidden in publicity photos of pcb. Tempers are high. I implement the Easter egg. This is months ago cause thats how long one needs to pre-flash chips. Time passed. Defcon still working on their game last moment. They had volunteers reflash badges cause they didn’t make the real pre flashing deadline. I forgot about the screen entirely more or less. Day of con. I spend all day helping debug badge issues. Push updates. Help people. Even pushed an update from plane on way to con to fix some things. Badge talk time. Half an hour before defcon tells me no talk for me cause someone found the Easter egg screen and they are pissed. I show up anyways since it was promised. I get dragged off stage. I hold talk outside answering questions. Next steps: I have no contact with defcon. They never bothered to. Normally: who cares? I get to talk, people get to play with badges. Nobody cares. But… I got kicked out, and… they have no license to my firmware they are distributing. Likely DMCA notice. reply ssl-3 13 hours agorootparentMan. I've never been to defcon, but it's been more than a passing curiosity ever since the first real announcement[0] crossed my BBS in '93. And recently I've had a string of bad, unalterable, and irrevocably-permanent events occur in my life. And yet, I'm very pleased to say that your write-up on your experiences with the RP2350[1] presented a small but meaningfully-positive thing for me to look forward to. Please be well -- and don't take any guff from these swine[2]. [0] https://media.defcon.org/DEF%20CON%201/DEF%20CON%201%20annou... [1] https://dmitry.gr/?r=06.%20Thoughts&proj=11.%20RP2350 [2] https://www.barnesandnoble.com/w/fear-and-loathing-in-las-ve... reply iwontberude 10 hours agorootparentDefcon is a waste of time. Nerds pay walled from their friends. reply markus_zhang 6 hours agorootparentIs blackhat more serious and better? reply MSFT_Edging 5 hours agorootparentBlackhat is even more of a pay-to-play corporate event.A few years ago, someone paid to do a talk on time traveling crypto and the CEO of trail of bits(iirc) stood up and called him out on the spot over the nonsense tech. Defcon has a lot more grassroots stuff, but it's grown to a size that it cannot avoid the corporate BS anymore. It's probably one of the biggest and most disruptive conferences in Vegas, venues don't like having 1000s of hackers hanging around slot machines. reply markus_zhang 1 hour agorootparentMaybe they should just move away from Vegas. I don't know why people choose that spot. Why not some place with better view? reply nicolas_17 48 minutes agorootparentA friend said \"getting out of vegas would mean losing half the point of going to bh/defcon (which is getting your company to pay for you to go to vegas)\" reply Aeolun 13 hours agorootparentprevWhy’d they be pissed about people donating money to the people they didn’t want to pay :/ I just don’t see how they lose anything there (or rather, don’t see how they lose anything there that they lose a hundred times more of by their actual actions, namely reputation). reply YeahThisIsMe 11 hours agorootparentEvery niche convention either stops existing or transitions into a business that slowly gets rid of all the fun stuff that created it in the first place. reply ahartmetz 10 hours agorootparentThe CCC congress is still going strong, but it wouldn't work without the many volunteers and non-profit CCC behind it. reply Yeul 9 hours agorootparentprevHackers themselves became corpos- or worse work for the intelligence agencies. reply q3k 10 hours agorootparentprevCop mentality. reply windexh8er 12 hours agorootparentprevThank you for the clarification, Defcon has some explaining to do given they make good money on the con. Things have definitely changed. reply notinmykernel 10 hours agorootparentprevYou left out the part where the \"Goons\" physically touched you, and forcibly removed you from a location against your will. The \"Goons\" have no authority to carry out such an act. And there's video footage. Congratulations on winning the lawsuit! reply lukan 10 hours agorootparent\"and forcibly removed you from a location against your will\" Not saying they were morally or ethically right, or smart to do this at all - but legally there usually is a right to remove a unwanted person from your stage with the help of your own security. reply more_corn 4 hours agorootparentYeah, pretty sure if you’re asked to leave an event and you refuse, they can have you escorted out even if you dig in your heels. reply IshKebab 10 hours agorootparentprevThey do have the authority to do that. They ask you to leave. If you say no then you're trespassing and can be physically removed. How do you think bouncers work? reply eddyfromtheblok 11 hours agorootparentprevSounds like a fiasco. Have to wonder why parts and subcontractors aren't getting paid reply tamimio 13 hours agorootparentprevAh, defcon drama! Old ones used to be much better anyway. reply loopdoend 11 hours agorootparentThe ninja badges even had games you could play where you fight other users if I recall correctly. (Mid 2000’s?) reply zmgsabst 11 hours agorootparentprevCommercial copyright infringement has a per instance statutory minimum. Demand the minimum for every badge distributed — as even if you later provided licenses to holders, DC had no license when distributing the copies as merchandise at their for-pay event. reply romwell 12 hours agorootparentprevOK, everything aside, thank you for your absolutely amazing work and the inspiring writing you do about it! Reading about rePalm has changed my definition of what monumental effort looks like. (You should absolutely add that you managed to get PalmOS running on the badges in question!) reply kstenerud 13 hours agorootparentprevTime to make your own Defcon. With blackjack. And... reply adastra22 11 hours agorootparentWhich black hat, and webhooks! reply rubans 12 hours agorootparentprevWith black hat* reply EarlKing 9 hours agorootparentprev....I mean, you're already in Vegas, so... reply abtinf 12 hours agorootparentprevIf that’s true, crucify them for piracy. Why would DMCA apply here? reply dmitrygr 12 hours agorootparentThey are Illegally distributing copies of my firmware on their badges reply Symbiote 11 hours agorootparentIf they don't have a licence to distribute your software, it's plain copyright infringement. The same as selling photocopies of a book. The DMCA criminalises breaking DRM, or providing tools to do so, such as distributing a tool to remove the DRM from an e-book. reply arghwhat 10 hours agorootparentThe Digital Millennium Copyright Act also does have provisions related to copyright infringement, not just circumvention devices. reply waihtis 13 hours agorootparentprevWild, but not surprising. Heard a lot of bad stuff from the village heads some years ago already about DC organization. reply utopcell 13 hours agorootparentprevdid they end up paying Entropic in the months that passed ? reply dmitrygr 13 hours agorootparentNo. But beyond money, the credit hurts more. Having your company name scratches out of plastic molds is … oof. reply utopcell 12 hours agorootparentthis is some pretty ugly stuff. If you are in contact with any of the Entropic folks, maybe point them to this or the r/ thread so that they can provide more context. reply dtx1 13 hours agorootparentprevOne part of me wants you to DMCA the living daylight out of them. The other part is currently seeding torrents and thinks copyright is kinda dumb. Anyway, shitty thing to do by the defcon people. reply dmitrygr 13 hours agorootparentI have been giving out licenses to the firmware to anybody who asks in the unofficial badge hacking discord. :) also my signature on the badge acts as a nontransferable license to the firmware in source and binary. i signed maybe a thousand today at my unofficial talk outside after i was dragged out. reply patrickhogan1 9 hours agorootparentprevNice work keeping the easter egg spirit alive. How would one trigger the easter egg? reply justjonathan 13 hours agorootparentprevI was at this talk, someone (you I guess) left at the beginning of this talk. To the audience it was not clear what happened, reply gavinhoward 13 hours agorootparentprevYeah, after some more digging, it does appear to be you. I do wish I had more context from the video, but at this point, it's getting hard to imagine any good reason for Defcon to do what they did. Assuming that you weren't threatening someone in the audience or something like that. Doubtful, from the way you've been talking. Anyway, it looks like good stuff. Wish I had some Game Boy games to try it. reply dmitrygr 13 hours agorootparentI threatened nobody. reply gavinhoward 13 hours agorootparentYeah, I hope it was clear that I don't think you did that. reply iJohnDoe 13 hours agorootparentprevWhy is it up to you to determine who is telling the truth? Why do you need to dig or investigate? Anyways, just seemed odd. reply urbandw311er 12 hours agorootparentI would counter that by asking why would any of us not want to dig or investigate claims and assertions made in 2024? It’s hugely important to approach life with a critical mindset these days, and something we should all be doing. reply rpdillon 2 hours agorootparentprevI don't think that's how he meant it, but rather that we all need to read/watch and evaluate credibility on our own, because this is the internet. reply irjustin 12 hours agorootparentprevYou always trust what someone on the internet tells you? reply gorgoiler 13 hours agorootparentprevI’m sorry to hear this happened to you. One cannot lay even a finger on another person, ever, let alone jostle someone just because they don’t like what they are saying. It doesn’t matter if they are “security”. It’s assault and battery just the same as if I shove grandma out the way to get to the bus! reply romwell 12 hours agoparentprevThis is Dmitry Grinberg[1] some of whose absolutely amazing projects (like, running Palm OS on other devices) have recently gotten some traction here on HN. (In particular, he managed to get Palm OS running on the badges in question). If there's one person whose credibility I wouldn't doubt on those matters, it's him. [1] https://dmitry.gr reply Animats 14 hours agoprevBadge is a GameBoy emulator.[1] [1] https://www.dexerto.com/tech/hacking-convention-uses-fully-w... reply numpad0 13 hours agoparentPut aside the fact that that’s awesome, that doesn’t sound like the safest thing on Earth to contract out. reply dmitrygr 14 hours agoparentprevIt also runs PalmOS. I published images for that. reply markus_zhang 14 hours agorootparentI heard they didn't pay you in full. This is so sad. Why did they do that? reply geerlingguy 13 hours agorootparentI believe the hardware designer was stiffed (according to some threads on Twitter)? There doesn't seem to be a summary of what happened anywhere, but from the reactions I've seen, it looks like DEFCON didn't pay a vendor for badge hardware, and the firmware has an easter egg showing that vendor. Not sure why the dragging off the stage happened. reply dmitrygr 13 hours agorootparentprevI worked for free. They didn’t pay hardware vendor (guys who made the physical badge) and removed their name from plastics and invitation to talk reply gryfft 13 hours agorootparentprev> Why did they do that? I'm confused by the rationale of questioning the OP about someone else's motivations. reply qmarchi 13 hours agorootparentYes and no, they may have been informed in a non-public setting on _why_ DEFCON has refused to pay. DEFCON themselves is likely to not state a reason publicly, so getting a \"here's what I was told by DEFCON\" is likely the closest thing that we're going to get for an answer. reply dmitrygr 13 hours agorootparentEven if they don’t pay, removing credit for work done is NOT ok. Work was done. Badge exists. Entropic made it reply gryfft 13 hours agorootparentprevI read it as tinged with the implication that the wronged party must have done something to deserve it. In retrospect, perhaps I was being too sensitive. reply gexcolo 1 hour agoprevAm I missing something about how this story went missing from the front page? There is at least one story with less points posted 12 hours earlier that is still visisble there. https://archive.is/dtRg2 https://archive.is/8HK5y https://archive.is/yk5uU Is there any transparency that could tell us why this change was made? reply raldi 13 hours agoprevDo you have a writeup or something? Twitter videos don’t really load anymore this year. reply orf 9 hours agoprevSeeing as you’re in the thread Dmitry, what was the Kindle bug referenced here? Sounds interesting. https://news.ycombinator.com/item?id=41207740 reply sneak 11 hours agoprevThe same Defcon that allowed NSA director Keith Alexander to keynote. I even live in Vegas now and I don’t go anymore. reply sschueller 9 hours agoparentThe event being named after a US military meeter to indicate how far away the US is from nuclear war should already be an indication. There are some good people there but also a lot of people who do not care what happens with what they build and look away when it would be time to speak up. reply nubinetwork 8 hours agoprevI've watched defcon and ccc a lot over the years... was this the first time a presenter has been physically dragged off stage? reply the_biot 7 hours agoparentStallman arguably was, one time at FOSDEM. Not over some disagreement, he just wouldn't stop talking and make room for the next speaker :-) reply mvdtnz 12 hours agoprevThis needs way way way way more context. reply h0l0cube 11 hours agoparentYep. Not sure why this is downvoted, but as an outsider to DefCon, I'm not sure what's going on here just looking at the tweet. reply znpy 9 hours agoprevI just read the timeline of events at https://old.reddit.com/r/Defcon/comments/1eoe4u7/so_the_guy_... Frankly… i’m not surprised. The whole industry is filled with this kind of fascistoid attitude now. Every organization takes any chance they can to silence opinions they don’t like (and this happens both left and right). I see from the link above that the POLICE was called on dmitrygr for… speaking to people in a public space? Really? Defcon has gone from outcast meeting to full mainstream and interest-preserving. Kinda lost all of its hacker attitude, and this is proof. reply Firmwarrior 12 hours agoprevI feel like this is a good spot to mention that Dmitry's a friggin beast when it comes to engineering. As that Tweetster put it: \"Dmitry is an insanely skilled dude. Easily on par with Carmack or Karpathy IMO. They almost had to delay the original Kindle Fire tablet because of a rare bug that all the king's horses and all the king's men couldn't fix in 6 months, but Dmitry nailed it in a few days\" Summary of the events unfolding by Sargonas on Reddit: Maybe this will help with a listed summary of the known facts from first hands accounts. I am leaving gaps where there has just been speculation or second hand unverifiable information, and welcome anyone with first-hand knowledge of those aspects to comment below me to fill in the gaps. I'm merely presenting the facts as we have them from first-hand accounts (mostly from reddit and discord), without personal opinion or bias (hopefully, human nature is a tricky thing.) Entropic Engineering designed and built the circuitry of the badges, physically. They were either only partially, or not at all, paid by DEFCON for this work, contrary to whatever formal agreement they had in place. (Other amazingly talented individuals create the silk screen design, the shells, and the game, but are totally removed from this drama so I'm leaving them out of it.) Subsequently, all references to them have been removed in various materials, and even one of their logos was removed from the silk screen. (apparently small one may be left under the battery? but I can't check because I affixed mine to the board to stop it's shifting.) dmitrygr wrote the firmware for the badges as well Somewhere along the way, Entropic was cut out of the process and left to the side by DEFCON in a way that left Entropic feeling burned and under/un paid for their non-trivial work (according to some comments below it is 6 figure sum, but this is second hand info). Dmitry felt this was unfair, and put an easter egg into the badge code. This easter egg simply comments that Entropic engineered the badges, and had their credits removed everywhere, with an address for donations if you wish to support them. This was entirely Dmitrys doing as a gesture of thanks to the Entropic team. This easter egg more or less flew under the radar until EoD friday. Friday evening, after spending most of his day traveling to DEFCON and writing a 1.5 update in his spare time on his flight to fix some issues, Dmitry was up on stage with the other badge creators about to present the usual badge talk, when word of the Easter egg went around (likely due to him including some slides on his portion of the presentation about it.) DEFCON staff had Goons escort Dmitry off stage shortly before the talk started, delaying the talk some. during the talk, a comment was made about “unauthorized code“ being on the badges. Dmitry setup himself on the sidewalk outside the hall, and basically held his own mini talk about the work he did and Entropics contributions. At some point, LVMPD showed up. It is unclear to me personally who issued the call but second hand info says it was DEFCON staff. They noted Dmitry was simply talking to people (albiet nearly 100 of them) on a public sidewalk, outside a building owned by the county, and nothing was really amiss, and left shortly after. Dmitry, in his (likely valid) opinion feels this whole situation has not been handled well, and since his code was written free of charge, without any signed agreements with DEFCON or consequently any rights assignments, has announced that he intends to assert his legal ownership of the code (which is his right under us copyright law). As a result, he will gladly issue a non-transferable right to the code to any attendee who asks him for one, but is no longer going to \"turn a blind eye\" to the fact DEFCON does not have a legal license to his code, and instead look into taking actions that are within his power to take to clarify their lack of ownership of the code on the badges. (I believe in discord he may have gone so far as to say DMCA, but I need to double-check.) bearing this in mind this does add a curious wrinkle to the statement about “unauthorized code” from DEFCON given… The obvious. reply lawgimenez 10 hours agoparentThanks for the summary. Why was Entropic not paid or cut out? reply TrueDuality 11 hours agoprev [15 more] [flagged] saagarjha 10 hours agoparentI was not in the crowd so I can't say anything more about that. That said, > This dude, as a contractor-for-hire, injected unwanted code he calls \"just an easter egg\" in the final firmware of the badge. This \"unwanted code\" is a screen asking for bitcoin donations and self-aggrandizing himself. If this is how you feel about an easter egg I suspect you misunderstand the point of DEF CON. Maybe the organizers of the conference do too. reply TrueDuality 10 hours agorootparentNah there is a difference between fun and light thing to find, and asking for money and disrupting an event. reply lukan 10 hours agorootparentAsking for money for other people, who created the badge - and had all their credit ereased. He put the credit back in as the easter egg. https://news.ycombinator.com/item?id=41207469 reply hitekker 10 hours agoparentprevThis is quite an angry comment. Do you have evidence to support your allegations? So far, other accounts indicate Dimitry has not done what you've accused him of: https://www.reddit.com/r/Defcon/comments/1eoe4u7/comment/lhe.... Besides what other commenters wrote, I think it'd odd to gloss over Defcon stiffing their Badge HW vendor while attacking Dmitry, Defcon's other business partner, for not having \"a responsible business dispute\". reply threatofrain 10 hours agoparentprevAre you sure Dmitry was a paid contractor? Let's see if Defcon disputes that Dmitry was basically asked to informally work on a friends and family basis. Where are you getting this information that Dmitry was a paid contractor? reply TrueDuality 10 hours agorootparentIt's a bit of inference on my part, I'll give you that but the premise doesn't make sense if he wasn't paid. If he was working as an unpaid volunteer with the \"compensation\" being a part of a talk on stage... What was he protesting before the event even started when he injected the screen asking for money? That's a pretty garbage thing to do, but he did it before the consequence he claimed he was protesting. reply debugnik 10 hours agorootparent> What was he protesting before the event even started when he injected the screen asking for money? The hardware vendor was stiffed and Defcon scratched their trademark from the badges, so this man added an easter egg asking for donations to them, not himself, as far as I understood. reply echoangle 10 hours agorootparentprevMaybe he was protesting that the hardware creator didn’t get paid? That’s the story I’ve read in the comments here. reply dmitrygr 9 hours agoparentprevI was not paid and I was not a contractor. No contract. No money. reply utopcell 2 hours agorootparent> \"He walked on stage and started yelling at the presenters. He was asked to leave by multiple groups of security staff and refused to leave while interrupting the talk. He demanded he be physically removed. The staff security eventually acquiesced to his demands.\" Did you do these things ? reply hitekker 1 hour agorootparentFrom my read, Dmitry didn't upset his audience, excluding the flagged TrueDuality commenter. Rather, after Dimitry's protest and physical removal, a bunch of the audience went outside to listen to his impromptu talk on the sidewalk. reply krisoft 9 hours agoparentprev> This dude, as a PAID contractor-for-hire Could you please tell us your source on that? Specifically that he was paid for developing the software. reply notfed 10 hours agoparentprevIt sounds like he did the Easter egg as a form of protest. Were the presenters he yelled at people who he was protesting against? reply notinmykernel 10 hours agoparentprev [–] A-holes and opinions; we all got them. From your comment, I see you located both tonight. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Defcon allegedly failed to pay the hardware company responsible for this year's badges.",
      "The software developer who included a mention of this issue in an easter egg was reportedly expelled from the event."
    ],
    "commentSummary": [
      "Defcon removed firmware author Dmitry Grinberg from the stage for including an Easter egg crediting unpaid hardware vendor Entropic Engineering.",
      "Controversy arose as Defcon removed Entropic's logo and did not pay them, leading to backlash and criticism of Defcon's actions.",
      "Dmitry conducted an unofficial talk outside after his removal, highlighting potential legal issues with distributing unlicensed firmware."
    ],
    "points": 440,
    "commentCount": 111,
    "retryCount": 0,
    "time": 1723262390
  },
  {
    "id": 41208988,
    "title": "A wonderful coincidence or an expected connection: why π² ≈ g",
    "originLink": "https://roitman.io/blog/91",
    "originBody": "roitman Blog Contact Subscribe A wonderful coincidence or an expected connection: why π² ≈ g. Let’s take a brief trip back to our school years and recall some lessons in mathematics and physics. Do you remember what the number π equals? And what is π squared? That’s a strange question too. Of course, it’s 9.87. And do you remember the value of the acceleration due to gravity, g? Of course, that number was drilled into our memory so thoroughly that it’s impossible to forget: 9.81 m/s². Naturally, it can vary, but for solving basic school problems, we typically used this value. August 9, 2024 Mysterious equality And now, here’s the next question: how on earth is it that π² is approximately equal to g? You might say that such questions aren’t asked in polite society. First of all, they aren’t exactly equal. There’s already a difference in the second decimal place. Secondly, π is a dimensionless number, while g is a physical quantity with its own units. And yet, no matter how you look at it, this can’t just be a simple coincidence. Not as simple as it seems Let's start by taking a close look at the right side. The value 9.81 is in m/s². But these are far from the only units of measurement. If you express this value in any other units, the magic immediately disappears. So, this is no coincidence—let's dig deeper into the meters and seconds. What exactly is a \"meter,\" and how could it be related to π? At first glance, not at all. According to Wikipedia, a \"meter is the distance light travels in a vacuum during a time interval of 1/299,792,458 seconds.\" Great, now we have seconds involved—good! But there's still nothing about π. Wait a minute, why exactly 1/299,792,458? Why not, for example, 1/300? Where did this number come from in the first place? It seems we need to delve into the history of the unit of length itself to understand this better. A standard for every honest merchant In the past, people didn't bother much with standards: they only cared about what was convenient for measurement. For example, why not measure length in human cubits? It might not be precise, but it was cheap, reliable, and practical. And the fact that everyone's cubits were of different lengths? Sometimes that was even useful. If you needed to buy more cloth, you'd call the tallest person in the village and have them measure the fabric with their cubits. Later on, of course, people began thinking about standardization. They started creating various standards. But this turned out to be inconvenient and cumbersome: you couldn't always run to a single standard for measurement. So, copies of the standards began to appear. And then copies of the copies... Serious people decided that such chaos was hindering serious business, so they set a goal: to come up with a definition of a unit of length that wouldn't depend on any arbitrary standards. It should only depend on natural constants, so that anyone with some basic tools could reproduce and measure it. Bright dreams of standardization and insidious gravity A \"standard-free\" definition for the meter was actually proposed back in the 17th century. The Dutch mechanic, physicist, mathematician, astronomer, and inventor Christiaan Huygens suggested using a simple pendulum for this purpose. You take a small object and suspend it on a string. The length of the string should be such that the pendulum completes a full oscillation (returns to its original position) in exactly two seconds. This length of string was called the \"universal measure\" or the \"Catholic meter.\" This length differed from the modern meter by about half a centimeter. The proposal was well-received and adopted. However, problems soon arose. First, Huygens was dealing with what he called a \"mathematical pendulum.\" This is a \"material point suspended on a weightless, inextensible string.\" A material point and a weightless string are hardly the simple tools that every merchant would have on hand. Second, it was quickly discovered that the length of the pendulum's string varied in different parts of the Earth. Gravity cunningly decreased as one approached the equator and did not cooperate with humanity's bright dream of standardization. An astonishing equation But let’s return to our mysterious equation. To find the period of small oscillations of a mathematical pendulum as a function of the length of the suspension, the following formula is used: And here it is—our π! Let's substitute the parameters of Huygens’ pendulum into this formula. The length of the string l in Huygens' pendulum equals 1. The T - oscillation equals 2. Plugging these values into the formula, we get π²=g. So, have we found the answer to our question? Well, not quite. We already saw that the equality is only approximate. It doesn’t feel right to equate 9.87 and 9.81 exactly. Does this mean that the meter has changed since then? With revolutionary greetings from France Yes, indeed, it did change! This occurred during the reform of the units of measurement initiated by the French Academy of Sciences in 1791. Intelligent people suggested maintaining the definition of the meter through the pendulum, but with the clarification that it should specifically be a French pendulum—at the latitude of 45° N (approximately between Bordeaux and Grenoble). However, this did not sit well with the commission in charge of the reform. The problem was that the head of the commission, Jean-Charles de Borda, was a fervent supporter of transitioning to a new (revolutionary) system of angle measurement—using grads (a grad being one-hundredth of a right angle). Each grad was divided into 100 minutes, and each minute into 100 seconds. The method of the seconds pendulum did not fit into this neat concept. The true and final meter In the end, they successfully got rid of the seconds and defined the meter as one forty-millionth of the Paris meridian. Or, alternatively, as one ten-millionth of the distance from the North Pole to the equator along the surface of the Earth’s ellipsoid at the longitude of Paris. This measurement slightly differed from the \"pendulum\" meter. The commission, without false modesty, dubbed the resulting value as the \"true and final meter.\" The idea of a universal standard accessible to everyone waved goodbye and faded into the sunset. Need an accurate standard for the meter? No problem! All you have to do is measure the length of a meridian and divide it by a few million. By the way, the French actually did this—they physically measured a portion of the Paris meridian, the arc from Dunkirk to Barcelona. They laid out a chain of 115 triangles across France and part of Spain. Based on these measurements, they created a brass standard. Incidentally, they made a mistake—they didn't account for the Earth's polar flattening. Conclusion Let's return to our equation once again. Now we know where the inaccuracy comes from: π² and g differ by about 0.06. If it weren't for yet another attempt to reform and improve everything, we would now have a slightly different value for the meter and the elegant equation π² = g. Later, scientists did return to defining the meter through unchanging and reproducible natural constants, but the meter standard was no longer the same. roitman Roitman LLC, All rights reserved Made with Caseme.io",
    "commentLink": "https://news.ycombinator.com/item?id=41208988",
    "commentBody": "A wonderful coincidence or an expected connection: why π² ≈ g (roitman.io)267 points by signa11 6 hours agohidepastfavorite173 comments mistercow 6 hours agoThis is interesting, but I have to quibble with this: > If you express this value in any other units, the magic immediately disappears. So, this is no coincidence Ordinarily, this would be extremely indicative of a coincidence. If you’re looking for a heuristic for non-coincidences, “sticks around when you change units” is the one you want. This is just an unusual case where that heuristic fails. reply karmakurtisaani 6 hours agoparentActually no, the whole equation boils down to the definition of meter. Or rather, one of the earlier definitions. reply mistercow 5 hours agorootparentYeah, I read the post. What I’m saying is “this relationship vanishes when you change units, so it must not be a coincidence” is a bad way to check for non-coincidences in general. For example, the speed of sound is almost exactly 3/4 cubits per millisecond. Why is it such a nice fraction? The magic disappears if you change units… (of course, I just spammed units at wolfram alpha until I found something mildly interesting). reply dr_dshiv 2 hours agorootparentAlpha brainwaves are almost exactly 10hz, in humans and mice. The typical walking frequency (for humans) is almost exactly 2hz (2 steps per second). And the best selling popular music rhythm is 2hz (120bpm) [1]. Perhaps seconds were originally defined by the duration of a human pace (i.e. 2 steps). These are determined by the oscillations of central pattern generators in the spinal cord. One might suspect that these are further harmonically linked to alpha wave generators. In any case, 120bpm music would resonate and entrain intrinsic walking pattern generators—this resonance appears to make us more likely to move and dance. Or it’s just a coincidence. [1] https://www.frontiersin.org/journals/neurorobotics/articles/... reply panarky 1 hour agorootparentprevAnother bad way to check for non-coincidences is to use a value like g which changes depending on your location. Pi is the same everywhere in the universe. g on Earth: 9.8 m/s² g on Earth's moon: 1.62 m/s² g on Mars: 3.71 m/s² g on Jupiter: 24.79 m/s² g on Pluto: 0.62 m/s² g on the Sun: 274 m/s² (Jupiter's estimate for g is at the cloud tops, and the Sun's is for the photosphere, as neither body has a solid surface.) reply TheRealPomax 6 minutes agorootparentFun fact: pi is both the same, and not the same, in all of those places, too. Because geometry. If you consider pi to just be a convenient name for a fixed numerical constant based on a particular identity found in Euclidean space, then yes: by definition it's the same everywhere because pi is just an alias for a very specific number. And that sentence already tells us it's not really a \"universal\" constant: it's a mathematical constant so it's only constant given some very particular preconditions. In this case, it's only our trusty 3.1415etc given the precondition that we're working in Euclidean space. If someone is doing math based on non-Euclidean spaces they're probably not working with the same pi. In fact, rather than merely being a different value, the pi they're working with might not even be constant, even if in formulae it cancels out as if it were. As one of those \"I got called by the principal because my kid talked back to the teacher, except my kid was right\": draw a circle on a sphere. That circle has a curved diameter that is bigger than if you drew it on a flat sheet of paper. The ratio of the circle circumference to its diameter is less than 3.1415etc, so is that a different pi? You bet it is: that's the pi associated with that particular non-Euclidean, closed 2D plane. So is pi the same everywhere in the universe? Ehhhhhhhh it depends entirely on who's using it =D reply euroderf 3 hours agorootparentprev32 meters is 35 yards, to within about an eighth of an inch. How's that grab you ? reply mistercow 1 hour agorootparentI wonder if this is related, but imperial measurements with a 5 in the numerator (and a power of two in the denominator) are generally just under a power of two number of millimeters. The reason is fun, and as far as I know, historically unintentional. To convert from 5/(2^n) inches to mm, we multiply by 25.4 mm/in. So we get 5*25.4/(2^n) mm, or 127/(2^n) mm. This is just under (2^7)/(2^n) mm, which simplifies to 2^(7 - n) mm. This is actually super handy if you're a maker in North America, and you want to use metric in CAD, but source local hardware. Stock up on 5/16\" and 5/8\" bolts, and just slap 8 mm and 16 mm holes in your designs, and your bolts will fit with just a little bit of slop. reply GoldenRacer 2 hours agorootparentprevMy favorite is 1 mile = phi kilometers withOr after-atmosphere insolation being somewhat on average 1kw/m2. I’m kind of inclined to say that this one isn’t so much of a coincidence as it is another implicit “unit” in the form of a rule of thumb. Peak insolation is so variable that giving a precise value isn’t really useful; you’re going to be using that in rough calculations anyway, so we might as well have a “unit” which cancels nicely. The only thing that’s missing is a catchy name for the derived unit. I propose “solatrons”. reply brians 5 hours agorootparentprevBecause the cubit is a measure of what a body can reach reply ants_everywhere 4 hours agorootparentI never thought of the cubit this way. It's an interesting idea, but the cubit is the length of a forearm, whereas you can reach around yourself in a circle the length of your extended arm, from finger tip to shoulder. That would be somewhere between 1.5 to 2 cubits for people whose forearm is about a cubit long. I think the cubit is mainly a measure of one winding of rope around your forearm. That way you can count the number of windings as you're taking rope from the spool. This is the natural way a lot of us wind up electrical cables, and I'm sure it was natural back in the day when builders didn't have access to precise cubit sticks. I don't see the connection with the units and sound that you're making. But it is kind of interesting to know that sound travels about 3/4 of a forearm length per millisecond. That's something that's easy to estimate in a physical space. reply Bjartr 4 hours agorootparentprevHow does that explain the relationship to the speed of sound? reply ValentinA23 4 hours agorootparentA bit out of topic, however https://www.youtube.com/watch?v=0xOGeZt71sg Note: I'm more inclined to think this is a coincidence given that it establishes a link between the most commented text and the the most commented building in history. However I don't think these kind of relationships based on \"magic thought\" should be discarded right away just because they are coincidences, and I'd be very interested in an algorithm that automatically finds them. reply jncfhnb 5 hours agorootparentprevX^2 is a lot more interesting than x*0.0000743 or whatever it is reply mistercow 4 hours agorootparentOk, then by that thinking, you should find it really interesting that Earth escape velocity is almost exactly ϕ^4 miles per second. In fact, adding exponents here objectively makes it less interesting, because it increases the search space for coincidences. What makes the case in the post most interesting to me is that it looks at first glance like it must be a coincidence, and then it turns out not to be. reply satvikpendem 4 hours agorootparentprevWhy is it more interesting? Is it just more interesting because we use such bases, or can it be interesting inherently? That is the question that is being asked, and why some say it's merely a coincidence. reply jncfhnb 1 hour agorootparentWell every number is the product of another number and some coefficient. If it’s a nice clean number then that implies it could be the result of some scaling unit conversion. But that should be sort of apparent. And it’s not super interesting if true. If a number is another number squared then that implies some sort of mechanistic relationship. Especially when the number is pi, which suggests there’s a geometric intuition to understanding the definition. reply satvikpendem 1 hour agorootparentIn other bases, it does not actually imply much, even if it were squared. Maybe it really does make sense if it existed in base 10 but I cannot see much if it were part of other bases. reply saghm 1 hour agorootparentprevReminds me of https://xkcd.com/687/ reply KeplerBoy 4 hours agorootparentprevIt does not? Pi has nothing to do with our arbitrary unit system. reply mikequinlan 4 hours agorootparentPi is related to the circumference of a circle; the meter was originally defined as a portion of the circumference of the Earth, which can be approximated as a circle. \"The meter was originally defined as one ten-millionth of the distance between the North Pole and the equator, along a line that passes through Paris.\" reply mistercow 3 hours agorootparentBut that connection actually is a coincidence. From what I can tell, when they standardized the meter, they were specifically going for something close to half of a toise, which was the unit defined as two pendulum seconds. So they searched about for something that could be measured repeatably and land on something close to a power of ten multiple of their target unit. The relationship to a circle there doesn’t have anything to do with the pi^2 thing. reply GuB-42 2 hours agorootparentNot a coincidence. They defined the meter from the second using the pendulum formula, and the pandulum formula has a pi in it, so pi is going to appear somewhere. The reason there is pi is probably because a pendulum is defined by its length and follows a circular motion that has the length as its radius. We could imagine removing pi from the pendulum equation, but that would mean putting it back elsewhere, which would be inconvenient. reply mistercow 2 hours agorootparentRight, that connection is not a coincidence. The connection the previous commenter drew between the meter, pi, and the circumference of the earth is a coincidence. reply mannykannot 2 hours agorootparentprevIt was news to me, but that's what the article says, and it is supported by by Wikipedia, at least. [1] In addition, I feel the article glosses over the definition of the second. At the time, it was a subdivision of the rotational period of the earth (mostly, with about 1% contribution from the earth's orbital period, resulting in the sidereal and and solar days being slightly different.) Clearly, the Earth's rotational period can (and does) vary independently of the factors (mass and radius) determining the magnitude of g. The adoption of the current definition of the second in terms of cesium atom transitions looks like a parallel case of finding a standard that could be measured repeatably (with accuracy) and be close to the target unit - though it is, of course, a much more universal measure than is the meridional meter. [1] https://en.wikipedia.org/wiki/History_of_the_metre reply mistercow 3 hours agorootparentprevCan you explain what you’re taking issue with in the post, then? Because it specifically lays out how the historical relationship between the meter and the second does in fact involve pi^2 and the force of gravity on earth. (Granted, from what I can tell, it’s waving away a few details. It was the toise which was based on the seconds pendulum, and then the meter was later defined to roughly fit half a toise.) reply eigenket 4 hours agorootparentprevpi is always just pi, but g may be defined in terms of the meter. reply KeplerBoy 4 hours agorootparentsure, that's the entire point. heck, g is not even a constant, it just happens to measure to roughly 9.8 m/s² at most places around here. reply john-aj 2 hours agoparentprevI agree. But if you remove the \"so\", there is no contradiction. It is possible the author used \"so\" not to mean \"in other words\", but simply as a relatively meaningless discourse marker. reply mistercow 2 hours agorootparentHuh, interesting point. Writing unambiguously is ridiculously hard. reply anon457437 1 hour agorootparentThe comma differentiates. The comma indicates a short pause and a certain intonation in speech (the period means a longer pause and a different intonation). If you say that sentence with and without a pause/comma, you'll see (hear) that the sentence is correct. Reading unambiguously is also hard. reply mistercow 1 hour agorootparentThe problem with that is that writers are not consistent with comma usage either, particularly when it comes to informal writing, where prescriptive rules are out the window anyway. And I would argue that it would be a bit of a norm violation even in informal writing to introduce this new point at the end of a paragraph rather than starting a new one, which makes me think that that was not the author's intent. reply arcastroe 3 hours agoparentprevI'm surprised at the number of people disagreeing with your quibble. I had the exact same thought as you! If pi^2 were _exactly_ g, and the \"magic\" disappeared in different units, THEN we could say \"so this is no coincidence\" and we could conclude that it has to be related to the units themselves. But since pi^2 is only roughly equal to g, and the magic disappears in different units, I would likely attribute it to coincidence if I hadn't read the article. reply mjburgess 2 hours agorootparentIt would be useful if people carried around some card with all the information that they understood on it, since opinions are largely symptoms of this. In almost all cases any apparent phenomenon specific to one system of measurement is clearly a coincidence, since reality is definable as that which is independent of measurement. reply twojacobtwo 2 hours agorootparent> since reality is definable as that which is independent of measurement. In terms of quantum mechanics, would that mean the wave function is real until it collapses due to measurement? Or am I misunderstanding your use of measurement there? Something about that is sticking in my mind in an odd way, but I can't put my finger on exactly what it is - which is intriguing. reply mjburgess 1 hour agorootparentMeasurement can change what is measured, but it doesnt change it from illusion to reality. I cannot measure santa clause into existence. But I can change the temperature of some water by measuring it with a very hot thermometer. That measurement changes what is measured is the norm in almost all cases, except in classical physics which describes highly simplified highly controlled experiments. The only 'unusual' thing about QM is its a case in physics where measurement necessarily changes the system, but this is extremely common in every other area. It is more unusual that in classical physics, measurement doesn't change the system. reply phkahler 4 hours agoparentprevDoesn't the relationship hold if we change units? It seems like it must. When I worked with electric water pumps I loved that power can be easily calculates from electrical, mechanical, and fluid measurements in the same way if you use the right units. VoltsAmps, torquerad/sec, pressure*flow_rate all give watts. reply eigenket 4 hours agorootparentNope, it completely vanishes in other units. If you do all your distance measurements in feet, for example, the value of pi is still about 3.14 but the acceleration due to gravity at the earth's surface is about 32 feet s^(-2). If you do your distance measurements in furlongs and your time measurements in hours then the acceleration due to gravity becomes about 630,000 furlongs per hour squared and pi (of course) doesn't change. reply ValentinA23 4 hours agorootparentOnly because you're using metric seconds instead of \"imperial seconds\" (the time it takes for a 1 foot long pendulum to complete a full oscillation). reply eigenket 3 hours agorootparentSure, if you change either of the units you can always change the other one to fix the equation again. reply mannykannot 3 hours agorootparentprevThis is not quite the same situation, as you are calculating a value having a dimension (that of power, or energy per second) three different ways using a single consistent system of units, and getting a result demonstrating / conforming to the conservation of energy. If you were to perform one of these calculations in British imperial units (such as from pressure in stones per square hand and rate of flow in slugs per fortnight) you would get a different numerical value (I think!) that nonetheless represents the same power expressed in different units. The article, however, is discussing a dimensionless ratio between a dimensionless constant and a physical measurement that is specific to one particular planet. reply usaar333 3 hours agorootparentprevNo, the equality requires the length of a 2 second period pendulum be g / pi^2. Change your definition of length - that no longer holds true. g in imperial units is 32 after all. g has units; pi does not reply phkahler 1 hour agorootparentThe equation holds in imperial units as well. The length of the 2 second pendulum needs to be in feet AND the value of g in ft/sec2. reply lupire 3 hours agorootparentprevA more natural way to say it is that equality requires that the unit of length is the length of an arbitrary pendulum and the unit of time is the half-period of the same pendulum. The pendulum is a device that relates pi to gravity. reply yunohn 13 minutes agoparentprevI don’t agree with this. You could literally redefine any unit (as we have done so multiple times in the past) and end up with zero “coincidences”. IMHO It’s perfectly valid to stick to one measurement method. reply throwawayk7h 1 hour agoparentprevyou can rule that heuristic out immediately because pi is unitless, surely? reply msteffen 3 hours agoparentprevIt’s really the best and only way to find non-coincidences involving the definition of units, though. All such non-coincidences will have this property reply mistercow 3 hours agorootparentAll coincidences involving the definition of units will also have this property. Once you’ve narrowed to that specific domain, invariance to change of units is completely uninformative. reply lupire 3 hours agoparentprevThe \"magic\" doesn't disappear in \"any\" other units. Period = 2π√(length/g) So the \"magic\" holds in any units where the unit of time is the period of a pendulum with unit length. reply blablabla123 5 hours agoparentprevChanging units in Electrodynamics for instance comes with unexpected factors in formulas though, indeed containing π. (CGSSI) reply HPsquared 5 hours agorootparentIsn't that just the change between rad/s and Hz? reply setopt 2 hours agorootparentIt’s more precisely the difference between “rationalized” and “unrationalized” units. You need a factor 4pi in either Gauss’ law or Coulomb’s law (because they are related by the area 4pi*r^2 of a sphere), and different unit systems picked different ones. It’s more akin to how you need a factor 2pi in either the forward or backward Fourier transform and different fields picked different conventions. reply vitus 57 minutes agorootparent> It’s more akin to how you need a factor 2pi in either the forward or backward Fourier transform and different fields picked different conventions. Some fields even use the unitary transform -- they split the difference and just throw in a 1/sqrt(2pi) in both directions. https://en.wikipedia.org/wiki/Fourier_transform#Angular_freq... reply elashri 3 hours agorootparentprevIt is more involving [1] [1] https://phys.libretexts.org/Bookshelves/Electricity_and_Magn... reply glitchc 3 hours agoparentprevYour quibble seems nitpicky and unwarranted. What the author is saying is that the relationship becomes evident if we consider the units of m/s^2 for gravity. They just didn't quite say it like that. reply mistercow 3 hours agorootparentObviously it’s nitpicky. That’s what a quibble is. But I don’t think it’s unwarranted. How you reason your way to a conclusion is at least as important a lesson as the conclusion itself. And in this case, the part I quoted is a bad lesson. reply gklitz 2 hours agoparentprevWhat? The entire point is that it’s no coincidence in this unit set. Saying that changing units indicates a coincidence is like saying that if we see Trump suddenly driving a Tesla after Elon stated throwing money at him, that must be just a coincidence because if we change the car model to a ford then there would be nothing odd about it. reply mistercow 2 hours agorootparentThat analogy is so bizarre that I have no idea how to respond to it. reply BrandoElFollito 6 hours agoprevAs a physicist, this makes sense. Pi = 3, pi^2 = 10, which is g Not sure why everyone is surprised. Ah, and a year is pi*10e9 seconds (IIRC) reply fouronnes3 5 hours agoparentAs a computer scientist this is not surprising either. After all there are only three numbers: 0 1 and n. reply jeffwass 5 hours agorootparentOne of my old physics professors said something similar - there are only three numbers in the world - 0, 1, and infinity. No wait, zero is just one divided by infinity, so there are only two numbers, zero and one. So if the answer is not zero, it must be one. (ie, how to justify dimensional analysis and ignore any dimensionaless constant). Hysterical, especially for the fact that he quotes 'two' and 'three' in the sentence itself. reply klabb3 2 hours agorootparentAnother one would be philosophy: there’s nothing, something and everything. Or logic: ∃, ¬∃ and ∀. Just rambling here, but seems like universal concepts across fields. reply john-aj 2 hours agorootparentChiming in from theoretical linguistics: it is impossible for natural languages to \"count\", i.e. make reference to numbers other than 0, 1 or infinity. As an example, there are languages where prenominal genitives are impossible (0). Then, there are languages, such as German, where only one prenominal genitive is possible (1): > Annas Haus > *Annas Hunds Haus Finally, there are languages, such as English, where an infinite number of prenominal genitives are possible (infinity). > Anna's house > Anna's dog's house > Anna's mother's dog's house > Anna's mother's sister's ... dog's house But there are no languages where only two or three prenominal genitives are possible. This property is taken to be part of Universal Grammar, i.e. the genetic/biological/mental system that makes human language possible. reply imoverclocked 2 hours agorootparentprevHe already got rid of \"three\" and just needed a little help to get rid of \"two.\" Since we already have 0 and (almost) everything else can just be \"one more\" than something else, we only need 0 and one more ... or 1. One and Done! reply pansa2 5 hours agorootparentprevRemember that `i` is also a number. As in `for i = 0 to n`. Don’t believe those mathematicians when they tell you that `i` is “imaginary”. reply Anarch157a 5 hours agorootparentAll numbers are imaginary. sqrt(-1) should have been called w, for \"weird\". reply syockit 4 hours agorootparentI use w for the complex roots of 1 though, when rewriting FFT notes. reply 360MustangScope 5 hours agorootparentprevYou mean the legendary “i”. There is no n. reply ithkuil 3 hours agorootparentprevAnd -0 and NaN reply HPsquared 5 hours agorootparentprevAnd int_max reply Maken 4 hours agorootparentThat's a implementation detail. reply de_nied 5 hours agorootparentprevYea if you're some classical snob. - Posted by the quantum gang reply radiator 5 hours agoparentprevAs a physicist? When we did physics at school, and we were solving problems, the answer was always a number together with its unit. pi² might be 10 because it is a pure number, but g can never be 10, because it is an acceleration, a physical quantity, so it must be 10 of some unit. reply BrandoElFollito 2 hours agorootparentOh, come on, it is inches / (day * \"hold on\"). Everyone knows this, this is physics for art majors 101. In guess it's a good thing I left physics after my PhD. reply bmacho 5 hours agorootparentprevNot if you define g as the real number before m/s^2, in the expression '10 m/s^2'. In middle school physics lessons this makes teachers to hate you (it's their job to ensure that you do not do this), but after that, this has advantages time to time. .. I remember hearing an anecdote that ancient Greeks did not know that numbers can be dimensionless, and when they tried to solve cubic equations, they always made sure that they add and substract cubic things. E.g. they didn't do x^3 - x, but only things like x^3 - 2*3*x. I don't think this is true (especially since terms can be padded with a bunch of 1s), but maybe it has some truth in it. It is plausible that they thought about numbers different ways than we do now, and they had different soft rules that what they can do with them. reply CoastalCoder 5 hours agoparentprevI assumed the pi / g connection was because cows that accelerate in a vacuum are spherical. reply Sharlin 2 hours agorootparentAccording to the Banach–Tarski paradox, if you accept the Axiom of Choice, you can disassemble a spherical cow and put the parts back together such that you end up with two cows of the original size. How exactly this affects Cow Economics is not well-understood. reply openrisk 4 hours agorootparentprevI think it was Gauss who proved that any convex cow would work equally well. But we need to assume an infinitesimally thin and infinitely long tail as boundary condition. reply sa46 4 hours agoparentprevPi seconds is a nano-century. So 1 year = pi*10^7 seconds reply leoff 3 hours agoparentprevas a mechanical engineer, can confirm. also, e ≈ pi ≈ 3 reply remuskaos 3 hours agoparentprevA year is pi 10^7, or pi 1e7. On the other hand, 10 e9 = 10 * 10^9. reply Sharlin 2 hours agoparentprevThe pi in pi*10^9 seconds clearly comes from the fact that Earth’s orbit is circular. reply maxnoe 32 minutes agorootparentNore sure if serious or not, but anyway: 1) it isn't circular, although just barely (it's an ellipse) 2) the length of the day is not really related to the length of a year, and the second was defined as 1 / (24 * 60 * 60) = 1 / 86400 of the mean solar day length So this is really just a coincidence, there is no mathematical or physical reason why this relationship (the year being close to an even power of 10 times pi seconds) would exist. reply Sharlin 5 minutes agorootparentDefinitely not serious :) But from the fact that an Earth year happens to be roughly pi*10^7 seconds long, it follows that in 10^7 seconds Earth travels about two radians, or one orbital diameter, and equivalently that the diameter of Earth's orbit is roughly 10^7 seconds times Earth's orbital speed. reply hyperhello 5 hours agoparentprev3600 seconds per hour, times 3*8 is only about 80,000 seconds a day. You can’t get to a billion from there. reply exe34 6 hours agoparentprevpi * 1e7 reply lutusp 1 hour agoprevAnother \"wonderful coincidence\" is that the conversion between miles and kilometers involves this constant of conversion : kilometers = miles * 1.609344. Let's call 1.609344 the \"km\" constant. As it happens, km is very close the the Golden Ratio (sqrt(5)+1)/2 = 1.618033989... (call this \"gr\"). In fact they only differ by about 1/2 of one percent (100 * (gr/km - 1) = 0.54%)! As the author of the original article says, \"If you express this value in any other units, the magic immediately disappears. So, this is no coincidence ...\". Yeah ... wait, what? Here's another one. Pi (3.141592654...) is nearly equal to 4 / sqrt(gr) (3.144605511...), call the latter number \"ap\" for \"almost pi\". This connects pi to the golden ratio, and they differ by only 0.096% (100 * (pi/ap - 1)). Surely this means something -- doesn't it? Finally, my favorite: 111111111^2 = 12345678987654321. This proves that ... umm ... wait ... reply maxnoe 37 minutes agoparentA year is very close to pi * 1e7 seconds, better than half a percent. reply areyousure 1 hour agoparentprevln(5) ~ 1.6094379 is much closer, differing by about half of a percent of a percent. reply 29athrowaway 1 hour agoparentprevThe best is sum(1, 36) reply philzook 5 hours agoprevI've got a related one I like. Why are the Avogadro's number and Boltzmann's constant inverses of each other N ~ 1/k? The statement doesn't make sense because the units don't work out, but it is true in mks. It's because they multiply to the gas constant which is ~1. They both are numbers to transfer from the microscopic to human scale units and they cancel for the gas constant, which is about human scale experience of gases. reply bonzini 5 hours agoparentBut it's a coincidence, right? N*k=8.31 is pressure*volume/temperature for a mole of gas. Temperature has a relatively small range (100-1000) and there's no reason why the range of P*V couldn't be far from that range, for example 0.01–0.1, with a different definition of meter, second or kilogram. reply lupire 4 hours agorootparentMeter, second, and kilogram were all chosen to be approximately the scale of a human, and the combined multiplicative units like Pascal, m^3, and Kelvin/Celsius are also numerically 1 in these units. reply Someone 3 hours agorootparent> Meter, second, and kilogram were all chosen to be approximately the scale of a human, “Approximately the scale of a human” leaves so much wiggle room that I don’t see how one can defend that claim. > and the combined multiplicative units like Pascal You don’t explicitly claim it, but I wouldn’t say the Pascal is “Approximately the scale of a human”. Atmospheric air pressure is about 10⁵ pascal, human blood pressure about 10⁴ pascal, and humans can very roughly produce about that pressure by blowing. reply Ekaros 1 hour agorootparentWhich is why I have always kinda hated kilogram. Such an ugly unit for it having prefix. Grav should have been correct answer, but instead we ended up with something that is too small... That is in reality gram. For grams we could simply have milligravs or decigravs for 100g equivalents... Not that hard considering decilitres are used and decimetres are kinda tried in schools. reply HuangYuSan 3 hours agoparentprevFunnily Avogadro's constant is actually equal to 1: it's defined as Avogadro's number times mol, but mol is itself a dimensionless quantity equal to the inverse of Avogadro's number. reply aaaronic 2 hours agorootparentMultiplying by increasingly complicated expressions equivalent to “1” is what I remember doing for almost every problem in Quantum Mechanics. reply vessenes 6 hours agoprevAwesome write up and a great surprise in the history of the definition of the meter. Reading this reminds me a little of mathematicians like Ramanujan who spent a fair amount of time just playing around with random numbers and finding connections, although in this case, I imagine the author knew the history from the beginning. Anyway, I feel like my math degree sort of killed some of that fun exploration of number relations — but I did like that kind of weird doodling / making connections as a kid. By the time I was done with the degree, I wanted to think about connections between much more abstract primitives I’d learned, but it seems to me there are still a lot of successful mathematicians that work this way — noticing some weird connection and then filling out theory as to why, which occasionally at least turns out to be really interesting. reply julienchastang 4 hours agoprevRelatedly, I recommend reading \"The Measure of All Things\" by Ken Alder about the origins of the metric system and the first scientific conference ever. It is a surprisingly gripping read. https://www.simonandschuster.com/books/The-Measure-of-All-Th... reply fireattack 1 hour agoprevTotally unrelated to the content, but about the website itself. The site completely breaks when I visit it. After some investigation, I found out that if I enable Stylus (a CSS injection extension) with any rules (even my global ones), the site becomes unusable. Since it's built using the React framework, it doesn't just glitch; it completely breaks. After submitting a ticket and getting a quick response from the Stylus dev, it turns out that this website (and any site built with caseme.io) will throw an error and break if it detects any node injected into ``. [1] https://github.com/openstyles/stylus/issues/1803 reply gpvos 1 hour agoparentI don't currently use Stylus, but it breaks for me too; it looks like CSS isn't applied at all: I get some big logo images, and the text uses standard fonts. Not sure which extension triggers it, probably Dark Reader. I could still read it, so no biggie. reply notfed 1 hour agoprevAnother wonderful coincidence: - Speed of light: 299,792,458 m/s - Great Pyramid of Giza: 29.9792458°N reply Ekaros 1 hour agoprevUnderlying idea of whole metric and SI system is the real start point. You want to define some units that you can easily replicate. Time is reasonable enough one, measure and track length of day and then length of second. Now based on this figure out way to come up with replicable definition for distance, pendulum is good enough gravity is constant enough. Thus linking gravity and meter arises. From here you can define lot of other units like mass and Volt and Ampere... Everything comes from second which is weird, but does make lot of sense. reply frankus 1 hour agoprevAnother interesting coincidence (or perhaps a decades-long dad-joke troll perpetrated by German-speaking scientists) is that 1 hertz is roughly equal to the frequency at which a human heart (“Herz” in german, with a nearly indistinguishable pronunciation to “Hertz”) beats. reply EasyMark 4 hours agoprev> Sometimes that was even useful. If you needed to buy more cloth, you'd call the tallest person in the village and have them measure the fabric with their cubits. I highly doubt this bit of strategy would have worked with sellers of said fabric. They may have not had formal measurements but they weren't stupid either. reply kthejoker2 3 hours agoparentI find this comment delightfully ironic in a contemporary moment of blatant shrinkflation. reply bravura 2 hours agoprevPhilosophy time: Does this mean in 400 years it's possible we no longer disagree about how to evaluate things? i.e. we converge on one totalitarian utility function that everyone basically accept answers every possible trolley dilemma? In 1600, people just took the world as that: measurements are sloppy, and vary culturally and based upon location etc. But we eventually came upon tools and techniques that are broadly accepted as repeatable and standard. Would this sort of shift be possible? Or desirable? reply sycren 5 hours agoprevIf the definition of the meter is still wrong disallowing π² = g, how might this affect other calculations like for example thrust and in aerospace engineering? reply kseistrup 4 hours agoparentAnd what would all other natural constants look like, had the meter kept the value derived from the length of the pendulum? reply levzettelin 6 hours agoprevHe wouldn't be speaking like this if he was born on Mars. reply edflsafoiewq 6 hours agoparentSure he would, the meter would just be a different length. reply Maxatar 3 hours agoparentprevI thought they key insight of this article was if he were born on Mars, then the meter would have been defined differently so that gravity would still be 9.8 m/s^2. I think what you meant to say was that he wouldn't be speaking like this if people were born with 3 fingers. reply baxtr 6 hours agoparentprevFinally an easy way to identify aliens! reply samstave 3 hours agorootparentHow? Because they don't have a Venus? reply alfiedotwtf 5 hours agoparentprevThe pendulum from the Mars pole to Paris would be long indeed! reply pclmulqdq 2 hours agoprevMore fun arithmetic coincidences: https://en.m.wikipedia.org/wiki/Almost_integer Some of these are test vectors for math systems. reply rich_sasha 3 hours agoprevThis is neat, but still something if a coincidence. It appears the first definition of a metre is in fact around 1/4e10 the circumference of Earth, and the further coincidence is that a 1m mathematical pendulum has a period of almost exactly 2 seconds. So there's still a neat relationship between mass/radius of Earth, its diurnal rotation period and the Babylonian division of it into 86,400 seconds. reply owisd 2 hours agoparentAccording to the article the 1/4e10 circumference definition came second reply rich_sasha 2 hours agorootparentWikipedia says the Earth circumference definition comes from around Copernican times. Also my reading of TFA is that the pendulum definition was in fact a redefinition that didn't catch on. reply otterley 1 hour agoprevThis post feels like one of those cork boards with photos and strings connected between them in some prepper’s basement, but in blog post form. reply xxmarkuski 4 hours agoprevI remember in mechanical engineering class we would often use this for exercise sheets. On our calculator we could directly enter π and ², thus it was equally as fast to entering 10. reply imoverclocked 2 hours agoparentThat's one way of setting up a standard deviation! reply shubhamjain 5 hours agoprevWhat an amazing post! Such an interesting investigation. These kinds of write-ups make me realize how truly far we are from AGI. Sure, it can write amazing code, poems, songs, but can it draw interesting conclusions from first principles? I asked both ChatGPT and Claude, the same question, and both failed at pointing out the connection the author states. This is not to deride feats of AI today, and I am sure it will transform the world. But until it can show signs of human ingenuity in making unexpected and far-off connections like these, I won't be convinced we are nearing AGI. reply avaldez_ 5 hours agoparent> Sure, it can write amazing code, poems, songs, but can it draw interesting conclusions from first principles? Can you? https://youtu.be/KfAHbm7G2R0?si=oAPrNGylo7pUcRMZ reply air7 5 hours agoparentprevArguably most humans can't do this either. reply spacebacon 5 hours agoprevI laughed 3 times reading this article while pondering the novelty of standardization. Is standardization the sans-serif of civilization? reply otabdeveloper4 6 hours agoprev> was actually proposed back in the 17th century Pretty sure it was done back in Sumer first. reply ValentinA23 4 hours agoparenthttps://www.ukbiblestudents.co.uk/Great%20Pyramid/chapter%20... >“It was contended,\" says Dr. Peacock, \" by Paucton, in his Mẻtrologie, that the side of the Great Pyramid was the exact 1/500th part of a degree of the meridian, and that the founders of that mighty monument designed it as an imperishable standard of measures of length. https://www.theguardian.com/science/2020/dec/06/revealed-isa... >Newton was trying to uncover the unit of measurement used by those constructing the pyramids. He thought it was likely that the ancient Egyptians had been able to measure the Earth and that, by unlocking the cubit of the Great Pyramid, he too would be able to measure the circumference of the Earth. reply karmakurtisaani 5 hours agoparentprevA standard free measure for distance? Sounds dubious. reply otabdeveloper4 5 hours agorootparentNo. The other way around. Two seconds is the period of a pendulum with a length of two Sumerian cubits. (One meter is thus two Sumerian cubits, but that's an artifact due to us still using Sumerian time measurements.) P.S. I don't know why Sumerians used a factor of two. Americans still divide the day into two 12 hour spans, according to Sumerian fashion. P.P.S. One second is 1/(2*12*60*60) of a solar day. 12 and 60 were \"round numbers\" in Sumer; they used sexagesimal counting. reply Maken 4 hours agorootparentProbably because 12 is a much better base than 10. 12 can be divided by 2, 3, 4 and 6 and still results in whole numbers, which helps a lot when doing rounding and fraccional numbers. The only reason we use base 10 is because is much easier to count with our fingers. reply karmakaze 4 hours agoprevMight be interesting if were true in Planck units. But also 2Pi is fundamental, who defines a ratio of something to 2 of something (radius)? reply rvbissell 4 hours agoparentNo, Tau is fundamental. Pi only exists because someone mistakenly thought the formula for circumference involved diameter, when in fact it involves radius. (\"Quit factoring a 2 out of Tau!\" I tell them.) reply mistercow 9 minutes agorootparentEh, you can find plenty of cases where tau is just as awkward as pi is elsewhere. Right off the bat, the area of a circle becomes more awkward with tau, becoming (tau*r^2)/2, and in general, the volume of an n-ball gains weird powers and roots of two in its denominator as n increases if you switch to tau. In general, I don't think you can really claim either one is \"more fundamental\". It's just a matter of framing. reply breck 6 hours agoprevVery interesting! So if I understand correctly: the meter was defined using gravity and π as inputs (distance a pendulum travels in 1 cycle), so of course g and π would be connected. reply fweimer 5 hours agoparentOn the hand, g is about 32.2 ft/s². So it's suddenly related to π³? I think there's no connection at all, it's just an accident. It would be really weird if some contemporary property of the earth were actually related to a fundamental mathematical constant. It's similar to finding a message among the digits of π that shouldn't be there, statistically speaking. reply cvoss 4 hours agorootparentThe bulk of the article is devoted to explaining that g = pi^2 in m/s^2 units (under an old definition of meter) because (that definition of) the meter was not selected arbitrarily, but selected in a way that makes the equation hold on purpose. reply renewiltord 1 hour agoprevHence the 2√l formula for the pendulum haha reply textlapse 3 hours agoprevI wonder if this is how astrology was born. You can draw arbitrary connections between things if you stare at them long enough. reply dweekly 5 hours agoprevLink is broken for me? \"[ErrorBoundary]: There was an error: {}\" reply roitman 5 hours agoparentTry refreshing the page reply im3w1l 5 hours agoprevI knew that historically meter was related to the size of the earth somehow, but I had never had about the pendulum definition! reply ValentinA23 4 hours agoprevOkay so this one has an explanation. But what about these ? https://en.wikipedia.org/wiki/Mathematical_coincidence See also this blog: https://martouf.ch/tag/coudee-royale-egyptienne/ One french royal cubit ≈ one egyptian cubit ≈ about π/6 meters. One royal span ≈ 1/5 meter = 20cm. I'm wondering whether some of these coincidences could be explained by the anthropic principle, which deals with these quasi-equalities, for instance: >An excited state of the 12C nucleus exists a little (0.3193 MeV) above the energy level of 8Be + 4He. This is necessary because the ground state of 12C is 7.3367 MeV below the energy of 8Be + 4He; a 8Be nucleus and a 4He nucleus cannot reasonably fuse directly into a ground-state 12C nucleus. However, 8Be and 4He use the kinetic energy of their collision to fuse into the excited 12C (kinetic energy supplies the additional 0.3193 MeV necessary to reach the excited state), which can then transition to its stable ground state. According to one calculation, the energy level of this excited state must be between about 7.3 MeV and 7.9 MeV to produce sufficient carbon for life to exist, and must be further \"fine-tuned\" to between 7.596 MeV and 7.716 MeV in order to produce the abundant level of 12C observed in nature. Source: https://en.wikipedia.org/wiki/Triple-alpha_process#Improbabi... The idea goes like this: 1. A more fundamental aspect under the anthropic principle which underpins the existence of complex life and intelligent observers is the quasi-alignment of values such as the fundamental constants in physics within a short margin. 2. If you consider the universe to be the product of a random sampling process over these constants (either real or virtual, it occurred many times or just once), and given the fact we exist, which implies an abundance of coincidences, the maths seem to tell us that we should expect to observe superfluous coincidences that are non-functional for the appearance of complex life, rather than the strictly minimal set of functional coincidences necessary for its emergence. 3. This implies that coincidences and pattern seeking are not just features (or bugs) of our complex minds but are present in the universe latently since it is not just fine-tuned for the emergence of complex life but for the presence of coincidences such as these https://medium.com/@sahil50/a-large-numbers-coincidence-299c.... 4. It may be even testable by running computer experiments relying on genetic programming/symbolic regression to see whether there is something special about the value of physical constants in our universe when compared to the value they would have in other universes. I think such experiments should factor the fact that not all equations with the same mathematical complexity (number of operands and operators) have the same cognitive complexity. Indeed, if you look at the big equation in the link above, you'll remark that it can be further compressed into a/b = c/d (where a is the photon redshift radius for instance). So I guess you'd also have to throw into the mix Kolmogorov algorithmic complexity to assess this aspect (which is in fact used in some cognitive theories of relevance to tackle this kind of stuff to the tune of \"simpler to describe than to generate\") Thoughts ? reply thaumasiotes 6 hours agoprevg is related to the radius of the earth; the meter is related to the circumference of the earth; and pi is the relationship between the radius and the circumference. reply mistercow 4 hours agoparentAside from the fact that the post already explained what the actual historical connection is, your explanation requires some serious hand-waving about the mass of the Earth and the gravitational constant, neither of which were known when the meter was first defined. reply ahmedfromtunis 5 hours agoprevnext [6 more] [flagged] IHLayman 5 hours agoparentI disagree… the article talks about defining the meter using the pendulum and the second. Other planets would have their own definition of second, but not their own definition of pendulum. Since one meter is prescribed though a pendulum because of the oscillation formula and dependent on the frequency alone (in this case, 2 seconds), no matter what planet you are on, how strong gravity, is or how long a second is, the pendulum describes a relationship between seconds and meters such that if using this method a planet’s scientists would always define their units such that acceleration of gravity was eerily equal to pi^2. Makes me think of possible lunar scientists unwittingly making their meter 5/6th shorter(edit: english is hard) and then marveling at the same coincidence… reply soulofmischief 4 hours agoparentprevYour comment is much more rage-bait than the article. Universal isn't a way we describe numbers. You meant to say dimensionless. Pi is dimensionless constant because it describes a relationship between two measurements of a dimensionless unit circle. Pi is expressed as a pure ratio between two other dependent numbers. Dimensionless values are special because they don't rely on any particular measurement in any particular location, lending to your misconception of \"universal\" constant. This article explains how a particular dimensionful constant (g, the strength of gravity on earth's surface) is related to pi. They are related because the dimensions in question are both derived from dependent properties of our planet. These dependent properties will be found on any other sphere floating in space if they are derived in the same fashion. It's good to thoroughly or even marginally understand a topic before adopting a dismissive and authoritative argument against it. reply jameshart 5 hours agoparentprevOn any planet where you want to define a system of units, you can start by defining a fixed time period (maybe use a fraction of the planetary rotation cycle or something), then make a pendulum that swings with that frequency, and derive a unit of distance from its length. The local value of g will be roughly pi squared pendulum lengths per tick squared, in that system of measurement. reply drexlspivey 5 hours agoparentprevIf you read the article you would see that it’s not a coincidence because the meter was defined such that pi^2 = g at the surface of the earth. reply mjfisher 5 hours agoparentprevNope, it's not a coincidence - it's an interesting exploration of the history of the definition of a metre. Read the article. As it says, at some point there was an attempt to standardise the length of a metre in terms of a pendulum's length; which related it directly to g through Pi. reply karmakaze 4 hours agoprevNumerologists unite! reply alberth 5 hours agoprevNo mention of ‘meter’ being the unit of measurement, make this like saying 3:14pm is related to pi. There’s no correlation between a continuous number and a unit of measure. That’s truly apples to oranges comparison. g can easily be expressed in ‘feet’ as ~32.1 ft/s^2 reply mistercow 4 hours agoparentWhat do you mean by “no mention”? The entire article is about why this is specifically due to how the meter was first defined. reply kwhitefoot 5 hours agoprevIt isn't equal to g even in SI units except at some very few spots on the surface of the earth. Change the units to any other system and it's not even roughly true. Edit: Now that i have read the article i see that it is no coincidence at all that it is close the pi squared. very interesting. reply jds-67 5 hours agoprev [–] Sorry to ruin the party, but g is a quite random number, on other planets the corresponding acceleration is different. So π^2~g is a pure coincidence and not relevant. The Newtonian gravitational constant G is a real constant btw. reply gpvos 5 hours agoparentHave you read the article? The point is that the definition of the metre, which is used in g, originates from the length of a pendulum that swings once per second in the gravity field around Paris. So it is a matter of definitions, and the length of the metre originates from the duration of the second and the Earth's gravity field. The definitions of 1/40.000 of the Earth's circumference or ~1/300.000.000 of a light second came later. reply ccvannorman 5 hours agorootparentMy intuitive assumption, then, is that on Mars they would have come up with a different meter such that π² ≈ 10 \"mars meters\" / s². Or alternatively stated, that the Mars meter would be much shorter than Earth's meter if they used the same approach to defining it (pendulums and seconds). reply ValentinA23 4 hours agorootparentA Martian meter defined by martians should relate their average size, the number of fingers they have on their hands and some basic measure of the planet. I mean, one meter is defined as 1/10^7 of the distance between the equator and the poles which leads to a round number in base 10. A unit system is not just something that matches objective reality but something that has some cognitive ergonomy. reply michaelrpeskin 4 hours agorootparent> A unit system is not just something that matches objective reality but something that has some cognitive ergonomy. Beautifully stated! And that's one reason why I like the US units of measurement better than SI. I mean, the divide-by-ten thing is nice and all. But _within a project_ how often are you converting between units of the same measurement (e.g, meters to centimeters)? You pick the right \"size\" unit for your work and then tend to stay there. So you don't get much benefit from the easy conversion in practice. But if you're doing real hands-on work, you often need to divide by 2, 3, 4, and so on. So, for example, having a foot easily divisible by those numbers works well. And even the silly fractional stuff make sense when you're subdividing while working and measuring. Of course it all finally breaks down when you get to super high precision (and that's probably why machinists go back to thousands of an inch and no longer fractions). I think there's a little bit of academic snobbery with the SI units (though, it is a good idea for cross-country collaboration), but for everyday hand-on work the US system works really well. I always love the meme: There are two kinds of countries in the world, those who use the metric system and those who've gone to the moon. I'm an AMO physicist by training and my choice of units are the \"Atomic Units\" where hbar, mass of the electron, charge of the electron, and permittivity are all 1. That makes writing many of the formulae really simple. Which is what you say: it has cognitive ergonomy (and makes all of the floating point calculations around the same magnitude). Then when we're all done we convert back to SI for reporting. reply bialpio 2 hours agorootparentOne example where picking units within a project is still not saving you from cognitive load is e.g. when doing woodworking. Ymmv, but I can add decimals way faster than I can add 7 9/16\" + 13 23/32\" (numbers picked arbitrarily but close to a precision of 1mm so if you are ok w/ that precision, you don't even need fractions in SI). reply jds-67 3 hours agorootparentprevI have to admit I only read half of the article. Even if there is some historical fact there (but it was not mentioned at the beginning of the article), from a physical standpoint this comparison is already dimensionally wrong and also coincidentally only correct if you choose appropriate units. That was the point I was trying to make. There is not anything \"deep\" here. reply kbelder 38 minutes agorootparentHow strange. \"I only ran the first half of the program, but it didn't seem to give the correct answer, so it's obviously broken.\" \"I only read the first half of the proof, but the answer wasn't contained there, so I'm forced to conclude the proof is worthless.\" You simply gave up before encountering the mathematical reason the relationship exists, why the units are different, and so on. You just ran with your incorrect initial assumption. reply gpvos 1 hour agorootparentprevI admit I scanned the article first and wondered what it was all about. The actual argument is not very clearly presented. reply shermantanktop 2 hours agorootparentprevI’d suggest fully reading the article. reply sidpatil 5 hours agoparentprevIt's not about the values, but the units of measurement. g is in units of meter/second^2. The article discusses the dependency of the meter's original definition on the value of pi. reply beardyw 5 hours agoparentprev [–] You are correct but the point is the way the meter is calculated, g in meters per second should come to pi squared. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "π² (approximately 9.87) and the acceleration due to gravity, g (9.81 m/s²), are intriguingly close in value, but not exactly equal.",
      "The discrepancy arises from historical changes in the definition of the meter, which has evolved from human-based measurements to a precise scientific standard based on the speed of light.",
      "The near-equality of π² and g is not a mere coincidence but a result of historical and scientific developments in measurement standards."
    ],
    "commentSummary": [
      "The discussion explores the relationship between π² (pi squared) and g (gravitational constant), questioning if it's coincidental or expected.",
      "Historical context is provided, noting that the meter was originally defined based on a pendulum's length, inherently linking it to gravity and π.",
      "Opinions vary, with some suggesting the relationship is coincidental due to unit changes, while others argue it's a deliberate connection due to the meter's definition."
    ],
    "points": 267,
    "commentCount": 173,
    "retryCount": 0,
    "time": 1723292694
  },
  {
    "id": 41205176,
    "title": "Urchin Software Corp: The unlikely origin story of Google Analytics (2016)",
    "originLink": "https://urchin.biz/urchin-software-corp-89a1f5292999",
    "originBody": "Urchin Software Corp. The unlikely origin story of Google Analytics, 1996–2005-ish Scott Crosby · Follow Published in Urchin Software Corp. Vault · 23 min read · Sep 2, 2016 -- 24 The first Urchin logo (Jason Collins) TL, DR: Urchin Software Corporation was a web analytics company based in San Diego, CA. The founders of the company were Paul Muret, Jack Ancone, Brett Crosby, and Scott Crosby (yours truly). In April 2005 the company was acquired by Google, and the Urchin product became “Urchin from Google,” then later simply Google Analytics. As the 10th anniversary of the acquisition has recently passed, I thought it was a good time to get the history of the company down for posterity. I don’t expect this to be a riveting read for those not directly involved; it’s more of my attempt to close the book on that era. And maybe, if nothing else, I guess it suggests that despite the soup du jour — huge seed/A rounds, massive valuations, binary outcomes— you can sometimes do alright by just taking less money and more time. Our first day at Google, April 21, 2005. Brett was on his honeymoon! T he predecessor to Urchin Software Corp. was originally started by Paul Muret and Scott Crosby (me) in late 1995. Prior to then, Paul had been working in the Space Physics dept. at UCSD, where he was exposed to HTML 1.0 after being tasked with putting the department’s syllabus online. Paul and I were post-college roommates at the time, living in the Bay Park neighborhood of San Diego. One night Paul came home from work and announced that he saw a business opportunity in building websites for businesses. To prove the point, he showed me his bright-blue-text-on-grey-background site for UCSD. Maybe some of the text even ed. I agreed and we started work on a business plan. This was presented to my proverbial rich uncle (Chuck Scott), who agreed to invest $10,000 in the “company” and provide a desk in a corner of his office at C.B.S. Scientific. It would be quite awhile until he saw a return on that money. Our first webserver, running at 50 mhz, was ~$3200 in 1995 money. That was about 1/3 of our total raised capital to-date. Armed with Chuck’s cash, the new company bought a Sun SPARC 20 for webserving duty and procured a then-very-expensive ISDN line. Ever heard of “10base2”? That’s how our office computers were networked — coaxial cable with fun twist-lock fittings, kinda like TV cable. Antiquated. Anyway, Paul and I then set about acquiring customers, which we slowly accomplished. Most were small businesses paying a modest monthly fee, like Cinemagic, a vintage movie-poster company run by a couple named Herb and Roberta. Or ReVest, a financial startup whose owner didn’t “do” email, so all edits to his site were communicated via thermal-transfer fax, which spooled out onto our floor for 6 or 8 pages every morning. Another was an obscure division of Pioneer Electronics that specialized in the even-then old-timey format known as LaserDisc [1] I know I know, the quality is better. These “wins” had us feeling optimistic enough to lease some office space in a squat brownish-green building in San Diego’s faux-historic Old Town theme park-y part of town, not far from Rockin’ Baja Lobster. Our office had room for 4 desks, or 5 if you counted the vestibule (for a secretary?) In 1997 Brett Crosby (my younger brother) joined the company, and things started improving. We managed to sign two of the larger local employers, Sharp Healthcare, a hospital system, and Solar Turbines*, the power generation subsidiary of Caterpillar. But we still had a bunch of small customers, most of whom we hosted on our lone webserver, for a recurring fee. To accurately bill for bandwidth consumed (weird right? bandwidth used to be expensive), Paul wrote a simple log analyzer to tally bytes transferred, and gave it a nice web interface. He added referrers, “hits”, pageviews, etc., and voilá, the first version of Urchin was born. After some further development to add date-range features, user authentication, etc., the product was demonstrated to customers, to generally favorable reviews. [*this deal paid $10k/month and kept us alive for at least a year; thanks Steve!] Our first tradeshow ever, circa 1997. We borrowed these giant blue light boxes from an underwear startup, as I recall. They were 1\" thick particle board and extremely heavy. And we had booth babes! Not really. They were friends who thought an internet tradeshow would be fun, so they hung out all day for free. Suffice to say they never volunteered again. Brett’s girlfriend at the time (Julie, now his wife) also worked in “the industry”, for Rubin Postaer Interactive (“RPI”, a subsidiary of RPA; A=Associates). RPA was and is a prominent advertising & web development shop in LA, and they managed the Honda.com account. Sometime in late 1997, it was learned via our RPA spy (Julie) that Honda.com, which was using WebTrends at the time, was unable to process each day’s Apache access log before the end of the current day, dooming them to fall ever more behind. After some effort, we obtained a few days’ server logs to process as a demo, and the task was completed in ~30 minutes. We became the web analytics solution for American Honda from that point forward, and it became clear a business could be built on this log processing technology. One of the earlier Urchin t-shirt designs, before we corporate-ized the logo. Cabel from Panic was mad at us for that. Around this time Jack Ancone joined the company as (initially) CFO and moved to San Diego. We moved into our office at 2165 India St. around the same time (Note: The Ballast Point tasting room is now located directly across the street from our old office; suffice to say we would have never achieved anything had they been there in the late 1990s.) The company was then known as Quantified Systems, Inc., and work was divided into web dev, hosting, and software dev. Be divided and conquer yourself, to paraphrase Caesar. Classy awnings right? The big Ballast Point tasting room/restaurant is now in the building barely visible to the left. They have since become a legit unicorn. So much for software being the way to get rich. In January 1998 we received our very first order for the “Pro” version of Urchin, for $199. [Side note: why does “Pro” always mean “lame” in the software world?] Anyway, shortly after, we made the decision to jettison the non-software parts of the business, and all hosting/webdev customers were rather abruptly “sold” ($0) to another local webdev shop. We were now a software company (high-five!). As such, we needed to raise some money. Tapping our family “networks” and one boutique VC (Green Thumb Capital, of NYC, who Jack brought on board*), we raised $1m, bringing our total outside capital to about $1.25m. We would never raise any further money (with the exception of ~$400k in debt, which was repaid with interest and warrants). Not for lack of trying… more on that later. [*to their credit, Green Thumb never once hassled us nor apparently had they any thought of recovering their investment; I can only imagine their dumbfounded shock when they found out Google had agreed to acquire us.] As we struggled to figure out how to sell “enterprise” software in the late 1990s, we decided to try an advertising-based approach to grab market share. For some reason, we were always more concerned with popularity than money… go figure. Internet companies of the era were often valued most highly if measured by “eyeballs” and we thought we could get lots of those by giving away the software for free and showing banner ads at the top of each page. So we released Urchin ASAP, the free counterpart to Urchin ISP. Both were designed to be used by hosting operations. We thought we could make some significant fraction of a cent per click on these ads, on top of some infinitesimal CPM… (reminds me of a classic SNL skit… Q: “how do you make money at the Citiwide Change Bank? A: Volume!”) We never made anything on those banner ads, but we did get exposure. And the software was pretty good, for the era. Good enough to make our first real breakthrough. One of the Urchin ASAP banner ads, which advertised itself when no one else wanted the space. Meta. Before Tumblr, before Blogger, and contemporary with Geocities, there was something called Nettaxi. What-Taxi? Right. But at the time they claimed something like 100,000 “sites”, and we viewed them as a fantastic source of eyeballs for our advertising-supported version of Urchin. They claimed to have no money for such a luxury as web statistics (glad that term got retired), so we “negotiated” a deal: Urchin would be 100% free for them in exchange for the anticipated ad revenue we’d get from all those eyeballs. How much money did we make? 4¢ or so maybe, I don’t recall ever actually getting a check. But that’s beside the point. From then on we claimed 100,000 “sites” were using Urchin, and that got us places. Another “innovation” we came up with mirrored what Google does with its logo on special days — we created a dynamic Urchin guy in the upper-left of the interface called “the Urchin of the Day.” This was straight silly, but we thought it would endear us to customers. Maybe it did. It definitely occupied our design guy Jason Collins for the better part of year, as he got so into it he forgot about his more important work. The images he made still make me laugh. So good! We even had our then-friend, the pre-famous Shepard Fairey, do one, the “Power to the People” version. 7'4\", 520 lb. He also did several promo posters and ads for us in exchange for free web hosting. Really nice, humble guy. Of course, now he gets presidents elected and such. My favorite Urchin of the Day — Jason Collins (graphics guy) was a car nut and master of animated GIFs. In 1999, Brett Crosby, VP of Sales and Marketing, was casting about trying to get Urchin 2.0 noticed. He had zeroed-in on Earthlink as our dream customer, mostly due to their vast reach and name recognition. Heck, they were almost as big as AOL! Of course, we had no idea how to reach anyone important at a place like that, so Brett did the natural thing and filled out a web form. Again, and again, and again. He must have submitted that thing 20 or 30 times. Finally, he got a response. Rob Maupin, VP of hosting (or something similar) agreed to a meeting. We were stunned. The all-powerful Earthlink would meet with a bunch of idiots like us? We could hardly believe it. So we piled into the fanciest car we had, Brett’s old Mercedes 420 SEL, which he had bought for $4,000, and drove up to Pasadena. I stayed at the office to “manage” and because I was scared of Earthlink. Rob didn’t seem very impressed. He immediately dismissed the Urchin 2.0 interface as (and I quote) “too blue blue blue blue blue,” which I had to admit was true. Rob Maupin: We’ll try it if you make it less blue. But he agreed to try it, and the tests went well. Urchin was perhaps not the most full-featured web reporting tool in the world at the time, but it was fast, and that’s mainly what web hosts cared about. It also managed log files and helped sysadmins run things more easily, so the ops guys liked it. After we made some changes as Earthlink requested, we negotiated a pretty lame deal that ensured our eventual success: $4,000/month for unlimited Urchin software across all Earthlink-hosted websites. We were ecstatic. Jack, Brett, and Jason Senn (head of Channel and carpentry), looking tough. This photo (and the above) were for an article in Fortune in 2000 (“Traffic Aficionados”). Thanks Suzi Koudsi! In 2001, the company was rechristened Urchin Software Corporation. Product and sales were sufficiently far along that we thought it would be a good idea to raise more money. Anyone who’s pitched VCs knows it’s a long, distracting slog, and the business really suffers during the months the leadership is preoccupied. But things went pretty well, and after dozens of meetings and plenty of travel, we finally secured term sheets from two respectable VCs — Ampersand and JMI. The closing was scheduled for late August, but then Labor Day rolled around, and a few more days passed, and finally the capital call to the LPs was supposed to happen on… September 12th (2001). Uhh, no. Suffice to say, the world had bigger things to worry about that day. By that point, having anticipated a capital infusion of approximately $7 million, we had ramped up hiring and infrastructure spending, as one does. We had leased two additional office spaces in the same building, and built out the interiors. So without the funding, we had little choice but to pare back down. On a Friday not long after, we laid off 12 people and shortly afterward relinquished one of our office spaces. We called it, somewhat unimaginatively, Black Friday. Our financial situation was bleak (like, we couldn’t make payroll in two weeks), and we saw no alternative but to borrow money from our rich uncles — Chuck Scott and Jerry Navarra. They saved us, and got interest and warrants for their trouble. But Thanksgiving was uncomfortable for a couple years. 2001 and 2002 were very difficult years for Urchin Software Corp. — I remember walking down our hallway, praying to the acoustic ceiling tiles on more than one occasion, “please, just let it die” — but it wouldn’t. Costs were cut way back, and some employees took voluntary pay cuts of up to 60% to help with cashflow (this “back pay” was eventually repatriated, thank goodness). We always had stickers, because we were juvenile and liked sticking them on competitors’ booths and airplanes. Surfer Urchin is the rarest of the lot. Shepard Fairey designed a few bits of schwag in exchange for hosting obeygiant.com. Tech spending was slow in the early 2000s post-bubble, and while things were gradually improving, revenue was uneven and not growing as hoped. Until 2002, our major source of inflow had been large annual licensing deals that were complex and long negotiations. Our biggest deal, at over $1 million, was negotiated by Jack Ancone with Cable & Wireless, a major global telco/host/ISP. Urchin 3.0’s interface, cobranded with the now-defunct Worldport, of Dublin. Urchin 3.x still runs on more than a few old servers in dusty corners of the internet. Similar deals were negotiated with Winstar, KeyBridge, and Ireland-based Worldport, all VC-backed hosts with seemingly limitless resources. As it turned out, they were indeed limited. All of them expired before we got paid. So to jumpstart sales, the decision was made to radically simplify our enterprise deals to hosting companies, even though it meant less money in the short term. Essentially, we made the financially-puny Earthlink deal the standard, but included some potential upside, at least. The Site License Model (“SLM”) was about as simple as it gets: $5,000/month per physical datacenter, all the Urchin software you want, 1-page contract, no legalese, and nothing really to negotiate. The accurséd Winstar blimp flew lazy circles around Jack’s house in Bird Rock while he negotiated a $400,000 deal with them, which was finally executed; we never saw a dime. Beware of customers with blimps! The SLM was immediately a hit, and we signed deals with many of the largest US and European hosting companies in the ensuing year. Rackspace (now part of IBM), Everyone’s Internet (aka EV1 Servers), The Planet, mediatemple, and many others signed on, with several agreeing to multi-datacenter deals. By around fall 2003, we were cashflow-positive on these alone, and we were also selling more and more individual licenses to self-hosted organizations including much of the Fortune 500 and many university systems. We had released most of the sales team during our near-death experience in 2001, but the few who remained — Paul Botto, Nikki Morrissey, and Megan Cash— worked for nothing and slowly, fitfully started selling our way out of the doldrums. Once we finally figured out a workable commission model — low base, high commission with fully retroactive kickers — these three positively rocked. Paul and Megan went on to work for Google for years (Nikki declined to move north in 2005, in favor of having kids.) Paul is still the best sales/BD guy with whom I’ve ever worked. Paul Botto accepts the Employee of the Month plaque, March 3rd 2002; note the drum kit in the background. After a failed attempt at running an international office in Tokyo (the moneys did not come[2]), we launched a channel program, which ran in parallel to direct sales. I still think for certain markets where English isn’t the primary language, it makes sense to have a local partner. Japan in particular generated strong sales for many years, and for this we can thank Jason Senn, our channel guy and chief office builder (we were too cheap to hire contractors.) Japan is also the most fun place ever to party it up in the name of business. On-sens and fire festivals? Yes please. If Urchin 2 got us in the door, and Urchin 3 didn’t suck, Urchin 4 was actually pretty respectable. It had the then-Apple-esque brushed-aluminum look, some fancy-for-the-time interface elements, and most importantly, it had the UTM. The UTM, or Urchin Traffic Monitor, was an early method for augmenting Apache (or IIS, etc.) log files with cookies, such that unique visitors could be established. This method entailed a line of javascript in theof each page on the site, and a small modification to the webserver’s logging behavior. Most of our competitors at the time used either logs only (old school) or javascript/cookies only (WebSideStory, etc.), and both necessarily missed out on a lot of available information. Urchin was the first to use both data sources in one unified collection method, neatly contained in augmented access-log files. Nowadays pretty much everything you’d want can be had via the cookie method (á la GA), but analyzing logs still has its advantages. Urchin 4 had an easter egg that no one ever found, to my knowledge. If you clicked a random “rivet” in the sexy brushed aluminum interface, you’d be treated to a photo of the illustrious Urchin dev team: Doug Silver, Nathan Moon, Paul, Jonathon Vance, Rolf Schreiber, and Jim Napier. Most of these guys are still at Google (as of Aug. 2016). Urchin 4 continued our tradition of supporting way, way too many random platforms (Google still has Urchin 4 help: check out the OS support… ever heard of Yellow Dog Linux?). I had this idea that platform-carpet-bombing might get us into some big corporations or universities running AIX or HP-UX, but no, everyone bought the Linux or Windows IIS versions. I guess I just liked buying random servers off ebay and getting Apache and a compiler running. We even compiled a NeXT version at one point, if I’m not mistaken. But no DEC, at least (I couldn’t get the machine to boot up). Paul, looking here like a cartel drug lord, withdrew something like $53,000 in cash for our xmas bonuses in 2004. Funny thing is, Google also gave out actual cash money bonuses for years after we joined — millions of dollars in currency. Great minds think alike I guess. Anyway, it was fun and no one got robbed. This was December 17, 2004. Urchin 4 was the first release I really felt could compete against anyone, and not just with regard to back-end performance. But Urchin 5 was superior in every way, and I’m sure thousands of instances still run to this day. If anything, Urchin 5 was just too much of a good thing. Almost every menu item had submenus upon submenus. It was pretty overwhelming and dry, but analytics nerds dug it. I’m embarrassed to see that “hits” was still part of Urchin at the time. Avinash is rolling his eyes right now. Urchin 5 had e-commerce/”ROI” tracking, the Campaign Tracking Module, and multiserver versions that could all conspire to get the price pretty high. But the real killer feature IMHO, which was released in Urchin 6, was individual visitor history drill-down. If this sounds potentially, um, sensitive, that’s because it is. Google wouldn’t touch this feature and it was summarily axed, never to return. Individual visitor history drilldown — potentially controversial I guess. But at least there wasn’t a “composite sketch” of the visitor. That would have been SO COOL. This is Urchin 6. Up through Urchin 5, we’d been a traditional licensed-software outfit — you pay us money, you own the software. But by 2004 it was obvious we needed a hosted version (“hosted” would later become “cloud”, but we didn’t know that yet.) So we bought a bunch of servers, upgraded our T1, and released Urchin 6, which was available in on-premises (you run it yourself) or hosted by us, for $500/month(!) We didn’t have much time left as an independent concern, but businesses were surprisingly willing to pay up for the privilege of not having to run Urchin themselves. That business was a winner from day 1. Paul Botto, me, and Brett at Search Engine Strategies 2004, San Jose, where we first met the Google people. By Summer 2004, Urchin had the largest installed base among web analytics vendors on a number-of-websites basis[3]. Tradeshows had become fun again, and we planned our biggest spread yet for Search Engine Strategies 2004, in San Jose. It was there that two Google people, Wesley Chan (PM) and David Friedberg (Corp. Dev.), went “shopping” as they put it, for a web analytics company. I guess they weren’t overly put-off by what they saw. The Google Dance was a big party thrown in conjunction with the Search Engine Strategies tradeshow for a few years. During the “Dance” in ’04, Paul, Jack, and Brett, iirc, were off doing some sneaky corp. dev. work. A few weeks later Google had made an offer for the company. By then we had interest from other quarters too — remember WebSideStory? They were actually a public company at the time and offered us more. But I think we made the right choice. Brett, some dude named Al, and David Friedberg, in 2006 Sidebar: Friedberg left Google in 2006 to start what became The Climate Corporation, which was acquired for over $1 billion by Monsanto. Now that’s an exit. He also started Metromile and Eatsa. Legit! By 2004, we were feeling pretty smug about ourselves, despite still being puny. Design by Merrick. Selling the company was a needlessly rough process. It should have wrapped up just after the Google IPO in late 2004, but frankly the Google lawyers were prickly CYA types, demanding all kinds of IP-related protection — the four founders were personally on the hook if we were later found to be violating anyone’s patents etc. As we were now part of the big G, it seemed distinctly possible that WebTrends or someone would see fit to sue us. In hindsight, probably all boilerplate, but it was scary to risk it all like that. By the time we finally got it done, it was April 2005, and Google’s stock had doubled (half our payout was in stock). Oh well. Brett prepares to “fax” the signed acquisition agreement back to Google. By this time we were sufficiently profitable that it was a tough decision to sell. Brett signed the actual, final paperwork in a tuxedo about 30 seconds before walking down the aisle at his wedding. The still-young Google of 2005 was, I think, a lot more fun than the Mature Google/Alphabet of today. It was small enough (~3,000 employees) that everyone could get together for one (awesome, incredible) holiday party. And MC Hammer was always around. That was cool. Jack, MC Hammer, and Chris Sacca, circa 2005. The day we joined, Eric Schmidt took time out of his day to hang out with us and learn about our flavor of web analytics. He immediately saw the potential with regard to Adwords spend, and was ever after helpful and available. I really liked the guy. Years later, Brett (then Sr. Director of Marketing) had an office right next to Eric, and they were bros. Kinda. I mean, billionaires are not like the rest of us. Eric Schmidt gets to know the Urchin sales team, plus some others. L-R: Nick Mihailovski, Mike Chipman, Jim Napier, Megan Cash, Eric Schmidt, Paul Botto, Rolf Schreiber, Jason Senn, and Jack Ancone. Our first office at Google (for some of us) was the “fishbowl” of Building 42, in the nucleus of the Mountain View campus. We were actually really close to Larry & Sergey for awhile. Sergey had this laser engraver in his office with a long air duct snaking down the hall to vent the gases. He’s a nut, that Sergey. The fishbowl was also home to a new Google engineer named Mike Stoppelman, whose brother would soon start a company called Yelp. Mike is SVP of engineering there as of this writing. Urchin stuff would plague the Google campus for years after we joined. I’m sure some of it still lurks in supply cabinets here and there. The pervasiveness of Google Analytics now seems kind of a given, but in the spring of 2005, we were fairly panicked that its Google-fied release would be greeted with a shrug. So Wesley Chan, the Google PM who spearheaded the integration effort, commenced a daily “war room” and everyone was given milestones (OKRs, in Google land) with pretty tight timelines. Paul got a bunch of engineering tasks, I got a bunch of sales-ish/adoption tasks around penetrating the Fortune-500, Brett got marketing/PR/branding stuff, and Jack got BD/partnerships. Camo’ was hot in 2005… this was the last shirt we made pre-Google, and the first we gave away at TGIF once we joined. It was a fun and hectic time, with much of the effort centered around bringing the rest of Google up to speed — some of us toured the nation visiting the various remote Google offices, small outposts that appreciated visitors from the mothership. By the time we thought we were ready for a public launch in November of 2005, we were sweating it. Would anyone care? Turns out they did. After we announced “Urchin from Google” was now free for any website in the world, the demand was sufficiently high that even Google’s infrastructure (well, the part allocated to us) was groaning, and the SRE team made us shut down signups until we could arrange the server resources etc. we needed to reopen. Google Analytics was once knows as “Urchin from Google,” catchy right? This is one of those nice-to-have problems, but a lot of people were still pissed off. Several months later, signups were reopened via the old invitation model, and the GA saturation we know today started happening in earnest. Alden DeSoto (chief GA tech writer), Jeff Veen, Brett, Greg Veen, Ryan Carver, and Jeff Gillis (GA marketing) sporting the new (2006) Google Analytics track jackets, celebrating the re-launch. A few years hence the Veens and Ryan would start TypeKit, which was later acquired by Adobe. 2nd exit for those guys, nice. Now, Google buys a lot of companies. Some of these are huge successes, like YouTube and Keyhole (Google Earth), but many just kind of scatter to the four winds, despite being worthy. Dodgeball, for example. I think this happens partially because of the way Google buys companies and partially because of big-company inertia/fog. Under some dollar amount (I’ve heard $50 million) all it took was one VP to say “buy them!” and it was done. Once they get onboarded, that VP maybe had left, or may have just been distracted. Turns out no one else cares, and the corporate soup subsumes the employees and the product melts into a shapeless saltine. In reality, no one at Google much cared about a product if it didn’t generate at least something like $100 million per year. Urchin of course didn’t either, but we were lucky enough to have some powerful allies: Wesley Chan and Eric Schmidt. Wesley was a PM (product manager) who understood Google needed effective analytics to drive Adwords spend. He was also dead determined not to let “his” acquisition be a failure, and he never let up until it could motor under its own power. But of course nothing can compare to having the CEO on your team, and lucky for us, Eric immediately got how web traffic analysis could positively affect Adwords. A few years later, Google did a big internal study with a bunch of “quants” running various models, and they pretty well proved an XX% increase in ad spending across the broad swath of customers studied. That was big money, with a “B.” Up and to the right! Now that I’ve moved out of San Francisco, I wear Google shirts a lot more often. In 2006, the Urchin people started drifting around Google, and some left. Today, my guess is about 12–15 original Urchin types are still there, and some still work on GA. Most notably, Paul is a senior VP of engineering, with hundreds of engineers reporting to him. He owns not just GA, but display ads too. Smart guy, that Paul. The last Urchin-specIfic shirt we ever made, in about 2009(?). Little-known fact: Urchin was sold as standalone software until 2012, since many educational, government, and corporate customers wanted on-premises analytics software. Some still do, and former Urchinite Mike Chipman started a company to serve them — the product is compatible with Urchin databases and is called Angelfish. Last I checked, Google Analytics is running on some large and increasing percentage of domains across the internet. Here’s one study by Pingdom showing 62% of the top 10,000 sites use it. Here’s another claiming over 10 million sites were using it (15,429,94) as of 2012. Here’s another claiming over 45 million sites were using it as of 2015. Pretty cool any way you slice it. Urchin/GA have touched a lot of people, and that’s probably the most satisfying thing about this whole adventure. It’s also great to see Urchin people like Nick Mihailovski and Nathan Moon do so well at Google. And of course Paul Muret, who is now a top exec in the engineering org. I’m also happy and very relieved that all our investors made money and got Google shares at 2005 prices. Thank you again for making this bumbling comedy of errors work out in the end. We (obviously) couldn’t have done it without you. We were based in San Diego, after all Footnotes Laserdiscs: The 12\" ones, like a shiny record. I’m sure some people still prefer them. The moneys will come was the mantra of one Chi Kwan, president of our Japan division. Quite possibly the stupidest thing we ever did was open an office in Tokyo. It absolutely incinerated cash, and didn’t sell anything. We must have blown close to a million dollars on that poorly considered idea. That said, we did finally figure out how to make money in Japan — partner with a distributor. They took a 70% cut, but they did everything, including put it on a CD in an actual physical box. Hats off to Runexy! And we have a fun phrase to say all these years later. Anytime I’m short on cash, I just repeat “the moneys will come,” and they always do. Most-sites marketshare — this did not translate to most revenue. Kind of a vanity metric, but we got a lot of mileage out of it. Viking Urchin? Seriously? Appendix I: Personalities Plenty of the old Urchin team is still at Google — Paul Muret is VP of Engineering, Analytics and Display Ads, which is something. Some of the other guys went on to start new companies. Here’s the Urchin Team over the years, in off-the-top-of-my-head order, with links to companies they started, if applicable. Paul Muret Brett Crosby — PeerStreet Jack Ancone Scott Crosby Paul Botto Rolf Schreiber Jason Senn — ProFundr/Marketface Jim Napier Hui-Sok “Nathan” Moon Alden DeSoto Jonathon Vance(s with Wolves) Doug Silver Jason Collins Justin Beope — Upas Street Brewing Megan Cash Christian Powell Nikki Morrissey Mike Chipman — Actual Metrics (Angelfish product) Steve Gott — Ecomiq Ted Ryan Jeromy Henry Annie Aubrey Alex Ortiz Kelley Wilson Christina Hild David Cerce Ryan Walker Nick Mihailovski Bill Rhodes Jason Chen Juba Smith Bret Aarons Merrick Bart Fromm Chi Kwan Ed Schwartz Andy Smith Ed Petersen Cindy Lee Davee Schultie Joanna Rocchio Ben Norton Another of my favorites Epilogue: Some lessons learned If I had to do it over again, I’d do a few things differently, of course. Here’s a distillation of my/our painfully learnt truths, along with some reinvention of the wheel wisdom we had to live to believe. Dispensing generalized advice is always a dicey business, but I think I can defend these. Read with a grain of salt. Be willing to leave money on the table. I can’t emphasize this enough. Deal velocity is far more important than getting every dollar you “should” from a customer. Doing two deals for $1 each is better than one deal for $2. Reduce legalese, reduce text, shrink your contracts. One page is best. Somebody, probably an underling concerned with CYA, is actually going to have to read that 40-pages of lawyerspeak and it’s going to take that poor sap a long time. Make it so your counterpart on the deal reads it instead and execute the deal that day. Shun terms that you need a lawyer to interpret. Warren Buffett lent Goldman Sachs $5 BILLION on a hand-written note. It’s a legally binding agreement. Simple=less room for wiggling, and no excuse to delay. Time kills all deals (just to recap 1 and 2). Specialize sooner. Narrow your market. No one believes you if you say you serve all customers. Legitimacy/credibility are contingent on tight focus. No one can do it all, but even if you could, no one will believe it. Put more thought into the right sales incentives and don’t limit the earnings of your sales people. Make commissions bigger as targets are hit, retroactively to all dollars — eg., maybe the commission is 8% up to $100k/month, then it becomes 10%, which applies to the entire $100k, not just the marginal amount above that. If your sales people make more than the CEO from time to time, you’re on the right track. Pay commissions at least monthly — quarterly is too long to wait, and will hurt motivation. Sales people think short term, as they should. Accounting transparency — be more transparent with employees, sooner, until you are really uncomfortable. All employees should have access to a sales dashboard showing daily/monthly sales in real time, along with a “here’s our nut” indicator so everyone knows what to shoot for — profitability. The nut itself can be just a simple number, but the more transparent the better, even with salaries. They should be defensible, after all. Overcommunicate organizational clarity. Hiring is a bitch, firing is harder. Everyone talks about hiring “A” players and sh*t like that. Of course, that implies you can divine which ones they are without seeing their work at your company. You’re better at hiring than I, if so. The reality is that you need to have the backbone to fire people that don’t work out. Do it as soon as it’s clear it’s the right move. Be generous with people you offload — if they speak positively of your company after the experience, that means you did it right. Do your best to hire the best (smarter than you is a good thing to strive for), but let’s admit the truth: it’s a crapshoot. Try hard, then cut loose your mistakes. Then there’s no fault, no guilt. More on hiring: Degrees are for working at Google. Also take a good look at highschool/college dropouts that are awesome. They usually can’t get a job at Google, so they might actually meet with you. Money will burn a hole in your pocket. Consider only raising as much as you need to get to break-even, plus some % to account for how slow things are in the real world. Every $1 you raise is another $10 you have to sell for to make VCs happy. Moving the goalposts farther away makes it harder to score (sorry, I hoped to avoid sports metaphors). And finally, the most important “rule” of all: if you want someone to read your email, make it short. At lease two of the UoDs were sporting cocktails Thanks for reading! You rule.",
    "commentLink": "https://news.ycombinator.com/item?id=41205176",
    "commentBody": "Urchin Software Corp: The unlikely origin story of Google Analytics (2016) (urchin.biz)233 points by cpeterso 22 hours agohidepastfavorite54 comments mkmk 19 hours ago> The UTM, or Urchin Traffic Monitor, was an early method for augmenting Apache (or IIS, etc.) log files with cookies, such that unique visitors could be established. Of course, “utm” lives on today as a standard prefix for link tracking parameters, even outside of google analytics reply tyingq 6 hours agoparentMany of them described for GA: https://support.google.com/analytics/answer/10917952 reply ThinkingGuy 16 hours agoparentprevThanks for that info. I’ve wondered for years what the meaning of the utf parameter was. reply userbinator 15 hours agorootparentGiven its purpose, I always thought it was \"user tracking mark\" or similar. reply holman 21 hours agoprevI can't really explain how cool Urchin was. I think it was one of the first truly analytical software I used — not just from a web traffic point of view, but it was a site that used and presented data. The graphs, the maps, even the two-column UI was stuff a lot of web developers copied and riffed on back then. It really opened my mind up to a lot of things: design, software as a service (and installable software), even acquisitions in general. Strangely had a large impact on my future career. reply aeyes 20 hours agoprevI'm very surprised that they signed up whole ISPs and got away with it. I wasn't able to process the daily logs of the tracking pixel of the site I was operating on Urchin 5 within 24 hours. I had a beefy server with a 16 drive raid array but the log processing never used multiple cores. By that time Google had aquired them, support didn't exist because they wanted you to switch to Google Analytics and it was basically 30k down the drain. reply ot1138 20 hours agoprevI loved this retell. Brings back the old days, especially the Google and Yahoo parties of the late 2000's. Those were crazy. They literally carried one of my employees out of a basement rave who had passed out from drinking too much. reply davidcbc 3 hours agoparentSounds like something better left in the past reply golergka 12 hours agoparentprevSomehow, even on the opposite side of the globe software company parties also were not very timid. I spent a whole morning in 2009 in an ambulance and then in hospital with my colleague who passed out in a bar after a full night of drinking. reply _the_inflator 9 hours agorootparentFor maybe different reasons or circumstances. Nevertheless cheers, mate. VC backed passing out was way different and not in the somewhat elitist sense that prevails in Europe. Play hard, party hard mixed with friendly and open nerd frat house mentality in California is one of a kind compared to then cold and dark winters in Europe. People forget that there is essentially always sun, a huge difference. Some had a 17:00 party break every weekday, loud music and food 17:00 sharp no exceptions, a phenomenon what became after work parties in Europe, but were more or less barbecue parties for casual idea sharing and bonding. Catering costs for a month alone would have killed every startup or company in EU. And then imagine special occasions somewhere else. These people knew how to have a good time - to pass out one way or the other. Happy times. reply jeffnappi 2 hours agoprevWe were Urchin users prior to the acquisition and were also Google AdWords customers... I remember being shocked at the idea of putting Google's JavaScript in our secure e-commerce site. We wanted to pay as little as possible for traffic and were mining the long tail of keywords. We certainly did not want AdWords to know what our economics were. Ultimately AdWords evolved into a very efficient system that groups similar keywords and takes as much margin as the advertisers can handle. The golden days of a level playing field in ppc advertising were over and Google won the game :) reply tgtweak 1 hour agoprevThe fact ga4 doesn't even do what urchin did back when Google bought it tells you everything you need to know about how great this software (and company) truly was. reply Lammy 20 hours agoprev> Our first tradeshow ever, circa 1997. Pardon my one nitpick: the computer in the photo (PowerMac1,1) was introduced 1999-01-05. reply pixelesque 15 hours agoparentFurther backed up by the fact that the photos show \"Urchin 3.0\" signs, and the article mentions: \"In 1999, Brett Crosby, VP of Sales and Marketing, was casting about trying to get Urchin 2.0 noticed.\" reply spydum 20 hours agoprevWorked at a hosting company in those years.. urchin was the GOAT. we ran it for every customer, and relied on it heavily for billing our customers. It was crazy fast and elegant. Nothing came close reply davidwinters 21 hours agoprevI was so excited to switch from Webtrends to Urchin and back when I still loved Google I was delighted that they bought it out and made it free. Now I wish Google had never touched them. reply egorfine 11 hours agoparent> Now I wish Google had never touched them. It is incredible how out of touch with reality GA has become. Nothing is called what it used to be, and not a single straight report with simple familiar figures. Everything is abstracted to the point of it being useless. I am pretty sure I understand what happens with the GA team today [1] We run self-hosted Matomo for analytics. One of the bonus points, besides actual sane reports is that Matomo can see about ~40% more traffic due to being invisible to blockers while being fully GDPR compliant and providing full privacy for visitors. [1] https://www.joelonsoftware.com/2001/04/21/dont-let-architect... reply PaulStatezny 21 hours agoparentprev> Now I wish Google had never touched them. Would you be willing to elaborate? reply davidwinters 20 hours agorootparentAfter the switch to Google Analytics the heat map feature was dropped pretty quickly and it was one of the features I really enjoyed. I also think it would have been better for us in the long run to have paid for a service that let us maintain control over our data. reply greenavocado 14 hours agorootparentYandex Metrica has free heatmap reply cqqxo4zV46cp 20 hours agorootparentprevI don’t think “Google bad” needs elaboration in 2024. reply jonas21 20 hours agorootparentMany of the things people think are bad about Google in 2024 (trackers, targeting, slurping up user data, etc) came from Urchin. reply taf2 8 hours agorootparentThe bad IMO originated from double click reply jlarocco 1 minute agorootparentI'm not so sure. When Google bought DoubleClick it was already apparent DC's over the top, obnoxious advertising (banner ads, punch the monkey, etc.) was dying off in favor of Google's more discrete advertising and data collection. DC may have caught on and turned it around eventually, but Google bought them up first. But Google already had a reputation for slurping up all the user data they could get, even in 2008. fellowniusmonk 20 hours agoparentprevOh man, what a shift moving from webtrends to urchin. Between that and following the regular \"google dance\" on the webmasterworld forums what a time to be alive. reply gumby 18 hours agoprevThat picture of their first computer, a sparcstation, brought back memories. Our first computer at Cygnus was a sparcstation that was actually a “prototype” (probably PVT since it had all the housing etc) for the first sparcstation. I think Andy B had given it to John. It worked fine and lasted for years. When the author said they’d started the company on a 10K investment I knew they were my kind of people. reply AlbertCory 3 hours agoprevPersonal story: in 2006 in Google Enterprise, we had many, many meetings with the GA team, the goal being a private, inside-the-firewall box that would run GA, using our Google Search Appliance hardware. This never came to anything. reply k__ 2 hours agoparentIn 2006, I worked for a company that built exactly that: A web analytics engine that ran behind the firewall. It would rely on a reverse proxy and not on cookies or pixels, so it couldn't be blocked. They even had some of the biggest sites in Europe as customers. However, the company never turned a profit and after going through the hands of a few investors, they closed shop. reply AlbertCory 2 hours agorootparentYeah, \"inside the firewall\" declined as a marketing pitch pretty quickly. reply dylan604 2 hours agorootparentSecurity over convenience is also something that declined pretty quickly as well followed quickly by the concept of privacy in exchange for convenience. With what we know about how/why/where the use of those analytics are used back then, would we make the same decisions if it was a choice today? reply sebastiennight 15 hours agoprevUrchin analytics (which, IIRC, were provided to us by our host OVH for free at the time) is what taught me what I would still call Rule #1 of being a webmaster: > Tracking your analytics makes traffic grow. Refreshing your analytics makes traffic stall. reply stingraycharles 15 hours agoparentCould you elaborate on that? The meaning of “makes traffic stall” is lost on me, unless you simply mean “don’t obsess over it, just look at long-term trends”. reply sebastiennight 5 hours agorootparentBecause humans like to see lines go up to the right, there's a weird Gaussian curve where - never checking your analytics means you're probably going to stagnate forever, - checking them at a fixed frequency means you're going to look at what's worked and work hard to keep it going, so traffic grows, - checking them at every time of the hour (I was at my worst when I switched from Urchin to Xiti client-side analytics in '06) means you're switching back to a passive almost-superstitious wait for the number to move, which is both frustrating and extremely ineffective. I've been there and done all 3, and as CEO of a startup[0] I find it's my job to do my best to stay in the middle :) [0] https://onetake.ai reply morning-coffee 1 hour agoprevHmm. So this is the ancestor of stuff I block with my pihole now? reply dang 17 hours agoprevDiscussed at the time (of the article): The origin story of Google Analytics - https://news.ycombinator.com/item?id=12986649 - Nov 2016 (53 comments) reply Terretta 17 hours agoprevUrchin is not Google advertising's only origin story... See also \"A Brief History of NetGravity\": In October 1999, DoubleClick purchased NetGravity in a stock deal valued at $530m. The NetGravity product line is now completely incorporated into the DoubleClick portfolio of advertising management products. The original founders and management team have all left to pursue new opportunities. NetGravity, having helped to create the multi-billion dollar internet advertising market, has essentially ceased to exist. -- https://news.ycombinator.com/item?id=41206733 DoubleClick rebranded NetGravity AdServer as DART Enterprise... On March 11, 2008, Google acquired DoubleClick for $3.1 billion. In June 2018, Google announced plans to rebrand its ads platforms, and DoubleClick was merged into the new Google Marketing Platform brand. -- https://en.wikipedia.org/wiki/DoubleClick reply jsjohnst 16 hours agoparent> Urchin is not Google advertising's only origin story... Further because that leaves out the Overture / Inktomi part of Google’s revenue origin story… reply ec109685 13 hours agorootparentYahoo bought them. reply jsjohnst 7 hours agorootparentSure, but what did Yahoo also do? They settled the patent suit that was jeopardizing Google’s IPO. What were those terms? Find out and learn a fascinating part of Google’s history. reply cj 7 hours agorootparentSpoiler alert: Google agreed to give yahoo $300m worth of Google IPO shares. reply sureIy 15 hours agoparentprevThis was the most consequential purchase, it’s the one product Google will never sunset because it is Google. reply ErikAugust 18 hours agoprevWhat about defunct startup shirts? Like, I’d wear that Urchin shirt. reply codetrotter 18 hours agoparentThat sounds like a potential business idea even. Although realistically I guess eBay and Craigslist already has that covered :p reply shombaboor 19 hours agoprevUA to GA4 finally got us to abandon google analytics for cookie free cloudflare completing the cycle reply millipede 15 hours agoparentUA transition shook me out too. Who breaks backwards compatibility?? reply randomgiy3142 15 hours agoprevSo have a good idea, be lucky and smart, and most importantly come from really rich families because floating 2.8million through two (!!?) crashes on an obvious now technology but log processing in the early 2000s is like describing how to win powerball. reply AlbertCory 1 hour agoparentwhat's the obvious new technology right now, and why aren't you doing it? reply rgrieselhuber 20 hours agoprevHad a chance to meet Brett at the Google offices shortly after the acquisition. Really nice guy, had a lot of good advice about being a founder. reply chatmasta 18 hours agoprev(2016) (In case anyone else is surprised by the line in the article that the “10th anniversary of the acquisition has recently passed.”) reply cut3 21 hours agoprevI remember switching from some cgi script web counter to urchin and it was incredible the insights it unlocked. Good nostalgia hit. reply heraldgeezer 19 hours agoprevLove reading stories like this! Thank you. I DO know about Yellow Dog Linux as it was the Linux officially supported on a PS3 console! reply iJohnDoe 16 hours agoprevI think a lot of people forget some of the other Google origin stories. Android was a company Google acquired. reply Dwedit 18 hours agoprevOh, that domain I block. I still have no idea what they actually do, but they sound really scary. reply sskates 14 hours agoprev [–] Wow- a lot of similarity to what's important with analytics today! Depth of analytics and speed of queries were their key competitive differentiators. Those are still ones we hammer at Amplitude. Also individual visitor history drill-down (we call it user timelines) is one of the most used features in Amplitude today. I have a huge amount of respect for the Urchin team. They had to figure out everything for the first time on their own with nothing to go off of while going after a much smaller and earlier market. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Urchin Software Corporation, founded in 1995, evolved from building websites to developing web analytics software, leading to its acquisition by Google in 2005 and the creation of Google Analytics.",
      "Key milestones include the development of the first log analyzer, rebranding in 2001, and achieving cashflow positivity by 2003 despite financial struggles.",
      "Google Analytics, launched in November 2005, quickly became a dominant web analytics tool, with the Urchin team integrating into Google and continuing to enhance the product."
    ],
    "commentSummary": [
      "Urchin Software Corp, the precursor to Google Analytics, introduced the UTM (Urchin Traffic Monitor) for tracking unique visitors, a method still used today in link tracking parameters.",
      "Urchin was highly influential in web analytics, offering features like detailed visitor tracking and heat maps, which were later dropped by Google Analytics, leading to some user dissatisfaction.",
      "The acquisition of Urchin by Google marked a significant shift in web analytics, with Google Analytics becoming a dominant tool, though some users miss the original features and simplicity of Urchin."
    ],
    "points": 233,
    "commentCount": 54,
    "retryCount": 0,
    "time": 1723235531
  },
  {
    "id": 41206908,
    "title": "Building a highly-available web service without a database",
    "originLink": "https://blog.screenshotbot.io/2024/08/10/building-a-highly-available-web-service-without-a-database/",
    "originBody": "Building a highly-available web service without a database Arnold Noronha Uncategorized August 10, 2024August 10, 2024 8 Minutes If you’ve ever built a web service or a web app, you know the drill: pick a database, pick a web service framework (and in today’s day and age, pick a front-end framework, but let’s not get into that). This has been the case for several decades now, and people don’t stop to question if this is still the best way to build a web app. Many things have changed in the last decade: Disk is a lot faster (NVMe) Disk is a lot more robust (EBS/EFS etc.) RAM is super cheap, for most startups you could probably fit all your data in RAM You can rent a machine with hundreds of cores if your heart desires. This was not the case when I first worked at a Rails startup in 2010. But most importantly, there’s one new very important change that’s happened in the last decade: The Raft Consensus algorithm was published in 2014 with many robust implementations easily available. In this blog post, we’re going to break down a new architecture for web development. We use it successfully for Screenshotbot, and we hope you’ll use it too. I’ll break this blog post into three parts: Explore, Expand and Extract, obviously referencing Kent Beck‘s 3X. Your needs are going to vary in each of these stages of your startup, and I’m going to demonstrate how you use the architecture in all three phases. Explore So you’re a new startup. You’re iterating on a product, you have no idea how people are going to use it, or even if they’re going to use it. For most startups today, this would mean you’ll pick Rails or Django or Node or some such, backed with a MySQL or PostgreSQL or MongoDB or some such. “Keep it simple silly,” you say, and this seems simple enough. But is this as simple as possibly can be? Could we make it simpler? What if the web service and the database instance were exactly one and the same? I’m not talking about using something like SQLite where your data is still serialized, I’m saying what if all the memory in your RAM is your database. Imagine all the wonderful things you could build if you never had to serialize data into SQL queries. First, you don’t need multiple front-end servers talking to a single DB, just get a bigger server with more RAM and more CPU if you need it. What about indices? Well, you can use in-memory indices, effectively just hash-tables to lookup objects. You don’t need clever indices like B-tree that are optimized for disk latency. (In fact, you can use some indices that were probably not possible with traditional databases. One such index using functional collections was critical to the scalability of Screenshotbot.) You also won’t need special architectures to reduce round-trips to your database. In particular, you won’t need any of that Async-IO business, because your threads are no longer IO bound. Retrieving data is just a matter of reading RAM. Suddenly debugging code has become a lot easier too. You don’t need any services to run background jobs, because background jobs are just threads running in this large process. You don’t need crazy concurrency protocols, because most of your concurrency requirements can be satisfied with simple in-memory mutexes and condition variables. But then comes the important part: how do you recover when your process crashes? It turns out that answer is easy, periodically just take a snapshot of everything in RAM. Hold on, what if you’ve made changes since the last snapshot? And this is the clever bit: you ensure that every time you change parts of RAM, we write a transaction to disk. So if you have a line like foo.setBar(2), this will first write a transaction that says we’ve changed the bar field of foo to 2, and then actually set the field to 2. An operation like new Foo() writes a transaction to disk to say that a Foo object was created, and then returns the new object. And so, if your process crashes and restarts, it first reloads the snapshot, and replays the transaction logs to fully recover the state. (Notice that index changes don’t need to be part of the transaction log. For instance if there’s an index on field bar from Foo, then setBar should just update the index, which will get updated whether it’s read from a snapshot, or from a transaction.) Finally, this architecture enables some new kind of code that couldn’t be written before. Since all requests are being served by the same process, which usually doesn’t get killed, it means you can store closures in memory that can be used to serve pages. For example on Screenshotbot, if you ever see a “https://screenshotbot.io/n/nnnnnnn” URL, it’s actually a closure on the server, where nnnnnnn maps to an internal closure. But amazingly, this simple change means we don’t need to serialize objects across page transitions. The closure has references to the objects, so we don’t need to pass around object-ids across every single request. In Javascript, this might hypothetically look like: function renderMyObject(obj) { return ...obj.delete()) >Delete ...} What this all means is that you can iterate quickly. If you have to debug, there’s exactly one service that you need to debug. If you need to profile code, there’s exactly one service you need to profile (no more MySQL slow query logs). There’s exactly one service to monitor: if that one service goes down the site certainly goes down, but since there’s only one service and one server, the probability of failure is also much lower. If the server dies, AWS will automatically bring up a new server to replace it within a few minutes. It’s also a lot easier to write test code, since you no longer have to mock out databases. Expand So you’re moving fast, iterating, and building out ideas, and slowly getting customers along the way. Then one day, you get a high-profile customer. Bingo, you’re now in the Expand phase of your startup. But there’s a catch: this high-profile customer requires 99.999% availability. Surely, the architecture we just described cannot handle this. If the server goes down, we would need to wait several minutes for AWS to bring it back up. Once it’s back up, we might wait several minutes for our process to even restore the snapshot from disk. Even re-deploys are tricky: restarting the service can bring down the server for multiple minutes. And this is where the Raft Consensus Protocol comes in to place. Raft is a wonderful algorithm and protocol. It takes your finite state machine (your web server/database), and essentially replicates the transaction log. So now, we can take our very simple architecture and replicate it across three machines. If the leader goes down, then a new leader is elected within seconds and will continue to serve requests. We’ve just made our simple little service into a full-fledged highly-available database, without fundamentally changing how developers write code. With this mechanism, you can also do a rolling deploy without ever bringing the server down. (Although we rarely restart our server processes, more on that in a moment.) Because there’s just one service, it’s also easy to calculate your availability guarantees. Extract So your startup is doing well, and you have thousands of large customers. To be honest, Screenshotbot is not at this stage, I’ll talk about where we are in a moment. But we’re preparing for this possibility, with monitoring in place for predicted bottlenecks. The solution here is something large companies already do with their databases: sharding. You can break up your web services into shards, each shard being its own cluster. In particular, at Screenshotbot we already do this: each of our enterprise customers get their own dedicated cluster. (Fun story: Meta switched to Raft to handle replication for each of its MySQL clusters, so we’re essentially doing the same thing but without using a separate database.) I don’t know what else to expect, since I’m more of a solve-today’s-problem kind of person. The main bottleneck I expect to see is scaling the commit-thread. The read threads parallelize beautifully. There’s one commit-thread that’s applying each transaction one at a time. It turns out the disk latency is irrelevant for this, since the Raft algorithm will just commit multiple transactions together to disk. My main concern is that the CPU cost for applying the transactions will exceed the single core performance. I highly doubt that I would ever see this, but it’s a possibility. At this point we could profile the cost of commits and improve it (for instance, move some of the work out of the transaction thread), or we could just figure out sharding. I’ll probably write another blog post when that happens. Our Stack Now that I’ve described the idea to you, let me tell you about our stack, and why it turned out to be so suitable for this architecture. We use Common Lisp. My initial implementation of Screenshotbot did use MySQL, but I quickly swapped it out for bknr.datastore exactly because handling concurrency with MySQL was hard and Screenshotbot is a highly concurrent app. BKNR Datastore is a library that handles the architecture described in the Explore section, but built for Common Lisp. (There are similar libraries for other languages, but not a whole lot of them.) Common Lisp is also heavily multi-threaded, and this is going to be crucial for this architecture since your web requests are being handled by threads in a single process. Ruby or Python would be disqualified by this requirement. We also use the idea of closures that I mentioned earlier. But this means we can’t keep restarting the server frequently (if you restart the server, you lose the closures). So reloading code is just hot-reloading code in the running process. It turns out Common Lisp is excellent at this: so much so that a large part of the standard is all about handling reloading code. (For instance, if the class definition changes, how do you update objects of that class? There’s a standard for it.) Occasionally, we do restart the servers. Currently, it looks like we only restart the servers about once every month or two months. When we need to do this, we just do a rolling restart with our Raft cluster. We use a cluster of 3 servers per installation, which allows for one server to go down. We don’t use Kubernetes, we don’t need it (at least, not yet). For the Raft implementation, we wrote our own custom library built on top of bknr.datastore. We built and open-sourced bknr.cluster, that under the hood uses the fantastic Braft library from Baidu. Braft is super solid, and I can highly recommend it. Braft also handles background snapshots, which means while we’re taking snapshots, the server can still continue serving requests. To store image files, or blobs that shouldn’t be part of the datastore, we use EFS (a highly available NFS) that is shared between the three servers. EFS is easier to work with than S3, because we don’t have to handle error conditions. EFS also makes our code more testable, since we aren’t interacting with an external server, and just writing to disk. How well does this scale? We have a couple of big enterprise customers, but one especially well-known customer. Screenshotbot runs on their CI, so we get API requests 100s of times for every single commit and Pull Request. Despite this, we only need a 4-core 16GB machine to serve their requests. (And similar machines for the replicas, mostly running idle.) Even with this, the CPU usage maxes out at 20%, but even then most of that comes from image processing, so we have a lot of room to scale before we need to bump up the number of cores. Summary I think this architecture is excellent for new startups, and I’m hoping more companies will adopt it. Obviously, you’ll need to build out some of the tooling we’ve built out for the language of your choice. (Although, if you choose to use Common Lisp, it’s all here for you to use, and all open-source.) We’re super grateful to the folk behind bknr.datastore, Braft and Raft, because without their work we wouldn’t be able to do any of this. If you think this was useful or interesting, I would appreciate it if you could share it on social media. Please reach out to me at arnold@screenshotbot.io if you have any questions. Share this: Twitter LinkedIn Facebook Like Loading... Related Published by Arnold Noronha CEO, Screenshotbot View all posts by Arnold Noronha Published August 10, 2024August 10, 2024",
    "commentLink": "https://news.ycombinator.com/item?id=41206908",
    "commentBody": "Building a highly-available web service without a database (screenshotbot.io)216 points by tdrhq 16 hours agohidepastfavorite127 comments oefrha 15 hours agoSeems weird to start with “not talking about using something like SQLite where your data is still serialized”, then end up with a home grown transaction log that requires serialization and needs to be replicated, which is how databases are replicated anyway. If your load fits entirely on one server, then just run the database on that damn server and forget about “special architectures to reduce round-trips to your database”. If your data fits entirely in RAM, then use a ramdisk for the database if you want, and replicate it to permanent storage with standard tools. Now that’s actually simple. reply Groxx 14 hours agoparentI do feel like this largely summarizes as \"we built our own sqlite + raft replication\", yeah. But without sqlite's battle-tested reliability or the ability to efficiently offload memory back to disk. So, basically, https://litestream.io/ . But perhaps faster switching thanks to an explicit Raft setup? I'm not a litestream user so I'm not sure about the subtleties, but it sounds awfully similar. That overly-simplified summary aside, I quite like the idea and I think the post does a pretty good job of selling the concept. For a lot of systems it'll scale more than well enough to handle most or all of your business even if you become abnormally successful, and the performance will be absurdly good compared to almost anything else. reply oefrha 11 hours agorootparentThey basically only save on serialization & deserialization at query time, which I would consider an infinitesimal saving in the vast majority of use cases. They claim to be able to build some magical index that's not possible with existing disk-based databases (I didn't read the linked blog post). They lose access to a nice query language and entire ecosystems of tools and domain knowledge. I fail to see how this little bit of saving justifies all the complexity for run-of-the-mill web services that fit on one or a few servers as described in the article. The context isn't large scale services where 1ms/request saving translates to $$$, and the proposal doesn't (vertically) scale anyway. reply rrrix1 2 hours agorootparentYou should probably RTFA before making broad assumptions on their solution and how it works. Most of what you wrote is both incorrect and addressed in the article. reply oefrha 6 hours agorootparentprevOne thing I forgot to mention: if you use a not-in-process RDBMS on the same machine you also incur some socket overhead. But that’s also small. reply kitd 13 hours agorootparentprevRqlite would be a better comparison. It is actually SQLite + raft https://github.com/rqlite/rqlite reply Groxx 1 hour agorootparentI'll throw in a \"ehh... sorta\" though rqlite is quite neat and very much worth considering. The main caveat here is that rqlite is an out-of-process database, which you communicate with over http. That puts it on similar grounds as e.g. postgres, just significantly lighter weight, and somewhat biased in favor of running it locally on every machine that needs the data. So minimum read latency is likely much lower than postgres, but it's still noticeable when compared to in-process stuff. reply otoolep 9 hours agorootparentprevrqlite author here, happy to answer any questions. reply lifeisstillgood 8 hours agorootparentSo some dumb questions if you don’t mind - In GitHub readme you mention etcd / consul. Is rqlite suitable for transaction processing as well ? - I am imagining a dirt simple load balancer over two web servers. They are a crud app backed onto a database. What is the disadvantages of putting rqlite on each server compared to say having a third backend database. reply otoolep 8 hours agorootparentAs for your second question, I don't think you'd benefit much from than that, for two reasons: - rqlite is a Raft based system, with quorum requirements. Running 2-node systems don't make much sense. [1] - Secondly, all writes go to the Raft leader (rqlite makes sure this happens transparently if you don't initially contact the Leader node [2]). A load balancer, in this case, isn't going to allow you to \"spread load\". What is load balancer is useful for when it comes to rqlite is making life simpler for clients -- they just hit the load balancer, and it will find some rqlite node to handle the request (redirecting to the Leader if needed). [1] https://rqlite.io/docs/clustering/general-guidelines/#cluste... [2] https://rqlite.io/docs/faq/#can-any-node-execute-a-write-req... reply otoolep 8 hours agorootparentprevIt depends on what kind of transaction support you want. If your transactions need to span rqlite API requests then no, rqlite doesn't support that (due to the stateless nature of HTTP requests). That sort of thing could be developed, but it's substantial work. I have some design ideas, it may arrive in the future. If you need to ensure that a given API request (which can contain multiple SQL statements) is atomically processed (all SQL statements succeed or none do) that is supported however [1]. That's why I think of rqlite as closer to the kind of use cases that etcd and Consul support, rather than something like Postgres -- though some people have replaced their use of Postgres with rqlite! [2] [1] https://rqlite.io/docs/api/api/#transactions [2] https://www.replicated.com/blog/app-manager-with-rqlite reply lifeisstillgood 7 hours agorootparentThank you - so my takeaway is that rqlite is well suited for distributed “publishing” of data ala etcd, but it is possible to use it as a Postgres replacement - thank you I will give it a go reply otabdeveloper4 10 hours agorootparentprevSQlite doesn't do Raft. There isn't any simple way to do replicated SQlite. (In fact, writing your own database is probably the simplest way currently, if SQlite+Raft is actually what you want.) reply carderne 7 hours agorootparentWhat about rqlite? reply bingo-bongo 13 hours agoparentprevYou don’t even need a ram disk imho, databases already cache everything in memory and only writes reach the disk. Just try and cold-start your database and run a fairly large select twice. reply piker 11 hours agorootparentAlso the OS will cache a lot of the reads even if your database isn’t sophisticated enough or tuned correctly. Still could be a fun exercise, as with all things on here. reply LtdJorge 1 hour agorootparentAny half decent DBMS bypasses the page cache, except for LMDB. reply tdrhq 5 hours agoparentprevI think it's important to understand that every startup goes through three phases: Explore, Expand, Extract. What's simple in one phase isn't simple in the other. A transactional database is simple in Expand and Extract, but adds additional overhead during the Explore phase, because you're focusing on infrastructure issues rather than product. Data reliability isn't critical in the Explore phase either, because you just don't have customers, so you just don't have data. Having everything in memory with bknr.datastore (without replication) is simple in the Explore phase, but once you get to Expand phase it adds operational overhead to make sure that data is consistent. But by the time I've reached the Expand phase, I've already proven my product and I've already written a bunch of code. Rewriting it with a transactional database doesn't make sense, and it's easier to just add replication on top of it with Raft. reply gtirloni 2 hours agorootparentI'd assume in the beginning you do not want to spend time writing a bunch of highly difficult code until you've proven your idea/product. Then when you're big enough and have the money, start replacing things where it makes sense. It seems to be the strategy used by many companies. Unless, of course, your startup is in the business of selling DBMSes. reply Groxx 1 hour agorootparentprevHaving Explored with a transactional database: I really can't agree. Just change your database, migrations are easy and should be something you're comfortable doing at any time, or you'll get stuck working around it for 100x more effort in the future. reply robertclaus 14 hours agoparentprevAgreed. Reinventing the WAL means reinventing (or ignoring) all the headaches that come with it. I got the impression it takes them a long time to recover from the logs, so they likely haven't even gotten as far as log checkpointing. reply chipdart 12 hours agorootparent> Agreed. Reinventing the WAL means reinventing (or ignoring) all the headaches that come with it. But if the blogger learned SQLite, how would they have a topic to blog about? Also, no benchmarks. It's quite odd that an argument grounded on performance claims does not bother to put out any hard data comparing the output of this project. I'm talking about basic things like how does this contrived custom ad-hoc setup compare with vanilla, out-of-the-box SQLite deployment? Which one performs worse and by how much? How does the performance difference reflect in request times and infrastructure cost? Does it actually pay off to replace the dozen lines of code of on boarding SQLite with a custom, in-development, ad-hoc setup? I mean, I get the weekend personal project vibe of this blog post, but if this is supposed to be a production-minded project then step zero would have been a performance test on the default solution. Where is it? reply bjornsing 11 hours agorootparentprev> I got the impression it takes them a long time to recover from the logs, so they likely haven't even gotten as far as log checkpointing. The OP starts out by talking about periodically dumping everything in RAM to disk. I’d say that’s your checkpointing. reply nine_k 12 hours agoparentprevTrading systems bluntly keep everything in RAM, in preallocated structures. It all depends on the kind of tradeoffs you're willing to make. reply ahoka 11 hours agorootparentI used to work on a telecom platform (think something that runs 4G services), where every node was just part of an in-memory database that replicated using 2PC and just did periodic snapshot to avoid losing data. Basically processes were colocated with their data in the DB. reply phamilton 32 minutes agorootparentVery erlang/otp. Joe Armstrong used to rant to anyone who would listen that we used databases too often. If data was important, multiple nodes probably need a copy of it. If multiple nodes need a copy, you probably have plenty of durability. Even if you weren't using erlang, his influence (and in general, ericsson) permeates the telecom industry. reply icedchai 3 hours agorootparentprevI worked on a lottery / casino system that was similar. In memory database ( memory mapped files), with a WAL log for transaction replay / recovery. There was also a periodic snapshot capability. It was incredibly low latency on late 90's era hardware. reply ActorNightly 9 hours agoparentprevSetting up a single server with database replication and restore functionality is arguably more complex then setting this up. There are libraries available to wrap your stuff with this algorithm, and the benefit is that you write your server like it would run on a single machine, and then when launching it in prod across multiple, everything just works. reply troupo 2 hours agoparentprev> ”. If your data fits entirely in RAM, then use a ramdisk for the database if you want, and replicate it to permanent storage with standard tools Then you get used to near-zero latency that in-RAM data gives you, and when it outgrows your RAM, it's a pain in the butt to move it to disk :) reply jb3689 2 minutes agoprevWe wanted to simplify our architecture and not use a database, so instead we created our own version of everything databases already do for us. Super risky for a company. Hopefully you don’t spend all of your time maintaining, optimizing, and scaling this custom architecture. reply paxys 6 hours agoprevThere is so much wrong with this I don't know where to even start. You want to \"keep things simple\" and not stand up a separate instance of MySQL/Postgres/Redis/MongoDB/whatever else. So, you: 1. Create your own in-memory database. 2. Make sure every transaction in this DB can be serialized and is simultaneously written to disk. 3. Use some orchestration platform to make all web servers aware of each other. 4. Synchronize transaction logs between your web servers (by implementing the Raft protocol) and update the in-memory DB. 5. Write some kind of conflict resolution algorithm, because there's no way to implement locking or enforce consistency/isolation in your DB. 6. Shard your web servers by tenant and write another load balancing layer to make sure that requests are getting to the server their data is on. Simple indeed. reply karmakaze 4 hours agoparentI played with making an in-memory database too, but I wouldn't recommend anyone use one in production unless they have strict latency requirements. Simple is what people are already using. And beware 'good for startups' tech. If you're successful you'll have legacy 'bad for scale' tech. reply SoftTalker 1 hour agoparentprevYeah and good luck when the CEO starts asking for reports and metrics (or anything else that databases have been optimized over the last 50 years to do very well). Surely this is a parody article of some sort? reply ozim 4 hours agoparentprevI don’t want to go ad personam on the blog author - but checking his socials he is not really experienced person. I don’t think we have anything to discuss here. He seems just to want to do cool stuff and his drop of databases seems to be because he just doesn’t know a lot of stuff there is to know. I applaud attempt and might be that his needs will be covered by what he is doing. But for everyone else yes, pick boring technology if you want to do startup because technology shouldn’t be hard or something you worry about if you are making web applications. reply mtlynch 2 hours agorootparent>I don’t want to go ad personam on the blog author - but checking his socials he is not really experienced person. According to LinkedIn: - Masters in CS from UPenn - 1 year as SWE at Google - 6 years as SWE at FB/Meta - 6 years running his own company When I hear \"not really experienced,\" I think recent college grad, not someone with a Master's and 15 years of industry experience. reply tdrhq 4 hours agorootparentprev> but checking his socials he is not really experienced person. I'm not sure what qualifies as experience if Meta/Google doesn't. ;) reply ozim 4 hours agorootparentWell he is not Kent Beck or Jon Skeet, Martin Fowler - that is what I call experienced to take seriously a blog post. Just working at Meta/Google doesn’t impress me much just like Shania Twain would sing. reply rrrix1 2 hours agorootparent> he is not Kent Beck or Jon Skeet, Martin Fowler Just FYI, you are (perhaps unintentionally) showing your lack of experience. There are many thousands of brilliant engineers for every brilliant engineer who also is a author/speaker/publisher. These are very different skills. Also, perhaps the author _is_ the next Martin Fowler? You never know... reply theideaofcoffee 15 hours agoprevI get the desire to experiment with interesting things, but it seems like such a huge waste of time to avoid having to learn the most basic aspects of MySQL or postgres. You could \"just\" build on top of and be done with it, especially if you're running in a public cloud provider. I don't buy the increased RTT or troubles with concurrency issues, the latter having simple solutions by basic tuning, or breaking out your noisy customers. There's another post on their blog mentioning the possibility of adding 10 million rows per day and the challenges of indexing that. That's... literally nothing and I don't think even 10x that justifies having to engineer a custom solution. Worse is better until you absolutely need to be less worse, then you'll know for sure. At that point you'll know your pain points and can address them more wisely than building more up front. reply chipdart 12 hours agoparent> I get the desire to experiment with interesting things, but it seems like such a huge waste of time to avoid having to learn the most basic aspects of MySQL or postgres. For server-based database engines you can still make an argument on shedding network calls. It's dubious, but you can. What's baffling is that the blogger tries to justify not picking up SQLite claiming it might have features that they don't need, which is absurd and does not justify anything. The blog post reads like a desperate attempt to start with a poor solution to a fictitions problem and proceed to come up with far-fetched arguments hoping to reject the obvious solution. reply wongarsu 7 hours agorootparentIf you want to shed network calls, the easiest solution would be to just run postgres or MySql on the same server and connecting to it via Unix domain socket. So even if SQLite wasn't an option network overhead isn't a good argument reply ksec 2 hours agoprev>RAM is super cheap I think this has to be the number one misunderstanding for developers. Yes, SSD in terms of throughput or IOPs has gone up by 100 to 10000x. vCPU performance per dollar has gone up by 20 - 50x. We went from 45/32nm to now 5nm/3nm, and much higher IPC. But RAM price hasn't gotten anywhere near the same fall as CPU or SSD. It may have gotten a lot faster, you may be even getting to stick lots of memory with higher density chip and channels went from dual to 8 or 12. But if you look at the DRAM Spot price since 2008 to 2022, you will see the lowest DRAM price has been the same at around $2.8/GB for three times. As the DRAM price goes in cycle with $8 / $6 per GB in between this same period. i.e Had you bought DRAM at its lowest point or its highest point during the past ~15 years your DRAM would have cost roughly the same plus or minus 10-20% ignoring inflation. It was only until Mid 2022 it finally broke through the $2.8/GB barrier and collapse close to $1/GB before settling on ~ $2/GB for DDR5. Yes you can now get 4TB RAM on a server. But it doesn't mean DRAM are super cheap. Developers on average or for those in big Tech are now earning way more than they were in 2010. Which makes them think RAM has gotten a lot more affordable. In reality even in the lowest point over past 15 years you only get at best slightly more than 2x reduction in DRAM price. And we will likely see DRAM price shot up again in a year or two. reply rrrix1 1 hour agoparentAn alternative interpretation is that the maximum RAM capacity for an individual node has drastically increased over the last couple of decades. A simplistic example, if a given node was limited to 16GB of RAM 20 years ago, I would need 256 nodes to have 4TB of RAM for my system (not including overhead for each OS). Compared to today, where a single node can have that entire 4TB all in one chassis. The total cost of RAM chips themselves may not have changed, but the actual cost of using that RAM in a physical system has dropped dramatically. reply klysm 2 hours agoparentprevSimultaneously, many developers reach for distributed systems too quickly when they could just buy more ram. Perhaps that’s what the writer means reply 0x74696d 5 hours agoprevThis architecture is roughly how HashiCorp's Nomad, Consul, and Vault are built (I'm one of the maintainers of Nomad). While it's definitely a \"weird\" architecture, the developer experience is really nice once you get the hang of it. The in-memory state can be whatever you want, which means you can build up your own application-specific indexing and querying functions. You could just use sqlite with :memory: for the Raft FSM, but if you can build/find an in-memory transaction store (we use our own go-memdb), then reading from the state is just function calls. Protecting yourself from stale reads or write skew is trivial; every object you write has a Raft index so you can write APIs like \"query a follower for object foo and wait till it's at least at index 123\". It sweeps away a lot of \"magic\" that normally you'd shove into a RDBMS or other external store. That being said, I'd be hesitant to pick this kind of architecture for a new startup outside of the \"infrastructure\" space... you are effectively building your own database here though. You need to pick (or write) good primitives for things like your inter-node RPC, on-disk persistence, in-memory transactional state store, etc. Upgrades are especially challenging, because the new code can try to write entities to the Raft log that nodes still on the previous version don't understand (or worse, misunderstand because the way they're handled has changed!). There's no free lunch. reply lpapez 9 hours agoprevI once saw a project in the wild where the \"database\" was implemented using filesystem directories as \"tables\" with JSON files inside as \"rows\". When I asked people working on it if they considered Redis or Mongo or Postgres with jsonb columns, they just said they considered all of those things but decided to roll out their own db anyway because \"they understood it better\". This article gives off the same energy. I really hope it works out for you, but IMO spending innovation tokens to build a database is nuts. reply ActorNightly 9 hours agoparentThis isn't innovation though. You literally just write your server like you would for a single machine, then wrap it any of the available Raft libraries. AWS and other cloud providers are money printers because a lot of engineers are insanely tied into established patterns of doing things and can't think through things at a fundamental level. Ive seen company backends where their entire AWS stacks could be replaced by a 2 EC2 instances behind a load balancer with a domain name, without affecting business flow. We did something similar to the work in the OP post at my work, we had a bunch of ECS tasks for a service, where the service did another call to an upstream service to fetch some intermediate results. We wanted to cache results for lower response latency. People were working to set up a Redis cluster. Except the TPS of the service was like 0.1. Took me one day to code a /sync api endpoint, which was just a replica of the main endpoint. The only difference is that the main endpoint would spin of a thread to call the /sync endpoint, whereas the /sync endpoint didn't. Both endpoints ended with caching the results in memory before returning. Easy as day, no additional infra costs necessary. But overall, personally, I don't hate the \"spending innovation tokens to build a database is nuts\" sentiment too much, because it keeps me employed at high salary while doing minimal work, where things that really should be basic CS are considered innovation. reply gtirloni 2 hours agorootparentSoftware Engineering is different than CS though. reply jmull 4 hours agoparentprevI get your point and I don’t doubt the project you’re talking about was a mess, but the file system is a database, and can be a very good choice, depending on exactly what you’re doing. reply rrrix1 1 hour agorootparentThe file system is a database and an API. Magic! reply leokennis 10 hours agoprevI’m not from “start up world” but in the end, few things give me more comfort and lack of surprises down the line than just having a relational database with built in redundancy/transaction logs/back up/recovery. Sure there might always be edge cases (lack of money, regulations, specialist software offering) but in the vast majority of cases - just get a database. reply gunapologist99 5 minutes agoparentIt's interesting you say \"backup/recovery\" as a strong point of relational databases (servers), because backup and recovery on hot databases have always been a challenge. With many enterprise databases these days, often \"incremental\" or other seemingly required backup modes are not included in the \"community source\" versions; perhaps because surely if you want your database to be backed up safely and then come back online safely, you certainly will fall into the \"contact us for quote\" enterprise customer demographic. At least, with SQLite, copying even a hot (in-use) db file to a remote server will usually \"just work\", with the potential loss of a few transactions, but with most other database/servers, you definitely can't just backup the data directory occasionally and call it a day. reply nephy 15 hours agoprevWe didn’t want to build something complicated, so we implemented our own raft consensus layer. Have you considered just using Redis? reply gunapologist99 2 minutes agoparentRedis is best as an in-memory cache, not a database. Having used it in production for roughly a decade, I don't trust it's on-disk capabilities (AOF/RDB etc) as either solid or reliable (or even performant) in an emergency scenario, especially with DR or DB migration in mind. reply tdrhq 15 hours agoparentprevHaha, I totally hear you. But but, we didn't really build the raft consensus layer from scratch. We used an existing robust library for that: https://github.com/baidu/braft reply ramon156 11 hours agorootparentYou completely skipped the question though reply ActorNightly 9 hours agoparentprevTo throw the question back at you: have you considered that this isn't complicated? reply echoangle 4 hours agorootparentCompared to installing, configuring and maintaining an installation of Redis, this absolutely is complicated. Do you think this is less complicated than using Redis? reply nephy 6 hours agorootparentprevNo I haven’t because it’s quite complicated. Databases are very much a solved problem. Unfortunately, this architecture is going to be nigh impossible to hire for and when it goes absolutely sideways recovery will be difficult. reply ahoka 3 hours agorootparentThat’s the best part, you don’t realize when things go sideways. reply 1oooqooq 8 hours agoparentprevredis and mongo are the type of things i will yak shave to no ends so i don't have to deploy them in production reply nephy 6 hours agorootparentI’m honestly not sure what you are talking about. In my experience, Redis is super easy to run and manage in production. reply ahoka 3 hours agorootparentIf you like split brains, yes. :) reply Zak 15 hours agoprevDecades ago, PG wrote that he didn't use a database for Viaweb, and that it seemed odd for web apps to be frontends to databases when desktop apps were not[0]. HN also doesn't use a database. That's no longer true, with modern desktop and mobile apps often using a database (usually SQLite) because relational data storage and queries turn out to be pretty useful in a wide range of applications. [0] https://www.paulgraham.com/vwfaq.html reply chipdart 12 hours agoparent> Decades ago, PG wrote that he didn't use a database for Viaweb, and that it seemed odd for web apps to be frontends to databases when desktop apps were not[0]. After reading the link, I don't think that database means the same thing for everyone. The vwfaq still mentions loading data from disk, and also mention \"start up a process to respond to an HTTP request.\" This suggests that by \"database\" they meant a separate server dedicated to persist data, and having to communicate with another server to fetch that data. Obviously, this leaves SQLite out of this definition of database. Also, if you're loading data from disk already, either you're using a database or you're implementing your own ad-hoc persistence layer. Would you still consider you're using a database if you load data from SQLite at app start? The problem with this sort of mental model is that it ignores the fact that the whole point of a database is to persist and fetch data in a way that is convenient to you without having to bother about low-level details. Storing data in a database does not mean running a postgres instance somewhere and fetching data over the web. If you store all your data in-memory and have a process that saves snapshots to disk using a log-structured data structure... Congratulations, you just developed your own database. reply tdrhq 13 hours agoparentprevI was certainly inspired by PG's writing (after all we do use Common Lisp, and it's hard to avoid PG in this space). But I don't think they did things like transaction logs like how bknr.datastore does, which makes the development process a lot more seamless. reply cultofmetatron 7 hours agoparentprevit was a different time. to my knowledge, viaweb was a series of common lisp instances. All states for a user session was held IN MEMORY on the individual machine. I remember reading somewhere that they would be on a call with a user on production and patch bugs in real time while they were on the phone. The web has gotten bigger and a lot of these practices simply would not fly today. If I was pushing a live fix on our prod machine with the amount of testing doing it live while on the customer is on the phone entails today, a good portion of you would be questioning my sanity. reply Zak 4 hours agorootparentAn important reason that practice wasn't as reckless as it sounds is that early Viaweb was just a page builder. The actual web stores its customers were building were static HTML, so updating a customer's instance while talking to them on the phone only affected that one user's backend. reply never_inline 14 hours agoparentprevI think even SQLite itself wasn't as ubiquitous (edit: it didn't exist) when pg write viaweb. If SQLite wasn't there and my options were basically key value stores, I could as well use filesystem in most cases. Second, querying the RDBMS has been much simplified in past 20 years. We have all kind of ORMs and row mappers to reduce the boilerplate. We also got advanced features like FTS which are useful for desktop and mobile apps. Today it's a good choice to use RDBMS for desktop apps. reply zimpenfish 7 hours agorootparent> If SQLite wasn't there and my options were basically key value stores Well, there were \"options\" other than KV stores - MySQL launched a month before Viaweb (but flakey for a good long while.) Oracle was definitely around (but probably $$$$.) mSQL was being used on the web and reasonably popular by 1995 (cheap! cheerful! not terrible!) (definitely understand making your own in-memory DB in 1995 though) reply knallfrosch 7 hours agorootparentprev> Today it's a good choice to use RDBMS for desktop apps. Is there an alternative? I haven't seen a \"local filesystem is okay as data storage\" software in the 21th century. reply endorphine 14 hours agoparentprevHN does not use a database?! Can you expand on that? It's very surprising to me. reply Zak 7 hours agorootparentIt just persists its in-memory data structures to disk. Here's the source of an old version; note uses of `diskvar` and `disktable`. A \"table\" here is just a hashtable. https://github.com/wting/hackernews/blob/master/news.arc reply 1oooqooq 7 hours agorootparentprevif pg is still stuck in the 90s lisp, if bet it's just a single process with the site in ram, using make-object-persistent and loading as needed (kinda like python pickle). that was all the rave for prototypes back then. reply exe34 13 hours agorootparentprevprobably uses the filesystem as the backing store reply szundi 10 hours agorootparentFilesystems these days are like dbs reply ahoka 3 hours agorootparentGood luck transactionally writing files to a random FS, but especially without access to native OS APIs. reply tofflos 3 hours agoprevCheck out https://eclipsestore.io (previously named Microstream) if you're into Java and interested in some of the ideas presented in this article. You use regular objects, such as Records, and regular code, such as java.util.stream, for processing, and the library does snapshotting to disk. I haven't tried it out but just thinking of how many fewer organizational hoops I would have to jump through makes we want to try it out: - No ordering a database from database operations. - No ordering a port opening from network operations. - No ordering of certificates. - The above times 3 for development, test and production. - Not having to run database containers during development. I think the sweet spot for me would be in services that I don't expect to grow beyond a single node and there is an acceptance for a small amount of downtime during service windows. reply nilirl 13 hours agoprevI'm baffled at the arguments made in this article. This is supposed to be a simpler and faster way to build stateful applications? The premises are weak and the claims absurd. The author uses overstatement of the difficulties of serialization just to make their weak claim stronger. reply t0mas88 13 hours agoparentAnd then they implement serialization to write their transactions to a log and replicate them to the other nodes... reply voidfunc 11 hours agoparentprevBig vibes of \"We are very smart, see how smart we are?\" from the blog post. These kind of people usually suck to work with. I'm glad they've found a startup to sink so I don't have to deal with them. reply donatj 3 hours agoprevI've got a handful of small Go applications where I just have a \"go generate\" command that generates the entire dataset as Go, so the data set ends up compiled into the binary. Works great. https://emoji.boats/ is the most public facing of these. I also have built a whole class of micro-services that pull their entire dataset from an API on start up, hold it resident and update on occasion. These have been amazing for speeding up certain classes of lookup for us where we don't always need entirely up to date data. reply oconnore 15 hours agoprevMy first thought was, “oh, I used to do this when I wrote Common Lisp, it’s funny someone rediscovered that technique in ”. But no, just more lispers. reply wmf 15 hours agoprevThis sounds a lot like Prevayler. https://prevayler.org/ reply tdrhq 15 hours agoparent[Author here] Indeed, bknr.datastore was inspired by Prevayler and similar libraries reply AdieuToLogic 13 hours agoprev> Imagine all the wonderful things you could build if you never had to serialize data into SQL queries. This exists in sufficiently mature Actor model[0] implementations, such as Akka Event Sourcing[1], which also addresses: > But then comes the important part: how do you recover when your process crashes? It turns out that answer is easy, periodically just take a snapshot of everything in RAM. Intrinsically and without having to create \"a new architecture for web development\". There are even open source efforts which explore the RAFT protocol using actors here[2] and here[3]. 0 - https://en.wikipedia.org/wiki/History_of_the_Actor_model 1 - https://doc.akka.io/docs/akka/current/typed/persistence.html 2 - https://github.com/Michael-Dratch/RAFT_Implementation 3 - https://github.com/invkrh/akka-raft reply jeremycarter 9 hours agoparentI have built some medium sized systems using Microsoft Orleans (Virtual Actors). There was no transactional database involved, but everything was ordered and fully transactional. If you choose say Cosmos DB, MongoDB or DynamoDB as your persistence provider you can even query the persisted state. https://learn.microsoft.com/en-us/dotnet/orleans/grains/grai... https://learn.microsoft.com/en-us/dotnet/orleans/grains/tran... https://learn.microsoft.com/en-us/dotnet/orleans/grains/even... reply Sn0wCoder 15 hours agoprevNot sure I would call that setup simple, but it is interesting. I have honestly never heard of ‘Raft’ or the Raft Consensus Protocol or bknr.datastore, so always happy to learn something on a Friday night. reply tdrhq 15 hours agoparentAuthor here. I agree, the infrastructure required to make this happen eventually gets quite complicated. But the developer experience is what's super simple. If somebody had to take all our infrastructure and just use it to build their next big app, they can get the simplicity without worrying about the internal plumbing. reply pclmulqdq 14 hours agoparentprevRaft is fantastic and most modern systems with more than one node are built on Raft. It is actually proven to be equivalent to Paxos, but the semantics of it are closer to what you would prefer as a software writer and the implementation is much simpler. reply annacappa 9 hours agoprevIt’s great that people explore new ideas. However this does not seem like a good idea. It claims to solve a bunch of problems by ignoring them. There are solid reasons why people distribute their applications across multiple machines. After reading this article I feel like we need to state a bunch of them. Redundancy - what if one machine breaks either a hardware failure a software failure or a network failure (network partition where you can’t reach the machine or it can’t reach the internet) Scaling- what if you can’t serve all of your customers from one machine ? Perhaps you have many customers and a small app or perhaps your app can use a lot of resources (maybe it loads gigs of data) Deployment - what happens when we want to change the code and not go down if you are running multiple copies of your app you get this for cheap There are tons of smaller benefits - right sizing your architecture What if the one machine you choose is not big enough you need to move to a new machine, with multiple machines you just increase the number of machines. You also get to use a variety of machine sizes and can choose ones that fit your needs so this flexibility allows you to choose cheaper machines I feel like the authors don’t know why people invented the standard way of doing things. reply annacappa 8 hours agoparentThe more I think about it the worse it gets. Because we don’t want everything to fall over when one machine goes down we need at least 3 machines (for raft). So if our traditional db would have 500 GB of data we now need 3 machines with 500 GB of ram running at all times. That is an epic waste of money. Millions per year to run ? And you could store it in a db for a couple of dollars. reply 1oooqooq 7 hours agorootparenttheir use case is mostly-never-retrieved images! they store the index of files only in memory. and have the entire build time to fetch build-1 images to get ready for the diff. it's much easier than most use cases reply annacappa 6 hours agorootparentSo all of this ram is being used and is only accessed sporadically if at all. This is not good. Sounds like you could implement the entire thing on a micro db instance (redis or a regular db) with no raft or any other custom implementation or messing. reply gchamonlive 6 hours agoprevThe problem is, you only know what you know. Sure you reduce deployment complexity, but what about maintaining your algorithm that implements data persistence and replication? To assume that will never spectacularly bite you is naive. Tests also only go so far as you know what you are testing for, and while you don't know if your product will ever be used, you also don't know if it will explode in success and you will be hostage of your own decisions and technical debt. These are HARD decisions. Hard decisions require solid solutions. You can surely try that with toy projects, but if I was in a position to build a software architecture for something that had a remote possibility of being used in production, I would oppose such designs adamantly. reply Tehdasi 14 hours agoprevHmm, but the problem with having in-memory objects rather than a db is you end up having to replicate alot of the features of a relational database to get a usable system. And adding all these extra features you want from those dbs end up making a simple solution not very simple at all. reply swiftcoder 10 hours agoparentTo some extent I think this is an \"if all you have is a hammer...\" situation. Relational DBs are often not a great fit for how contemporary software manages data in memory (hence the proliferation of ORMs, and adapter layers like graphql). I think it's often easier to write out one's relations in the data structures directly, rather than mapping them to queries and joins reply _the_inflator 9 hours agoprevThis reminds me of the heated discussions around jQuery by some so called performance driven devs, which cumulated into this website: https://youmightnotneedjquery.com/ The overwhelming majority underestimates the beauty and effort as well as experience that goes into abstractions. There are some true geniuses at times doing fantastic work, to deliver syntactical sugar while the critics mock the maybe somewhat larger bundle size for “a couple of lines frequently used.” That’s why. In the end, a good framework is more than just an abstraction. It guarantees consistency and accessibility. Try to understand the source code if possible before reinventing the wheel is my advice. What maybe starts out to be fun quickly becomes a burden. If there weren’t any edge cases or different conditions, you wouldn’t need an abstraction. Been there, done that. reply mg 13 hours agoprevWhen I start a new project, the data structure usually is a \"list of items with attributes\". For example right now, I am writing a fitness app. The data consists of a list of exercises and each exercise has a title, a description, a video url and some other attributes. I usually start by putting those items into YAML files in a \"data\" directory. Actually a custom YAML dialect without the quirks of the original. Each value is a string. No magic type conversions. Creating a new item is just \"vim crunches.yaml\" and putting the data in. Editing, deleting etc all is just wonderfully easy with this data structure. Then when the project grows, I usually create a DB schema and move the items into MariaDB or SQLite. This time, I think I will move the items (exercises) into a JSON column of an SQLite DB. All attributes of an item will be stored in a single JSON field. And then write a little DB explorer which lets me edit JSON fields as YAML. So I keep the convenience of editing human readable data. Writing the DB explorer should be rather straight forward. A bit of ncurses to browse through tables, select one, browse through rows, insert and delete rows. And for editing a field, it will fire up Vim. And if the field is a JSON field, it converts it to YAML before it sends it to Vim and back to JSON when the user quits Vim. reply joatmon-snoo 15 hours agoprevThis is cool! I’m always excited by people trying simpler things, as a big fan of using Boring Technology. But I have some bad news: you haven’t built a system without a database, you’ve just built your own database without transactions and weak durability properties. > Hold on, what if you’ve made changes since the last snapshot? And this is the clever bit: you ensure that every time you change parts of RAM, we write a transaction to disk. This is actually not an easy thing to do. If your shutdowns are always clean SIGSTOPs, yes, you can reliably flush writes to disk. But if you get a SIGKILL at the wrong time, or don’t handle an io error correctly, you’re probably going to lose data. (Postgres’ 20-year fsync issue was one of these: https://archive.fosdem.org/2019/schedule/event/postgresql_fs...) The open secret in database land is that for all we talk about transactional guarantees and durability, the reality is that those properties only start to show up in the very, very, _very_ long tail of edge cases, many of which are easily remedied by some combination of humans getting paged and end users developing workarounds (eg double entry bookkeeping). This is why MySQL’s default isolation level can lose writes: there are usually enough safeguards in any given system that it doesn’t matter. A lot of what you’re describing as “database issues” problem don’t sound to me like DB issues, so much as latency issues caused by not colocating your service with your DB. By hand-rolling a DB implementation using Raft, you’ve also colocated storage with your service. > Screenshotbot runs on their CI, so we get API requests 100s of times for every single commit and Pull Request. I’m sorry, but I don’t think this was as persuasive as you meant it to be. This is the type of workload that, to be snarky about, I could run off my phone[0] [0]: https://tailscale.com/blog/new-internet reply tdrhq 13 hours agoparent> This is actually not an easy thing to do. If your shutdowns are always clean SIGSTOPs, yes, you can reliably flush writes to disk. But if you get a SIGKILL at the wrong time, or don’t handle an io error correctly, you’re probably going to lose data. Thanks for the comment! This is handled correctly by Raft/Braft. With Raft, before a transaction is considered committed it must be committed by a majority of nodes. So if the transaction log gets corrupted, it will restore and get the latest transaction logs from the other node. > I’m sorry, but I don’t think this was as persuasive as you meant it to be. I wasn't trying to be persuasive about this. :) I was trying to drive home the point that you don't need a massively distributed system to make a useful startup. I think some founders go the opposite direction and try to build something that scales to a billion users before they even get their first user. reply joatmon-snoo 10 hours agorootparentWait, so you’re blocking on a Raft round-trip to make forward progress? That’s the correct decision wrt durability, but… I’m now completely lost as to why you believe this was a good idea over using something like MySQL/Postgres/Aurora. As I see it, you’ve added complexity in three different dimensions (novel DB API, novel infra/maintenance, and novel oncall/incident response) with minimal gain in availability and no gain in performance. What am I missing? (FWIW, I worked on Bigtable/Megastore/Spanner/Firestore in a previous job. I’m pretty familiar with what goes into consensus, although it’s been a few years since I’ve had to debug Paxos.) > I was trying to drive home the point that you don't need a massively distributed system to make a useful startup. I think some founders go the opposite direction and try to build something that scales to a billion users before they even get their first user. This reads to me as exactly the opposite: overengineering for a problem that you don’t have. For exactly the reasons you describe, I would argue the burden of proof is on you to demonstrate why Redis, MySQL, Postgres, SQLite, and other comparable options are insufficient for your use case. To offer you an example: let’s say your Big Customer decides “hey, let’s split our repo into N micro repos!” and they now want you to create N copies of their instance so they can split things up. As implemented, you’ll now need to implement a ton of custom logic for the necessary data transforms. With Postgres, there’s a really good chance you could do all of that by manipulating the backups with a few lines of SQL. reply aeinbu 9 hours agorootparent> As implemented, you’ll now need to implement a ton of custom logic for the necessary data transforms. With Postgres, there’s a really good chance you could do all of that by manipulating the backups with a few lines of SQL. Isn’t writing «a few Lines of SQL» also custom logic? The difference is just the language. It is also possible that the custom data store is more easily manipulated with other languages than SQL. SQL really is great for manipulating data, but not all relational databases are easy to work with. reply qprofyeh 9 hours agoprevWe used Redis with persistence to build our first prototype. It performed amazingly and development speed was awesome. We were a full year beyond break-even before adding MySQL to the stack for the few times we missed the ability to run SQL queries, for finance. reply antman 10 hours agoprevAs a side question is there a python library for braft or a production grade raft library for python? reply tdrhq 4 hours agoparentThere's a list of libraries here, which include a few Python libraries: https://raft.github.io/ I don't know if they're production grade. I was drawn to Braft because of Baidu's backing. reply hankchinaski 9 hours agoprevtextbook example of overengineering for no reason reply ibash 15 hours agoprev1. If your entire cluster goes down do you permanently lose state? 2. Are network requests / other ephemeral things also saved to the snapshot? reply tdrhq 14 hours agoparent[Author here] The transactions and snapshots are still logged to disk. So if the cluster goes down and comes back up, each one just reloads the state. Until at least two machines are back up, we won't be able to serve requests though. Not sure what you mean by ephemeral things. If you mean things like file descriptors, they are not stored. Technically the snapshot is not a simple snapshot of RAM, it snapshots through all the objects in memory that are set up to be part of the datastore. (It's a bit more complicated and flexible than this, but that's the general idea.) reply ibash 14 hours agorootparentAh awesome! Thank you! reply k__ 8 hours agoprevWell, at least they gave an example of what not to do. reply nesarkvechnep 13 hours agoprevIt’ll be interesting to do something like this in Elixir where clustering is almost a runtime primitive. reply andrewstuart 14 hours agoprevBut why, when you can build things in an ordinary way with ordinary tech like Python/Java/C#/TypeScript and Postgres. Lots of developers know it, lots of answers to your questions online, the AI knows how to write it. Reading posts like this makes me think the founders/CTO is mixing hobby programming with professional programming. reply nesarkvechnep 13 hours agoparentWhy not, though? Because you only know the languages you listed? reply andrewstuart 9 hours agorootparentA home grown maintenance nightmare. Try logging in and querying and working out what is going on. There's literally no reason to waste time doing all this. So many lines of pointless, wasted code. Which is absolutely fine if you are hobby programming but if you are running a business then this approach is wasteful. reply nickpsecurity 15 hours agoprevWhat they described early on in the article was basically how NUMA machines worked (eg SGI Altix or UV). Also, their claimed benefit was being able to parallelize things with multithreading in low-latency, huge RAM. Clustering came as a low-cost alternative to $1+ million machines. There’s similarities to persistence in AS/400, too, where apps just wrote memory that gets transparently mapped to disk. Now, with cheap hardware, they’re going back in time to the benefits of clustered, NUMA machines. They’ve improved on it along the way. I did enjoy the article. Another trick from the past was eliminating TCP/IP stacks from within clusters to knock out their issues. Solutions like Active Messages were a thin layer on top of the hardware. There’s also designs for network routers that have strong consistency built into them. Quite a few things they could do. If they get big, there’s hardware opportunities. On CPU side, SGI did two things. Their NUMA machines expanded the number of CPU’s and RAM for one system. They also allowed FPGA’s to plug directly into the memory bus to do custom accelerators. Finally, some CompSci papers modified processor ISA’s, networks on a chip, etc to remove or reduce bottlenecks in multithreading. Also, chips like OpenPiton increase core counts (eg 32) with open, customizable cores. reply aorloff 13 hours agoprevThis is like an example case of a lambda + kinesis reply golergka 12 hours agoprev> Imagine all the wonderful things you could build if you never had to serialize data into SQL queries. No transactions, no WAL, no relational schema to keep data design sane, no query planner doing all kinds of optimisations and memory layout things I don't have to think about? You could say that transactions, for example, would be redundant if there is no external communication between app server and the database. But it is far from the only thing they're useful for. Transactions are a great way of fulfilling important invariants about the data, just like a good strict database schema. You rollback a transaction if an internal error throws. You make sure that transaction data changes get serialised to disk all at once. You remove a possibility that statements from two simultaneous transactions access the same data in a random order (at least if you pick a proper transaction isolation level, which you usually should). > You also won’t need special architectures to reduce round-trips to your database. In particular, you won’t need any of that Async-IO business, because your threads are no longer IO bound. Retrieving data is just a matter of reading RAM. Suddenly debugging code has become a lot easier too. Database is far from the only other server I have to communicate with when I'm working on user's HTTP request. As a web developer, I don't think I've worked on a single product in the last 4 years that didn't have some kind of server-server communication for integrations with other tools and social media sites. > You don’t need crazy concurrency protocols, because most of your concurrency requirements can be satisfied with simple in-memory mutexes and condition variables. Ah, mutexes. Something that programmers never shot themselves in a foot with. Also, deadlocks don't exist. > Hold on, what if you’ve made changes since the last snapshot? And this is the clever bit: you ensure that every time you change parts of RAM, we write a transaction to disk. So if you have a line like foo.setBar(2), this will first write a transaction that says we’ve changed the bar field of foo to 2, and then actually set the field to 2. An operation like new Foo() writes a transaction to disk to say that a Foo object was created, and then returns the new object. A disk write latency is added to every RAM write. It has no performance cost and nobody notices this. I apologise if this comes off too snarky. Despite all of the above, I really like this idea — and already think of implementing it in a hobby project, just to see how well it really works. I'm still not sure if it's practical, but I love the creative thinking behind this, and a fact that it actually helped them build a business. reply briHass 5 hours agoparentI would add that the 'serialization' to a RDBMS-schema cites as a negative is actually a huge positive for most systems. Modeling your data relationally, often in 3NF, usually differs from the in-memory/code objects in all but the most simple ORM class=table projects. Thinking deeply about how to persist data in a way that makes it flexible and useful as application needs change (i.e. the database outlives the applications(s)) has value in itself, not just a pointless cost. I like being able to draw a hard line between application data structures, often ephemeral and/or optimized for particular tasks -- and the persisted, domain data which has meaning beyond a specific application use case. reply iammrpayments 14 hours agoprevIsn’t this like redis? reply LAC-Tech 9 hours agoprevReally got a kick out of this article. RAM is big, and cheap. And as we all know the database is the log, and everything else is just the cache. A few questions, comments! 1. I take it you've seen the LMAX talk [0], and were similarly inspired? :) 2. Are you familiar with the event sourcing approach? It's basically what you describe, except you don't flush to disk after editing every field, you batch your updates into a single \"event\". (you've come at it from the exact opposite end, but it looks like roughly the same thing). [0] https://www.infoq.com/presentations/LMAX/ reply apexkid 13 hours agoprev> periodically just take a snapshot of everything in RAM. Sound similar to `stop the world Garbage collection` in Java. Does your entire processing comes to halt when you do this? How frequently do you need to take snapshots? Or do you have a way to do this without halting everything reply tdrhq 13 hours agoparentGood catch! Snapshotting was certainly a bottleneck that I chose not to write about. But we aren't really taking the snapshot of RAM, instead we're running some code asking each object to snapshot itself into a stream. If you do this naively, it will block writes on the server until the snapshot is done (reads will continue to work). But Raft has a protocol for asynchronous snapshots. So in the first step we take an immutable fast snapshot of the state we care about which happens quickly, then writes can keep going while in the background we serialize the state to disk. reply jhardy54 14 hours agoprev> Hold on, what if you’ve made changes since the last snapshot? And this is the clever bit: you ensure that every time you change parts of RAM, we write a transaction to disk. So if you have a line like foo.setBar(2), this will first write a transaction that says we’ve changed the bar field of foo to 2, and then actually set the field to 2. An operation like new Foo() writes a transaction to disk to say that a Foo object was created, and then returns the new object. > > And so, if your process crashes and restarts, it first reloads the snapshot, and replays the transaction logs to fully recover the state. (Notice that index changes don’t need to be part of the transaction log. For instance if there’s an index on field bar from Foo, then setBar should just update the index, which will get updated whether it’s read from a snapshot, or from a transaction.) That’s a database. You even linked to the specific database you’re using [0], which describes itself as: > […] in-memory database with transactions […] Am I misunderstanding something? [0]: https://github.com/bknr-datastore/bknr-datastore reply localfirst 15 hours agoprev [–] I would use cloudflare R2 but its not globally distributed so its pointless using it on edge otherwise I get the messaging with edge you the database is the bottleneck just need a one stop shop to do edge functions + edge db reply tazu 11 hours agoparent [–] Cloudflare's durable objects seem similar to this article's \"objects in RAM\", but I think you still have to do some minimal serialization. reply jeremycarter 9 hours agorootparent [–] The Cloudflare durable object is very much the same as a Virtual Actor https://www.microsoft.com/en-us/research/project/orleans-vir... reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article proposes a novel architecture for building web services without traditional databases, leveraging advancements in RAM, disk storage, and the Raft Consensus algorithm.",
      "For startups, using RAM as a database simplifies architecture, speeds up data retrieval, and eases debugging, with periodic snapshots and transaction logs for crash recovery.",
      "High availability and scalability are achieved through the Raft Consensus Protocol for replication and sharding for clustering, as demonstrated by Screenshotbot's use of Common Lisp, BKNR Datastore, and EFS."
    ],
    "commentSummary": [
      "A blog post discusses building a highly-available web service without using a traditional database, sparking debate among tech enthusiasts.",
      "Critics argue that the approach essentially recreates existing database functionalities, such as transaction logs and replication, but with added complexity and potential reliability issues.",
      "The post has garnered attention due to its unconventional approach, prompting discussions on the practicality and efficiency of custom-built solutions versus established database systems like SQLite, MySQL, and Postgres."
    ],
    "points": 216,
    "commentCount": 127,
    "retryCount": 0,
    "time": 1723257475
  },
  {
    "id": 41205439,
    "title": "DARPA wants to bypass the thermal middleman in nuclear power systems",
    "originLink": "https://www.ans.org/news/article-6276/darpa-wants-to-bypass-the-thermal-middleman-in-nuclear-power-systems/",
    "originBody": "Research & Applications DARPA wants to bypass the thermal middleman in nuclear power systems Wed, Aug 7, 2024, 5:00PMNuclear News AI-generated concept image. (Image: DARPA) Nuclear power already has an energy density advantage over other sources of thermal electricity generation. But what if nuclear generation didn’t require a steam turbine? What if the radiation from a reactor was less a problem to be managed and more a source of energy? And what if an energy conversion technology could scale to fit nuclear power systems ranging from miniature batteries to the grid? The Defense Advanced Research Projects Agency (DARPA) Defense Sciences Office (DSO) is asking these types of questions in a request for information on High Power Direct Energy Conversion from Nuclear Power Systems, released August 1. DARPA is interested in ideas to take alpha, beta, gamma, and neutron radiation from “any type of reactor,” including fission and fusion, and from nuclear processes and radioisotope decay, and directly convert those radioactive emissions to electricity to meet the specific power and lifetime requirements of a range of nuclear power systems. Respondents have until Aug. 30 to share their ideas. There’s got to be a better way: “Methods to convert the energy of nuclear fission reactions and the decay of radioisotopes into electricity have not evolved since the invention of radioisotope power systems and fission reactors over 70 years ago and remain unoptimized,” the RFI says. They rely on thermal heat transfer, and “in each step of this indirect conversion method neutrons, heat, and energy are lost to the shielding material, working fluid, and other system materials.” Advanced reactor designs that use alternative coolants, including helium, sodium, and salts, would still use what DARPA calls “heritage nuclear power conversion technology” with water and steam as the working fluids, as would the fusion power plants being planned today. Why now? Tabitha Dodson, the program manager for DARPA DSO, which is launching the RFI, told Nuclear News that “two big things” are driving the interest. “One is the extreme surge of investment in small and advanced nuclear technologies, such as in fusion and space reactors, which do not have a concurrent pairing of advanced power generation methods that doesn’t involve liquid-based heat transfer,” she said. “Next, there has been an order of magnitude improvement in radiation tolerance and efficiency for voltaics in recent years with encouraging performance that indicates radiovoltaics could scale up as an array usable in nuclear reactors.” Exploring radiovoltaics: The RFI points to research in direct energy conversion based on radiation, or radiovoltaics, which includes semiconductor-based neutron, gamma, beta, and alpha voltaics. In radiovoltaics, radiation indirectly excites electron-hole pairs in a semiconductor lattice—a process that resembles but is distinct from how photons accomplish energy conversion in photovoltaics. Radiovoltaics has been used to generate electricity from small amounts of decaying radioisotopes to produce commercially available microelectronics and small batteries at the nanowatt to milliwatt levels. “At least two challenges, however, [prevent] these from being viable solutions today for simultaneous high-power, long-duration applications,” according to the RFI. Those challenges are efficiency—\"in most cases the efficiencies of radiovoltaics are 1–3 percent per radiation emission”—and the lifespan of candidate semiconductor materials, which is limited by their ability to withstand excess radiation energy over time and maintain performance. That’s where the order of magnitude improvement in performance that Dodson noted comes in. Recent years have seen “the discovery of radiation-resilient materials that are still able to carry electrons into the conduction band to drive current despite the incursion of radiation-driven defects,” she said. Now, DARPA is interested in the possibility of applying direct energy conversion beyond the milliwatt power levels that have been demonstrated, and in solutions optimized for neutron and gamma radiation from a fission or fusion reactor. Scaled to fit: If durable, efficient radiovoltaics can be developed, Dodson sees the potential for them to fit a range of electricity needs. “If we could make an array of cells that could be scaled to any broad area, this power generation method could be paired with any sized nuclear reactor or even nuclear radioisotope power system. It could even be scaled up to a commercial-sized power plant or down to tiny-sized microelectronics. What’s appealing about voltaics versus thermoelectrics or working-fluid methods are how thin, light, pliable, and scalable they could be to any size or form factor,” Dodson said. Dodson’s work at DARPA has included a key role in establishing and then serving as program manager of the nuclear thermal propulsion rocket program DRACO—the Demonstration Rocket for Agile Cislunar Operations. Space missions and deployments stand to gain from a scalable high power direct energy conversion technology. “The issues that come with outdated power generation equipment on the ground are magnified for space nuclear technologies since space reactors are size constrained and have to carry all of that equipment with them,” according to Dodson. Here on Earth, progress in neutron- and gamma-based radiovoltaics could lead to greater availability of small neutron and gamma detectors for reactor instrumentation and control, she noted. The RFI suggests that, with systems scaled for large-scale electricity generation and with improved material lifetimes and energy conversion efficiency, “one could create energy-generating ‘smart shields’ for nuclear systems that simultaneously cut down on nuclear waste.” In such shields, “neutron radiation from a fusion or fission reactor could transmute and decay radiovoltaic lattice materials doped or layered with isotopes that are tuned to absorb the reactor’s neutrons, thereafter generating secondary emission alpha or beta particles to further energize radiovoltaics.” What is the ask? The RFI asks: “Is it possible to achieve [a] direct energy conversion nuclear power system, ranging in power from 10s of watts electric (We) to 100s of kWe?” DARPA wants information “on the potential to improve specific power greater than 1 We/kg conversion from watts-thermal per radiation emission product,” and information on the potential to improve damage tolerance of the voltaic to nuclear radiation to reach an operating lifetime comparable to the life of its nuclear source, on the scale of decades. “We will learn what our boundary conditions are when respondents tell us what technologies in the field of voltaics are possible, and we’ll use that to see if there is sufficient scientific rationale make a case to present for further DARPA investment,” Dodson said. “I also hope people are going to start thinking about nuclear systems that use electromagnetic versus thermal-kinetic methods to harvest nuclear energetic reactions.” Responses can be submitted until 4 p.m. (EDT) on August 30. Questions can be directed to Dodson at DARPA-SS-24-01@darpa.mil. Tags: darpadodnuclear energy Share: LinkedInTwitterFacebookEmail",
    "commentLink": "https://news.ycombinator.com/item?id=41205439",
    "commentBody": "DARPA wants to bypass the thermal middleman in nuclear power systems (ans.org)179 points by bilsbie 21 hours agohidepastfavorite121 comments Animats 20 hours agoNuclear batteries with beta emitters driving some kind of semiconductor have been around for a while, but they're very low power.[1] \"... Betavolt's team of scientists developed a unique single-crystal diamond semiconductor that is only 10 microns thick, placing a 2-micron-thick nickel-63 sheet between two diamond semiconductor converters to convert the decay energy of the radioactive source into electric current to form an independent unit.\" \"... 100 microwatts, a voltage of 3V, and a volume of 15 X 15 X 5 cubic millimeters ...\" 3-4 orders below the power requirements for a phone. An AirTag-type intermittent device, though... So, can those be scaled up? Are all those little beta-emitters in coin cell form factor going to be a problem? Nickel-63 has a half life of 100 years, so they'll be active for a while. Not dangerous unless broken up and ingested, but need to be kept out of the food chain. [1] https://www-betavolt-tech.translate.goog/359485-359485_64506... reply saulrh 20 hours agoparentNot dangerous unless broken up and ingested, but need to be kept out of the food chain. No worse than a NiCad in that respect. Probably better, if anything, since it's so much easier to detect and track. reply hilbert42 19 hours agorootparentWithout going into too many specifics, for a period during my career I was involved with an organization whose responsibility it is to track nuclear materials and keep them under safe surveillance—in fact my job had the words 'surveillance engineer' in its title. I say that only bring to your attention how difficult this would be in practice. Putting safety aside for a moment, in most countries the regulatory restrictions are enormous because they are signatories to the NPT—Treaty on the Non-Proliferation of Nuclear Weapons which tightly bind them to how they use and handle nuclear materials. This involves, use, tracking, short and long-term disposal thereof not to mention how to keep radioactive materials away from bad actors/those who've ill intent. With safety, there are so many issues involved that I can hardly even mention them here. Just as an illustration, the once lack of regulations covering the manufacture and use of luminous radium paint turned out to be a disaster. I've thought about this a great deal, whenever the batteries in my flashlight die I wish I had some nuclear powered ones and evey time I'm brought back to reality when I think how difficult it would be to implement in practice. reply jessriedel 13 hours agorootparent> With safety, there are so many issues involved that I can hardly even mention them here. Just as an illustration, the once lack of regulations covering the manufacture and use of luminous radium paint turned out to be a disaster. I think it's telling that the big health disaster everyone remembers happened like a hundred years ago and occurred not just before regulation, but before the danger was even understood. There are negligible annual deaths in the US from either acute radiation exposure or nuclear-material-related chronic radiation exposure. reply defrost 13 hours agorootparentThree US workers died in 1961 when the SL-1 reactor went prompt critical and the core explosively vaporized. All up there are at least seven or eight fatalities in US reactorresearch facilities in that general time frame, Los Alamos National Laboratory, et al. The Columbus radiotherapy accident 1974-76 led to 10 deaths and 88 \"immediate severe complications\" There was another in Houston in 1980 with 9 deaths and additional complications. https://en.wikipedia.org/wiki/SL-1 https://en.wikipedia.org/wiki/Columbus_radiotherapy_accident REAC/TS Radiation Accident Registry: : https://www.irpa.net/irpa10/cdrom/00325.pdf reply jessriedel 13 hours agorootparentThanks but I think this proves my point? A handful of deaths each decade, in an industry with hundreds of thousands of workers. Like, being killed by a falling I beam or in a car accident while commuting to work are vastly more likely. reply defrost 11 hours agorootparentI agree with your point; there are negligible annual deaths in the US from meteorite strikes. I've had a career mapping environmental radiation across entire countries; background uranium, potassium, and thorium and residual traces from testing, mining and accidents. Deaths are rare in the US, a bit more common elsewhere, that's a fact. I can't say that's an argument for relaxing standards or being less safety conscious in reactor design, building codes, or medical and industrial procedures. The Union Carbide Corporation (UCC) of the United States demonstrated pretty well what can happen if you shirk safety and that was just manufacturing pesticides. There's always that one meteorite. Mind you, there's a steady supply of radioactive waste from rare earth processing that gets offshored and swept under the carpet .. it's okay to have an addiction to fancy electronic gadgets, less so to be ignorant of by products and the harm caused in other peoples backyards. reply roenxi 8 hours agorootparent> The Union Carbide Corporation (UCC) of the United States demonstrated pretty well what can happen if you shirk safety and that was just manufacturing pesticides. > There's always that one meteorite. But we just ignore the meteorite. Nobody has made any attempt to stop either of us being hit by a meteorite. We just let it fall where it may. We've had safety standards shirked, we've had multiple disasters and the worst case scenario so far appears to be order-of-magnitude equal to a normal year of current practice using fossil fuels. It seems to be well within our tolerance for risk. The issue here is that progress on one of the most promising sources of energy we have has been blocked and it is hard to find someone who can articulate a reason why, let alone a good reason. Between Germany and Japan we've had countries that appear to be more willing to risk deindustrialisation than just keep on with a perfectly acceptable nuclear status quo. It is madness. It is akin to trying to move civilisation underground to avoid the inevitable meteor strike that is going to wipe out humanity - we can't afford that expensive a risk mitigation and it doesn't seem clear that it would even help. reply defrost 7 hours agorootparent'We' is doing a great deal of heavy lifting for you there. South Korea has fast build times, China has 100 reactors planned with 10(?) (IIRC) currently under construction, a large MW scale pilot SMR completed and tested for a year, ground broken for a low GW 2nd gen salt reactor based on the pilot, and plans for a large high GW third gen version waiting on the 2nd gen being completed and bedded in for any modifications to plan. The economics vary by country and demand, here in Australia there's no economically feasible near term path for nuclear power gen. for a number of good reasons, not the least being the short term return from putting any available money into renewables and batteries - but this is a particular economic constraint setup that differs to other countries. reply ben_w 11 hours agorootparentprev> I think it's telling that That's putting the cart before the horse. Those regulations came to be because of things like that (plus also \"we don't want everyone getting nukes or radioisotope weapons\" because this is more general than just industrial accidents). The only way to compare is to look at times (or places) without the legislation. reply kelnos 12 hours agorootparentprevMaybe the reason for the low number of deaths is the high levels of tight regulation. reply Weryj 11 hours agorootparentYeah, I was about to say. We consider it safe because it’s tightly controlled and very centralized, but that has no connection to how safe it would be as a consumer product. Just because it contains the same material, doesn’t mean anything, because the methods of harm that could emerge have never existed. Ingestion, trash disposal, recycling contamination, the infinite ways you could accidentally destroy a device. reply saulrh 18 hours agorootparentprevI meant precisely what I said. Tracking NiCads to the standards of the NPT would presumably be impossible. If your standard is \"keep it out of the food supply\", though, I guarantee that there's a little bit of NiCad in that hot dog in your fridge, and there'd be much less NiCad in your hot dog if they tripped a radiation detector before they hit the incinerator or the landfill. reply XorNot 18 hours agorootparentI've always said that I'm more afraid of heavy metal contamination then nuclear material contamination. There are no hand held devices which will tell you if the soil you're vaguely near has heavy metals in it, nor how much. reply CamperBob2 18 hours agorootparentThere are no hand held devices which will tell you if the soil you're vaguely near has heavy metals in it, nor how much. Well, technically, there are, but now you're back in the ionizing-radiation business: https://www.youtube.com/watch?v=KdfHVcU8U7U reply im3w1l 11 hours agorootparentprevI've been thinking for a while that there are so many possible sources of poisons it's very hard to monitor them all. But there is only one of me. So logically I should check if I have elevated levels of poisons. Then, and only then does it make sense to start monitoring my surroundings to trace where it came from. reply hilbert42 15 hours agorootparentprevWhether it's warranted or not is immaterial given the current situation with regulations and there seems little chance of that changing. Personally, I've a healthy respect for radiation/nuclear materials but I'm not afraid to work with them so long as I know what I'm dealing with—and that's the key point. It'd be a bit pretentious to describe situations where I've been exposed to radiation levels above background except to say they were deemed occupationally safe. That said, I've always avoided such situations when and wherever possible. Let's put my view into perspective: here's NileRed (a YouTube channel I like and watch often) making uranium glass in his home lab: https://m.youtube.com/watch?v=RGw6fXprV9U. Note: I'd never do this despite the low level radiation because of the potential for breathing in uranium dust, albeit a small risk. That said, I nevertheless own several old wine glasses made from uranium glass which I keep not to use for drinking but as a demonstration of how uranium glass fluoresces under UV light. It's very difficult to put information about radiation into proper perspective or in ways that the lay public can properly understand and appreciate, thus the need for tight regulations. Then, as I mentioned, there are the bad actors and of course a small collection of damn fools who are a danger not only to themselves but also to others. No doubt, you're right about cadmium and traces of it in food. That comparison isn't lost on me either. It just so happens at another time I ran a business maintaining handheld portable cassette recorders of the type used in exhibitions, etc. and they used rechargeable NiCd batteries that needed replacement. It was not unusual for me to have to dispose of upwards of 500 old, often leaking batteries. Being concerned about Cd contamination and disposing of it in an environmentally-friendly manner was just part of the job. Contamination from heavy metals is a very real problem and it's not only Cd but also Pb, Tl, Hg, As and orhers. Moreover, assessing the actual risk can be very difficult and depends very much on circumstances. Like its more notorious mate mercury, cadmium is a poisonous heavy metal, nevertheless that hasn't stopped it from being used in industry for plating etc. (passivated cadmium plating makes a very nice surface). Thus, in the recent past cadmium has been deemed safe enough for these purposes in the same way mercury was considered safe enough for tooth amalgam/fillings. That said, just add a couple of CH3 methyl groups to Cd and we get one of the most diabolical poisons available—dimethylcadmium (same goes for Hg—dimethylmercury). Fortunately, these diabolical compounds aren't that common so we must take that into account when assessing the dangers of these heavy metals. Heavy metals are everywhere in the environment both from natural sources and from pollution, so when assessing the risks several factors predominate, concentration and their potential for forming compounds that are far more toxic than are the base metals. Also, these compounds are often soluble which adds to their danger. BTW, it's often been said that one cubic meter of soil from the average backyard has enough naturally occurring arsenic to kill someone—or at least sufficient to make them very sick. I've never seen assays to prove that one way or other but assuming it's true it puts the risks from heavy metals into perspective. reply lazide 13 hours agorootparentYou can also order (natural) Uranium ore via the mail or on Amazon, some of which has pretty high disintegration rates and a decently high amount of Radium in it. 80-100k CPS. Or just walk to a number of known sites in Utah and pick up chunks of ore off the ground. A real danger IMO with Alpha and Beta emitters is that most Geiger counters aren’t going to pick them up at all - most are only meaningfully sensitive to Gamma. reply hilbert42 12 hours agorootparent\"…(natural) Uranium ore via the mail or on Amazon, some of which has pretty high disintegration rates and a decently high amount of Radium in it.\" I'm in Australia and there's no shortage† of the stuff here. Moreover, mining it has always been politically controversial. Whilst it wouldn't happen now, when I was at school decades ago we had radioactive sources in the science lab and we did experiments showing how alpha rays could be stopped by paper, beta with tin foil and so on. I also recall the lab had a round section of metallic uranium a bit bigger than a US silver dollar and about twice as thick, it was handed around the class for all to feel how heavy the element was. It was also a source of radioactivity for our Geiger counter (but not the only one). To some degree, we have to be pragmatic about access to such materials but I'd be the first to agree that finding the right balance is difficult. Scaring everyone out of their wits about radioactivity is counterproductive (as we've seen in recent decades), similarly overfamiliarity is as equally dangerous. I'm glad I had that early experience at school together with proper instruction that put its dangers into perspective. The same went for mercury which we had at school in reasonable quantities. We were taught its dangers and to be very careful with it, especially so its compounds. In recent times I've met young people who've never actually seen mercury and who are terrified of even the mention of it. Clearly no one ever wants a repeat of the Minamata tragedy but being scared of elemental mercury to this extent isn't right either. I've often said our best approach is proper education, that is by providing factually accurate information from early on. Seems to me in recent years we've not done a particularly good job at doing that. __ † https://en.m.wikipedia.org/wiki/Uranium_mining_in_Australia https://en.m.wikipedia.org/wiki/Radium_Hill reply xtiansimon 5 hours agorootparentprevMeanwhile and just a few days ago… “Rising rates of cancer in young people prompts hunt for environmental culprit (ft.com)” https://news.ycombinator.com/item?id=41178776 reply giantg2 20 hours agorootparentprevAnd set off all the NBC detectors on the highways near major cities. reply thadt 17 hours agorootparentNot Nickel-63 - Beta particles don’t go very far in air, and are shielded by almost anything. You’ll be unlikely to be alarming on beta emitters anywhere, unless they’re right up against your specialized Beta detector. reply KiwiJohnno 14 hours agorootparentMy understanding is, the danger with Beta emitters is if they are broken up into dust, and you breathe the dust in (or eat/drink it) then you are toast, as your lungs and internal organs get a small, but continuous bombardment of Beta particles which will eventually give you cancer. If you are contaminated internally, with radioactive dust then there is no way to fix that. reply lazide 13 hours agorootparentAlso nearly impossible to detect. No roadside detector will, anyway. reply arcticbull 19 hours agorootparentprevWell yes but only if destroyed. Then wouldn’t you call that a feature? When in their enclosures there should be no radiation. reply giantg2 19 hours agorootparentNo way could all the alerts be tracked. reply jacobgkau 19 hours agorootparentYeah, you bring up another angle to look at it from: even if the alerts didn't go off when the batteries are being used/stored properly, it would make it easy to create a lot of noise/false positives as part of an actual attack (were those batteries to be readily available). reply arcticbull 18 hours agorootparentThey were for a long time, betavoltaics were used in pacemakers. They started using more conventional batteries because the betavoltaics far outlasted the actual pacemakers. reply FooBarWidget 15 hours agorootparentprevI regularly see thrown away batteries on the streets of Amsterdam. This worries me. reply swores 19 hours agoparentprev> \"... 100 microwatts, a voltage of 3V, and a volume of 15 X 15 X 5 cubic millimeters ...\" > 3-4 orders below the power requirements for a phone. An AirTag-type intermittent device, though... If my maths is right (and it's past midnight, and I'm not entirely sober, so might not be) and my search results are too, 15 x 15 x 5 cubic millimeters is approximately 9.68 times smaller than an iPhone battery (95 mm x 37.6 mm x 3.05 mm, ish), but if energy capacity scales linearly to volume then its ~12,500 times lower capacity per volume than an iPhone battery. reply K0balt 16 hours agorootparentThat’s 100 microwatts x100 years, so about 876 wh, or 292 amp hrs (292,000 mah) But, still, only 80mah a day . So 750mah scaled up to iPhone battery size. So abut 1/5 of the average daily power requirement for an iPhone. Even at that rate you’d need to use a supecapacitor to even out the load profile. OTOH, in terms overall energy, it would be about the same as about a 50 litre lithium ion so it is rediculously dense, just low output reply timschmidt 16 hours agorootparent1/5 the daily power requirement is surprisingly decent. Swapping out the screen for an eink display or ultra low power LCD like those from PixelQi and downclocking the SoC might be enough to make up that gap. reply swores 3 hours agorootparentFYI, your comment made me look up PixelQi and Wikipedia says that conpany died almost a decade ago (although 2015 feels to me like much, much less than a decade ago): > \"By 2015, PixelQi's team and offices were unreachable, and the company is presumed defunct.[3] The intellectual property is now owned by the original investor of Pixel Qi, while the right to manufacture Pixel Qi technology contractually rests with Tripuso Display Solutions.[4][5]\" https://en.m.wikipedia.org/wiki/Pixel_Qi reply com2kid 16 hours agorootparentprevOr half the battery size that came with the iPhone 4s. It could be made to work if software wasn't so violently inefficient (both CPU and data usage) and screens weren't so large. reply db48x 19 hours agoparentprevPretty dangerous when burned though. reply refulgentis 19 hours agoparentprevTFA states this and replies to this, in detail :) reply mannykannot 20 hours agoprevIn fission, it seems that most of the energy release is in the form of the kinetic energy of the daughter nuclei rather than gamma radiation or the kinetic energy of neutrons (from Wikipedia: For uranium-235 (total mean fission energy 202.79 MeV), typically ~169 MeV appears as the kinetic energy of the daughter nuclei, which fly apart at about 3% of the speed of light, due to Coulomb repulsion. Also, an average of 2.5 neutrons are emitted, with a mean kinetic energy per neutron of ~2 MeV (total of 4.8 MeV.) The fission reaction also releases ~7 MeV in prompt gamma ray photons.)[1] Given this, I'm guessing that, for direct conversion to be at all efficient here, a significant fraction of this energy would have to be converted into electrical potential energy rather than be dissipated as heat in collisions between these nuclei and any part of the apparatus. Are there any nascent technologies of this sort? [1] https://en.wikipedia.org/wiki/Nuclear_fission reply db48x 19 hours agoparentIt’s been proposed as an extremely efficient spaceship drive. Make 1µm beads of fissile fuel embedded at below critical density in aerogel. A thin sheet of aerogel with these fuel pellets in it is then inserted into the engine right inside a very strong magnetic field. Bombard the fuel with neutrons to ramp up the fission rate and those same daughter nuclei come streaming out of the pellets. They are still charged, so in the magnetic field they take a curved path. They push the magnet forward as the field pushes them out the back of the engine. With an exhaust velocity of 3% of the speed of light, they can get enough ΔV out of a few kilograms of fuel to zip out to Pluto and back in a few years. reply jpk 16 hours agorootparentNow knowing that small quantities of space dust settle on our roofs, I presume you'd have to reach some safe distance from populated planets before using such an engine? reply db48x 15 hours agorootparentOrbit is sufficiently safe. The exhaust products are individual atoms rather than grains of rock that can fall on a roof. reply jpk 14 hours agorootparentYeah, but those atoms are fission products! reply db48x 12 hours agorootparentBut they’re also just individual atoms. They’re not a chunk of radioactive material that can sit on your roof for years. Besides, the whole ship would have maybe 15kg of fuel. That means that there can only be a maximum 15kg of fission products. It would burn fuel that for several years, spreading the exhaust out over the distance from here to Pluto and back. reply satvikpendem 6 hours agorootparentprevAtoms are atoms, by definition. reply Intralexical 13 hours agorootparentprevEh, they're moving at 3-5% the speed of light. Just don't point it towards the planet. reply db48x 12 hours agorootparentIrrelevant. They are moving fast but they are tiny individual atoms. There would be no harm in having them impact the atmosphere. They would bump into a few thousand or perhaps a million gas molecules on their way down to the surface, turning their tiny kinetic energy into a tiny amount of heat. And since there is only a few kilograms of fuel, there can only be a few kilograms of exhaust. With a low thrust and high specific impulse, the engine would burn that fuel continuously for most of the trip, spreading the exhaust from here to Pluto and back. It’s not going to be sufficiently concentrated to bother anybody. In fact, even though the fuel pellets are only about 1µm across, they still bump into enough atoms on their way out that the pellets heat up significantly. A major engineering consideration of the engine would be to absorb or deflect the heat radiated by the >1000°C fuel pellets without letting that heat quench your superconducting magnets. reply ben_w 10 hours agorootparentOn the one hand, I also think it's likely safe: we've had a huge nuclear reactor in the sky since before life happened, the atmosphere and the magnetosphere are pretty effective barriers. (I think they're more worried about actinides than impactors). On the other, I'm not sure where your 15 kg came from. This matters, because fancy fuels matter a lot more for higher-mass or high-Δv payloads than smaller ones. A fission fragment rocket can be Isp of 1,000,000[1] depending on the exact details — thrust is proportional to momentum (mv), not energy (0.5(mv^2)), and that means four million times the energy density is two thousand times the momentum and thrust, so that 15 kg is like 30 tons of conventional propellant: a nice saving, but you'd use a lot more than that for e.g. a manned mission to Mars. For missions where the payload rather than the speed is critical, fuel is also a small fraction of total mass, so you also get a performance boost from being able to approximate the Tsiolkovsky rocket equation as linear. But that's perhaps another factor of 10, which is still roughly 25% of a Starship upper stage, so even then I'd expect at least 60 kg even if the engine itself can be considered negligible in both cases. And that's likely to be burned through much sooner than Pluto, though it depends on the details of the design. The ship would likely melt if you tried to thrust at 1 gee, but I think it would still be comparable to the Earth-Moon distance, give or take a factor of 3. If you want something that burns from here to Pluto, then… huh, I was going to say you're likely back in Tsiolkovsky's realm, but apparently still not, and also still sub-relativistic (~ 1 milli-c for the specific values I was using). Which is still safe, I just don't think it's quite as trivial as you say. [1] https://en.wikipedia.org/wiki/Fission-fragment_rocket reply db48x 2 hours agorootparentHonestly, I might have misremembered the fuel mass. I tried looking for the paper I read about this design, but I couldn’t find it. It’s been a whole year since I read it, and I guess they don’t think hosting it is useful anymore. reply lazide 13 hours agorootparentprevOne of my fav. points in one of the classic sci-fi books (a deepness in the sky maybe?) is how the main engines of their ships (bussard ramjet fusion drives) were also such incredibly powerful weapons, that merely pointing one (even when off) at anyone was seen as a clear declaration of war/hostile intent. Which, if you do the math, is definitely the case. Ain’t nobody walking away from getting one of those to the face. reply db48x 12 hours agorootparentYes, Vernor Vinge’s A Deepness in the Sky had Bussard ramjets, and using one inside a civilized solar system was usually a great crime since the magnetic fields may be extremely large. But you can’t point them; they’re more of an area–effect weapon. Larry Niven’s Known Space stories coined the phrase Kzinti Lesson when a peaceful Human crew turned their photon drive on an attacking Kzinti ship, slicing it in half. The Kzinti had acquired an anti–gravity drive from aliens (who they then enslaved and ate) so they didn’t have a good visceral sense of the energy required to visit the stars the hard way. Their telepaths kept reporting that the Humans were peaceful and didn’t have any weapons on their ship right up until the ship flipped over and sliced them in half. That kind you can point. reply drivebyhooting 19 hours agorootparentprevThat sounds very cool. Like a nuclear ion drive. Is there a technical paper about it? reply Intralexical 19 hours agorootparentSounds like what Wikipedia calls a \"Fission-fragment rocket\", I think? So check the citations for papers: https://en.wikipedia.org/wiki/Fission-fragment_rocket reply mannykannot 15 hours agorootparentVery interesting - I had not heard of this before. I see that the entry on the “dusty plasma” design says that the exhaust flow can be decelerated for power (presumably that applies to other designs as well.) It does not mention how the deceleration is performed (electrostatically, a bit like a reverse Van der Graaff particle accelerator?) or how efficient and compact this could be. reply db48x 12 hours agorootparentWikipedia has a short list: https://en.wikipedia.org/wiki/Direct_energy_conversion reply epistasis 19 hours agoparentprev> which fly apart at about 3% of the speed of light, due to Coulomb repulsion So is that at first an electrical force that results in kinetic acceleration? reply tmiku 19 hours agorootparentWhat do you mean by \"at first\"? The protons are pushing each other away via that Coulomb repulsion while they're all in the pre-fission nucleus, but at that time it's not enough to counteract the strong force (https://en.wikipedia.org/wiki/Strong_interaction) holding the nucleus together. Once that once nucleus has been split into parts that can move freely, the daughter nuclei are both accelerated by an electromagnetic force. reply epistasis 19 hours agorootparentWell, yeah, once the distance gets out of the well of the strong force, the nuclei are at the top of a big electrical force gradient that gets converted to kinetic energy. With proper ionization of the daughter atoms that kinetic energy could potentially be converted back to electric, well, potential. reply geuis 20 hours agoprevHelion https://www.helionenergy.com/technology/ is a commercial fusion company working on a design that theoretically would use direct energy capture from the magnetic fields generated during the fusion event. They made some headlines last year. Not clear if their approach will be successful but it certainly is an interesting approach. reply dclowd9901 19 hours agoparentCan someone who has a firm grasp on this stuff explain to me how nuclear reactions don’t create massive amounts of electromagnetism that we can just capture directly? Is it really just heat that it produces? reply Filligree 19 hours agorootparentIt generates high-speed neutrons, helium cores, photons, fissile fragments, and in rare circumstances free protons. Of those, only the protons have an electric charge you could use in any form of generator… but I’m not aware of any form of reaction that predominantly creates protium. The fragments are also charged, but the implication that you’re using fission means they’re in the middle of a block of uranium and won’t keep their speed for long. The others ignore electromagnetic fields for the most part, and will fly around until they smash into something and go goooong like the world’s smallest bell. Or smash through something, perhaps; it’s a chain reaction after all. This mostly just makes other stuff move about. Repeat a few dozen times, and you’ve got heat. reply adrian_b 13 hours agorootparentThe helium nuclei a.k.a. alpha particles are also charged, like the free protons. However, the alpha decay of some product of the fission reactions does not change the total charge of the fissile material, because the emission of a helium nucleus with a double positive elementary charge leaves a heavy nucleus with a diminished nuclear charge, by those two elementary charges. Only when the alpha decay happens to occur close to the surface of the material, the positive helium nuclei may escape from it and they could land on a collecting electrode, making that electrode positively charged and leaving the fissile core negatively charged. However such a process would extract only a negligible part of the energy produced by fission. Even if the alpha extraction could be enhanced somehow, the decay energy of the fission products is small in comparison with the energy produced by the initial fission of the uranium nuclei. Extracting directly from the fissile material the nuclei generated by fission would be much more difficult than extracting the helium nuclei. The Darpa project may succeed to stimulate the creation of some electric generators that could deliver additional energy from a fission reactor, by direct electric charge separation, but that would remain a small part of the total fission energy, most of which will still have to be extracted through thermal methods, like today. reply oneshtein 7 hours agorootparentprev2D + 3He → 4He + 1p + 18.3 MeV 3He + 3He → 4He + 2 1p + 12.86 MeV reply db48x 19 hours agorootparentprevThey kinda do. When a fissile atomic nucleus splits, the daughter nuclei repel each other; they are both positively charged and the strong force is no longer holding them together. So they fly off in opposite directions at a measurable fraction of the speed of light. But they don’t generally get very far, because they are embedded in a solid fuel pellet. They can push their way through a few µm of uranium before they are stopped, bumping into thousands of atoms along the way. That’s really where the heat comes from; all that electrostatic force accelerates them to high velocity, but they dump it all very quickly into the material around them as heat. reply Muromec 19 hours agorootparentprev> Is it really just heat that it produces? Yep, it's a big nuclear powered boiler. Boil water, get the steam, spin the turbin, cool the water, repeat. reply lazide 13 hours agorootparentIt’s amazing how many generators basically boil down to the same ‘boring’ process of ‘boil water. spin turbine. repeat.’ reply Iulioh 5 minutes agorootparentI mean, that's just because water is a simple medium we can just literally trow out in the environment after use, using basically anything else to spin said turbines would require a closed system and cooling. Gravity batteries could be a thing but pumped water is the best version of that system, in this case we don't boil the water tho reply exabrial 20 hours agoparentprevThere definitely trendy since some high profile YouTubers were invited to tour! I sincerely hope they can succeed. I believe a limiting factor is going to be fuel unfortunately, as well as I’m not entirely sure it’ll be radiation free. reply DennisP 18 hours agorootparentThe original fuel is deuterium, which is absurdly abundant on Earth. Pure deuterium fusion results in half helium-3, and half tritium which decays to helium-3 with a 12 year half-life. Then their main reaction is D-He3. The D-D reaction is less energetic and produces a neutron, and the D-He3 reaction doesn't produce a neutron. The combined reaction would release about five percent of its total energy as neutron radiation. The neutrons from D-D are about as energetic as fission neutrons, rather than the extremely high energy of D-T fusion neutrons. They'll never run out of fuel; there's enough deuterium in your morning shower to provide all your energy needs for a year. But the need to breed He3 will put a limit on how fast they can possibly scale up. It could be that manufacturing will be slower than that anyway though. reply exabrial 3 hours agorootparentThanks for the insight. I remember it being like the raw ingredients were plentiful, but the main reaction ingredients were not. reply sigmoid10 20 hours agoparentprevFusion is infinitely harder for this than fission. No company has demonstrated stable fusion with a positive net energy gain. Most of these startups are borderline scams for milking gullible VCs. Helion in particular has been around for more than a decade and was supposed to reach break even in 2023. They haven't even achieved a fully stable D-D reaction so far. The biggest thing it has achieved is siphoning tons of money from OpenAI's investors because of some questionable actions by Sam Altman. reply Intralexical 19 hours agorootparentFusion overall is harder than fission. Is the direct energy capture part also harder for glowy fusion gas than scary fission rocks? reply thayne 18 hours agorootparentI think in a Deutritium-Tritium fusion reaction a lot the energy is in the neutron. And since neutrons are neutral you can't really directly convert that into electrical energy. reply DennisP 17 hours agorootparentYep, for D-T 80% of the energy is in neutrons. Helion is using D-D/D-He3, and for that it's about 5% in neutrons, and most of the rest in fast-moving charged particles. So they have a simple way to extract electricity directly. They squeeze the plasma with a magnetic field from a copper coil, then there's an explosion of charged particles, which pushes back against the magnetic field and causes electricity to flow in the coil. reply selectodude 19 hours agorootparentprevI think the concepts are the same but the execution (heat up water with plasma) is still a work in progress. reply Intralexical 19 hours agorootparentThat's the \"thermal middleman\" part they're trying to cut out. By analogy, compare Concentrated Solar Power versus Photovoltaics. reply DennisP 18 hours agorootparentprevIt's a pulsed reactor by design, it's not supposed to create a \"fully stable\" reaction. They're actually pretty much on schedule, once you account for the several years it took them to get the necessary funding. reply fallingknife 18 hours agorootparentprevWhat do you know that all those investors don't that lets you so confidently call this a borderline scam? reply waryFormerNuke 20 hours agoparentprevI don't remember the details, but the last time I looked into Helion I came away with the belief that their technology flat out doesn't make sense and will likely never be anywhere near net-positive. Like, the numbers literally don't add up and their design could never be anywhere near net-positive. reply foobarian 17 hours agorootparentI had the impression that the energy flux required to break even is higher than any known materials can support, at any geometry. I really hope that's wrong :-) reply TheRealPomax 20 hours agoparentprevCommercial energy company. Not fusion company. There are no fusion companies on this planet yet. reply Intralexical 19 hours agorootparentThey claim to have performed fusion, but not yet produced net energy. So they're very much a fusion company, but not an energy company: > In 2023, we will end operations on Trenta, our 6th fusion prototype… Our results suggest that Trenta is currently the best performing privately-funded fusion machine in the world. After these last weeks of plasma operations under vacuum, we will retire Trenta and move all focus to Polaris, our 7th fusion prototype, expected to demonstrate net electricity in 2024. So, they have 143 days left to make good on their current timeline, I guess. reply TheRealPomax 2 hours agorootparentThey're an energy company that has failed to produce any yet because of how they chose to generate that energy. Unfortunately, like everyone else who tried this so far, they can make tiny bang go flash, and that's unfortunately still just about it. So, indeed, so far they failed at energy, and they've only succeeded at fusion in the same way and at the same scale that university labs have. So I guess you're right: they're not even any kind of company at the moment. They don't sell anything. They're an R&D lab. reply ChrisClark 19 hours agorootparentprevWhat do they plan on using to generate energy then, oil, coal, solar, wind? Something else? reply TheRealPomax 2 hours agorootparentSo far: looks like hope and promises rather than any of those. reply kccqzy 18 hours agoprevNuclear generation didn't always require a steam turbine. Radioisotope thermoelectric generator is an old tech that doesn't need any kind of turbines or liquids to function. It's still being used on the two Voyager spacecrafts. Of course it doesn't meet DARPA's requirement of bypassing the thermal middleman but it can be scaled to be reasonably small and can generate a few hundred watts. reply bitmasher9 18 hours agoparentThe issue with RTGs is that they don’t scale up, not that they don’t scale down. I’m not sure what the biggest RTG is, but they are usually measured in hundreds of watts. Then there is the issue of the radioactive waste. It’s useful for situations where refueling or maintenance are not options and access to solar light is poor. Pretty niche requirements, and the radiation issue limits applications to military levels of security. reply lupusreal 18 hours agoparentprevThe thermocouples those use are wildly inefficient and only make sense in cases where no moving parts that might break is the utmost priority (spacecraft, extremely remote lighthouses or radio relays, etc.) Betavoltaics are another option, which actually skip the thermal step, but those are only good for very small amounts of power. reply elevaet 19 hours agoprevWhat's the typical efficiency of a nuclear power plant? i.e. what fraction of the energy from the fission reaction gets converted into electricity? reply Muromec 19 hours agoparentI remember something like 1/3 of thermal energy. reply orbital-decay 19 hours agoprevOne of the previous attempts at that, with a \"power density of a gasoline tank\", according to the authors: https://en.wikipedia.org/wiki/Optoelectric_nuclear_battery reply analog31 19 hours agoprevThis is just a speculation. What if we were to use the heat from fission to generate hydrogen instead of electricity? Would that help at all? For instance a high enough temperature will cause water to dissociate. reply rgmerk 17 hours agoparentThere's been some research into high-temperature electrolysis. The idea is that a lot of the energy to split the hydrogen and oxygen can be provided as heat; that means you need a lot less electrical energy. To a rough approximation, for every three units of heat energy produced by a nuclear plant, you get one unit of electricity, so the process could in theory considerably reduce the cost of zero-carbon hydrogen. In practice, it seems like it's going to be very hard for a nuclear plant to beat an electrolyser that runs when near-free solar electricity is available. As you say, if you get hot enough you can do away with electrolysis entirely. A little bit of casual reading suggests that the temperatures required by a naive approach are in excess of 2000 degrees Celsius, far, far beyond the point where any existing or near-term reactor design would turn into a puddle of very radioactive molten metal. reply geuis 18 hours agoparentprevAs far as I know (and its not very far to be fair), the main way to generate hydrogen would be via electrolysis in water, which requires electricity. Which means you have to turn that heat into electricity first anyway. This is one of the big critiques of using hydrogen as an everyday fuel source. Takes more energy to produce that you can recover. Its super hard to store (requires very cold temps, or high pressure), and it has a habit of wiggling through any other material's atomic bonds and overall weakening the container material. But if there is another chemical method that used thermal energy in the process to produce hydrogen then there might be some possibilities in the idea. reply g15jv2dp 9 hours agoparentprevAnd then what do you do with the hydrogen? Unless you plan on fueling your spaceship with it, you must burn it off to harvest the thermal energy... I'm sure you see the issue here. reply defrost 8 hours agorootparentAmmonia, Methanol, etc - Fertilisers and fuels for marine shipping in addition to being transportable \"energy\" that's less slippery than hydrogen and can travle further than an HVDC transmission line \"extension cord\". Currently green hydrogen plants are expanding and ammoniamethanol marine fuel ships have been built and trialed - there are contracts signed and in the works to both build a 4,000 km HVDC \"suncable\" and to ship hydogen products longer distance. reply xhkkffbf 21 hours agoprevIf photovoltaic cells can create power from radiation in the visible light range, I suppose there might be radiovoltaics that can do something similar. But I wonder if they can capture the high power fluxes from a modern core. reply actionfromafar 20 hours agoparentMayne one could run it in the visible range, or almost there. Wasn’t there some new kind of IR solar cells? reply baking 20 hours agorootparentI think the issue is the low absorption rate. Eli Yablonovitch proposed a box of PV cells facing inward containing a heat source where the IR light would bounce around until converted to electricity or absorbed as heat. This could be used inside a water heater so waste heat could be stored. Known as thermo-photovoltaics. See this talk I think: https://www.youtube.com/watch?v=lDxJsa8miNQ reply not2b 20 hours agorootparentYes, I see how direct conversion could work with alpha and beta radiation, but it seems the gamma and the neutrons would just blast through everything and you'd capture only a tiny percent of the energy. reply baking 20 hours agorootparentSorry, I was responding to the part about IR. reply ta988 20 hours agorootparentprevYou have to go the other way of the spectrum toward something that loves to avoid interacting with matter... reply exabrial 20 hours agorootparentFinally a use for dark matter reply thayne 17 hours agorootparentBut dark matter is matter that doesn't react very much with radiation (including light), so it would react even less. reply fulafel 12 hours agorootparentprevWe just need some blimp attached mini suns floating in the sky in the night and this can power all the existing solar panels on the ground. reply gweinberg 18 hours agoprevAug 30 seems like a ridiculously short deadline for proposals considering that this is as cutting edge as it gets. reply tconbeer 17 hours agoparentIt’s an RFI, not an RFP. They are basically looking to build a list of vendors who might be interested in bidding an RFP or competing in a domain-relevant contest. reply at_a_remove 20 hours agoprevThis is one of the reasons why, as an undergrad, I switched from nuclear engineering to physics: at the end of the day, we're still using heat and turbines, just with extra, more dangerous steps; although the materials engineering aspect is recognizably challenging, I found it not particularly thrilling. At other, far end of the scale, if Hawking radiation does exist, black holes could be considered converters of mass to energy, skipping all of the conservation of baryon and lepton numbers ... although at very large timescales until you have a fizzy, spicy nano black hole on hand. Controlled capture of the various types of radiation (sometimes I find that word to be sloppy) to extract the kinetic energies does not seem to be physically impossible, but I have oft wondered how as I think about various nuclear batteries which have existed. Indeed, the article doesn't even break it down enough: beta ought to be split into beta-plus (positrons) and beta-minus (electrons), and they skipped some 2p emissions. My guess is that not only will each need its own approach, but that each of those would be subdivided into different energy bands, not unlike having different compounds for chlorophyll-A and chlorophyll-B, only for, say, fast neutrons versus thermal neutrons. And I think that's gonna be materials engineering again. Whoops! reply wizardforhire 20 hours agoprevI always thought super conducting ccds with plasma scintillating cell intermediaries were the way to go. Capture the alpha and beta radiation with the plasma scintillators. Plasma being ideal because it wont degrade with bombardment. Capture the em radiation with ccds. We normally think of ccds as low power capture devices for cameras. Theres no reason they couldn't be scaled up to handle the power requirements. Perfect use case for super conductors. This of course for moderate to large scale fusion reactors where cost is a negligible object. Of course the dream is solid state Hau arrays. Which Dr Lene Hau postulated 15 years ago… but thats a whole other story. reply wizardforhire 20 hours agoparentOf course plasma will degrade its just easier to separate out the products. You could feed the plasma back into the reactor and use cyclotron resonance. Alpha and Beta decay being one of the big problems with reactor design as the walls degrade over time. So designing for that with an active system seems to me to be a way a viable solution to minimize maintenance. reply carabiner 17 hours agorootparentCould this cause a resonance cascade? reply wizardforhire 14 hours agorootparentUnlikely as resonance in this case is referring the minuscule difference in mass between isotopes which results in preferential orbits within a tokamak which can be exploited for separation. I guess depending on what you're separating and whether or not someone is paying attention I guess conceivably a runaway event could occur but I think the masses and densities involved are too small to be of any concern. reply epistasis 20 hours agoprevThis is pretty much the only hope for nuclear power in the future. Current reactors are way too expensive, and they do not get cheaper the more we build of them. Miles upon miles of pipes with high-performance welds meant to last decades is no way to build a cheap and cost-effective electrical generation system. We need something better. Also, getting off a thermodynamic heat engine means the chance for far greater efficiency. Going through a heat cycle is hugely inefficient. For example, just extending the lifetime of the Diablo Canyon reactor pair in California, for five years extra life from 2025 to 2030, is expected to cost a minimum of $8.3B. That's the utility's claim before the work has been done, and life all nuclear/construction projects, it will almost certainly balloon midway. TL;DR nuclear needs a tech breakthrough like direct conversion. reply cinntaile 18 hours agoparentIf they utilize the waste heat for eg. district heating, the equation looks a lot better. Unfortunately most cities don't have district heating. reply epistasis 17 hours agorootparentLosing 50%-67% of the energy to waste heat is not the roadblock to new nuclear. The roadblock is the immense expense of a massive, complicated, intricate machine requiring massive workforces of highly skilled construction labor. Shifting from heat conversion to some sort of direct conversion, and in the process ideally eliminating a huge amount of the construction expense, is the way out. As our economies become ever more advanced, skilled labor becomes ever more expensive. Our existing fleet of nuclear reactors is much like the intricate cathedrals of past centuries. We could build in that style, but the expense is much higher today than it was back when the cathedrals were first made. reply cinntaile 10 hours agorootparentYou mentioned energy efficiency, I simply provided a possible way to boost that efficiency up a bit. reply epistasis 4 hours agorootparentYou are right! I must have been thinking of different types of efficiency and written very unclearly. A pet peeve of mine is people talking about \"efficiency\" in energy and not defining it or switching between definitions sloppily, and I seem to have done it there. In any case apologies for not being consistent. reply pfdietz 17 hours agorootparentprevThere are already lots of sources of low grade waste heat. Since we aren't exploiting them, it must not be worth doing. So, for nuclear district heating, you'd need higher quality heat, probably steam. reply cinntaile 10 hours agorootparentYou don't use steam for district heating. There are two problems here, the first one is that district heating doesn't exist in a lot of places so the infrastructure needs to be built. The second problem is that people are afraid of nuclear so running water through their house warmed almost directly with nuclear heat is a sensitive topic. It's not actually dangerous of course, but perception matters. Actually there is a third reason now that I think of it. Nuclear plants are usually not close to big enough cities to absorb that heat, but it's possible to transport the water over 100km while still retaining enough heat for district heating. reply pfdietz 2 hours agorootparentSome district heating systems do in fact use steam. reply tiku 17 hours agoparentprevBut why is it so hard. A steam engine in itself is not complex, we had locomotives for a long time, they didn't have high performance welding for example. Why can't we dumb down nuclear reactors? While keeping it safe. Perhaps by using material that won't cause meltdowns or using heat from nuclear waste? reply epistasis 15 hours agorootparentIf you have 20,000 welds that each need to last 30 years without being fixed later, that's an order of magnitude difference in quantity than the corresponding 2,000 for a coal boiler, in addition to a few orders of magnitude difference in the necessity of lasting a long time without repair. It's a hell of a lot more than a steam boiler, even if ultimately that's the goal. The nuclear island is a hell of a beast of complexity, size, and quality. reply worik 19 hours agoprev [–] Makes the use of depleted uranium look benign Imagine thousands of soldiers with battery powered tools that must not(!!!) be dismantled So long as it happens \"over there\" I guess reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "DARPA is investigating direct energy conversion from nuclear power, bypassing traditional steam turbines, to convert radiation directly into electricity.",
      "This initiative could transform nuclear power systems, from small batteries to large grid-scale plants, driven by advancements in radiation-tolerant materials and small nuclear technologies.",
      "DARPA aims to develop efficient, durable radiovoltaics for diverse applications, including space missions, with responses to their request for information due by August 30."
    ],
    "commentSummary": [
      "DARPA is working to remove the thermal intermediary in nuclear power systems, aiming to improve efficiency.",
      "Betavolt's innovation uses a diamond semiconductor and nickel-63 to produce 100 microwatts, suitable for low-power devices like AirTags but not for high-power needs like smartphones.",
      "Significant challenges include scaling up production, ensuring safety to prevent radioactive contamination, and navigating stringent regulatory frameworks due to historical safety concerns and international treaties like the NPT (Non-Proliferation Treaty)."
    ],
    "points": 179,
    "commentCount": 121,
    "retryCount": 0,
    "time": 1723237954
  },
  {
    "id": 41208836,
    "title": "Ladybird browser to start using Swift language this fall",
    "originLink": "https://twitter.com/awesomekling/status/1822236888188498031",
    "originBody": "We&#39;ve been evaluating a number of C++ successor languages for @ladybirdbrowser, and the one best suited to our needs appears to be @SwiftLang 🪶Over the last few months, I&#39;ve asked a bunch of folks to pick some little part of our project and try rewriting it in the different…— Andreas Kling (@awesomekling) August 10, 2024",
    "commentLink": "https://news.ycombinator.com/item?id=41208836",
    "commentBody": "Ladybird browser to start using Swift language this fall (twitter.com/awesomekling)169 points by nopakos 7 hours agohidepastfavorite160 comments stephen_g 6 hours agoI had suspected this would happen, I haven’t got into Swift yet (I’m mostly doing embedded C still) but Swift finally seems to have just ticked off some niggles that makes it a much stronger contender. Things like not having official Debian builds (there were Ubuntu etc.), not being able to run under other C libraries like musl (like if you want to run in Alpine Linux containers), not really being able to run embedded etc. basically all being fixed in the last release (or starting the process, like with the embedded subset). Add in the newish C++ interop and it does seem much more attractive now as a pin ergonomic, memory safe, cross-platform language at all levels of the stack! (This is of course by design, Apple intend to use Swift from everything from firmware of things like the Secure Enclave chip, through to the kernel, through to all the apps, but to be able to bring it in gradually with the interop, so not having to rewrite everything from scratch). reply cube2222 5 hours agoparentHonestly, Swift seems like such a nice language. Most of the performance and power, great interop, but more directed at application development than Rust (with e.g. refcounting being the default). But as they say, you choose a language for its ecosystem, not for the language itself. It would be great if Swift’s open source ecosystem for stuff other than app development grew. It does indeed seem like Apple is pushing for it with stuff like Swift for embedded. The fairly recent presentation about starting to move FoundationDB to Swift[0] was also very interesting. A follow-up on that at some point would be quite interesting to see too, and would inspire confidence if the process is going well. Arc is also a nice example of a cross-platform app written in Swift, with their fairly recent addition of Windows support. Either way, fingers crossed, and very happy with TFA. PS: does anybody have experience with async/await in Swift? Is it pleasant to use? [0]: https://www.youtube.com/watch?v=ZQc9-seU-5k reply cvwright 1 hour agorootparentI have about 30k lines of Swift in my app + Matrix sdk, all heavily using async/await. Plus another couple kloc in a Vapor API backend. Swift async/await is quite nice. The Actor stuff is IMO way oversold - reentrancy issues make it not actually useful for the things that they claim, like querying a database. It’s still a useful construct to have, you just need to be aware of what it does or doesn’t provide. reply cube2222 4 hours agorootparentprevFound an interesting article about the internals of async specifically[0], also the docs[1]. TLDR: Seems like it uses a global thread pool, where each async method call yields to the runtime. Additionally, you get actors which are special classes with serialized method calls, and everybody other than itself has to call those methods as async. Additionally, you can have custom executors, who, if I understand correctly, still only pass tasks to the global thread pool, but can influence the scheduling order. Finally, you can force functions/actors to run on the main thread (outside of the thread-pool) as iOS requires the UI to run on the main thread. Interestingly (from an API evolution perspective), async protocol functions can be implemented in classes by synchronous functions, as async in swift means \"this could be async\". Which plays well with the fact that async functions can call sync ones, but not vice-versa. Additionally, it has cooperative cancellation (you can basically check if you've been cancelled and react accordingly). Concurrency is by default structured, and cancelling a parent task will cancel its children. [0]: https://swiftrocks.com/how-async-await-works-internally-in-s... [1]: https://docs.swift.org/swift-book/documentation/the-swift-pr... reply Decabytes 5 hours agoprevI totally get using Swift in this context considering their heavy emphasis on C++. From my personal experience, Swift still feels like the early days of Open source .NET/Mono. You will definitely experience the growing pains of being an early adopter of the language. The fact that JetBrains killed AppCode in Dec of 2022 7 years after Swift went Open Source is telling to me that getting the traction outside of the Apple ecosystem is not there. The vast majority of the people I see developing open source Swift apps still use Xcode and a Mac. For example Miguel De Icaza is a huge proponent of open source Swift, and is doing a lot of cool things with Swift Godot. But he develops on a Mac just like everyone else. The experience with VScode is just okay. I think that the cross platform story both in terms of developer libraries, experience, and tooling is still much better on .NET, and provides a happy middle ground between something like Swift and Java. With that beings said I hate the options for Mobile/GUI with .NET (MAUI, or AvaloniaUI), and would recommend Java/Kotlin if you want to do that. I want to give a special shout out to F# as I feel like it is the most sensible functional programming language I've ever used, and is a lot less verbose then C#. The only knock against it I have is that it's a smaller community than C# and most of the libraries you use will be written in C# so you need to know a little C# as well to be effective reply pjmlp 5 hours agoparentC# has a uphill battle against those that don't believe in systems programming languages with GC, despite several graphical workstations have been done in the past in such languages. Unfortunately freebie UNIX, and security was yet decades away to be relevant to governmental regulators, thus they never managed to gain enough mindshare to keep going. Additionally even with all the .NET team efforts, the technology remains mostly relevant to Microsoft shops. I seldom see RFPs from UNIX first culture companies, that quote .NET as possible delivery technology. reply layer8 5 hours agorootparentGC still has the downside of higher memory overhead. While I’m not particularly a fan of Swift, this is a relevant argument for a general-purpose browser implementation. reply pjmlp 4 hours agorootparentReference counting is also a GC algorithm, even though people pretend otherwise, as they seldom learn from CS literature. Plus all systems languages with GC, including C#, can do C and C++ style memory management. reply layer8 4 hours agorootparentThis is an old argument, and it’s well understood that “GC” by default refers to tracing GC and delayed collection. (Without delayed collection, there arguably isn’t any “garbage” in the first place.) “Can do C++ style memory management” is very different from what happens when coding in the default idiomatic style of the language and when using existing libraries written in the language. What happens by default is a relevant consideration. reply pjmlp 4 hours agorootparentUnderstood as such by those that don't grok CS. What is relevant is if one is actually skilled in using their tools, or should be doing something else instead. reply neonsunset 4 hours agorootparentprevThe degree to which GC issues in the context of deterministic memory management apply to C# is incomparably lower to pretty much every other language that offers GC (especially JVM family) or a similar automatic memory management capability (except Swift or D). However, D's GC is very rudimentary, and Swift pays very hefty performance price imposed by ARC for lower memory footprint and somewhat more predictable memory behavior. In the context of writing something like a browser engine, both Swift and C# offer strong if different capabilities to control or avoid allocations, with Swift introducing Rust-like lifetime annotations for affine-like memory management, while C# relying on improving escape analysis in compiler and much better integration of plain structs and byreflike structs (they can hold GC-aware pointers called byrefs (`ref` keyword) to arbitrary memory) with generics for zero-cost abstractions. Note that today, if I ever dared to even think about writing a browser engine, then the choice would have been Rust. But if not Rust, then C# would have been the next on the list. Some may suggest Zig but I have only brief knowledge of it so cannot comment further. reply pjmlp 4 hours agorootparentUntil Zig has a good story for use after free, I wouldn't be considering it. Regarding C#, there was some research work at MSR for improving escape analysis and IDispose usage via lifetime analysis, but seems to never have moved beyond proof of concept. By the way, Midori internal presentation from 2013 is doing the rounds on twittersphere. reply neonsunset 57 minutes agorootparentI don't think there was any work on escape analysis in current .NET related to Midori, at the very least not in public. However, there has been separate research and support for object escape analysis unrelated to this. Here's the rough timeline of the work: Initial issue https://github.com/dotnet/runtime/issues/11192 was submitted in 2018 and concerns general research direction on feasibility and profitability of EA. At the time, the results were very unpromising given compiler throughput impact: there were very few objects that were not escaping due to inlining limitations and (relatively) rudimentary approach to EA. In addition, there obviously was no impact on performance sensitive code that just used structs instead that are not reliant on fragile optimizations like this one. Here, I would like to add a personal note that .NET teams are exposed to a much more well-behaved code and there existed (and still exists to an extent) bias that overlooks the nastiest and worst codebases that, no matter their issues and unnecessary allocation on every step, are an important optimization target. I think today there is a good degree of awareness and understanding of this bias, which drives further compiler improvements. Back to EA. After initial research was done, the relevant code was merged into JIT - the feature was added around .NET 5 but remained disabled by default. Later on, it was occasionally in a broken state and generally not well validated against, given nothing used it besides compiler tests. This, however, has changed in .NET 9. In order to understand why we first have to consider what were the changes in .NET's compiler in the previous versions. Before .NET 7 and 8, JIT had nice but limited capability to perform something Java calls \"scalar replacement\" except for structs, the .NET name for this is \"struct promotion\". This feature \"promotes\" constituent struct fields to individual local values which are then stored in CPU registers or individual stack locations instead of \"together\" and being copied every time. This also included other common cases like treating single-field structs as an underlying field (making such wrappers effectively free). At the time, this optimization was great but nevertheless limited - there were restrictions on the amount of fields which could have been \"promoted\" and \"enregistered\" (up to 4 I believe?) as well as the depth - the quality of compiled code could easily regress if the target of promotion was nested within another struct, etc etc. In order to address this, a new handling of struct promotion was introduced - \"physical promotion\": https://github.com/dotnet/runtime/issues/76928. This did away with the limitations of the past and enabled significantly better[1] handling of structs, allowing them to be optimized away, promoted without depth and count restrictions, propagate constants and assertions through struct fields, CSE more expressions on struct and more. This was a significant overhaul which pushed .NET's compiler output quality concerning structs way closer to the kind of behavior you would usually expect from GCC and LLVM. At this point, I think you have an idea where this is leading to. Come in https://github.com/dotnet/runtime/pull/102808, an unrelated change which enabled the compiler to reason about propagation of addresses (object references, byref and unmanaged pointers) through struct fields. However, the importance of this change is that Steve (hez2010) noticed[0] that it may have closed the critical gap that previously prevented generalized optimizations enabling optimal struct handling from being applied to objects allocated on the stack. Once it was merged, it made the simpler scenarios EA was working for to produce the same optimal codegen you would see from structs as of .NET 8. This and related discussions prompted further work on analyzing the most common unescaped allocation patterns and resulted in https://github.com/dotnet/runtime/pull/103361 by Andy Ayers. Once it was merged, it extended supported cases by previously limited EA capability, tuned inlining heuristics to make it light up more often and proved that the way it was handled as of the change was noticeably more profitable. It was subsequently enabled for NativeAOT and R2R as well: https://github.com/dotnet/runtime/pull/104411 As a result, .NET 9 will come with improved escape analysis capability, now enabled by default. It is still fairly limited but nonetheless an another change that incrementally adds to the nice \"free\" performance improvements everyone has grown to expect from bumping up a TFM version with each release for the last 7 years or so. Further EA work is planned https://github.com/dotnet/runtime/issues/104936 and there are already initial experiments for .NET 10 like this one https://github.com/dotnet/runtime/pull/104906 I don't claim this timeline/sequence of events is perfectly accurate but I hope it sheds light on how and why this optimization has been evolving in .NET so far. [0]: https://github.com/dotnet/runtime/pull/102808#issuecomment-2... [1]: https://devblogs.microsoft.com/dotnet/performance-improvemen... reply neonsunset 5 hours agoparentprevLuckily, for the project of this type, you can use SkiaSharp (which is awesome) or simply implement a rendering back-end that targets OpenGL/Vulkan/DX/Metal. There are rich binding libraries with low/zero overhead to do so like TerraFX or Silk.NET or you can just do it directly. For example, Avalonia implemented Vulkan back-end some time ago, no C or C++ required: https://github.com/AvaloniaUI/Avalonia/pull/12737 Even then, you are absolutely not married to any of these GUI frameworks, but if are targeting desktop, then Avalonia offers great user experience. reply enragedcacti 4 hours agoprevI'm seeing a lot of doom and gloom about this mostly stemming from the state of open source swift, but I think the choice has a lot of upside for two main reasons: 1) Choosing Swift implicitly adds improving the status quo of open source swift to the tasks of ladybird. This obviously expands the already huge scope of the project but also derisks it in some ways because it means the project can have a lasting impact regardless of its goals as a competitive browser. Remember that Rust was tempered as a language through the development of Servo and Ladybird could do the same for the non-Apple Swift ecosystem. 2) It unlocks access to a huge number of Swift developers and offers them a unique open source project to work on rather than just building apps for Apple products. As far as I am aware there is no other major language with such a massive (size of developer base):(open source opportunities) ratio. Ladybird acting as the cornerstone of that community could have mutually beneficial results that improve the development of ladybird while also fostering excitement for open source, non-Apple Swift projects. Ladybird is a wildly ambitious project. We have N=3(ish) for how long it takes to develop a competitive browser from scratch in C++ even with the support of massive companies behind you and it isn't very fast. Obviously we know it works but Ladybird is on mile 100 of a bicycle race around the globe that started 30 years ago. Staying the course on C++ to me looks like saying \"We're already so far behind, we can't afford to stop and add an electric motor!\" meanwhile everyone else is still pedaling and you aren't getting any closer. reply christophilus 5 hours agoprevFor those who are worried, Andreas is a thoughtful dude. This decision was not made on a whim. Also, they’re not doing a massive rewrite: > The Swift team is also investing heavily in C++ interop, which means there's a real path to incremental adoption, not just gigantic rewrites. To me, the Tweet does a good job justifying the decision. I’m rooting for Ladybird, and I hope this decision pays off. A modern browser in a modern language sounds like a dream come true. reply meiraleal 4 hours agoparent> For those who are worried, Andreas is a thoughtful dude. This decision was not made on a whim. Yes. But many terrible decisions are taken this same way. > and I hope this decision pays off It is terrible when we need to hope for something to succeed because we see that they are clearly doing something wrong but will do it that way anyway because they are strong-willed. Just take the obvious path everybody is pointing to. Guy doesn't even know Swift yet, wants to rewrite a Chrome/Firefox alternative using it. That's a great recipe for failure. Alright, I need to find another browser project to be delusional about. reply stephc_int13 5 hours agoparentprevI strongly disagree. This is not a justified decision, they just feel like it based either on vague and speculative reasons, or because they are funded to do so, I would not be surprised if they had discussions with the Swift marketing team. reply breckinloggins 4 hours agorootparentCan you back up this claim? Knowing what I know of both Andreas and the Swift team I find this comment incredibly bizarre. You either know something the rest of us don’t or you have made an emotional outburst in the form of an insult. reply stephc_int13 4 hours agorootparentI don't know. This is speculation on my side. But they recently announced funding as a non-profit, as a few days later, they switch to Swift. Following the money is a good way to explain seemingly irrational decisions, at least as a first order approximation. reply open592 2 hours agorootparentprevAndreas has been talking about liking and exploring Swift since before he started working on Jakt [0] and if you look at Jakt you will clearly see it is heavily influenced by Swift. [0] https://github.com/SerenityOS/jakt reply rjh29 5 hours agorootparentprevI feel like the tweet explains their rationale pretty well... the main reason being memory safety. It's a constant overhead in both programming time and bug handling for them. reply keybored 5 hours agorootparentprevHow do you know? reply gjsman-1000 5 hours agorootparentprevThen build your own browser in Rust, start contributing to Servo, and who cares when a volunteer writes a browser in any language? Write a browser in COBOL for all I care. If it’s open source, it’s still a gift. reply stephc_int13 5 hours agorootparentAbsolutely not. I don't know Rust and I think it is worse than C++ in many ways. This is a false dichotomy, they don't have to switch language mid-course. reply JTyQZSnP3cQGa8B 4 hours agorootparentI am very confused by your message. I know both Rust and C++ and think it’s an improvement in many ways. Why do you you think it’s worse without using the language? reply stephc_int13 2 hours agorootparentI don't use it, it does not mean that I know nothing about it. I know enough. Rust is extremely anti-ergonomic for me, and too complex, just as bad or worse than C++ in that regard. reply zozbot234 2 hours agorootparentThe original tweet was essentially complaining about boilerplate, which is all that's involved in managing most \"complex object graphs\" in Rust. If you think some minor boilerplate makes languages \"extremely anti-ergonomic\" I sure hope you're not writing Java. reply LoganDark 5 hours agorootparentprev> start contributing to Servo Servo as a browser is (sort of) dead, though webrender still lives. I remember when (back when the icon was a doge) it had an actual UI and could be used as a real web browser... that's all been stripped out now. https://book.servo.org/: > Work is still ongoing to make Servo consumable as a webview library, so for now, the only supported way to use Servo is via servoshell, our winit- and egui-based example browser. A shame, really, since the Servo project was the source of some of the best macOS Cocoa/AppKit bindings for Rust. reply fabrice_d 4 hours agorootparentServo was never usable as a \"real browser\", and it's been revived since last year by Igalia. Looks like you should refresh your view on the project overall. reply LoganDark 1 hour agorootparent> Servo was never usable as a \"real browser\" I had a 2018 (or 2017?) build on my Mac that was a native app using Cocoa/AppKit, which had a URL bar and could do most things in a functional capacity (like using Google services). AFAIK I tried a newer build back in 2020 or 2021 which had stripped out all of the browser chrome (like URL bar). Maybe they had intended to add it back in the future, but didn't get to do that before, you know, the layoff. Servo the project was never revived as it was originally; the Servo name is being reused for what is actually a continuation of just the webrender project, which was part of the original Servo project, but is nonetheless much more limited in scope. I know it's confusing. Servo was once going to be a browser plus engine, and now it's just the engine. Of course, officially, Servo has always only been a \"research project\" to \"rethink the browser at every level of the technology stack\", which primarily meant \"layout engine\", but then again, they did do such things as creating their own bindings to macOS Cocoa and AppKit which has no place in a layout engine, just to create, you know, a browser that demonstrates the engine. The browser that used the engine was part of the project. Nowadays, the new Servo does have a demo/example project, but it's not meant for end use like the original Servo browser would have been. It just uses egui and all the other parts of the original Servo project have been essentially deprecated in favor of the new one, which is just webrender. reply blinkingled 5 hours agoprevSeems premature. You don't write successful browser engines using relatively new language that is optimized for one platform. But it was predictable - Andreas comes from Apple background so.. The other thing is no one can build a browser alone - the ability to attract the right people is what differentiates a mainstream usable browser and a toy one. IOW focusing on adding another language that is not as popular amongst the right developer demographic seems like the wrong thing to focus on at this stage. reply peppermint_gum 6 hours agoprevOne thing I don't understand about Swift is why it uses a private fork of LLVM. Why can't they upstream whatever changes they need? reply pjmlp 6 hours agoparentBecause the same also applies to clang, and contrary to what people think, Apple like every other big tech, is only as nice to FOSS as they need to be for their own purposes. Same applies to all C and C++ compiler vendors, that have replaced their proprietary compilers (there are plenty more than just clang/gcc/msvc), with LLVM. Such is the freedom of Apache/MIT/BSD style licenses. reply peppermint_gum 6 hours agorootparentSwift's LLVM fork is open-source, just not upstreamed. No Free Software license requires forks to upstream their changes. https://github.com/swiftlang/llvm-project reply pjmlp 5 hours agorootparentYet you're complaining that they are using the licence exactly as they feel like. reply nequo 4 hours agorootparentParent was not complaining. Parent was asking what the rationale is behind maintaining a separate LLVM fork instead of upstreaming and reducing the maintenance burden on Apple engineers. reply Zambyte 5 hours agorootparentprevReferring to their fork as \"private\" seems quite misleading then. reply okr 5 hours agorootparentprevI would not say its about niceness, its more about necessities. If ya don't own something, the walls are high to have anything changed, naturally. Because it might not be aligned with what the owner has had in it's mind. And you want to move quickly. So you fork and apply your changes. But i also think, in the long run, it hurts, bcs at some point, you forks are too diverged. But so is life. reply masklinn 6 hours agoparentprevBecause Apple does not direct the LLVM project, and they have their own corporate designs and plans. I'm sure they upstream what changes they think will be accepted, but there's no guarantee upstream would accept what they want or need let alone on the timeline they need it. reply GeekyBear 5 hours agoparentprev> Today there are a few non-trivial differences from LLVM, but we are actively working on either upstreaming or reverting those differences https://github.com/swiftlang/llvm-project reply ChocolateGod 6 hours agoparentprevDoesn't Xcode ship with a closed-source build of LLVM (with patches) that you're referring to. reply ezfe 6 hours agoparentprevI’ve just read the swift build guide and there’s no sign of a closed-source version of LLVM. What are you talking about? reply mkl 6 hours agorootparentpeppermint_gum didn't mention a closed-source version of LLVM either. \"Private\" just means \"their own\" here. reply Zambyte 5 hours agorootparent> \"Private\" just means \"their own\" here. \"Fork\" is actually the word that means \"their own\". The \"private\" does indeed mean \"proprietary\" in this context. reply lawn 6 hours agoprev> Support for non-Apple platforms is also improving, as is the support for other, LSP-based development environments. Improving, as in ready now or still far in the future? What does the current state of Swift look like for Linux and Windows? And how well does the LSP server function today? reply alargemoose 6 hours agoparentI can’t speak to the current state of swift on other platforms directly/in detail. But I would point to the Arc browser being built using swift for both the windows and MacOS versions. They’ve also open-sourced a number of tools they built to make that work https://github.com/thebrowsercompany reply rescripting 5 hours agoparentprevUsable now for sure. I’ve been doing Swift development in VS Code which uses the LSP under the hood and it pretty much does what I expect an editor to do. Both the VS Code extension and the LSP are open source and seem pretty active, so hopefully they’ll get even better over time. The package ecosystem does feel sparse, especially coming from doing Node development. reply jiripospisil 32 minutes agoprevDoes anybody know if the upcoming version resolves the compilation time issues? https://danielchasehooper.com/posts/why-swift-is-slow reply zelphirkalt 4 hours agoprevHm. Not sure, if this is really a wise choice. After all they are choosing to use an Apple controlled programming language. Whatever direction Apple wants to go in, they will face themselves with following or working around. As an example we can look at Go and the whole GOPROXY debacle. And they will also have to deal with Apple not going into a direction, if they need that direction. Might have to build more stuff themselves, than with a language that is basically community owned. What if the Swift compiler starts doing things they don't like? They just going to be stuck at an obsolete version then? Or fork the language? reply losvedir 2 hours agoprevWow! This is awesome news. Swift is like the perfect language to me - kind of a Rust (whose type system I adore) but with garbage collection. I'd always thought it was a little too tied to the Apple ecosystem, and specifically iOS, but if they can make this work for a cross-platform browser, then I'll have to give it another look. Maybe things have changed recently. Oooh, or maybe I can even contribute now! I've supported Kling via GitHub for a while now and have been stoked about his pivot to building a browser. I never really dreamed of contributing, given C++, but now it feels more achievable. reply ksec 2 hours agoprevI am just worried. I just wish they could at least delay it until Swift 6.1, giving time for it to mature. And let the idea to jump right into Swift after 6.0 to age a little more. Developers have a tendency to jump to new language, new tools, new problems because it is exciting and fun. reply nu11ptr 6 hours agoprevThis is interesting. I evaluated Swift, but it didn't feel like platforms outside of Apple were first class. If this is changing, it would be a good thing. reply pelagicAustral 5 hours agoprevI did wondered how long would it take for a Rust zealot to take over this thread, it is already ongoing... That being said, this is a rather odd decision. Why would you go so much out of your way to add yet another compiling stage, yet another language that, far as I can tell, is not getting much traction in this space? reply dvektor 5 hours agoprevI am a bit surprised at this, considering the lack of non-apple ecosystem but I guess when you build everything yourself completely from scratch, you may not care as much about libraries and ecosystem. reply BaculumMeumEst 5 hours agoprevWhat happened to jakt? reply hypeatei 5 hours agoparentContributions are still being made to it[0], but definitely nothing compared to when it was first announced. Seems essentially dead to me at least. [0]: https://github.com/SerenityOS/jakt reply CxByte 4 hours agoparentprevRegardless of where jakt goes, it would never be qualified for this; Ladybird is doing its best to get rid of everything home-built that is not the web-platform. (Also it's a really young language withI'm starting to wonder if the Rust toxicity and evangelism are more meme than reality. Doubtful. If you're running a somewhat known FOSS C or C++ project, chances are you've had to close issues from Rust fanatics aggressively urging you for a rewrite, and shaming you if you object. Nothing has changed in that regard. reply commodoreboxer 4 hours agorootparentI do, and I haven't. reply throwaway215234 4 hours agorootparentI'm glad you've been spared. That doesn't really negate all the negativity and outright harassment that lots of people have experienced with the Rust community. I think the best example is the continuous vandalization of cppreference [0][1]. I've never seen such behavior from another language community. There's also continuous mocking/brigading campaigns organized on reddit and mastodon. [0] https://news.ycombinator.com/item?id=36349576 [1] https://www.reddit.com/r/Cplusplus/comments/14aiwqj/cpprefer... reply zozbot234 4 hours agorootparentprev\"Managing any kind of object graph in general\" is just a hard problem. It's what tracing GC was actually invented for! (And indeed, that is still the only one-size-fits-all solution.) It's not fair to blame Rust for surfacing the issues instead of just sweeping them under the rug and letting them blow up in production. reply keybored 4 hours agorootparentprevIME in the last while on HN the Rust Evangelism(TM) debate has been brought up either unprompted or because someone argued that Rust was objectively better on some metric (like memory safety compared to another language). In the latter case someone says something that can be argued on its merits but then someone else decides to tone police about “evangelism”. In this thread there are two Rust subthreads: someone brought up (and was downvoted) “why not Rust” out of nowhere (evangelism) and this one where we are discussing Rust Evangelism because GP quoted Kling on some separate tweet. So yes. We mostly seem to discuss Rust Evangelism as a meta thing. Something that has supposedly definitely happened, or is happening somewhere else, just rarely right in front of us in the discussions at hand.[1] I think that qualifies as a meme. [1] https://news.ycombinator.com/item?id=41119392 reply jeltz 5 hours agoparentprevI love Rust but have to agree that there is a lot of truth in all of those. The Rust community really should take a look at more welcoming and diverse communities like the Ruby and PostgreSQL communities. Not sure though what can be done to make handling long-lived state less clunky. reply __float 4 hours agorootparentWhat about the Rust community is not welcoming? Ruby has had its fair share of community controversies, so that's an odd choice for comparison. reply stiltzkin 34 minutes agorootparentMost have controversies and trivalism. reply anon-3988 5 hours agoparentprev> - Clunky for long-lived programs that maintain large complex object graphs Interesting observation...I have the exact opposite experience. Rust is especially amazing for long last program because you spend twice as much time developing it and then forget about it for the rest of your lives until you have to change something. And just by browsing the code, a flood of contexts come in because its expressed in the language fairly well (This function returns Option because ...., this function is generic over Read because ...) reply edflsafoiewq 5 hours agorootparentThat quote is describing the program's lifetime (how long a process runs), not the project's. reply pjmlp 5 hours agoparentprevAs someone that likes Rust, but is decades away from the days I identified myself with any specific language, the Rust Evangelism Strike Force are the ones that spoil the party. That is exactly the way to put off people, that initially could even be welcoming to hear about what the language is all about. reply jghn 5 hours agorootparent> Rust Evangelism Strike Force I realize this is not what people generally are referring to when they complain about the Rust community, but this is the part that annoys me. Feels like every damn day I see people preaching the Good News of Rust, pointing to things as being the unique and sole property of their preferred language. Except those things have been around for ages, in other languages. Memory safety? Invented by Rust! Algebraic Data Types? Invented by Rust! Funadamental FP constructs? Invented by Rust! High performance? Invented by Rust! If instead they just said that they enjoy having all of these things in a single language, well great. But instead it has to turn into a preach fest. reply neonsunset 5 hours agorootparent> Golang Evangelism Strike Force Concurrency? Invented by Go! (quickly corrected by Elixir/Erlang strike force, but these, just like Golang, have worse throughput than a particular C family language I have a soft spot for). Apologies, could not help myself as this response is amusing if sadly accurate (I do like Rust, but blind hostile evangelism tends to create the opposite to the desired outcome). reply freedomben 4 hours agorootparentElixir strike Force member here. Minor correction, concurrency wasn't invented by elixir, it was just perfected by it ;-D (That's a joke for the record. Elixir mainly uses erlang's stuff, and it's based on the actor model, which was not invented by elixir or erlang. I do personally love it though, I believe it to be a great implementation.) reply jghn 4 hours agorootparentprevAhaha, yes. Amazing. Even the evangelism strike force wasn't invented by Rust :) It's a good point. These things always annoy me. Rust just happens to have the most vocal one these days. reply brigadier132 5 hours agoparentprev> - Toxic community I think a lot of this is just rumors and maybe one or two high profile people. When I go to discord servers for rust and rust libraries, the help I get is as good as, if not better than support from companies I literally pay. reply blueflow 5 hours agorootparentFor years, whenever there was drama and shit-flinging in the OSS world, i looked up the people causing that on github and blocked them. Github has this feature that it warns you when you look at a repository where people you blocked contributed. If you keep such a list, you'll easily recognize projects you better stay away from. For me, this was one of the reasons to keep away from Rust. reply commodoreboxer 5 hours agorootparentThat sounds flawed to me. A large block list will disproportionately warn you about projects that are more open to any external contribution in general. Guilt by association is a weird standard for FOSS contributions. I certainly don't review the external lives of contributors on my repositories. reply brigadier132 4 hours agorootparentprevMy point was just about my actual experience with the community versus what everyone says about it. There is a lot of excitement I've noticed which seems to bother some people but I've never had anyone outright call me an idiot or anything and I always get help when I ask for it. reply the__alchemist 5 hours agoparentprevInteresting re complex projects. Compared to other langs I've used, rust gives me more confidence in maintaining and refactoring complex projects, maintaining state etc. I think this is due to the strict type checks, the helpful compile errors, and the ownership system. Maybe also due to the robustness of what I call struct-and-enum-oriented programming. I have plenty of my own beefs with rust that I won't go into here, but... it comes out on top for complex projects. reply hatefulmoron 4 hours agorootparent> Compared to other langs I've used, rust gives me more confidence in maintaining and refactoring complex projects In my humble experience, Rust gives me great confidence that my refactoring will likely be correct, but the type system makes refactoring anything moderately complex very difficult. I tend to paint myself into corners, and the compiler, in it's religious oath of correctness, won't allow a mortal like me to get away with it. I guess you can dismiss that as a skill issue, but Rust feels like a language that is very tough to iterate with. It's probably something I will reach for when I'm sure of what exactly my program will do, and how it will do it. reply commodoreboxer 4 hours agorootparentprevIt's definitely more clunky for complex object graphs. Making a useful directed graph with cycles is pretty annoying. Not impossible my any means (I'm currently working on a Rust project for audio graphs that allows cycles), but not nearly as easy as a GC language would make it. reply fidotron 5 hours agoparentprevThe key rust problem relates to: - Excellent for short-lived programs that transform input A to output B - Clunky for long-lived programs that maintain large complex object graphs To rust purists the latter should be solved through composition of many of the former. This is what happens when constantly going on about the evils of state becomes one of your cultural norms. That said I recently poked swift for non mac use and was not impressed by the status quo, and am not sure Apple are committed to the exercise. The core language is very nice though. reply odiroot 5 hours agoparentprevI'm really glad someone prominent has stated that. reply stephc_int13 5 hours agoparentprevChoosing between Rust or Swift is a false dichotomy. Switching programming language (or game engine) mid-course is a well known suicidal move. Who is asking them to use a different programming language? I am not a C++ fan, but it is a lot less risky to stick to it than switching, and this is true for any large projects ran by experts. reply jart 5 hours agorootparentIt was probably a condition of getting funding. In the NGO world using or funding greenfield C/C++ is a great way to make yourself a social pariah I bet. A corporation wouldn't care, because they're driven by what makes dollars and cents. But in non-profits (which Ladybird chose to be part of) it's all about ideology. The only way to get an exemption is if you're doing AI which he isn't. reply gjsman-1000 5 hours agorootparentprevC++ is a loaded gun, strapped to your body and aimed at your foot, with infinite bullets automatically firing every second, that requires you to constantly exert 25 lbs of force to tilt the gun and avoid hitting your foot. Most of the time, you’ll be successful. However, nobody seeing your plight would be shocked if your foot eventually gets blown up. To claim this state of affairs is just fine because you’ve done it for years, pitiable. reply stephc_int13 5 hours agorootparentWell, there are indeed many ways to shoot yourself with C++, this is why having C++ experts on the team is a good thing. They are supposed to know how to avoid the traps and avoid being lured into the worst parts of C++ and OOP design style. I have seen very good C++ projects using only the minimal amount of bullshit features, Omar Cornut's Dear Imgui comes to mind as an example. As Swift beginners, they are less likely to avoid the bad idioms, but this is the kind of thing you only discover late, when the codebase is large enough. reply gjsman-1000 4 hours agorootparentPerhaps, but here’s a question: Can you really tell me, that any C++ codebase doesn’t have memory safety bugs? The last decades have shown that almost every C++ codebase has a bug somewhere, as long as you look hard enough. That’s not a good state of affairs. C++ is a reactionary language. The programmer assumes they are an expert who can use it safely, there’s just a few exceptions or mistakes here and there and that’s normal. Using memory safe languages is a programmer knowing they will mistakes, that they aren’t that smart despite their best efforts, and mitigating the opportunity. Avoid near occasions of sin. reply bn-l 5 hours agoparentprevAgree absolutely with every single point. Especially the last one. reply steeve 5 hours agoparentprevThe last one is so very true reply LoganDark 6 hours agoparentprevI wouldn't say all the Rust community is toxic. Then again, I'm not sure which Rust community he's referring to, I'm sure there are some toxic ones out there. reply ayhanfuat 5 hours agorootparentThere was a big fight on Twitter last month because of a comment he made 3 years ago (https://github.com/SerenityOS/serenity/pull/6814). I think that's closely related. reply commodoreboxer 5 hours agorootparentHow is that related? What does it have to do with Rust? If anything, I'd say it shows that social media (and microblogging platforms like Twitter and Mastodon in particular) tend to be politically charged, toxic, and dogmatic. reply irusensei 2 hours agorootparentI can totally imagine someone from the Ladybird project reaching out for the Rust community channels and being harassed because of that silly PR. reply Spivak 5 hours agorootparentprevThis is such a weird thread, sure it's a nit but grammatically a person of unknown sex should be either \"he or she\" or \"they.\" And the latter is by far the preferred form by English writers regardless of political affiliation. It didn't become a political thing until Andreas made it political. It would have taken two seconds to be like \"+1 Good catch man, merged.\" reply skipkey 5 hours agorootparentIt could be an age thing. When I was taught grammar 40 plus years ago, for someone of indeterminate sex, “he” was taught as always appropriate, “he or she” was a somewhat clunky alternative that was situationally appropriate where you were stressing the gender neutrality, and “they” was just simply bad grammar which would get you bad marks. I’m honestly not sure when that changed. reply freedomben 4 hours agorootparentIndeed. I was taught very directly that the singular pronouns were he, she, and it. The plurals were we, you, they. So grammatically if you were referring to a singular person of unknown sex, then you should use \"it\" . Obviously using the pronoun \"it\" at some point became offensive, so is highly not recommended. But, (probably after having drilled into my head repeatedly that \"they\" is a plural) it seems very incorrect to my ears when \"they\" is used to describe a singular person. It also unfortunately comes with ambiguity sometimes. I've had misunderstandings where I used they as a singular pronoun to describe someone of unknown gender, and the person I was talking to took it as a reference to a plural, which at best creates confusion, at worst misleads. Language is an incredibly hard problem, and it certainly doesn't help that as youth, we are drilled with supposedly objective truth regarding language, when in reality it is far less defined and more nebulous than than the teachers would have us believe. The generational gaps can already be tricky to navigate. Having different ideas of objective truth, especially regarding language, certainly does not help. reply commodoreboxer 5 hours agorootparentprev\"They\" as a gender neutral singular pronoun has never been bad grammar, and has been accepted in common use for many hundreds of years. reply jml7c5 5 hours agorootparentIn casual use, yes. In formal writing, the broad switch to acceptance of singular \"they\" is only about 15 years old. Up until that point it's the sort of thing that would be flagged by an editor, or lose you marks in an English paper. reply commodoreboxer 4 hours agorootparentI'd be shocked if that were universal over that time, given that even formal language has undergone many changes in attitude. Over hundreds of years, I bet that in many times and places it has not considered it a problem, particularly given its use in the King James Bible. reply LoganDark 5 hours agorootparentprevA fun fact I learned just recently is that even Shakespeare used singular \"they\": http://itre.cis.upenn.edu/~myl/languagelog/archives/002748.h... (and even singular \"themselves\"!) which puts to rest approximately every argument I've ever seen against it. reply commodoreboxer 5 hours agorootparentIt was also used in the King James Bible, published in 1611. reply LoganDark 24 minutes agorootparentInteresting. Shakespeare had first used singular 'they' in 1594, so not even that long before. reply littlestymaar 5 hours agorootparentprevIt's been qualified as “bad grammar” by many people over the years though. reply littlestymaar 5 hours agorootparentprev“They” is particularly convenient when discussing about people over the internet, because not only we don't have to assume the person's gender, but we don't have to assume if it's an individual or a group either. And tbh using gender in pronouns is artificially annoying, and it's good to see English has a way out of it, like it got rid of giving genders to common objects like most European languages (“Non, it's La chaise, chair is feminine in French” -_). reply __float 4 hours agorootparentLanguages hold complexity in different areas, but that doesn't make it artificial. Grammatical gender (and noun classes more generally) may seem redundant, but redundancy in language is quite common. It helps disambiguate, as it turns out speech (especially, but writing too) is a very lossy method of communicating. (You seem perfectly happy distinguishing between animate/inanimate nouns and choosing \"it\" or \"he/she/they\" -- that's a difference not all languages make, but should we get rid of it in English too?) reply arcxi 1 hour agorootparent1. \"it\" does not distinguish between animate and inanimate nouns: The baby grunted again, and Alice looked very anxiously into its face to see what was the matter with it. — Lewis Carroll, Alice's Adventures in Wonderland But he [Jesus] said to them, \"It is I; do not be afraid.\" — John 6:20 2. gender distinction is artificial because it's not based on anything real, rather it's based on whether the \"vibes\" that a person (or an inanimate object in European languages) that you're referring to gives off are more feminine or more masculine. this \"redundancy\" creates all sorts of trouble for folks who are not comfortable with the \"vibes\" society assignes them with a particular gender at a given moment. the problem here is not that the speech is lossy, but that this particular \"feature\" of language demands that you convey the person's identity when it's almost always irrelevant in a way that's exclusive to gender (thank God nationalism wasn't invented when the language was forming) reply __float 35 minutes agorootparent1. Yes, as with many \"rules\" in language there are exceptions. I would find it a bit odd to refer to a baby as \"it\" in (current) English, though I do admit there are some situations where it wouldn't feel as out of place. In my read of the Bible quote, it's not really referring to a person as \"it\" in the same way. 2. Grammatical gender has nothing to do with the \"vibes\" of an inanimate object - it's quite arbitrary, really. The problem you're associating here is much more with gender in humans, but we were talking about the grammatical construct applied to objects (like a chair as the grandparent mentioned). reply LoganDark 1 minute agorootparentBabies are weird. So are animals. So, as far as I understand it, gender pronouns (this includes singular they/them, which is a gender pronoun in the way that it has no particular gender; this could be the 'gender' of 'neuter') are typically for referring to individuals. This means that whether to call a baby, or animal, by gender pronouns or object pronouns varies depending on the expectation. I guess the generally understood term for this would be \"humanization\", although as someone who identifies non-human that still sounds somewhat exclusive, but regardless, that is what I generally observe to be the difference. So, it's possible to refer to a baby or an animal as an object, if, in doing so, you intend not to assign that object any individuality; in other words, if you're referring to it in a non-individualistic way. ex. \"I needed to change its diaper again today\" (\"dehumanizing\"; I guess shows a lack of empathy, but not everyone necessarily feels empathy for the baby until it is more markedly an individual) It's also possible to refer to a non-individual (such as an inanimate object) as an individual, which, in doing so, typically implies that the non-individual nonetheless has some sort of individuality or that you're specifically assigning it such. ex. referring to ships / other vehicles using 'she' Typically, it's respectful to refer to people as individuals because they are. It is \"dehumanizing\" to suggest otherwise. (seriously, is there a better word for this?) Some prefer to be referred to as objects instead, though; I know at least one like this. But those will typically specify it in some way, and it's rude not to refer to any one as an individual unless otherwise specified. LoganDark 22 minutes agorootparentprev> not only we don't have to assume the person's gender, but we don't have to assume if it's an individual or a group either. as someone with DID (formerly called Multiple Personality Disorder) this is actually kind of a nice bonus. (though people still often use he/him pronouns to refer to specifically me, which is fine) reply LoganDark 5 hours agorootparentprev> I think that's closely related. I am the wrong person to comment on this. Of course there's a big fight when you claim that gender is a political issue. reply rvense 5 hours agorootparentprevLadybird and Serenity have a policy of not allowing any sort of expression of or reference to someone's sexuality or gender identity, as this is deemed \"divisive\" or \"politicising\". Rust does... not have that. reply nequo 5 hours agorootparent> not allowing any sort of expression of or reference to someone's … gender identity So the use of he/she is banned by those projects? reply rvense 5 hours agorootparentNot like that. A pull request that replaced \"he\" in documentation with \"they\" was closed with the comment \"This project is not the place to advocate your personal politics\". reply jeltz 5 hours agorootparentYeah, that was a pointlessly rude way to close the PR since it assumed ill intent. But tiny pull requests like that are rarely helpful since the one reviewing it will need to check what pronouns are used in the rest of the documentation to make sure the style is consistent so they just create busywork for maintainers even though those PRs are almost always done in good faith. I definitely do not think he was leading by example here. Making assumptions aabout why people do PRs and denying them based on those is a good way to create a toxic community. reply __float 4 hours agorootparent> the one reviewing it will need to check what pronouns are used in the rest of the documentation to make sure the style is consistent Huh? Nothing in a software project will ever be perfect – code or docs — so this doesn't seem like a reasonable expectation. It's always a process of gradual improvement, and that can be true for a change like this too. reply bn-l 5 hours agorootparentprevYou are purposefully taking a wild assumption to frame his character a certain way because of your politics. This is literally the kind of toxic divisiveness he’s talking about. Can’t you see how this makes people want to have nothing to do with this issue? reply rvense 4 hours agorootparentYou are right. I don't in fact know if that's what he means by calling the Rust community \"toxic\". I've never seen anything like a bigoted word attributed to Andreas, by all appearences he is one of the most caring people in open source, and his character is obviously a big part of Serenity's success in attracting followers and contributers. But he does seem to be very insistent on \"having nothing to do with the issue\" (of inclusivity). His stated goal is to make a welcoming and inclusive environment, and ultimately I just think letting Pixie Ada put pride flags in xer bio will be more succesful at that than a don't ask, don't tell policy that seems mostly geared to not bother people who happen to fit in by default. reply spencerchubb 5 hours agorootparentprevif that is their stated policy, they don't seem to follow it very well since they use 'he' in documentation reply jenadine 5 hours agorootparentNot anymore https://github.com/SerenityOS/serenity/pull/24648 reply LoganDark 5 hours agorootparentprevRust communities even generally try to provide a safe space for queer identities. Honestly I can't even count the number of trans people in the Rust server I typically hang out in. I don't even talk about Rust there, the people just are nice lol reply Hizonner 5 hours agorootparent> Rust communities even generally try to provide a safe space for queer identities. It's pretty clear that that's exactly what this asshole is calling \"toxic\". reply pjmlp 5 hours agorootparentprevBasically the one that gave origin to Rust Evangelism Strike Force meme. reply Sakos 6 hours agorootparentprevIt doesn't matter if only a portion is toxic, because that portion can easily poison the well all on their own for everybody. reply eviks 5 hours agorootparentIt does matter because there is a portion that is toxic in about any sizeable community, so following that logic all wells would be easily poisoned reply LoganDark 5 hours agorootparentAll wells are easily poisoned, though; Hyprland for example. reply ironmagma 6 hours agorootparentprevEspecially if that portion is in the official nonprofit associated with the language. reply LoganDark 5 hours agorootparentEh, I don't personally consider the Rust Foundation to have anything to do with Rust The Language. I consider \"the community\" to be everyone who doesn't have official ties to the language. Is this incorrect? reply 42lux 6 hours agoparentprevHe's not wrong. reply ramon156 5 hours agorootparentI wouldn't be surprised if it is true that the community is toxic, but I myself haven't really seen it reply pas 6 hours agorootparentprevcan you please substantiate in which points and how right he is? do you have experience with complex object graphs in Rust, direct or indirect experience about the community? thanks! reply Decabytes 5 hours agorootparentThis huge blog post goes over some of the challenges of using Rust. https://loglog.games/blog/leaving-rust-gamedev/ For the community I'll pluck out this paragraph > That being said, there is an overwhelming force in the Rust community that when anyone mentions they're having problems with Rust the language on a fundamental level, the answer is \"you just don't get it yet, I promise once you get good enough things will make sense\". This is not just with Rust, if you try using ECS you're told the same thing. If you try to use Bevy you'll be told the same thing. If you try to make GUIs with whichever framework you choose (be it one of the reactive solutions or immediate mode), you'll be told the same thing. The problem you're having is only a problem because you haven't tried hard enough. I've experienced this same feedback when I was struggling with Rust. One time when I posted in the Rust subreddit about it seeking help and talking about my struggles, I got the unhelpful response of \"I believe in people\" as a dismissive response to my struggles. Admittedly this was years ago and I've since moved on from Rust, but the blog post is dated from 2024-04-26, so it appears the issues with the language still remain reply littlestymaar 5 hours agorootparentIt's not specific to Rust at all, I remember hearing the same kind of talks when learning Java because I found OOP confusing. And in fact most people saying that are right: most of the time people complain about stuff because they haven't internalized how it's suppose to work (as I was). Don't get me wrong, there are plenty of valid criticism of Rust or Java (and OOP in particular), but at the same time in practice most of the people who complain aren't at the level of understanding and their criticisms aren't good. Both are true at the same time: - every programming language has terrible flaws. - 99.9% of the criticisms you'd see online about a programming language in particular are garbage. reply Decabytes 5 hours agorootparent> It's not specific to Rust at all, I remember hearing the same kind of talks when learning Java because I found OOP confusing. You're right, but that doesn't excuse it. And most languages don't have this as their first bullet point in their code of conduct >We are committed to providing a friendly, safe and welcoming environment for all, regardless of level of experience, gender identity and expression, sexual orientation, disability, personal appearance, body size, race, ethnicity, age, religion, nationality, or other similar characteristic. What is the point of a code of conduct if you can't rally the community around the first part of the first bullet point. If people are still experiencing toxicity on the level of other communities that don't have a code of conduct, then it's not working and the leaders of the Rust community should do something about it. reply littlestymaar 5 hours agorootparent> the leaders of the Rust community should do something about it. You should read the reaction of the Rust community leaders to the quoted article, and you'll see that they share your opinion that something must be done. At the same time when you have people in the community saying politely and cheeringly that “you'll get over it when you've internalized the rules” what are you supposed to do as a mod? It obviously doesn't infringe the code of conduct even though it seems to have offended the author of the article. Also, when what the people get pissed of about a community is “they don't want to admit it doesn't work” it's had to say that the toxicity is “people are still experiencing toxicity on the level of other communities that don't have a code of conduct”, by any means… The goal of a CoC is to make sure nobody gets bullied or harassed, not that nobody will ever get annoyed by other people. You can't make sure you don't have idiots in your community, all you can do is making everyone behaving in a civil manner, which is already hard enough. reply Thaxll 5 hours agoprevUsing Swift outside of Apple ecosystem seems like a bad idea, other platform are subparts. reply yohannparis 5 hours agoparentCompiled Swift code cannot run on other platform? Curious, I never used it and I'm not aware of those limitations. reply breakfastduck 5 hours agorootparentIt can, the poster you're replying to is ill informed. reply rvz 6 hours agoprevI would have thought that Ladybird would be using a language that specifically guarantees memory safety which is Rust. But Swift is a very surprising choice but actually makes sense for a browser. The browser story is not great for Rust as we can only point to Servo which isn't ready to be used as a daily driver for millions of users. But Arc Browser is written with a combination of Swift and C++ to run on macOS and Windows. Other than iOS apps, perhaps Swift found another use-case in large C++ code bases thanks to the C++ interop story. reply GeekyBear 6 hours agoparent> I would have thought that Ladybird would be using a language that specifically guarantees memory safety which is Rust. Rust isnt the only compiled language that provides memory safety by default. Swift does as well. reply zozbot234 5 hours agorootparentDoes Swift enforce memory safety in concurrent code also, i.e. preventing thread-unsafe data access in safe code? That's a really hard problem that Rust tries to address mostly successfully, and many other languages don't. reply GeekyBear 4 hours agorootparentYes. That is a new feature as of version 6 of Swift. https://www.swift.org/migration/documentation/swift-6-concur... reply stephen_g 6 hours agoparentprevSwift is memory safe. The C++ interop thing I think is massive. But isn’t there also the problem that with Rust you can’t have the equivalent of shared pointers, so you can only have a single reference to one object (sorry I don’t really know Rust, just going from how this has been described to me) which apparently makes representing things like DOMs and abstract syntax trees an absolute nightmare? reply rahkiin 5 hours agorootparentAnd cannot have linked lists either. When you make a compiler in rust, basically you give everything the same lifetime and drop the memory at the very end. That allows cicular references. Or you use Rc, but that is against what purists want you to do. For longer lifetime programs with complex models the borrow checker becomes harder reply zozbot234 4 hours agorootparentYou can express linked lists efficiently in Rust using the GhostCell/QCell pattern. Yes it's clunky, but this is after all an area of active research in PL theory. As it is, most ordinary \"easy\" implementations of linked lists do not actually prove memory safety - it's a genuinely non-trivial problem, not a case of mere incidental complexity. reply ghosty141 4 hours agorootparentprevthere are also classical shared pointers in rust: https://doc.rust-lang.org/std/cell/struct.RefCell.html reply jsheard 6 hours agoparentprevI'm not sure if the comparison to Servo holds up since that's a browser engine, and Arcs engine (Chromium) is 100% C++. Swift is only used for the frontend. reply jghn 6 hours agoparentprev> specifically guarantees memory safety which is Rust I think you mean \"one of which is Rust\". reply stephc_int13 5 hours agoprev [–] I think this kind of reckless move is likely to be very costly and could even jeopardize the success of this project. I would say the same thing with any languages switch, except C and C++ as they tend to mix well and coders are usually familiar with both. But Swift is, in my opinion, the worst possible choice. It is known to be a mess, even criticized by its original maker. The compilation times are horrendous and nobody in the team is a Swift expert. When making large architecture decisions on such a complex and difficult project, the people in charge should use all their mental energy on that task, not exploring new idioms or styles. The only valid explanation that I can think of is that they are being funded to promote Swift. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Ladybird Browser team is considering Swift as a potential successor to C++ for their project.",
      "Andreas Kling has been testing various languages by having contributors rewrite parts of the project in different languages over the past few months.",
      "Swift has emerged as the most suitable option among the evaluated languages."
    ],
    "commentSummary": [
      "Ladybird browser will adopt the Swift programming language this fall, prompting debates about its suitability beyond the Apple ecosystem.",
      "Proponents cite Swift's recent enhancements, including improved C++ interoperability and memory safety, as advantages for cross-platform development.",
      "Concerns include the challenges of switching languages mid-project and the potential impact of funding on the decision."
    ],
    "points": 169,
    "commentCount": 160,
    "retryCount": 0,
    "time": 1723290742
  },
  {
    "id": 41209688,
    "title": "OpenSnitch is a GNU/Linux interactive application firewall",
    "originLink": "https://github.com/evilsocket/opensnitch",
    "originBody": "Join the project community on our server! OpenSnitch is a GNU/Linux application firewall. •• Key Features • Download • Installation • Usage examples • In the press •• Key features Interactive outbound connections filtering. Block ads, trackers or malware domains system wide. Ability to configure system firewall from the GUI (nftables). Configure input policy, allow inbound services, etc. Manage multiple nodes from a centralized GUI. SIEM integration Download Download deb/rpm packages for your system from https://github.com/evilsocket/opensnitch/releases Installation deb $ sudo apt install ./opensnitch*.deb ./python3-opensnitch-ui*.deb rpm $ sudo yum localinstall opensnitch-1*.rpm; sudo yum localinstall opensnitch-ui*.rpm Then run: $ opensnitch-ui or launch the GUI from the Applications menu. Please, refer to the documentation for detailed information. OpenSnitch in action Examples of OpenSnitch intercepting unexpected connections: https://github.com/evilsocket/opensnitch/discussions/categories/show-and-tell Have you seen a connection you didn't expect? submit it! In the press 2017 PenTest Magazine 11/2019 It's Foss 03/2020 Linux Format #232 08/2020 Linux Magazine Polska #194 08/2021 Linux Format #280 02/2022 Linux User 06/2022 Linux Magazine #259 Donations If you find OpenSnitch useful and want to donate to the dedicated developers, you can do it from the Sponsor this project section on the right side of this repository. You can see here who are the current maintainers of OpenSnitch: https://github.com/evilsocket/opensnitch/commits/master Contributors See the list Translating",
    "commentLink": "https://news.ycombinator.com/item?id=41209688",
    "commentBody": "OpenSnitch is a GNU/Linux interactive application firewall (github.com/evilsocket)156 points by dp-hackernews 4 hours agohidepastfavorite34 comments samlinnfer 2 hours agoI've tried to use it extensively (as an interactive firewall). However there are just some problems (that are not the fault of OpenSnitch) that I'm not even sure that are even solvable. For example, supposed I run `curl` on the terminal, I can either always decide on a case-by-case basis to allow it thru, or I'm required to whitelist it permanently. Once I've whitelisted generic tools like `curl` or `wget`, then the floodgates are really open, since any malware that have compromised my machine can just use `curl` or `wget` to get to the internet without hitting the firewall. reply haswell 2 hours agoparentI’ve found that by using subdomain wildcards and/or subnets, I build up a stable set of rules pretty quickly and then only have to review requests to new endpoints once in awhile. To me, the peace of mind knowing that I’ll be prompted to allow new access is worth the initial hassle. And once the habit is built, it’s pretty easy to manage. Editing to add: I also use expiring rules regularly. Maybe I trust an installer and want to let it do its thing. So I open it up with a rule for the executable expiring in the near future (options include: forever, until reboot, for the next 30s, for the next 5 mins, etc). This can drastically simplify some tasks if there are a large number of endpoints for some reason and avoids leaving a hole open permanently. reply xyst 10 minutes agorootparentIMO - requires a ton of work. Adoption requires updating rules quite often reply xyst 11 minutes agoparentprevMight be the same but what if you allow all curl/wget traffic for 'dev' user, but continue to flag any traffic for 'normal' user for dev work run 'su -c curl … dev' But if malicious program in normal user space is running, then app firewall flags curl and wget use appropriately. It would be annoying to input password every time so maybe setup PAM to use yubikey or biometric? Also make sure this user cannot login and does not have a password. reply netule 1 hour agoparentprevI wonder if there's a way to configure it so that when the parent cmd is a trusted command (say, a bash/zsh owned by the user), it could let the curl command through and otherwise block it. But yeah, that seems like a bit of a hassle. reply akdev1l 48 minutes agorootparentThen any process can do `system(“bash -c curl malware.attacker”)` reply netule 39 minutes agorootparentThe bash command line wouldn't be the same as the one launched by your terminal, though. But yes, I’m sure there are myriad exploits around something like that. reply ddtaylor 30 minutes agorootparentWhat could work instead is something where you run a command like `opensnitch-context dev` and it would talk to the running daemon to do proper authentication (\"do you want to allow this context to be used?\") and then hopefully some other magic (cgroups?) to know if the processes are part of that context even if they are sparse/nested child processes. reply phoe-krk 1 hour agoparentprevYou'd need a firewall that is not just TCP/UDP-aware, but HTTP(S)-aware, and a way for your firewall to sniff on TLS-encrypted traffic. reply diggan 52 minutes agorootparentOr be ok with filtering HTTP/TLS traffic based on the domain only, as that part isn't encrypted (the SNI [Server Name Indication]). OpenSnitch should be able to allow/disallow based on that, rather than having to decrypt the TLS part. reply djent 32 minutes agoparentprevso don't do that. problem solved reply chefandy 2 hours agoparentprevIt's the filter configured per user, or is it system-wide? I know you can filter per-user with IP tables and whatever the newer one is, but I haven't dug that deep into open snitch. Maybe a single trusted user account without a login that you could su into? I wonder if you could also whitelist a VM process and spin up single-use VM sandboxes to use when you want to do a bunch of work like that. Definitely a minor hassle to set up compared to just saying yes or no to permissions, but it's not complicated, if it works. reply bulatb 52 minutes agorootparent> IP tables and whatever the newer one is nftables (\"nf\" for Netfilter). https://wiki.nftables.org/wiki-nftables/index.php/What_is_nf... reply vlovich123 45 minutes agoprevHow does this compare with something like UFW? Is the main thing a UI to view ongoing activity? reply pull_my_finger 39 minutes agoparentOpenSnitch prompts you when there's network activity. So if random app makes a telemetry call or something, you get the option to white/greylist that connection with granularity, like OK to make a connection to that address from this executable etc, or always OK to this address, and with duration options like once/for 15 seconds, until reboot etc. Once you get over the hurdle of whitelisting the apps you use and trust, it's actually pretty nice and gives you good insight into what your apps/games are doing you otherwise wouldn't have known about. reply zargon 36 minutes agoparentprevUFW isn't an application firewall, it only blocks/allows port numbers (system-wide), as far as I know. reply orkj 1 hour agoprevDoes something like this exist for my phone, android specifically? Any good recommendations? reply Joe_Cool 1 hour agoparentSadly all real firewalls need root. I was using AFWall+ for a long time it has neat controls for every app to allow or deny Wifi, Cell or LAN (if you have). It is a iptables/nftables frontend so you can customize the rules to your heart's content: https://github.com/ukanth/afwall Works from Android 2+ Without root only VPN solutions like Adguard are available. EDIT: if you want neat stats: Glasswire has an Android version. I have only used the beta so I have no idea about its current state. Might be worth checking out though. reply ignoramous 1 hour agorootparentex-AOSP and rethink dns+firewall dev here > Sadly all real firewalls need root What do you mean by a \"real\" firewall? It is very much possible to build a userspace firewall in Android using the VPN APIs. On Android, ROMs like GrapheneOS, Lineage, and CalyxOS have firewalls built-in. > Glasswire has an Android version Note though, Glasswire was recently acquired by another company: https://archive.is/KW2R3 reply yndoendo 20 minutes agorootparentI thought parts of the Android OS can by-pass the VPN so the firewall becomes ineffective against blocking Google, OEMs, and others that have root. Wouldn't the VPN API being used as a firewall also prevent one to use a VPN client at the same time? reply Joe_Cool 12 minutes agorootparentprev> Note though, Glasswire was recently acquired by another company Ah that's why the premium stuff is now free. I was wondering. Let's hope it's not the first sign of enshittification. > What do you mean by a \"real\" firewall? In my experience the \"block all non VPN traffic\" options in Android don't work reliably. iptables does however. It's a sad state that you cannot even set a static IPv6 on Android without root. reply sureglymop 1 hour agoparentprevThe app \"Rethink: DNS + Firewall + VPN\" has similar features. reply supriyo-biswas 1 hour agoparentprevThere's netguard[1], although most of the convenience features are behind a small payment. [1] https://netguard.me reply mikae1 55 minutes agoparentprevGrapheneOS can at least block internet traffic for specific apps. But can't do it for port ranges or specific domains. reply SparkyMcUnicorn 1 hour agoparentprevMy non-root solution is to use NextDNS or ControlD with \"private DNS\" (DNS over TLS). Doesn't stop direct IP connections, but it's good enough. I also have the CLI installed on OpnSense so DoH is enforced for all devices on my LAN as well. reply vhguru 3 hours agoprevWould be great to have Arch and OpenSUSE packages too. reply jiripospisil 3 hours agoparentThere is an official package for Arch Linux. It doesn't ship with the ebpf modules for some reason though (you need to get them separately from AUR). reply diggan 3 hours agoparentprev`opensnitch` is in the extra repository on Arch, and `opensnitch-ebpf-module` exists on the AUR. reply amingilani 3 hours agoprevIs there an open source equivalent for MacOS? reply eep_social 2 hours agoparentI tried LuLu and it was okay but I did end up trying and subsequently buying Little Snitch. The level of UX polish wasn’t quite there for me with LuLu. reply jiripospisil 2 hours agoparentprevThere's Lulu based on Apple's Network Extension framework but there are quite a few issues with the framework itself (it will briefly initiate a connection even though there's a deny rule for that address etc). https://github.com/objective-see/LuLu reply lelag 2 hours agoparentprevYes, there is: Lulu at https://objective-see.org/products/lulu.html. reply mixmastamyk 2 hours agoprev [–] This is great for catching sloppy apps that make an excessive number of connections. Thunderbird, I’m looking at you. I like it, but it has a small annoyance in that the temporary rules that have expired don’t get deleted or marked in the interface. So I have to restart the gui once in a while to clear them. reply richardlblair 1 hour agoparent [–] Not to be that guy, because I never really have the time myself. But, I'm sure PRs are welcome reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "OpenSnitch is a GNU/Linux application firewall offering features like interactive outbound connections filtering, system-wide ad/tracker/malware blocking, and GUI-based system firewall configuration.",
      "It supports managing multiple nodes and Security Information and Event Management (SIEM) integration, making it a robust tool for network security.",
      "The project has gained attention from notable publications such as PenTest Magazine, It's Foss, and Linux Format, highlighting its relevance and utility in the tech community."
    ],
    "commentSummary": [
      "OpenSnitch is an interactive firewall for GNU/Linux, with discussions focusing on its pros and cons, such as the difficulty of whitelisting tools like `curl` or `wget` without compromising security.",
      "Users suggest solutions like subdomain wildcards, expiring rules, and user-specific configurations to manage permissions effectively.",
      "Comparisons are made with other firewalls like UFW, and alternatives for Android and MacOS, such as AFWall+, NetGuard, and Lulu, are mentioned, along with tips on managing firewall rules and interest in packages for various Linux distributions."
    ],
    "points": 156,
    "commentCount": 34,
    "retryCount": 0,
    "time": 1723299352
  },
  {
    "id": 41207446,
    "title": "Susan Wojcicki has died",
    "originLink": "https://www.facebook.com/share/p/qe2ZMcs9Bz4K1SPt/",
    "originBody": "Log In Log In Forgot Account? Facebook Facebook Facebook Facebook Facebook Facebook Facebook Facebook Facebook Facebook Facebook Facebook Facebook Facebook Facebook Facebook Facebook Facebook Facebook Facebook Facebook Facebook Facebook Facebook Facebook Facebook Facebook Facebook Facebook Facebook Facebook Facebook Facebook Dennis Troper d o S n o s t e r p 3 3 t m 2 5 7 a u t m g m 0 7 g i g 6 3 a 2 1 6 1 5 u 1 f g 4 f 5 4 g g l 9 u 1 3 2 1 h 6 a 4 c 1 4 · It is with profound sadness that I share the news of Susan Wojcicki passing. My beloved wife of 26 years and mother to our five children left us today after 2 years of living with non small cell lung cancer. Susan was not just my best friend and partner in life, but a brilliant mind, a loving mother, and a dear friend to many. Her impact on our family and the world was immeasurable. We are heartbroken, but grateful for the time we had with her. Please keep our family in your thoughts as we navigate this difficult time. +3 qbyW5jK58.com Photos from Dennis Troper's post VzLkfM1w0JSUV1mziN2ZIctf2iBLc5BQe47KraWDMLJh7LntkfxWi d o S n o s t e r p 3 3 t m 2 L 7 a u e M g m 0 7 g a g o n a 2 1 6 1 5 u 1 f g 4 f 5 r g g l 9 u 1 3 2 e r a 4 c 1 4 All reactions: 1.8K 221 comments 136 shares Like Comment Most relevant Jose Steinkoler Un fuerte abrazo Denis en este difícil momento. 14h 14 hours ago 8 Brian Jackson That is devastating news, Dennis. I am so sorry for your loss. Estella and I send our deepest condolences to you and your family. 14h 14 hours ago 9 Karen Zonzinski Lo siento mucho Dennis, Que descanse en Paz y recuerden siempre los lindos momentos que tuvieron juntos! Un abrazo 14h 14 hours ago 4 Mauricio Gutiérrez B Cuánto lo siento Dennis Troper, un fuerte abrazo, mis más sentidas condolencias 14h 14 hours ago 5 Kal Amin Dennis, I'm saddened to hear this. I am sorry for your loss and our deepest condolences go out to you and your family. 14h 14 hours ago 6 Hunter Walk My heart and thoughts to you and the family. She made the hugest impact and that will live on forever in so many people 14h 14 hours ago 15 Abraham Stern So sorry for your loss Dennis Troper. Our sincere condolences to all your beautiful family. May her memory be always a blessing. BDH’ 14h 14 hours ago 4 Gabrielle Hull I’m heartbroken. Susan was a shining star to all who knew her Sending all of my love to the whole Wojcicki/Troper family. 14h 14 hours ago 7 Shenaz Zack Mistry Oh no this is so sad to read. Hugs to you and your family at this extremely difficult time 14h 14 hours ago 6 Daniel Politzer Lo siento tanto Dennis Troper. Un fuerte abrazo y mucho amor para ti y los niños. 14h 14 hours ago 5 View more comments 10 of 220 Facebook Facebook Facebook Facebook Facebook Facebook Facebook Facebook Facebook Facebook Facebook See more on Facebook See more on Facebook Email or phone number Password Log In Forgot password? or Create new account",
    "commentLink": "https://news.ycombinator.com/item?id=41207446",
    "commentBody": "[dupe] Susan Wojcicki has died (facebook.com)150 points by nmwnmw 13 hours agohidepastfavorite34 comments dredmorbius 12 hours agoDupe:reply CSMastermind 13 hours agoprevFYI Sundar Pichai posted a tribute: https://x.com/sundarpichai/status/1822132667959386588 > Unbelievably saddened by the loss of my dear friend @SusanWojcicki after two years of living with cancer. She is as core to the history of Google as anyone, and it’s hard to imagine the world without her. She was an incredible person, leader and friend who had a tremendous impact on the world and I’m one of countless Googlers who is better for knowing her. We will miss her dearly. Our thoughts with her family. RIP Susan. I'll say personally it's tragic to see someone like this pass in their 50s. Given Susan's impact on both Google as a whole and more specifically YouTube it's no understatement to say that she changed the world profoundly. I don't think that YouTube, in its current form, or the creator economy that it produced, would exist in anywhere near the same shape had Google not acquired and then spent years funding the company at a financial loss. reply xbmcuser 12 hours agoparentShe had a huge impact on YouTube and with it the world as I personally feel YouTube has become one of the largest resource of information on how to do almost anything for the newer generations as well as for people that had no access because they could not read. And as ai translation get better the impact on billions of people will be huge. reply guywithahat 13 hours agoprevI can’t get the link to load, but here’s Pichai’s take: > Unbelievably saddened by the loss of my dear friend @SusanWojcicki after two years of living with cancer. She is as core to the history of Google as anyone, and it’s hard to imagine the world without her. She was an incredible person, leader and friend who had a tremendous impact on the world and I’m one of countless Googlers who is better for knowing her. We will miss her dearly. Our thoughts with her family. RIP Susan. https://x.com/sundarpichai/status/1822132667959386588?s=46 reply nsoonhui 13 hours agoprevHer sister, Anne, is the ex spouse of Google founder Brin, and 23andme cofounder. https://en.m.wikipedia.org/wiki/Anne_Wojcicki reply chubot 12 hours agoprevI always thought it was cool that Google started in her garage in Menlo Park. Too young to be gone :-( reply broknbottle 13 hours agoprevwhoa, I believe her son also passed away like ~5 months ago. reply rottencupcakes 13 hours agoparentAn accidental drug overdose on campus at UC Berkeley. One wonders if his mom having terminal cancer was a factor in his overdoing it. And I cannot imagine how news like that would hit a mother with cancer, when the only thing left for her is legacy. Truly tragic. reply talldatethrow 12 hours agorootparentnext [2 more] [flagged] underdeserver 12 hours agorootparentDon't be so quick to judge. Your mother dying of cancer at such a young age is hard. Everyone deals with it their own way. reply Xenoamorphous 13 hours agoparentprevYes just read that in Wikipedia. Really sad. reply jjallen 13 hours agoparentprevYeah super sad recent events in the family. Reminds me that no matter how much money you have life can still hit us hard. reply thrownawaysz 12 hours agorootparent> no matter how much money you have life can still hit us hard Us? Poor rich people :( reply rishabhjain1198 13 hours agoprevRest in peace. A true SV legend. reply langsoul-com 13 hours agoprevInteresting how it's a threads link, and how it loads infinitely faster than Twitter reply kylehotchkiss 13 hours agoparentRegardless of how people feel about it, Meta/FB is sure putting a lot of resources into it and it seems like it's growing even on people who didn't do a text-first social network in the past. reply Nuzzerino 13 hours agoparentprevThey both seem to load in about the same amount of time for me. Edit: Elon haters downvoting as usual, but my post wasn't a lie. reply kreetx 12 hours agorootparentTwitter loads in a reasonable time for me, yet Facebook loads slow. reply momoschili 12 hours agoprevwhat a tragedy... I can't think of many sites with the impact that YouTube has had, especially during her tenure as the lead. lung cancer as well, I don't think she was a smoker so what a bad stroke of luck. reply snake_doc 12 hours agoprevTragic loss to the world reply sgammon 13 hours agoprevWow. Way too soon :( reply talldatethrow 12 hours agoprevRumble and X posts are gloating that she blocked/delisted anti covid vaccine videos on YouTube, and then gets cancer, something the videos tried to warn people of related to vaccines. I'm not sure what to say about that anymore. reply seydor 12 hours agoparentjust say that there are a lot of idiots in the world reply talldatethrow 12 hours agorootparentOn both sides probably. One side exaggerates statistics to make their point, and the other wishfully accepts unproven statements to feel better. I've taken basically all vaccines ever recommended while growing up and traveling, but to say that the covid vaccine was \"safe and effective\" a year after coming out was a crazy stretch. Why couldn't they just say \"we didn't have time to do long term studies, but we think it's fine and worth the risks\"? But to say it's safe was a lie IMO and lost the vaccine side a lot of credibility. reply carabiner 12 hours agoprevOne thing I've heard is that before age 40, people die of trauma or suicide. After age 40, people, including the healthy, just starting dying of everything. reply orionblastar 13 hours agoprevRIP she will be missed. reply valid4life 13 hours agoprevR.I.P. - too soon. reply Yeri 13 hours agoprevOriginal post on fb: https://www.facebook.com/share/p/qe2ZMcs9Bz4K1SPt/ reply sgammon 13 hours agoprev [7 more] Who is this guy on Threads? Sundar's tweet should be the canonical source: https://x.com/sundarpichai/status/1822132667959386588 reply pogue 13 hours agoparentCasey Newton, former editor @ The Verge & who currently runs platformer.news, a pretty significant tech news site in his own right. I'm not sure why he's going by 'crumbler' these days. https://en.wikipedia.org/wiki/Casey_Newton reply aaomidi 13 hours ago [flagged]parentprev [5 more] Her husband Jesus Christ reply fells 13 hours agorootparentNo? The person on Threads does not appear to be her husband. They're merely posting a screenshot of her husband's Facebook post. reply saagarjha 13 hours agorootparentThe link now points at Facebook fwiw reply aaomidi 1 hour agorootparentHuh I swear when I was looking at this post it was the Facebook thread reply sgammon 12 hours agorootparentprev [–] Not the depicted post, the dude on Threads. The link has been changed now. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Dennis Troper announced the passing of his wife, Susan Wojcicki, after a 2-year battle with non-small cell lung cancer.",
      "Susan Wojcicki, married to Dennis for 26 years and mother of five, was remembered as a brilliant mind and loving mother.",
      "The family is heartbroken but thankful for the time they had with her, with friends and family offering condolences and support."
    ],
    "commentSummary": [
      "Susan Wojcicki, a pivotal figure in Google's history and former CEO of YouTube, has passed away after a two-year battle with cancer.",
      "Sundar Pichai, CEO of Google, posted a heartfelt tribute highlighting her significant contributions to Google and YouTube, and her lasting impact on the world.",
      "Susan's legacy includes transforming YouTube into a major information resource, and her personal connections include her sister Anne, cofounder of 23andMe and former spouse of Google cofounder Sergey Brin."
    ],
    "points": 150,
    "commentCount": 34,
    "retryCount": 0,
    "time": 1723266421
  },
  {
    "id": 41206443,
    "title": "Rivian reduced electrical wiring by 1.6 miles and 44 pounds",
    "originLink": "https://www.popsci.com/technology/rivian-zonal-electrical-architecture/",
    "originBody": "Technology Vehicles Electric Vehicles How Rivian reduced electrical wiring by 1.6 miles and 44 pounds The EV maker reduces software and hardware complexity with zonal electrical architecture. By Kristin Shaw Posted on Aug 6, 2024 12:20 PM EDT 5 minute read Rivian’s R1T was the brand’s first vehicle, built in the company’s Normal, Illinois plant. Image: Rivian Unveiled just a couple of months ago, Rivian’s second-generation R1T pickup and R1S SUV will maintain their distinctive look, with playful headlamps and a sleek exterior shape. Underneath the surface is where the magic is taking place, specifically a wholly new electrical architecture the brand says is less costly and easier to service. Rivian senior vice president of electrical hardware Vidya Rajagopalan says the new electrical system offers more features, as well as an increase in sensing and computing capability. In the process of making the transition from Gen 1 to Gen 2 R1 vehicles, Rivian switched to a zonal architecture. Ultimately, that results in a more sustainable option. The zonal approach reduces the total wiring length by a whopping 1.6 miles and enables each R1 vehicle to shed 44 pounds. Weight is a big deal for EVs, as it has a direct correlation to battery performance. Plus, the company claims a 20 percent savings in material costs and 15 percent reduction in its carbon footprint between Gen 1 and Gen 2. All of it was developed in-house by Rivian’s hardware and software team, an impressive feat. Software complexity is a big deal, and Rivian is finding ways to simplify and streamline its golden goose as a software-defined automaker. Zone versus domain-based architecture In basketball, kids learn one-to-one defense early on. Each player is assigned to a competitor, and they stick to that person like glue for effective coverage. Zone defense requires each player to guard an area (zone) and any offensive player within those parameters. It’s a more elegant option, and one that requires more knowledge of the game. Using a zonal approach, Rivian is showing off its technological prowess. When Rivian engineers started building R1s, they designed a platform based on what’s called domain-based architecture, Rajagopalan explains. With this setup, each category of software is paired with a piece of hardware. Every time you open a door, raise the cabin temperature, slide your seats, turn on the lights, change the mode, and more, you could be connecting to different hardware. Those electrical control units, or ECUs, can multiply like Gremlins after dark. Each R1T and R1S is lighter in its second generation due to a vast reduction in electrical control units and wiring. Image: Rivian “We had 17 ECUs [in Gen 1], each dedicated to a category,” Rajagopalan says. “Other manufacturers can have between 40-150 per vehicle, depending on how they work.” Even though Rivian was using significantly fewer pieces of hardware than their competitors, they wanted to improve the system. More ECUs means more parts overall; consequently, that leads to increased opportunities for failure. For the second generation of vehicles, four categories get their own ECUs: infotainment, autonomy, vehicle access, drive units, and its battery management system. Every other vehicle function is controlled by just three ECUs Rivian refers to as West, East, and South. The infotainment ECU alone is as powerful as a laptop and has the capabilities of a smartphone. Switching from domain-based to zonal architecture allowed the company to reduce its complexity and improve scalability. Image: Rivian However, the ECU that runs the vehicle’s autonomy platform is the most powerful computer in the R1S and R1T. The system includes an array of 11 internally developed cameras and five radars performing over 250 trillion operations per second, which Rivian says is an industry-leading statistic. As such, it connects to artificial intelligence, which helps identify and perceive the world in front of you to detect street signs, lanes, pedestrians, and more. Reducing parts improves scalability and reduces cost Fewer ECUs also results in less wiring, and another upshot of casting off ECUs is reduced weight. “If your ECUs control function by function, you’ll have long wires running all over the car,” Rajagopalan says. “When you switch to a zone mindset, it’s more like a wheel-and-spoke function. Consolidation always wins; having fewer pieces reduces cost and makes manufacturing easier.” It also makes room for scalability, something Rivian will need in order to grow. Rajagopalan was working for Tesla as a senior director of engineering before joining Rivian at the end of 2020. Now she manages 400+ people at Rivian and has witnessed the evolution of the company. She says when Rivian first launched the first generation of its R1T and R1S, buyers loved the adventure-focused brand and the vehicles’ off-road capabilities. Since then, the automaker has proven it can ramp up its manufacturing capacity and make improvements. With a new joint venture with Volkswagen in progress, Rivian will have the opportunity to build a common platform on a much larger scale. To start, VW will invest $1 billion in Rivian and invest another $4 billion over time. In turn, VW will benefit from Rivian’s software-defined vehicle expertise and maverick approach.Meanwhile, we’ll be waiting for the smaller R2 and R3 to debut as Rivian ramps up. Kristin Shaw Contributing writer Kristin Shaw is a freelance writer specializing in anything with wheels, and calls on her technology background to explain complex concepts. Currently living in her sixth state (New Jersey, Indiana, Ohio, Kentucky, Georgia, and now Texas), she does most of her work in coffee shops around Austin. Share Kristin Shaw Contributing writer Kristin Shaw is a freelance writer specializing in anything with wheels, and calls on her technology background to explain complex concepts. Currently living in her sixth state (New Jersey, Indiana, Ohio, Kentucky, Georgia, and now Texas), she does most of her work in coffee shops around Austin. Latest in Electric Vehicles Technology Ram’s vision for a three-row pickup truck could be closer to reality than you think Ram’s vision for a three-row pickup truck could be closer to reality than you think By Kristin Shaw Technology The 2024 Hyundai Ioniq 5 N is the EV that driving enthusiasts have been waiting for The 2024 Hyundai Ioniq 5 N is the EV that driving enthusiasts have been waiting for By Bradley Iger",
    "commentLink": "https://news.ycombinator.com/item?id=41206443",
    "commentBody": "Rivian reduced electrical wiring by 1.6 miles and 44 pounds (popsci.com)148 points by addaon 18 hours agohidepastfavorite81 comments gorgoiler 14 hours agoThe before/after ECU layout diagram is very instructional. I like to imagine some kind of engineering “meet cute” whereby, one random day, the headlights engineer and the parking radar engineer happen to be working on the front of the car together. Their eyes meet: “hey, I’m John — I didn’t know you had an ECU here!”, “hi, I’m Claire — wow, you have an ECU right up front too? It’s, like, right next to mine and we never knew!” “I know, crazy right?! Hey this is going to sound really forward and I don’t normally do this but I’m only running at 70% compute capacity. I don’t suppose you need any real-time budget this evening?” “So funny you should ask, I was just about to run a whole bunch of heavy new wiring to…” And in a story as old as time they get ECU married and raise their control loops in the same front-of-vehicle ECU together instead of living their separate, lonely, ECU-right-next-to-each-other-and-they-didn’t-know-it lives. reply kevin_thibedeau 4 hours agoparentFord did this with the cost reduced version of SYNC 3, merging two modules to form SYNC 2.5. The result is an unstable heap of trash. reply dangus 1 minute agorootparentWell, it is Ford. You buy a Ford you should expect it to be trash. reply plg94 1 hour agoparentprevwow, you made hackernews turn into tumblr. Well done, great explanation. reply jdiez17 6 hours agoparentprevI ... am a bit speechless ... I didn't know this was something I could be into so much, and yet here we are. reply brundolf 3 hours agorootparentThat's what they said reply yc-kraln 7 hours agoprevThe electrical wiring in cars is Conway's law manifest in copper. For those unfamiliar with Conway's law, I am arguing that how the car companies have organized themselves--and their budgets--ends up being directly reflected in the number of ECUs as well as how they're connected with each other. I imagine that by measuring the amount of excess copper, you´d have a pretty good measure for the overhead involved in the project management from the manufacturers' side. (I previously worked for Daimler) reply mensetmanusman 7 hours agoparentWould be funny to have a ‘mm Cu / FTE’ scaling law. reply throwaway48476 4 hours agorootparentComplexity is a function of the number and depth of suppliers. reply westurner 3 hours agorootparentprevThe ohm*meter^3 is the unit of electrical resistance. Electrical resistivity and conductivity: https://en.wikipedia.org/wiki/Electrical_resistivity_and_con... Is there a name for Wh/m or W/m (of Cu or C) of loss? Just % signal loss? \"Copper Mining and Vehicle Electrification\" (2024) https://www.ief.org/focus/ief-reports/copper-mining-and-vehi... .. https://news.ycombinator.com/item?id=40542826 There's already conductive graphene 3d printing filament (and far less conductive graphene). Looks like 0.8ohm*cm may be the least resistive graphene filament available: https://www.google.com/search?q=graphene+3d+printer+filament... Are there yet CNT or TWCNT Twisted Carbon Nanotube substitutes for copper wiring? reply thelastgallon 6 hours agoprevRivian can switch to 48V for more gains. https://news.ycombinator.com/item?id=38576612: The move to 48V means much less power is lost (power loss = (IxI)xR ), cables can be much smaller, cables and terminals can be much lighter and much less copper can be used used. Discussion: Tesla shares 48V architecture with other automakers: https://news.ycombinator.com/item?id=38557203 reply jondwillis 4 hours agoparentThose are rookie numbers. Let’s bump it up to 96V while we are at it. reply throwaway48476 4 hours agorootparent50V is the generally accepted safe cutoff. There are separate electrical certifications for 'low voltage'\"if you open the passenger door, then open the tailgate, then close the passenger door and press the lock button, the driver's door will lock but the passenger won't until you first unlock then shut everything\" I have a Jeep where the dome light logic has a problem like that. If you open a door, the dome light comes on. When all doors are closed, but the engine is not running, the dome light dims out after a delay. If the engine is running or is started in the all doors closes, dome light on situation, the dome light goes out. If you open the tailgate, the dome light comes on as well. That's all normal. But if I open a side door, then close it, and the light times out and dims, then, for some period of time thereafter, opening the tailgate will not turn on the light. I can just see some horrid mess of IF statements written in C behind this. reply sdwr 5 hours agorootparentState management is the only difficult problem in computer science Or something like that reply euroderf 4 hours agorootparentprevHave they never heard of fuzzing. reply Lvl999Noob 6 hours agoparentprev> With zone-based, it could be the entire \"west\" zone that stops, which means you can't unlock the driver's door, open the windows, adjust the seat, and maybe even the ventilation fans don't work From my reading, I thought the important parts were on their own dedicated ECUs (7 ECUs, 3 zones). Battery management, driving related stuff, infotainment, door mechanisms, etc have their own ECUs. The three zones are for smaller things that are probably important but not urgently important. reply daghamm 11 hours agoparentprevThere is a short answer to all this: Distributed systems are hard, more so in a real-time environment. If you can reduce the number of components or the need for them to communicate they will almost always become more robust and also easier to code. Rivian added some network redundancy and central monitoring to make this design safe, but otherwise the core design principle was basically KISS. reply morning-coffee 2 hours agorootparentFrom the article: > The system includes an array of 11 internally developed cameras and five radars performing over 250 trillion operations per second, which Rivian says is an industry-leading statistic I generally like what they are doing with their overall architectural simplifications, but gee-zus; the feeling of complexity I get from that one statement leaves me with the feeling of \"it's just a car man... it takes us from point A to point B... is all that really necessary?\" reply mynameisvlad 1 hour agorootparentThe point is that it might in the future take you from point A to B autonomously. reply Moto7451 6 hours agoparentprevSome cars work this way logically already. If you scan my Audi with a compatible tool it will read various functional modules. If one dies than that modules’ systems go down but other nearby functions work. Child locking is a separate unit from door locking and as a result in my car my driver side rear door will lock in such a way that only the inside manual latch will open the door. The dealer can’t figure out the issue four years in. reply moring 8 hours agoparentprevWhen I read this, my first thought was: Why do these ECUs have any deep logic at all? I would have expected all logic to be centralized at one point (or in a few points, but with each domain localized to one of them), and everything at the edge be dumb(1) port extenders. That's a single point of failure, of course, but as far as I understand the zonal approach has those too -- multiple SPOFs, actually. At least when it's a single SPOF, that problem can be better mitigated. (1) \"dumb\" meaning no decision-making logic. It could still mean a lot of decision-less logic, from button debouncing to input signal filtering/processing and outputting compressed audio streams. reply guai888 6 hours agoparentprevStandard approach is following ISO 26262 development to deal with risk resulting from failure mode. reply edmundsauto 14 hours agoparentprevSome door locks will trigger the servo every time you hit the heron (older-ish cars) and some have a sensor. Not clear to me if it’s a remote sensor or some sort of smarts in the local mechanism. Given some of the chip shortages of recent year, I’m curious how the teams responsible for those trade offs made the balance. reply Timshel 12 hours agoparentprevThey though of the failure mode opening doors should be part of the \"vehicle access\" which get its own ecu. reply xbmcuser 7 hours agoprevI recalled I read something similar before so I searched for it. It was Tesla doing something like this in 2019 https://electrek.co/2019/07/22/tesla-revolutionary-wiring-ar... \"In order to facilitate the automation of manipulating cables, Tesla has been reducing the length of wiring harnesses in its vehicles. Musk said that Model S has about 3 kilometers of wiring harnesses and Tesla brought it down to 1.5 kilometers in length for the Model 3. But that’s just the beginning. Tesla is working on a whole new wiring architecture for future vehicle platforms and they aim to bring it down to just 100 meters starting with the Model Y.\" reply grecy 6 hours agoparentTesla have taken it to a whole new level on cyber truck. It is assumed this will continue in their next gen vehicles reply theluketaylor 6 hours agorootparentThe legacy car makers have flirted with 48V components for decades but haven't been willing to do the hard work to realize all the benefits it brings. The germans in particular are stuck in limbo. For their PHEV and BEV cars they are shipping 12V for all traditional functions, 48V for advanced functions like active suspension and anti-roll bars, and high voltage systems for the traction motor. Complete mess. It's frustrating to be a Tesla owner. For every great engineering choice they make like going all in on 48V they make a user hostile choice like removing stalks and selling \"full self driving\" that is downright dangerous. reply postalrat 4 hours agorootparentAdding one additional voltage doesn't turn something from elegant to a complete mess. I don't know why you mentioned the traction motor voltage as part of the mess. Do you want hundreds of volts DC running all over the car? reply katzinsky 3 hours agorootparentprevIn my homebrew BEV I've started just using AC for most smaller things. It's easier than finding 48v components, the connectors are nicer than 12v (I've really come to hate cigarette lighter plugs) the high voltage means the conductors can be small and the zero crossing means the switches can be much cheaper too. And being able to find replacement parts at the dollar store no matter where you are is really great. reply throwaway48476 4 hours agorootparentprevThe problem is for the whole industry to go 48V costs money and whoever pays will also benefit the competition because everyone has the same suppliers. There needs to be some kind of industry regulation that says by so and so date everything had to be 48V. reply jvanderbot 5 hours agorootparentprevThe single most frustrating thing Tesla did re: Power was not allowing me to plug an appliance in. We lose power somewhat regularly where I live due to storms, and the tesla has 6-10 days of my household power budget sitting in its banks. Just let me plug in a deep freezer and coffee maker, please. INB4 the 12V terminals: They are hard to access, have limited amps, and are a separate crappy battery. reply trainsarebetter 3 hours agorootparentFor sure, but the economics don’t work out for the earlier Bev battery chemistry’s. The additional cycle where from v2x don’t justify it, getting a power wall just makes more sense in the long run. But I still agree the option should be there for emergencies reply jvanderbot 2 hours agorootparentThe thing is, Tesla is the only large battery I can put in my house, according to local regulations (I can get solar+battery, but the solar provider terms in my area are garbage, and I can only sell power to local company and get credits for later use. I can't actually store it). This is a disruption opportunity wasted. reply samatman 3 hours agorootparentprev> selling \"full self driving\" that is downright dangerous. Is there evidence of this, at this point? I haven't looked into it in several years, but back then, Teslas were getting in fewer accidents per driver mile than average. I would think given that there's a faction of the public, and especially of the activist public, who are hostile to Tesla/Musk, that if FSD is in fact more dangerous (which would mean more accidents per driver mile), there would be a good URL you could provide us which makes that case using the available statistics on the subject. Because it's an entirely empirical question. Anyone can argue from first principles in either direction, but one of two things are the reality: either FSD driver miles are less prone to accident than average, or they're more so. I suppose it could be precisely at 50%, as well. reply theluketaylor 55 minutes agorootparentExtensive analysis of Tesla and NHTSA crash reporting (some by NHTSA themselves) shows that autopilot and fsd do not have significantly better safety outcomes than manual drivers or drivers aided by other non-tesla assistance systems. This NHTSA report is pretty damning about Tesla's cavalier attitude towards the design of safe systems. https://static.nhtsa.gov/odi/inv/2022/INCR-EA22002-14496.pdf https://www.forbes.com/sites/bradtempleton/2023/04/26/tesla-... https://www.forbes.com/sites/bradtempleton/2020/10/28/new-te... https://www.wired.com/story/tesla-autopilot-risky-deaths-cra... reply toast0 1 hour agorootparentprevTo do proper statistical analysis, you'd need to compare miles driven with FSD to miles driven by humans in similar conditions. That's not the easiest thing to do. Tesla had occasionaly released statistics with their earlier driver assistance technology, but without enough detail to form informative comparisons. Based on past experience, I don't expect Tesla to provide meaningful statistical data or to allow outside access to their raw data (which fwiw, seems like a huge privacy risk to collect), so I don't think we'll have an empirical result unless there's discovery for a lawsuit. reply mrgoldenbrown 2 hours agorootparentprevIt may be an empirical question, but as long as Tesla insists on keeping the raw data secret, it's reasonable to suspect their conclusions/claims https://www.wsj.com/business/autos/tesla-autopilot-crash-inv... reply hulitu 2 hours agorootparentprev> The legacy car makers have flirted with 48V components for decades but haven't been willing to do the hard work to realize all the benefits it brings Can you name some benefits ? ICs working at 48 V are expensive and hard to find. reply AlotOfReading 2 hours agorootparentThat's why DC/DC converters exist. Only the things that can take 48v (and associated voltage spikes) get exposed to it. reply brianwawok 2 hours agorootparentprevMassively smaller wires and higher powered accessories reply OptionOfT 13 hours agoprevI think having multiple ECUs over time is a cost savings mechanism. You have a module that you can use in all your models because it works. If Rivian wants to add a new feature that doesn't 'fit' on the AIO ecu, then what? Replace it and re-certify ALL of its functions? A good example is the ABS controller which is usually just a Bosch COTS ECU. You wouldn't even want to implement that for yourself. reply schobi 8 hours agoprevThe diagrams for the new west south and east zones still show a lot of wires going all across the vehicle. This step might be a good first one to reduce the number of ECUs by combining them, but there is still the same cross-car wiring. You still seem to have a single ECU per function, but merged into a few dedicated boxes for example. Next step: Each wire only goes to the nearest box. I'm curious how the Tesla unboxed architecture will eventually play out. I understand that eventually, the ECUs will be split up, so you have some aspect of each ECU in each corner of the vehicle. Part of the \"lights\" function is in front-left, part of it in the back. Wires only go to the nearest box. A powerful vision, with the potential to further reduce wiring. Complex until you get a distributed brake ECU. reply daghamm 11 hours agoprev\"four categories get their own ECUs: infotainment, autonomy, vehicle access, drive units, and its battery management system.\" Am I reading this wrong, or are these actually five categories? reply masklinn 6 hours agoparentGiven the wording of \"drive units, and its battery management system\" I'd think the BMS is linked to the drive units and under the same ECU. I'd assume the drive units and BMS are tightly integrated, as that's basically the entire high-voltage system and you have to manage the two-ways energy flow between the two (propulsion and braking / regen). reply trainsarebetter 3 hours agorootparentNot really, the FOC software that runs on the inverters is compute heavy and safety critical. It gets its own dedicated controller (they are actually running to cpus in parallel in case one fails) and same with the bms. They talk over can currently in teslas. bms states it’s max charge and discharge current, and everything else listens reply indoorcomic 14 hours agoprevI love this. I hope this more manufactures go this route. I've always felt that having ~100 ECUs in a car is complete overkill. reply AlotOfReading 13 hours agoparentI've been a (somewhat successful) advocate of similar approaches at the automakers I've worked for, but it's not as simple as the article makes it sound. Individual components in each \"zone\" can have different reliability requirements, for example. They also might be produced by different suppliers, or only be present on certain models / trims. Rivian is able to do this because they're taking advantage of modern heterogenous processors and they haven't made the mistake of outsourcing almost all of their software capabilities to tier 1,2,3 suppliers. Legacy OEMs find it much more difficult to adopt, especially once the institutional inertia takes over. reply Jtsummers 14 hours agoparentprevSee gregmac's comment, it changes the failure modes and makes what could be isolated subsystem failures larger regional failures. However, components are also becoming much more reliable so this is an engineering tradeoff. Cases can be made in both directions. EDIT: That's not the only tradeoff, but it is a key one. reply metadat 12 hours agorootparenthttps://news.ycombinator.com/item?id=41207335 In the future, please include the actual link. It is 10x more useful. reply Ekaros 11 hours agoparentprevReplacing word ECU with micro-controller makes number seem less insane. Okay, PCs are having less and less components. But one might ask why do so many components have any logic at all? We got extremely insanely powerful central CPUs with loads of memory and storage space. So why not just do absolutely everything there? Remove any logic and computing from screens, keyboards, mice, SSDs, HDDs, off load everything from network chips and sounds chips. Just move all of it to CPU? reply moring 7 hours agorootparentI think you'd want at least some \"dumb\" logic moved to the periphery, otherwise everything has to be conected directly to the CPU and you would still end up with tons of wiring. Also, some functions done in the periphery are ideal candidates for parallelization, such as the keyboard scanning the key matrix for pressed keys. reply maxerickson 4 hours agorootparentSeems like modularization is going to be beneficial pretty much anytime you can define an interface you think is going to be somewhat stable. I wonder to what extent Rivian has removed intermediate controllers here, where they used them in the first place to get things done on a tighter timeline. reply kevin_thibedeau 4 hours agorootparentprevThe value proposition of CAN bus is that peripherals can be scattered around connected by two data lines and a power wire. Dumb peripherals need more wiring. reply moring 3 hours agorootparentThey are deviating from that already, aren't they? If they use one ECU per zone, then the peripherals in that zone can't be connected via CAN bus, otherwise they would need their own controller. reply quanto 6 hours agoprevquick math check > 1.6 miles and 44 pounds pure copper density at 9000 kg/m3, wire diameter assumed at 1mm, length at 3000 m (1.8 mi, approx) gives 21 kg, approximately 46 lb. math checks out. > the company claims a 20 percent savings in material costs and 15 percent reduction in its carbon footprint between Gen 1 and Gen 2. surely this is not just due to the reduction of copper. copper is around 10 USD/kg at bulk. now let's see if we can address the copper length number. can 1.6 mi ( EMI is a real issue To the point they are wanting to eliminate AM radio because they've gotten to the point that the uncontrollable EMI makes AM \"unlistenable\". So move the goal posts, and make AM radio out-of-fashion and get rid of it rather than solving the EMI issues. reply katzinsky 4 hours agorootparent1) I don't think you'll ever be able to make an electric vehicle electrically quiet enough to make AM work nicely and if you somehow did between the shielding and all the balancing currents there's no way it would be efficient. I like AM radio but these two things are probably never going to be compatible. 2) WiFi really isn't as reliable as a cable. There are all kinds of things internal and external that could cause an outage. Why bother with that when you can just run maybe a dollar of copper to the ECU? reply janice1999 7 hours agoparentprevIt's a good question. Wireless is already replacing wiring inside the battery pack performing some of the most sensitive data transmission. See here for details: https://www.gm-trucks.com/explained-general-motors-wireless-... reply silisili 14 hours agoparentprevIgnoring wifi as a poor use case here(you'd likely use something with much less interference and better latency), RF will still usually have more latency than a wire. It's more prone to interference from other random devices and even other cars. Canbus is typically shielded, which you obviously can't do with something relying on radio. Then you have physical interference...imagine all your warning lights come on, wipers come on, and radio cuts off because your wife put her Stanley in just the wrong spot. reply adrian_b 14 hours agoparentprevSo that anyone could crash your car with a jammer? reply daghamm 11 hours agoparentprevOP is heavily downvoted, but yes some ECU are moving to wireless communication although not WiFi. It started with places where you simply can't have wires, for example tire pressure monitoring. But is now spreading to other simple ECUs. And yes, it can be jammed so obviously it's not for brakes and steering and things like that. reply Gibbon1 13 hours agoparentprev [–] People don't like your comment but I have a side project that requires controlling 36 lamps in groups of 3. I rolled it over and I'm just going to slap a cheap radio on a PCB's and just daisy chain the power. reply gruturo 11 hours agorootparentMaybe you already completed your project, maybe you already knew about Charlieplexing (https://en.wikipedia.org/wiki/Charlieplexing), maybe it doesn't apply to your case as your controller didn't support tristate output, but, just in case you didn't know about it: It's a technique for controlling (or reading) large numbers of LEDs, switches, etc, with surprisingly little wiring. Instead of the usual X/Y of multiplexed I/O, the wiring is diagonal. To control 12 outputs (36 in groups of 3) you'd need just 4 pins (if your lamps are not LEDs, though, you probably need to put some diodes in there) reply kkfx 11 hours agorootparentprev [–] I've built my \"smart home\" explicitly without wifi [1] to shield against any kind of \"local exterior attack\" and mere communication issues due to natural phenomenon. Even for light I decide for ShellyPro 4PM to avoid wireless... Surely without cables it's far easier, but this easiness have a price. [1] with the exception of the car charger since I wasn't able to find a damn cabled one (it's 230Vac, not CCS eh!) reply viraptor 6 hours agorootparentThere's often the \"wifi or wired\" discussion around here, so I'll just add that those are not the only choices. Zwave for smart devices for example is a local wireless protocol which is completely separate from WiFi and doesn't have the same addressing / access issues. reply stavros 3 hours agorootparentI built everything in my house with Zigbee and could not be happier. The \"everything is just a message queue\" approach that Zigbee takes is fantastic for the home, and the fact that I don't have to worry about a whole complicated protocol that can do anything is great. reply nurettin 9 hours agorootparentprev [–] > \"local exterior attack\" I appreciate the geek, but is this useful in practice? Does it happen to anyone? reply kkfx 8 hours agorootparent [–] I do not know any statistic, but for instance https://www.cnet.com/home/security/can-burglars-jam-your-wir... it's a well known phenomenon, as it's well known enough you can buy a ready-made multi-frequency jammer for very little price from China. Aside another aspect is how to make the home impossible to live in case someone illegally occupy it (here, France, but essentially all south Europe is a relatively new but spread thing) while you are on vacation to be quicker than local authorities. Another one is avoiding connecting too much black boxes to their OEM homes. Another final aspect is mere reliability, as a small anecdote: a neighbor due to some unknown issue have had roller shutters locked down because they have ONLY a wireless remote with a kind of ESP32 inside, all proprietary, no emergency manual opening, no access to the motor to power it directly or detach the break manually on the shutters. My home while \"a bit smart\" have a far little attack surface in that regard. For instance just to have central/remote lights control I've chosen a set of ShellyPro 4PM (the least expensive option of that kind I was able to find) witch operate remotely (LAN only, via HA or directly logging on the device, extended via wireguard) but i can also operate via classic mechanical switches and internally the Shelly are \"dumb classic switch\" + extras so if their fw crash from the physical buttons (not the one on the devices, but their normally open contacts) they still operate. For the car charger I'm obliged to go wifi (I find exactly no one domestic charging station with wired connections for control) but it's a dedicated WLAN (a small GL.iNet \"stamp\" size on the back of the charger, wired to a dedicated port of my homeserver on a completely separated LAN without internet access and the charger itself is MQTT/ModBUS-bridged to its local, internet-less controller/server for p.v. integration. I can't do nothing for my car and well... Sometimes it's \"app-service\" to remote control A/C etc get connected to someone else car in another country and yes, I can monitor it and act on it when this happen (few times per years so far). No special hacking needed. No response from the vendor (MG/SAIC)... And for cars some demoed serious remote vulnerabilities able to physically make a car crash while running. All those might be very rare events, but their seriousness it's relevant enough for me to avoid them as much as possible. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Rivian has introduced its second-generation R1T pickup and R1S SUV, featuring a new zonal electrical architecture that reduces wiring by 1.6 miles and weight by 44 pounds.",
      "The new system, developed in-house, simplifies software and hardware, cuts material costs by 20%, and reduces the carbon footprint by 15%.",
      "The switch from domain-based to zonal architecture consolidates functions into fewer, more powerful ECUs, enhancing scalability and reducing complexity, positioning Rivian for growth, including a joint venture with Volkswagen."
    ],
    "commentSummary": [
      "Rivian has reduced electrical wiring in its vehicles by 1.6 miles and 44 pounds through the consolidation of Electronic Control Units (ECUs), simplifying the vehicle's architecture.",
      "The discussion covers the benefits, such as reduced complexity, and challenges, including potential failure modes and impacts on vehicle reliability.",
      "Comparisons are made to other automakers like Tesla, highlighting broader implications for innovation and the trade-offs involved in adopting new technologies."
    ],
    "points": 148,
    "commentCount": 81,
    "retryCount": 0,
    "time": 1723248725
  },
  {
    "id": 41209181,
    "title": "Deep Live Cam: Real-time face swapping and one-click video deepfake tool",
    "originLink": "https://deeplive.cam",
    "originBody": "✨ Experience Deep Live Cam Deep Live Cam The Next Leap in Real-Time Face Swapping and Video Deepfake Technology Deep Live Cam harnesses cutting-edge AI to push the boundaries of real-time face swapping and video deepfakes. Achieve high-quality face replacement with just a single image. editions Deep Live Cam Supports Multiple Execution Platforms CPU NVIDIA CUDA Apple Silicon Flux.1 Schnell The fastest image generation model in the Flux.1 family. It produces images of quality comparable to Flux Dev and Flux Pro. Ideal for users who prioritize speed. Flux.1 Dev Generates high-quality images that closely align with your input prompts, offering good consistency. Flux.1 Pro Deep Live Cam: Bringing Your Ideas to Life Deep Live Cam is a state-of-the-art AI tool that delivers astonishingly accurate real-time face swapping and video deepfakes. Here's what sets it apart: Get Started Real-Time Face Swapping Swap faces in real-time using a single image, with instant preview capabilities. One-Click Video Deepfakes Generate high-quality deepfake videos quickly and easily with simple operations. Multi-Platform Support Run on various platforms including CPU, NVIDIA CUDA, and Apple Silicon, adapting to different hardware setups. Ethical Use Safeguards Built-in checks prevent processing of inappropriate content, ensuring legal and ethical use. Optimized Performance Leverages optimized algorithms for significantly faster processing, especially on CUDA-enabled NVIDIA GPUs. Open-Source Community Benefit from an active community providing ongoing support and improvements, keeping the tool at the cutting edge. How Deep Live Cam Works Deep Live Cam employs advanced AI algorithms to achieve real-time face swapping and video deepfakes. 1 Select Source Image Upload a single image containing the desired face as your source. 2 Choose Target Select the target image or video for face swapping. 3 Begin Processing Click 'Start', and Deep Live Cam will automatically perform the face replacement. What Users Are Saying About Deep Live Cam on X Explore real experiences and creations shared by developers and users on X. See how Deep Live Cam is inspiring creativity and solving practical problems across various fields, from stunning face-swap effects to innovative applications. MatthewBerman @MatthewBerman Link to tweet #1 trending github repo right now looks INSANE Single image to live stream deep fake. Look at that quality!! It's called Deep-Live-Cam (link in replies) orange.ai @oran_ge Link to tweet Github trending 第一名 Deep Live Cam 只需要一张照片即可进行换脸直播 以后我们在线会议、直播带货都可以用任何人的脸了 Sam Rad 🔮 @SamRadOfficial Link to tweet This is Deep-Live-Cam. The software enables **anyone** to convert a single image into a live stream deepfake. One click. One image. And it is currently the #1 trending repo on GitHub. Over the past few years, I’ve been educating companies, agencies, and associations on… Shaun.AGI @agishaun Link to tweet Deep-Live-Cam. Realtime 0 latency deepfake. You only need a picture. 🤯💡I wasn’t expect this to be this good and this quick. With voice clone and this, I don’t need to attend any zoom meetings! github.com/hacksider/Deep… Jen Zhu @jenzhuscott Link to tweet Live cam deep fake. No latency. I did not think this would happen this fast. Create code words with your team now to protect your business from scams. This election cycle is going to be wildly troubling. github.com/hacksider/Deep… しろくま【ロボットと生成AIのエン... @neka_nat Link to tweet ウェブカメラでリアルタイムなFace swapができるGUIツール 光の当たり方とかもリアルに再現できてるのすごいな。 github.com/hacksider/Deep… みるぼん@スモビジ @milbon_ Link to tweet リアルタイムでディープフェイクができる『Deep-Live-Cam』が公開。画像1枚読み込ませれば、リアルタイムで顔を変換できる。遂に中身おっさんでも『ライブ配信AI美女』として稼げる時代が到来。詳細はリプ欄👇 レモン爺 @granpa_lemon Link to tweet またまたリアルタイムdeepfakeのアプリケーョンが出てたぞい。 シンプルなUIで使いやすそうじゃな。 先日WEB会議にトランプの顔で参加したら、かなり掴みが良かったぞい！ cuda,cpu,apple silicon等、色々なプラットフォームに対応とのこと。 github.com/hacksider/Deep… ropeもおすすめ！ #deepfake Tory @Tory90445456 Link to tweet 只需一张图片即可实现视频实时换脸！✨ 🖼 Deep-Live-Cam让你轻松完成： 🔄 实时人脸替换：将视频中的人脸替换为图片中的人脸 ⚡ 选择一张图片和一个视频，自动生成换脸视频 💻 支持 CPU、GPU(CUDA、CoreML、DirectML、OpenVINO) 不仅换脸，还支持人脸增强、多脸处理等功能！ #AI #换脸 Frequently Asked Questions About Deep Live Cam Get answers to common questions about Deep Live Cam What is Deep Live Cam? Deep Live Cam is an open-source tool for real-time face swapping and one-click video deepfakes. It can replace faces in videos or images using a single photo, ideal for video production, animation, and various creative projects. What are the main features of Deep Live Cam? Deep Live Cam's key features include: 1) Real-time face swapping; 2) One-click video deepfakes; 3) Multi-platform support; 4) Ethical use safeguards. How do I use Deep Live Cam? To use Deep Live Cam: 1) Set up the required environment; 2) Clone the GitHub repository; 3) Download necessary models; 4) Install dependencies; 5) Run the program; 6) Select source image and target; 7) Start the face-swapping process. Which platforms does Deep Live Cam support? Deep Live Cam supports various execution platforms, including CPU, NVIDIA CUDA, Apple Silicon (CoreML), DirectML (Windows), and OpenVINO (Intel). Users can choose the optimal platform based on their hardware configuration. How does Deep Live Cam prevent misuse? Deep Live Cam incorporates built-in checks to prevent processing of inappropriate content (e.g., nudity, violence, sensitive material). The developers are committed to evolving the project within legal and ethical frameworks, implementing measures like watermarking outputs when necessary to prevent abuse. Is Deep Live Cam free to use? Yes, Deep Live Cam is an open-source project and completely free to use. You can access the source code on GitHub and use it freely. Can I use Deep Live Cam for commercial purposes? While Deep Live Cam is open-source, for commercial use, you should carefully review the project's license terms. Additionally, using deepfake technology may involve legal and ethical considerations. We recommend consulting with legal professionals before any commercial application. What are the hardware requirements for Deep Live Cam? Deep Live Cam's performance varies with hardware configuration. Basic functionality runs on standard CPUs, but for optimal performance and results, we recommend using CUDA-enabled NVIDIA GPUs or devices with Apple Silicon chips. Does Deep Live Cam support real-time video stream processing? Yes, Deep Live Cam supports real-time video stream processing. You can use a webcam for real-time face swapping, with the program providing live preview functionality. How can I improve the face-swapping results in Deep Live Cam? To enhance face-swapping results, try: 1) Using high-quality, clear source images; 2) Choosing source and target images with similar angles and lighting; 3) Adjusting program parameters; 4) Running the program on more powerful hardware. If you have any other questions, don't hesitate to reach out to us.support@deeplive.cam Alice @alice Deep Live Cam makes real-time face swapping a breeze. The realism is absolutely mind-blowing! 张伟 @zhangwei Deep Live Cam 的效率令人难以置信。我能在瞬间生成高质量的换脸视频。对任何创意工作者来说都是必备工具！ Charlie @charlie I love how user-friendly Deep Live Cam is. It's perfect for both beginners and seasoned content creators. Alice @alice Deep Live Cam makes real-time face swapping a breeze. The realism is absolutely mind-blowing! 张伟 @zhangwei Deep Live Cam 的效率令人难以置信。我能在瞬间生成高质量的换脸视频。对任何创意工作者来说都是必备工具！ Charlie @charlie I love how user-friendly Deep Live Cam is. It's perfect for both beginners and seasoned content creators. Alice @alice Deep Live Cam makes real-time face swapping a breeze. The realism is absolutely mind-blowing! 张伟 @zhangwei Deep Live Cam 的效率令人难以置信。我能在瞬间生成高质量的换脸视频。对任何创意工作者来说都是必备工具！ Charlie @charlie I love how user-friendly Deep Live Cam is. It's perfect for both beginners and seasoned content creators. 李梅 @limei Deep Live Cam 的多平台支持真是太棒了。无论是在我的 NVIDIA GPU 还是 Apple Silicon Mac 上，都能完美运行。 Ethan @ethan The versatility of Deep Live Cam is impressive. I use it for everything from digital art to marketing videos. 王芳 @wangfang Deep Live Cam 的一键视频深伪功能太强大了。这个工具极大地提高了我的创意输出效率，而且完全免费！ 李梅 @limei Deep Live Cam 的多平台支持真是太棒了。无论是在我的 NVIDIA GPU 还是 Apple Silicon Mac 上，都能完美运行。 Ethan @ethan The versatility of Deep Live Cam is impressive. I use it for everything from digital art to marketing videos. 王芳 @wangfang Deep Live Cam 的一键视频深伪功能太强大了。这个工具极大地提高了我的创意输出效率，而且完全免费！ 李梅 @limei Deep Live Cam 的多平台支持真是太棒了。无论是在我的 NVIDIA GPU 还是 Apple Silicon Mac 上，都能完美运行。 Ethan @ethan The versatility of Deep Live Cam is impressive. I use it for everything from digital art to marketing videos. 王芳 @wangfang Deep Live Cam 的一键视频深伪功能太强大了。这个工具极大地提高了我的创意输出效率，而且完全免费！ Alice @alice Deep Live Cam makes real-time face swapping a breeze. The realism is absolutely mind-blowing! 张伟 @zhangwei Deep Live Cam 的效率令人难以置信。我能在瞬间生成高质量的换脸视频。对任何创意工作者来说都是必备工具！ Charlie @charlie I love how user-friendly Deep Live Cam is. It's perfect for both beginners and seasoned content creators. Alice @alice Deep Live Cam makes real-time face swapping a breeze. The realism is absolutely mind-blowing! 张伟 @zhangwei Deep Live Cam 的效率令人难以置信。我能在瞬间生成高质量的换脸视频。对任何创意工作者来说都是必备工具！ Charlie @charlie I love how user-friendly Deep Live Cam is. It's perfect for both beginners and seasoned content creators. Alice @alice Deep Live Cam makes real-time face swapping a breeze. The realism is absolutely mind-blowing! 张伟 @zhangwei Deep Live Cam 的效率令人难以置信。我能在瞬间生成高质量的换脸视频。对任何创意工作者来说都是必备工具！ Charlie @charlie I love how user-friendly Deep Live Cam is. It's perfect for both beginners and seasoned content creators. 李梅 @limei Deep Live Cam 的多平台支持真是太棒了。无论是在我的 NVIDIA GPU 还是 Apple Silicon Mac 上，都能完美运行。 Ethan @ethan The versatility of Deep Live Cam is impressive. I use it for everything from digital art to marketing videos. 王芳 @wangfang Deep Live Cam 的一键视频深伪功能太强大了。这个工具极大地提高了我的创意输出效率，而且完全免费！ 李梅 @limei Deep Live Cam 的多平台支持真是太棒了。无论是在我的 NVIDIA GPU 还是 Apple Silicon Mac 上，都能完美运行。 Ethan @ethan The versatility of Deep Live Cam is impressive. I use it for everything from digital art to marketing videos. 王芳 @wangfang Deep Live Cam 的一键视频深伪功能太强大了。这个工具极大地提高了我的创意输出效率，而且完全免费！ 李梅 @limei Deep Live Cam 的多平台支持真是太棒了。无论是在我的 NVIDIA GPU 还是 Apple Silicon Mac 上，都能完美运行。 Ethan @ethan The versatility of Deep Live Cam is impressive. I use it for everything from digital art to marketing videos. 王芳 @wangfang Deep Live Cam 的一键视频深伪功能太强大了。这个工具极大地提高了我的创意输出效率，而且完全免费！ Alice @alice Deep Live Cam makes real-time face swapping a breeze. The realism is absolutely mind-blowing! 张伟 @zhangwei Deep Live Cam 的效率令人难以置信。我能在瞬间生成高质量的换脸视频。对任何创意工作者来说都是必备工具！ Charlie @charlie I love how user-friendly Deep Live Cam is. It's perfect for both beginners and seasoned content creators. Alice @alice Deep Live Cam makes real-time face swapping a breeze. The realism is absolutely mind-blowing! 张伟 @zhangwei Deep Live Cam 的效率令人难以置信。我能在瞬间生成高质量的换脸视频。对任何创意工作者来说都是必备工具！ Charlie @charlie I love how user-friendly Deep Live Cam is. It's perfect for both beginners and seasoned content creators. Alice @alice Deep Live Cam makes real-time face swapping a breeze. The realism is absolutely mind-blowing! 张伟 @zhangwei Deep Live Cam 的效率令人难以置信。我能在瞬间生成高质量的换脸视频。对任何创意工作者来说都是必备工具！ Charlie @charlie I love how user-friendly Deep Live Cam is. It's perfect for both beginners and seasoned content creators. 李梅 @limei Deep Live Cam 的多平台支持真是太棒了。无论是在我的 NVIDIA GPU 还是 Apple Silicon Mac 上，都能完美运行。 Ethan @ethan The versatility of Deep Live Cam is impressive. I use it for everything from digital art to marketing videos. 王芳 @wangfang Deep Live Cam 的一键视频深伪功能太强大了。这个工具极大地提高了我的创意输出效率，而且完全免费！ 李梅 @limei Deep Live Cam 的多平台支持真是太棒了。无论是在我的 NVIDIA GPU 还是 Apple Silicon Mac 上，都能完美运行。 Ethan @ethan The versatility of Deep Live Cam is impressive. I use it for everything from digital art to marketing videos. 王芳 @wangfang Deep Live Cam 的一键视频深伪功能太强大了。这个工具极大地提高了我的创意输出效率，而且完全免费！ 李梅 @limei Deep Live Cam 的多平台支持真是太棒了。无论是在我的 NVIDIA GPU 还是 Apple Silicon Mac 上，都能完美运行。 Ethan @ethan The versatility of Deep Live Cam is impressive. I use it for everything from digital art to marketing videos. 王芳 @wangfang Deep Live Cam 的一键视频深伪功能太强大了。这个工具极大地提高了我的创意输出效率，而且完全免费！ Create Stunning Face-Swap Effects with Deep Live Cam Experience the power of Deep Live Cam. Achieve real-time face swapping and video deepfakes quickly and easily, with high-quality visual results. Whether for entertainment or professional applications, unleash your creative potential with our open-source tool and diverse features. Start creating amazing visual content today! Get Started Now",
    "commentLink": "https://news.ycombinator.com/item?id=41209181",
    "commentBody": "Deep Live Cam: Real-time face swapping and one-click video deepfake tool (deeplive.cam)143 points by blini2077 5 hours agohidepastfavorite116 comments rnimmer 5 hours agoFTA: \"Ethical Use Safeguards Built-in checks prevent processing of inappropriate content, ensuring legal and ethical use.\" I see it claims to not process content with nudity, but all of the examples on the website demo impersonation of famous people, including at least one politician (JD Vance). I'm struggling to understand what the authors consider 'ethical' deepfaking? What is the intended 'ethical' use case here? Of all the things you can build with AI, why this? reply KolmogorovComp 4 hours agoparentFor many (notably mastercard and VISA), when they say “ethical” they really mean anything but porn. reply hackernewds 3 hours agorootparentthat seems like an overreaction. the card processors ban much more questionable trades - such as weapons and terrorism financing reply Maxatar 2 hours agorootparentI can't find anything to support your claim about weapons. Seems pretty much all online arms dealers I can find selling anything from grenades, machine guns, and even rocket launchers take credit cards and I'm fairly certain stores also accept them too. reply happyopossum 1 hour agorootparent> grenades, machine guns, and even rocket launchers Umm, yeah - what country are you buying live grenadesor working rocket launcher online with a Mastercard? Cuz it’s not the US or Canada. And if it’s not a live grenade or working rocket launcher, it’s no different than any hunk of metal. reply highcountess 2 hours agorootparentprevI am not sure what the current state of the issue is, but there was an initial effort to restrict gun sales in various devious and deceptive ways since it is illegal to overtly do so because it is legal trade and economic activity. I would not be surprised though if the clear illegality of the violation of the Constitution of such efforts were brought to the attention of the payment processors, and they were reminded that they would severely regret hastening attention on an effort that still needs to happen, a public electronic payment processing capacity. reply sneak 2 hours agorootparentprevI buy weapons with my Visa card all the time. reply PontifexMinimus 1 hour agorootparentprevAnd backed off from blocking Onlyfans. reply roamerz 3 hours agorootparentprevI think “questionable” is very subjective especially when blocking transactions on something that is constitutionally protected. I wonder what would happen if a processor banned paying for something that ended someone’s life on a near 1:1 ratio like abortion? Just using that to highlight the subjective nature of the comment. reply bee_rider 2 hours agorootparentIn general I think payment processor are not required to associate with anybody. The government (in the US at least) is limited in their ability to prevent you from buying guns and making porn (a form of speech), but they can’t make people do the transactions with you; the right to have somebody process payments for you is not constitutionally protected. But I’d be at least curious (as a non-lawyer) if there could be issues around discriminating against pregnant women in the US, since abortion is a service that is only used by them. reply parineum 1 hour agorootparentThe real answer to the guns/abortion comparison is there are a lot of people that Will loudly state their opposition. No (or few) politician is going to stand up for porn reply coolspot 2 hours agorootparentprevGP comment is misleading. Visa/MC do not block gun/ammo purchases in the US. reply roamerz 2 hours agorootparentIt’s not so much Visa/MC but rather the payment processors that are at issue here. reply mynameisvlad 2 hours agorootparentThe payment processors interpret the networks’ rules, you do understand that right? If they’re banning something, it’s because the networks either outright are banning it too or have put enough restrictions and constraints in place that the liability for the transaction doesn’t make sense. The payment processors are doing what the networks tell them to do. It’s not like the processors are actively looking for ways to turn down money; they want as many transactions going through them so they can earn their share of it. reply tourmalinetaco 2 hours agorootparentprevThe entire US financial apparatus is part of the problem. reply highcountess 2 hours agorootparentprevThere were several efforts to restrict the people’s right ability to marshal resistance to tyranny and Visa/MC was very much involved with that even though they were not the only ones. reply lancesells 2 hours agorootparentWhen did this happen? reply cess11 3 hours agorootparentprevThat's because the state is forcing them to. reply tourmalinetaco 2 hours agorootparentThe state has never stopped the funding of terrorism. https://www.nbcnews.com/politics/us-taxpayers-may-funding-ta... reply cess11 38 minutes agorootparentSure, but that doesn't mean it wants competition in that space. reply greg_V 1 hour agoparentprevThe number one use case for this will be to beat KYC checks, which means KYC procedures will get more annoying and bothersome for everyone else! reply rikafurude21 4 hours agoparentprev# process image to videos if modules.globals.nsfw == False: from modules.predicter import predict_video if predict_video(modules.globals.target_path): destroy() reply exe34 3 hours agorootparentI'm a big fan of explicit checks like this. reply tdeck 2 hours agoparentprevThe answer is that anyone working on deepfakes doean't care much about ethics or they wouldn't be doing it in the first place. reply ithkuil 2 hours agorootparentOTOH now that we know the technology is possible, would you prefer that only some actors had perhaps the ability to do that. or perhaps not and having the lingering doubt that anything you see could be deep fake but there could always be plausible deniability that it would be too hard to actually carry it out. If the technology is actually made widely available that just reveals that the Pandora box was actually already open reply dylan604 1 hour agorootparentThe claim of \"deepfake\" will be much more difficult to disprove than \"my account was hacked\" reply reaperducer 4 hours agoparentprevOf all the things you can build with AI, why this? That can be asked of 90% of what's come out of the latest AI bubble so far. Like a lot of technology, AI has so much potential for good. And we use it for things like games that simulate killing one another, or making fake news web sites, or pushing people to riot over lies, or making 12-year-olds addicted to apps, or eliminating the jobs of people who need those jobs the most, or, yes, pornography. We can do better. reply parineum 1 hour agorootparent> AI has so much potential for good. Like what? reply arjie 10 minutes agorootparentMy wife used ChatGPT and Adobe’s AI to design our wedding outfits so there’s that. Turned out great! reply dylan604 1 hour agorootparentprevI'm hoping that at some point the novelty and hype will die down so that the headline grabbing \"send a follow up email\" or \"summarize call\" will get out of the way so the more impressive things like detecting medical conditions months/years earlier than human doctors will be a much more visible. The things for making people lazy are a total waste to me. reply RafelMri 2 hours agoprevInteresting... This project is built upon \"GFPGAN v1.4\" (https://github.com/TencentARC/GFPGAN) and \"FaceSwap Extension - Automatic 1111 - Proof of Concept\" (https://github.com/revolverocelot1/-webui-faceswap-unlocked). The GFPGAN project is grounded on its own in the paper \"GFP-GAN: Towards Real-World Blind Face Restoration with Generative Facial Prior\" by Wang et al. (https://xinntao.github.io/projects/gfpgan) reply ed 1 hour agoparentThis is not a new face swapping technique, it’s a wrapper around inswapper (aka InstantID, an IP adapter): https://github.com/haofanwang/inswapper Relevant source https://github.com/hacksider/Deep-Live-Cam/blob/main/modules... reply cs702 5 hours agoprevWell, I understand how it works, and I still find it freaking amazing. The quality is... impressive. On the flip side, the ability to deep-fake a face in real time on a video call is now accessible to pretty much every script kiddie out there. In other words, you can no longer trust what your eyes see on video calls. We live in interesting times. reply Xeoncross 5 hours agoparentIt's interesting, because the subconscious ability of the mind to identify discrepancies is incredible (even if we ignore that feeling we get about something). The feel of counterfeit bills, the color someone choose to wear, the sound that doesn't quite fit. I think deep-fakes are mostly a danger to people without a lot of source material for their minds to compare against. You could trick me into believing I was taking with Elon, but not my son. reply cs702 1 hour agorootparentThe key take-away, for me, is that I should \"keep my guard up\" on any video call about money or other important matters, even if other participants on the call are colleagues, friends, or relatives. There are no guarantees of authenticity anymore. My new motto for video calls is \"trust by verify.\" reply emsign 4 hours agorootparentprevWhat if that source material for young brains gets more and more contaminated with artificial junk? reply reaperducer 4 hours agorootparentprevYou could trick me into believing I was taking with Elon, but not my son. And yet there have been several recent studies that show the younger someone is, the more likely they are to be scammed online. > In 2021, Gen Xers, Millennials, and Gen Z young adults (ages 18-59) were 34% more likely than older adults (ages 60 and over) to report losing money to fraud,[1] and some types of fraud stood out. Younger adults reported losses to online shopping fraud – which often started with an ad on social media – far more often than any other fraud type, and most said they simply did not get the items they ordered.[2] Younger adults were over four times more likely than older adults to report a loss on an investment scam.[3] Most of these were bogus cryptocurrency investment opportunities. https://www.ftc.gov/news-events/data-visualizations/data-spo... reply vincnetas 3 hours agorootparenti fell victim to such scam this year (first time i got scammed over 40 years). Key factor was that i got link to scam shop not from social ad but from my wife :) she got it from insta ad. So basically my wife scammed me :) reply dexterdog 3 hours agorootparentprevOlder people are less likely to invest in high risk, high yield. reply Rinzler89 3 hours agorootparentOlder people are less likely to have their entire personas and private lives fully documented on social media. reply eltoxo 1 hour agorootparentYounger people really should consider this point. Personally, I don't use streaming video outside of work and there are no videos of me on youtube or any social media to train a model on even if someone wanted to. My mother in her 70s doesn't even have a debit card. She thinks the idea is ridiculous and insecure. She writes paper checks and that is it. To put her account number on an electronic device would be completely unthinkable. While the average older person might be more easily confused by social engineering the attack surface for an electronic scam is so tiny compared to the average younger person. reply bsenftner 48 minutes agorootparentOnly one photo is needed. I've not looked deep into this specific project, but speaking as an early developer of likeness transfer trained algorithms, only one image is needed, and it can even be a crude sketch - but if one's true likeness is captured by an image it can be recreated in full 3D. The catch is an individual's specific facial expressions, such as the real individual has a slightly lopsided smile, or they have smile dimples, or simply their characteristic at rest facial positions are absent, so they don't look like themselves to those that know them. reply bsmithers 3 hours agorootparentprev> And yet there have been several recent studies that show the younger someone is, the more likely they are to be scammed online. I think you are misreading the post. Pretty sure they meant you could trick me into believing I was talking with Elon, but you could not trick me into believing I was talking with my son To which I agree personally, though I don't know how universal this is. reply Bluecobra 4 hours agoparentprevIndeed. Just recently a company got fooled into hiring a remote employee who turned out a North Korean hacker: https://arstechnica.com/tech-policy/2024/07/us-security-firm... reply ibejoeb 3 hours agoparentprevIt's got a lot of uncanny valley going on. Zuck looks like a corpse. I'm sure it could fool some people, but I'm not terrified yet. reply exe34 3 hours agoparentprevI recommend setting up code words with people. I haven't gone that far myself yet, but in my mind, there are clear phrases I could say to the people in my life that they would be convinced it was me. Unfortunately, until I have the specific talk with them, I suppose anybody could impersonate me to them. reply emsign 4 hours agoparentprevPost-truthism has reached live video and is accessible to everyone. Turns out it's still only a few weirdos who love to use it for grifting purposes. I think most normal people are like \"what do I need this crazy sh*t for?\" reply Stagnant 2 hours agoprevLooks like this project is a fork of the discontinued roop[0] with primarily some UI improvements. One of roop's main developers has been working on facefusion[1] for the past year and it produces by far the most convincing results from the ones i've seen and it also supports real time webcam face swapping. 0: https://github.com/s0md3v/roop/ 1: https://github.com/facefusion/facefusion reply nope1000 5 hours agoprevTechnically impressive but I fail to see a good use case for it that's not related to propaganda or scam and the website doesn't seem to list one either. reply rebeccaskinner 38 minutes agoparentJust a few off the top of my head: Movies and TV: - As an alternative to motion capture for animation - As an alternative to existing de-aging CGI when you want to flash back to a younger version of a character (especially for cases where newer sequels are being made for much older movies) - As an easy way to get some additional footage if an actor no longer looks the part In a professional setting: - Conduct job interviews were interviewees faces are mapped to the faces of a few pre-defined images, to reduce a major source of implicit bias in interviewing - Get some footage of yourself when you're looking your best, with great lighting, and use that rather than being off-camera if you're joining a meeting when you don't look great - Create virtual spokespeople to represent your company in marketing, and allow that person to be played by different actors News and Politics: - An alternative to blurred or blocked out faces for people giving interviews or whistle blowing - Allow people to testify in court (virtually) without revealing their identity and risking retaliation reply pavel_lishin 5 hours agoparentprevIf I had to dig way, way down to the bottom of the barrel for use cases, it would be very funny if everyone showed up to a meeting wearing one of the attendee's faces. reply nope1000 4 hours agorootparentThat would have been the dream of students during remote schooling times. reply stavros 1 hour agorootparentprevDon't they already? reply muixoozie 2 hours agoparentprevOnly things I can think of: - streamer goofing around. - Perhaps something like this could be used to map your facial expressions onto video game characters in real-time. - could take tictok style social media to the next level of absurdity. make me into a meme. Ghana says goodbye etc. reply skocznymroczny 1 hour agoparentprevIt's fun for goofing around. Imagine a conference call with your buddies and each one comes with a different deepfake. Kind of like a costume party but on camera. reply luzojeda 1 hour agorootparentI don't think that compensates all the bad uses it will probably have. reply nwoli 3 hours agoparentprevOne legitimate one I could imagine is if people want to pursue a career in the adult film industry but without having to reveal their true face (not with a celebrity face of course) reply eltoxo 1 hour agorootparentI have been thinking about this comment and if it isn't a celebrity then just someone you know? If not someone you know then just a random stranger? Not that I can think of a better use case but it is telling if this is the best we can do. reply irq-1 40 minutes agorootparentJob interviews, bank loans, anywhere racism or discrimination exists (or might exist.) reply nwoli 49 minutes agorootparentprevI just meant a synthetic human (a dalle/stylegan/stable diffusion face output). reply bsenftner 44 minutes agoparentprevOh those without the imagination: this is gold marketing for makeup and fashion advertising companies. The \"good use\" is the multi-billion dollar makeup and fashion industry. People will submit their own images so they can see themselves randomly appear in their own media feeds in the latest fashions. This is a no brainer for those with the connections to fashion marketing. reply Willingham 4 hours agoprevJust need to add voice augmentation and every grandma and grandpa in the world will have their bank accounts cleaned out! Better go warn mine now! XD reply curiousgal 4 hours agoparentIn the world? You'd be surprised by how many grandmas out there that don't have bank accounts or access to the Internet... reply reaperducer 4 hours agoparentprevJust need to add voice augmentation and every grandma and grandpa in the world will have their bank accounts cleaned out! Only if by \"grandma\" you mean \"Millennial\" and by \"grandpa\" you mean \"Gen Z.\" Your ageism doesn't jibe with reality: https://www.ftc.gov/news-events/data-visualizations/data-spo... reply hungie 4 hours agorootparentI think you should read that again. It's clear that different age groups fall for different scams and have different impacts from them. Grandparents absolutely fall for some scams at disproportionate rates. And are less likely to be able to recover. (A 19 year old who loses everything has many more productive years to recover than a 72 year old.) Also, humorously, millennials are starting to become grandma and grandpa. Elder millennials are in their mid 40s. It's young, but not impossible for them to be grandparents now. reply declan_roberts 3 hours agoprev\"Built-in checks prevent processing of inappropriate content, ensuring legal and ethical use.\" A software engineer says to himself, if only I could keep these guns from jumping off the table and shooting people. reply KaiserPro 2 hours agoprevIs there a legitimate usecase for this? Like when they were brainstorming this as a product, what was the persona/vertical they were targeting? reply jader201 48 minutes agoprevI feel like this is one step closer to the Black Mirror episode where the grieving widow orders an AI version of her late husband. And I don’t say this with excitement. reply araes 1 hour agoprevHuh. Thought politics was dead with VASA-1 [1], EMO [2], and Animate / Outfit anyone [3], so we could clothe people in anything, animate them any way we want, put them anywhere, and have them say anything to the public. \"Thoughts and prayers victims...\" However, this really nails that pretty dead itself. Wonder if I can: - Sit at home in pajamas. - Change my face to Sec. of Def. Lloyd Austin. - Put myself in a nice suit from TV - Call the White House with autotune voice pretending to be going in for surgery yet again because of life threatening complications - Send the entire military into conniptions (maybe mention some dangerous news I need to warn them about before the emergency rush surgery starts) Edit: This [4] might be an Animate / Outfit anyone image... It's difficult to tell. Even with huge amounts of experience, the quality has become too elevated, too quick to check 1000's of depressing murder images for fakes because it might be a BS heart string story. All stories on the WWW are now, \"that might be fake, unless I can personally check.\" Al-arabiya upvoted casinos and lotteries for muslims recently. [5] \"they all might be fake.\" [1] https://www.microsoft.com/en-us/research/project/vasa-1/ [2] https://humanaigc.github.io/emote-portrait-alive/ [3] https://humanaigc.github.io/animate-anyone/ [4] https://www.reuters.com/resizer/v2/https%3A%2F%2Fcloudfront-... [5] https://english.alarabiya.net/News/gulf/2024/07/29/uae-grant... reply xnx 1 hour agoprevhttps://github.com/C0untFloyd/roop-unleashed does this for free on your own computer reply doctorhandshake 5 hours agoprevThis makes me think there could be use for a very very (very) easy-to-use tool that allows two parties to choose and store a secret (verbally pronounceable) passphrase known only to the two of them, for use in situations in which it might be necessary to ‘sign’ a video chat or audio conversation in which one party’s identity might be in doubt. reply 101008 3 hours agoparentI always liked that idea (not original, I know) in the Harry Potter books (Harry Potter and the Deathly Hallows, more specifically), where two people ask a private question they should only know to be sure they are not being impersonated. reply sebastiennight 3 hours agoparentprevI've seen people try and share such a \"password\" verbally on a video call. With recording and live transcribing on. From free-tier extensions with wobbly privacy policies. This won't work. I've resorted to using OTP apps with family and coworkers. reply mynameisvlad 2 hours agorootparentSo you force your parents/kids/aunts/etc to give you a one time code every time they want to talk to you? That seems extremely clunky and impersonal and I couldn’t imagine anyone in my family willingly agreeing to do it. reply reaperducer 4 hours agoparentpreva very very (very) easy-to-use tool that allows two parties to choose and store a secret (verbally pronounceable) passphrase known only to the two of them So, quite literally, a \"password\" in its original pre-internet meaning. reply doctorhandshake 2 hours agorootparentHaha yes. Maybe a secret knock? reply dpweb 5 hours agoprevFacinating software although I hope the idea \"we're gonna rely on people to be good humans and DO THE RIGHT THING\" is quickly abandoned and instead there is just as robust development of detection software that goes along with newer and better deep fake tools. reply BugsJustFindMe 5 hours agoparentDetection is ultimately impossible. Anything you can detect can be explicitly evaded. reply exe34 3 hours agorootparentI dream of a world where a web of trust signatures are taken seriously. A few hops should get you to a real human holding the camera who claims it's a real recording. If that person or someone along the way is regularly flagged as malicious by others that you trust, you can blacklist them. reply FredPret 2 hours agoprevI think AI + deepfakes will increase the value pressure on in-person interactions - ie, the only time when you can (for now) believe your eyes and ears. I wonder how politics can be transacted in such an environment. Old-timey first-past-the-post might be the optimal solution if you can't trust anything from out of earshot. reply shireboy 1 hour agoparentIn person interactions like this CIA mask expert tricking a US president? https://spyscape.com/article/master-of-disguise-how-the-cias... reply carapace 2 hours agoparentprev> I wonder how politics can be transacted in such an environment. Codes and seals predate computers (by quite a bit.) https://en.wikipedia.org/wiki/Code_(cryptography) https://en.wikipedia.org/wiki/Seal_(emblem) reply FredPret 2 hours agorootparentThose are relevant to the workings of government. The process of politicians debating and getting elected is going to have to be much more local. Just look at how easy it is to spread misinformation now. reply goda90 5 hours agoprevHow long until we see \"anti-cheat\"-like software to try to detect this stuff for video chatting? reply radicality 1 hour agoparentPerhaps we’ll see it a requirement to use a closed platform like an iPhone where it would be much easier to attest that the feed is not tampered with. It’s already a requirement sometimes to take a video of your face from multiple angles using your phone - some identity verification service forced me to do it. I imagine that stuff like this will evolve to check for hardware attestations more, or use info from depth/lidar sensors to verify video and other sensor data align. reply diggan 5 hours agoparentprevI'm guessing that finding a technology to try to detect this would be over-engineering. I'd love to see a sample where the person with the swapped face passes their hand with spread fingers over their face, and see how it handles that. reply Raicuparta 4 hours agorootparentI've tried it, it currently does not handle that scenario well at all. reply warkdarrior 3 hours agorootparentWait three months, it'll be fixed. reply illnewsthat 4 hours agoprevWhat’s the technical difference in how this works vs. previous face swapping tech (like Snapchat filters)? reply chefandy 2 hours agoprevWell, this will make for some \"interesting\" viral campaign fodder. reply hackernewds 3 hours agoprevwhere are all these \"wow impressive\" comments coming from? clicking \"Get Started\" dumps you into a loop of landing on the home page reply jakepage91 3 hours agoparentthe README.md seems straightforward enough. reply robxorb 2 hours agorootparentWhere is the repo? Stuck in the landing page loop here and no github link I could find. reply stavros 1 hour agorootparentYeah all of the page's links just go to the same page, except the \"experience live cam\" link at the top. That goes to this: https://github.com/hacksider/Deep-Live-Cam Took me multiple minutes to find too. reply freeone3000 2 hours agoprevThe future of v-tubers is here reply XorNot 4 hours agoprevA practical use of this would be to animate your face onto a CGI model which was independently posed for the purposes of video meetings - which is something I've always wanted. Let me separate my face, body and words and craft the experience. reply gunalx 2 hours agoparentStrit up look into vtubing, and it's already done. https://inochi2d.com/ reply greeniskool 4 hours agoparentprevFace tracking has existed for years now. I frankly don't see what's different between what you described and FaceRig. reply XorNot 1 hour agorootparentYou're missing the point: I want a fake version of myself. I want a model which is made photoreal with my own image, so it can be given a voice in real time with my words, but a filtered version of my facial expression and pose. So how I look and act is essentially scriptable. reply radicality 1 hour agorootparentI think that’s already happening. You can buy a trained model of someone to do 24/7 live-streaming peddling products, or even black-mirror-esque bringing back deceased ones. Company in china selling this is Silicon Intelligence. https://www.technologyreview.com/2023/09/19/1079832/chinese-... https://www.technologyreview.com/2024/05/07/1092116/deepfake... reply hankchinaski 1 hour agoprevNow the question is, what is the use case that does not entail misinformation or personal amusement? reply bufferoverflow 1 hour agoparentCam girls will get some competition from guys. reply zug_zug 4 hours agoprevTechnologically seems cool, and the first use that pops into mind is \"wouldn't this be funny to prank my friend?\" But maybe no, it wouldn't. Maybe it'd be deeply disconcerting. We have very strong norms around honesty as a society, and maybe crossing them in video just for a joke is comparably crass to giving somebody a fake winning lottery ticket. reply paul7986 32 minutes agoprevNeil DeGrasse Tyson says it best the Internet will die because of this type of technology https://www.youtube.com/shorts/AxM2XTwaaUA AI will kill the Internet we know today and the new one im guessing you will have to have a Internet license attached to your identity which is backed by your internet reputation which you always want to keep it high for veracity/validity! You can still post anonymously but it wont hold as much weight compared to you posting using your verified Internet identity. This idea of mine i posted good number of times here and it gets downvoted but with the IRS in bed with ID.Me (elon musk is involved with them in some capacity) you can see what i mention with ID.me and the IRS being a small step in this direction. Otherwise no one uses the Internet (zero trust of it) .. it dies and we go back to reading books and meeting in person (doesnt sound all that bad yet ive never read a book before). reply haxiomic 5 hours agoprevI miss the recent past where new tech felt exciting and inspiring but for the last few years new developments are often coupled with an anxiety for the new harms possible and often unclear benefits. I wonder how much is 'inevitable', at large enough scale we will always exploring new possibility spaces as they become available and how much is our choosing – we put resources to build these things in full awareness because we think they bring value over focusing on other things. I realise though it is useful for society to develop understanding and defences for these things early I've notice I've steadily become more ashamed to be associated with tech. I'm still processing how to react to this and what to choose to work on in response Am I in a bubble? Do you share similar feelings or are yours quite different? I am very curious reply diggan 4 hours agoparent> I've notice I've steadily become more ashamed to be associated with tech Are you actively contributing to these areas you feel ashamed about? If not, you shouldn't really feel ashamed about what other people chose to work on, even if both of you work \"in tech\". I'm sure not all people working on medical research agrees with what all other researchers are working on, but you cannot really control what others are working on, so why feel ashamed over what others are working on? reply reaperducer 4 hours agorootparentyou shouldn't really feel ashamed about what other people chose to work on, even if both of you work \"in tech\". Why not? Someone who builds boxes that hold bombs can be ashamed of being in the munitions industry, even if they don't make the actual bombs. reply diggan 3 hours agorootparentRight, but if you're in general \"manufacturing\", there isn't much point of feeling ashamed about some parts of the industry focusing on munitions manufacturing. reply 0xf00ff00f 4 hours agoparentprevI feel the same way. I can't think of a single legitimate use case for this. I wish all those GPU teraflops were being used for something else. reply chillingeffect 4 hours agoparentprevDefinitely with you. It used to be a higher entry point so a certain passion was necessary. And it was less about money and more about sharing info and joy. Now networking tech has been \"democratized\", it's another medium where the usual human pain and greed play out. High school again, but with real consequences on peoples' lives. reply blini2077 5 hours agoprev [–] Deep Live Cam is a cutting-edge AI tool that enables real-time face replacement in videos or images using just a single photo. Perfect for video production, animation, and more. reply emsign 4 hours agoparent [–] I don't want to see faked videos. reply corn13read2 2 hours agorootparentMaybe you have been this whole time... reply exe34 3 hours agorootparentprevYou won't know the difference. reply luzojeda 1 hour agorootparentThat only makes it worse. reply warkdarrior 3 hours agorootparentprev [–] Son, you no longer have an option on our free service. But you can subscribe to our deep fake-free service for only $89.99/month. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Deep Live Cam is an advanced AI tool for real-time face swapping and video deepfakes, requiring only a single image for high-quality results.",
      "It supports multiple platforms, including CPU, NVIDIA CUDA, and Apple Silicon, and features ethical safeguards to prevent misuse.",
      "The tool is open-source, offers instant previews, and is optimized for faster processing, making it accessible for both personal and commercial use."
    ],
    "commentSummary": [
      "Deep Live Cam is a real-time face-swapping and video deepfake tool, raising ethical concerns about its use, especially in impersonating famous individuals.",
      "The tool claims to have built-in ethical safeguards to prevent processing inappropriate content, but the definition of 'ethical' use remains ambiguous.",
      "The technology is built on existing projects like GFPGAN and FaceSwap Extension, making advanced deepfake capabilities more accessible to the general public."
    ],
    "points": 143,
    "commentCount": 116,
    "retryCount": 0,
    "time": 1723295148
  },
  {
    "id": 41207182,
    "title": "Caltech Develops First Noninvasive Method to Continually Measure Blood Pressure",
    "originLink": "https://www.caltech.edu/about/news/caltech-team-develops-first-noninvasive-method-to-continually-measure-true-blood-pressure",
    "originBody": "skip to main content Visit Careers Access Quick Links for Faculty for Students for Staff for Alumni Directory Caltech Today Alumni GIVE About Open About submenu At a Glance Open At a Glance submenu University and College Rankings Leadership Open Leadership submenu President Provost Board of Trustees Academic and Administrative Leadership Values Open Values submenu Diversity, Equity, and Inclusion Sustainability Freedom of Expression Honor Code Legacy Open Legacy submenu History & Milestones Awards & Honors Caltech Archives Interactive History Map News Publications Open Publications submenu Caltech Science Exchange This is Caltech Caltech Magazine Periodic Table of Caltech Visit Open Visit submenu Directions Campus Maps Parking Tours Administrative Offices & Departments Research Open Research submenu Academic Divisions Open Academic Divisions submenu Biology and Biological Engineering Chemistry and Chemical Engineering Engineering & Applied Science Geological & Planetary Sciences Humanities and Social Sciences Physics, Mathematics and Astronomy Jet Propulsion Laboratory Student Research Centers & Institutes Technology Transfer & Corporate Partnerships Sponsored Research Research Facilities Faculty Listing Academics Open Academics submenu Undergraduate Studies Graduate Studies Online Education Executive Education Teaching, Learning, & Outreach Resources Open Resources submenu Registrar Catalog Academic Calendar Library International Offices Career Development Admissions & Aid Open Admissions & Aid submenu Undergraduate Admissions Open Undergraduate Admissions submenu Apply Cost & Aid Graduate Admissions Open Graduate Admissions submenu Apply Funding & Aid Campus Life & Events Open Campus Life & Events submenu Institute Calendar Caltech Today Athletics & Recreation Events / CaltechLive! Performing & Visual Arts Housing Dining Caltech Y Wellness Services Diversity Center Security Emergency Information SearchSearch Menu Close About Open About submenu Research Open Research submenu Academics Open Academics submenu Admissions & Aid Open Admissions & Aid submenu Campus Life & Events Open Campus Life & Events submenu Visit Careers Access Quick Links for Faculty for Students for Staff for Alumni Directory Caltech Today Alumni GIVE About Caltech Back At a Glance University and College Rankings Leadership President Provost Board of Trustees Academic and Administrative Leadership Values Diversity, Equity, and Inclusion Sustainability Freedom of Expression Honor Code Legacy History & Milestones Awards & Honors Caltech Archives Interactive History Map News Publications Caltech Science Exchange This is Caltech Caltech Magazine Periodic Table of Caltech Visit Directions Campus Maps Parking Tours Administrative Offices & Departments Research Back Academic Divisions Biology and Biological Engineering Chemistry and Chemical Engineering Engineering & Applied Science Geological & Planetary Sciences Humanities and Social Sciences Physics, Mathematics and Astronomy Jet Propulsion Laboratory Student Research Centers & Institutes Technology Transfer & Corporate Partnerships Sponsored Research Research Facilities Faculty Listing Academics Back Undergraduate Studies Graduate Studies Online Education Executive Education Teaching, Learning, & Outreach Resources Registrar Catalog Academic Calendar Library International Offices Career Development Admissions & Aid Back Undergraduate Admissions Apply Cost & Aid Graduate Admissions Apply Funding & Aid Campus Life & Events Back Institute Calendar Caltech Today Athletics & Recreation Events / CaltechLive! Performing & Visual Arts Housing Dining Caltech Y Wellness Services Diversity Center Security Emergency Information SearchSearch Home / About / News / Caltech Team Develops First Noninvasive Method to Continually Measure True Blood Pressure Caltech Team Develops First Noninvasive Method to Continually Measure True Blood Pressure August 07, 2024 Solving a decades-old problem, a multidisciplinary team of Caltech researchers has figured out a method to noninvasively and continually measure blood pressure anywhere on the body with next to no disruption to the patient. A device based on the new technique holds the promise to enable better vital-sign monitoring at home, in hospitals, and possibly even in remote locations where resources are limited. The new patented technique, called resonance sonomanometry, uses sound waves to gently stimulate resonance in an artery and then uses ultrasound imaging to measure the artery's resonance frequency, arriving at a true measurement of blood pressure. In a small clinical study, the device, which gives patients a gentle buzzing sensation on the skin, produced results akin to those obtained using the standard-of-care blood pressure cuff. \"We ended up with a device that is able to measure the absolute blood pressure—not only the systolic and diastolic numbers that we are used to getting from blood pressure cuffs—but the full waveform,\" says Yaser Abu-Mostafa (PhD '83), professor of electrical engineering and computer science and one of the authors of a new paper describing the technique and device in the journal PNAS Nexus. \"With this device you can measure blood pressure continuously and in different sites on the body, giving you much more information about the blood pressure of a person.\" \"This team has been working for almost a decade, trying to build something that makes a difference, that is good enough to solve a real clinical problem,\" says Aditya Rajagopal (BS '08, PhD '14), visiting associate in electrical engineering at Caltech, research adjunct assistant professor of biomedical engineering at USC, and a co-author of the new paper. \"Many groups, including tech giants like Apple and Google, have been working toward a solution like this, because it enables a spectrum of patient-monitoring possibilities from the hospital to the home. Our method broadens access to hospital-grade monitoring of blood pressure and cardiac health metrics.\" Blood pressure 101 Blood pressure is simply the force of blood pushing on the walls of the body's blood vessels as it gets pumped around the body. High blood pressure, or hypertension, is related to risk of heart attack, stroke, chronic kidney disease, and other health problems. Low blood pressure, or hypotension, can also be a serious problem because it means the blood is not carrying enough oxygen to the organs. Taking regular measurements of blood pressure is considered one of the best ways to monitor overall health and to identify potential problems. Most of us have experienced the cuff-style measurement of blood pressure. A nurse, doctor, or machine inflates a cuff that fits around the upper arm until blood can no longer flow, and then slowly releases the air from the cuff while listening for the sound that blood makes as it once again begins to flow. The pressure in the cuff at that point corresponds to the blood pressure in the patient's arteries. But this technique has limitations: It can only be performed periodically, as it involves occluding a blood vessel, and can only collect data from the arm. Physicians would very much like to have continuous readings that provide full waveforms of a patient's blood pressure, and not only peripheral measurements from an arm but also central measurements from the chest and other parts of the body. To get the full information they need, intensive care physicians and surgeons sometimes resort to inserting a catheter directly into the artery of critical patients (a practice known as placing an arterial line, or \"a-line\"). This is invasive and can be risky, but, until now, it has been the only way to get a continuous readout of true blood pressure. In some cases, such as problems with heart valves, full blood-pressure waveforms can provide physicians with diagnostic information that they cannot get any other way. \"There's a lot of information in that waveform that is really valuable,\" says Alaina Brinley Rajagopal, a visiting associate in electrical engineering at Caltech, an emergency medicine physician, and a co-author of the paper. And other blood pressure devices developed over the last decade or two require a calibration step that emergency physicians simply do not have time for, she says. \"I need to be able to put something on a patient and have it work immediately.\" The new device fits the bill. The current prototype, built and tested by a spin-off company called Esperto Medical, is housed in a transducer case smaller than a deck of cards and is mounted on an armband, though the researchers say it could eventually fit within a package the size of a watch or adhesive patch. The team aims for the device to first be used in hospitals, where it would connect via wire to existing hospital monitors. It could mean that doctors would no longer have to weigh the risks of placing an a-line in order to get the continuous monitoring of real blood pressure for any patient. Eventually, Brinley says their device could replace blood pressure cuffs as well. \"Blood pressure cuffs only take one measurement as often as you run the cuff, so if you're asking patients to monitor their blood pressure at home, they have to know how to use the device, they have to put it on, and they have to be motivated to record the information, and I would say a majority of patients do not do that,\" says Brinley Rajagopal. \"Having a device like ours, where it is just place and forget, you can wear it all day, and it can take however many measurements your provider wants, that would allow for better, precision dosing of medication.\" Developing a game changer Rajagopal recalls the long road it has been getting to this point with the blood pressure device. About a decade ago, Brinley Rajagopal returned from a global health trip particularly frustrated by the standard of care she could provide patients in remote locations. Talking with Rajagopal, the two wished they could invent something like a medical tricorder, a handheld device seen in Star Trek that helped the fictional doctors of the future scan patients, gather medical information, and diagnose. \"That got us thinking about technologies we could adapt to get us closer to a goal like that,\" says Brinley Rajagopal. Those initial sci-fi–inspired discussions eventually led them down the path to try to develop a better blood pressure monitor. But their first efforts did not pan out. After years of work on a possible solution using blood velocity to derive blood pressure, the team decided that they had reached a dead end. As with many other current blood pressure monitoring devices, that approach could only provide the relative blood pressure—the difference between the high and low measurements without the absolute number. It also required calibration. Back to the drawing board Rajagopal decided it was time to reevaluate and determine if they had any chance of solving this problem. \"It was this moment of desperation that actually led to the key insight,\" says Rajagopal. Thinking back to his first-year physics course at Caltech, he began scribbling on a nearby wall. He remembered that his Physics1 textbook presented a canonical problem: You have a string under tension. How can you determine how taut the line is? If you tweeze the string, you can relate the velocity at which vibration waves travel back and forth on the string to the resonance frequency in the string, which could give you your answer. \"I thought if I could stretch an artery in one direction and magically tweeze it and let it go, the ringing would give us the resonance frequency, which would get us to blood pressure,\" says Rajagopal. After six years of failures and returning to first principles, they finally had their guiding insight. And indeed, that is the underlying idea behind the new device: Like a guitar changing pitch as it is plucked while being tightened, the frequency at which an artery resonates when struck by sound waves changes depending on the pressure of the blood it contains. This resonance frequency can be measured with ultrasound, providing a measure of blood pressure. This measurement requires three parameters—a measurement of the artery's radius, the thickness of the artery's walls, and the tension or energy in the skin of the artery. With the physics worked out, there were still a lot of other details to be resolved—identifying the sound waves that would make arteries resonate, understanding how to measure that resonance, and then determining how to efficiently map that back to blood pressure, and, significantly, how to build a working system. \"Building that system required some extraordinarily bespoke technologies,\" says Rajagopal. Caltech alumnus Raymond Jimenez (BS '13) was instrumental in building out that first system. \"The art form, which involved a lot of other Caltech alumni, was to put the physics answer into a very simple, practical instrument.\" The resulting Esperto device is small, noninvasive, relatively inexpensive, and it has an automated method for locating the patient's blood vessel without needing to be physically repositioned. It also does not suffer from the problems that some blood pressure monitoring devices have, such as not being accurate for patients with low blood pressure or getting varying results depending on a patient's skin tone. It might not be a medical tricorder, but the team says the device solves the longstanding blood pressure monitoring problem. And Rajagopal says it is the product of a million small leaps. \"Everything we've done is a product of the exact mistakes we've made over time,\" he says, \"and all the work that others have done too.\" \"This work is emblematic of what makes Caltech so remarkable: solving a very hard problem by going back to first principles and understanding a physical phenomenon at the fundamental level,\" says Fred Farina, Caltech's Chief Innovation and Corporate Partnerships Officer. \"This approach, combined with the tenacity and entrepreneurial drive of the team, is our homemade recipe for societal impact and improving people's lives.\" The paper describing the new technique is titled \"Resonance sonomanometry for noninvasive, continuous monitoring of blood pressure.\" Additional authors on the paper include Raymond Jimenez (BS '13), Steven Dell, Austin C. Rutledge, Matt K. Fu (BS '13), and William P. Dempsey (PhD '12) of Esperto Medical, and Dominic Yurk (BS '17, PhD '23), a current member of Abu-Mostafa's group at Caltech. The work at Caltech was supported by Caltech trustee Charles Trimble (BS '63, MS '64), the Carver Mead Innovation Fund, and the Grubstake Fund. Written by Kimm Fesenmaier Contact Kimm Fesenmaier (626) 395‑1217 kfesenma@caltech.edu A concept design for what the team envisions as final products using the resonance sonomanometry blood pressure method. The device on the upper arm measures from the brachial artery and the wristwatch measures from the radial artery. The devices run independently of one another. Credit: Matt Fu, Esperto Medical Alaina Brinley Rajagopal, a visiting associate in electrical engineering, an emergency medicine physician, and a co-author of the new paper describing the new technique, demonstrates the current prototype of the resonance sonomanometry blood pressure device. Credit: Daniel Cellucci, Esperto Medical This graphic shows carotid placement of the Esperto sensor and ultrasound imagery (central) as gathered by the device. Resonance sonomanometry human data (right) shows arterial waveforms from the Esperto device compared to an arterial catheter, including blood pressure, resonance frequency, and arterial radius. Credit: Esperto Medical Image Lightbox Subscribe The Caltech Weekly Share this See All News California Institute of Technology 1200 East California Boulevard Pasadena, California 91125 Contact UsClaimed Copyright InfringementPrivacy NoticeDigital AccessibilitySite Content Copyright © 2024",
    "commentLink": "https://news.ycombinator.com/item?id=41207182",
    "commentBody": "Caltech Develops First Noninvasive Method to Continually Measure Blood Pressure (caltech.edu)121 points by crhulls 15 hours agohidepastfavorite37 comments coldcode 5 hours agoAs a person who had a hypertensive crisis late last year, nothing boils my blood (yes, a pun, I am fine now) more than how people measure blood pressure incorrectly in doctors offices and even hospitals. There are many different things than can increase a BP measurement above the \"baseline\" including talking, moving around, not having rested but also just waking up, not being in a supported position, only a single value, etc. Most of the major health agencies (AMA,AHA,CDC, etc in the US) have recommendations on how to do it properly, but in medical situations like doctors offices and hospitals, these are rarely done as they take too much time. A single measurement is not sufficient and can result in misdiagnosis. A more reliable way to measure a continuum would make a difference, but I imagine it would still require time to collect as BP is a dynamic value that changes with behavior, posture and activity. reply hereme888 35 minutes agoparentI'm a resident physician and I deny having my BP taken in outpatient clinics. The techniques used are ridiculously inappropriate: \"Ok, Mr. So-and-so, come with me.\" calls the nurse, as the pt who is irritated for having to wait 30 minutes quickly gets up to walk along unknown hallways, while rushing to finish a phone conversation, stressed and not knowing where to turn next...\"Ok, now we're going to weigh you on this scale\" while the pt thinks 'oh man, I've probably gained weight', followed by \"ok, now we're going to measure your blood pressure.\" 'I don't want BP meds...let me try to relax...breathe slooowly...but I don't want the nurse to notice I may be trying to cheat this sudden examination.' That's why the most appropriate way nowadays is to measure it at home, and keep a BP log. reply dgacmu 2 hours agoparentprevIt's frustrating. I usually bike to the doctor's office, and every time I warn them that they're going to get a systolic 10 higher than if they'll wait until the end of the appointment. They don't wait. The tech-taken entry gets put in the EMR. The doctor takes my BP again at the end, says \"oh, great\" and that reading gets ignored. :p As a sibling comment noted, I ended up deciding to just watch my BP at home every now and then. It turns out it's fine and it reduced my metaphorical blood pressure to monitor it myself. reply benmanns 55 minutes agorootparentHowever, as discovered during a family heart crisis, medical professionals will routinely ignore any kind of heart rate or blood pressure readings that you take at home. In my experience, it's not until they see the same measurement during the ($$$) ambulance ride that they take it seriously. reply nulbyte 5 hours agoparentprevAs an adult with a congenital heart defect and white coat hypertension, I can relate. Once, a nurse took my blood pressure and immediately freaked out as I was sitting calmly on the exam table. She took it again in the same arm, then hurriedly took it in each of my other limbs before throwing her hands up. Often, I would arrive at the cardiology office having made my way through downtown traffic to find a parking space and walk across the pedway. Then I'd find a seat as far away as possible from all the noisy children there to remind me that I should be dead. No wonder my BP is higher than usual. And you're the one freaking out? I got so used to nurses tossing out every recommendation for measuring BP that I started taking it myself at home before visits just to prove the point. Eventually, as I grew older, my BP rose to a point where it actually needed to be addressed. I am now on medication. But I have yet to find a nurse anywhere that has taken time to follow even one recommendation for properly taking BP. reply pkaye 2 hours agorootparentWhen I was a dialysis patient with frequent office visits, I've had the same experiences myself. Two things I've ended up doing is get to the hospital 30 minutes early, sit in a quiet area and relax till 10 minutes before the appt. Secondly I've found deep and slow breathing can improve your blood pressure a lot. The problem of white coat syndrome still remain though. reply teamspirit 2 hours agoparentprevI had hypertension for about 15 years and after quitting drinking and smoking no longer do. I still suffer from white cost hypertension regularly and frequently have to tell nurses to just press the button again - second time drops back to normal range with a drop of about 20/10. reply hn72774 31 minutes agorootparentI had it too. When I was under stress, sometimes I could hear my pulse in my ears like a whooshing sound. I stopped drinking and my BP is now completely normal, and RHR is low 40's. Sleep is much better too. reply HPsquared 1 hour agoparentprevI find doctors and nurses rush things too much in general. I guess they're paid flat-rate, like mechanics? reply barbazoo 45 minutes agorootparentThey have a million patients. I bet no one on that moment thinks, oh I’m only paid $10.75 for this, I better rush this so I can earn more money. reply ineedaj0b 1 hour agorootparentprevthere's just no time. we have to write down everything you tell us, we have to come off genial, make you sure you aren't lying about something or mistaken, and fix you. reply xattt 2 hours agoparentprev> A single measurement is not sufficient and can result in misdiagnosis. During an acute care stay, a single blood pressure is a drop in the bucket. It averages out on the long term, and it’s not taken out of context of a clinical presentation. I would take pressures manually, question unusual values, repeat on the spot and after some time had passed. reply samstave 27 minutes agoparentprevThis would be the best use of the \"AI Pin\" fiasco of a device; Create an AI pin that takes in all the activity associated with the BP monitoree, including telemtry for environment, movement, and diet. if I had a pin that did this (and recorded all audio for the day, and snapped pictures when I wanted and transcribed all audio via whisper and I had a full searchable day-runner... Yay! reply blackeyeblitzar 1 hour agoparentprevTotally agree and I think the malpractice comes from laziness and a lack of interest in their patients. If they cared, they would do it correctly per the guidelines they hand out to patients themselves! By which I mean these: https://www.heart.org/en/news/2020/05/22/how-to-accurately-m... It is especially bizarre to me when they don’t listen to patients and make medical decisions like deciding prescriptions and dosage amounts based on false readings. reply ineedaj0b 50 minutes agorootparenti don't think it matters too much. we don't want to take it right after you just exercised obviously, but even taking it once is indicative of things. 'i have white coat etc. i have nerves!' these are all things we don't mind seeing. all those those things connect. using up time to double check blood pressure is so/so useful but generally a waste. a patient's labs tell much more, and are better to hedge suspicions against. white coat hypertension at 320lbs!? alright sir we can check again if you like... reply hm-nah 7 minutes agoprevHuge deal for humans moving forward. ~5-8yrs too late for me (2-5yrs for product dev, 3yrs since a hemorrhagic stroke that was likely caused by serious blood pressure). I was 40 at the time and never measured my blood pressure (and certainly never when exercising). After the event I measured it all the time. During the 8th time of sitting in a chair, rolling up my sleeve, I thought, the Apple Watch has BP sensor, right? That question sent me on a quest only to find that humans had not yet figured out a way to measure blood pressure on-the-go. Congratulations on this effort! reply dredmorbius 13 hours agoprevThis approach has been tried before. Bill Softky describes a startup he'd worked for using a similar sound-transduction continuous non-invasive blood-pressure monitoring technique. It ... had problems: Our non-invasive device was supposed to measure blood pressure just as accurately [as an arterial line], but without the cutting, using specially-sculpted sonic vibrations and fancy algorithmic analysis, which was my job. The overall challenge was like measuring the pressure inside a bottle without opening it. Our device worked fine, in that our algorithmically-estimated blood pressure moved up and down, beat to beat, in lockstep with the actual blood pressure. The problem was that our estimate also moved up and down at other times as well, say when the patient moved her fingers, rotated her arm, or took vaso-constricting drugs like nicotine. I spent most of a year understanding these problems, and understanding they couldn’t be solved before our funding ran out. That was when an old-timer taught me an important lesson of measurement: it’s fairly easy to calculate a signal which correlates with what you want to measure, the way our vibration-estimate correlated with actual blood pressure. It’s much harder, though, to calculate a signal which does NOT correlate with what you DON’T want to measure, like arm motion.I'd be exceedingly curious as to how the CalTech team have solved that non-correlation problem. reply mhb 5 hours agoparentPaper: https://academic.oup.com/pnasnexus/article/3/7/pgae252/77177... They tested on the carotid artery. I don't know whether they're concerned with addressing issues of wearing this while active. It seems more likely that it will be used in a clinical setting. reply phkahler 1 hour agorootparentThe article mentions getting it down to an arm band or patch. reply Timothy055 6 hours agoparentprevLooking at the diagram I’d suspect they use accelerometer information from both the wrist watch and the upper arm mounted sensor to remove the effects of arm motion. At simplest it could only check when the arm is in a neutral position. But I’d expect they did something more complex/better than that. reply dredmorbius 3 hours agorootparentAs I understand Softky's work, it's not that the measurements varied predictably with movements, it's that they varied unpredictably. I'm obviously distant from the project, but a team of SWEs spending years trying to make nondeterministic data deterministic suggests a fairly deep problem. reply Mistletoe 4 hours agoparentprevIt’s just a blurb from a college PR team. As someone that came from academia, they don’t have to have solved any of that because these are generally pretty worthless. It can be as small as someone in a lab discovered how to do the smallest thing and the college wants to run with it to look good. reply dredmorbius 1 hour agorootparentI'm aware. Which is why I'm pointing to someone who chased that \"first\" achievement for years, and has the scars to show for it. reply ryukoposting 2 hours agoprevInteresting. I recall working on some devices that implemented something called Pulse Arrival Time [1] which the biomeds on the team told me \"isn't blood pressure, but it can be used for the same purposes.\" Does this technique have an advantage over PAT? How true is the statement that \"PAT can be used for the same purposes?\" [1]: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6912522/ reply pkaye 2 hours agoprevThis believe this blood pressure watch has been approved in a few European countries. It requires you to calibrate against the normal approach every month. I think they are trying to get it approved in the US by next year. https://aktiia.com/ reply queuebert 3 hours agoprevThis is quite an old problem. A quick search of PubMed yields 4834 results for \"noninvasive blood pressure monitoring\". Caltech has a weird definition of \"first\". Edit: To clarify, plenty of things have been tried besides the cuff, but most patients who need something more sophisticated than that are already sick enough to be in the ICU, where an a-line can be placed. This is really a solution in search of a problem. reply Herodotus38 3 hours agoprevAside from the home use, If this could be proven to be just as accurate as arterial lines this would be a huge benefit to patients in the ICU or undergoing major surgery where continuous blood pressure is needed. I hate putting in A-lines. reply _qua 2 hours agoparentIt’s one of my favorite procedures! To each their own I guess. reply kekeblom 3 hours agoprevAktiia has a product on the market which supposedly already does this https://aktiia.com/uk/. It is based on an optical method though. reply trentnix 3 hours agoparentA year or two ago, I interviewed a developer who worked for one of the companies trying to build these types of optical blood pressure sensors. I have high blood pressure so I was keen to learn more. The gist of his message was that even in excellent conditions, it was very inaccurate. reply robomartin 2 hours agoprevI've been thinking a lot about continuos health parameter monitoring lately. For the last 100 days or so I have been running a personal health experiment and collecting multiple data points during the process. I guess some use the term \"bio-hacking\", not sure if it applies. The experiment has included multiple fasting periods, with a maximum of 7 days as well as changing one variable at a time in categories such as diet and exercise. The results have been very interesting and I intend to continue on this path until at least the end of the year. As part of the data collection I have been taking my blood pressure a minimum of twice a day, sometimes more. Also blood glucose, ketones and (consumer) EKG. The first thing that jumped at me was the inaccuracy or variability of these measurements. I even got a Dexcom continuous glucose monitor. Interesting but useless for my purposes. The thing produced 20% error with respect to finger poke measurements. And, then again, when I got a calibration kit to check my finger poke meter, the calibration range is approximately +/- 18%. In other words, unless you hit extremes it feels like these measurements are almost useless. You can kind of tell you are going up or down, yet don't really know where you are. The same, of course, has been true of blood pressure measurements. I went through three consumer machines. I can't say any of it is accurate because there are too many variables. I have run multiple experiments with regards to where and how to measure BP. All I can determine are relative changes by effectively measuring under as close to the same conditions as possible twice a day, morning and evening (both before meals). During the last month or so I have been using a protocol I learned from one of Andrew Huberman's presentations (can't remember which one or I would post a link). I believe he was interviewing a researcher who explained the process they use during their studies. In simple terms, they take three measurements and then average. The first is after 15 minutes sitting, feet on the ground, back supported, no movement, no speaking, no activity. The second and third are at 5 minute intervals under the same conditions. In other words, the entire process takes at least 25 minutes. After adopting this approach I have been seeing wildly different numbers with respect to the single measurement protocol I had been using for two months. In addition to that, the standard deviation of the computed values are much tighter now. This experience, so far, has made me wonder about just how many people might be misdiagnosed and put on medication every year because of bad data. I can see the value in having more data, of course. Yet, continuous data is only good if it is accurate to within a reasonable margin. reply ck2 3 hours agoprevNo they didn't invent the first way The first way has been done in studies for years, maybe even a decade ago. Earlobes. I'll search for the papers later and link them. https://scholar.google.com/scholar?q=earlobe+blood+pressure https://www.todaysmedicaldevelopments.com/article/wearable-b... I've always wanted a Garmin linked ear-cuff device that uses the earlobe for heartrate and blood pressure and then doubles as music playback or alerts from the watch. You could even do body temperature from the earlobe reliably. reply anon115 3 hours agoprevmeowdoesnt the apple watch do this already? or was that just heart rate? reply rrrix1 2 hours agoparentJust heart rate and psuedo \"EKG.\" BP monitoring requires a pressurized cuff which restricts (stops) arterial flow. The readings are the pressure of the cuff as it deflates when the blood starts flowing and when it can no longer be detected. reply jkid 4 hours agoprev [–] https://bodyport.com/ (YCS15). Not continuous, but is non invasive. Given the variability of blood pressure throughout the day… reply oezi 4 hours agoparent [–] This isn't measuring blood pressure, isn't it? reply barbazoo 42 minutes agorootparent [–] And it’s not continuous either. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A Caltech team has developed a noninvasive method called resonance sonomanometry to continually measure true blood pressure using sound waves and ultrasound imaging.",
      "The device, tested in a small clinical study, produced results comparable to standard blood pressure cuffs and can be used in various settings, including hospitals and remote locations.",
      "The new device, developed by Esperto Medical, is small, inexpensive, and offers continuous monitoring, potentially replacing traditional blood pressure cuffs and improving medication dosing precision."
    ],
    "commentSummary": [
      "Caltech has developed the first noninvasive method for continuous blood pressure measurement, addressing common inaccuracies in traditional methods.",
      "This new method aims to provide more consistent and accurate readings, overcoming challenges faced by previous continuous monitoring devices due to movement and other variables.",
      "The innovation could benefit both home users and clinical settings, improving diagnosis and monitoring by offering reliable blood pressure data."
    ],
    "points": 121,
    "commentCount": 37,
    "retryCount": 0,
    "time": 1723261984
  },
  {
    "id": 41206025,
    "title": "Grace Hopper, Nvidia's Halfway APU",
    "originLink": "https://chipsandcheese.com/2024/07/31/grace-hopper-nvidias-halfway-apu/",
    "originBody": "Grace Hopper, Nvidia’s Halfway APU July 31, 2024 clamchowder 2 Comments Nvidia and AMD are the biggest players in the high performance GPU space. But while Nvidia has a huge GPU market share advantage over AMD, the latter’s CPU prowess makes it a strong competitor. AMD can sell both a CPU and GPU as one unit, and that capability has gotten the company wins in consoles and supercomputers. Oak Ridge National Laboratory’s Frontier supercomputer is one such example. There, AMD MI250X GPUs interface with a custom EPYC server CPU via Infinity Fabric. Of course, Nvidia is not blind to this situation. They too have a high speed in-house interconnect, called NVLink. Nvidia has also dabbled with bundling CPUs alongside their GPUs. The Nintendo Switch’s Tegra X1 is a prominent example. But Tegra used relatively small CPUs and GPUs to target low power mobile applications. Grace Hopper is an attempt to get Nvidia’s CPU efforts into high performance territory. Beyond providing server-level CPU core counts and memory bandwidth, Grace Hopper comes with Nvidia’s top-of-the-line H100 datacenter GPU. GH200 rendering from Nvidia, showing the CPU on the left and GPU on the right I’ll be looking at GH200 as hosted on Hydra. GH200 has several variants. The one I’m looking at has 480 GB of LPDDR5X memory on the CPU side, and 96 GB of HBM3 on the GPU side. I’ve already covered Neoverse V2 in Graviton 4, so I’ll focus on implementation differences rather than going over the core architecture again. System Architecture GH200 bundles a CPU and GPU together. The Grace CPU consists of 72 Neoverse V2 cores running at up to 3.44 GHz, supported by 114 MB of L3 cache. Cores and L3 cache sit on top of Nvidia’s Scalable Coherency Fabric (SCF). SCF is a mesh interconnect, with cores and L3 cache slices attached to mesh stops. Mesh layout from Nvidia at https://developer.nvidia.com/blog/nvidia-grace-cpu-superchip-architecture-in-depth/ SCF’s responsibilities include ensuring cache coherency and proper memory ordering. From a core to core latency test, those requirements are satisfied with reasonably consistent latency across the mesh. Latency is generally comparable to Graviton 4’s, which uses Arm’s CMN-700 mesh interconnect. Core to core latency test on Grace’s CPU DRAM access is handled by a 480-bit LPDDR5X-6400 setup, which provides 480 GB of capacity and 384 GB/s of theoretical bandwidth. Graviton 4 opts for a 768-bit DDR5-5200 setup for 500 GB/s of theoretical bandwidth and 768 GB of capacity. Nvidia may be betting on LPDDR5X providing lower power consumption, as DRAM power can count for a significant part of a server’s power budget. GH200’s H100 GPU sits next to the Grace CPU. Even though both are sold as a single unit, it’s not an integrated GPU setup because the two chips have separate memory pools. Opting against an integrated GPU is a sensible decision because CPUs and GPUs have different memory subsystem requirements. CPUs are sensitive to memory latency and want a lot of DRAM capacity. GPUs require high memory bandwidth, but are less latency sensitive. A memory setup that excels in all of those areas will be very costly. GH200 avoids trying to square the circle, and its H100 GPU comes with 96 GB of dedicated HBM3 memory. That’s good for 4 TB/s of theoretical bandwidth, far more than what the LPDDR5X setup can provide. From Intel’s Hot Chips presentation Conceptually, GH200’s design is similar to Intel’s Kaby Lake CPU with AMD’s Radeon RX Vega M graphics. That design also packages the CPU and GPU together as one unit. A 4 GB pool of HBM2 memory gives the GPU high memory bandwidth, while regular DDR4 memory gives the CPU high memory capacity and low latency. GH200 of course does this on a much larger scale on both the CPU and GPU side. From https://developer.nvidia.com/blog/nvidia-grace-hopper-superchip-architecture-in-depth But an integrated GPU design has benefits too, mainly allowing for faster communication between the CPU and GPU. Games don’t require much bandwidth between the CPU and GPU, as long as there’s enough VRAM to handle the game in question. But compute applications are different, and can involve frequent data exchange between the CPU and GPU. Therefore, Nvidia connects the two dies with a high bandwidth proprietary interconnect called NVLink C2C. NVLink C2C offers 900 GB/s of cross-die bandwidth, or 450 GB/s in each direction. That’s an order of magnitude faster than a PCIe Gen 5 x16 link. Besides higher bandwidth, NVLink C2C has hardware coherency support. The CPU can access HBM3 memory without explicitly copying it to LPDDR5X first, and the underlying hardware can ensure correct memory ordering without special barriers. Nvidia is confident enough in their NVLink C2C implementation that HBM3 memory is directly exposed to the CPU side as a NUMA node. Note that remote bandwidth for Grace Hopper is for CPU-owned memory allocated through standard Linux interfaces, which uses the CPU cores for all data transfer and does not make use of CUDA Copy Engines or other acceleration Accessing the HBM3 memory pool across NVLink C2C provides comparable bandwidth to AMD’s current generation Zen 4 servers in a dual socket configuration. It’s a good performance, if a bit short compared to the theoretical figures. Bandwidth is still significantly higher than what AWS can achieve between two Graviton 4 chips, and shows the value of Nvidia’s proprietary interconnect. Bandwidth from Grace’s local LPDDR5X pool is also solid, and on par with AMD’s Bergamo with DDR5-4800. Latency however is poor at nearly 800 ns, even when using 2 MB pages to minimize address translation penalties. That’s a difference of 592 ns compared to accessing directly attached LPDDR5X, which itself doesn’t offer particularly good latency. Part of this is undoubtedly because HBM isn’t a technology designed to offer good latency characteristics. But testing from the H100 GPU shows about 300 ns of DRAM latency, suggesting HBM3 latency is only a minor factor. NVLink C2C therefore appears to have much higher latency than AMD’s Infinity Fabric, or whatever Graviton 4 is using. Intel’s QPI also offers better latency. To make things worse, the system became unresponsive during that latency test run. The first signs of trouble appeared when vi, a simple text editor, took more than several seconds to load. Even weak systems like a Cortex A73 SBC usually load vi instantly. Then, the system stopped responding to all keystrokes over SSH. When I tried to establish another SSH session, it probably got past the TCP handshake stage because it didn’t time out. But the shell never loaded, and the system remained unusable. I eventually managed to recover it by initiating a reboot through the cloud provider, but that sort of behavior is non-ideal. Since GH200 is a discrete GPU, it’s insightful to compare link latency against other discrete GPU setups. Here, I’m using Nemes’s Vulkan uplink latency test, which uses vkMapMemory to map a portion of GPU VRAM into the test program’s address space. Latency is then measured using pointer chasing accesses, just like above. This comparison is more reasonable, and NVLink C2C offers better latency than some discrete GPU configurations. It lands right between setups with AMD’s RX 5700 XT and HD 7950. Latency with that in mind is quite reasonable. However, CPU code will need to be careful about treating HBM3 memory simply as another NUMA node because of its high latency. Grace’s Neoverse V2 Implementation A CPU core architecture’s performance can vary depending on implementation. Zen 4 for example behaves very differently depending on whether it’s in a server, desktop, or mobile CPU. Neoverse V2’s situation is no different, and can vary even more because Arm wants to give implementers as much flexibility as possible.Nvidia Grace Amazon Graviton 4 Arm Neoverse V2 Emulation Environment Clock Speed 3.44 GHz 3.1 GHz base 3.0 GHz all-core SIMD 2.7-2.8 GHz 3 GHz Core Count 72 96 32 L2 Cache Capacity 1 MB 2 MB 2 MB Interconnect Nvidia SCF Arm CMN-700 ARM CMN-700 L3 Cache 114 MB 36 MB 32 MB Main Memory 480 GB LPDDR5X-6400, 480-bit bus 768 GB DDR5-5200, 768-bit bus DDR5-5600, 128-bit bus Grace targets parallel compute applications. To that end, Nvidia opted for a large shared L3 cache and higher clock speeds. Less parallel parts of a workload can benefit from a flexible boost policy, giving individual threads more performance when power and thermal conditions allow. A large L3 might handle better when threads from the same process share data. Graviton 4 on the other hand has to server a lot of customers while maintaining consistent performance. Neoverse V2 cores on Graviton 4 get a larger L2, helping reduce noisy neighbor effects. Low clock speeds minimize workload-dependent thermal or power throttling, Finally, a higher core count lets Amazon fit more of their smallest instances on a single server. A latency test shows the memory hierarchy differences well. Latency in cycles is identical up to L2, because that’s part of the Neoverse V2 core design. Differences start to appear at L3, and do so in dramatic fashion. Large mesh interconnects tend to suffer high latency, and high capacity caches tend to come with a latency cost too. L3 load-to-use latency is north of 125 cycles on Grace. With such a high L2 miss cost, I would have preferred to see 2 MB of L2 cache. Graviton 4 and Intel’s Sapphire Rapids both use 2 MB of L2 cache to counter L3 latency. AMD’s Zen 4 does have a 1 MB L2, but has much lower L2 miss costs. Higher clock speeds do hand Grace an advantage over Graviton 4 when accesses hit L1 or L2. But L3 latency is still sky-high at over 38 ns. Even Intel’s Sapphire Rapids, which also accesses a giant L3 over a giant mesh, does slightly better with 33 ns of L3 latency. L3 cache misses head to Grace’s LPDDR5X controllers. Latency at that point is over 200 ns. Graviton 4’s DDR5 is better at 114.08 ns, putting it in the same ballpark as other server CPUs. Bandwidth Higher clocks mean higher bandwidth, so a Neoverse V2 core in Grace is comfortably ahead of its counterpart in Graviton 4. Cache bandwidth isn’t quite as high as AMD’s, which can be a disadvantage because Nvidia positions Grace as a CPU for highly parallel workloads. Such workloads are likely to be vectorized, and Zen 4 is very well optimized for those cases. Even when both are pulling data from large L3 caches, a Zen 4 core has more bandwidth on tap. To Nvidia’s credit, a single Grace core can pull more bandwidth from L3 than a Graviton 4 core can. This test uses a prefetcher-friendly linear access pattern. I suspect Grace has a very aggressive prefetcher willing to queue up a ton of outstanding requests from a single core. Single core bandwidth is usually latency limited, and a L2 prefetcher can create more in-flight requests even when the core’s out-of-order execution engine reaches its reordering limits. But even the prefetcher can only go so far, and cannot cope with LPDDR5X latency. DRAM bandwidth from a single core is only 21 GB/s compared to Graviton 4’s 28 GB/s. When all cores are loaded, Grace can achieve a cool 10.7 TB/s of L1 bandwidth. L2 bandwidth is around 5 TB/s. Both figures are lower than Graviton 4’s, which makes up for lower clock speeds by having more cores. AMD’s Genoa-X has the best of both worlds, with high per-cycle cache bandwidth, higher clock speeds, and 96 cores. L3 bandwidth is hard to see from this test because Grace and Graviton 4 have a lot of L2 capacity compared to L3. I usually split the test array across threads because testing with a shared array tends to overestimate DRAM bandwidth. Requests from different cores to the same cacheline may get combined at some level. But testing with a shared array does help to estimate Graviton 4 and Grace’s L3 bandwidth. Grace has over 2 TB/s of L3 bandwidth, putting it ahead of Graviton 4’s 750 GB/s. Nvidia wants Grace to serve bandwidth hungry parallel compute applications, and having that much L3 bandwidth on tap is a good thing. But AMD is still ahead. Genoa-X dodges the problem of servicing all cores from a unified cache. Instead, each octa-core cluster gets its own L3 instance. That keeps data closer to the cores, giving better L3 bandwidth scaling and lower latency. The downside is Genoa-X has more than 1 GB of last level cache, and a single core only allocates into 96 MB of it. Some Light Benchmarking In-depth benchmarking is best left to mainstream tech news sites with deeper budgets and full time employees. But I did dig briefly into Grace’s performance. libx264 uses plenty of vector instructions, and can demand a lot of bandwidth. It’s the kind of thing I’d expect Grace to do well at, especially with the test locked to matching core counts. But despite clocking higher, Grace’s Neoverse V2 cores fail to beat Graviton 4’s. 7-Zip is a file compression program that only uses scalar integer instructions. The situation is no better there, and I ran the test several times despite the clock running on cloud instance time. Despite using the same command line parameters, 7-Zip wound up executing 2.58 trillion instructions to finish compressing the test file on GH200. On Graviton 4, the same work took a mere 1.86 trillion instructions. libx264’s instruction counts were similar on both Neoverse V2 implementations, at approximately 19.8 trillion instructions. That makes the 7-Zip situation a bit suspect, so I’ll focus on libx264. …counts cycles in which the core is unable to dispatch instructions from the front end to the back end due to a back end stall caused by a miss in the last level of cache within the core clock domain Arm Neoverse V2 Technical Reference Manual Neoverse V2 has a STALL_BACKEND_MEM performance monitoring event. The description for this event is clear if a bit wordy. Let’s unpack it. L2 is the last level of cache that runs at core clock. Therefore, STALL_BACKEND_MEM only considers stalls caused by L3 and DRAM latency. Dispatching instructions from the frontend to the backend is what the renamer does, and we know the renamer is the narrowest part of Neoverse V2’s pipeline. Therefore, the event is counting L2 miss latency that the out-of-order engine couldn’t absorb. And, throughput lost from those events can’t be recovered by racing ahead later elsewhere in the pipeline. libx264 sees a massive increase in those stalls. Grace’s smaller L2 combined with worse L3 and DRAM latency isn’t a winning combination. Overall lost throughput measured at the rename stage only increased by a few percent. It’s a good demonstration of how Neoverse V2’s large backend can cope with extra latency. But it can’t cope hard enough, nullifying Grace’s clock speed advantage. The same counters in 7-Zip don’t show such a huge discrepancy, though Grace again suffers more from L2 miss latency. Grace’s poor showing in this workload is largely due to 7-Zip somehow executing more instructions to do the same work. 7-Zip and libx264 don’t benefit from Nvidia’s implementation choices, but that doesn’t mean Grace’s design is without merit. The large 114 MB L3 cache looks great for cache blocking techniques, and higher clocks can help speed up less parallel parts of a program. Some throughput bound programs may have prefetcher-friendly sections, which can be aided by Grace’s prefetcher. Specific workloads may do better on Grace than on Graviton 4, particularly if they receive optimizations to fit Grace’s memory subsystem. But that’s beyond the scope of this brief article. H100 On-Package GPU The GPU on GH200 is similar to the H100 SXM variant, since 132 Streaming Multiprocessors (SMs) are enabled out of 144 on the die. VRAM capacity is 96 GB compared to the 80 GB on separately sold H100 cards, indicating that all 12 HBM controllers are enabled. Each HBM controller has a 512-bit interface, so the GH200’s GPU has a 6144-bit memory bus. Even though GH200’s GPU is connected using a higher bandwidth NVLink C2C interface, it’s exposed to software as a regular PCIe device. nvidia-smi indicates GH200 has a 900W power limit. For comparison, H100’s SXM variant has a 700W power limit, while the H100 PCIe makes do with 350-400W. GH200 obviously has to share power between the CPU and GPU, but the GPU may have more room to breathe than its discrete counterparts when CPU load is low. Compared to the PCIe version of the H100, GH200’s H100 runs at higher clocks, reducing cache latency. Otherwise, the H100 here looks a lot like other H100 variants. There’s large L1 cache backed by a medium capacity L2. H100 doesn’t have a gigantic last level cache like RDNA 2, CDNA 3, or Nvidia’s own Ada Lovelace client architecture. But it’s not a tiny cache either like on Ampere or other older GPUs. VRAM latency sees a very substantial improvement, going down from 330 ns to under 300. It’s impossible to tell how much of this comes from higher clock speeds reducing time taken to traverse H100’s on-chip network, and how much comes from HBM3 offering better latency. Bandwidth also goes up, thanks to more enabled SMs and higher clock speeds. Unfortunately, the test couldn’t get past 384 MB. That makes VRAM bandwidth difficult to determine. If things worked though, I assume GH200 would have higher GPU memory bandwidth than discrete H100 cards. Further tests would have been interesting. I wanted to test CPU to GPU bandwidth using the GPU’s copy engine. DMA engines can queue up memory accesses independently of CPU (or GPU) cores, and are generally more latency tolerant. Nemes does have a test that uses vkCmdCopyBuffer to test exactly that. Unfortunately, that test hung and never completed. Checking dmesg showed the kernel complaining about PCIe errors and graphics exceptions. I tried looking up some of those messages in Linux source code, but couldn’t find anything. They probably come from a closed source Nvidia kernel module. Overall, I had a frustrating experience exercising NVLink C2C. At least the Vulkan test didn’t hang the system, unlike running a plain memory latency test targeting the HBM3 memory pool. I also couldn’t use any OpenCL tests. clinfo could detect the GPU, but clpeak or any other application was unable to create an OpenCL context. I didn’t have the same frustrating experience with H100 PCIe cloud instances, where the GPU pretty much behaved as expected with Vulkan or OpenCL code. It’s a good reminder that designing and validating a custom platform like GH200 can be an incredibly difficult task. Final Words Nvidia’s GH200 and Grace CPU is an interesting Neoverse V2 implementation. With fewer cores and a higher power budget, Grace can clock higher than Graviton 4. But rather than providing better per-core performance as specifications might suggest, Grace is likely optimized for specific applications. General consumer workloads may not be the best fit, even well vectorized ones. Previously I thought Arm’s Neoverse V2 had an advantage over Zen 4, because Arm can focus on a narrower range of power and performance targets. But after looking at Grace, I don’t think that captures the full picture. Rather, Arm faces a different set of challenges thanks to their business model. They don’t see chip designs through to completion like AMD and Intel. Those x86 vendors can design cores with a comparatively narrow set of platform characteristics in mind. Arm has to attract as many implementers as possible to get licensing revenue. Their engineers will have a harder time anticipating what the final platform looks like. Arm evaluated Neoverse V2 in an emulation environment that drastically differs from Grace and Graviton 4. Slide from Arm’s Hot Chips 2023 presentation So, Neoverse V2 can find itself having to perform in an environment that doesn’t play nice with its core architecture. Nvidia’s selection of a 1 MB L2, high latency L3, and very high latency LPDDR5X present Neoverse V2 with a spicy challenge. As covered in the Graviton 4 article, Neoverse V2 has similar reordering capacity to Zen 4. I think Zen 4 would also trip over itself with 125 cycles of L3 latency and over 200 ns of memory latency. I don’t think it’s a coincidence that every Zen 4 implementation has a fast L3. Intel is another example, Golden Cove can see 11.8 ns of L3 latency in a Core i7-12700K, or 33.3 ns in a Xeon Platinum 8480+. Golden Cove has much higher reordering capacity, making it more latency tolerant. In a server environment, Golden Cove gets a 2 MB L2 cache as well. GH200’s GPU implementation deserves comment too. It should be the most powerful H100 variant on the market, with a fully enabled memory bus and higher power limits. NVLink C2C should provide higher bandwidth CPU to GPU communication than conventional PCIe setups too. But it’s not perfect. NVLink C2C’s theoretical 450 GB/s is difficult to utilize because of high latency. Link errors and system hangs are a concerning problem, and point to the difficulty of validating a custom interconnect. Exposing VRAM to software as a simple NUMA node is a good north star goal, because it makes VRAM access very easy and transparent from a software point of view. But with current technology, it might be a bridge too far. NVLink provides a high speed cross-node interconnect too for cluster setups. From https://developer.nvidia.com/blog/inside-nvidia-grace-cpu-nvidia-amps-up-superchip-engineering-for-hpc-and-ai/ Even though it’s not an iGPU, Grace Hopper might be Nvidia’s strongest shot at competing with AMD’s iGPU prowess. Nvidia has already scored a win with Amazon and the UK’s Isambard-AI supercomputer. AMD’s MI300A is shaping up to be tough competition, with a win in Lawrence Livermore National Laboratory’s upcoming El Capitan supercomputer. MI300A uses an integrated GPU setup, which speeds up CPU to GPU communication. However, it limits memory capacity to 128 GB, a compromise that Nvidia’s discrete GPU setup doesn’t need to make. It’s good to see Nvidia and AMD competing so fiercely in the CPU/GPU integration space, and it should be exciting to see how things play out. If you like our articles and journalism, and you want to support us in our endeavors, then consider heading over to our Patreon or our PayPal if you want to toss a few bucks our way. If you would like to talk with the Chips and Cheese staff and the people behind the scenes, then consider joining our Discord. Author clamchowder View all posts Don’t miss our articles! Email Address * Related Posts",
    "commentLink": "https://news.ycombinator.com/item?id=41206025",
    "commentBody": "Grace Hopper, Nvidia's Halfway APU (chipsandcheese.com)109 points by PaulHoule 20 hours agohidepastfavorite63 comments erulabs 10 hours agoIf AI remains in the cloud, nvidia wins. But I can’t help but think that if AI becomes “self-hosted”, if we return to a world where people own their own machines, AMDs APUs and interconnect technology will be absolutely dominant. Training may still be Nvidias wheelhouse, but for a single device able to do all the things (inference, rendering, and computing), AMD, at least currently, would seem to be the winner. I’d love someone more knowledgeable in AI scaling to correct me here though. Maybe that’s all far enough afield to make the current state of things irrelevant? reply wmf 2 hours agoparentYou may be seeing something that isn't there. I don't even know if MI300A is available to buy, what it costs, or if you'll be forced to buy four of them which would push prices close to DGX territory anyway. reply passion__desire 6 hours agoparentprevIf compute is gonna play the role of electricity in coming decades, then having a compute wall similar to Tesla powerwall is a necessity. reply rbanffy 56 minutes agorootparentPowerwall makes sense because you can’t generate energy at any time and, therefore, you store it. Computers are not like that - you don’t “store” computations for when you need them - you either use capacity or you don’t. That makes it practical to centralise computing and only pay for what you use. reply jfoutz 17 minutes agorootparentI was going to make a pedantic argument/joke about memoization. It is kind of an interesting thought though. A big wall of SSD is a fabulous amount of storage. and maybe a clever read only architecture, would be cheaper than SSD. and a clever data structure for shared high order bits, maybe, maybe there is potential for some device to look up matrix multiply results, or close approximations that could be cheaply refined. Right now, I doubt it. But big static cache it is a kind of interesting idea to kick around Saturday afternoon. reply CooCooCaCha 2 hours agorootparentprevPowerwall and electric car in the garage, compute wall in the closet, 3d printer and other building tools in the manufacturing room, hydroponics setup in the indoor farm room, and AI assistant to help manage it all. The home becomes a mixed living area and factory. reply crowcroft 1 hour agorootparentThe vision of this sounds so cool, but man, for a lot of use cases at the moment most 'smart home' stuff is still complicated and temperamental. How do we get from here to there, cause I want to get there so bad. reply ta988 3 hours agorootparentprevOnly if improvements in speed and energy savings slow down reply CooCooCaCha 2 hours agorootparentAnd if models don't get any larger, which they will reply teaearlgraycold 8 hours agoparentprevYou need orders of magnitude more compute for training than for inference. Nvidia still wins in your scenario. Currently rendering and local GPGPU compute is Nvidia dominated and I don’t see AMD competently going after the market segments. reply demaga 8 hours agorootparentBut you also run inference orders of magnitudes more times, so it should still amount to more compute than training? reply teaearlgraycold 7 hours agorootparentThat matters more to the electricity company than the silicon company. The profit margins on the datacenter training hardware are stupidly high compared to an AMD APU. reply binary132 7 hours agorootparentIf there are tens of thousands of training GPUs but billions of APUs, then what? BTW, training is such a high cost that it seems like a major motive for the customer to reduce costs there. reply k__ 2 hours agorootparentThis. Most will probably use something like Llama as base. reply talldayo 2 hours agorootparentprev> If there are tens of thousands of training GPUs but billions of APUs, then what? Believe it or not, we've actually been grappling with this scenario for almost a decade at this point. Originally the answer was to unite hardware manufacturers around a common featureset that could compete with (albeit not replace) CUDA. Khronos was prepared to elevate OpenCL to an industry standard, but Apple pulled their support for it and let the industry collapse into proprietary competition again. I bet they're kicking themselves over that one, if they still hold a stronger grudge against Nvidia than Khronos at least. So - logically, there's actually a one-size-fits-all solution for this problem. It was even going to get managed by the same people handling Vulkan. The problem was corporate greed and shortsighted investment that let OpenCL languish while CUDA was under active heavy development. > BTW, training is such a high cost that it seems like a major motive for the customer to reduce costs there. Eh, that's kinda like saying \"app development is so expensive that consumers will eventually care\". Consumers just buy the end product; they are never exposed to building the software or concerned with the cost of the development. This is especially true with businesses like OpenAI that just give you free access to a decent LLM (or Apple and their \"it's free for now\" mentality). reply mistercow 6 hours agorootparentprevI think this is the big point of uncertainty in Nvidia’s future: will we find new training techniques which require significantly less compute, and/or are better suited to some fundamentally different architecture than GPUs? I’m reluctant to bet no on that long term, and “long term” for ML right now is not very long. reply brigadier132 2 hours agorootparentIf we find a new training technique that is that much more efficient why do you think we wont just increase the amount of training we do be n times? (or even more since it's now accessible to train custom models for smaller businesses) reply mistercow 2 hours agorootparentWe might, but it’s also plausible that it would change the ecosystem so much that centralized models are no longer so prominent. For example, suppose that with much cheaper training, most training is on your specific data and behaviors so that you have a model (or ensemble of models) tailored to your own needs. You still need a foundation model, but those are much smaller so that they can run on device, so even with overparameterization and distillation, the training costs are orders of magnitude smaller. Or, in the small business case (mind you, “long term” for tech reaching small businesses is looooong), these businesses again need much smaller models because a) they don’t need a model well versed in Shakespeare and multi variable calculus, and b) they want inference to be as low cost as possible. These are just scenarios off the top of my head. The broader point is that a dramatic drop in training cost is a wildcard whose effects are really hard to predict. reply moffkalast 6 hours agoparentprevNvidia still has 12-16GB VRAM offerings for around $300-400, which are exceptionally well optimized and supported on the software side. Still by far the most cost effective option if you also value your time imo. The Strix Halo better have high tier Mac level bandwidth plus ROCm support and be priced below $1k or it's just not competitive with that because it'll still be slower than even partial cuda offloading. reply sirlancer 1 hour agoprevIn my tests of a Supermicro ARS-111GL-NHR with a Nvidia GH200 chipset, I found that my benchmarks performed far better with the RHEL 9 aarch64+64k kernel versus the standard aarch64 kernel. Particularly with LLM workloads. Which kernel was used in these tests? reply MobiusHorizons 17 hours agoprevI am really surprised to see the performance of the CPU and especially the latency characteristics are so poor. The article alludes to the design likely being tuned for specific workloads, which seems like a good explanation. But I can't help wonder if throughput at the cost of high memory latency is just not a good strategy for CPUs even with the excellent branch predictors and clever OOO work that modern CPUs bring to the table. Is this a bad take? Are we just not seeing the intended use-case where this thing really shines compared to anything else? reply freeqaz 11 hours agoparentWhat's the point of having the GPU on die for this? Are they expecting people to deploy one of these nodes without dedicated GPUs? It has a ton of NVLink connections which makes me think that these will often be deployed alongside GPUs which feels weird. The flip side of this is if the GPU can access the main system memory then I could see this being useful for loading big models with much more efficient \"offloading\" of layers. Even though bandwidth between GPU->LPDDR5 is going to be slow, it's still faster than what traditional PCI-E would allow. The caveat here is that I imagine these machines are $$$ and enterprise only. If something like this was brought to the consumer market though I think it would be very enticing. (If anybody from AMD is reading this, I feel like an architecture like this would be awesome to have. I would love to run Llama 3.1 405b at home and today I see zero path towards doing that for any \"reasonable\" amount of money ( The downside is Genoa-X has more than 1 GB of last level cache, and a single core only allocates into 96 MB of it. I wonder if AMD could license the IBM Telum cache implementation where one core complex could offer unused cache lines to other cores, increasing overall occupancy. Would be quite neat, even if cross-complex bandwidth and latency is not awesome, it still should be better than hitting DRAM. reply tedunangst 19 hours agoprevIrrelevant, but the intro reminded me that nvidia also used to dabble in chipsets like nforce, back when there was supplier variety in such. reply MegaDeKay 15 hours agoparentOne place you'll find said chipset is in the OG XBox, where they provided the Southbridge \"MCPX\" chip as well as the GPU. https://classic.copetti.org/writings/consoles/xbox/#io reply m463 14 hours agoparentprevI think that stopped when intel said nvidia couldn't produce chipsets for some cpu architecture they were coming out with. I don't know if this was market savvy or a footshoot that made their ecosystem weaker. reply wtallis 11 hours agorootparentThe transition point was when Intel moved the DRAM controller and PCIe root complex onto the CPU die, merging in the northbridge and leaving the southbridge as the only separate part of the chipset. The disappearance of the Front Side Bus meant Intel platforms no longer had a good place for an integrated GPU other than on the CPU package itself, and it was years before Intel's iGPUs caught up to the Nvidia 9400M iGPU. In principle, Nvidia could have made chipsets for Intel's newer platforms where the southbridge connects to the CPU over what is essentially four lanes of PCIe, but Intel locked out third parties from that market. But there wasn't much room for Nvidia to provide any significant advantages over Intel's own chipsets, except perhaps by undercutting some of Intel's product segmentation. (On the AMD side, the DRAM controller was on the CPU starting in 2003, but there was still a separate northbridge for providing AGP/PCIe, with a relatively high-speed HyperTransport link to the CPU. AMD dropped HT starting with their APUs in 2011 and the rest of the desktop processors starting with the introduction of the Ryzen family.) reply jauntywundrkind 16 hours agoparentprevSoundStorm vs Dolby is such a turning point story. Nvidia had a 5 billion op/s DSP and Dolby digital encoding on that chipset. Computers were coming into their own as powerful universal systems that could do anything. Then Dolby cancelled the license. To this day you still need very fancy sound cards or exotic motherboards to be able to output good surround sound to a large number of av receivers. There are some open DTS standards that Linux can do too, dunno about windows/Mac. But it just felt like we slid so far down, that Dolby went & made everything so much worse. (Media software can do Dolby pass-through to let the high quality sound files through, yes. But this means you can't do any effect processing, like audio normalization/compression for example. And if you are playing games your amp may be getting only basic low quality surround surround, not the good many channel stuff.) reply izacus 10 hours agorootparentI'm bit confused about your last paragraph - what's low quality about Dolby Atmos / DTS:X output you get for games these days? reply throwaway81523 13 hours agorootparentprevDo you mean AC3? Ffmpeg has been able to do that since forever. https://en.wikipedia.org/wiki/Dolby_Digital reply jauntywundrkind 13 hours agorootparentTheres some debate about what patents apply, but even Dolby had to admit defeat as of 2017. So yes, a 640kbit/s 6 channel format is available for encoding on ffmpeg & some others. I don't know if games are smart enough to use this? It also feels like a very low bar. It's not awful bitrate for 6 channels but neither is it great. It's not a pitiful number of channels but again neither is it great. Last & most crucially, just because one piece of software can emit ac3 doesn't make it particularly useful for a system. I should be able to have multiple different apps doing surround sound, sending notifications to back channels or panning sounds as I prefer. Yes ffmpeg can encode 5.1 media audio to an AVR but that doesn't really substitute for an actual surround system. This is more a software problem, now that the 5.1 AC3 patents are expired. And there have been some stacks in the past where this worked on Linux for example. But it seems like modern hardware (with a Sound Open Firmware) has changed a bit and PipeWire needs to come up with a new way of doing ac3/a52 encoding. https://gitlab.freedesktop.org/pipewire/pipewire/-/issues/32... reply waynecochran 7 hours agoprevSide note: The acronym APU was used in the title but not once defined or referenced in the article? reply layer8 6 hours agoparentIt’s an established term (originally by AMD) for a combination of CPU and GPU on a single die. In other words, it’s a CPU with integrated accelerated graphics (iGPU). APU stands for Accelerated Processing Unit. Nvidia’s Grace Hopper isn’t quite that (it’s primarily a GPU with a bit of CPU sprinkled in), hence “halfway” I guess. reply falcor84 7 hours agoparentprevHere's my reasoning of what an APU is based on letter indices: if A is 1, C is 3 and G is 7, then to get an APU, you need to do what it takes to go from GPU to a CPU, and then apply an extra 50% effort. reply sebastiennight 5 hours agorootparentThis... is technically wrong, but it's the best kind of wrong. reply astromaniak 1 hour agoprevThis is good for datacenters, but.. NVidia stopped doing anything for consumers market. reply alexhutcheson 5 hours agoprevSomewhat tangential, but did Nvidia ever confirm if they cancelled their project to develop custom cores implementing the ARM instruction set (Project Denver, and later Carmel)? It’s interesting to me that they’ve settled on using standard Neoverse cores, when almost everything else is custom designed and tuned for the expected workloads. reply adrian_b 3 hours agoparentAlready in Nvidia Orin, which has replaced Xavier (with Carmel cores) a couple of years ago, the CPU cores have been Cortex-A78AE. So Nvidia has given up on designing CPU cores, already for some years. The Carmel core had a performance similar to Cortex-A75, even if it was launched by the time when Cortex-A76 was already available. Moreover, Carmel had very low clock frequencies, which diminished its performance even more. Like also Qualcomm or Samsung, Nvidia has not been able to keep up with the Arm Holdings design teams. (Now Qualcomm is back in the CPU design business only because they have acquired Nuvia.) reply jokoon 4 hours agoprevIt always made sense to have a single chip instead of 2, I just want to buy a single package with both things on the same die. That might make things much simpler for people who write kernel, drivers and video games. The history of CPU and GPU prevented that, it was always more profitable for CPU and GPU vendors to sell them separately. Having 2 specialized chips makes more sense because it's flexible, but since frequencies are stagnating, having more cores make sense, and AI means massively parallel things are not only for graphics. Smartphones are much modern in that regard. Nobody upgrades their GPU or CPU anymore, might as well have a single, soldered product that last a long time instead. That may not be the end of building your own computer, but I just hope it will make things simpler and in a smaller package. reply tliltocatl 3 hours agoparentIt's not about profit, it's about power and pin budget. Proper GPU needs lots of memory bandwidth=lots of memory-dedicated pins (HBM kinda solves this, but has tons of other issues). And on power/thermal side having two chips each with dedicated power circuits, heatsinks and radiators is always better then one. The only reason NOT to have to chips is either space (that's why we have integrated graphics and it sucks performance-wise), packaging costs (not really a concern for consumer GPU/CPU where we are now) or interconnect costs (but for both gaming and compute CPU-GPU bandwith is negligible compared to GPU-RAM). reply bmacho 11 hours agoprev> The first signs of trouble appeared when vi, a simple text editor, took more than several seconds to load. Can it run vi? reply dagmx 14 hours agoprevThe article talks about the difference in the pre-fetcher between the two neoverse setups (Graviton and Grace Hopper). However isn’t the prefetcher part of the core design in neoverse? How would they differ? reply MobiusHorizons 3 hours agoparentI believe the difference is in the cache hierarchy (more l3 less l2) and generally high latency to dram even higher latency to hbm. This makes the prefetcher behave differently between the two implementations, because the l2 cache isn’t able to absorb the latency reply dagmx 3 hours agorootparentThat was my initial read but they have this line which made me wonder if it was somehow more than that > I suspect Grace has a very aggressive prefetcher willing to queue up a ton of outstanding requests from a single core. reply rkwasny 12 hours agoprevYeah so I also benchmarked GH200 yesterday and I am also a bit puzzled TBH: https://github.com/mag-/gpu_benchmark reply adrian_b 2 hours agoparentI suggest that wherever you write \"TFLOPS\", you should also write the data type for which they were measured. Without knowing whether the operations have been performed on FP32 or on FP16 or on another data type, all the numbers written on that page are meaningless. reply benreesman 9 hours agoprev [–] I’m torn: NVIDIA has a fucking insane braintrust of some of the most elite hackers in both software and extreme cutting edge digital logic. You do not want to meet an NVIDIA greybeard in a dark alley, they will fuck you up. But this bullshit with Jensen signing girls’ breasts like he’s Robert Plant and telling young people to learn prompt engineering instead of C++ and generally pulling a pump and dump shamelessly while wearing a leather jacket? Fuck that: if LLMs could write cuDNN-caliber kernels that’s how you would do it. It’s ok in my book to live the rockstar life for the 15 minutes until someone other than Lisa Su ships an FMA unit. The 3T cap and the forward PE and the market manipulation and the dated signature apparel are still cringe and if I had the capital and trading facility to LEAP DOOM the stock? I’d want as much as there is. The fact that your CPU sucks ass just proves this isn’t about real competition just now. reply almostgotcaught 9 hours agoparent [–] Sir this is a Wendy's reply benreesman 9 hours agorootparent [–] This is Y-Combinator. Garry Tan is still tweeting embarrassing Utopianism to faint applause and @pg is still vaguely endorsing a rapidly decaying pseudo-argument that we’re north of securities fraud. At Wendy’s I get a burger that’s a little smaller every year. On this I get Enron but smoothed over by Dustin’s OpenPhilanthropy lobbyism. I’ll take the burger. edit: tinygrad IS brat. YC is old and quite weird. reply defrost 8 hours agorootparent [–] Hell to the Yeah, it's filled with old weird posts: https://news.ycombinator.com/item?id=567736 reply benreesman 8 hours agorootparent [–] I’m not important enough to do opposition research on, it bewilders me that anyone cares. I was 25 when I apologized for trolling too much on HN, and frankly I’ve posted worse comments since: it’s a hazard of posting to a noteworthy and highly scrutinized community under one’s own name over decades. I’d like to renew the apology for the low-quality, low-value comments that have happened since. I answer to the community on that. To you specifically, I’ll answer in the way you imply to anyone with the minerals to grow up online under their trivially permanent handle. My job opportunities and livelihood move up and down with the climate on my attitudes in this forum but I never adopted a pseudonym. In spite of your early join date which I respect in general as a default I remain perplexed at what you’ve wagered to the tune of authenticity. reply benreesman 8 hours agorootparentIt’s my hope that this thread is over. You joined early, I’ve been around even longer. You can find a penitent post from me about an aspiration of higher quality participation, I don’t have automation set up to cherry-pick your comments in under a minute. My username is my real name, my profile includes further PII. Your account looks familiar but if anyone recognizes it on sight it’s a regime that post-dates @pg handing the steering wheel to Altman in a “Battery Club” sort of way. With all the respect to a fellow community member possible, and it’s not much, kindly fuck yourself with something sharp. reply defrost 8 hours agorootparentErr .. you getting enough sleep there? reply defrost 8 hours agorootparentprev [–] There's no drama as far as I'm concerned, I got a sensible chuckle from your comment & figured it deserved a tickle in return; the obvious vector being anyone here since 2008 has earned a tweak for calling the HN crowd 'old' (something many can agree with). My \"opposition research\" was entirely two clicks, profile (see account age), Submissions (see oldest). As for pseudonym's, I've been online since Usenet and have never once felt the need to advertise on the new fangled web (1.0, 2.0, or 3), handles were good enough for Ham Radio, and TWKM - Those Who Know Me Know Who I Am (and it's not at all that interesting unless you like yarns about onions on belts and all that jazz). reply benreesman 8 hours agorootparent [–] I’m pretty autistic, after haggling with Mistral this is what it says a neurotypical person would say to diffuse a conflict: I want to apologize sincerely for my recent comments, particularly my last response to you. Upon reflection, I realize that my words were hurtful, disrespectful, and completely inappropriate, especially given the light-hearted nature of your previous comment. I am truly sorry for any offense or harm I may have caused. Your comment was clearly intended as a friendly jest, and I regret that I responded with such hostility. There is no excuse for my behavior, and I am committed to learning from this mistake and ensuring it does not happen again. I also want to address my earlier comments in this thread. I now understand that my attempts to justify my past behavior and dismiss genuine concerns came across as defensive and disrespectful. Instead of taking responsibility for my actions, I tried to deflect and downplay their impact, which only served to escalate the situation. I value this community and the opportunity it provides for open dialogue and growth. I understand that my actions have consequences, and I am determined to be more mindful, respectful, and considerate in my future interactions. I promise to strive for higher quality participation and to treat all members of this community with the kindness and respect they deserve. Once again, I am truly sorry for my offensive remarks and any harm they may have caused. I appreciate the understanding and patience you and the community have shown, and I hope that my future actions will reflect my commitment to change and help rebuild any trust that may have been lost. reply defrost 8 hours agorootparent [–] Cheers for that, it's a good apology. Again, no drama - my sincere apologies for inadvertently poking an old issue, there was no intent to be hurtful on my part. I have a thick skin, I'm Australian, we're frostily polite to those we despise and call you names if we like you - it can be offputting to some. :) reply benreesman 7 hours agorootparent [–] The best hacker I know is from Perth, I picked up the habit of the word “legend” as a result. You’ve been a good sport legend. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Nvidia and AMD are leading the high-performance GPU market, with AMD leveraging its CPU capabilities to compete effectively.",
      "Nvidia's new Grace Hopper (GH200) combines a server-level CPU with its top-tier H100 datacenter GPU, featuring 72 Neoverse V2 cores, 480 GB of LPDDR5X memory, and 96 GB of HBM3 memory.",
      "GH200 aims to compete with AMD’s MI300A, showcasing Nvidia's strong entry into the CPU/GPU integration space, despite some performance issues and system instability during testing."
    ],
    "commentSummary": [
      "Nvidia's Grace Hopper APU (Accelerated Processing Unit) is a hybrid chip combining CPU and GPU capabilities, aimed at specific workloads like AI and data centers.",
      "The discussion highlights a potential shift in AI computing from cloud-based to self-hosted solutions, where AMD's APUs might have an edge due to their interconnect technology.",
      "The article raises questions about Nvidia's strategy and performance, particularly in terms of memory latency and the practical use cases for the Grace Hopper APU."
    ],
    "points": 109,
    "commentCount": 63,
    "retryCount": 0,
    "time": 1723243933
  },
  {
    "id": 41207417,
    "title": "Hal Hickel on Creating Tarkin for Rogue One",
    "originLink": "http://fxrant.blogspot.com/2024/06/hal-hickel-on-creating-tarkin.html",
    "originBody": "FXRant A blogtacular blog filled with words, images, and whipped cream on top. Written by Todd Vaziri. Sunday, June 23, 2024 Hal Hickel on Creating Tarkin Back in 2020, Hal Hickel answered a Quora question with great detail about how we created Grand Moff Tarkin for \"Rogue One\" (2016), and in the interest of film history preservation, I got Hal's permission to reprint it here. (I was a lead on the digital human team at ILM for Tarkin, and worked closely with Hal on the film.) Hal summarizes our process succinctly, and corrects many misconceptions and untruths about how we made Tarkin, so I feel like this is an important document. To be frank, I hesitate to talk publicly too much about our Tarkin and Leia work for \"Rogue One\" because for some folks it generates a lot of... emotion. I, like Hal, have no interest in defending the quality of our work. I'll say this: immediately after the movie came out, I talked to a lot of regular, non-industry people who saw the movie and asked them their thoughts on Tarkin, 'you know, the older gentleman who was Krennic's boss.' Many folks didn't understand the nature of my question, nor why I was asking it. They liked his performance, and didn't think anything further of it. Then I let them know that Tarkin is a digital creation, meant to resemble Peter Cushing who appeared in the original \"Star Wars\" (1977) and who died in 1994. I got a lot of stunned reactions from relaying that news. A lot of people who saw \"Rogue One\" had no idea that Tarkin was a digital, synthetic character, and just assumed it was a regular human actor. I hope you like Hal's piece. . . . . Quora: Why does Tarkin's CGI in Rogue One look so plastic-y? Could they have made it look more realistic? Answered by Hal Hickel, Animation Supervisor for \"Rogue One\" Hi, I was the animation supervisor on Rogue One, and as such I was intimately involved with the creation of Tarkin. I’ve decided to chime in for one purpose only, to clarify the process we used. I have no interest in trying to convince anyone to like the results more than they do, or to argue with anyone about how “real” our work looked in the film. Again, I just want to clarify our process for informational purposes. The broad plan was to hire an actor, film them on set in costume, and just replace the head with a CG Tarkin head, leaving the real body in the scene. The actor on set would be wearing a helmet with small cameras mounted to it, to record their facial performance (similar to what you’ve seen in the behind the scenes footage from Avatar, or Planet of the Apes). That’s what we did, excepting that in about 30% of the shots, we opted for full replacement (head and body) with CG, because for certain shots it just made more sense. Guy Henry was cast because he’s a terrific actor, and had the bearing and vocal quality we were looking for. It was helpful that he also had a certain physical resemblance (high cheekbones, etc), though that was not essential, given that the plan was to completely replace his head with our CG Tarkin. That said, when remapping the facial expressions of one person onto another (Henry to Cushing), the more similar they are, the easier it’s going to be. The intention was never for Guy to do either a vocal, or physical “impression” of Peter Cushing, but rather to give us a performance that “felt” like Tarkin, both physically and vocally. So we never asked for, or expected a spot on vocal match, or for Guy to smirk, etc, like Cushing. We didn’t do any modulation or any other audio tricks with Henry’s voice. We didn’t compare waveforms with Cushing audio, talk to his old manager, or any of that other stuff mentioned elsewhere in this thread. We just used Guy Henry’s voice. I’m sure Guy watched the Tarkin scenes from ANH endlessly, and did his best to find a tone and delivery that felt right. Guy didn’t wear any prosthetics or makeup as part of the process, with the exception of the dots that help us track his facial movement. Someone in this thread talked about “makeup, cosmetics, physical altering”. No. Again, we just put dots on Guy’s face to track it’s movement, that’s all. Guy was filmed on set, in the costume. The movement of the dots on his face, and his voice were recorded simultaneously during filming. I mention this, because some VFX companies prefer a method where Facial Capture is done separately, on a specialized stage at a later time. We prefer to capture an actor’s performance all at once (voice, body, face) whenever possible. We also scanned Guy Henry on the ICT Light Stage, to give us a high resolution CG model of Guy Henry, and to capture his skin texture. Now why would we need a CG Guy Henry? The CG version of Guy Henry (left) and the real Guy Henry as photographed (right), from Rogue One - A Star Wars Story: The Princess & The Governor Featurette We needed it for a few reasons: One is that once we’ve tracked the motion of the dots on his face in a given piece of performance, rather than immediately applying that motion data to the CG Tarkin, we instead apply it first to the CG Guy Henry. This give us an apples to apples comparison to see if we’ve captured and processed the facial performance accurately. When we’re satisfied that we have, we then apply it to Tarkin. Another reason, is that having the lighting data that is captured with Guy Henry on the Light Stage, gives us a sort of “ground truth” that we can compare our CG Tarkin to, to see if his skin is reacting to light realistically. Also, because there are many things about the fine details of Guy Henry’s skin that are appropriate for Tarkin’s skin (general tone, pores, etc), we can use the Guy Henry textures as a way to get a leg up on the Tarkin skin textures, rather than starting from zero. Ok, so we’ve hired an actor, and shot them on location. We’ve built a CG copy of that actor in order to be able to check out facial capture data to see that it’s accurate, and to give us a “ground truth” for the skin texture and lighting. Now we (obviously) have to build a CG Tarkin. I noticed some comments in another answer in this thread about his mouth “not being aligned to his chin”, or the ears being “too long”. Again, I’m not here to argue the merits of our work, but I think it’s useful to point out that if you assembled hundreds of photographs of Peter Cushing (as we did), you would find that he can look vastly different from one photograph to another, depending on his expression, the lighting, the makeup, the focal length of the lens, the year the photo was taken, etc etc. So comparing a single frame of our Tarkin to a single photo of Cushing is not a particularly valid way to troubleshoot whatever issues there may be. Luckily, we didn’t have to work from just photos. We had in our possession a life casting of Peter Cushing’s face. It was made not long after New Hope, so it was very accurate in terms of Cushing’s age, etc. Of course we know that sometimes the process of taking a life cast can slightly distort the face of the subject (the weight of the casting material can pull down on the skin), so we were mindful of that. That casting was a terrific starting point for us, and gave us very accurate information. Starting from there, a very accurate CG model of Tarkin was created. As well, highly detailed textures, with pore detail, age spots, veins, etc etc. The CG hair groom was challenging, as the styling on Cushing for that role was a bit eccentric. So taking one shot from the film as an example, let’s say a medium close up: We track the movement of Guy’s head through space, so we can move the CG Tarkin head in the same way. We track the dot motion on Guy’s face to extract his facial performance. We apply that motion to the CG Guy Henry, and if we’re happy with how it looks, we apply it to the CG Tarkin. By the way, someone in this thread theorized that perhaps the CG Tarkin was missing “micro expressions”. While we are always trying to increase the accuracy, and detail of our Facial Capture system, I have to say that even now, we are capturing very fine detail, including very tiny, barely perceptible micro movements. We are familiar with Paul Ekman’s work, and the importance of Micro Expressions, and have tried hard to be sure that level of fidelity exists in our work. If it was happening on Guy Henry’s face, it was happening on Tarkin’s face. Now we have the real Guy Henry body, with the CG Tarkin head. We paint out any bits of Henry’s head that Tarkin doesn’t cover up. We make adjustments to the facial performance to make it feel more “Tarkin”, since (unsurprisingly), Guy Henry doesn’t use his facial muscles the same way that Peter Cushing did. Guy doesn’t smile like Cushing, doesn’t form phonemes like Cushing, etc. So we have to do a sort of “motion likeness” pass. This is done by our animators, using a very light touch. Note: the point is NOT to change the acting choices made by Guy Henry, it’s just to adjust things so that when Guy chooses to smile, it looks like a Tarkin smile, not like a Guy Henry smile. Of course in doing so, we have to be very careful to maintain exactly what sort of smile it is. We don’t want to transform a mocking, insincere smile into a genuine, warm smile. The Tarkin head with final facial performance is lit to match the lighting in the footage, and rendered. The rendered CG Tarkin head is composited onto the real Guy Henry body. There are of course many many steps to each one of the steps I’ve outlined above. Each one of these steps encompasses the highly skilled work of many many very talented artists and technicians. So again, like it, don’t like it, that’s none of my business. I just wanted to get the facts out there, in terms of our process, because there was some inaccurate information being posted. Thanks for reading. H Posted by Todd Vaziri at 6/23/2024 03:50:00 PM Labels: Rogue One, Tarkin No comments: Post a Comment Older Post Home Subscribe to: Post Comments (Atom) FXRant by Todd Vaziri Todd Vaziri Links tvaziri.com Todd Vaziri's Home Page Todd Vaziri's IMDB Page Todd Vaziri on Twitter About Me Todd Vaziri tvaziri.com - my name is todd vaziri and make movies and talk about movies a lot. mail me feedback at tvaziri@tvaziri.com. View my complete profile tvaziri on Twitter Blog Archive ▼ 2024 (9) ▼ June (4) Hal Hickel on Creating Tarkin Lighting Techniques and Style The Apple HomePod \"Welcome Home\" Ad was NOT 'All P... Studios: Please Don't Spoil The Movie We Are Seate... ► April (1) ► March (1) ► February (2) ► January (1) ► 2023 (25) ► December (1) ► November (1) ► October (1) ► August (1) ► July (2) ► May (2) ► April (1) ► March (3) ► February (5) ► January (8) ► 2022 (9) ► December (2) ► November (2) ► October (3) ► March (2) ► 2021 (6) ► May (1) ► April (2) ► March (1) ► February (2) ► 2020 (4) ► November (3) ► January (1) ► 2019 (16) ► November (3) ► October (1) ► March (4) ► February (3) ► January (5) ► 2018 (36) ► December (5) ► November (3) ► October (1) ► September (15) ► August (2) ► July (1) ► June (1) ► March (1) ► February (3) ► January (4) ► 2017 (16) ► November (1) ► September (1) ► May (1) ► April (1) ► March (1) ► February (7) ► January (4) ► 2016 (15) ► December (1) ► August (1) ► April (1) ► March (2) ► February (5) ► January (5) ► 2015 (24) ► December (4) ► September (1) ► August (2) ► July (2) ► June (1) ► May (1) ► March (2) ► February (6) ► January (5) ► 2014 (20) ► December (2) ► November (1) ► October (2) ► September (1) ► May (1) ► April (1) ► March (3) ► February (4) ► January (5) ► 2013 (22) ► December (3) ► August (1) ► July (1) ► June (2) ► May (3) ► March (3) ► February (6) ► January (3) ► 2012 (23) ► December (2) ► November (1) ► September (1) ► August (2) ► July (1) ► June (2) ► March (1) ► February (10) ► January (3) ► 2011 (23) ► December (2) ► October (8) ► July (1) ► April (1) ► March (4) ► February (4) ► January (3) ► 2010 (34) ► November (1) ► October (1) ► August (2) ► July (7) ► May (5) ► March (6) ► February (2) ► January (10) ► 2009 (30) ► December (4) ► November (3) ► October (1) ► August (2) ► July (1) ► June (2) ► May (6) ► April (3) ► February (4) ► January (4) ► 2008 (47) ► December (2) ► November (4) ► October (1) ► August (3) ► July (1) ► June (8) ► May (5) ► April (3) ► March (7) ► February (4) ► January (9) ► 2007 (101) ► December (4) ► November (4) ► October (8) ► September (3) ► August (14) ► July (31) ► June (12) ► May (6) ► April (5) ► March (2) ► February (5) ► January (7) ► 2006 (10) ► December (9) ► November (1) Labels visual effects (117) film (109) Academy Awards (94) ILM (81) Transformers (52) predicting the oscar (43) predictinator (38) VES Awards (24) camera movement (22) Stephen Colbert (21) Transformers Review (21) cinematography (18) podcast (18) The Colbert Report (17) Oscar Ballot (16) movie marketing is hard (16) Randomizer (15) Star Trek (14) Star Trek 2009 (14) J.J. Abrams (12) favorite interviews (12) Avatar (10) Michael Bay (10) 87th Academy Awards (9) Apple (8) James Cameron (8) Star Wars (8) The VFX Show (8) mi3 (8) Box Office Average Per Academy Award Category (7) President Bush (7) hero (7) media (7) 88th Academy Awards (6) 89th Academy Awards (6) Brad Bird (6) Halloween (6) Raiders of the Lost Ark (6) Rogue One (6) advertising (6) ratatouille (6) 90th Academy Awards (5) Back To The Future (5) Christopher Nolan (5) Transformers 2 (5) anamorphic (5) mi4 (5) Adapt (4) Douglas Slocombe (4) Inception (4) Indiana Jones (4) John Carpenter (4) Mac (4) Pirates 2 (4) Rob Zombie (4) Robert Zemeckis (4) The Onion (4) Transformers 3 (4) always awesome (4) movie poster (4) 5by5 (3) 91st Academy Awards (3) After Effects (3) Apple TV (3) BTTF podcast (3) Brett Ratner (3) Chicago (3) Cinefex (3) Digital Domain (3) Hulu (3) Iron Man 2 (3) John Knoll (3) Pixar (3) Speed Racer (3) Star Trek Into Darkness (3) Thankless (3) The Daily Show (3) The Dark Knight (3) VES Awards 2008 (3) VES Awards 2010 (3) Van Helsing (3) Wally Pfister (3) jaws (3) lens flare (3) superman returns (3) television (3) 1-18-08 (2) 2001 (2) 3D (2) Avengers (2) Cloverfield (2) Dan Benjamin (2) Defamer (2) Fake Movie Poster (2) John Gruber (2) Jon Favreau (2) Jon Stewart (2) Let The Right One In (2) Marketplace (2) Microsoft (2) NPR (2) New York Times (2) Rango (2) Roger Guyett (2) Ron Fricke (2) Sam Elliott (2) Shake (2) Stanley Kubrick (2) Steven Spielberg (2) Terminator 2 (2) The Force Awakens (2) The Shining (2) The Talk Show (2) VES Awards 2009 (2) VES Awards 2011 (2) VES Awards 2013 (2) VES Awards 2014 (2) VES Awards 2015 (2) VES Awards 2016 (2) VES Awards 2017 (2) VES Awards 2018 (2) Visual Effects Hall of Fame (2) Weta Digital (2) camera shake citation (2) clip show (2) dr. weil (2) editing (2) iraq (2) lost (2) maura tierney (2) radio (2) recap montage (2) sequels (2) split diopter (2) tomorrowland (2) twitter (2) 300 (1) 92nd Academy Awards (1) 93rdAcademy Awards (1) 94th Academy Awards (1) 95th Academy Awards (1) 96th Academy Awards (1) A Fish Called Wanda (1) AV Club (1) American Pie (1) Andrew Stanton (1) Ant-Man 3 (1) Baraka (1) Barbie (1) Barry Bonds (1) Batman (1) Benjamin Button (1) Beowulf (1) Better Call Saul (1) Box Office vs. Tomatometer (1) CGLies (1) Carl Kasell (1) Carlos Mencia (1) Children of Men (1) DC Comics (1) Danny DeVito (1) Darth Vader Being a Jerk (1) David Bordwell (1) Dexter (1) Disney (1) Disney Plus (1) District 9 (1) Double Negative (1) Dungeons & Dragons: Honor Among Thieves (1) Forrest Gump (1) Fox (1) Fox News (1) Futurama (1) Game of Thrones (1) George Carlin (1) Gran Turismo (1) HBO (1) Halloween Ends (1) Hans Zimmer (1) Harry Potter (1) Heat (1) Hypercritical (1) It (2017) (1) James Bond (1) Joe Rogan (1) John Alcott (1) John McTiernan (1) Judd Apatow (1) KQED (1) Kevin Smith (1) Knocked Up (1) M*A*S*H (1) Marvel Comics (1) Men in Black (1) Michael Giacchino (1) Mission Impossible (1) Mitt Romney (1) Noises Off (1) POV (1) Pat Tubach (1) Paul Franklin (1) Peacock (1) Pitch Black (1) R-Rated (1) Rain (1) Schindler's List (1) Seven (1) Spider-Man (1) Stan Winston (1) Star Trek First Contact (1) Stephen Sommers (1) Tarkin (1) The Exorcist (1) The Incredibles (1) The Office (1) The Sopranos (1) Titanic (1) Tom Martinek (1) Toy Story (1) Tran (1) True Lies (1) VES Awards 2012 (1) VES Awards 2019 (1) VFXHQ (1) Visual Effects Headquarters (1) Visual Effects Society (1) Wall•E (1) War of the Roses (1) action choreography (1) art vs. technology (1) as himself (1) bake-off (1) baseball (1) blocking (1) casino royale (1) color timing (1) correcting the record (1) credits (1) dedioptered (1) dolly zoom (1) drone (1) dumb product alert (1) empire strikes back (1) flying spaghetti monster (1) godzilla 2014 (1) goodfellas (1) grown ups 2 (1) hal hickel (1) hulk (1) iPod (1) iTunes (1) inspirational quotes (1) intertubes (1) iphone (1) long take (1) motion smoothing (1) new term (1) nicolas cage (1) politics (1) positive acknowledgment (1) professional screenplay filmer (1) rand (1) ratings (1) shouldabeen (1) sound design (1) spider-man into the spider-verse (1) spinoff (1) storify (1) stunts (1) the frame (1) torture (1) vexation (1) waterworld (1) writing (1) zune (1)",
    "commentLink": "https://news.ycombinator.com/item?id=41207417",
    "commentBody": "Hal Hickel on Creating Tarkin for Rogue One (fxrant.blogspot.com)90 points by trauco 14 hours agohidepastfavorite52 comments rickstanley 2 hours agoI enjoyed Rogue One, they took a unexplored slice of the story after the legends thing and created this self contained, well written journey of a group that is only mentioned in the 4th episode. Takin may have felt a bit off (uncanny valley), but I think it was a good choice to have him included in the story nonetheless. I like the cold, unhinged personality of this character; I've grown used to Peter Cushing's acting and facial features. I feel like, there should be more exploration of Star Wars in the aspect of \"mundane\" life, like it's done in Andor. There's a big universe already established. Andor really helped me understand 2 things of SW universe: the oppression which built up the motivation for Cassian to join the Rebels, and, effectiveness of the Empire, specifically the ISB. God, the exchange between Daedra Meero and Blevin, with an added mediation of the cunning Major Partagaz was excellent. Reminded me of the discussion in Jurassic Park about ethics. reply avaldez_ 2 hours agoparent>God, the exchange between Daedra Meero and Blevin, with an added mediation of the cunning Major Partagaz was excellent. The writing in that scene is on par with the best in HBO. The political maneuvering and intrigue are reminiscent of House of Cards, and Partagaz stands out as a truly formidable leader. https://youtu.be/iKl0F640914?si=Mkgy-BTM1cp8m5rQ reply prpl 2 hours agoparentprevI liked Andor a lot too, because of the mundane, the prison/cruelty, the guerilla-like warfare, and betrayal. The mundane existed in episode 4 as well, at least at the beginning. reply rrnechmech 2 hours agoparentprev> discussion in Jurassic Park about ethics. Care to elaborate? reply avaldez_ 2 hours agorootparent_Your Scientists Were So Preoccupied With Whether Or Not They Could, They Didn’t Stop To Think If They Should_ (?) reply rrnechmech 1 hour agorootparentOf course. That is legendary. Thanks reply libria 2 hours agorootparentprevNot sure why this was downvoted, but I also assumed they were referring to this scene, the Hammond + Grant + Sadler + Malcolm + Gennaro lunch debate in the original. reply TacticalCoder 1 hour agoparentprev> I enjoyed Rogue One... So did I: I love it that it ends just where episode IV start and I like it too, spoiler alert, that the likeable protagonist do not make it (which we knew from episode IV but still). reply abetusk 2 hours agoprevIn my opinion, the failing of Tarkin was one of animation, not so much rendering. If you watch some of the deepfake videos where they swap the original actors face over the CGI version (e.g. [0]), to me, it looks better but the movement is still unnatural. The lips curl, the head bobs, etc. all have a \"linear interpolated\" look that makes it seem like it was hand animated rather than motion captured by any actor. It looks like in the article either the system they had in place captured facial expressions or an animator tried to recreate them, so I'm unclear why the facial movement looks so awful. Maybe they captured waypoints and then interpolated and we're seeing the aftereffect of the interpolated system? I don't know. I remember Logan coming out at around the same time and being blown away by the younger Hugh Jackman. This was a year later than Rogue One and the younger version didn't really speak, so maybe it's not a fair comparison but I don't think there was a good excuse to have such a bad model. Certainly later, with Luke Skywalker in the Mandalorian or Carrie Fisher in the later Star Wars series, there was no excuse to have had it be so bad. [0] youtube.com/watch?v=_CXMb_MO3aw reply kevingadd 1 hour agoparentIf it looks interpolated, that suggests to me that the people creating it were in a hurry - and film VFX operations are well known for crunch at this point, so it seems possible that they simply didn't give it enough attention. Mocap without lots of hand touchups would normally look very noisy/jittery from what I know, so if it looks unnatural and \"interpolated\" it was probably hand animated in a very coarse way, like high level 'gaze here, tilt head at this point, clear throat' sort of stuff without an artist ever going in and fussing over each frame to make it feel really natural. In 2D animation you have stages like this, there's the initial storyboard, then the keyframing, and then the inbetweening. The inbetweening can be surprisingly important since it comes down to making the motion between those \"key\" frames feel natural instead of just a linear interpolation from A to B. The same applies to 3D animation, you want to put anticipation in the right places, have momentum build up or dissipate, have objects overshoot their destination and then snap back, that sort of stuff. reply PaulHoule 7 hours agoprevI enjoyed Rouge One a lot despite of all that. It was my favorite of all the recent Star Wars movies. reply tsujamin 6 hours agoparentI remember leaving Rouge One _shocked_ that it was a self contained story, no post credits scenes, no need to commit to an entire trilogy or need to understand half a dozen recent releases. Given Marvel and similar franchises at the cinema around the same period, it was a breath of fresh air (also a great film) reply grogenaut 19 minutes agorootparentI loved that rogue one was was self contained. It's a great single mission movie expanding on a throw away line in a previous movie. Solo on the other hand was either way too long for a kid who stole someone's ship and did a joy ride and turned it into an outlandish tale or way too short for a 3 year career. Should have been either a side plot in a movie or a 3 episode arc. Per the movie he's been soloing for like 45 minutes or 63 parsecs total. reply PaulHoule 5 hours agorootparentprevIt was a prequel to one of the greatest films of all time so there is no way they can top that. reply afavour 4 hours agorootparentprevIt is very sad that this is the state of moviegoing these days. That said I’ve learned to just lean back and forget about it. I’ve missed more Marvel movies than I’ve seen (haven’t seen any of the Avengers movies beyond the first I think) and still enjoyed the recent Deadpool movie by just switching off my brain and enjoying the silliness. Same with the second most recent Thor movie… it’s when these movies get excessively self serious that it all unravels. reply thaumasiotes 5 hours agorootparentprevI was just watching the X-Men films. I only went up to 2014, but that appears to be basically contemporary - Rogue One is from 2016 and the MCU apparently has a formal division into phases of which \"phase 2\" centers on 2014. The X-Men films have the property you want, with plots and characterization included in the movie instead of relying on you to bring them with you in your mind. (Are the later films good? They're not great, but if you watch one you'll come out with a sense that the movie had a plot, the things that happened were related to that plot, and the characters had reasons for the things they were doing. The films are quite inconsistent with each other, but they're very coherent considered individually.) The MCU films of phase 2 have already lost it. (For context, phase 2 starts with Iron Man 3 and is mostly garbage with the exception of Winter Soldier, concluding with Ant-Man.) My conclusion is basically just that someone at the MCU decided \"we can save on the budget if we stop using writers\". reply totoglazer 2 hours agorootparentI don’t think it’s budget, i think it’s about the churn. They want an assembly line of blockbusters at a predictable cadence. If you need a good plot it adds a lot of uncertainty into which script, how long it will take to write, etc. much easier to just take whatever the best thing laying around on the deadline day and keep moving forward. reply chaostheory 3 hours agorootparentprevThat’s because many of the people watching already committed to three trilogies. Without the previous world building, Rogue One wouldn’t be as good. reply omoikane 2 hours agoparentprevI didn't even notice that Tarkin was a CG rendition until this post. I thought they did a wonderful job. I remember Rogue One as one of the better Star Wars movies, especially with how they patched up certain holes in other movies while remaining mostly self-contained. If Star Wars were software, Rogue One might be more of a \"bug fix release\" as opposed to a \"feature update\", and bug fix releases are the best releases. reply rubyfan 6 hours agoparentprevAgree, it was by far a much better story line and set of characters than The Force Awakens and so on. I generally like a lot of the series on Disney+ and get the sense you have a few different creative teams pushing this stuff. reply nordsieck 6 hours agoparentprev> I enjoyed Rouge One a lot despite of all that. It was my favorite of all the recent Star Wars movies. Not super surprising to me. I've only seen episode 8. And that was enough for me to be completely uninterested in seeing any new Star Wars media. It's made me strangely nostalgic for the prequel trilogy. At the time they came out I was a little sad at how poorly they compared to the original trilogy. But at least those movies wanted to be in the Starwars universe. reply ensignavenger 6 hours agorootparentRogue One is by far the best of the Disney \"Star Wars\" movies, and the only one that fits with the Lucas movies. Highly recommend it. reply squarefoot 2 hours agorootparentThis. Loved every minute of Rogue One, it worked great as a self contained story, then the finale blended so gracefully with the beginning of Ep IV. That is how a prequel should be made. Newer SW movies aren't that good, but at least they also aren't as bad as Ep. I, II and III, while it seems they're going on the right direction with most of the series. reply dwighttk 1 hour agorootparentprevConnecting Rogue One directly to the beginning of A New Hope really made the Leia / Darth Vader interactions work differently though. reply bigstrat2003 3 hours agorootparentprevI liked the prequels overall (despite their flaws), but I can say you're definitely not alone here. I have seen a lot of discourse online where the sequel trilogy made people appreciate that at least the prequels had a coherent creative vision behind them. Lucas made plenty of mistakes in realizing his vision, of course. But he had one. By contrast, the sequel trilogy is painful to watch because they feel like they were designed by a committee (and the difference in creative leads hurts a lot too). Episode 7 in particular feels like they consciously tried to make a by-the-numbers Star Wars which passed muster with focus groups, but it had no soul at all. reply BolexNOLA 6 hours agorootparentprev8 has a few low points but overall I think it was great tbh. Took some risks and tried to get away from the importance of “who your parents are”/general “great man” nonsense a lot of heroic epics lean on. 9 on the other hand…oof. Don’t watch that. reply lll-o-lll 5 hours agorootparent8 was not great. David Mitchell puts it best. “My enjoyment was predicated on it amounting to something. It was an IOU to be redeemed at the point of pleasurable revelation, and as there was none, the IOU was never redeemed. Therefore, I hadn’t enjoyed myself.” reply PaulHoule 5 hours agorootparentprevI watched 9 in 3-d on my Meta Quest 3. The villain in the last three movies is hard for me to take seriously because he seems to have stepped out of an episode of Doctor Who. I appreciate the last three movies though for outdoing themselves in scale as did early space operas such as Skylark of Space. I see Star Wars as a project that suffered because it went on for way too long; there were major changes in the external culture inside of and between the last two trilogies that make them hard to watch together. reply vundercind 4 hours agorootparentprev8 is at least the 4th-best Star Wars movie. Rogue one is distantly at 5th. All the rest are quite bad. [edit] though 8’s quality is kinda useless, being in the middle of a trilogy. It’s hard to recommend. reply bigstrat2003 3 hours agorootparentNo way. The Last Jedi is the second-worst Star Wars movie, only outdone (somehow) by its sequel. It was terrible. reply dwighttk 1 hour agorootparentAnd that is including the Holiday Special. reply mattnewton 2 hours agorootparentprevI liked it better than the force awakens but I think we could both agree they’re all safely in the “not worth watching” bucket so the order we stack them in there doesn’t matter. (9 definitely is on the bottom though) reply Svip 6 hours agoprev> We had in our possession a life casting of Peter Cushing’s face. It was made not long after New Hope, so it was very accurate in terms of Cushing’s age, etc. Not mentioned is that the cast he is talking about was made for the movie Top Secret!, where Peter Cushing plays a bookshop proprietor with a distorted face around a magnifying glass.[0] [0] https://www.youtube.com/watch?v=uuYTVl0iOkk reply cancerhacker 4 hours agoprevI recently watched George Millers _Furiosa_ and they used machine learning and cgi to manipulate the face of the pre-teen actress to more closely resemble the adult actress. With the amount of data available constantly being captured of todays actors I’m sure this will become more common - and the brief article I read about it in this case made a point of saying that they had worked with the actors Guilds to establish appropriate Compensation (in this case). But it was subtle and I wouldn’t have known without looking into the trivia. I saw and enjoyed _The Instigators_ last night and was thinking about how strong a physical impression some of the actors made on screen - Alfred Molina, Ving Rhames, and Ron Perlman in particular. reply throwawayk7h 25 minutes agoparentThe adult actress, however, doesn't really resemble Charlize Theron from _Fury Road_ though. She did a great job, but I wonder if they couldn't have picked someone with a greater resemblance. reply mmastrac 1 hour agoprevI can't wait for a re-release of this particular film with the latest deepfake tech integration. It looks quite terrible in the original release -- enough to pull me out of the immersion of the film -- and the fan edits of those scenes are fantastic. The movie is certainly one of the highlights of the modern SW universe and deserves a bit of additional love to bring it to the modern standards for virtual actors. Not to say it wasn't an achievement at the time, but it's too far in the uncanny valley as it stands. reply ane 34 minutes agoprevThey could've used Guy Henry's likeness as-is. He already looks a lot like Peter Cushing. And his accent was impeccable reply francisofascii 6 hours agoprevI remember when watching in the theater, the audience reacted with awe. At the time is was a novel technique. Then it was followed up with Carrie Fisher at the end. And the audience loved it. reply 1123581321 5 hours agoparentI remember the same. I saw it in a packed opening weekend; Tarkin’s was more of a cheer and Leia’s a wave of appreciative murmurs. Overheard only positive remarks exiting the theater. Sometime after that the imperfection and potential inappropriateness of the technique gained more cultural traction. It wasn’t until after The Last Jedi was released that Star Wars stopped getting the benefit of the doubt during first viewings, broadly speaking. reply throwawayk7h 20 minutes agorootparentI recall discussing it with my family after stepping out of the theatres. I hadn't realized there was anything strange, most of us didn't, but one of my siblings criticized the \"bad CGI\" at length on the walk home and said they should have hired a look-alike instead. reply layer8 4 hours agoparentprevI remember a lot of uncanny-valley conversations back then. reply thaumasiotes 5 hours agoparentprevThe synthetic Tarkin was well received and looked accurate. The synthetic Carrie Fisher looked weird and wasn't so well received. reply lordfrito 4 hours agorootparentA while back someone deepfaked the CGI Leia scene with footage of the actual Carrie Fisher as Leia in the original Star Wars. It looked amazing. So amazing I'm surprised the CGI -> Deepfake technique isn't used more often in movies. reply geerlingguy 4 hours agorootparentCorridor did it and it was a great episode on how deepfakes were progressing (they're muck better now): https://youtu.be/_CXMb_MO3aw?feature=shared reply dwighttk 1 hour agoprevNone of these fake faces look that good out of the chute, and even the best looking ones look terrible a year later. reply causality0 1 hour agoprevTo me one of the most interesting things about Rogue One was how differently the Tarkin and Leia recreations were received, at least in person. Of course we know that online everybody is a critic and hates both of them, but that wasn't what it was like in the theater. I went with a large group and half of the group didn't even realize Tarkin wasn't real, while the entire group and and a good chunk of the theater audibly groaned when they saw Leia. reply ekianjo 7 hours agoprevIt was not very impressive to say the least. It looked fake the second it appeared on screen. reply TillE 4 hours agoparentIt would've been fine if they kept it to a brief appearance, but the movie spends so much time with Tarkin, including closeups of the face which simply does not move like a human's. Really bad call, takes away from an otherwise very good movie. reply drunkencoder 7 hours agoprev [–] I wonder how this would have played out using deep fake technology reply thih9 7 hours agoparent [–] Mandalorian Season 2 spoilers below. This article looks relevant: “How Star Wars Deepfake Seriously Improves Luke Skywalker Cameo in The Mandalorian” - the youtuber that did that eventually got hired by ILM. There is also an example with Tarkin. https://www.denofgeek.com/tv/star-wars-deepfake-luke-skywalk... reply BolexNOLA 6 hours agorootparent [–] It is definitely better but it still has the problem of the original where his face just looks so stiff when he speaks. reply mock-possum 1 hour agorootparent [–] It also looks like his face is sort of floating superimposed over the front of his head. I feel like I notice that a lot with deepfake stuff, it’s like the generated patch they’re compositing overtop doesn’t quite move at the same rate as the rest of the thing. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Hal Hickel, Animation Supervisor for \"Rogue One,\" detailed the creation process of the digital character Grand Moff Tarkin, clarifying misconceptions about its CGI.",
      "The process involved filming an actor, Guy Henry, in costume and replacing his head with a CG Tarkin head, using facial performance capture and a life cast of Peter Cushing’s face.",
      "This explanation highlights the intricate work of many artists and technicians at ILM (Industrial Light & Magic) to achieve a realistic digital human character, which many viewers did not realize was CGI."
    ],
    "commentSummary": [
      "Hal Hickel discusses the creation of the CGI character Tarkin for \"Rogue One,\" highlighting the challenges and techniques used in the process.",
      "The inclusion of Tarkin, despite some viewers finding it uncanny, was a significant technical achievement and sparked discussions about the use of CGI and deepfake technology in films.",
      "The post also touches on the broader reception of \"Rogue One\" as a well-received, self-contained story within the Star Wars universe, appreciated for its unique narrative and connection to the original trilogy."
    ],
    "points": 90,
    "commentCount": 52,
    "retryCount": 0,
    "time": 1723266000
  },
  {
    "id": 41207556,
    "title": "Larry Wall's Very Own Home Page",
    "originLink": "http://wall.org/%7Elarry/",
    "originBody": "Larry Wall's Very Own Home Page Howdy, world! This website is under construction. (Did you ever see a website that wasn't under construction?) Yes, I'm afraid chartreuse is one of my favorite colors... No, I'm not going to change it just because it's not your favorite... my geek code (3.1): GC/CS/E/H/IT/L/M/MU/PA/P/S/SS/TW/O d(+++)>+ s: a+>++>+++$ C++++$ UBAHS*++++$ P+++++(--)$ L !E? W+>++ N+++@ K+++>++++++@ w$ !O M->+ V--() PS+(-) PE(++) Y+ PGP->+ t+() 5 X? R>* tv@ b++>+++ DI+++ D? G(-) e++>+++@ h----() r+++ y++++ (explanation) my ravings 1st State of the Onion, 1997 Perl Conference. 2nd State of the Onion, 1998 Perl Conference. Perl, the first postmodern computer language, LinuxWorld Spring 1999. 3rd State of the Onion, 1999 Perl Conference. I'm also keeping a diary all about my cornea transplant. Perl See my Perl page. Web and CGI programming I haven't done much of this. (Consider how lousy this web page is.) Consult the appropriate webpage. rn There are various derivatives being supported by various people. None of them are me. patch I recommend the version supplied by the GNU folks. ftp://prep.ai.mit.edu/pub/gnu. metaconfig No longer maintained. These days you're probably better off using something like GNU autoconf, one of the spiritual descendents of metaconfig. my publisher See O'Reilly & Associates. my church See New Life Church. my family See The Wall Nuthouse. my alma mater See Seattle Pacific University. my personality type See the personality page for INFP. my email address Mail to larry@wall.org. I do answer my email. Occasionally. my phone number I hate my telephone. Please don't ask for my phone number.",
    "commentLink": "https://news.ycombinator.com/item?id=41207556",
    "commentBody": "Larry Wall's Very Own Home Page (wall.org)89 points by thunderbong 13 hours agohidepastfavorite51 comments AdieuToLogic 12 hours agoIt is a sad day indeed when the Perl link on Larry Wall's home page results in a 404. reply _giorgio_ 12 hours agoparentThat was a fast 404 anyway. I forgot how damn fast websites used to be. reply romwell 12 hours agoparentprevIt's been \"a sad day\" for over a decade. Here's the last capture on archive.org[1]; there wasn't much there in the first place. It looks like Larry had better things to do than maintaining that page (...or the page that links to it) :) [1] https://web.archive.org/web/20100420032605/http://www.wall.o... reply beretguy 10 hours agorootparentIt says right at the beginning that site is under construction. reply olalonde 10 hours agoprev> I hate my telephone. Please don't ask for my phone number. I can relate... reply userbinator 12 hours agoprev%7Elarry? Looks like an old trend ( https://jkorpela.fi/tilde.html ) that is no longer common. reply riiii 12 hours agoparentIt wasn't a \"trend\". It was Apache's way of automatically mapping a username to his home directory. I feel old. reply xelxebar 11 hours agorootparentNot just Apache, but POSIX shell syntax! It's called Tilde Expansion[0], so in your dash, bash, whatever, ~USER expands to the home directory of USER. This is the general form of standard \"bare tilde\" syntax as a stand-in for $HOME. [0]:https://pubs.opengroup.org/onlinepubs/9699919799/utilities/V... reply CalRobert 11 hours agorootparentprevMy 90's ISP homepage URL makes more sense. inreach.net/~myusername Actually, I miss when ISP's all came with some space for simple web hosting. It was a given that a lot of people would want to make their own sites, not just consume them. reply dotancohen 10 hours agorootparent> It was a given that a lot of people would want to make their own sites, not just consume them. I wouldn't say it was a given that a lot of people would want to host, but it was a given that people _could_ host. Then Geocities came along and made the hosting easy, destroying the ISP-hosting market. reply beretguy 10 hours agorootparentAnd now we have Neocities. reply userbinator 11 hours agorootparentprevI am referring to the practice of escaping the tilde. reply mikae1 12 hours agoparentprevBut still incredibly rad. https://tildeverse.org/ reply guax 11 hours agorootparentGodamnit, is beautiful. 10/10 click. reply alex-moon 10 hours agoprevGEEK PERL CODE [P+++++(--)$] My tendencies on this issue range from: \"I am Larry Wall, Tom Christiansen, or Randal Schwartz.\", to: \"Perl users are sick, twisted programmers who are just showing off.\" Getting paid for it! Thing of beauty. reply kzisme 11 hours agoprevI used to visit his personal site to see updates, but It's been awhile since I last looked. I do however frequently watch this interview with him: https://www.youtube.com/watch?v=aNAtbYSxzuA reply bluedays 13 hours agoprevIs Larry Wall brat? reply nabla9 11 hours agoprevThat's exactly as I remember it from 1999 when I visited it. reply romwell 12 hours agoprevIt's... beautiful. And doesn't chew up CPU nor makes me wait. reply cornholio 10 hours agoparentLooks just like Perl. reply tmtvl 9 hours agorootparentIs Perl chartreuse? I always imagined it to be a light blueish colour. Maybe cornflower blue, or dodger blue, or a light steel blue. reply penguin_booze 8 hours agoprevI didn't know Mr. Wall was competing (or teaming up) with tonsky.me on who blinds the reader faster. reply ChrisArchitect 12 hours agoprevSome previous discussion: 2018 https://news.ycombinator.com/item?id=18175215 reply commandersaki 10 hours agoprevAh I remember his journal on Kerataconus, helped me through my own struggle. reply borlanco 12 hours agoprevThank you, Larry! reply veltas 11 hours agoprevIs there a Larry Wall Facebook Wall? reply fuzztester 9 hours agoparentLarry is Wall. reply cranberryturkey 13 hours agoprev [–] i wonder what he's up to these days. reply _giorgio_ 12 hours agoparent [–] He's building a bigger keyboard, because perl has finished all the available symbols £_&++()/@!?;:'\"*~`••√π÷×∆∆\\}{=°^¢$¥€%©™™]] reply librasteve 51 minutes agorootparentthat’d be unicode then https://docs.raku.org/language/unicode reply shawn_w 11 hours agorootparentprevThat looks more like APL. reply zerr 11 hours agorootparentprevWould be useful for Rust as well. reply cranberryturkey 11 hours agorootparentprev [–] i became a master at regex from my perl days in the 90s and early 2000s....valuable skill imo reply silisili 10 hours agorootparent [–] Regex is great (sometimes), for the writer. As a team lead for a typical SaaS app, they're banned. I'd rather see a chain of individual string checks than long regex strings that only the author understands, because they're usually brittle and often incomprehensible to anyone but the author. reply bazoom42 10 hours agorootparentHow is a chain of string checks less brittle and easier to understand? If they are checking for the same pattern, the intrinsic complexity will be the same, the string checks will just add some additional complexity and risk of bugs. reply silisili 10 hours agorootparentEdited a bit to explain we're just a typical SaaS application. Regex mostly crops up in validations. Just Google the first result for 'email address regex validation.' (?:[a-z0-9!#$%&'+/=?^_`{|}~-]+(?:\\.[a-z0-9!#$%&'+/=?^_`{|}~-]+)|\"(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21\\x23-\\x5b\\x5d-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])\")@(?:(?:[a-z0-9](?:[a-z0-9-][a-z0-9])?\\.)+[a-z0-9](?:[a-z0-9-][a-z0-9])?|\\[(?:(?:(2(5[0-5]|[0-4][0-9])|1[0-9][0-9]|[1-9]?[0-9]))\\.){3}(?:(2(5[0-5]|[0-4][0-9])|1[0-9][0-9]|[1-9]?[0-9])|[a-z0-9-]*[a-z0-9]:(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21-\\x5a\\x53-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])+)\\]) How many programmers do you think understand that perfectly at first glance? I've programmed and used regex for decades and can admit, I don't. Is it even correct? Who knows, unless I waste time deciphering both it and the RFC side by side. I'd much rather have a handful of single checks, preferably commented. As is usually the case, performance is not the primary concern. reply nathell 10 hours agorootparent> Regex mostly crops up in validations. I’ve just grepped my codebase for regex matchings, and this is not true. The most common use case is matching a filesystem path or a URL that is known to conform to a schema (e.g. file names prefixed with dates) and extracting parts of the schema from it. > Just Google the first result for 'email address regex validation.' That is an abomination and not a good way to validate emails, because, as you say, it’s super complicated and barely understandable. Draw a finite-state automaton corresponding to this regex to see why. Equivalent code written without regex, implementing the same FSA, would easily be >100 LOC and equally incomprehensible. In practice, it’s better to check whether the string contains an @ and maybe a dot, and that’s it. Sure, you won’t be RFC 5322 compliant, but who cares? Your users are much more likely to make a typo in the domain name anyway than misspell the characters that would render the email invalid. Just send an email and see if it arrives. All of the regexes in said codebase of mine are simple. The longest is 75 characters and a straightforward one to check for UUIDs; you can understand it at a glance: [0-9A-Fa-f]{8}-[0-9A-Fa-f]{4}-[0-9A-Fa-f]{4}-[0-9A-Fa-f]{4}-[0-9A-Fa-f]{12} reply bazoom42 10 hours agorootparentprevNow rewrite the same to a sequence of string checks and show me the code. For a fair comparison you should remove all comments and whitespace as you have done with the above regex. The problem with the above is not the regex per se, the problem is that the email address grammar is really complex for historical reasons. If you insist on validating email syntactically, you can’t avoid that complexity by rewriting to multiple string checks. The solution is to use a library or just perform a simpler validation (eg check for a ‘@‘), since a full syntactic validation does not provide much value anyway - the address might still be invalid anyway. reply silisili 10 hours agorootparentThe difference is, individual checks can be commented and referenced to a particular rule or even line in an RFC. A regex blob is basically 'this is all the rules, RTFM.' And as you mentioned (especially in the case of email validation), they're usually incorrect. reply bazoom42 9 hours agorootparentYou can add comments to regexes, explaining each part. I believe it is called verbose mode. > And as you mentioned (especially in the case of email validation), they're usually incorrect. My point was that the email address might still be invalid despite being syntactically correct, eg if you miss a letter. This is why I don’t understand the obsession with syntax-level email validation. You still need a confirmation mail. But of course there can be a bug in a regex - just as there can be a bug in imperative string-matching code implementing the same pattern. reply tmtvl 9 hours agorootparentFrom `perldoc perlre`: > A single \"/x\" tells the regular expression parser to ignore most whitespace that is neither backslashed nor within a bracketed character class, nor within the characters of a multi-character metapattern like \"(?i: ... )\". You can use this to break up your regular expression into more readable parts. Also, the \"#\" character is treated as a metacharacter introducing a comment that runs up to the pattern's closing delimiter, or to the end of the current line if the pattern extends onto the next line. reply defrost 10 hours agorootparentprevThat alone is hard to document and maintain. Coupled with auto gen state diagrams, the current and correct RFC 5322 spec and case notes it's far more defensable. There are some pretty decent RegEx tools about these days. https://regexper.com/#(%3F%3A%5Ba-z0-9!%23%24%25%26%27*%2B%2...) ^^ Heh. Markup processing error in HN ?? the final ) wasn't captured in the link creation. See https://stackoverflow.com/questions/201323/how-can-i-validat... for a working link to the state diagram generator. Even with a handful of single checks there's still the need to compare those, block by block, to the RFC. Assuming RegEx is to be used (I'm not intimidated by RegEx's but I'm general not a fan, preferring custom parsers for many things that are hard or impossible with a RegEx) this is a better approach: https://regex101.com/r/gJ7pU0/1 It's a \"live\" example that includes a test suite and has a parser that annotates blocks. The RegEx expression uses a DEFINE for sub clauses to improve clarity. reply bazoom42 7 hours agorootparent> I'm not intimidated by RegEx's but I'm general not a fan, preferring custom parsers for many things that are hard or impossible with a RegEx Good call not to use Regex for things that are impossible to do in Regex! But seriously, a custom parser must have some way to recognize individual tokens. If you distinguish parsing and lexing, what tool do you use for lexing? Regexes have a particular purpose: matching patterns of characters. I haven’t seen anyone suggest how to do that in a simpler and cleaner way. reply defrost 6 hours agorootparentIt's less about the matching and more about the validation with most of my past applications, IIRC the best RegExp matchers for the current email specification have 99% or somesuch coverage but aren't complete .. there are many examples of data extraction and validation where a regular expression is an imperial tool for a metric job. Nested data, eg JSON, not a good fit in general, they are weak at balanced tag matching, they suck at validating numeric ranges such as Lat|Long clock time, etc. reply fuzztester 9 hours agorootparentpreviirc perl from 5.x onwards allowed both whitespace (at the right places) and comments, in regexes. using those could make them a lot more readable. can't remember but you might have to specify a flag for it. reply librasteve 48 minutes agorootparentthis is the default in https://raku.org reply cranberryturkey 10 hours agorootparentprev [–] interesting...you ban anything people typically suck at? At PayPal we banned html and made everyone write XML....turns out we just wrote shitty XML which lead to shitty xhtml :P reply tannhaeuser 9 hours agorootparent> At PayPal we banned html and made everyone write XML That's gross when XML with its pointless verboseness is actually just a \"canonical\" SGML subset without tag omission and other short forms, intended for delivery to browsers, while SGML proper has all the authoring features. Goes to show how clueless and prone to koolaid sellers developers were and still are (cf crypto, LLMs). reply cranberryturkey 8 hours agorootparentthe idea was you ask 10 web devs how to code a Save you'd get 10 different answers, so we had a Save xml tag that generated them all the same. there was only one way to create a button now. It worked until people started adding all these options to totemplate that it became garbage again. reply silisili 10 hours agorootparentprev [–] Absolutely. Readability trumps all else in a productive team environment. If everyone had the same 'because people suck at it' attitude, we'd never have evolved beyond asm, if even. reply cranberryturkey 8 hours agorootparent [–] well most code i've seen in corporate america sucks balls reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Larry Wall, the creator of the Perl programming language, has a personal website under construction, sharing his interests and personal updates.",
      "Wall's site includes links to his notable talks, such as the \"State of the Onion\" addresses at Perl Conferences and his views on Perl as a postmodern computer language.",
      "He provides updates on his personal life, including a diary about his cornea transplant, and offers resources and recommendations related to Perl and other software tools."
    ],
    "commentSummary": [
      "Larry Wall's personal website, known for its link to Perl, now results in a 404 error, causing disappointment among long-time followers.",
      "The discussion highlights nostalgia for the early internet days, with comments on the simplicity and speed of old websites and the use of tilde (~) in URLs.",
      "The conversation also touches on the evolution of web hosting, from ISP-provided space to platforms like Geocities and Neocities, reflecting changes in how people create and consume web content."
    ],
    "points": 89,
    "commentCount": 51,
    "retryCount": 0,
    "time": 1723268127
  }
]
