[
  {
    "id": 41123155,
    "title": "Suspicious data pattern in recent Venezuelan election",
    "originLink": "https://statmodeling.stat.columbia.edu/2024/07/31/suspicious-data-pattern-in-recent-venezuelan-election/",
    "originBody": "*{box-sizing:border-box}body,html{font-family:proxima-nova,sans-serif;font-size:14px;line-height:1.42857143;margin:0;padding:0}h1,h2,h3,h4,h5,h6,label{color:#555}h1{font-family:inherit;font-size:2.8em;font-weight:600;margin:.8em 0 .6em}a{color:#2c6bac;text-decoration:none}p{margin:0 0 20px}svg:not(:root){overflow:hidden}.btn{background-color:#337ab7;color:#fff;display:block;width:100%;font-weight:400;line-height:1.3333333;border-radius:6px;text-align:center;white-space:nowrap;vertical-align:middle;-ms-touch-action:manipulation;touch-action:manipulation;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;background-image:none;border:1px solid transparent;margin:20px 0;font-size:22px;padding:14px 16px}#nav-wrapper{font-family:Helvetica Neue,Helvetica,Arial,sans-serif;position:relative;z-index:5;min-height:42px;background:#fff}#nav-wrapper a{display:inline-block;color:#3a6fa2;text-transform:uppercase;padding:13px 0}#main-article{padding-bottom:40px}.container{margin:auto;max-width:970px}.row{margin:0 -15px}.row:after{clear:both}.row:after,.row:before{content:\" \";display:table}.col-md-4{width:33.3333%}.col-md-4,.col-md-8{float:left;padding:0 15px}.col-md-8{width:66.6667%}.col-md-9{float:left;padding:0 15px;width:75%}#sidebar-content{font-size:16px;padding-bottom:40px}#sidebar-content h2,#sidebar-content h3{font-size:1.35em;color:#555;margin-bottom:.4em;font-weight:400}#main .panel-group,aside section{margin-bottom:40px}#cu-footer{line-height:27px;padding:30px 0;color:#fff}#cu-footer .copyright a{color:#093552}#site-footer{background:#093552;color:#fff;padding:40px 0 30px}#cu-footer-links{text-align:right}#cu-footer-links a{color:#093552}#cu-footer-links span:after{content:\"\\B7\";margin-left:5px;margin-right:5px}.fa{display:inline-block;font:normal normal normal 14px/1 FontAwesome;font-size:inherit;text-rendering:auto;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale}.fa-wheelchair:before{content:\"\\f193\"}#cu-footer .a11y img{display:inline-block;width:21px}.cu-brand{fill:#fff;margin:14px 0 0}.sr-only{position:absolute;width:1px;height:1px;padding:0;margin:-1px;overflow:hidden;clip:rect(0,0,0,0);border:0}Columbia University in the City of New York Access DeniedA Potential Problem has Been Detected Your session has been detected as an attack against our site.If you are reading this message, this was likely detected incorrectly. We ask that you please use your browser's \"Back\" button and resubmit your request.If you see this message a second time, please report this incident (including the URL of this page and how you got to here, along with the information below) to the CUIT Service Desk so that we can review and address this issue: Client IP 52.225.76.190 RAY ID8ac814b5bde39872 Why have I been blocked? This website is using a security service to protect itself from online attacks. The action you just performed triggered the security solution. There are several actions that could trigger this block including submitting a certain word or phrase, a SQL command or malformed data.Support Contact Please submit a ticket to the CUIT Service Desk to ask questions or report an issue.Submit a ticketDepartment Client Device EngineeringClient Support ServicesAudience StaffCategories Service DeskColumbia University ©2021 Columbia University Accessibility Nondiscrimination Careers Built using Columbia Sites (function(){function c(){var b=a.contentDocument||a.contentWindow.document;if(b){var d=b.createElement('script');d.innerHTML=\"window.__CF$cv$params={r:'8ac814b5bde39872',t:'MTcyMjUzODkyOS4wMDAwMDA='};var a=document.createElement('script');a.nonce='';a.src='/cdn-cgi/challenge-platform/scripts/jsd/main.js';document.getElementsByTagName('head')[0].appendChild(a);\";b.getElementsByTagName('head')[0].appendChild(d)}}if(document.body){var a=document.createElement('iframe');a.height=1;a.width=1;a.style.position='absolute';a.style.top=0;a.style.left=0;a.style.border='none';a.style.visibility='hidden';document.body.appendChild(a);if('loading'!==document.readyState)c();else if(window.addEventListener)document.addEventListener('DOMContentLoaded',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);'loading'!==document.readyState&&(document.onreadystatechange=e,c())}}}})();",
    "commentLink": "https://news.ycombinator.com/item?id=41123155",
    "commentBody": "Suspicious data pattern in recent Venezuelan election (columbia.edu)831 points by kgwgk 22 hours agohidepastfavorite442 comments alejohausner 3 minutes agoHere are the true vote totals, as reported by witnesses at the polling booths: https://resultadosconvzla.com/ It was a landslide for the opposition candidate Gonzalez, 67% to Maduro’s 30%. reply dinobones 21 hours agoprevHere's this re-explained with a simpler example. Imagine you have 1,000 votes. You want to show that your political party got 60% of the vote, so, you claim: My party: 600 votes Opposition: 300 votes Other: 100 votes Presto, we got a good breakdown. The people will buy it.... It makes sense that 600 is exactly 60% of 1,000, because this was an artificial example. But in the real world, we don't get 1,000 votes. We get 10,058,774 votes. What are the odds that the % of votes you get is a round number like 60%, or 51.2%? They're infinitesimally small. You're much more likely to get ugly numbers, like 59.941323854% of the vote, unless you choose some artificial percentage and work backward. reply zyklu5 12 hours agoparentThis is not correct since you can claim the above for any number of votes actually obtained (if you asked someone to pick a number from 1 to 10 million, any number the person picks (assuming iid picks) will be by definition 10^-7). The problem is more subtle. There are around 10,000 integers n such that n/10058774 when rounded to 3 decimal places gives 0.512. Of those 10,000 this particular one has the smallest rounding error. That's what gives one the sense that probably they started with the clean fraction 0.512 and then worked their way to the tally. reply agroot12 11 hours agoparentprevYou are right that it is unlikely that one candidate gets the number of votes that exactly matches a certain percentage with one decimal (1:10.000 as per the source article). But it's even more unlikely and astonishing that the second candidate also gets a number of votes corresponding to a percentage with one decimal! This is highly suspicious if the vote counts are presented as official result. But as mentioned in the comments, we cannot be sure that someone was given the total vote count, and the percentages rounded to one decimal, and thought it would be helpful to recalculate how many votes each candidate must have gotten. reply tptacek 3 minutes agorootparentThe results we're discussing were read live by the president of the Venezuelan electoral authority. It is possible that they... simply read the wrong results? Like an internal estimate rather than the real numbers? But that is a wild mistake for the electoral authority to make. https://news.ycombinator.com/item?id=41125031 reply tomp 21 hours agoparentprevMy favourite part of my math education, solutions were always nice. Compute the eigenvalues of a random-looking (but still integers) 4x4 matrix? Oh, it's sqrt(2), I probably didn't make an error in the calculation. Then came the advanced physics / mechanics exam. It threw a wrench into our beautiful system. The results were just about anything, incredibly ugly, like the real world :yuck: :vomit: reply timthorn 18 hours agorootparent> Oh, it's sqrt(2), I probably didn't make an error in the calculation You remind me of my university maths exam. In all the past papers, the eigenvalues came out to be round numbers. But in the real paper I sat, no matter how many times I tried to find my mistake, they didn't. I wasted hours of the exam on that. It was the professor's final year before his retirement. reply twright0 11 hours agorootparentThe year that I took AP Physics, every single piece of study material and practice test exercised only really simple math - small numbers, everything cleanly worked out into integers, etc etc. I did almost everything in my head or with quick notes on paper. This pattern was so consistent I almost didn't bring my calculator into the actual exam because I hadn't needed it all year, and grabbed it only at the last second \"just in case\". Turns out that was not a design goal of the real exam and basically nothing worked out to neat, small integer solutions - I probably would have hard failed without the calculator. I'm still sort of confused why prep materials and the real exam diverged so much. reply goodcanadian 10 hours agorootparentI had a university exam where my calculator literally didn't work. I put a note on the paper to that effect and worked out as far as I could by hand without actually giving any of the final answers. Given the test was about knowledge and not the precise answers, I don't think it harmed me any (my grade was over 80%). reply dietr1ch 3 hours agorootparentI passed my physics classes refusing to evaluate the final expressions, after all that's what calculators and computers are for. I don't feel that had a huge impact on my grades either and my sanity/stubbornness went unharmed. reply ertgbnm 21 hours agorootparentprevExcept in the real world we are allowed to offload the computation to a computer and have more time to double check things. Nice solutions are necessary due to time and resource constraints that exist within an educational setting. reply amelius 20 hours agorootparentprevTests should have checksums built into the correct answers. reply ajnin 10 hours agoparentprevWhen I try to explain the issue, it boils down to this : the results look like they have been cooked. And the probability of that hapening by chance is 1 in 100 million. Mathematically, if votes are random, with 10,058,774 voters you have 10,058,774^2 ~= 1e14 possibilities of different results for 3 candidates (Maduro, Gonzalez and \"Other\"). On the other hand, the number of possible results that land exactly on the closest integer to be a round 0.1 percentage point is 1000^2 = 1e6. So the probability of the actual votes landing on a round 0.1 percentage point purely by chance is 1000^2/10,058,774^2 ~= 1 in 100 million. Of course the votes are not entirely random, but they have a random element, so it gives a rough idea of the reality. reply gmaster1440 21 hours agoparentprevIf I'm in charge of forging a presidential election, how difficult is it for me to use realistic, \"ugly\" numbers to sell it more effectively? reply aaplok 20 hours agorootparentIn light of recent analyses of suspicious elections (Iran, Russia, Venezuela), it seems harder than it sounds to avoid discernible patterns. On the other hand, the goal is to get away with fraud, not to convince an international community who will likely look for any confirmation of their suspicion. It would be interesting to look for patterns in a (presumably) fair election like the recent British one for comparison. Disclaimer: I have never tried to rig elections myself so I don't really know how hard it is. reply colimbarna 19 hours agorootparent> On the other hand, the goal is to get away with fraud, not to convince an international community who will likely look for any confirmation of their suspicion. Despite my joke in a sibling comment, this is key. When you're a politician everything is power relations. Sometimes it's necessary to show that you have the power to semi-obviously rig an election. Your bargaining position is different if it requires military force to remove you vs just an unhappy electorate. You can achieve different things. reply lazide 17 hours agorootparentYup. It’s a special kind of power that can flat out rig an election and have opponents ‘fall out of windows’ with no repercussions. The type no one wants to even be seen trying to challenge. reply IAmGraydon 18 hours agorootparentprev>It would be interesting to look for patterns in a (presumably) fair election like the recent British one for comparison. Someone should run this same analysis on all the election data they can get their hands on. Who knows what might be found. reply nick238 14 hours agorootparentThere were some pretty shit analysises of the 2020 US elections that Matt Parker covered with videos like \"Why do Biden's votes not follow Benford's law?\"[1] and \"Why was Biden's win calculated to be 1 in 1,000,000,000,000,000?\"[2]. I don't know about other countries, but the amount of data that every county in every US state produces makes systematic fraud pretty much impossible. If there's literally only 3 numbers produced by the Venezuelan government, you need to be seriously incompetent to have detectable fraud because techniques like Benford's or Zipf's law need lots of individual numbers. [1]: https://youtu.be/etx0k1nLn78 [2]: https://youtu.be/ua5aOFi-DKs reply m0dest 16 hours agorootparentprevIf you were forced against your will to aid in this type of fraud, might you not intentionally include a subtle error in your work that reveals its illegitimacy to a careful observer? reply lostlogin 15 minutes agorootparentIf have thought it more likely that the stress would cause an accidental subtle error. reply fshbbdssbbgdd 14 hours agorootparentprevGun to my head? No. reply gorgoiler 12 hours agorootparentprevE. Goldstein wins with 51.2HELPIMTRAPPEDINANELECTIONRIGGINGBUNKER% of the vote! One would have to take care with the analysis because humans are actually trapped in vote counting bunkers (or local sports halls more likely) in legitimate elections. Any analysis that simply concludes votes were subject to the foibles of hand counting wouldn’t be very useful. reply verbify 20 hours agorootparentprevThis kind of mistake is easy to avoid. The problem is that there are a lot of potential mistakes that could be made, this is just one of them. reply energy123 20 hours agorootparentAnd the people doing the fraud aren't going to be computer scientists or statisticians. They were chosen for their loyalty to the dear leader. reply AnimalMuppet 19 hours agorootparentThe dear leader wasn't chosen for his ability, either, but for his loyalty to the previous dear leader. reply DonsDiscountGas 20 hours agorootparentprevNot difficult at all. Just pick the approximate numbers you want and then introduce a random error of a few percent. (Normal, uniform, doesn't really matter). This is also not hard for statistics experts to detect, but it's much harder to prove (aka you've got plausible deniability). One wonders why they didn't even bother to do fraud slightly better. reply stouset 19 hours agorootparentUnless done carefully this will almost certainly fail Benford’s Law. Manipulating statistics is harder than you think. reply Terr_ 17 hours agorootparent> Unless done carefully this will almost certainly fail Benford’s Law. IIRC Benford's law relies upon things that have power-law underpinnings, such as iterated growth% at different rates. In contrast, relative vote amounts at a given point in time don't have many ways to exhibit that, particularly when the total number of voters is fixed rather than having voters divide like bacteria during polling day. However it might work if you were checking the growth in total eligible voters in different locations over time. I like to imagine Benford's Law a bit like throwing randomly distributed darts through the air at a paper target, exept the target is graph paper with log-10 subdivisions. The \"leading 1\" zones are simply bigger targets. [0] [0] https://commons.wikimedia.org/wiki/File:Logarithmic_scale.sv... reply dllthomas 18 hours agorootparentprevIt's my understanding that legitimate vote totals aren't likely to conform to Benford's law in the first place. Even if that's the case, though, there might very well be other applicable tests this would run afoul of. reply stouset 18 hours agorootparentI’m not a statistician so I may be confusing it with Zipf’s law. But IIRC tallies from individual precincts should roughly conform to Benford’s law. reply adgjlsfhk1 18 hours agorootparentPrecints have roughly even populations and therefore typically don't conform to Benford's law. https://www.youtube.com/watch?v=etx0k1nLn78&t=76s&pp=ygUQYmV... reply dllthomas 18 hours agorootparentprevI think the concern is that precinct size tends to cluster in ways that mean results can cluster in ways that - for a large portion of the data - does not span a full order of magnitude. reply dllthomas 16 hours agorootparentTo elaborate, if we imagine a polity with precincts that turn out 10,000 people each election, with two major party candidates that each get between 20% and 80% of the vote, we'd see precisely 0% precincts with a leading digit of 1, much less the ~30% predicted by Benford's law. Of course that doesn't exactly describe any real polity, but it doesn't seem surprising that real elections would be enough like that to screw with the pattern. reply immibis 17 hours agorootparentprevThe Biden election in 2020 also failed Benford's law - unless you're suggesting that one was fake, it seems that failing Benford's law is okay. reply selimthegrim 16 hours agorootparentThere was a good paper in an American Statistical Association journal about this. https://chance.amstat.org/2022/04/benfords-law-votes/ https://www.tandfonline.com/doi/abs/10.1080/09332480.2022.20... reply stouset 14 hours agorootparentprevNobody is saying that failing a statistical test is by itself indicative of anything. reply lostlogin 14 minutes agorootparentStatistically, yes they are. Immibis just did. reply lazide 17 hours agorootparentprevIf they can get away with being balatant, that is even more of a show of power. Think of it this way - who has more power in a relationship? The one who is really good at cheating and hiding it? Or the the one who doesn’t even try to hide it, but suffers no consequences? Just look at how many comments are trying to figure out how the numbers could be legitimate, and how unlikely it is that Maduro is going to actually be removed from power. reply refurb 17 hours agorootparentprevBut votes aren’t tallied in one location, districts individually tally. So now you’ve got to force each of those districts to change the numbers. reply ordu 17 hours agorootparentprevGenerate 10,058,744 random floating numbers from [0,1), and count how many will fall into each of the intervals: [0, 0.522), [0.522, 0.522+0.442), or [0.522+0.442, 1). You can do it with less calculations if you know how to generate random numbers from binomial distribution. Then you should calculate percentages from these three numbers just to be sure they are right. It is not difficult at all, but it needs some basic programming skills and some basic knowledge of statistics. reply wrsh07 18 hours agorootparentprevHard. Naively, run the election, use real vote counts, claim that you're the one that got more. Ok but now we need to fake this on a local level. But everybody knows people in this district are more Party A and in that are more Party B. Well.... let's correct for that... If you want to give top line numbers, fine. Credible local numbers would get really hairy reply zaik 13 hours agorootparent> Naively, run the election, use real vote counts, claim that you're the one that got more. I think this would be even more obvious, even to the general public, especially when there is a landslide victory. Oh, your result is 70%? That's exactly what the exit polls said about our candidate. reply BurningFrog 15 hours agorootparentprevIt's not hard for you or me. But for the brutal thugs running Venezuela, it is a very advanced conept. reply fragmede 15 hours agorootparentit's like Russia killing someone with polonium. Hitting 60% exactly sends a message to anyone with the bright idea of running against the brutal thug's preferred candidate that it might not be a good idea, because there are brutal thugs involved. reply glenstein 16 hours agorootparentprevActually think this is a fascinating question, although perhaps for different reasons within whatever reasons might have led you to ask it. I think you raise a legitimate point that it's not that hard to create ugly numbers. I also think that authoritarian social dynamics come to these questions with a kind of brutal simplicity, lack of intellectual curiosity or creativity, and a lot of the traits that would entail a value for democracy are mutually exclusive with the brute simplicity of authoritarian mindset. And so the story they choose to tell of how they won is going to have similar hallmarks of brute simplicity and absence of nuance. reply worewood 15 hours agorootparentprevDepends on if you're in on it with the forgers or if you're against it but being forced to do it. It's the perfect clue to leave in, as its intention is plausibly deniable and you can tip statisticians to uncover the fraud. reply anvuong 10 hours agorootparentprevYou just need to run some Monte Carlo sims where the priors are your desired rates, then use this results to alter the real numbers. It's as random as it gets. reply onlyrealcuzzo 19 hours agorootparentprevVotes are not random. So it would be non-trivial to make results look real. Additionally, if even a few polling places release real data - that can really complicate things. It will look very, very suspicious when some polling places display wildly different behaviors (especially if they match expectations) then the rest of the polling places. reply tptacek 19 hours agorootparentprevI don't know, but the numbers they provided here are impossible. reply forinti 19 hours agorootparentprevUse the real numbers but change the owners of each count. Except, of course, if the winning party has a huge advantage which you don't think people would buy. reply a0123 20 hours agorootparentprevNo you see, they had the perfect plan. But they got foiled by that one thing they always forget at every single election (that never gets brought up when your government agrees with the result, because in that case it's just a \"statistical anomaly\" or \"shit happens sometimes\") reply colimbarna 19 hours agoparentprevThanks. Note to self: Next time I want to rig election results, generate a random integer between 54.2% and 54.3% of the vote and count it as the winner's vote, subtract from total pool, wash rinse repeat. reply sien 19 hours agorootparentIt's remarkable that they don't do this. The sheer incompetence of the Maduro government and other governments that rig election results is surprising. reply IAmGraydon 17 hours agorootparentWell, yes, but I think you are vastly overestimating the percentage of the population that would even think of this. Countries like Venezuela have a major problem with brain drain as it is. There's very little chance they would think to get a competent statistician involved in rigging their election. They're just simple numbers, right? You don't know what you don't know. reply wruza 6 hours agorootparentprevYou’re much more intelligent than any of the people that control your life, especially so in a dictatorship. That’s a pill hard to swallow, but ideas itt aren’t even remotely a concern for them. They are idiots with a microphone who excel at being at power, that’s it. Everything else gets done by lower and lower ranks with higher and higher competence. Since election rigging isn’t an industry, you can’t expect it to be any smart. It’s not even that “only 1% who understands will be unconvinced, so why care”. They simply aren’t aware of this because it works without it. reply dinobones 18 hours agorootparentprevSo there are 2 things that may not make this no longer so surprising. 1) The Maduro government is more like a large gang that is holding a population hostage, than a government. All major businesses/imports/exports are owned by people connected to the Maduro regime. They are extorting remissions out of the population because they're the only ones who can import products. The government is so incompetent, it no longer has sufficient machinery or brains to operate their petroleum extractors, so instead they've pursued the more lucrative method of drug smuggling. The upper echelons of military are in on it and are all very individually wealthy, the lower echelons are brainwashed, but still well compensated for a \"government\" employee in Venezuela. Think $100 month vs $3 a month. This \"government\" will never give this up. They make too much money, and they have bought out the military. They can't just peacefully go away, or they will be tried for their crimes in any major nation. Almost every country has placed sanctions on various high level individuals from the government and frozen all of their assets. 2) There are no intellects in this government. The socialists that fought violently in the 90s that had little/no education rose up the ranks and are now extravagantly rich and powerful. Imagine if you took a bus driver and made him the dictator of a country. That is exactly what happened, Maduro was literally a bus driver. This is not to disparage bus drivers, they're fine people, but countries should be ran by experts. Economists, politicians, lawyers, people with some form of education. They don't understand economics. They don't understand engineering. Almost all of the intellectual work of the country is outsourced to Chinese or Russians. The entire country is being held hostage by people who have about a 3rd grade education, and that's being generous. But it's because they have guns, and money. But mostly the guns. reply ithkuil 11 hours agorootparentWhy didn't they outsource the election count rigging to Russian or Chinese? Because they didn't know they would need help? reply noirscape 10 hours agorootparentBecause the Russians (don't know about China) also don't try to hide it. Not hiding your election fraud isn't always a sign of incompetence; it's also a show of power over the people these dictatorships are oppressing. In Russia, the election is blatantly forged[0]. The goal here isn't just to validate the dictatorship it's to dare you to speak up against it so the nice men with guns can knock on your door and tell you to knock it off, whether that's nicely or less nicely. [0]: https://www.economist.com/graphic-detail/2021/10/11/russian-... reply wruza 6 hours agorootparentKnock it off why? The electorate doesn’t care, it will never get to tv or average feed or even have effect on an average person who barely understands the graph. Everyone knows it’s rigged. This “power show” argument copes with dumb reality more than anything else, it is a HNer idea of how to be a dictator. Power doesn’t need to show itself in such an intricate way, as if it was hiding. It’s right in your face all the time. reply lupusreal 10 hours agorootparentprevThat would significantly weaken whatever negotiating position they have with either country. reply xenospn 12 hours agorootparentprevHave you ever heard a politician speak? Not surprising at all. reply einpoklum 21 hours agoparentprevThe odds are, that if you go looking for any one of multiple low-probability events, one of them will be found to have happened. reply KennyBlanken 21 hours agoparentprevIt's called \"digit tests\" and it was further theorized that the last digit had a particularly even distribution in natural, honest elections. Further research showed that last digit test wasn't very good - there are multiple obvious counters to the test. reply lolinder 17 hours agorootparentThis isn't a digit test, though—the giveaway here isn't a problem with the last digit (or any single digit), the giveaway is that the vote tallies reported exactly match what you would arrive at if you attempted to derive them from nice round 3-digit percentages. reply a0123 20 hours agoparentprevnext [4 more] [flagged] educasean 20 hours agorootparentMany instances of numerical manipulations end up being discovered because the cheater didn't understand math well enough to hide their tracks correctly. See this link for a recent example that's been on my mind: https://en.m.wikipedia.org/wiki/Mnet_vote_manipulation_inves... Basically, they just grabbed a random-looking numerical constant and used its multiples as the difference between vote numbers. reply tryauuum 20 hours agorootparentprevI don't understand your logic. \"The easiest thing to do\" is to do less thinking, less mathematical operations reply michaelmrose 18 hours agorootparentprevI have always called the argument that someone couldn't have possibly done it because it would be stupid to have done so the \"Connie Defense\" after a woman who tried to assert same before I picked her up and put her out of the house like Fred Flinstones cat. This was after she was caught driving without a license while speeding and smoking weed in a state where it was still illegal. reply nikolay 21 hours agoparentprevWhat's wrong with announcing results with rounded percentages?! reply kadoban 21 hours agorootparentNothing. The problem is when you obviously picked the rounded percentages that sounded good first and then calculated the number of votes from that. reply nikolay 21 hours agorootparentNot necessarily. If the person announcing was given the number of votes and rounded percentages, then this could explain it. For example, in my country, they always report only turnout as a percentage with a single decimal and the share of each candidate/party with up to 2 decimals, never the number of votes - who cares about the absolute numbers anyway? reply forgetfulness 20 hours agorootparentThe thing is, that the absolute number of votes work out to give the announced percentage with 6 decimal digits, just as if they put \"51.2%\" on a calculator and worked backwards. The point is that they didn't actually round the percentage, it was actually 51.199999 for the President and 44.199999 for the opposition, the only credible explanation is that they picked the percentages and then cooked the absolute numbers to line up, so the numbers look \"ugly\", but the percentages are neat. reply mateuspires 1 hour agorootparentFinally some good explanation reply foobarqux 18 hours agorootparentprevAs they say in the article one explanation is the guy publishing the numbers was not given the actual counts only the percentages and imputed the counts on his own. reply lolinder 17 hours agorootparentThat's fishy in its own right. The absolute vote tallies are the key thing in a democratic election. The percentages are a derived value to quickly make sense of the vote tallies, but the vote tallies are the actual results. Why would you need to derive vote tallies from percentages when you derived the percentages from the tallies? It'd be like feeding your English marketing copy into Google translate to Spanish and back and using that instead of the original copy. reply foobarqux 17 hours agorootparentBecause voting results are universally reported as percentages, that's what everyone uses and understands. reply tptacek 17 hours agorootparentReporting just the percentages makes sense. Reporting rounded versions of those percentages not only makes sense, but is the universal idiom for reporting percentages. But reporting synthesized vote counts from the percentages --- even from non-rounded percentages --- is not normal. People on this thread are hung up on the reported percentages, but those don't matter in this analysis at all. They're not the problem. The problem is the counts themselves. Discard the reported percentages entirely; exact same critique, one statistics students would spot instantly. reply foobarqux 17 hours agorootparentMaybe I don't understand what you have identified as the problem. My understanding of the article is that the raw tallies should not correspond to \"precise\" rounded percentages. The article in an addendum points out one way that could legitimately occur (some underling has the totals and rounded percentages but needs the raw tallies and naively multiplies to get them). reply tptacek 16 hours agorootparentI'm summarizing that PPS in my comment. The exculpatory scenario is: (1) start with real numbers, (2) compute percentages, (3) round percentages, (4) discard original numbers, (5) compute new numbers from the round percentages. Steps (4) and (5) don't have any valid explanation, and few (though maybe some) plausible human error explanations. As long as we're on the same page that nobody ever had any business reporting the numbers in step (5) --- they're completely fictitious! --- I don't have much to argue about here. The politics aren't interesting to me. reply kelipso 3 hours agorootparent> Steps (4) and (5) don't have any valid explanation, and few (though maybe some) plausible human error explanations. It does... Person A didn't send the original numbers to Person B. And then Person B wanted to publish a document that showed the original numbers anyway (maybe they were asked to by a media person or something). And they did the glaringly obvious calculation of g% x total_votes and called it a day instead of being delayed for hours or days waiting for a request for the original numbers. This is really a very common scenario that happens everywhere in multiple fields. reply tptacek 1 hour agorootparentPerson B made up vote counts for the candidates in your scenario. That is not a very common scenario in official elections results reporting, which is what this was. reply lolinder 17 hours agorootparentprevNo, they are universally reported in raw numbers accompanied by percentages, as indeed they were here. The raw numbers are universally understood to be derived from the percentages and not vice versa. The votes are the ground truth. That's how elections always work. The votes are what counts, the percentages are an abstraction to make the votes easier to parse. Any government agency that doesn't operate that way doesn't understand democracy, even if they weren't committing outright fraud. reply foobarqux 17 hours agorootparentFirst these were intermediate results. Second virtually no one reads or understands raw tallies, I don't know anyone who would or could quote them in any election. The final result, the result that is published as a headline in the newspaper are the rounded percentages. No one is saying that the percentages are not derived from the raw tallies they are saying that it might be that somewhere in the game of telephone to the person that goes on TV and reports only the percentages were communicated and they realized they should put the tallies in too so they imputed them from the numbers they had, the total votes cast and the percentages (and naively it seems obviously okay to do that). reply mannykannot 15 hours agorootparent> Virtually no one reads or understands raw tallies... I believe virtually anyone could look at the raw tallies and see which is the largest, and that a majority could calculate the percentages by themselves, if they were so inclined. This was direct election plurality voting, not some sort of proportional voting scheme, and even if it were, having the raw tallies in the public domain is essential to transparency, verification and legitimacy. reply lolinder 17 hours agorootparentprev> it might be that somewhere in the game of telephone to the person that goes on TV and reports only the percentages were communicated and they realized they should put the tallies in too so they imputed them from the numbers they had And I'm telling you that anyone who handles votes this way doesn't understand democracy. The best case scenario here is that the Venezuelan government doesn't really care about the vote tally (which is, again, bad, because the votes are the thing). The worst case is that they fabricated it entirely. Neither one speaks well for the state of democracy in Venezuela. reply marcosdumay 20 hours agorootparentprevThat's a really bad thing and a reason not to trust the entire system. They should report the absolute number of votes at each counting station. reply nikolay 19 hours agorootparentI am talking about publicizing on media - the raw data of Bulgarian elections is available for download in real time during the counting and afterward [0], including the scanned protocols of each polling station and the video recording, which is now required. Even if the voting is electronic in particular (well, most) stations, there's still a paper protocol signed by the members of the section's committee. A tweet, an article, or a chart on TV doesn't prove anything, as they are not official documents. [0]: https://results.cik.bg/ reply marcosdumay 19 hours agorootparentWell, nobody else is talking about the headline numbers. That was the miscommunication. reply lxgr 21 hours agorootparentprevBut they did report the absolute number of votes. reply nikolay 19 hours agorootparentWhere? In a tweet? reply kadoban 21 hours agorootparentprevA possibility, but not a good one. Depending on your goal, you either care a _lot_ about the raw number (in which case doing that calculation is _insane_), or you don't care really at all (so...why would you calculate it?). reply paxys 21 hours agorootparentprevThe didn’t announce the percentages, they announced the vote counts. reply nikolay 21 hours agorootparentWhy is that article not pointing to the source? I've looked for it, and I couldn't find it. reply kgwgk 21 hours agorootparenthttps://x.com/yvangil/status/1817787106237743565 reply nikolay 20 hours agorootparentI don't see the total number of votes/ballots. Is the vote in Venezuela 100% electronic? If not, there might be invalid paper ballots, too. reply olalonde 19 hours agorootparentThey are read aloud by the presenter in Spanish (both total votes and percentages). You can also see them in the tweet if you don't speak Spanish. The announcer appears to represent the national electoral council (Consejo Nacional Electoral), so it's unlikely that he didn't have access to the exact counts (and had to compute them from percentages). reply KennyBlanken 21 hours agorootparentprevIt's...rarely to never done? The exact counts are nearly always provided by voting officials. The press might summarize an election in whole numbers and maybe round up, but...that's very different from voting officials doing it. reply a0123 20 hours agorootparentprevnext [5 more] [flagged] noduerme 20 hours agorootparentOr maybe western democracies do demand higher standards of transparency. Notice which countries called to congratulate Maduro immediately without waiting a day to find out if any the announced results were valid: Russia, Iran and Cuba. Paragons of liberty. reply stoperaticless 20 hours agorootparentprevs/(non-)?western//g > See when democracies do it, it's ¨just to make it simpler\" > When dictatorships do it, it's \"fraud\". Seems plausible. Credentials and reputation matter. reply devnullbrain 20 hours agorootparentprevIn western democracies, among others, we use \"\" to denote that we are quoting somebody. reply killingtime74 20 hours agorootparentprevIn western countries power is handed over routinely amongst political enemies. So what, the incumbent is cooking the books to give power to their rival? If power is being handed over, where is the book cooking? Here they are staying in power. You think the Liberals in Australia wanted to give power over to Labor? You think Obama liked having Trump follow him? Macron cooked the votes so his own party lost the majority? reply notjoemama 21 hours agoprevI recall having read about elections in Africa and the troubles they faced. I can't find it now, but there was one particular website offering a very detailed but rigorous approach to determining the legitimacy of elections. I'll offer this article from the BBC as a stand in for the criteria (from 2016): https://www.bbc.com/news/world-africa-37243190 Vote rigging: How to spot the tell-tale signs 1. Too many voters 2. A high turnout in specific areas 3. Large numbers of invalid votes 4. More votes than ballot papers issued 5. Results that don't match 6. Delay in announcing results I would encourage anyone from Venezuela to look into the history of elections in Africa. It is well documented and criteria well supported. reply goodcanadian 10 hours agoparentOne more tell tale sign is if a particular candidate's vote count correlates to voter turnout. That is a good sign of ballot box stuffing. [i.e. a candidate gets a higher percentage of the vote in districts with higher turnout] reply HPsquared 9 hours agorootparentCouldn't it also just be one party being very \"organised\" in that area and getting their people out to vote? reply motohagiography 18 hours agoparentprevI have family who volunteered as international election monitors and these are the criteria they used as well. Ironic, really. I've been against electronic voting for over a decade for the same reasons. It's a ritual that if you don't do it correctly and with integrity, you get challenges to the results. Only question is how those challenges manifest. reply soco 3 hours agoparentprev7. Outliers. Like in the recent Romanian votes, in the same building there were 4 booths. On 3 of them a party got around 150 votes each, on the fourth zero. But did the authorities care? No, because it's not their party. reply kirmerzlikin 11 hours agoparentprevLast year there was this HN post about people's efforts to validate results of the Nigerian elections. https://news.ycombinator.com/item?id=35272227 reply the_af 20 hours agoparentprev> I would encourage anyone from Argentina Surely you meant Venezuela? reply notjoemama 20 hours agorootparentThank you! I had just been reading on another site about the US and it's \"involvement\" in a previous election in Argentina. Appreciate the correction. Oh my, I need to step away from the computer today. :/ reply sam36 20 hours agoparentprevnext [8 more] [flagged] knowaveragejoe 19 hours agorootparentWe're still clinging to this in 2024? Wow. reply aniviacat 18 hours agorootparentIf you consider the US election to clearly not have been rigged, then you should question the legitimacy of the signs listed in the top level comment. If the signs don't convince you that the US election was rigged, they shouldn't convince you of other elections being rigged, either. (I'm not from the US and don't care much about the US election. But I do think that the comment which sadly was flagged made a valid point about the signs not being useful indicators if they also apply to elections which are not rigged.) reply adamtaylor_13 19 hours agorootparentprevSuppose there was legitimacy to this, which many believe, why wouldn’t we still talk about this in 2024? Are we not allowed to discuss history? reply AnimalMuppet 19 hours agorootparentBy 2024, most people should have figured out that there wasn't legitimacy to this. reply adamtaylor_13 5 hours agorootparentWhy? What happened in 4 years that revealed to everyone beyond a doubt that it wasn’t legitimate? Where I live, no one questions that the election was rigged. Most believe it was. I haven’t done enough of my own research to know one way or the other. reply AnimalMuppet 5 hours agorootparentLosing 60 out of 60 court cases that claimed election fraud should have been a data point. (Or 60 data points.) reply HPsquared 9 hours agorootparentprevPeople still complain about Brexit constantly in British newspaper comment sections. reply GolberThorce 17 hours agoparentprevThis criteria is erroneous as the 2020 US election proved. The UN updated its Election Observation standards, and Venezuela's election mostly passes them. reply SXX 4 hours agoprevBTW when actual raw electoral data is available it's possible to create infographics that far easier to read. Like there been Shpilkin graphs for every major Russia elections. When cental authorities trying to match specific number in percent of votes it's always obvious on scale. Like you basically can see \"cells\" on these graphs that appear because of falsefied results on particular voting stations: https://www.economist.com/graphic-detail/2021/10/11/russian-... https://meduza.io/en/feature/2024/03/21/putin-2024 reply stapled_socks 21 hours agoprevTo play the devil's advocate: It's possible that the person making the announcement was only given the rounded percentages and the total number of votes, and then \"created\" the number of votes per candidate to fit to the format of the announcement. That would be sloppy, but not malicious. reply worstspotgain 20 hours agoparentIt's technically possible that that was not their weed and their meth in their pants because those were not their pants. However when they have a mile-long rap sheet for selling drugs, it weakens their argument a bit. reply culi 20 hours agorootparentWhat's the mile long rap sheet though? The group that's alleging fraud (AltaVista) is using images of printed receipts from different voting places as a sample to estimate the final vote. That group also said it's same technique resulted in election outcomes that are within 2 points or less of the announced outcome for 2021, 2018, and 2015. This seems like a new and unique accusation for Venezuela Source: https://www.nytimes.com/2024/07/31/world/americas/venezuela-... reply JumpCrisscross 20 hours agorootparent> What's the mile long rap sheet though? Venezuela’s terrible electoral record post Chavez. reply dmix 17 hours agorootparentAnd the fact the gov quietly funds roving mobs of bike gangs to intimidate the populace. On top of that they completely control 10% of the Venezulas cities. > Human Rights Watch described colectivos as \"armed gangs who use violence with impunity\" to harass political opponents of the Venezuelan government.[10][11] Amnesty International calls them \"armed pro-government supporters who are tolerated or supported by the authorities\".[12] Colectivos have attacked anti-government protesters[1] and Venezuelan opposition television staff, sent death threats to journalists, and once tear-gassed the Vatican envoy.[10] Through violence and intimidation, by 2019 colectivos increasingly became a means of quashing the opposition and maintaining political power;[9][13] Maduro called on them during the 2019 Venezuelan blackouts.[14][15] And that in poor areas these armed gangs are directly involved in bringing people to voting stations > Every member of a colectivo is required to bring ten individuals to vote at polls during elections.[34] Over time, colectivos became more heavily armed and their criminal activity increased.[3] A small number of groups maintain community and cultural functions; most are \"criminal gangs with immense social control\", who \"work alongside the security forces, often doing their dirty work for them\", according to InSight Crime.[6] Members can be difficult to identify because they often wear masks and do not have license plates on their motorcycles.[9] https://en.wikipedia.org/wiki/Colectivo_(Venezuela) The fact there were armed guards around the voting stations reply olalonde 19 hours agorootparentprevIt seems Maduro was way behind in the polls. https://www.as-coa.org/articles/poll-tracker-venezuelas-2024... reply culi 18 hours agorootparentDepends which polls you're looking at. So far, no non-US-linked pollsters have shown Maduro behind (that is, behind the US backed opposition candidate). If you look at something like Hinterlaces you get a very different picture reply olalonde 18 hours agorootparentAccording to this Venezuelan news article[0], several did: > Well-known pollsters in the Venezuelan political sphere, such as Datanálisis, Datincorp, Delphos, and Consultores 21, along with the emerging Poder y Estrategia, indicated that Urrutia had more than 50% of voting intentions. [0] https://www.lapatilla.com/2024/07/15/la-guerra-de-encuestas-... reply culi 16 hours agorootparentThanks for the article. I had to translate as my Spanish isn't very good. These seem to be the main points > Surveys of career-marking firms in the Venezuelan political environment, such as Datanalisis, Datincorp, Delphos and Consultores 21, as well as the incipient Power and Strategy, by political scientist Ricardo Ríos, claim that the postulate of anti-chavismo accumulates more than 50 percent of the intention to vote. > However, others, such as Hinterlaces and some practically unknown in the Venezuelan or recent data market, including Polymarket, BMI Orientation and DataViva, conclude that Maduro leads his surveys with between 54 percent and 70 percent of the preference. Another, ECSC, talks about a technical tie tipped slightly towards opposition. > The C-INFORMA Information Coalition, made up of media teams such as Media-analysis, Cocuyo Effect, Fake News Hunters and Probox, concluded this month that 6 out of 14 firms evaluated, recently created and dubious credibility, have published 37 public opinion studies - used in a strategy - to manipulate the country's. The main point of the article seems to be that there's a lot of misleading polling in general. Which is a fair point, but does kinda leave us outsiders in the dark reply uoaei 12 hours agorootparentwhich makes all this commentary all the more appalling. rationalism requires more than poorly-informed guesses. rationalism allows for the distinct and non-negligible possibility that surveys are gamed by manipulating the wording of the questions and/or who is asked to respond. skepticism is more than toeing the line of whatever country you think is morally righteous reply throwaway59148 18 hours agorootparentprevWe are meant to believe that Maduro outperformed his exit polling by twenty percentage points. Source: https://www.foreignaffairs.com/venezuela/venezuela-elections... If you have serious doubts about whether the election was fair (it wasn't,) I'd encourage you to read the whole article as a primer on how and why the election was conducted and what it might mean for Venezuela going forward. reply mihaaly 21 hours agoparentprevTrue in general, but here \"the President of the National Electoral Commission announced the winner\". Sloppy in this situation equals malicious. And I wonder who gave the president the numbers to calculate with. ; ) reply culi 18 hours agorootparentSure, and it's only \"80%\" (another sloppy-looking number) of the count, but these numbers are still useful in that it'd be an insurmountable lead. Independent decision desks don't wait for exact final tallies to call a race. It will likely take weeks for every single vote to be fully counted. I agree this is at least sloppy work though. Apparently the explanation for the delay in full results is an ongoing cyber attack reply olalonde 19 hours agoparentprevUnlikely, the person making the announcement was an official from the national electoral council (Consejo Nacional Electoral). There's no reason the national electoral council wouldn't have access to the exact counts and would have to work their way backwards from percentages. Source: https://x.com/yvangil/status/1817787106237743565 reply foobarqux 18 hours agorootparentYes but that guy certainly didn't tally the votes himself, someone gave him the numbers (and someone else gave him those numbers). It's plausible that in some step only the (rounded) percentages and overall total were given and then someone downstream imputed the counts. reply olalonde 18 hours agorootparentIt's possible but not very plausible. Why would the official organization charged with overseeing the elections knowingly report inaccurate numbers when it has access to the accurate numbers? reply foobarqux 17 hours agorootparentBecause maybe they didn't have direct access to the original numbers? You can't understand that some consumer of the data might not get the original CSV only some summary? reply lolinder 17 hours agorootparentA summary that includes the exact number of votes cast and the percent for each candidate but not the breakdown by candidate? Why would someone go out of their way to construct a CSV that has the tally by candidate removed* but still has the total vote count? What would that CSV even look like? * Yes, the tally would have to be removed, because presumably there's a spreadsheet somewhere that was used to generate percentages from tallies. reply foobarqux 16 hours agorootparentYes, the percentages are the most important number, the number everyone is interested in. The next most important number is the voter turnout. You can verify this by looking at the newspaper headlines of any election. Again unless you are an electioneer no one cares about the raw numbers so it would not be surprising that only the percentages and total are communicated to the public relations department. I don't understand your comments about the CSV: I'm saying that the raw CSV is not being distributed, only the summary statistics. reply lolinder 16 hours agorootparent> Yes, the percentages are the most important number, the number everyone is interested in. Then why did the hypothetical sub-sub-librarian who put together the final spreadsheet feel the need to go back and repopulate those numbers? Clearly they thought people would want to see them, right? > The next most important number is the voter turnout. You can verify this by looking at the newspaper headlines of any election. So, in this hypothetical, when the tallies per candidate are expressed as percentages it's because percentages are the natural way to think about these things, but when voter turnout is expressed in raw numbers that's because raw numbers are the natural way to think about voter turnout? Voter turnout is the only number in the set that I could possibly see making sense to express only as a percentage! reply foobarqux 16 hours agorootparentMy recollection is that turnout is usually quoted in both percentage and absolute numbers but quoting it as a percentage requires external data (population demographics) which presumably isn't in the electioneering department. Why do you have such a hard time believing that election results (e.g. for a union, for school president etc) might be communicated like \"55 to 45, 3000 people voted\"? reply lolinder 16 hours agorootparentBecause I've literally never seen percentages without tallies reported in any context. It's apparently so uncommon that your hypothetical person who created these clearly-not-real numbers felt the need to go backfill them. Explain that. If it's so unnecessary to report the tallies and people only want to hear the percentages, why did your hypothetical person go back and backfill them? reply foobarqux 15 hours agorootparentPretty much every headline number does not show tallies (it's impossible to fit in a headline in any case). It's often included in a more detailed analysis further in an article or segment which the vast majority of people don't read. My point is that they are obviously far less important numbers and not the \"headline\" numbers. So one person (the supplier) could easily have decided (or misunderstood that) the detailed numbers were not required and another person (the consumer) decided that they needed or wanted them because they are conventionally or should be reported. Remember too that this was not the final completed tally so someone may not have supplied detailed results for intermediate reporting. If you've ever worked at a big organization it really isn't hard to understand that the left hand doesn't always know what the right hand is doing. reply Skeime 10 hours agorootparentIt is inconceivable to me that in a competently-run real election, you would not transfer actual vote tallies at any point in the (internal) process. This is true for intermediate results just like it is true for final results. If percentages are calculated at all, it is to gain insight into your local results. (I volunteer at a polling station. We count the votes, and submit the raw counts to the next level. Then, we might do a quick calculation of the percentages, just to see how our voting district did. I can also go to my municipality's website and see the results of my polling station, and for the entire municipality. There are absolute numbers, which are reported to the next level, and the website also shows percentages, again, to gain insight into the municipality's results. Even if partial results are reported to the next level, this absolutely happens in the form of \"these districts with this number of eligible voters have been counted; these are the absolute numbers\".) Everybody in the chain of responsibility should understand that the absolute numbers are what counts. And even if some people don't, the system must be set up in a way where you cannot transfer anything else. If there is even a serious possibility that someone might re-create voter counts from percentages, your system is a failure, and here it seems to have happened at the highest level. reply nikolay 21 hours agoparentprevI've never seen any preliminary results announcing numbers of votes - it's always rounded up percentages with 1 or 2 decimals. reply yongjik 20 hours agorootparentIn my country (Korea) they broadcast vote counts, per district, in real time as data pours in from all over the country. It's a big entertainment going on for the whole night. And you can log onto the website of the office of the election commission and see raw numbers by each voting district. It's 2024; I'd consider it a minimum level of government competency if anyone wants to be called a democratic country. reply HPsquared 8 hours agorootparentThis process led to a lot of controversy in the 2020 US Presidential election. reply lumb63 18 hours agorootparentprevAs an American, boy, do I have news for you… reply zamadatix 20 hours agorootparentprevI'd say it's extremely common to announce numbers of votes both as they come in and when the final total is known. Here in the US major news networks (ABC, CNN, Fox, 270towin, and others) all have live maps that show the total number of votes + total percentages during the voting period. They usually also let you hover over the states/counties to see the percentages and votes for the particular area. E.g. here's the Fox map https://www.foxnews.com/elections/2020/general-results and total votes comes first in the same font as percentages marked to the side. During the election these totals and percentages are live numbers. And in the US we're not even that interested in the popular vote since it's all about the electoral college which has historically not always aligned with the popular vote numbers anyways yet we still list the totals as they come in. reply ptero 20 hours agorootparentprevIf the vote numbers were not provided, this would not have been an issue. But in this case they did announce the vote numbers. reply shusaku 20 hours agoparentprevThe article has been updated to mention this theory > Commenter Ryan points out that you could also explain this data pattern as a result of sloppy post-processing, if votes were counted correctly, then reported to the nearest percentage point, and then some intermediary mistakenly multiplied the (rounded) percentages by the total vote and reported that. I have no idea; you'd want to know where those particular numbers were coming from. I’m inclined to believe this. It seems like if they had some grand conspiracy it’d be more likely for them to just add some votes here and there to the real number. reply __MatrixMan__ 20 hours agorootparentI hope you're right. If there's anything more insulting than having an election tampered with, it's having it tampered with... poorly. Like, you couldn't even bother to lie precisely? reply HPsquared 8 hours agoparentprevThat's the story we'll hear anyway, regardless of what actually happened. reply q1w2 20 hours agoparentprevThat would mean that the group that released the percentage, and thus calculated it, was a different group than the one that released the raw numbers. That doesn't seem likely since they seem to be coming from the same gov't body. This is an official election release, not some PR post on their website. reply foobarqux 18 hours agorootparentBig departments have lots of people, made up of smaller groups, they are not monoliths with a single mind. reply noobermin 18 hours agoprevThe point of the article which I missed: the issue here is that the vote totals are very close to their 0.1% place roundings after multiplying the total votes times the percentages, suggesting that the vote totals were simply faked by taking the total votes and multiplying them by percentages precise only to the 0.1% place. I had mistakenly thought the quoted twitter post found it weird that the vote totals had the same leading digits as the percentages, which absolutely makes sense when the total vote count is near a multiple of 100. For example >>> 0.5123 * 1_002_232 513443.45359999995 I had pulled an all-nighter (writing a grant proposal actually) and was steaming mad reading this and had to scroll a bit. May be a comment like this will help someone else out who might be confused. reply energy123 17 hours agoparent> the issue here is that the vote totals are very close to their 0.1% place roundings after multiplying the total votes times the percentages That's right, but the conclusion is a bit stronger than just \"very close\". There was no other integer that could have been closer, which is consistent with them rounding their fraudulent vote count up/down to the nearest integer. reply notfed 13 hours agorootparentYeah, \"very close\" is not the right wording: \"EXACTLY\" is. reply MontagFTB 19 hours agoprevThis reminds me of the story how the height of Mt. Everest was first measured at exactly 29,000 feet. The surveyor’s boss at the time added two feet thinking no one would trust such an exact number. reply adin8mon 16 hours agoparentI wonder why he added two feet instead of three, or some decimal. reply worstspotgain 20 hours agoprevThis should remind us that \"One Person, One Vote\" can all too easily slip into \"One Person, One Vote, One Time.\" For Venezuela that one time was in ~1998. reply oceanplexian 20 hours agoparentI guess it might be quite ironic but if people want to vote in a dictatorship, don’t they have the right to under a true democracy? reply worstspotgain 20 hours agorootparentNo, that's a meta-democratic vote, not a democratic vote. Many constitutions disqualify insurgents and revolutionaries from running for office for this reason. At a minimum you'd have to follow the super-majority process for amending the constitution if there is one. In practice, it's no different from having a revolution. Might as well wear the shoe if it fits. Congrats to the generalissimo dictator! reply oceanplexian 20 hours agorootparentIn this case the question would be, do citizens in a democracy have the right to dissolve their government peaceably, provided they meet whatever threshold is required in that system (Could be a super majority, for the sake of argument)? I’d argue it must be or it’s not really a democracy. reply worstspotgain 20 hours agorootparentThey have the \"right\" to have a revolution too - many countries treasure the revolutions they had. They can amend the constitution and make another democracy. They can also amend the constitution and make a dictatorship. Or just have a dictatorship without bothering. Those do not need constitutions at all. To have a vote that turns a democracy into a non-democracy is a meta-democratic vote, not a democratic vote. Abusing a democratic system to surreptitiously make a non-democratic system is just a caveat that dictators find convenient to use. reply drexlspivey 19 hours agorootparentA dictator is just someone with absolute power. How he got the power is orthogonal. He doesn’t have to gain power through insurrection or a revolution, he can gain it inside a democratic system. In fact in Ancient Rome, where the term comes from, the Dictator was appointed by congress in times of crisis. reply dllthomas 18 hours agorootparent> Dictator was appointed by congress in times of crisis. A dictator was appointed by a consul, at the direction of the Senate, with the job of solving a specific problem. The history of the dictatorship in ancient Rome, before Sulla, is really interesting, and differs quite a bit from the popular understanding: https://acoup.blog/2022/03/18/collections-the-roman-dictator... reply worstspotgain 19 hours agorootparentprevIndeed, dictators are dictators, including all those in your examples. In the cases I brought up, an elected leader can turn into a dictator by not leaving when they lose an election, canceling regular elections, faking the vote totals, etc. One Person, One Vote, One Time. reply lucianbr 13 hours agorootparentprev> No, that's a meta-democratic vote, not a democratic vote. Now whoever decides which votes are democratic and which are meta-democratic is the de-facto ruler of the country, and elections are just a show. Any time you don't like the result - \"well, it was meta-democratic you see, and therefore does not count\". It's frankly incredible that people put out arguments like this with a straight face. The only way elections can work is if you actually abide by the result, whatever it is. If you get to reject some of the results, then you might as well not do elections at all, just let us know what results you want. reply CSMastermind 20 hours agorootparentprevTwitter has been saying, \"you can vote yourself into a dictatorship but you have to shoot your way out.\" reply manoweb 19 hours agorootparentprevPure democracies will ALWAYS vote themselves into dictatorships. That is why Constitutional Republics that use representation are more long-term stable. reply weberer 10 hours agorootparentSwitzerland has been a pure democracy since the 1800's and they're still not a dictatorship. reply beaglesss 16 hours agorootparentprevIt's not clear to me constitutional republics are superior to monarchy for stability. reply shiroiushi 13 hours agorootparentThere's plenty of historical examples of monarchical governments where the king/queen/emperor was pretty good (or even great), but then died and was succeeded by their shitty son/daughter and things quickly went to hell. The primary strength of a democratic republic (or a monarchy where the monarch has no power at all and is merely a figurehead, as is the case in many of today's monarchies) is avoiding this scenario. It doesn't guarantee stability, but monarchies are guaranteed to be unstable precisely because children are frequently not like their parents, and those systems don't have a way of removing shitty rulers, so you only get stability as long as the monarch is alive and of sound mind. reply tim333 9 hours agoprevIt's all nice looking for suspicious patterns but a bit pointless when the election is very obviously rigged (107% of votes counted etc) and Maduro is like I control the army what you going to do about it? The latter is a more interesting question. There must be some way to get vote rigging dictators out? reply SXX 4 hours agoparent> There must be some way to get vote rigging dictators out? If only other countries wasn't supplying dictator regimes with money, but it's very hard to do. Especially after EU gave enough money to another dictator to make him into much more dangerous warmonger. So now Venezuela isn't the worst dictatorship and it's will get more money from oil. reply atleastoptimal 18 hours agoprevIt's clear Maduro is running a near dictatorship and will do anything to keep power. The country is doing absolutely horribly, all due to mismanagement. Even with proof of fraud, he will pull whatever is needed to avoid stepping down at this point, as is the case with all autocrats. reply prmoustache 10 hours agoparentWhen a country start building statues in every major city of the current running government leader, you are already past _near dictatorship_. This is full cult of personality and dictatorship bullshit. EDIT: I saw images of venezuelans destroying statues all over the country but my partner who has been following better told me they were statues of Hugo Chavez, not Nicolás Maduro. reply culi 19 hours agoprevNo one has yet to post the actual official statement by the CNE. It doesn't seem too unlikely that they had a total vote count as well as the percentages for each candidate and released those. It feels like people are jumping to some major conclusions in this thread reply eirikbakke 18 hours agoparentHere is the CNE press conference where the numbers were announced: https://www.youtube.com/watch?v=pB7g4y4M4s8 reply culi 18 hours agorootparentWonderful, thanks! I really struggled to find this. Funnily enough they give different percentages. 51.1% to 44.2% round and round we go reply tptacek 17 hours agorootparentNo. The percentages reported don't matter. These are the same absolute vote numbers; the percentage they work out to is what matters. This seems to be tripping a lot of people up. reply culi 17 hours agorootparentIt certainly does! Watch the video. No total number is ever reported This means that \"total votes\" number was worked backwards by a third party. It's not even the CNE's fuckup reply tptacek 16 hours agorootparentNo. Watch the video. After Gonzalez' result, he reads the results para otros candidatos†. It's the same as the number in this post. It literally doesn't matter what else happens after this; you can reconstruct the result, after less than 2 minutes of the video's runtime. It's cooked. † as you can see, i am not a fluent speaker of Spanish, and i managed to work it out :) reply kgwgk 10 hours agorootparentprev> This means that \"total votes\" number was worked backwards by a third party. Any school child can \"work backwards\" that if the vote counts are X for Maduro, Y for Gonzalez and Z for others the total number of votes cast for any of the candidates is X+Y+Z. reply firekvz 14 hours agoparentprevcause they did not release any official statement, they only read those numbers on national TV and 8 hours later they made maduro sign the papers as a winners. now, more than 72 hours after elections, we still dont know the results and there is not a single place to check the acts or the numbers by pooling center. it was all fraud. reply liendolucas 12 hours agoprevYesterday there were news regarding 4 misterious flights from Cuba to Venezuela. Apparently a technical chinese team went there to rig the legitimate results, hence the delay to reveal them. Obviously unverifiable but I wouldn't be surprised to be true. Source: https://www.infobae.com/venezuela/2024/07/31/grave-denuncia-... As an argentinian and having lived the so called \"K\" period I can only say that we were extremely lucky not ending like Venezuela did (we are still facing a really hard time thanks to 20 years of robberies). For me, this period along with this so called \"bolivarian revolution\" (whatever that means) will forever be a reminder of how dangerous populism and empty political fanatisms can be. A model that can only spread poverty, corruption, and permanently fracture society just like in Argentina. reply deathanatos 16 hours agoprevReminds me of https://danluu.com/discontinuities/ reply HPsquared 9 hours agoprevIt could be someone having the total and percentages, and \"reconstructing\" the individual vote counts. Or, that's what they would say anyway in response to this. reply sergiogjr 15 hours agoprevIt will be interesting to see if they release the tallies by region, on how those number will match with the overall result. reply veltas 13 hours agoprevIs it possible some idiot was given the percentages, the total votes, and then decided they could just estimate the breakdown from the percentages for the announcement? Assuming stupidity before malice. reply koube 21 hours agoprevForgive me if this is a dumb question, but isn't every vote total extremely unlikely if you make it precise to the exact number of votes? Like the chances of getting n+1, n+2... votes is roughly the same probability. For example the probability of getting [1,2,3,4,5,6] as the winning numbers in the lottery is the same as any random set of numbers. reply jvanderbot 21 hours agoparentThe question was \"How likely is it that the votes worked out so well that they were basically even 1/10 percentages and not ugly numbers?\" So for a given number of votes, which determines a split, how many times does the split come out so nice? Answer: Effectively none - there are always ugly numbers with lots of decimal places. Now that analysis comes after they conjecture that the percentages were fixed apriori. The first comment \"That seems fishy\" basically says this. \"How can it be that we're so close to even 1/10 percentages. How can it be that we're exactly one vote off from nice 1/10 percentages\"? Fishy indeed - must be rounding. And they tell you: it's very unlikely to be 1 vote off from nice 0.1% percentage splits. reply tumult 21 hours agorootparentAnother way of writing it out: How likely is it that you'd get these votes distributions 51.2000000% 44.2000000% 04.6000000% exactly? With all of those clean 0s? Very low. But it's also possible that there was sloppy reporting and the vote counts were re-processed at some point in the chain and rounded to one decimal place. reply contravariant 21 hours agorootparentWell there weren't zeros but within rounding error it was exact. That actually gives a way to estimate the probability. There's 1002 choose 2 ways to divide 1000 permils over the 3 options. While there's 10 058 776 choose 2 ways to divide the 10 058 774 votes. That works out to about 1e-8 of the possible results being an exact multiple of 0.1% up to rounding error. Of course an actual election doesn't simply pick one of the possible results at random (heck even if everyone voted randomly that wouldn't be the case). However these 'suspicious' results are distributed in a very uniform stratified fashion, any probability distribution that's much wider than 0.1% would approximately result in the same 1e-8 probability. And pretty much no reasonable person would expect a priori that the vote would result in such a suspicious number with such a high accuracy, so this should be considered strong evidence of fraud to most people. reply neura 21 hours agorootparentprevIt's more that if you start with those clean, single decimal percentages and a total number of votes, you'd end up with decimals for number of votes, which isn't possible. So if you then remove the decimal from the votes, you get slightly different percentage values when taken to 7 decimal places, but the original decimals would still be the same. The chances of those numbers occurring normally for all 3 vote counts together is just ridiculously tiny. reply culi 19 hours agorootparentprevActually if you're going that many decimals its 51.1999971% 44.1999989% 04.6000039% reply achempion 21 hours agorootparentprevThe numbers are definitely sus, but what if they were 52.2543689% 44.2689426% 04.6345625% How likely is it that you'd get these votes distributions exactly with these exact tails? Compared to all other possibilities? reply kadoban 21 hours agorootparentBasically the same 1/verymany chance, but that doesn't matter. The difference is that there's no particular reason to choose these numbers to start with. There _is_ a reason to choose nice round, but not too round numbers: that's what humans do. reply jvanderbot 20 hours agorootparentprevThe question is \"How likely is it that humans would begin with those numbers when fudging?\" answer is low. But clean numbers? Much more likely. reply happyopossum 20 hours agorootparentprevBut that’s not what happened, if you read the article it actually expands everything out to the seventh decimal, and they’re not all zeros reply jvanderbot 20 hours agorootparentYes, they are not all zeros, but they are exactly what you'd expect if someone picked percentages that were all zeros, then added +1/-1 to get integer votes. So the argument is once removed, but still compelling. reply tumult 20 hours agorootparentprevIt is equivalent to all zeroes with the numeric precision used. reply noitpmeder 21 hours agorootparentprevThis comment perfectly distills this post. reply melenaboija 21 hours agorootparentprevThe same probability as any combination of three results with 7 decimals and adding up to 100. reply staunton 21 hours agorootparentThe question isn't \"probability you get those exact numbers\". It's \"probability that you get numbers which all have at most N decimal places\". reply enoch_r 21 hours agoparentprevIf the lottery administrator's daughter wins the lottery, he may say \"no, no - don't you see, her probability of getting the winning numbers is exactly the same as anyone else's!\" But in reality, we can say that: - her probability of winning in the world where her father is cheating is very high - her probability of winning in the world where her father isn't cheating is very low Together these two facts give us evidence about which world we're actually inhabiting - though of course we can never be completely certain! In the same way, yes, it's equally (im)probable that the winning percent will be 51.211643879% or 51.200000000%. But the latter is more likely to occur in a world where Maduro said \"get me 51.2% of the votes\" and someone just did that mechanically with a pocket calculator, which is good evidence about which world we live in. reply ChadNauseam 20 hours agoparentprevThe other commenters point at the explanation but don't explain it rigorously IMO. Here's how I'd say it. 60% is a nice, round percentage. In an honest election, this is just as likely to be reported as any nearby percentage, like 59.7% or 60.3%. As you mention, any particular percentage is equally (and extremely) unlikely. SUppose this you estimate the chance of this occurring, given an honest election, is 1/1000. 60% however is a much more likely outcome if the election results were faked sloppily. A sloppy fake is reasonably likely to say \"Well, why not just say we won 60%\". Suppose you estimate the chance of this occurring, given a sloppily faked election, are 1/100. Bayes' theorem tells us that we can use this information to \"update our beliefs\" in favor of the election being faked sloppily and away from the election being honest. Say we previously (before seeing this evidence) thought the honest:faked odds were 5:1. That is, we felt it was 5 times more likely that it was honest than that it was sloppily faked. We can then multiply the \"honest\" by 1/1000 (chance of seeing this if it was honest), and the \"faked\" by 1/100 (chance of seeing this if it was faked), to get new odds of (5 * 1/1000):(1 * 1/100), which simplifies to 1:2. So in light of the new evidence, and assuming these numbers that I made up, it seems twice as likely that the election was faked. This exact analysis of course relies on numbers I made up, but the critical thing to see here is that as long as we're more likely to see this result given the election being faked than given it being honest, it is evidence of it being faked. reply a0123 20 hours agorootparentYeah, they just forgot to report 59.869280705993% instead of 60%. They would have got away with it too, if it weren't for those cunning statisticians. They just forgot to come up with a random, credible number. Happens to the best of us I guess. To think they could have got away with it if only they hadn't forgotten. That´s what you get when you defer the dirty work to interns on their first day, I guess. Which you always rely on to stay in power. Wouldn't want to rely on competent advisers who would have reminded you to come up with a non-round number with 8 or 9 decimals. reply marcosdumay 20 hours agorootparent> They would have got away with it too Well, on this case they wouldn't. The smoking gun is their refusal to publish the counting totals, the round ratio is just some extra confirmation. reply paxys 21 hours agoparentprevThe second half of the article answers this very question. Here's an example – if I generate 10 random numbers between 1 and 100, what is more likely: all ten are multiples of 10, or at least one is not a multiple of 10? reply SoftTalker 21 hours agoparentprev> For example the probability of getting [1,2,3,4,5,6] as the winning numbers in the lottery is the same as any random set of numbers. Yes, but the comparison is not to \"any random set of numbers\" it's \"all other random sets of numbers\" The candidate got 52.200000% of the vote instead of any other percentage, not another specific percentage. reply happyopossum 20 hours agorootparent> The candidate got 52.200000% of the vote instead of any other percentage, not another specific percentage No, he got 51.1999971%. It’s right there in the second table of the article reply ithkuil 10 hours agorootparentSome other comment in this discussion claims that if you nudged the total count integer +-1 you'll never hit 52.20000000% exactly hinting at the possibility that they choose 52.2% exactly, then computed the total counts which would be a non-integer and then just rounded that. Once re-computing the percentage from that number you end up with the slightly less round-looking 51.1999971%. reply neura 21 hours agoparentprevI think you are correct, but that's missing the point of the article's content. I'm just a programmer, not a math expert, but I believe these statements are accurate. 1. It's very easy to arrive at the provided values, if you make up some percentages that only go to a single decimal value (1/10th). Though doing so would result in vote counts that are decimal, as well. Then if you just remove the decimal from those values, the given percentages don't change enough to be incorrect, but even when taken to 7 decimal places, the new values are pretty clearly due to the rounding (44.2%: 44.1999989%, 4.6%: 4.6000039%). 2. While yes, the chance of these vote counts coming up in this kind of pattern is similar to the example you provided, even if you were using 0-9 for your example of 6 values, the total combinations is about an order of magnitude less than the total vote count provided here. 3. The finer point made is that there's a very small chance for one of the vote counts to show up as a number that so nicely fits the single decimal percentage, but in this case, all 3 vote counts fit this pattern. The calculations are shown for just 2 of the candidates (so not including the \"other\") resulting only a 1 in 100 million chance. reply tumult 21 hours agoparentprevThat’s not what this article is about. Read the article. reply shadowgovt 21 hours agorootparentFWIW, statistics is hard. Having read the article, I came away with similar questions and I appreciate the sibling comments clarifying. reply tumult 21 hours agorootparentFair enough. Sorry. reply Waterluvian 21 hours agoparentprevYes. For one set. But if your next lottery is 4,5,6,7,8,9 and then 11,12,13,14,15,16 it becomes improbable. The issue here is that a bunch of the percentages imply super round numbers. The signal isn’t that there’s a round number. It’s that they’re all round numbers. reply neura 21 hours agorootparentI've tried to explain this a couple of times, but I keep falling back on the calculations used to show the problem (that it's not the numbers themselves, but the pattern). This comment nailed it with simply \"It's that they're all round numbers\". I've always been terrible at rephrasing things to make stronger points in a more concise way. Thanks! :D reply danihh 21 hours agoprevComing from a family that lived in soviet russia (and still partly is), this reminds me of Putin’s 85% approval rating. But if you ask anybody in private, nobody voted for him… reply wodenokoto 14 hours agoprevI’d like to see a pattern that is likely to put this in perspective. Rolling ten 1s in a row does look suspicious but it’s just as likely as rolling 4846211536 reply RND_RandoM 21 hours agoprevDidn't they show the distribution of votes on the TV and the sum there was 106%? reply victorbjorklund 21 hours agoparent109%. Which of course isnt better. reply bjourne 18 hours agoparentprevhttps://x.com/weegeedutchie/status/1817903230946337121 No one cared to listen to the Spanish-language broadcast where it is explained that the 4.6% is for the other candidates combined. The stats indeed sum up to 100%. reply feedforward 20 hours agoparentprevThat would make this whole article bogus. Actually it didn't add up to 106%, although the reality doesn't matter. That the mud the CIA, NED etc. throw on Venezuela is all that matters. reply guywithahat 17 hours agoprevThis is why you don’t vote away your right to bear arms reply commandlinefan 4 hours agoparentThere were just as many, if not more, statistical anomalies in the US 2020 election, but all the guns stayed in their gun lockers then. reply _joel 9 hours agoparentprevYea, be awful if, say the US, was on the precipice of slipping into a dictaorship. Thank god they've got guns, that'll make everything better! reply guywithahat 3 hours agorootparentVenezuela went from the richest country in South America to one where the average citizen lost 17lbs in a year. Once your economy looks like that, the slightest hint of armed unrest could collapse the government. The only reason Maduro stayed in power was because he could have the military shoot into unarmed crowds with no repercussions. reply krapp 9 hours agorootparentprevYes, an armed society is a polite society, and no one is more polite than, say, American police or the ATF or FBI or IRS. If you see an American walk into a school or a hotel with a gun, you know everything is going to be A-OK. reply SV_BubbleTime 17 hours agoparentprevTrue. But might not be a popular comment here. It seems many think you can carbon tax out of any problem. There is one logical resolution to where Venezuela finds themselves. No one really believes they’re going to pull out of this economic situation, nor now this political one. reply meepmorp 5 hours agorootparent> It seems many think you can carbon tax out of any problem. What relevance does this have to gun ownership? reply casenmgreen 21 hours agoprevIf the post looks odd and makes no sense, it's because CF is blocking image loads. I think there are two screenshots which are missing in the initial text. reply whalesalad 21 hours agoprevAnyone else stuck in an endless \"Verifying you are human. This may take a few seconds.\" cloudflare captcha loop? reply NJRBailey 21 hours agoparentI get this due to a browser extension I have (in my case it is the extension FreeTree, but chances are you aren't using that). Maybe try disabling all extensions and try the captcha again? reply shiroiushi 13 hours agoparentprevAre you sure you're human? reply bjourne 18 hours agoprevThe most important part of the article is buried in the PS:es: > Commenter Ryan points out that you could also explain this data pattern as a result of sloppy post-processing, if votes were counted correctly, then reported to the nearest percentage point, and then some intermediary mistakenly multiplied the (rounded) percentages by the total vote and reported that. I have no idea; you'd want to know where those particular numbers were coming from. Author has no idea about how the vote counting process works, yet he spreads FUD. There are many plausible reasons why the tallies are \"suspiciously well-rounded\". The result was announced when it, according to the Venezuelan electoral commission, was clear that Maduro had an insurmountable lead. The cutoff point may just have been 51.2% with less than X% of the votes remaining. We don't know how their statistical modelling works. reply throwaway14356 17 hours agoprevif only we had secure computing devices. Imagine a useful application of blockchain. A historic first :p reply SV_BubbleTime 17 hours agoparentIn the US we have known-flawed closed-source machines where the company executives that make them also make clearly political statements that favor the side that used to be against those machines. I have zero confidence they’re going to leap frog the US in election security. Retro. Paper, no mail, vote one day on a holiday, count by that night, all manual all reviewed. This just is not somewhere we need a high tech solution. reply ahmeneeroe-v2 2 hours agorootparent>Paper, no mail, vote one day on a holiday, count by that night, all manual all reviewed. And voter ID required reply Axsuul 15 hours agorootparentprevWe do need a better solution because running elections is very expensive while voter participation is not great if you have to show up in person. reply notfed 13 hours agorootparentThat expense is worth our democracy not getting hacked. reply weberer 10 hours agorootparentprevI disagree. I think the bar is low enough already. All you have to do is show up to the closest school. Its so easy that 10 year olds do it every day. reply Axsuul 9 hours agorootparent10 year olds don't have jobs and responsibilities. reply supergirl 13 hours agoprevmisleading article, pretending this is some kind of scientific evidence of fraud without mentioning other possible explanations. the most likely and obvious explanation is that there was a mistake in the final report not in the raw data. they just rounded the percentages first and gave them to someone who then made the report with the number of votes based on that. you can’t really distinguish a mistake from fraud in this case. and then they will fix the mistake and people will say “aha we caught them and now they try to hide it” reply account42 11 hours agoprev> statmodeling.stat.columbia.edu > Verify you are human by completing the action below. No thanks and fuck you to you too. reply aa_is_op 21 hours agoprevGod, I love mathematicians! reply acchow 21 hours agoparentThere’s also the really powerful Benford’s Law which has been admitted in criminal court cases! reply Waterluvian 19 hours agoprevI used to think that there’s something terribly embarrassing about watching people like these lying in such a pathetically obvious way. Like catching my 5 year old in a lie. But I think I’m realizing that it simply doesn’t matter. They just need the “forged document” to hold up in their hands. Not to survive scrutiny. reply jijji 20 hours agoprevsome reporting [0] is claiming the opposite: 2.75 million votes for Maduro and 6.27 million for his rival, Edmundo Gonzalez. [0] https://www.reuters.com/world/americas/government-opposition... reply jiveturkey 21 hours agoprev> That seems fishy They didn't explain why and it wasn't obvious to me. I had to think embarrassingly long about it. It's because the tally by extended decimal shows that each of the 3 rows show that the tally was back-filled from a one-decimal-place desired result. With only 3 rows I'm not so sure how strongly this proves anything but it certainly is fishy. EDIT: oh wait they do explain it. But only after they stated the conclusion so matter-of-factly first. I'd stopped reading because right then and there I thought I missed some fact or point earlier, or that they otherwise were presenting it as obvious and why wasn't it obvious to me? reply 192 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "Recent Venezuelan election results show a suspicious data pattern, with opposition candidate Gonzalez reportedly winning 67% of the vote compared to Maduro's 30%, raising questions about the legitimacy of the results.",
      "Analysts argue that the probability of vote percentages landing on exact round numbers is extremely low, suggesting potential manipulation or fraud in the reported results.",
      "The discussion highlights the broader issue of election integrity and the challenges of detecting and proving electoral fraud, especially in authoritarian regimes where power dynamics can influence the transparency of the process."
    ],
    "points": 831,
    "commentCount": 442,
    "retryCount": 0,
    "time": 1722458071
  },
  {
    "id": 41127706,
    "title": "How I got my laser eye injury",
    "originLink": "https://www.funraniumlabs.com/2024/07/how-i-got-my-laser-eye-injury/",
    "originBody": "How I Got My Laser Eye Injury Posted byPhil B July 31, 2024July 31, 2024 It has been brought to my attention that I have never actually written this story down before, merely told it in person to many students for valuable lessons and also for laughs over cocktails. It is a litany of bad ideas from several people that all came together at once to reach out and zap me. DISCLAIMER FOR THE SQUEAMISH: My eyes and vision are fine. There was some slight retinal bleaching in the peripheral vision of my right eye. If I hold up a large plane of white paper in front of me, like when helping a friend make posters for Ren Faire, there’s a small patch of yellowish tint in the lower right corner. Not a big deal, but damage is damage. [Scene – A very overcast morning in the spring of 1999. Exterior driveway between Building 6 & 15 of $LASER_COMPANY, roughly 10am] It was a day much like any other in my four years, five months and eighteen days of working there, not that I was counting or anything. After checking on a couple laser labs and talking to people, I needed to go across the way to visit the optics coating facility. So, I walked out the side door of Building 6 to cross the driveway, go down the stairs and over to the loading dock of Building 15. As I was walking across the driveway, I heard a weird noise. Something was rhythmically clicking away a bit faster than once a second. My thought process went a bit like this. Me: What is that noise? Me [a few seconds later]: Ohhhhh, I know that noise. That’s the flashlamps of a Quanta-Ray system going off. Me [immediately after, spinning on my heels to head toward the source of the sound]: Why am I hearing this outside? It was at some point while walking that way and waving my hands and yelling “SHUT IT DOWN!!!” that I took my laser hit from a scattered, fractional beam from the shenanigans going on (I didn’t notice the damage from the hit until several months later). I am going to try to describe what I saw in enough detail that hopefully you can reconstruct the scene in your head, because I don’t want to use my non-existent art skill in Paint to draw this. Quanta Ray PRO350 with frequency doubling, emitting a 532nm beam – Sales brochure image from Quanta Ray, unknown date The back of Building 6 had their shipping and receiving area and the rear parking lot. In the parking spaces closest to the shipping & receiving area, several spaces had been taken up by a Quanta-Ray’s power supply, a Rubbermaid cart with a large Quanta-Ray laser balanced on it, and it was connected to some Caltrans utility trailer looking contraption downstream and in line with the output aperture of the laser. Beyond the contraption trailer was a VP of Sales’ brand new cherry red Jeep Grand Cherokee. There were umbilicals for chilled water and power running across the parking lot back into the loading dock. Three men are standing behind the laser with another rolling cart being used as moveable workbench, fiddling with the controls for the laser and the contraption it was connected to on the trailer. Two of them were wearing laser safety eyewear. The third, one of our sales engineers who is named Bob, was not wearing any. After making sure everything was shut down, I assessed the scene and realized something had gone wrong beyond simply “this entire situation”. This was a sales demo for prospective customers gone horribly awry. I identified myself as the Laser Safety Officer and that I had some questions. The customers looked very much like they wanted to be anywhere but here. Me: May I see your glasses? [Customers 1 & 2 hand me them] Me: These are argon filters. Are these your glasses at you brought with you? Customer 1: Yes. Me: Shame you’re working with a Nd:YAG laser, not an argon one. Customer 2: Better than nothing, right? Me: These are utterly useless at 1064nm. You both should go make appointments with your ophthalmologists. But at least you understood that you need gogs. Bob, where are yours? Bob: In the lab. Me: Would that be the lab that this laser was in before you wheeled it outside? Bob: Yes. Me: Bob, why is this laser outside? What are you even doing here? Customer 1: You see, we had an idea… I want to say that, on first blush, their idea was admirable. They were trying to come up with a less destructive way to remove striping from roadways. You have to grind that stuff off, which damages the road surface, leading to increased wear & tear and thus potholes. Their solution was to do it with a laser instead. Me: Let me see if I understand this right. You want to mount a high power laser on a cart, towed by a Caltrans or contractor truck, to burn the striping off roads? Customer 1: Yes, ingenious isn’t it? Me: The striping with REFLECTIVE paint? Customer 2 [looks with concern at Customer 1]: Umm. Me: I’m sure you can find a way with enough power. Customer 1: But look, it worked! The customer motioned for me to look at the parking lot space stripe that a whole bunch of of round spots on it which had, indeed, burnt the paint off the asphalt. Me: Bob, $FACILITIES_GUY is going to kill you. He just repaved and striped this parking lot a couple of weeks ago. Bob: [looks morose, as he’s starting to get an inkling of how bad this looks] Me: But you’ve been having some trouble, haven’t you? Customer 1 [surprised]: Yes! We can’t get beam no matter what we do. Me: That’s because you’ve blown the coating on one of your steering optics. Customer 1 & 2: How do you know? Me: Because your beam is not being steered to raster the stripe on the ground. Instead, it’s been firing a flat beam forward and doing a raster scan of [gestures] that Grand Cherokee. Bob and Customer 1 & 2 looked up to see the stripe of exposed metal on the door of the VP of Sales’ car where the paint had been burnt away. On closer inspection, we later leaned that the Quanta-Ray had burnt through the wheel well and cut the brake line. At this point, I decided I want to really rub in what a terrible idea all this was to them. How they had failed on so many levels. Me: That’s $VP_of_Sales’ car, isn’t it Bob? Bob: [groans] Yes. Me: Pretty sure that’s your boss, Bob. Bob: Yeah. Me: When did you start doing this? Customer 1: Around 8am. Me: And when did you start having problems? Customer 1: 8:30ish, maybe? Me: Ah, so you were lasing through break time. Bob, what’s behind the car? Bob: Building 15. Me: $VP_of_Sales doesn’t normally get here until after 9am and the roach coach always pulls up at the loading dock of Building 15 at 8:45. So, hopefully you were aiming above eye level for all the employees on break. Also, that exposed brushed steel on the Cherokee is a mirror for near-infrared, so you’ve been shining that beam right back at yourselves. You definitely should call your ophthalmologists. But what’s behind you, Bob? Bob: The fence. Me: What kind of fence is it? Bob: Chain-link. Me: So, not a solid fence then. What’s on the other side of the fence, Bob? Bob: [now staring at the ground in shame] The elementary school. Me: If you’re very lucky, recess happened before your optic failed but we’re still gonna have to send a letter to the school about a potential exposure. Of course, that brushed steel mirror isn’t flat, which means your reflections went all over. Bob, what’s above us? Bob: [picking up where I was going] Planes. Me: How many airports worth of airspace travels over us? Bob: SFO, Oakland, San Jose, the tiny municipal ones. Me: You forgot a really important one. Our neighbor, Moffett fucking Field. Firing a laser into military airspace is an act of war. Are you declaring war on the United States, Bob? Bob: [stands silently] Me: Bob, what else is above us? Bob: [looks up] Clouds. Because timing is the essence of comedy, that would be when it started to rain on the quarter million dollar laser system, destroying it. Bob no longer worked at $LASER_COMPANY two weeks later. MORAL: Of all the bystanders you could injure, DO NOT HURT THE SAFETY PERSON. ~fin~ Posted byPhil BJuly 31, 2024July 31, 2024Posted inAdventure & Radiation, All News, Reference Rants",
    "commentLink": "https://news.ycombinator.com/item?id=41127706",
    "commentBody": "How I got my laser eye injury (funraniumlabs.com)473 points by omnibrain 8 hours agohidepastfavorite195 comments DannyBee 6 hours agoSo I laser weld, and beyond my own PPE, interlocks (gun won't fire if it's not touching metal, etc), the most important part of the whole setup is laser safety curtains. Because it's a 2500 watt laser, if i didn't have laser safety curtains , the relections/etc could very easily blind someone at a fairly long distance. The NOHD (nominal ocular hazard distance) is something like 10km (2500 watt laser, 0.06mm spot size, divergence is very very small). The actual hazard distance is shorter, but still, kinda crazy. (as for why i have a laser welder - i got it cheap and besides the downsides above, it is very easy to weld ~anything without much skill. A person who has never welded in their life can weld sheet metal and have it come out basically perfect in 5 minutes) reply tlb 4 hours agoparentWhy don't welding/cutting lasers add more divergence with built-in optics? Would it hurt performance? It seems like you could add 1 mrad and it would hardly make a difference at the usual working distance, but spread out to a meter over 1 km, so you can't zap people across town. reply notelectronic 3 hours agoparentprevI get laser safety curtains, but what do you do for reflections off the ceiling? Asking because our makerspace was recently donated a fiber laser welding unit and we don’t yet know best practices for not blinding our membership short of building a completely enclosed separate room for it with door interlocks. reply DannyBee 3 hours agorootparentIdeally you have an enclosed area with interlocks. All of the laser welders support it (and it's the standard way). They make and sell mobile ones that can be pushed around. See, e.g., https://lasersafety.com/barriers/rigid-barriers/ for some examples (I don't know these folks, they just have helpful pictures/listings of kinds of things that exist) If you can't do this, you do need to panel or curtain the ceiling or use laser absorption coating or other things. There are places that also just use reflection sensors that detect reflection on the ceiling and trigger (again, machines already support handling this). I have heard this works very well but have no direct experience with it. All that said, reflection off ceiling is more uncommon for practical reasons (The angle at which you hold the gun to the piece, the fact that ceiling directed angles often become back reflection into the gun which it already detects, etc). They already detect very high reflection as well. For a makerspace, one of the issues you will have is that people will likely want to try to weld copper and aluminum a lot, both of which are highly IR reflective. If you said \"You can only weld steel and iron\" you would eliminate a very high percent of reflection in the first place. Here's a basic chart that looks right: https://www.researchgate.net/profile/Tomasz-Kurzynowski/publ... For a 1064nm laser, you can see Al or Cu is going to reflect a lot of the energy, while steel/iron are still off the graph high in absorption reply convolvatron 3 hours agorootparentI tig. wear a helmet and have to buy argon every year. this seems like a huge hassle in comparison. is there that big a difference in quality and or range of processes that make it worth it? reply hinkley 59 minutes agorootparentI know one of the reasons we wanted pico-second and shorter pulsed lasers is that they can cut material with little to no damage of the neighboring material. There was a demo that I read about when this was all brand spanking new research, where they claimed that a laser scalpel causes no heat damage to tissue outside of a cell’s breadth from the contact point. reply abakker 2 hours agorootparentprevits the operator skill part when dealing with thin sheet metal. It just works better / easier / faster for thin stuff, where in TIG, that's the high-skill work that everyone pays big bucks for. Agree with the post above, though. The safety setup for lasers is basically full isolation. reply convolvatron 1 hour agorootparentseems like its more cost effective to just stay on or above 20ga unless you're really high volume or you really need the weight savings reply cowthulhu 2 hours agorootparentprevAre lasers typically able to reflect off of surfaces that diffuse light (ie drywall)? I’m totally ignorant when it comes to laser safety, apologies if this is a stupid question . reply meindnoch 1 hour agorootparentDo you see a bright spot when aiming the laser at drywall? If the answer is yes, then laser light is being reflected into your eye. Hope this helps! reply dheera 2 hours agorootparentprev> completely enclosed separate room for it with door interlocks You absolutely, absolutely need this. Do not take chances. \"Real estate is expensive\" is not an excuse for a blinding hazard to members and visitors of your space. I've worked with very high powered room-sized laser cutters before and they should all have a full room enclosure. reply bozhark 2 hours agorootparentprevSeparate room with interlocking doors -coming from another hacker space reply hinkley 1 hour agoparentprevI had a friend, “Kevin” who got picked as a lab assistant for a guy making one of the first violet, and IIRC, picosecond lasers. It’s frickin’ laser beams so of course I had to ask way too many questions. They probably should have been using curtains but if they were he never said, and I’m sure laser safety has evolved with the wattage and commercialization, whereas this was a static benchtop system. There were lots of mirrors and prisms and they has to calculate refraction off of them and stick carbon blocks everywhere that light transmission was less than 100% efficient so that no light could escape the system except via the target. reply sph 5 hours agoparentprevNOHD = Nominal Ocular Hazard Distance reply DannyBee 5 hours agorootparentYes. Sorry for not expanding it. I edited it to expand it. For others: The NOHD is really a nominal distance. It's just the distance at which the beam falls below the maximum permissible exposure. The 50% eye hazard distance (ED50) is 31.6% of this number. That is, if the NOHD is 100m, then at 31.6 meters you have a 50% chance of causing a medically detectable change to the eye. It's also worth noting - the beam power at this 31.6% distance is 10x, not 3x, what it is at the NOHD. For laser welding, the spot beam is small (60um) which is one reason the NOHD distance is so high. For reference, a laser pointer is like 1.5mm, so this is 25x smaller. It also doesn't help that the lasers used are all ~1060-1070nm wavelength and so invisible as well :) reply RealityVoid 6 hours agoparentprevI'm dying of curiosity how cheap a cheap laser welder can be. reply DannyBee 5 hours agorootparentSo, to clarify - what i have is a very nice IPG lightweld 1500 XR. They are normally not cheap (30k), and are very nice and well thought out safety wise. One of the fun parts when i lived in the bay area was that as companies got acquired, they didn't know what to do with the stuff they had before acquisition that isn't needed anymore, and it either sits in a warehouse, or gets auctioned off (or both!) So for example, at one point, Google (after acquiring terra bella and some other companies) had like 5 or 6 very nice 5 axis VMC's sitting around collecting dust. Each was worth well over 250k. They already had plenty of VMC's in the machine shop, etc, and didn't need these, and it was not worth the trouble to sell them. At least back then. In my case, I was able to get this welder for way less than half price. The lightweld's have come down in price over the years, and that will keep happening. They are pretty much the most expensive laser welders though, you can easily get one for 10k these days. The truth is, however, if you go cheaper than this, what often what gets overlooked is safety. So some of them in the lowest price range don't even require you touch the gun to metal before letting you fire, etc. All of them can weld the same, so if you go looking, look at other things too. THe other thing - one of the nice things about laser welding is that it's improving very fast. So similar to fiber, running multiple types of lasers or optics in the cable is not particularly more difficult than running one. They just add more fibers (it's not quite the only issue, but you get the point). Why does this matter? Because it means you can run another laser or something to monitor the weld and adjust parameters on the fly. Which lightweld and others are starting to do. So if you are moving the gun too fast/slowly, or got the power wrong or whatever, it will compensate automatically This probably won't ever happen on mig/tig. The lasers are heavily computer controlled already, this just adds a feedback loop. It also enables real time certification of a weld - see https://www.ipgphotonics.com/products/laser-weld-measurement for an example (this is a separate product, but you get the idea) In any case, my take would be - if you want to play with them as a hobbyist, or have too much money, they are cool Otherwise i'd wait ~5 years and what you get will probably be 5-10x better for the same price. reply mhb 5 hours agorootparentVMC == Vertical Machining Center PSWAATY == Please Say What the Acronyms Are. Thank You. reply PoignardAzur 13 minutes agorootparent> PSWAATY I'm keeping that one. reply DannyBee 5 hours agorootparentprevUsually i do, but there is one acronym in the entire 450 words, and it doesn't really matter to the point what the thing was? reply mhb 36 minutes agorootparentOK. Thanks for the informative post. Don't want to discourage you from more. reply SkyPuncher 4 hours agorootparentprevI agree with you. It's also pretty easy to figure out what you're talking about from context. reply mhb 38 minutes agorootparentIt's the second post in which he did this. And how should anyone know whether it's important to know what it means without knowing what it means? reply digging 2 hours agorootparentprevIf the definition doesn't matter, better to use a more generic term than a more specific/cryptic one. reply HeyLaughingBoy 4 hours agorootparentprev> plenty of VMC's in the machine shop So now I have to know why Google has a machine shop. Beyond the obvious \"why not?\" reply krisoft 3 hours agorootparentThey make hardware prototypes. When you do that having your own machine shop can lower the iteration time and thus speed up the development. Just from the top of my head: waymo develops their own lidars, akamai obviously needed a ton of machining for the kite, project loon probably had machined components. And those are just the flashy examples we heard about outside of the company. They can have ton of other projects which didn’t get to the point where we heard about them but required hardware prototyping. reply HeyLaughingBoy 2 hours agorootparentDuh! Of course! I think Google and I only think search/ads. I forgot Alphabet has all that other stuff going on. reply ethbr1 2 hours agorootparentSo does Alphabet. reply throwup238 2 hours agorootparentprevIIRC it was started in earnest for Nexus phone prototypes in the early 2010s. reply antoinealb 3 hours agorootparentprevGoogle as a company manufactures hardware, it makes sense to have a machine shop for prototypes. reply psd1 3 hours agorootparentGoogle was founded by burners who want to take cool shit to the desert. reply DannyBee 3 hours agorootparentprevLots of reasons. Prototyping consumer goods of various sorts, etc. reply throw0101a 5 hours agorootparentprev> So some of them in the lowest price range don't even require you touch the gun to metal before letting you fire, etc. Are you able to attach them to the heads of sharks? reply DannyBee 5 hours agorootparentIf you can get them to stay still long enough, maybe. reply abakker 2 hours agorootparentprevhttps://www.everlastgenerators.com/catalog/laser-welders this is probably the easiest one to buy from a reputable (non alibaba) company. its $17k, so not \"cheap\", but hardly expensive. My gut says they'll be for sale at $2-5k within 2 years at the rate things are going. reply supermatt 6 hours agorootparentprevI don't have one yet so cant really advise on quality, but I was recently looking and you can pick up a 2.5kW laser welder from about $15k. They are slightly cheaper (around 12k) from alibaba, but then you will be looking at import duties, warranty complexities, etc reply HeyLaughingBoy 3 hours agorootparentYeah, that's the problem with some of the more expensive Alibaba/Aliexpress stuff. The list price is attractive, but once you add in all the extras like duties, transportation from the port of entry to your location, warranty difficulty etc., there's not much price difference from heading over to the local Kubota dealership. Still, some of those little tracked tractors on TikTok are interesting. If I could somehow raise enough money to start importing them, I'm sure I could sell quite a few. reply ensignavenger 3 hours agorootparentA lot of folks find those little chineese tractors at auctions in the US. There are folks who handle all the import and then resell them. Can be a great deal but many of them need some mods, like better cooling, to really shine. reply isoprophlex 5 hours agorootparentprevThere's a killer Neal Stephenson plotline in here somewhere. Redneck protagonist zapping enemy drones with a modified laser welder. reply HeyLaughingBoy 3 hours agorootparentHmmm. I'm black, but my wife did anoint me to the position of \"honorary redneck\" some time ago. Neighbor has stopped with the drone overflights of my property, but still, you're giving me ideas... reply rtkwe 2 hours agorootparentBe careful as far as the FAA is concerned drones get the same legal protection as a plane with people in them so messing with them is legally hazardous. reply HeyLaughingBoy 2 hours agorootparentI know. Hence the laser: blind the camera first and they can't prove that it didn't mysteriously drop out of the sky as soon as it passed the property line. reply isoprophlex 3 hours agorootparentprevGo get em cowboy! reply zokier 4 hours agorootparentprevOh yes: https://youtu.be/xNmbvaUzC8Q This is why we can't have nice things reply btbuildem 3 hours agorootparentThere's no way this stuff isn't giving the secret service nightmares. This guy set ablaze the inside of a vehicle through closed windows from a significant distance. reply dgacmu 2 hours agorootparentprevIt's rare to have such a clear illustration of the difference between intelligence and wisdom. reply paranoidrobot 5 hours agorootparentprevI had to look it up, because I thought that was what \"Reason\" was in Snowcrash. I was mistaken: Reason was a railgun. reply rtkwe 4 hours agorootparentThe weird part of reason is it is also (in the family of) a mini gun with it's multiple rotating barrels. reply bzax 3 hours agorootparentprevI feel obliged to mention that this does feature prominently in Kim Stanley Robinson's Red Mars trilogy. The single most important piece of infrastructure on Mars is a space elevator, but not everyone on the planet is happy with how the owners of the space elevator are running things. reply trelane 4 hours agorootparentprevAlmost a different Funranium post: https://www.funraniumlabs.com/2022/12/choose-your-own-radiat... reply mdorazio 6 hours agorootparentprevA quick search is showing me new machines in the $7k range. You could probably pick up a used one for a few thousand less. This is cheaper than I would have thought, honestly - a decent full MIG rig is not exactly cheap. reply DannyBee 5 hours agorootparentThey are coming down in price very quickly. The materials cost is really not very high (no idea on the laser itself, but the rest is easily(as for why i have a laser welder - i got it cheap that's how a lot of good stories start reply dotancohen 4 hours agorootparentYou don't want to hear how I met the ex. reply NathanielBaking 5 hours agoprevSafety guys always ruin the fun. I was in the Marine Corps and every time we got to test some new piece of gear the safety officer was like \"No, you can't live fire it off the flight deck of the ship\" or \"No, not here, that village is down wind of the dust you will kick up when it goes off.\" No, that has a kill distance of 6 miles, you have to fire it into a hill.\" Blah, blah, blah. So after I got out I joined the National Guard. reply RandomThoughts3 4 hours agoparentI may or may not be aware of hull damage being caused or not caused by a rifle being fired from the flight deck of a ship. My point being, your safety officer had a point. reply dctoedt 4 hours agorootparent> hull damage being caused or not caused by a rifle being fired from the flight deck of a ship How did that happen? Our MarDet would occasionally do live-fire training off the flight deck (CVN-65); they naturally pointed their weapons away from the ship .... Or are you talking about hitting the hull of a different ship, e.g., one of the tin cans in plane guard, or alongside during an UNREP? Seems like that would ... get noticed by a lot of folks. reply RandomThoughts3 2 hours agorootparentHypothetically, someone could have left a guest (like say an engineer from the shipyard doing sea acceptance testing) fire a rifle and an unlucky wave reflection might have bounced a round back towards the bow. reply rtkwe 1 hour agorootparentWow what an incredibly unfortunate hypothetical situation. 1 in a million ricochet that one. reply trelane 4 hours agorootparentprevI think they know that. I read their comment as sarcastic. reply jprete 4 hours agorootparentIt's really, really close though. The kill distance of six miles is what tips me over the edge of reading it as sarcasm. reply trelane 4 hours agorootparentReally? To me, it is a very clear instance. Amongst my cohort, saying \"The safety officer won't let us do anything fun\" is going to generally always be sarcastic, unless the point is that some rules seem excessively and obviously pointless, which these aren't. It's more a backhanded way of saying \"thank goodness the safety office stopped us / those boneheads from doing something that would have been incredibly stupid.\" reply nocman 3 hours agorootparentIt depends totally on how you read it. In this case, my first thought after reading that was \"play stupid games, win stupid prizes\". There are plenty of people (especially on the internet) who actually do think that way -- by which I mean people that are serious when they respond with \"you guys ruin all the fun\" to others who bring up genuine concerns that will most likely have wide-sweeping ramifications. reply trelane 2 hours agorootparent> There are plenty of people (especially on the internet) who actually do think that way Sure. That's why these safety officers exist. I think some other funranium posts state.that (paraphrased) \"safety rules are written in blood.\" That said, I suspect folks like that would tend to phrase the rule in a way to diminish the implied impact/likelihood, rather than enhance it or state as-is, as (afaict) the original did. reply ooterness 3 hours agoparentprevI am reminded of the \"Sir Isaac Newton is the deadliest son of a bitch in space\" speech from Mass Effect 2. https://youtu.be/hLpgxry542M?feature=shared reply elzbardico 3 hours agorootparentCompton is a bitch for astronauts too. reply talldayo 5 hours agoparentprevIt's all fun and games until you walk in front of a live AESA radar and sterilize yourself. reply khorne 4 hours agorootparentSave $300 on a vasectomy. reply ryneandal 3 hours agorootparentMine was $750 :( reply peepee1982 4 hours agorootparentprevThey're about twice as much where I live! reply onemoresoop 4 hours agorootparentprevI'm guessing there are other adverse effects beside sterilizing. reply gumby 3 hours agoparentprev> I was in the Marine Corps and every time we got to test some new piece of gear the safety officer was like \"No, you can't live fire... I thought the whole point of the Marines was to cause maximal amounts of damage. Are you implying there is a constraint on that? But now I understand why the marines hate the navy: I had a buddy who'd been in the navy and he said they kept the kids busy by cleaning and painting everything but frequently they'd let 'em blow off steam by tossing cardboard boxes and stuff off the end the flight deck and shooting at them with the 50 cal machine guns. We were good friends, attended MIT together, but if I thought the Navy would take many people like him I'd doubt their ability to fight a war. He was only in the navy because it would pay for school and AFAIK he managed to avoid getting any rank advancement at all. MIT requires, or used to, a lot of all nighters and he once said \"I'm probably only sane with these all nighters because I did so much extra sleeping in the navy\" reply robertlagrant 19 minutes agorootparent> But now I understand why the marines hate the navy: I had a buddy who'd been in the navy and he said they kept the kids busy by cleaning and painting everything but frequently they'd let 'em blow off steam by tossing cardboard boxes and stuff off the end the flight deck and shooting at them with the 50 cal machine guns. If anything this should be why the taxpayer doesn't like the navy. reply afterburner 2 hours agorootparentprev> I thought the whole point of the Marines was to cause maximal amounts of damage. I thought their point was to expose themselves to maximal amounts of damage. reply NoMoreNicksLeft 2 hours agorootparent> I thought their point was to expose themselves to maximal amounts of damage. I hate to be pedantic, but technically the whole point is to expose the enemy to maximal amounts of damage. Whoever that is. Anything else is incidental. reply archgoon 4 hours agoparentprev> that village is down wind of the dust you will kick up when it goes off. I'm always happy to hear that there are people saying these sorts of things in the military. I'm sorry it wasn't fun at the time, but the Safety Officer really was looking out for you. You really don't want to be the unexpected cautionary tale, like Bob. reply dmd 6 hours agoprevI'm not entirely sure, but I suspect my Hole In My Eye[0] came from being 30 years old (I'm 46 now) and saying \"look, this laser pointer is so low power, I can shine it in my eye to no ill effect!\". [0] https://dmd.3e.org/a-hole-in-my-eye/ reply madjam002 1 hour agoparentOne of the things I hate most in tourist hotspots these days are the people selling high powered laser pointers, normally selling them to kids, and they are shining it at their faces, in the faces of others, and at the neighbours. I swear they never used to be so commonplace. Having worked nightclub lighting a long time ago I have a deep appreciation for laser safety haha reply pflenker 52 minutes agorootparentWhen I was ~12 years old one boy pinned me down and another one shone a laser pointer in my eye just for fun. Needless to say, this has been my „bad eye“ ever since (I’m 39 now) reply leptons 34 minutes agorootparentprevA friend of mine gave me a high power blue laser pointer, and it was fun for a night but I gave it back to him because I recognized that it was just too dangerous. One slip, one stray reflection, and I'd damage my eyesight or go blind. It's just too dangerous, and I'm a very careful person who takes precautions - I can't imagine kids with laser pointers are going to be able to see very well when they are older. reply dghughes 5 hours agoparentprevAt a casino where I was a slot tech we used fiber optics that went into a fiber converter module and then RJ-45. Often I would look at the ends of the fiber connectors to see if they were lit or if the light looked odd. They were quite low in power but I'm surprised at myself that I didn't think of the risk. edit: optics not options reply wildzzz 3 hours agorootparentPatch fiber is usually using Class 1 or Class 1M lasers which are entirely safe to look at. Also the light spreads out very rapidly at the end of an unterminated fiber because there's no lens to focus it. So don't hold it directly up against your eye but like a foot away is fine. The lasers are less focused (i.e. cheaper) and the multi-mode fiber is wide so it spreads out very quickly. You can't actually see the IR light, the red light you see is just sidebands of the signal. Fiber used for long hauls is much more powerful but uses a wavelength that the human eye is very good at blocking (so your eye dissipates more of the energy but what does get through could damage your retina). There are systems that will decrease the power if the link is lost (cut or unplugged) to protect eyes. The light will still dissipate in free space (because there's no lens) so you should be safe from a distance. Single-mode fiber uses a more focused laser and more narrow fiber so it will spread less over a free space distance so don't get too close. Always better to just use a light meter (or a phone camera) if you're unsure but also just holding the end of the fiber against some paper or your palm may reflect enough of the visible light to let you know the fiber is live. reply foobarian 2 hours agorootparentJust in case, always use the same eye to look into these things. reply leoqa 1 hour agorootparentprevAs an intern moving data centers the old networking guy told me to look into them; I used my right eye and now my eye is 20/40 a decade later whereas my left eye is still 20/20. I did hold it up to my eye because it was hard to see.. reply justin66 3 hours agorootparentprevSome scientists used to look at the beam emitter to adjust the aim of old particle accelerators. The story I heard was that some of them eventually developed cataracts as a result. Come to think of it, with today's medical technology that's a lot less awful than punching holes into your retina with a laser, but I think the result back then was eventually blindness. reply NotYourLawyer 2 hours agoparentprev“Low power” lasers are sometimes wildly more powerful than they claim to be. I guess what do you expect when you buy a Chinese laser pointer on Amazon for 5 bucks. reply anonymousiam 1 hour agorootparentNd:YAG lasers such as the one in the article use an IR exciter into a crystal to achieve frequency doubling or tripling. Much of the energy from the fundamental exciter makes it past the crystal, so without good filtering, a \"safe\" class 2 or 3R laser can still produce blinding (but invisible) light. Lots of the cheap lasers don't have good filtering, so be careful what you buy. reply NotYourLawyer 24 minutes agorootparentOh yeah, that’s a real problem for cheap green lasers. IR diode laser, doubling crystal, and no IR filter is a good way to go blind. reply zoky 7 hours agoprevI’m not saying it didn’t happen as described, but this really kinda reads like the “Bald eagle named Albert Einstein flew into the classroom” copypasta… reply mpalmer 7 hours agoparentNever let facts get in the way of a good story. The build-up is great (VP's car, elementary school, military base) and the punchline is funny, but it's just a bit too perfect (\"and what's above us?\", cue clouds). Even the name Bob sounds like it's been chosen for comedy. It's clearly a mostly true story that's been refined and polished over the years. reply cududa 39 minutes agorootparentWas curious so I looked it up - Jose Antonio Vargas Elementary School is right by Moffet Field. The school also abuts an industrial park that fits the description. One of the current tenants there is Volvo Innovation Lab, which I imagine does laser testing. I have no idea if buildings need certain certifications for working with lasers, so I mention that tidbit. As well, that office park has 16 buildings in it, by my count. The pieces of this story very much so line up. reply mpalmer 18 minutes agorootparentYeah like I said I'm sure it's mostly true. I just don't necessarily buy that he had a comedian's delivery on the day in question reply foehrenwald 3 hours agorootparentprevreads like a BOFH story reply rob74 5 hours agorootparentprevIt's entirely possible that \"Bob\" is a generic name (using $SALES_GUY, like he uses $LASER_COMPANY and $FACILITY_GUY, would have been too repetitive). ...or the guy was really called Bob. reply trelane 5 hours agorootparentAlso, the guy had enough happen to him. He doesn't need his actual name put in the story. One might hope that in the intervening 25 years he would have improved, especially after such an expensive lesson. reply gadders 2 hours agorootparentprevYeah, I thought it sounded a bit too good to be true as well... reply neilv 5 hours agoparentprevAs I read through it, it does sound like an apocryphal old story, since too many of the details are too perfect setups for the teller. Then again, occasionally real life really does happen unbelieveably, including when fudge-ups are involved. Maybe what's most unbelieveable is that, to the extent the story tells, the only known injured person was the laser safety officer. Presumably the safety person was partly in the loop on some other injuries, but maybe they're NDA'd on that, yet not NDA'd on mentioning the incident. Or, maybe an incident like that was kept very quiet by a company, and injured people never knew how they got injured. Then there's this: > It has been brought to my attention that I have never actually written this story down before, merely told it in person to many students for valuable lessons and also for laughs over cocktails. Did they only give verbal reports and verbal depositions/testimony? Never wrote up a report for internal use or for professional publication? \"Laughs over cocktails\" could mean finding humor in the ridiculousness of disaster, and taking a battle scar in stride. Could also be a hint that the entire story is a fabricated/embellished/appropriated story, like people often tell recreationally when drinking, and understood in that context for what it is. reply kragen 4 hours agorootparentpossibly his boss asked him to not write up the report reply neilv 2 hours agorootparentYes, I don't want to speculate, but would hope that, for whatever happened, the affected people were notified, and all the appropriate safety officer processes were followed up on. Or, the story might have started a bit like when grandkids ask grandpa how he got that arm injury, and instead of telling the troubling story about shrapnel in the war, or the car crash, he tongue in cheek tells a fantastic tall tale of fishing, when along comes a bear who wanted to eat his fish, chock full of lessons. That could've been a goal with students: if one ran out of real-world case studies to drive home laser safety practices, a semi-plausible, if over-the-top, narrative of how a not-unlikely cavalier mistake could become a clusterfudge, with the story of course hitting all the safety practices they were just told about. There would normally be verbal cues as to the kind of story, and there'd be the context of telling, both of which are lost in blog posts. reply relaxing 7 hours agoparentprevThe sales guy set up the entire rig on his own? And no other engineers in the lab stopped to ask what he was doing? I know some places have poor safety culture, but this is a “laser company”. Basic laser safety should be drilled into them from day 1 and every day after. When I worked in an optics lab, we had interlocks on the doors that switched on with the power supply running the experiment and a sign outside indicating which wavelengths were operating. reply somat 5 hours agorootparentThe guy was listed as a \"sales engineer\" which on first glance is the worst sort of oxymoron, everybody knows engineers make terrible salesmen[1]. But perhaps it could work, just take your sleaziest engineer, put them through an intensive indoctrination in chicanery and lies and you get a salesman who almost knows what he is talking about. 1. How do you know if the guy trying to sell you something is the engineer. They will tell you in excruciating detail every flaw and design mistake in the thing and how they should have designed it better. Savor this moment, look past the terrible sales pitch and buy from them, for you have been gifted that elusive thing, the engineer. reply neilv 4 hours agorootparentMy dad was such an engineer doing sales, of industrial components. Grew up on a farm, engineering degree, very honest type churchgoer and family man, and in his spare time DIY projects like a classic engineer type. I'm sure he'd know when something would or wouldn't work, and would candidly tell the customer about any problems or risks. (In this case, maybe honest as much as an engineer personally bothered by design flaws.) I've also seen a different kind of engineer in sales, where they're paired long-term with salespeople. They sit in on sales meetings as a technical expert, and also do things like customizations and integrations. I suppose the presence of the salesperson helps suppress the engineer's inclination to start riffing on every flaw, but the pairing retains the engineer ability to help the customer be successful with the product. reply somat 4 hours agorootparentYeah, I am a bit rough on sales, but it is critical to doing business. And a good saleman is a wonderful find, talking with someone who is knowledgeable and honest about the product is great. reply RandomThoughts3 4 hours agorootparentprevSales engineers are very common if you are selling complex industrial products. At a certain point of complexity, selling a product and designing its integration with the customer kind of bridge. You need a deep understanding of the product and process involved to be able to sell it. reply ta988 6 hours agorootparentprevI have seen a drunk employee wrestling with a moving industrial robotic arm trying to \"fix it\" after having disabled the numerous safeties with screwdrivers. This was at a major car manufacturer plant. Do not underestimate the horrible situations people can put themselves in. reply p_l 6 hours agorootparentSometimes you fight and curse the volkswagen-special VKRC safety circuits. And sometimes you think what kind of shenanigans might happen and why it might be better to have complex safety interlocks that mate with entire automation cell controls... reply hotsauceror 2 hours agorootparentprevA relative of mine works with assembly-line robots at heavy equipment manufacturers. He told me that while they were calibrating a new robot that was used to move axles for industrial mining dump trucks, a miscalculation caused the robot to fling a 800 lb axle through the air like a marching band baton. reply unkeptbarista 6 hours agorootparentprevI find this basics of this story believable. I worked at a place that manufactured IR lasers, and where the owner (the \"Doctor\" as we called him) set up similiar impromptu demonstrations that went awry. Thankfully no one was injured, but some random piece of equipment was damaged by the reflected beam. reply rkachowski 6 hours agorootparentprevIt's pretty crazy that the sales guy was able to connect the water cooling and power with enough hosing and cables to bring it outside, as well as know how to operate the device enough to activate it - but couldn't correctly point it _at the ground_ and burn the paint off of the street without melting through a car. But forgetting that, what are the core safety issues described? I get the direct exposure to unprotected eyes damage, but there's discussion of infra red reflections endangering nearby children + aircraft + casus belli with the US army. reply teractiveodular 6 hours agorootparentThe story says he did point it at the ground, but a) it was reflecting off the reflective paint they were aiming at and b) towards the end the laser was badly misaligned. reply relaxing 5 hours agorootparentprevNot operating in a controlled environment, no curtains to block stray reflections, not ensuring your optic path is stable and clear of obstructions and reflective objects. Doesn’t sound like they had a beam block around for safety, nor did they first use a lower power visible laser to simulate beam path. reply tpmoney 5 hours agorootparentprev“Sales engineer” sounds like one of those positions that would be regularly setting up demos for customers and have access to the equipment and basic operating procedures. “Could we use this to burn paint off the road” sounds exactly like the sort of question a person doing a demo might say “I don’t see why not, let’s try it” to. While with deliberate thought about it, the fact that road markings are retro-reflective is obvious, but it’s not something you would necessarily consider immediately, since it’s called “paint” and almost all paint you encounter in the world is not retro-reflective. For the rest of it, my reading of the story is multiple things happened here: 1) They initially aimed the IR laser at the paint on the ground. The paint being retro-reflective the laser damaged itself in about an half hour and stopped producing consistent results, just occasional spots of results. 2) The sales person rather than halting the demo to get someone else to take a look at what was malfunctioning continued to fire the laser after making various adjustments not realizing that because the laser had been damaged it was firing not at the ground anymore, but at the car a few spaces away. 3) They’d been messing with the laser after malfunctioning since before the VP parked their car, so there’s possibility they were sending lasers in the direction of the other building, so that’s one issue which would have been bad enough on its own but… 4) At some point the VP parked their car in the path between the laser and the building. As they continued to mess with the malfunctioning laser, they burned through the paint on the side of the car, exposing the bare metal underneath. 5) The bare metal is also highly reflective, but because it’s not retro-reflective the problem is now you had completely uncontrolled reflections. The ones that went backwards had nothing to stop them since there was only a fence and field between the lot and the school. And the ones that went up obviously also had nothing to stop them since they were outside. 6) Because of the unknown detections and quantity of reflection, in addition to getting all the potentially exposed employees and customers checked out, the company would also have to make advisory calls (at a minimum) to the school and the local airports and military installations. Whether those schools and planes were actually in danger or not could not be said with certainty, but the point was less “oh know we’re terrorists now” and more “this was a huge screw up, and I need to impress on you why it was bigger than just breaking company property or not wearing your safety gear” reply ben_w 7 hours agorootparentprevMm. Should be, isn't. I've heard of one place that had a class IV laser mounted on a robot arm in a public area, which turned itself off when the arm happened to flail in exactly the right way to hit its own emergency stop button. reply elzbardico 3 hours agorootparentprevWith highly technical products usually you have at least two guys working on a account: The salesman, who deals with the business guys on the other side, the folks who will actually sign the check. The sales engineer, that deal with the guys who will actually use the product, is able to understand their requirements and come up with ways the product can fullfil those, provide Proofs of Concept, demos and initial training for those guys on the other side that will give the final ok to the business people: 'this will work for us, you can sign the check if you want\" reply protocolture 5 hours agorootparentprevSales Engineer = Knows enough to be dangerous. Sometimes a good sales engineer can tell you all about then undocumented feature you need to get something delivered. reply gus_massa 6 hours agoparentprevI worked for a few weeks in a class with a custom infrared -> green laser. The teacher were very hard about glasses, how to crouch looking away from the laser table, close the door and a few more security measures. And later, I had a 5W (0.5W?) green laser at 3 yards pointed at me [1] with some optical equipment bolted to the table in the middle so there was (almost) no possibility that it hit me. The story sounds real. [1] If all the bolted devices in the middle magically fall down, the laser would have hit my belly, not my eyes. So it's important to crouch looking away, just in case. reply aj7 6 hours agorootparentCrouch? When training technicians, the first thing is, you never ever bend your waist in the laser room, with lasers on. Your head never enters the plane of the laser beams. You do not put your ahead above the laser. You use a piece of copy paper to earache for stray beams near the apparatus. You use an IR viewer to (shock yourself as to how many there are to) find 1064nm stray beams. reply gus_massa 4 hours agorootparentI agree. I'm not a native English speaker, so I may have choose the wrong verb. Is \"squatting\" better? And with that kind of care, like turn everything off and still be very careful if you have to pick something from the floor. reply amluto 5 hours agorootparentprev> custom infrared -> green laser Nd:YAG lasers always creep me out. I worked in a lab that had an Nd:YAG with two janky doublers: 1064 -> 532 -> 266 nm. The output energy was supposed to be a few mJ (IIRC), but it was basically zero. So the students operating it took off the second doubler and fired it at a bookend. Nothing (well, nothing visible). Took off the first doubler. After investigation, the zapping sound was the paint vaporizing off a computer at the other end of the lab, because the beam was actually scooting just past the bookend. 1064 nm is almost the worst wavelength you can work with. (Okay, 233nm is probably worse, but the available energy with a setup like this is much lower.) I have a green laser pointer, and I made a point of buying a diode laser. It’s a slightly different color than 532, its battery life is better, but, critically, there is no way it could malfunction or be sloppily constructed to leak infrared light. reply amluto 4 hours agorootparentReplying to myself: I just searched Amazon. There are plenty of green “diode” lasers, 532nm, ~100mW, for very little money. I don’t believe that for a second — those are surely crappy frequency doubled Nd:YAG lasers, probably unfiltered (that filter wouldn’t be cheap, and it might fail anyway under that ridiculous power level), and they will blind you when some funny reflection of the, I dunno, 500mW of stray IR light hits your eye. Now that real name brand laser pointers are mostly gone, if you actually want green, get a 515nm laser or something along those lines. Stay away from 532nm! reply entropie 3 hours agorootparentI have a friend with multiple green and red lasers, some from aliexpress. Years ago when the hype wasnt really there he visited me and wanted to show off. I have 3 dogs and I really like this kind of tech but I forbid it to turn that thing on near me, especially in my flat. Even if they are directed away, the chance of unpredictable reflections is just too high for a bit of fun. reply cyberax 59 minutes agorootparentprev> (Okay, 233nm is probably worse, but the available energy with a setup like this is much lower.) How do you get 233nm lasers?!? reply fsh 5 hours agoparentprevYeah, the story contains some obvious bullshit. There is no way in hell a flashlamp-pumped Nd:YAG laser could cut through a piece of steel. With typical ~Hz repetition rate and ~J pulse energy, the average power is only around 1 W. This is three to five orders of magnitude lower than typical welding lasers. This could burn some paint or engrave metal, but burning through a wheel well and brake line is completely ridiculous. reply xiphmont 3 hours agorootparentHe didn't claim it cut through steel, JGCs have polymer wheel wells and brake lines like most modern cars. reply mistercow 5 hours agorootparentprevMaybe they meant the plastic wheel well liner? I don’t know if that makes sense, I’m just googling around looking at Jeep Cherokee images. reply actionfromafar 4 hours agorootparentprevIt's just there for flair. :) reply DannyBee 5 hours agoprevSo while trying to answer another comment on cost, i ran into this: https://www.sciencedirect.com/science/article/abs/pii/S09240... and https://www.sciencedirect.com/science/article/abs/pii/S00303... I had thought, reading the article, that maybe this was a relatively new idea, and they were at least trying something relatively new in an insane way. But no, the latter is from 1999 (so when this event occurred), and there were earlier papers they cite. Using lasers to do paint stripping of coatings from roadways was well studied even then, and all the risks/rewards carefully laid out. Not that i expect the sales engineer to have read that, but still. reply csours 43 minutes agoparent> \"oxygen shroud-gas\" Do they call it MOG instead of MIG? Although it's Chlorinated Rubber, not metal, so maybe it's CROG. reply manithree 6 minutes agoprevNot to be insensitive about your injury, but I'm more curious how you got your laser eye. reply N_A_T_E 4 hours agoprevI worked in a laser lab for a few months early in my career. After the safety training I fear lasers getting near my eyes in situations most people don't care about. I even look away from barcode scanners at grocery stores. Sometimes I wonder about lidar being shot in all directions from those self-driving cars around SF. reply Miraste 3 hours agoparentThere's been at least one sketchy self driving startup that drove their LiDAR hard enough they burnt holes in journalists' camera sensors at CES. https://arstechnica.com/cars/2019/01/man-says-ces-lidars-las... reply neilv 2 hours agorootparentI'd wondered about the eye safety of LIDAR on prototype autonomous vehicles, but then thought \"surely anything at all unsafe to eyes wouldn't be allowed on public streets.\" Now I'm reminded of all the unregulated recklessness in some technical topics that I do understand, and realizing it's silly to assume. reply kqr 1 hour agoparentprevWait, are barcode scanners lasers? I've always thought of them as red lamps because their cone spreads out so widely quickly. reply rtkwe 59 minutes agorootparentIt's a scanning dot moving fast enough to appear as a cone. reply hinkley 49 minutes agorootparentThe stationary ones used to have a spinning mirror with a laser pointed at it. You used to be able to look in the machine and see it. Dunno how they do it now for the handheld scanners. Smaller mirror or some other trick like piezo? reply sersi 2 hours agoparentprevShould I be concerned about the lidar in my dreame robot vacuum (L10s ultra) and my 3 years old whose head is closer to the ground than me? I never thought about it before but you'r comment worries me. reply gtmitchell 4 hours agoprevThat brings back memories. One of my first research projects in school was doing sketchy things with a Quanta-Ray Nd:YAG laser. I remember the distinct 'tack-tack-tack' sound of the Q-switching at 10 Hz which I used to create a laser-induced plasma right around eye level. Fortunately I had the proper goggles on but was always terrified of catching a stray reflection and blinding myself. Now we live in a world of dirt-cheap high-powered diode lasers, and when I see all the stupid things YouTubers do with them with almost no discussion of proper eye safety, I wince. reply franciscop 4 hours agoprevI've touched all sorts of things in my \"Maker\" years, but one of the things I'm never going to touch by far is lasers. I know how bad they are, and I also know how woeful unqualified I'm for messing with lasers. Heck, I've even left a couple of dancefloors in clubs that I heavily suspected were firing actual lasers at the people, wonder how many of those were actual lasers vs light pointers and how many people got unknowingly injured, but it was just not worth the risk. reply krisoft 2 hours agoparent> Heck, I've even left a couple of dancefloors in clubs that I heavily suspected were firing actual lasers at the people, wonder how many of those were actual lasers vs light pointers and how many people got unknowingly injured, but it was just not worth the risk. It is not really clear what you are saying here. What do you mean by \"actual lasers\" vs \"light pointers\". Whether or not a light show is safe has nothing to do with the light source being an \"actual laser\" or not. What matters is what kind of laser and how it is used. reply voidUpdate 4 hours agoparentprevEven better is when the dancefloor wants UV lighting, so they just buy some cheap UV-C bulbs reply RA2lover 8 hours agoprevI wonder what happened to literally everyone else present at this situation. That's beyond \"Yikes!\" territory. reply MeteorMarc 7 hours agoparentYes, I also dislike the culture in which this can be called a funny story. Such culture will cause more incidents. Worked in a laser lab for 5 years without incident in a time when eye safety goggles were not used for visible light. reply ta988 6 hours agorootparentSometimes a funny story is one that helps you remember about safety. reply ordu 6 hours agorootparentYeah, emotions are a positive factor for a memories forming. Add some emotions to a fact, and it will be remembered better and for longer. Some things are remembered for life without any repetition, and mostly it happens for things that trigger your emotions. reply bbarnett 5 hours agorootparentprevIf the Germans can joke about it, anyone can. https://www.youtube.com/watch?v=xJ_86lxP36I reply cqqxo4zV46cp 6 hours agorootparentprevNo. That only says something about you, not “the culture”. It’s incredibly common to laugh at the absolute absurdity of a situation. It doesn’t mean that people are making light of it. It doesn’t mean that they don’t grok how serious it is. They just react differently to you. reply MeteorMarc 5 hours agorootparentI agree there is more to it than yes/no making a joke of an incident. I associate it with a macho culture in which people do not feel safe to speak up in case of unsafe circumstances. Same for IT security. reply WarOnPrivacy 5 hours agorootparentprev> in a time when eye safety goggles were not used for visible light. Also Yikes. Even with my low(ish) 1w-5w handhelds, it's self-evident that eye protection is needed when the beam travels less than a few yards. reply jnwatson 5 hours agoprevRule number 1 of laser safety is \"do not look into beam with remaining eye\". reply altruios 3 hours agoparentI think that's rule number two. Right after \"don't look at the laser\". reply dietr1ch 1 hour agorootparentthen the third rule must be, \"now you can do whatever the fuck you want\" written in Braille. reply jmclnx 6 hours agoprevOne thing I learnt, different glasses for different type lasers, who knew :) reply 0x138d5 4 hours agoparentOne of the professors in my uni lab had \"universal laser goggles\". They were regular goggles with a sheet of lead bent over them. reply trelane 4 hours agorootparentNiiice. Even attenuates those xray lasers! reply ta988 6 hours agoparentprevThat and different glasses depending on how you use that laser... Because some lasers can do variable wavelength. reply cyberax 56 minutes agorootparentDye lasers are the worst. You now have _two_ (or more) wavelengths to shield against. Bonus points if one of them is in IR. That's probably how I got my eye damage - a small hole in the retina of one eye. reply amluto 5 hours agorootparentprevI’ve seen some references to the universal laser glasses: Apple Vision Pro! reply ta988 4 hours agorootparentNo, the cameras would probably not survive laser exposure beyond a cat toy pointer level power (and even then I wouldn't bet long exposure of those). reply gabrielhidasy 18 minutes agorootparentCameras are cheap, eyes are expensive. Ok, the Vision pro cameras are probably very expensive (mostly because I doubt you can just switch them with new ones). Maybe put a bag over it and a Pi camera on the outside? Can you live-stream to a Vision Pro? reply amluto 3 hours agorootparentprevThat’s fine. If I worked in a room with a laser and I screwed up and hit my face, frying an Apple Vision Pro seems like a pretty small price to pay. My eyes will be fine. And the Apple Vision Pro works against tunable lasers, lasers of unknown frequency, flashlamps, etc. reply rtkwe 56 minutes agorootparentprevThey'd still protect your little human eyes. If you wanted to use them as safety glasses normally you'd want their cameras to be easily replaceable but they would function as safety goggles for short periods until the camera caught a stray beam. reply hanniabu 5 hours agoparentprevWhy can't there be glasses with the different types layered together into one? reply fabian2k 5 hours agorootparentBecause if you want to cover all possible lasers you'll block out the visible spectrum as well and won't see anything. reply WarOnPrivacy 5 hours agorootparentYou can get some overlap tho. I have 520nm goggles that tone down 465nm. reply rtkwe 54 minutes agorootparentThat's mostly because it's tough to get a perfect notch filter in the visible spectrum but you'd never want to use the 520nm with a 465nm unless it was low enough power the fuzzy edge of the filter knocked it's power down enough to be safe. reply pjc50 5 hours agorootparentprevThen you can't see anything. They're narrowband filters. A welding mask would be a wideband filter, but is much harder to work with when it's engaged. reply kevinmchugh 4 hours agoprevOne of the lessons you can take from this is that people think in the tools they know even when there's better, simpler tools available. It wouldn't be hard to get some asphalt into the lab, but if you don't know how to pour asphalt...or swing a hammer, you're gonna haul the tool you know to the asphalt reply steve1977 6 hours agoprev\"Are you declaring war on the United States, Bob?\" This almost made me spill my tea... reply delichon 6 hours agoparentA few years ago I worked in a high rise in an office with a window facing Moffet Airfield. I worried about crashing experimental planes but never thought to worry about being blinded by a stray laser beam. Maybe I'm not paranoid enough. reply tgsovlerkhgsel 4 hours agorootparentI remember reading a story of someone photographing a military helicopter (I think), only to find out that the crew apparently considered it funny to point some laser based system (likely a range finder or designator) at the photographer, burning the camera sensor to the point of damage being clearly visible on the sensor itself (not just the pictures). reply tomcam 1 hour agoprev> the company claims the machine can take care of business safely \"even in the most movement-heavy conditions,\" and that dry run testing on moving humans has all been successful. So many questions reply JansjoFromIkea 5 hours agoprevLasers absolutely terrify me now; I impulse bought a 2w lasercube in 2020 for next to nothing (circa $200) and once I started reading up on it I was pretty appalled how easy it was to buy. This was a fairly expensive RRP laser with some level of protection and stuff around it, the fact you could buy pens capable of pretty significant damage on ebay for way less where people wouldn't even grasp just how dangerous the thing is. So I've got a laser I'm afraid to play with until I can make a safe environment for it and I'm even more afraid to sell on to anyone... Feel like there's going to be some atrocity and some big time laser panic in the future. reply CamperBob2 2 hours agoparentWhy not just wear the appropriate goggles? You don't have to be afraid, you just have to be careful. Of course, being careful means considering the possible presence of subharmonics, and buying your goggles from legitimate suppliers rather than unpronounceable Chinese brands on Amazon or eBay. reply hinkley 52 minutes agoprevOne of my cleverest friends loves to say, “do not look into laser with remaining eye.” reply sethammons 7 hours agoprevThat is a heck of a cocktail story. A bit more terrifying than I expected. As the safety officer, I wonder what new policies they put into place after this. reply pja 7 hours agoparent“Do not let salesweasels anywhere near the bright shiny things” hopefully. reply iaresee 3 hours agoprevHaving started out my tech career as an intern in an industrial laser lab, this story is parts amusing and horrifying. Brought back a lot of memories of all the ablation tests and via drilling I used to do, with varying degrees of success, to help sell this massive lasers. reply rob74 7 hours agoprev> On closer inspection, we later leaned that the Quanta-Ray had burnt through the wheel well and cut the brake line. The I guess they were lucky that they weren't aiming in the general direction of the fuel tank, or that the \"experiment\" was stopped before burning through it? reply londons_explore 3 hours agoprevAre there any stats on the scale of laser eye injuries? Like what percentage of the world population are blind because of laser injuries? What percentage have permanent vision issues? How do those compare with the number of people who work with lasers? How does it compare with say vision loss from arc welding? reply inetknght 5 hours agoprevWhat a wonderful story about why we can't have nice things. Hopefully nobody else outside of the story was hurt. Lasers are fun. Like all fun things, they demand respect. reply Flop7331 2 hours agoprev1999, when you could pull a stunt like this and still get two weeks notice for it reply davecahill 5 hours agoprevBlame Free Retrospective challenge reply protocolture 5 hours agoprevYou could have just said \"Sales Guy\" reply aj7 7 hours agoprevJust for giggles, who owned Spectra-Physics at the time? reply dwighttk 7 hours agoprevMoral of the story is: make sure and tag the safety officer when you’re being stupid so he can make sure and inform all of the correct people. reply igleria 7 hours agoprevhow do people like Bob get a job in the first place? reply myrmidon 5 hours agoparent- Familiar enough with product to set up customer demonstration on his own with minimal help from enigneering - Shows initiative by exploring novel applications with customers - Expertly alleviates doubts & hesitation in customers :P Honestly, apart from blatant disregard for safety culture, that is not a bad salesperson at all. Without additional info, I would honestly put the blame mostly on the company, because instilling a certain respect for dangerous products should be part of company culture and employee training, you just can't expect fresh hires to come with all the common sense baked in... reply 77soccer 5 hours agoprevVery interesting reply paulluuk 7 hours agoprevThis was a great read, thanks for sharing! reply yobid20 6 hours agoprev [–] The laser should've been mounted on a shark. reply steve1977 6 hours agoparent [–] \"Sharknado 8 - Now They Have Lasers!\" reply inetknght 5 hours agorootparent [–] https://www.youtube.com/watch?v=INFavIUmhcE reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Phil B. recounts a series of poor decisions leading to a laser eye injury while working at a laser company in 1999.",
      "A Quanta-Ray laser was improperly set up for a sales demo, causing safety violations and damage to a VP's car.",
      "The incident highlighted severe safety lapses, resulting in the firing of a sales engineer and underscoring the importance of proper laser safety protocols."
    ],
    "commentSummary": [
      "Laser eye injuries can occur even with PPE (Personal Protective Equipment) and interlocks; laser safety curtains are crucial.",
      "A 2500-watt laser can cause blindness over long distances due to reflections, with a NOHD (Nominal Ocular Hazard Distance) of about 10km.",
      "Enclosed areas with interlocks, mobile barriers, and laser absorption coatings are recommended for safety, especially when working with reflective materials like copper and aluminum."
    ],
    "points": 473,
    "commentCount": 195,
    "retryCount": 0,
    "time": 1722507934
  },
  {
    "id": 41125490,
    "title": "Just Disconnect the Internet",
    "originLink": "https://computer.rip/2024-07-31-just-disconnect-the-internet.html",
    "originBody": ">>> 2024-07-31 just disconnect the internet (PDF) So, let's say that a security vendor, we'll call them ClownStrike, accidentally takes down most of their Windows install base with a poorly tested content update. Rough day at the office, huh? There are lots of things you could say about this, lots of reasons it happens this way, lots of people to blame and not to blame, etc., etc., but nearly every time a major security incident like this hits the news, you see a lot of people repeating an old refrain: these systems shouldn't be connected to the internet. Every time, I get a little twitch. The idea that computer systems just \"shouldn't be connected to the internet,\" for security or reliability purposes, is a really common one. It's got a lot of appeal to it! But there's not really that many environments where it's done. In this unusually applied and present-era article, I want to talk a little about the real considerations around \"just not connecting it to the internet,\" and why I wish people wouldn't bring it up if they aren't ready for some serious considerations. We Live in a Society In the abstract, computers can perform valuable work by doing, well, computation. In practice, the computation is rarely that important. In industry, there is a lot more \"information technology\" than there is \"computation.\" Information technology inherently needs to ingest and produce information, and while that was once facilitated by a department of Operators loading tapes, we have found the whole Operator thing to be costly and slow compared to real-time communications. In other words, the modern business computer is almost primarily a communications device. There are not that many practical line-of-business computer systems that produce value without interconnection with other line-of-business computer systems. These interconnections often cross organizational and geographical boundaries. I am thinking, for example, of the case of airline reservation and scheduling systems disabled by the CrowdStrike, er, sorry, whatever I called them incident. These are fundamentally communications systems, and have their origins as replacements for the telephone and telegraph. It is not possible to simply not internetwork them, because networking is inherent to their function. Networking is important to maintenance and operations But let's consider systems that don't actually require real-time communications to perform their business purpose. Network connectivity still tends to be really valuable for these. For one, consider maintenance: how does a system obtain software updates if you have no internet connection? How is that system monitored? And even if you think you can avoid those requirements by declaring a system \"complete\" and without the need for any updates or real-time monitoring or intervention, business requirements have the frustrating habit of changing over time, and network connectivity reduces the cost of handling those changes tremendously. What does it mean for a system to not be connected to the internet? First, we need to consider the fact that there are as many forms of \"not connected to the internet\" as there are ways of being connected to the internet. For this reason alone, proposing that a system shouldn't be internet-connected is usually too nonspecific to really discuss. Let's consider a menu of possibilities: List 1: A single device with no network connection at all. A system of devices that is \"air-gapped\" in the strictest sense, with no connection to any network other than its private local-area one, where data never crosses the security boundary. That same system, but someone carries DVD-Rs across the security boundary to introduce new data to the private network. That same system, but a cross-domain solution or \"data diode\" allows movement of data from a wider (or lower-security) network into the private (or higher-security) network. That same system, where the cross-domain solution does not have a costly and difficult to obtain NSA certification. List 2: A system of devices which interconnect over a private wide-area network using fully independent physical infrastructure with physical precautions against tampering. That same system, but the independent physical infrastructure is run through commodity shared ducts. That same system, but the infrastructure is leased dark fiber. That same system, but the infrastructure is wavelengths on lit fiber. That same system, but the infrastructure is \"virtual private ethernet\" implemented by the provider using, let's say, MPLS. That same system, but the infrastructure is \"virtual private ethernet\" implemented by the provider using a tunneling solution with encryption and authentication. List 3: A system of devices which interconnect over a common-carrier network (such as, we might even dare say, the internet), where private network traffic is tunneled through encryption and authentication performed by hardware devices. That same system, but the hardware devices do not have a costly and difficult to obtain NSA certification. That same system, but the tunneling is performed by a software solution that is well-designed such that it configures the operating system network stack, at a low level, to prevent any traffic bypassing the tunnel, and this has been validated by someone much smarter than me. That same system, but not so well designed and validated by someone like me. That same system, but the \"software solution\" is like Wireguard and an iptables script that has been \"thoroughly tested\" by someone on Reddit. List 4: A system of devices which interconnect on a private network that has interconnection to the internet that is strictly limited by policy-based routing or other reliable methods, such that only very narrowly defined traffic flows are possible. That same system, but the permissible network flows are documented in some old Jira tickets and some of them were, you know, just thrown in to make it work. That same system, but it's basically protected by a firewall that's pretty liberal about outbound flows (maybe with IPS or something), and pretty restrictive about inbound flows. List 5: An AWS private VPC without any routing elsewhere. An AWS private VPC with PrivateLinks and other AWS networking baubles that allow it communicate with other private VPCs. That same system, but some of the interconnected VPCs can route traffic to/from the internet. An AWS private VPC with NAT GW and IGW but the security groups are set up pretty tight in both directions. These are all things that I have seen described as non-internet-connected. Take a moment to work through each list and mark the point at which you think that is no longer a reasonable claim. It's okay, I'll wait. I'm not going to provide threat modeling for all of these scenarios because it would go on for pages, but you can probably see that pretty much every option is at least slightly different in terms of attack surface and risk. This might seem like an annoying or pedantic argument, but this is actually the biggest reason I get irritated when people say that something should never be connected to the internet. What do they mean by that? When someone says that an airline reservation system shouldn't be internet-connected, they clearly don't actually mean the strictest form of that contention (no network connection at all) unless their name is Adama and they liked when airline reservation centers had big turntables of paper cards they spun around to check off your seat. They must mean one of the midpoints presented above, which are pretty much all coherent positions, but all positions with different practical considerations. This ambiguity makes it hard to actually, seriously consider the merits of dropping internet connectivity. Non-internet connected systems are so very, very annoying In my day job, I work with a wide variety of clients with a wide variety of cultures, IT architectures, and so on. Some of them are in highly regulated industries or defense or whatever, and so they actually conduct software operations in networks with either no internet connectivity or tightly restricted internet connectivity. When I discover this to be the case, I mentally multiply all of the schedule/cost estimates by a factor of, I would say, 3 to 10, depending on where they fall on the above lists (usually 3x to 5x for list 5 and 10x to a bajillion times forever for list 1, just rule of thumb). Here's the thing: virtually the entire software landscape has been designed with the assumption of internet connectivity. Your operating system wants to obtain its updates from online servers. If you are paying for expensive licenses for your operating system, the vendor probably offers additional expensive licenses for infrastructure to perform updates within your private network. If you are getting your operating system for free-as-in-beer, there's a good bet you can figure it out yourself, but if you're using anything to new and cutting-edge it might be a massive hassle. But that just, you know, scratches the surface. You probably develop and deploy software using a half dozen different package managers with varying degrees of accommodation for operating against private, internal repositories. Some of them make this easy, some of them don't, but the worst part is that you will have to figure it out about fifty times because of the combinatorial complexity of multiple package managers, multiple ways of invoking them, and multiple environments in which they are invoked. If you are operating a private network, your internal services probably don't have TLS certificates signed by a popular CA that is in root programs. You will spend many valuable hours of your life trying to remember the default password for the JRE's special private trust store and discovering all of the other things that have special private trust stores, even though your operating system provides a perfectly reasonable trust store that is relatively easy to manage, because of Reasons. You will discover that in some tech stacks this is consistent but in others it depends on what libraries you use. A bunch of the software you use will want to perform cloud licensing and get irritated when it cannot phone home for entitlements. You will have to go back and forth with your vendors to figure out a workaround somewhere between \"add these ninety seven /16s to your firewall exceptions\" and \"wait six months while we figure out the internal process to issue you a bespoke licensing scheme.\" All of your stuff that requires updates or content updates will have some different process you have to follow to obtain those updates and then provide them internally. Here's a not at all made up example, but a real one I have personally lived through: you will find that a particular (and particularly hated) enterprise software vendor provides content updates for offline use only through a customer support portal that is held over from three acquisitions ago, and that it is only possible to get an account in that customer support portal by getting an entitlement manually added in a different customer support portal held over from two acquisitions ago. It will take over three months of support tickets and escalations through your named account executive to get accounts opened in successively older customer support portals until you can finally get into the right one, which incidentally has an invalid TLS cert you are reassured is not something to worry about. Once you download your offline content update, you will find that the documented process to apply it no longer works, and it will take a long email chain with one of the engineers to get the right instructions. You paid a five-figure sum for a 1-year license to this software and it has now nearly elapsed while you figured out how to use it. You will of course get an extension on that license pro bono, because this is enterprise software sales and what is a quarter worth of my salary between friends, but they won't manage to issue the extension license until after your original one has already expired, causing a painful interruption in CI pipelines and a violent revolution by the developers. I am sorry, you are not my therapist, I will try to stop remembering that dark time in my career. Don't worry, the software in question seems to have fallen out of favor and cannot hurt you. So, like, that's an over-the-top example (but seriously, a real one!), but you get the point. It's not really that any individual part of operating in an offline environment is hard---I mean some of them are, but most of them aren't. It's a death by a thousand cuts. Every single thing you ever do is harder when you do not have internet connectivity, and you will pay for it in money and time. The largest problem by far is that almost everyone who develops software assumes that their product will not need to operate in an offline environment, and if they find out that it does they will fix that with duct tape and shell scripts because it only matters for a small portion of their customers. You, the person with the offline environment, will become the proud owner of their technical debt. None of this really needs to be that way, it's just how it is! There are not really that many offline environments, and they tend to be found in big institutions that have adapted to the fact that they make everything cost more and take longer, and are surprisingly tolerant of vendors who perform a three stooges routine every time you say \"air-gap,\" because that's what pretty much every vendor does. Except for like Red Hat, I genuinely think Red Hat is pretty good about this, but you betcha what you save in time you are paying in cash. Not many people do this That's kind of the point, right? The problem with non-internet-connected environments is that they are rare. The stronger versions, things from List 1 and List 2, are mostly only seen in defense and intelligence, although I have also seen some banks with pretty impressive practices. You will note that defense and intelligence, and even banks, are also famously industries where everything costs way too much and takes way too long. These correlations are probably not coincidences. Even the weaker forms tend to be limited to highly-regulated industries (finance and healthcare are the big ones), although you see the occasional random software company that just takes security really seriously and keeps things locked down. Occasionally. Okay, let's stop just complaining Here's the thing: I genuinely do not think that \"fewer systems should be connected to the internet\" is a bad idea. I really wish that things were different, and that every part of the software industry was more prepared and more comfortable operating in environments with no or limited internet connectivity. But that is not the world that we currently live in! So let's get optimistic, what should we be doing right now? Apply restrictive network policy on as much of your stuff as possible. Cloud providers generally make this easier than it has ever been before, it's not all that easy but it's also not all that hard to operate a practical non-internet-routed environment in AWS. If you stay within the lanes of all the AWS managed services, it's mostly pain-free. You will pay for this, but, you know, AWS always gets their check anyway. Build software with offline environments in mind. Any time that you need to phone home to get something, provide a way to disable it (if practical) or a way to override the endpoint that will be used. If the latter, keep in mind that you will also need to come up with a way for a customer to feasibly host their own endpoint. If you keep to simple static files, that's really easy, just nginx and a directory or whatever. If it's an API or something, well, you're probably going to have to ship your internal implementation. Brace yourself for the maintenance overhead. Try to think about the little assumptions that go into connecting to other services that become more complex in an offline environment. Please, for the love of God, do not assume you can reach LetsEncrypt. But that's not the only TLS problem, offline environments virtually always imply internal certificate authorities. Use the system trust store. Please. I am begging you. Avoid fetching any kind of requirements or dependencies at deploy time. One of the advantages Docker supposedly brought us was making all of the requirements of a given package self-contained, but then I still run into Docker containers that can't start if they can't reach the npm repos or something. And now I have yet another place to fix configuration and trust store and etc., in your stupid Docker container. It has made things more difficult instead of less. Have I mentioned that Docker, paradoxically, actually makes offline environments more difficult to manage? Yeah, because virtually every third-party Docker container has at least a TLS trust store you'll have to modify. Docker is, itself, a profound example of how the modern software industry simply assumes that everything is running On The Internet. Anyway I wrote this out in a bit of a huff because I have seen \"why were they connected to the internet at all?\" like four times in response to the CrowdStrike incident. I know, I am committing the cardinal sin of taking things that people on the internet say seriously, but I feel obligated to point out: internet connectivity is pretty much completely orthogonal to what happened. CrowdStrike content updates are the kind of thing that, in a perfect world, you would promptly make available in your offline environment. In practice, an internal CrowdStrike update mirror would probably lag days, weeks, months, or years behind, because that's what usually ends up happening in \"hard\" offline environments, but that's a case of two wrongs making a right. Which they do, more often than you would think, in the world of information technology. Don't worry, I'll be back next time with something more carefully written and less relevant to the world we live in. I just got in a mood, you know? I just spent like half the day copying Docker images into an offline environment and then fixing them all. I have to find something to occupy the time while a certain endpoint security agent pegs the CPU and makes every \"docker save\" take ten minutes.",
    "commentLink": "https://news.ycombinator.com/item?id=41125490",
    "commentBody": "Just Disconnect the Internet (computer.rip)335 points by bathtub365 17 hours agohidepastfavorite181 comments flumpcakes 8 hours agoI work in security/systems/ops/etc. and fundamentally disagree with this premise. I understand the author is saying \"it's not that easy\" and I agree completely with that, but I don't agree that it means you're doing your job well. Unfortunately the vast majority of people do their jobs poorly. The entire industry is set-up to support people doing their job poorly and to make doing your job well hard. If I deploy digital signage the only network access it should have is whitelisted to my servers' IP addresses and it should only accept updates that are signed and connections that have been established with certificate pinning. This makes it nearly impossible for a remote attacker to mess with it. Look at the security industry that has exploded from the rise of IoT. There's signage out there (replace with any other IoT/SCADA/deployed device) with open ports and default passwords, I guarantee it. IoT is just a computer, but it's also a computer that you neglect even more than the servers/virtual machines you're already running poorly. People don't want to accept this, or even might be affronted by this. There are some places doing things well - but it's the vast minorities of companies out there, because you are not incentivised to do things well. \"Best practises\" or following instructions from vendors does not mean you are doing things well. It means you are doing just enough that a vendor can be bothered to support. Which in a lot of cases is unfettered network access. reply zippergz 1 hour agoparentA sign connected to the internet but with IP whitelists and cryptographic checks is still CONNECTED TO THE INTERNET. Yeah, it's way safer than the same sign with ports open to the world and no authentication, but you can't treat it as \"not connected to the internet.\" You still have to worry about networking bugs, cryptographic vulnerabilities, configuration errors, and other issues that can allow remote attackers to exploit the system. If you want to make the point, you have to give an example of something that's literally not connected to the internet, not one that's simply locked down better. reply Spivak 37 minutes agorootparentThe number of people who are willing and able to build their own disconnected network is vanishingly small which is the author's point. When deploying \"edge\" computing like signage which demands remote administration telling your customers anything other than \"get it connected to the internet and we'll handle it from there\" isn't going to go over well. \"Sorry you can't deploy our signs because we haven't deployed our custom LoRa towers in your area\" is just gonna get laughs. reply hypeatei 7 hours agoparentprevFor IoT in particular, you hit a crossroads where the embedded devs haven't really dealt with advanced security concepts so you kinda have to micromange the implementation. And, in small teams it's hard to justify the overhead of managing x509 certs and all the processes that come along with it. Just my personal experience. reply kwhitefoot 5 hours agorootparentSurely white lists and certificate pinning are not advanced security concepts? reply pizzafeelsright 5 hours agorootparentYes, they are. Perhaps not in a practical or educational sense but in the real world, of people with non-cryptographic or security related jobs, a certificate is a PITA that goes beyond the functional requirements. I have seen many insecure building automation systems that are maintained by reclassified HVAC technicians. The movies about hackers taking over an elevator are entirely accurate. reply CapstanRoller 4 hours agorootparentThe hassles of cert pinning, etc. should not be laid at the feet of the customer/integrator/whatever. Regardless of whether that person is an HVAC tech who learned about serial ports & busybox yesterday or is a seasoned expert with Ghidra & Wireshark & binwalk. Companies are being incredibly lazy (at our expense), and the author states this obliquely: >virtually the entire software landscape has been designed with the assumption of internet connectivity reply shadowgovt 3 hours agorootparentThe issue is the alternative does not scale. It's not that companies are being lazy at our expense; it's that nobody wants to pick up the bill. If you write something to work against an online system, the fact it is online implies it adheres to some standard that you can work with, so solving the problem for one online client creates an artifact that is likely applicable to many clients. Air-gapped systems drift. They get bespoke. They get very out of date. So you have the two practical problems of labor: (a) the product created solves the problem here, today, but nobody else benefits from repurposing that solution and (b) the developer isn't gaining as many transferrable skills for the next gig, and they know it, and so the developers who are willing to do the air-gapped work are harder to find and more expensive. (I believe this is also the reason you see air-gap a lot more often in government security and banks: they can afford to retain talent past the current project with the certitude there will be more projects in the future). reply reaperducer 2 hours agorootparentThe issue is the alternative does not scale. That's a feature, not a bug. Almost the entire downfall of the modern tech industry can be attributed to two things: greed, and the fetishization of \"scale.\" Not everything has to scale. Not everything should scale. Scale is too often used as an excuse to pinch pennies. If you business model only works at massive scale, then your business model might be broken. (Not always, but more often than most people think.) reply hypeatei 4 hours agorootparentprevEmbedded devs can come from a variety of backgrounds (e.g. Electrical engineering) that don't necessarily concern themselves with software security. They're not dumb, it just isn't something they (typically) are knowledgeable in. reply simianparrot 4 hours agorootparentThen they need to learn it. Otherwise they’re being unprofessional and bad at their job. reply dsr_ 3 hours agorootparentThey were hired by a company which is bad at its job of delivering secure or securable products. The products were purchased by someone bad at their job of selecting secure products. They were deployed by someone who was told that having the signs working ASAP is more important than anything else, so the management is bad at their job of securing the company. But I won't say that the designing engineer was bad at their job, I would say that the product manager was bad at their job... but probably got promoted, because the company made a bigger profit and delivered faster because security didn't get any attention. And that's why we need regulation, because \"this product is secure\" is not easily and cheaply verifiable and carries no penalties for being incorrect. The market can't tell, so everything is a lemon. reply michaelt 3 hours agorootparentprevThe makers of PC BIOSes are arguably the firmware developers who are closest to being normal PC programmers. They've been at it for 40+ years, and they have long provided network-connected features like network boot and remote management. And yet over 200 motherboards and laptops have their secure boot root of trust key set to a log-ago-leaked example key from a development kit, named \"DO NOT TRUST - AMI Test PK\" [1] The firmware industry at large just ain't good at this stuff. (Of course from the perspective of the firmware industry, they can make a non-internet-connected heating timer or a washing machine control board that will work fine and reliably with no software updates, for 25+ years - while us PC software cowboys make software so bad crashes are just a fact of life, and bug fix/security updates are a daily occurrence. So the firmware industry isn't all bad - only when they start putting things onto the internet.) [1] https://news.ycombinator.com/item?id=41071708 reply szundi 6 hours agorootparentprevYeah you know, just roll out our MVP, let's see where the business goes with it, and then we'll fix it. Whaat? Budget of fixing it is 2x of the product itself? Hm. Let's have meetings over meetings to postpone the decision until the next one, indefinitely - we cannot really make the decision not to do it of course. reply throw0101a 5 hours agorootparentprev> And, in small teams it's hard to justify the overhead of managing x509 certs and all the processes that come along with it. Just my personal experience. If you're using (say) Python in your client code, call SSLSocket.getpeercert() and check if your company's domain is in the subjectAltName: * https://docs.python.org/3/library/ssl.html#ssl.SSLSocket.get... You can ensure it is a valid cert from a valid public CA (like Let's Encrypt) instead of doing your own private CA (which you would specify with SSLContext.load_verify_locations()). reply karmarepellent 5 hours agorootparentI think parent refers to the infrastructure that is required to (automatically?) sign certificates by an internal CA and managing the distribution of those certificates. I don't think verification is the issue. reply hypeatei 4 hours agorootparentThis is correct. You have to consider every step from when the device is manufactured to when something goes catastrophically wrong in the field. All the internal documentation and tools so Joe from support can help customers and Bob in manufacturing can provision devices on his own all while maintaining controls around that process so nothing is getting leaked or abused. reply CapstanRoller 4 hours agorootparentprevOK, that's fine. Not everyone has to know everything. So why aren't their employers investing in educating their devs & PMs about security? (rhetorical - we all know why) reply skywhopper 3 hours agorootparentprevSure, for “small teams”. Does that apply to the companies with huge impact from this issue? Is Delta Airlines IT run by a small team? I hope not. reply karmarepellent 7 hours agoparentprev> I understand the author is saying \"it's not that easy\" and I agree completely with that, but I don't agree that it means you're doing your job well. Could you elaborate what you mean by this? It seems to me that your comment just highlights another set of problems that should (in theory) motivate people to think more clearly about the ways their system communicates with the internet. I don't see where you disagree with the blog author. Or are you saying that it's fundamentally impossible to improve security in internet-connected systems because people are not equipped to do so? reply flumpcakes 7 hours agorootparentThere's no reason for digital signage inside an airport to be connected to the internet (or running enterprise security software either). The author seemingly doesn't agree with this. Hospital computers should not be connected to the internet. If you are receiving real-time updates directly from a vendor, you are connected to the internet. Ideally updates should come from a central source internally to the organisation that has been vetted and approved by the organisation itself. Clearly CrowdStrike knows this and that's why they offer N, N-1, N-2 updates for their falcon sensor. It's easier to remote into a box and just pull updates from the internet though. Granted I have not had dozens of jobs, but the only place I have worked where security was treated as the first class issue that it is, (and this type of CrowdStrike incident probably wouldn't have happened), is at one of the largest financial services companies in the world. And it did not hamper development, it actually improved it because you couldn't make stupid mistakes like relying on externally hosted CDN content for your backend app. But for people that don't do their job well, it's a pain. \"Hey why doesn't my docker image build on a prod machine, why can't I download from docker hub?\" reply horsawlarway 6 hours agorootparentI don't really think you're speaking from a spot that's actually considered the requirements of the system. Ex - you say this: > Hospital computers should not be connected to the internet. But then you immediately jump onwards, as though what you've said is obvious common sense - but I don't think it is. Can you explain to me why you believe hospital computers shouldn't be connected to the internet, and then discuss and weigh the downsides of NOT connecting them? Because there I think that comment exposes the exact mindset that the author was discussing... no obvious appreciation or understanding of the situation, just an ill-informed off-the-cuff remark. Can you tell me how you plan to implement cross facility dosage tracking for patients? Can you let me know how you're going to send CT scans or x-rays to correct expert? Can you tell me how that patient's records are going to be updated, how billing is going to be generated, or how their personal doctor is going to be notified of their condition? I can think of a LOT of reasons that hospital computers really should be connected to a network. Maybe not every computer, maybe not every network, but even that distinction appears to be far beyond the thought you put into it before immediately saying \"Hospital computers should be connected to the internet\". You're basically making the author's point for him here. reply throw0101a 5 hours agorootparent> I can think of a LOT of reasons that hospital computers really should be connected to a network. Connected to network ≠ connected to Internet. reply flumpcakes 5 hours agorootparentprev> You're basically making the author's point for him here. And this is were I fundamentally disagree with the author. Nothing you've listed requires access to the internet - it requires access to a network. It's a lot easier to just deploy everything and set the firewall to any-any and go home because it's working. Like the author says, it's hard and difficult to find the right level, but to scoff at the simplest of advice of \"it shouldn't be on the internet\" is giving up. reply horsawlarway 3 hours agorootparent> And this is were I fundamentally disagree with the author. Nothing you've listed requires access to the internet - it requires access to a network. Ok - now what? I don't understand the disagreement you seem to think you have. That network inevitably requires a connection to the outside world or those exact same features I listed above stop working. So you're just shifting blame without an answer... So continue with your path - now I have an X-Ray machine that's connected to a network. The router on that network still has to connect to the internet to facilitate functional use of the machine, so let's assume crowdstrike is running there - tell me how your advice of \"Don't connect it to the internet\" is meaningful here? I have an expert radiologist who I want to confer with on my patients x-ray, he's in a different state - what is your advice? How is my problem solved with a banal \"Just don't connect it!\"? reply worthless-trash 4 hours agorootparentprev> it's hard and difficult to find the right level There are some pretty solid documentation on this and has been for some time, the knowledge simply has been lost or discarded because this kind of knowledge was considered 'arcane' or 'restrictive'. There were times when infrastructure had devel/testing/production environments with staged rollouts and deployment. Production had only only the minimal access, with admin config routable only to a private network, hidden behind the frontend cluster. Things were hard for admins and hackers alike. There was at one point gated networks and the idea of militarized and demilitarized zones, router level firewalls, outgoing connection limiting. Centralized logging (nah, don't do that, just run your apps on a POD and forget your security, forensic recover of your app is dead by the next deployment (probably twice over today) already) and many many more things. We bought the newthink of 'web security' as how we should build our infra as the the true way. When we see it fall apart on a blue friday afternoon do we look back to see the bigger picture ? No, we can't take responsibility for the weakness because any suggestion of personal responsibility that requires work is out of the question. reply CapstanRoller 4 hours agorootparentprevMost of your questions can be answered with these two weird old tricks: site-to-site VPNs && VLANs Why has everyone seemingly discarded these ideas or forgotten? Yes, it is a pain to manage. Industry could reduce this pain, but investing in good security isn't profitable. Blame the profit incentive. Blame the VCs (especially the people who own this website) reply Spivak 28 minutes agorootparent* Because they don't really work. It's better to assume the network is adversarial and work from there than to separate the world into the trustworthy network and untrustworthy network. * It's much much easier to secure a network when you completely disallow client-to-client communication and block all communication to clients not initiated by them. * Trusting the client that attackers can physically access is a recipe for disaster. * Because VPNs are just an application on the internet. reply bornfreddy 6 hours agorootparentprevThe answer is simple: security. Attacker needs a way into the machine to control it. Granted, there are some obscure vectors of attack that don't need network connectivity (Stuxnet), however the game becomes much harder for the attacker when they have no direct connection to the target system. Many countries solve this by having a separate network for hospitals, but it is not the only way. In general, it is a trade-off between security and convenience. Yes, you can't send an e-mail without an Internet connection (well... not easily). But do you need to? From the computer that controls the MRI machine? Or is it just easier to say \"we need Internet because updates\"? reply kwhitefoot 5 hours agorootparent>you can't send an e-mail without an Internet connection Of course you can. reply bornfreddy 1 hour agorootparentTo an external recepient? And you misquoted me by removing end of the sentence in parenthesis. reply devbent 3 hours agorootparentprev> Hospital computers should not be connected to the internet. Scheduling an urgent care appointment is connected to my account at the hospital network. When I step into the hospital and get tests done, everything is automatically uploaded to a web portal where I can view it and doctors can easily forward my test results to other facilities. Lot of the imaging work is actually done at third party facilities but they still show up in my medical records , presumably having been forwarded. When my appointment begins my doctor can look up any comments I left when scheduling the appointment so she knows why I'm there. Is it possible all the different buildings and facilities that are part of the hospital Network I belong to which extends across multiple counties across my state could all be running on their own private isolated network that is air gapped with medical records manually transferred over to the web portal via sneaker net? Sure, but no one is going to do that. reply reaperducer 1 hour agorootparentWhen my appointment begins my doctor can look up any comments I left when scheduling the appointment so she knows why I'm there. Or, you could… you know… talk to her. I work for a healthcare company that runs several hospitals and primary care clinics. When you become a patient, you're given a little notebook and a branded pen so that inbetween appointments, the patient writes down every little health question and problem they have. When the patient shows up for the appointment, the little notebook is reviewed by the doctor. Convenience should not always trump security. reply devbent 1 hour agorootparentThat sounds like an absolute nightmare. I'd lose the pen and paper within 30 seconds. I much prefer being able to send a quick message to a healthcare provider on my phone and have them get back to me same or next day. Especially for the \"should I come in for this rash?\" types of questions. (I got MRSA at the gym one time!) At my child's pediatrician I can upload images through the web portal and have a nurse call me back anytime of the day or night. If there's any follow-up questions at my child's next appointment, his doctor has full access to all communications that happened through both text message and the web portal. This kind of 24-hour digitally connected healthcare access with a huge boon as a first-time parent and made life a lot easier, especially when incidents like when my son woke up at 3:00 in the morning screaming and then projectile vomited 6 ft across his room (which by the way, was nothing to worry about and apparently completely normal... So long as it just happened once.) reply karmarepellent 6 hours agorootparentprevJust to add to this: Apart from the security aspect of hosting your software dependencies internally, it also gives you the added benefit of better availability and performance. As you mentioned in your other comment however, this presumes a certain mindset in people where they are willing to plan upfront and are mindful of the dependencies their software needs. As you say, just pulling whatever from Docker hub is certainly easier. Internally hosted repositories also allow you to pull and install updates at your own pace, possibly days after they have been released upstream. So if a patch is borked you won't be affected. reply worthless-trash 4 hours agorootparentI hate to be that guy but 'back in my day', that was called \"testing/production\" deployments. reply jstanley 5 hours agorootparentprev> Hospital computers should not be connected to the internet. But then how will doctors google the patients' symptoms? If your answer is \"they should already know all that is required to do their job without looking it up online\", then consider whether you hold yourself to the same standard. I don't. reply rightbyte 5 hours agorootparentThey could have designated internet connected computers and other computers for admin tasks and processing x-rays etc. Having the hospital admin and some machines connected outwards seems like a recipe for killing patients. reply karmarepellent 5 hours agorootparentprevIt is hard to make assumptions about what parent means by that statement, given that there are degrees in which a system can be \"connected to the internet\". For example, every request coming in or going out, as well as SSH access, could go through a proxy. I would still call that being \"connected to the internet\", but it's different from giving your server a public IP address. reply flumpcakes 5 hours agorootparentprevThis information (looking up symptoms) would be better served by a curated internal wiki that all practitioners have access to. Not google. reply patmorgan23 3 minutes agorootparentWhat about medical reference service like uptodate.com mixmastamyk 1 hour agorootparentprevMobile device, second network, vlan etc. Lots of options. reply cowboylowrez 3 hours agorootparentprevdoctor: heart arythmia google ai: remove heart doctor: ok lets schedule the operation! reply Mistletoe 4 hours agorootparentprevMedical care is so bad now I have had the doctors and nurse practitioners look up webmd while I’m in the room with them. reply devbent 3 hours agorootparentDoctors and nurses have always had large reference tomes that they refered to. List of medication side effects, dosing guidelines and so forth have been common throughout the industry almost since it's very inception. Indeed, there are books going back thousands of years across multiple cultures around the world that are just referenced guides for medical practitioners. reply flumpcakes 7 hours agorootparentprev> Or are you saying that it's fundamentally impossible to improve security in internet-connected systems because people are not equipped to do so? Yes - but I don't think think it's that hard. There's 90% easy work to be more secure than most out there. It just requires expertise and for people to change how they work. Instead people spend $bn on cyber security when you can get 97% of the way there by following good standards and knowing your systems. I am by no means perfect, I spent all day Friday fixing hundreds of machines manually that had BSOD'd from CrowdStrike. In this case the vendor had made it impossible to do my job well because they offered zero control on how these updates are rolled out - there is no option to put them through QA first. Unlike the sensor itself, which we do roll out gradually after it has been proofed in QA. reply karmarepellent 7 hours agorootparentI agree with you. Unfortunately my place of work has a habit of buying snake-oil security appliances as well which seems to magically absolve everyone from actually thinking about security deeply themselves. Rather ironically said appliance (that basically acts as a man-in-the-middle in remote access) prevents me from going the last mile in securely configuring my systems. I would not be surprised if the appliance self-updates, but I'm not sure. Regardless you could make the case that practices like these do not improve overall security, but instead just cost a large amount of money that you could hire three security-minded engineers from. reply myself248 6 hours agorootparentprevI interpreted it as \"Software is crap, and it's hard to make crap work offline. The problem is not the offline, it's the crap.\" The question is where to lay the blame for the crap, and how to change that. I would love to see the author's \"lists\" turned into a table of sorts, and then any given piece of software could be rated by how many situations on each list it works in without modification, works in with trivial config tweaks, works in with more elaborate measures, or cannot work in. Turn the whole table green and your software is more attractive to certain environments. reply karmarepellent 6 hours agorootparentI don't think it's always the software that is to blame. Sure there is software that wants to self-update and only accepts one upstream update source run by the vendor, instead of allowing users to run their own mirror and control update distribution to some extent. But there are also cases where the software could be perfectly run in air-gapped systems but people are unwilling to put in the work (for some reason or another). For example everyone could run their own Docker image mirror that only contains images that are actually needed and pulls them from upstream with some delay. Docker allows you to pull images from your own registry. But not veryone is willing to operate their own registry. reply slumberlust 5 hours agoparentprevThere is some legislation with actual teeth getting implemented to help force vendors to incorporate decent security standards in all these edge deveices: https://www.withersworldwide.com/en-gb/insight/read/new-uk-l... reply LeifCarrotson 2 hours agoprevI'm a controls engineer. I've built hundreds of machines, they do have Ethernet cables for fieldbus networks but should never be connected to the Internet. Every tool and die shop in your neighborhood industrial park contains CNC machines with Ethernet ports that cannot be put on the Internet. Every manufacturing plant with custom equipment, conveyor lines and presses and robots and CNCs and pump stations and on and on, use PLC and HMI systems that speak Ethernet but are not suitable for exposure to the Internet. The article says: > In other words, the modern business computer is almost primarily a communications device. > There are not that many practical line-of-business computer systems that produce value without interconnection with other line-of-business computer systems. which ignores the entirety of the manufacturing sector as well as the electronic devices produced by that sector. Millions of embedded systems and PLCs produce value all day long by checking once every millisecond whether one or more physical or logical digital inputs have changed state, and if so, changing the state of one or more physical or logical digital outputs. There's no need for the resistance welder whose castings were built more than a century ago, and whose last update was to receive a PLC and black-and-white screen for recipe configurations in 2003 to be updated with 2024 security systems. You just take your clipboard to it, punch in the targets, and precisely melt some steel. Typically, you only connect to machines like this by literally picking up your laptop and walking out to the machine with an Ethernet patch cable. If anything beyond that, I expect my customers to put them on a firewalled OT network, or bridge between information technology (IT) and operations technology (OT) with a Tosibox, Ixon, or other SCADA/VPN appliance. reply bo1024 42 minutes agoparentIt's reassuring that such things still exist. My mental model of consumer hardware is that they take devices like the ones you describe, and just add wifi, bluetooth, telemetry, ads, and an app. reply anticristi 12 hours agoprevIn Sweden, there is a private network (Sjunet) which is isolated from the Internet. It is used by healthcare providers. Its purpose is to make computers valuable communication devices (I love how the article points this out), but without exposing your hospital IT to the whole Internet. Members of Sjunet are expected to know their networks and keep tight controls on IT. I guess Sjunet can be seen as an industry-wide air-gapped environment. I'd say it improves security, but at a smaller cost than each organization having its own air-gapped network with a huge allowlist. reply NavinF 11 hours agoparentI bet that gives hospital IT a false sense of security. A huge intranet is kinda the opposite of modern best practices: https://en.wikipedia.org/wiki/Zero_trust_security_model reply 3np 4 hours agorootparentYou know what I've seen give decision-makers a false sense of security? \"Zero Trust Architecture\" and not thinking to deeply about the extent to which you're not actually removing overall trust from the system, just shifting and consolidating much of it from internal employees to external vendors. I'm not even thinking about CS here. It's curious to see what the implications on individual agency and seem to become when the \"Zero Trust\" story is allowed to play out - not by necessity but because it's \"the way we do things now\". (As the wiki page you linked notes, the concept is older and there are certainly valuable lessons there. I am commenting on the \"ZTA\" trend kicked off by NIST. I bet the NSA are happy about warm reception of the message from industry...) reply marcosdumay 48 minutes agorootparentIn principle, there are many good practice for zero trust architecture that make it viable to have a secure network while keeping it open. And also in principle, even then you'd still not want to make it open because you gain nothing by it. In practice, no big company follows any of those practices. So, yeah, anything that's derived from \"Zero Trust Architecture\" is wrong from its inception. reply llm_trw 3 hours agorootparentprevI think we saw how it plays out in the last few days. >The worst IT outage ever! >>The worst IT outage so far. reply throw0101a 5 hours agorootparentprev> I bet that gives hospital IT a false sense of security. Why? They can just as effectively use (e.g.) Nessus/Rapid7/Qualsys to do security sweeps of that network as any other. At my last job we had an IoT HVAC network that we regularly scanned from a dual-homed machine where the on-network devices could not get to the general Internet (no gateway). reply raxxorraxor 7 hours agorootparentprevThat is a solution for companies like Google or non-essential cloud software provider. For all others serious network segmentation is the safer approach. You could argue that this network is far too large and that is probably true. There is future tech on ancient software stacks. There is no safe solution to put it on the net directly. AWS was an example in the article. Easy to get a fixed IP? True. Getting a fixed IP for outgoing traffic? Not that easy anymore - AWS is nice, but for many application it just isn't a solution. reply actionfromafar 11 hours agorootparentprevIt's not exactly like just a WAN or intranet over the Internet. It's a separate network with agreed on availability guarantees. reply nindalf 11 hours agorootparentThe problem is that you think it’s private but it isn’t. If an attacker wants access they’ll get access. At that point the false sense of security is a hindrance, because systems might not have been secured like they would have been on the public Internet. reply clan 10 hours agorootparentSecure is not a binary term. If sjunet is managed as a number of interconnected airgapped networks then I for sure find that more secure than a Internet connected network. The attacker surely still have vectors in but whole classes of common attacks are mitigated. Even if it is just \"one big intranet\" it is still better than one big intranet with one really good ((zero) trust me bro!) firewall to the Internet. Various levels of zero trust principles can easily be applied within sjunet. That makes it better in my eyes. For critical infrastructure I find this an important step. In the end security relies on us stupid humans. And it is easier to manage an airgap. It is the number of things we do afterwards to bypass it which is the problem. The idea of an Intranet is still sound. But private does not mean secure. It is just a security layer. The next layer is if you run it fully open. Are the rooms locked? Do you require 802.11X certificates for connectivity? Are all ports open for all clients/hosts. Do you have a sensible policy for you host configuration? Have you segmented the network even further? Etc. Etc. So your point is still valid for sure! You should secure it like on the public Internet aka a hostile environment. That is the important takeaway. My point is that is should no be used as an argument against a private network. For large critical infrastructure such as hospitals it makes good sense. It is an added layer for the attacker to overcome - it is not security theater. For some the hassle might not be worth the while but that is then the trade off as with all forms of security. It ain't binary but discussion often end up like that. Done right it can be additive. Done wrong it just adds pain and agony. We all dread the security theatre. I boldly claim this aint't it. reply krab 10 hours agorootparentprevMaybe knowing there are many institutions on the network is a good motivation to keep services secure. It's apparent any hospital or vendor may be breached. So if you overcome the false sense of security, the separate network will give you another layer of defense. reply jaapz 10 hours agorootparentprevWho says they're not securing anything apart from being air-gapped from the internet? reply grvbck 7 hours agorootparentSjunet is not air-gapped though. Clients can connect via vpn over the internet. reply robjan 8 hours agorootparentprevIt's not necessarily air-gapped. There are many ways to accidentally or deliberately patch the intranet and internet together. reply actionfromafar 9 hours agorootparentprevIt's not only about security but also availability. If the regular Internet goes down for some reason, the private network (is meant to) keep operating. reply msla 3 hours agorootparentSo they actually have multiple physical sets of cables? reply actionfromafar 3 hours agorootparentYes, I think so. There's not much public information, perhaps on purpose. reply usrnm 10 hours agorootparentprev> might not have been secured like they would have been on the public Internet Yes, because we all know how secure the tings on the public Internet are. /s Nobody's saying that a private network doesn't have to be properly secured, you're fighting a strawman argument reply moffkalast 6 hours agorootparentprevIf you can't trust anything, you can't do anything. The result is that people who actually need to get their job done then circumvent the entire system and reduce security to absolute zero. As much as the average security expert would like to lock everyone in a padded room forever, there needs to be an acceptable trade-off level of safety and usability. Post-its with passwords are the most classical example, but removing internet access from an entire institution is just gonna lead to people bringing their own mobile networked devices and does honestly sound like a completely braindead idea. reply orkoden 4 hours agorootparentPost-it‘s with passwords aren’t the worst in security. Physical access to the note is required to get the password. One post-it under each keyboard with a different password is better than the same password shared widely. reply miki123211 9 hours agoparentprevPoland has the little-known \"źródło\" (meaning \"source\" in English). It's a network that interconnects county offices, town halls and such, giving them access to the central databases where citizens' personal information are stored. It's what is used when e.g. changing your address with the government, getting a new ID card, registering a child or marriage etc. As far as I know, the \"Źródło\" app runs on separate, \"airgapped\" computers, with access to the internal network but not the internet, using cryptographic client certificates (via smart cards) for authentication. reply sz4kerto 11 hours agoparentprevUK has that (called the HSCN). I don't think it's a good thing. Couple of years ago you had to pay hundreds of dollars for a a TLS certificate because there were only a couple of 'approved' certificate providers. It also provides a false sense of security and provides an excuse to bad security policies. The bandwidth is low and expensive. reply simonjgreen 11 hours agorootparentIt’s not sure it’s quite the same, HSCN does provide border connectivity to Internet as well as a peering exchange. Sjunet on the other hand is an entirely private network with no border connectivity. I have dealt with both. reply citrin_ru 7 hours agorootparentprev> It also provides a false sense of security The same argument was against seat belts in cars and bicycle/motorcycle hemlets. IMHO this arguments is rarely good. False sense of security should not be addressed by removing protection. > provides an excuse to bad security policies It should not be used as an excuse but bad policies in air-gaped network is less bad than bad policies in the Interned connected one. I doubt policies will be quickly improve as soon as you connect to the Internet. reply actionfromafar 11 hours agorootparentprevWhether an implementation is bad is orthogonal to whether the idea itself is good. reply sz4kerto 11 hours agorootparentI don't agree fully. If some idea looks really good but implementations tend to be very problematic then the idea is likely presented incompletely or inaccurately, because it carries some hidden/non-apparent risk. Some good-looking ideas almost always result in beneficial implementations, some good-looking ideas almost always result in bad implementations. reply ithkuil 10 hours agorootparentIf all implementations of a \"good\" idea are bad then that's a strong indication that the \"good\" idea might have some significant flaws. If the \"good\" idea has some bad implementations as well as some good implementations (like the swedish network example?) then perhaps you shouldn't dismiss the \"good\" idea so quickly reply actionfromafar 11 hours agorootparentprevSure, let's get to concrete things. What is a separate physical network worth, availability wise? Kind of hard to answer. It depends on the threat model. Even geography. reply roenxi 8 hours agorootparentprevIn this case though the two things are closely intertwined. The reason we all use the internet is because it is the most fit-for-purpose network for moving bits around between intranets. If there was a substantially more effective way to do it then it'd be cheaper or better and we'd all migrate to it over time. Countless businesses at all levels of the abstraction stack labour to make the internet cheaper and more convenient (CDNs are unbelievable, I say!). So people choosing to create a new network are, with high confidence, going to end up with networks that are substantially worse at moving bits around cost effectively than the internet. The reality that they are inconvenient and expensive is built in once the deliberate choice is made to avoid the internet. It might be worth the cost, but the cost comes with the idea. reply 3np 4 hours agorootparentNot sure what you are even refering to. Could you be specific? Got examples in mind? reply Xelbair 11 hours agorootparentprevnext [2 more] [flagged] cqqxo4zV46cp 10 hours agorootparentUsing Latin words isn’t a suitable substitute for critical thought. You aren’t applying any here. There’s a clear difference between these two scenarios. The argument with communism tends to hinge on the assertion that there’s been no good real-world implementation of communism. Here, OP is asserting that an implementation is good. That’s yet to be refuted based on the actual characteristics of the implantation. You’re at the very least being tone deaf. reply digging 3 hours agorootparentprev> provides an excuse to bad security policies That's a (highly predictable) implementation problem of HSCN, not a problem with the idea. These complaints boil down to the same old thing: stupidly written law setting a (potentially) good policy up for failure. reply nox101 12 hours agoparentprevGiven the state of IT in healthcare in pretty much every other country, is there any reason to believe \"Members of Sjunet are expected to know their networks and keep tight controls on IT\" has any meaning? Does the government audit every computer on the network? Are they all updated with the latest patches? Do we know people aren't plugging in random USB devices, etc..? reply anticristi 2 hours agorootparentMy understanding is that the members need to sign a contract to join Sjunet. I'm not sure of penalties, but being kicked out of Sjunet is likely an incentive for decent IT staffing. reply jmprspret 11 hours agorootparentprevYeah. As someone who has literally been in this industry.. As sad as it is, its a pretty massive ask to expect all healthcare places to have their security \"tight\". All it takes is one lax clinic or hospital (and truth be told they are ALL lax in their security in one way or another) for it to come crumbling down. reply hulitu 11 hours agorootparentprev> Are they all updated with the latest patches? Are the latest patches security updates ? reply wkat4242 12 hours agoparentprevI kinda wish there was a WAN the way internet used to be in the 90s. With more hobby stuff, no commercial things and no regulations. A bit like tor but without all the creepy stuff I guess. reply simonjgreen 11 hours agorootparentThere are several overlay WANs for fun and learning. For example, check out DN42. reply wkat4242 3 hours agorootparentInteresting, thanks! I will check it out. reply kreddor 12 hours agoparentprevDenmark has something quite similar (Sundhedsdatanettet). reply mrweasel 8 hours agorootparentSundhedsdatanettet actually runs on \"public IPs\". They aren't public, they aren't routed and they certainly are not connected to the internet, but they do exist within a public range. Not sure why a private range wasn't picked, but I'd guess it's to avoid conflicts with other networks. reply anticristi 2 hours agorootparentSjunet also uses public IP, but never exposes those on the Internet. No clue why, probably it turned out to be the easiest solution to avoiding collision with private ranges used at all member organizations. reply myself248 6 hours agorootparentprevCould that actually provide a benefit, in that if someone accidentally DOES connect it to the public internet, all sorts of things break immediately and obviously? If the two networks are entirely separate, and they absolutely must be, then there's no reason for addressing concerns of one to influence the other one iota. (Except that certain OSes might have baked-in assumptions about things like the 127/8 network, so you'd have to work around those.) reply jmnicolas 11 hours agorootparentprev> Sundhedsdatanettet What a tongue twister for non danish speaking people :D reply skrebbel 10 hours agorootparentIt’s even better when you know that the proper pronunciation is essentially “soondhldlddlnl” (Source: I speak Danish as a second language. I used to think Georgian was the language with the most consecutive consonants but then I learned how little the Danes respect their vowels so now I know better) reply ithkuil 10 hours agorootparentObligatory reminder of https://youtu.be/s-mOy8VUEBk?si=QTjx6KEmOuPUoq9I reply Symbiote 6 hours agorootparent\"Why Danish sounds funny\" is more informative: https://www.youtube.com/watch?v=eI5DPt3Ge_s reply Symbiote 11 hours agorootparentprevIn English we would put spaces between parts of a \"compound\" word. > Sundheds data nettet Sund-hed is \"sound-ness\" (or even \"sound-hood\"), i.e. health. > The health data network reply kwhitefoot 5 hours agorootparentIn Norway this is called engelsk orddeling and is a source of gentle amusement, or occasionally outbursts of irritation. See https://www.diskusjon.no/blogs/entry/878-orddeling-en-engels... reply ithkuil 10 hours agorootparentprevYep. not putting spaces on compound words doesn't twist the tongue but twist the eyes! Eyetwister reply jmnicolas 11 hours agoparentprevNo computers connected to the internet in Swedish hospitals? If there are, a bridge could be made willingly or not. OFC it's more secure than everything on the internet. reply djha-skin 4 hours agoprev> If you are operating a private network, your internal services probably don't have TLS certificates signed by a popular CA that is in root programs. You will spend many valuable hours of your life trying to remember the default password for the JRE's special private trust store and discovering all of the other things that have special private trust stores, even though your operating system provides a perfectly reasonable trust store that is relatively easy to manage, because of Reasons. You will discover that in some tech stacks this is consistent but in others it depends on what libraries you use. Oof, I feel this one. I tried to get IntelliJ's JRE trust store to understand that there was a new certificate for zscaler that it had to use and there were two or three different JDKs to choose from, and all of their trust stores were given the new certificate and it still didn't work and we didn't know why. reply forinti 6 hours agoprevAfter watching a video of a person playing with a MacDonald's kiosk, I started to do the same with equipment I found at different places. One food court had kiosks with Windows and complete access to the Internet. Somebody could download malware and steal credit card data. Every time I used one, I turned it off or left a message on the screen. Eventually they started running it in kiosk mode. Another was a parking kiosk. It was never hardened. I guess criminals haven't caught on to this yet. The third was an interactive display for a brand of beer. This one wasn't going to cause any harm, but I liked to leave Notepad open with \"Drink water\" on it. Eventually they turned it off. That's one way to fix it, I guess. reply remus 6 hours agoparent> Another was a parking kiosk. It was never hardened. I guess criminals haven't caught on to this yet. I don't know the details of how the parking kiosks near me are setup, but I can only assume they're put together really poorly because once, after mashing buttons in frustration, it started refunding me for tickets that I'd not purchased. You'd have thought \"Don't give money to random passers by\" would have been fairly high on the list of requirements, but there we are. reply golergka 15 minutes agoparentprevIf you open a browser with porn on it, they will get fixed very, very fast. reply RajT88 3 hours agoprevMy big take-away is not that \"all these systems shouldn't be connected to the internet\", it's a few other things: 1. These systems shouldn't allow outbound network flows. That will stop all auto-updates, which you can then manage via internal distribution channels. 2. Even without that, you can disable auto-updates on many enterprise software products - Windows notably, but also Crowdstrike itself. I heard about CS customers disabling auto-update and doing manual rollouts who were saved by this practice. 3. Tacking on to number 2 - gradual rollout of updates which you've done some smoke testing on. Just in case. Again - I heard of CS customers who did a gradual rollout, and managed to only have a fraction of their machines impacted. reply tormeh 7 hours agoprevI remain unconvinced that you shouldn't air-gap systems because that means you can't use internet-centric development practices. I find this argument absurd. The systems that should have their ethernet ports epoxyed also should never have been programmed using internet-centric development practices in the first place. Your MRI machine fetches JS dependencies from NPM on boot? Straight to jail. Not metaphorically. reply NoboruWataya 7 hours agoprevIt seems fairly obvious that an airline reservation system needs to be connected to a network at least, I haven't heard many people claim they should have been all offline. But for example I heard stories of lathe machines in workshops that were disabled by this. You gotta wonder whether they really needed to be online. (I'm sure there are reasons, but they are reasons that should be weighed against the risks.) Beyond that there are plenty of even more ridiculous examples of things that are now connected to the internet, like refrigerators, kettles, garage doors etc. (I don't know if many, or any, of these things were affected by the CrowdStrike incident, but if not, it's only a matter of time until the next one.) As for the claim that non-connected systems are \"very, very annoying\", my experience as a user is that all security is \"very, very annoying\". 2FA, mandatory password changing, locked down devices, malware scanners, link sanitisers - some of it is necessary, some of it is bullshit (and I'm not qualified to tell the difference), but all of it is friction. reply kwhitefoot 4 hours agoparent> a network Of course. But not the Internet. reply RF_Savage 12 hours agoprevThere is also hamnet, which is partly internet routable and partly not on the 44Net IP block. https://hamnetdb.net/map.cgi It has interesting limitations due to the amateur radio spectrum used. Including total ban commercial use. As that is the social contract of the spectrum, you get cheap access to loads of spectrum between 136kHz and 241GHz, but can't make money with it. reply wkat4242 12 hours agoparentYeah it's really hard to get an uplink to it though. Even in a big city. Only in the Netherlands and Germany is it really widespread: https://hamnetdb.net/map.cgi . Here in Spain it's not available anywhere near me. reply withinboredom 9 hours agorootparentWith hamm radio, it doesn't need to be near IIRC. It's been a long af time since I've messed about with radio, but pretty sure you'd be able to use the ionosphere as an antenna. reply wkat4242 7 hours agorootparentFor this it does need to be near. These are all high-speed connections that need line of sight. Basically those microwave dishes that you see everywhere. Or at least a grid reflector or yagi or something. With HF yes you can use the various atmospheric layers to reflect depending on band but in those bands the available bandwidth is extremely low (the entire HF range itself is only 30mhz and the amateurs only have a few small slices of that). The only practical digital operations there are Morse, RTTY (basically telex) and some obscure extremely-slow GPS synced data modes like WISPR and FT8 that are basically for distance bragging rights but don't transmit useful payload. So in effect, no. In this case line of sight or at least short distances (VHF/UHF) are required. Also, I don't have space for huge antennas that HF requires as I'm in a small apartment in the middle of a built-up city. reply 1970-01-01 1 hour agoprevOne way to see how she is right is by asking how many layers of 'disconnect from the Internet' do you need? Are you expecting a firewall rule of deny all? Closing all ports on the hosts? Ripping away the TCP/IP stack? Where are you expecting the line of success? Remember, all traffic is routable. reply eqqn 8 hours agoprev\"Don't worry, the software in question seems to have fallen out of favor and cannot hurt you.\" It may not be the software in question, but proprietary snowflake entitlement management software that has a lot of black box and proprietary voodoo, that does not have any disaster recovery capacity and would be considered tech debt a decade ago... Disgracefully came into life in the year 2021. It did not gracefully recover from clownstrike to say the least. reply lokimedes 11 hours agoprevThat pretty well summed up my time delivering state of the art AI solutions to military customers. 80% of the effort was getting internet-native tooling to work seamlessly in an air-gapped environment. reply tjoff 12 hours agoprevGood article, though I really thought it would be about the other end. You know hacking movies in the 90s(?) where the good guys face a hacker-attack, frantically typing at the keyboard trying to keep the hackers away. It is a losing battle though, but just at the nick of time (the progress bar is at 97%) the hero unplugs the power cord or internet cable. Or, in the case of crowdstrike. I can imagine support starts to get some calls, at some time you realize that something has gone horribly wrong. An update, maybe not obvious which, is wreaking havoc. How do you stop it? Have you foreseen this scenario and have a simple switch to stop sending updates? Or, do you cut the internet? Unlike the movies there isn't a single cord to pull, maybe the servers are in a different building or some cloud somewhere. They probably have a CDN, can you pull the files efficiently? Now maybe by the time they discovered this it was mostly too late, all online systems might already have gotten the latest updates (but even if that is the case, do they know that is the case?). reply JKCalhoun 6 hours agoparentI have resisted \"auto updates\" for the OS's of my personal machines. Instead the OS nags me when there is a software update and I just ignore it for a week or so. I assume that any accidentally buggy software update will be found by others (or Apple) first and I can have dodged that particular bullet. Not air-gap, temporal gap. reply rowbin 10 hours agoprev>> The stronger versions, things from List 1 and List 2, are mostly only seen in defense and intelligence And I don't think that is enough. I agree that it easier and sufficient for most systems to just be connected over the internet. But health, aviation and critical infrastructure in general should try to be offline as much as possible. Many of the issues described with being offline stem from having many third party dependencies (which typically assume internet access). In general but for critical infrastructure especially you want as little third party dependencies as possible. Sure it's not as easy as saying \"we don't want third party dependencies\" and all is well. You'll have to make a lot of sacrifices. But you also have a lot to gain when dramatically decreasing complexity, not only from a security standpoint. I really do believe there are many cases where it would be better to use a severely limited tech stack (hardware and software) and use a data diode like approach where necessary. One of the key headaches mentioned when going offline is TLS. I agree and I think the solution is to not use TLS at all. Using a VPN inside the air-gapped network should be slightly better. It's still a huge headache and you have to get this right, but being connected to the internet at all times is also a HUGE headache. reply halfcat 35 minutes agoprevThere are many fundamental assumptions that ought to be challenged like this. Does a computer that can access your accounting system need to access the internet? Or email? A user could run two computers, one that’s for internet stuff, and one that does important internal stuff. But that’s a silly idea because it’s costly. However, we can achieve the same thing with virtualization, where a user’s web browser is running in a container/VM somewhere and if compromised, goes away. Stuff like this exists throughout society in general. When should a city employee carry a gun? On one end of the spectrum, the SWAT team probably needs guns. On the other end, the guy who put a note on my door that my fence was leaning into the neighbor’s property didn’t have a gun. So the question is, is a a traffic stop closer to the SWAT team or the guy kindly letting me know I’ve violated a city ordinance? I don’t know why these things don’t get reassessed. Is it that infrastructure is slower to iterate on? Reworking the company’s network infrastructure, or retraining law enforcement departments, is a big, costly undertaking. reply readyplayernull 2 hours agoprevAnd I just got this from big bro Google: [...] With the new Find My Device network, you’ll be able to locate your devices even if they’re offline. [...] Devices in the network use Bluetooth to scan for nearby items. Full email content: Find My Device network is coming soon You can use Find My Device today to locate devices when they’re connected to the internet. With the new Find My Device network, you’ll be able to locate your devices even if they’re offline. You can also find any compatible Fast Pair accessories when they’re disconnected from your device. This includes compatible earbuds and headphones, and trackers that you can attach to your wallet, keys, or bike. To help you find your items when they’re offline, Find My Device will use the network of over a billion devices in the Android community and store your devices’ recent locations. How it works Devices in the network use Bluetooth to scan for nearby items. If other devices detect your items, they’ll securely send the locations where the items were detected to Find My Device. Your Android devices will do the same to help others find their offline items when detected nearby. Your devices’ locations will be encrypted using the PIN, pattern, or password for your Android devices. They can only be seen by you and those you share your devices with in Find My Device. They will not be visible to Google or used for other purposes. You’ll get a confirmation email in 3 days when this feature is turned on for your Android devices. Until then, you can opt out of the network through Find My Device on the web. Your choice will apply to all Android devices linked to [email]. After the feature is on, you can manage device participation anytime through Find My Device settings on the device. Learn more reply llm_trw 3 hours agoprevThe description of updates is painfully true. A long time ago I worked at a broker trader where all communications, including servers communications, had to go through zscaler as a man in the middle. What had been routine all of a sudden became impossible. Turns out that git, apt, pip, cabal and ctan all had different ideas about how easy they should make this. After a month of fighting each of them I gave up. I just downloaded everything from their public ftp repos and build from source over a week. I wish good luck to whoever had to maintain it. reply creesch 11 hours agoprevA bit of a tangent to the subject of the blog, but something that has been bugging for a while. What's up with all these blogs that choose fonts that are just not that good for readability? In this case, monospace. It's not code, it is not formatted as code, making it a bad choice for comfortable reading. Are these people not writing blogs to be read? And just to be ahead of it, just because you are able to read it doesn't mean it wouldn't be easier and more comfortable to read in a more suitable font. reply inetknght 5 hours agoparent> What's up with all these blogs that choose fonts that are just not that good for readability? In this case, monospace. It's not code, it is not formatted as code, making it a bad choice for comfortable reading. That's a subjective opinion. I vastly prefer monospaced fonts. They're easier to read! reply creesch 4 hours agorootparentNot really, there have been various studies that have shown that for the majority of people and cases sans serif fonts are the better choice for reading. There are some exceptions. Obviously, code is one of these, as code is explicitly differently structured. Dyslexia is another one where monospaced fonts might actually increase readability. But overall they decrease readability compared to other font types. reply msla 3 hours agorootparent> Not really, there have been various studies that have shown that for the majority of people and cases sans serif fonts are the better choice for reading. ... so therefore thinline grey-on-gray text is ideal! Good meeting, let's do lunch. You can nitpick the linked site, but it is amazingly readable compared to sites that feel compelled to adhere to modern fashions, like having blinking, throbbing nonsense in the field of vision making it impossible to concentrate on the actual text, or making the text too small unless you have exactly the same ultra-retina 8K HD phone the author does, or thinking \"contrast\" is a city in Turkey. reply creesch 3 hours agorootparentWell that is one way to go over the top with a counterargument. I am not advocating for any of that, just that maybe a sans serif would have been a more suitable choice. reply msla 2 hours agorootparentIt's odd how you insist that sans serif is more readable when body text in every book (OK, every grown-up book) I've read has been serif, as far as I can remember. reply creesch 2 hours agorootparentThis very much feels like an arguing for the sake of arguing type response to me. Given that, what I am typing isn't obscure knowledge in the slightest. Anyway, assuming you are honestly just curious. Sans serif has shown to be the better readable font type on displays. Granted, on modern displays with higher density pixels that is less important. Either way, both are a better choice compared to a monospaced font. reply williamdclt 8 hours agoparentprevI always think that if I prefer to enable Firefox's reader view on a blog, they _really_ messed up: a bland, basic, generic syling is preferrable to their custom one. It's what happens with most blogs, sadly reply creesch 7 hours agorootparentIt is indeed what prompted me to go on this tangent. I see so many blog posts being posted here that are just unnecessarily uncomfortable to read. It's just baffling how a person can spend time and effort to publish something on the internet, clearly wanting people to read it, and then not consider the bare basics. reply 0898 10 hours agoparentprevIt’s a retro nod to newsletters like NTK and Popbitch, I believe. reply creesch 10 hours agorootparentI get that it is an aesthetic choice. One I can't really understand given the main purpose of a blog, I think anyway, is to be read. reply gizmo 10 hours agoprev> But that just, you know, scratches the surface. You probably develop and deploy software using a half dozen different package managers with varying degrees of accommodation for operating against private, internal repositories. That's non-ironically the problem. Current software culture creates \"secure software\" with a 200 million line of code attack surface and then act surprised when it blows up spectacularly. We do this because there is effectively no liability for software vendors or for their customers. What software security vendors sell is regulatory compliance, not security. reply andrewstuart 12 hours agoprevI don't think systems should not be connected to the Internet. I did find it surprising however that so many systems shown on TV run Windows. Digital signage screens, shopping registers all sorts of stuff that I assumed would be running Linux. It is surprising to me that systems with functions like a cash register would be doing automatic updates at all. reply forinti 6 hours agoparentA long time ago I built a multimedia kiosk for a retail chain. I used Linux and X without a Window Manager, so my worst case scenario was that the clients would see a gray screen. I agree that it does not make sense to use Windows for this sort of thing. reply hnthrow289570 6 hours agoparentprevI don't think many developers are going to be really excited about building signs or kiosks, so they will not be bringing their A-game. Since MS has a kiosk mode officially, they probably assume either choice is good enough. reply ahoka 4 hours agoparentprevIt wouldn't be much better if they ran Fedora 14. reply willi59549879 11 hours agoparentprevIt surprised me too. Maybe it is because people are just more used to windows. Or it might be because of more software geared to roll out software updates. reply mrweasel 8 hours agoparentprev> It is surprising to me that systems with functions like a cash register would be doing automatic updates at all. Yeah that's weird, at least do it via some on-premise \"proxy\". Windows has WSUS and I'd assume that Crowdstrike has something similar. I know that TrendMicro provides, or have provide an update service, allowing customers to rollout patches at their own pace. Sadly very few things seems to run correctly without internet access these days. I get the complaint about management and updates for something like things in people homes, but if you're an airport, would it be so bad to have critical infrastructure not on the internet? I don't really care if the digital signs run Windows, there are plenty of reasons why you'd choose that, but why run Crowdstrike on those devices? Shouldn't they be read-only anyway? reply heraldgeezer 5 hours agoparentprevBecause software is bought from vendors that require Windows. This is often the case with Point of Sale software. OR the solution is a powerpoint or mp4 file running on a TV for signage. If every office computer is already Windows, IT has management applications like GPO, SCCM/Intune, or RMMs like Datto/Ninjaone to deploy policy and manage Windows computers remotely. It then makes sense to just keep using those, rather than making a whole new system just for the digital signage computers. reply cqqxo4zV46cp 9 hours agoparentprevBecause desktop Linux is an absolute bloody mess and most IT departments are completely justified in not wanting to deal with it? I’m not saying that Windows is great. I haven’t willingly used it in 15 years. But you can’t keep your head in the sand about the sad state of Linux and anything graphical, especially on esoteric hardware. POS systems are often effectively Internet-connected, because they need to report stock levels, connect to financial networks, process BNPL applications, etc. it’s completely warranted to treat them like ‘endpoints’, because they are. reply bregma 8 hours agorootparentPOS terminals and electronic billboards are not desktops, though, so arguments about desktop software is irrelevant. These are all dedicated application appliances with known, controlled hardware and software constraints. Using a general-purpose desktop designed for corporate executives running Excel and PowerPoint is just the wrong technology choice for such an application. Some kind of specialized Linux-based system, on the other hand, is an excellent choice. reply duckmysick 4 hours agorootparentMost of the point of sale systems I've seen run Windows, which means most of the off-the-shelf apps are written for Windows. Even if they are written in Java, they have hard dependencies on Windows. > Using a general-purpose desktop designed for corporate executives running Excel and PowerPoint is just the wrong technology choice for such an application. Agree, which is why most of the time you use Windows Embedded for Point of Service or Windows IoT Enterprise. Which again, is Windows. reply heraldgeezer 5 hours agorootparentprevI have seen digital signage just be a PPT file running in full screen though. Good? No, but that's the reality of things. reply andrewstuart 9 hours agorootparentprevI have alot of experience with Linux running Custom builds with chrome. I can say it’s not easy to configure but once done it’s very stable and simple. reply gwern 1 hour agoprevMarvin Minsky in 1970 (54 years ago) on how you can't just \"turn off the X\" when it is a powerful economically-valuable pervasive computer system: \"Many computer scientists believe that people who talk about computer autonomy are indulging in a lot of cybernetic hoopla. Most of these skeptics are engineers who work mainly with technical problems in computer hardware and who are preoccupied with the mechanical operations of these machines. Other computer experts seriously doubt that the finer psychic processes of the human mind will ever be brought within the scope of circuitry, but they see autonomy as a prospect and are persuaded that the social impact will be immense. Up to a point, says Minsky, the impact will be positive. “The machine dehumanized man, but it could rehumanize him.” By automating all routine work and even tedious low-grade thinking, computers could free billions of people to spend most of their time doing pretty much as they d—n please. But such progress could also produce quite different results. “It might happen”, says Herbert Simon, “that the Puritan work ethic would crumble to dust and masses of people would succumb to the diseases of leisure.” An even greater danger may be in man’s increasing and by now irreversible dependency upon the computer The electronic circuit has already replaced the dynamo at the center of technological civilization. Many US industries and businesses, the telephone and power grids, the airlines and the mail service, the systems for distributing food and, not least, the big government bureaucracies would be instantly disrupted and threatened with complete breakdown if the computers they depend on were disconnected. The disorder in Western Europe and the Soviet Union would be almost as severe. What’s more, our dependency on computers seems certain to increase at a rapid rate. Doctors are already beginning to rely on computer diagnosis and computer-administered postoperative care. Artificial Intelligence experts believe that fiscal planners in both industry and government, caught up in deepening economic complexities, will gradually delegate to computers nearly complete control of the national (and even the global) economy. In the interests of efficiency, cost-cutting and speed of reaction, the Department of Defense may well be forced more and more to surrender human direction of military policies to machines that plan strategy and tactics. In time, say the scientist, diplomats will abdicate judgment to computers that predict, say, Russian policy by analyzing their own simulations of the entire Soviet state and of the personalities—or the computers—in power there. Man, in short, is coming to depend on thinking machines to make decisions that involve his vital interests and even his survival as a species. What guarantee do we base that in making these decisions the machines will always consider our best interests? There is no guarantee unless we provide it, says Minsky, and it will not be easy to provide—after all, man has not been able to guarantee that his own decisions are made in his own best interests. Any supercomputer could be programmed to test important decisions for their value to human beings, but such a computer, being autonomous, could also presumably write a program that countermanded these “ethical” instructions. There need be no question of computer malice here, merely a matter of computer creativity overcoming external restraints.\" reply fifteen1506 9 hours agoprevThe author is failing to see a potential solution. Whitelist all needed IPs for business functionality, enable the whole Internet once every 3 hours for an hour. Bonus points if you can do it by network segment. It would be enough to spare half your computers from the CrowdStrike issue, since I believe the update was pulled after an hour. Will any-one do this? Probably not. But it is worth entertaining as a possibility between the fully on connectivity and the fully disconnected. reply deathanatos 1 hour agoparent> It would be enough That depends on the phase of your \"every 3 hours for an hour\" signal, and the phase of \"the update was pulled after an hour.\". That's a 33% overlap. Feelin' lucky? reply vel0city 2 hours agoparentprev> Whitelist all needed IPs for business functionality I really don't like this mentality. The IP I'm serving some service might change. DNS is a useful thing. reply deathanatos 1 hour agorootparentSecurity types love it. But from a infra eng viewpoint, it's an utter pain in the ass, and the thought of \"what if IP changes?\" — which inevitably happens — has no process, no plan, and ends up as \"manually update O(n) different configurations, of which there does not exist a list of, so you'll never know if you got them all.\" reply asynchronous 13 hours agoprevGreat write up on the issues and challenges with airgapped and entirely internet avoidant systems in the modern software world. reply gala8y 11 hours agoparentI will piggyback on your comment. Absolutely stellar example of fine grain thinking which accidentally shows huge expertise and real life experience of the author. Regardless of type of a problem, the amount of thinking put into solving it makes the difference. It is thinking in systems, building complex mental models and finding edge cases which pays off, regardless of the domain / problem at hand. People tend to halt too soon in building mental models. When you are responsible for any given area, you better build a fine grained model. Obviously this is costly in terms of time, money, lost opportunity,... and there is of course a blurry line where you should stop building complexity of a model and just implement a solution. Life will come knocking on your door anyways, Aunt Entropy shows up sooner or later. This is also why almost all news is non-sense for an expert in given domain. Basically... \"It's not that simple.\" reply jongjong 12 hours agoprev'Disconnect from the internet' is a kind of 'Security through obscurity'; which isn't very good security. It's basically an admission that the software may be full of vulnerabilities and the only way to protect it is to limit its exposure to the outside world. The root of the problem is that almost all software is poorly designed and full of unnecessary complexity which leaves room for exploitation. Companies don't have a good model for quality software and don't aim for it as a goal. They just pile on layer upon layer of complexity. Quality software tends to be minimalistic. The code should be so easy to read that an average hacker could hack it in under an hour if there was an issue with it... But if the code is both simple and there is no vulnerability within it, then you can rest assured that there exist no hackers on the face of the earth who can exploit it in unexpected ways. The attack surface should be crystal clear. You don't want to play a game of cat and mouse with hackers because it's only a matter of time before you come across a hacker who can surpass your expectations. Also, it's orders of magnitude more work to create complex secure software than it is to create simple secure software. The mindset to adopt is that bad code deserves to be hacked. Difficulty involved in pulling off the hack is not a factor. It's a matter of time before hackers can disentangle the complexity. reply bux93 12 hours agoparentI don't agree that airgapping is security through obscurity; it's defense in depth, just like putting up a fence around your datacenter. It doesn't solve your insider risk (or 12 foot ladder risk), but it is an additional measure. reply sureIy 12 hours agoparentprev> 'Security through obscurity'; which isn't very good security. I never understood this. You never have absolute security, that’s why you must apply the Swiss cheese model. Obscurity is definitely a worthy slice to have. Few people can attack you if you can only be attacked in person. reply Animats 12 hours agorootparentThe \"Swiss cheese model\" worked against amateur attackers. It doesn't hold up against well-funded or patient ones who can work through the holes in each layer. The extreme demo of this was Stuxnet. reply DaSHacka 12 hours agorootparentHence the purpose behind threat modelling? All security is really just the swiss-cheese model. Some entities just invest in more slices than others to keep more sophisticated/determined attackers out (such as nation states). What other practical model is there for security then defense in depth? \"Just make 100% bulletproof computers with no faults?\" reply Animats 1 hour agorootparentAlternative models: - Systems that store the code in read-only memory. Example: slot machines. - Systems with backup systems completely different from the main system, implemented by a different group, and thoroughly tested. Example: Airbus aircraft. - Systems continuously sanity-checked by hard-wired checkers. Example: Traffic lights. - Systems where the important computational functions are totally stateless and hardware reset to a ground state for each transaction. Example: #5 Crossbar. reply UncleMeat 5 hours agorootparentprevSystems security is an economics game. It is valuable to be protected against amateur attackers even if the most extreme state actors can still breach you. The criticism of \"security through obscurity\" is specifically Kerchoff's Principle, which applies to cryptographic systems. It is not an absolute rule outside of that domain. reply lelanthran 11 hours agorootparentprevNothing works against an attack like stuxnet. This doesn't mean that you should do nothing. Obscurity is one layer, and it does protect against drive by attacks. Obscurity as the only layer does not work. Obscurity as an added layer improves security. reply wkat4242 11 hours agorootparentprevNo but it makes it a hell of a lot harder for them to do it undetected. There's a reason Stuxnet was an exception. These things are not very common and the only reason we even know about it is because it managed to spread further than its intended target. reply Pavilion2095 10 hours agorootparentprevWhat is better than the Swiss cheese model or its derivatives? Planes still crash from time to time, but nobody is saying that the model is wrong as the reliability is insane. reply eimrine 12 hours agoparentprev> 'Disconnect from the internet' is a kind of 'Security through obscurity' I disagree with this, no internet is not an obscurity this is more like incapsulation for the sake of having controllable interface via setters and getters only. If some computer rules something (something big as an airport or something tiny like a washing machine) how often it really needs an update of something system-related like the kernel? How many MB of code with potential 0-days are you going to expose to the wild for the sake of that autoupdate? reply d4mi3n 12 hours agoparentprevCybersecurity is mainly a technical application of risk management. An untrusted network (the internet) is a risk. Removing access from that network is one way to mitigate that risk. Obscurity doesn’t remove a risk, it just reduces its likelihood. An obscurity approach here would be more akin to changing your SSH port from 22 to some random number rather than blocking SSH entirely. reply christianqchung 12 hours agoparentprevI have no experience in cybersecurity, but if the software is possibly full of vulnerabilities and the company is not willing to fix it, why not support disconnecting it if it functions anyway? Analogously, someone who lives in a dangerous neighborhood locks their doors because they can't move somewhere safer, and that's viewed as normal. reply epigramx 12 hours agoparentprevGive an example of software that exists for decades and never had an exploit. You might say basic OS tools. The OS might not be secure then; giving internet terminals to everyone in the world is just a stupid oversight; the best is probably a combination of both having internet when needed but most access to it to be through an extremely thick layer of firewalls (e.g. only system administrators updating stuff should be exposed to the internet for software involving airport security). reply PhilipRoman 10 hours agoparentprevI actually agree with this. Of course it's easy to dismiss as \"just don't make mistakes\" but there is a profound lack of simplicity. For example, a security boundary like ssh or vpn should not have a billion configuration options (or any options for that matter), some less secure than others. It also shouldn't have any complex negotiating before auth. Receive a fixed size magic + auth key, validate with small formally verified crypto, if doesn't match then drop connection without any IO or other side effect. But instead we have protocols where the security boundary represents thousands of pages of specifications, parsing of complex structures in elevated context, network requests on behalf of untrusted users, logging without input escaping, and a dozen \"unused\" extensions added by some company in 1990s to be backwards compatible with their 5 bit EBDIC machines. reply m_eiman 11 hours agoparentprev> 'Disconnect from the internet' is a kind of 'Security through obscurity'; which isn't very good security. Just think of it as a very efficient firewall. reply fiatpandas 12 hours agoparentprev> But if the code is both simple and there is no issue with it, then you can rest assured that there exist no hackers on the face of the earth who can exploit it Ah yes, security through absolute perfection. reply formerly_proven 12 hours agorootparentsecurity through absolute holistic perfection (STAHP) reply jongjong 12 hours agorootparentprevIt's difficult to get there but it's often achievable and worthwhile. When a company is worth billions, what's the cost of aiming to reach perfection? What's the cost of not trying? reply kalleboo 11 hours agorootparentThe cost is you lose to your competitor who offers features (complexity) instead of security and now all your effort is for naught. People talk a lot about security but nobody actually values it. You just send out some Uber Eats coupons or free Credit Protection vouchers and keep on doing what you were doing and in a month everyone has forgotten. reply DaSHacka 12 hours agorootparentprevI'd argue more aptly: what's the cost when this \"perfect\" solution inevitably fails? If it was easy (or even _possible_) to make perfect computers, I assure you we already would. reply mewpmewp2 12 hours agorootparentprevWhat is your experience with that perfection? Have you been able to achieve it in a large org? reply lelanthran 10 hours agorootparentNevermind a large org, I'd be surprised if you can achieve that perfection in tiny software written in the safest languages reviewed by experienced engineers. reply gz5 5 hours agoprevwe can use the Internet without being used by the Internet. an open source example: https://blog.openziti.io/no-listening-ports reply renegat0x0 11 hours agoprev [–] Connection between clownstrike and cybersecurity is flimsy. This was not an attack. This was a resource management problem, a process problem. Meaning: if your process are invalid, you can also fail in off-line scenario. If you do not treat quality control, or tests correctly you gonna have a bad time. reply owl57 11 hours agoparent [–] > if your process are invalid, you can also fail in off-line scenario Online amplifies failure at least as well as it amplifies success. Offline maintenance is quite unlikely to bluescreen 8 million devices before anyone has time to figure out something's going wrong. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A security vendor, ClownStrike, hypothetically disrupts their Windows install base with a faulty update, sparking discussions on the feasibility of disconnecting systems from the internet for security.",
      "Disconnecting systems from the internet is impractical for modern businesses due to the need for real-time communication, maintenance, updates, and monitoring.",
      "Enhancing security within connected environments through restrictive network policies and designing software with offline capabilities is a more effective approach than complete disconnection."
    ],
    "commentSummary": [
      "Disconnecting from the internet is not a straightforward solution for security issues, especially in IoT and healthcare industries that depend on connectivity for updates and functionality.",
      "The debate centers on the practicality of air-gapped systems versus the need for improved security practices, regulations, and balancing security with operational efficiency.",
      "Enhancing security involves a mix of better practices, education, and occasionally, strategic disconnection from the internet."
    ],
    "points": 335,
    "commentCount": 181,
    "retryCount": 0,
    "time": 1722477177
  },
  {
    "id": 41126944,
    "title": "Breakthrough a step toward revealing hidden structure of prime numbers",
    "originLink": "https://www.science.org/content/article/sensational-breakthrough-marks-step-toward-revealing-hidden-structure-prime-numbers",
    "originBody": "www.science.org Verifying you are human. This may take a few seconds. www.science.org 8ac814c95d6d1748",
    "commentLink": "https://news.ycombinator.com/item?id=41126944",
    "commentBody": "Breakthrough a step toward revealing hidden structure of prime numbers (science.org)286 points by igitur 11 hours agohidepastfavorite124 comments throwaway81523 10 hours agoThis is from May and there was a better article in Quanta already discussed here. https://www.quantamagazine.org/sensational-proof-delivers-ne... reply jhncls 9 hours agoparentDiscussion: https://news.ycombinator.com/item?id=40981272 There are 6 comments; the last one is clearly the most interesting: a link to a discussion by Terence Tao https://mathstodon.xyz/@tao/112557249982780815 Terence Tao also provides links to a presentation by James Maynard and Larry Guth: https://www.ias.edu/video/new-bounds-large-values-dirichlet-... and https://www.ias.edu/video/new-bounds-large-values-dirichlet-... reply riidom 7 hours agoparentprevI am a bit disappointed that the article doesn't explain what the introductory illustration about Sack's spiral has to do with any of this. reply alkyon 6 hours agorootparentSack's spiral is a variant of Ulam's spiral, he discovered in 1963 using MANIAC II. Edit: https://en.wikipedia.org/wiki/Ulam_spiral reply munificent 2 hours agorootparentprevThe somewhat cynical but honest answer is that all articles need some kind of pretty image at the top because when you share a link on any social media platform, the platform looks for an image to use as a thumbnail. If it doesn't find one, it gets posted as just a plain link and almost no one clicks it. This is why Medium requires an image on every post, why every programming blog out there puts random pictures of laptops and coffee cups at the top of their articles, why Unsplash is so popular, and now why AI-generated images at the top of posts are so common. It's dumb. reply 6gvONxR4sf7o 1 hour agoprevOn a slight tangent, this line makes me think about aspects of automated provers that I don’t even know if we’ve begun thinking about: > “It’s a sensational breakthrough,” says Alex Kontorovich, a mathematician at Rutgers University. “There are a bunch of new ideas going into this proof that people are going to be mining for years.” Frequently, a proof of a thing is less interesting as a way to bring rigor than it is as a new way to look at a thing. I wonder if there’s been any work on that side of things in automated mathematics? reply EMIRELADERO 10 hours agoprevThis got me thinking. Imagine this discovery led to a larger breakthrough on prime numbers that allowed easy factorization of large integers and effectively rendered public key cryptography such as RSA ineffective overnight, by allowing anyone with a consumer-grade CPU to crack any production-size key. Does the industry have DR plans for this scenario? Can the big players quickly switch to a different, unbroken encryption system? While it would probably be a heavenly day for jailbreakers, console modders and other \"device freedom\" types generally, the overall impact would be disastrous and incalculable. Does the industry simply not consider \"sudden number theory breakthrough\" a possible event? reply AnotherGoodName 3 hours agoparentThat happened many many times over with rsa! The us government used to restrict export of long rsa keys. At one point much of the world was using 128bit rsa keys but Dixon method had everyone scrambling to use 512bit keys. Then the special number field drive had us all scrambling to use 1024bit keys and the general number field seive again had us scrambling to get to 2048bit keys.l and that really wasn’t that long ago relatively speaking. Check out rsa encryption hardware from the 80s. They are really proud of some of the hardware that can do 512bits! (Useless today) https://people.csail.mit.edu/rivest/pubs/pubs/Riv84.pdf The special and general number field seize complexity statements are a few constants in difference. Look at those constants. Do they seem to be some root limit to you? Is it really that unlikely that there’s not a way to reduce those further making even 2048bit keys useless? You don’t need to ask “what would happen if RSA broke” because those of us who have been through this many times now can straight up tell you. You’ll be scrambling to once more bump up the key size and you’ll be auditing all the potential data leaked. reply scrapheap 9 hours agoparentprevIf someone found a way to easily factorize large integers easily on consumer grade hardware then it would be very painful as RSA is one of the big public key algorithms. Before you start worrying about it though consider that RSA has held up for 47 years of active cryptanalysis so far - during which time many alternative algorithms have been suggested as being superior, only to be broken a short time later. Also the push to switch to Elliptic-Curve algorithms has been more down to them being easier for computers to use to encrypt/decrypt data. Personally if I had to bet on which public key algorithm will still be around in 10 years time then I'd put my money on RSA. reply AnotherGoodName 3 hours agorootparentRSA has effectively been broken many times. We literally had 128bit RSA encryption hardware at one point. There were even export controls on keys beyond a certain length (512bits) that today are trivial to break with the general number field seive. You look at the history of RSA and it’s not pretty. Dixons method had us all scrambling to use 512bit keys (pushing the export restrictions), special number field seive had us rushing to get to 1024bit. The general number field seive more recently pushed us to 2048bits. Who can tell what’s next here. In fact look at the complexity of the special vs general number field seives and you’ll see the statements are almost the same, just some constants reduced. That’s worrying because there’s no reason to think the current constants are a minimum here. We may well find out 2048bits is not enough. Heck just read a paper in state of the art dedicated RSA encryption hardware from the 80s. All now completely broken. They are very impressed with some of the 512bit hardware! https://people.csail.mit.edu/rivest/pubs/pubs/Riv84.pdf reply tzs 3 hours agorootparentprev> Before you start worrying about it though consider that RSA has held up for 47 years of active cryptanalysis so far True, but is there much overlap between the set of people who actively do cryptanalyses on RSA and the set of people who actively research integer factoring? As far as I know the skills needed to make progress on integer factoring are not really needed for anything in cryptography other than that specific problem and include a bunch of other skills that have nothing whatsoever to do with cryptography and take a long time to master. It's also been an open and important problem long enough that if it is solved it is likely to be by someone who is a world class expert in it, similar to how Fermat's Last Theorem was finally solved. Similarly the skills needed for anything in cryptanalysis other than trying to break RSA by factoring are useless for working on integer factoring. The result is that very few, if any, people have the time and ability to become both cryptanalysts and world class integer factoring researchers. Thus I'd expect nearly all of the 47 years of active RSA cryptanalysis has been on finding and fixing the numerous mistakes that can be made when implementing RSA that allow it to be broken without factoring. I'd guess it is also similar with the P = NP problem. A solution to that has implications for cryptography but I doubt many cryptanalysts are working on the P = NP problem. Also maybe same for the Riemann hypothesis (I'm not sure if that one has implications for cryptography). reply raverbashing 6 hours agorootparentprevActually RSA has several \"gotchas\", so it is not that it has held up but people have managed to work around those gotchas into a working encryption system (Basically your data is not encrypted with RSA, you encrypt a secondary key, send it with RSA but the main encryption is AES see https://en.wikipedia.org/wiki/Transport_Layer_Security#Key_e... ) reply scrapheap 5 hours agorootparentThere's \"gotchas\" with every encryption scheme - in fact whenever TLS uses any Public Key encryption scheme it'll pair it with a Symmetric Key encryption scheme. So you could say that by your definition no Public Key encryption scheme has \"held up\" and they've all had to be worked round :) There are benefits to pairing the slower Public Key schemes with a Symmetric Key encryption scheme using a session key, as you get the benefits of an Public Key encryption scheme with the performance of a Symmetric Key encryption scheme. reply fharding 5 hours agorootparentprevKey exchange is done for speed (symmetric key crypto is way faster than public key) and forward secrecy. It’s not done because RSA is flawed per se. We use DH instead of e.g. ElGamal encryption for the same reasons. reply raverbashing 4 hours agorootparentYeah it's not so much of a flaw of RSA, but encrypting pure text with it for example is more complicated (and has more caveats with padding, etc) than just encrypting a fixed amount of bytes reply sk5t 5 hours agorootparentprevDon’t think this merits an “actually” - using a session key et al. is basic usage and does not bear on the strength of RSA itself. reply admax88qqq 3 hours agorootparentprevA lot of the RSA gotchas are due to trying to take implementation shortcuts either for convenience or speed. If you don’t choose your primes truly randomly for example. Using a secondary key and using RSA for the key share is not about avoiding RSA gotchas it’s just about performance. reply tommiegannert 10 hours agoparentprevI think this is where the move to elliptic curve comes in, and that seems well on its way. Both in signatures and handshakes (Diffie-Hellman). Perhaps it's not a one minute operation to DR, but I doubt everything would be open if RSA/DH was rendered insecure overnight. I know my SSH keys are a mixed bag right now. reply TheCondor 6 hours agorootparentArguably, we know a lot more about elliptical curves than prime number theory too. There have definitely been a lot more folks working on it. There are other algorithms, NIST has a post-quantum project. There are options, but it’s a lot more than having some algorithms, we need protocols and they are still a bit off. Prime factorization isn’t going to get easier or faster though. There might be another attack or approach to attacking, some other numerical break through that leads to faster rsa cracking might be found but it’s hard to imagine it being that practical. reply exe34 10 hours agorootparentprevdoes the move to elliptic crypto suggest that the people in the know expect prime factorisation to be broken soon? reply bjoli 6 hours agorootparentIf anything, ECC is probably easier to break with qc. Shor's algorithm works \"better\" for discrete logarithms than for prime factorisation. \"Better\" as in requiring a smaller quantum computer. Still way beyond what is available today. The reason for switching to ECC is speed and key size. The NSA recommends 3096bit rsa keys for 128 aes, but only 256 bit ecc keys for the same security against traditional attacks. They also went ahead and recommended 348bit keys for ecc, but I don't know if something like that is widely used anywhere. Curve448 is nice but slow. Curve41417 is fast but largely unused. reply Jach 9 hours agorootparentprevSince no one mentioned, a major reason to prefer elliptic curves is that you can get equivalent security for much smaller key sizes. reply eddd-ddde 1 hour agorootparentI remember when I generated my first EC key and added it to an SSH client. I was so surprised by the size of the key I spent some time researching if I had made a mistake. Honestly impressive. reply tommiegannert 9 hours agorootparentprevAnd the key consituents don't have to be prime. That use of heuristics has always scared me a bit. reply dspillett 7 hours agorootparentNit-pic: the key constituents only need to be co-prime rather than absolutely prime, though in practise this makes little or no difference. reply bluGill 6 hours agorootparentSo far as we know. It scares some people that maybe co-primes working might be a sign of some future attack. Nobody has been able to figure out how such an attack works, but considering RSA is defined for primes, that some non-prime numbers also work is scary. reply exe34 8 hours agorootparentprevnice thank you! reply staunton 10 hours agorootparentprevIt's to do with \"if we ever have big/good quantum computers, prime factorization is doable\" and with \"let's use the new shiny things\". On a related note, someone might discover some elliptic curve math tomorrow and your CPU can break all that stuff just as well... reply exe34 8 hours agorootparentso with my cynic hat on, maybe a bunch of people already have that and that's why we're being moved off the hard stuff. reply staunton 5 hours agorootparentThe NSA had the option to do something like that when they (via NIST) standardized DES. They chose to standardize a version that's secure against attacks that only they knew at the time, shorten the key length so they can still brute-force it if they really need to, and successfully kept the attack secret until researchers at a foreign university independently discovered it decades later. reply shakow 9 hours agorootparentprevSmaller key sizes and faster at a given level of security, PQ-safe (at least as far as we publically know). reply temporary_name 10 hours agorootparentprevhttps://en.wikipedia.org/wiki/Shor%27s_algorithm As soon as quantum computers have enough qbits prime factorisation can be done very quickly. Not sure the timeline on that as there are a lot of challenges in the technology and it is hideously expensive, but a lot of the move away from RSA to elliptic curves is driven by readiness for quantum computing. https://en.wikipedia.org/wiki/Post-quantum_cryptography reply kamov 10 hours agorootparentElliptic curve cryptography can be broken by Shor's algorithm as well https://arxiv.org/pdf/1706.06752 reply upofadown 7 hours agorootparent... and easier than with RSA. Not that it would make a significant difference. reply fragmede 10 hours agorootparentprevsgt101 posted a good comment about this a couple months back: https://news.ycombinator.com/item?id=40187560 tl;dr: not in our lifetime. reply neets 4 hours agoparentprevI always assumed in the Anime “Ghost in the Shell Stand Alone Complex” they used, “Barrier Mazes” rather than cryptography for a reason reply keepamovin 9 hours agoparentprevI guess one perspective is finding fast factoring is considered super rare. The story is so many smart people have looked at it, it's probably impossible...for now. But that story may be its own weakness. Anyway, the risk, while just as real as something like the grid being downed by a massive solar storm with multiyear recovery period from stone age due to transformer manufacturing delays and no stockpiles, just seems too minuscule/theoretical to spend much time on - from that point of view. Regarding any plan, I don't know if it's so easy to just switch to ECC, because actual asymmetric encryption with ECC depends on shared secret, which (if you're assuming an unsecured exchange channel due to RSA being broken), is more vulnerable to MITM than RSA. I don't think it's an easy swap out. All that aside, another point of view is RSA is probably already broken, the break is just secret to the codebreaking agencies. It would be very desirable for them to keep their breakthrough secret. That might even involve trying to find ways to suppress any \"sudden number theory breakthroughs\" hahaha! :) reply JackSlateur 10 hours agoparentprevThe world has moved away from RSA etc to elliptic curves. Not everybody did, through. RSA is no longer the standard, and has not been for many years. reply opyate 10 hours agorootparentStill, plenty of old stuff was scraped/sniffed under the \"store now, decrypt later\" methodology. reply milansuk 8 hours agorootparentTrue. The only solution is to keep your data outside cloud(aka someone else's computer) no matter what encryption you use. reply K0balt 6 hours agorootparentAlso means it can’t transit the internet. So actually, only on airgapped networks. reply 8372049 5 hours agorootparentIf we're going to extremes like that, airgapped networks aren't truly safe either reply mckn1ght 59 minutes agorootparentCould you explain why that is? If I have an airgapped smart home network, someone has to come physically sniff the packets. If it’s only over ethernet, they have to physically plug in. That’s not a scalable attack strategy. reply barelyauser 5 hours agorootparentprevAlso, the safest data is the one never sampled into digital format and stored in computer systems. reply jiggawatts 9 hours agorootparentprevYou can’t imagine how many places I’ve seen “Elliptic curve certificates are not supported” as recently as this year. It’s the IPv6 of the security world. reply upofadown 7 hours agorootparentThat's because certificates are all about authentication not encryption. There is no real reason to move away from RSA for authentication. The reason that TLS moved away from RSA for encryption is that it is awkward to do forward secrecy with RSA due to the slowness of generating new RSA keypairs. In practice you would want to generate a new RSA keypair every, say, hour on the server and then somehow get it down to the cryptography level for use. Totally doable, but a different way of doing things. reply devnull3 4 hours agoparentprevIf there is a such a breakthrough then the hackers or even spy agencies will not reveal it. They will instead silently make use of it. It will be essentially a backdoor for them. reply heyoni 4 hours agorootparentWouldn’t it likely originate from academia? If so you can bet that the work will be published just like this one. reply Retr0id 4 hours agorootparentIt's hard to know where things are today, but historically, public academia has often been behind the true cutting edge of cryptanalysis. For example, take a look at the history of Differential Cryptanalysis https://en.wikipedia.org/wiki/Differential_cryptanalysis > The discovery of differential cryptanalysis is generally attributed to Eli Biham and Adi Shamir in the late 1980s, who published a number of attacks against various block ciphers and hash functions, including a theoretical weakness in the Data Encryption Standard (DES). It was noted by Biham and Shamir that DES was surprisingly resistant to differential cryptanalysis, but small modifications to the algorithm would make it much more susceptible. > In 1994, a member of the original IBM DES team, Don Coppersmith, published a paper stating that differential cryptanalysis was known to IBM as early as 1974, and that defending against differential cryptanalysis had been a design goal. According to author Steven Levy, IBM had discovered differential cryptanalysis on its own, and the NSA was apparently well aware of the technique. reply heyoni 3 hours agorootparentThat is both impressive and disappointing. I'm so used to seeing large corporations publishing AI models and other techniques (like Ghidra) that I assumed a finding like that would be disseminated to the public. But you're right, something that could be used to decrypt modern ciphers could very well be kept secret for as long as possible. reply Retr0id 2 hours agorootparentGhidra was private for many years before it was public (I don't know precisely how many, I suppose that information is also private heh) Edit: Wikipedia mentions 1999, with v1.0 existing in 2003 https://en.wikipedia.org/wiki/Ghidra#History reply Retr0id 4 hours agorootparentprevIt depends on who makes the breakthrough. reply EvanAnderson 4 hours agorootparentprevSETEC ASTRONOMY reply zitterbewegung 5 hours agoparentprevMany people in the industry does not think that RSA is crackable due to the assumptions that the Riemann Hypothesis and also the distribution of prime numbers is such a hard problem with a long time of being unsolvable. A possible mitigation for things like websites would be either ECC or even using the quantum resistant encryption systems (the industry would more likely avoid this due to the systems being very prototypical since we have just started researching this). Since old bitcoin wallets can’t be moved off of RSA you can transfer the coins to your wallet and there is no mitigation. reply red_trumpet 5 hours agorootparentI don't see how proving the Riemann Hypothesis would help cracking RSA? If it helps, couldn't you just assume it is true and start cracking RSA today? If you ever hit a point where it doesn't work then BOOOM: Riemann Hypothesis disproven! reply tzs 2 hours agorootparentI think it is the other way around--disproving the RH might break some things. Most mathematicians believe RH is true, and generally when doing industrial number theory people operate under the assumption that RH is indeed true and so if they need to use X to justify something and there is a theorem of the form \"if RH is true then X\" they use X. Thus a proof of RH is not a problem. It just confirms that what people applying number theory already assumed was correct. A disproof means that those X's might not be true and their use would need to be reassessed. reply AnotherGoodName 3 hours agorootparentprevRSA was once 128bits and today has to be 2048bits minimum to be secure because it was essentially broken multiple times. There used to be 128bit rsa encrypting hardware that now doesn’t work at all to protect data due to previous mathematical breakthroughs. The congruence of squares equivalence to factorization demonstrated we need at least 500 bits and then the special number field seive that built on this push it to 1024. The general number field seive pushed it again to 2048. Sure it’s not a log(n) break but it’s been broken. If you look at the complexity analysis of the special vs general number field seive the portion of the exponent going from 1/2 to 1/3 should give you thought. Can it be moved to 1/4? Could it be moved indefinitely to 1/x? The general number field seive is relatively recent. If someone comes up with a similar breakthrough again (and this has happened many times over with rsa) your 2048bit keys won’t be secure just as your 128bit rsa keys from the past are no longer secure. reply golol 7 hours agoparentprevI think someone working in cryptography will worry about a sudden number theory breakthrough that allows for breaking of cryptography as much as a someone working in the energy sector will worry about a sudden physics breakthrough that allows for practically free energy cold fusion energy. reply igleria 7 hours agorootparentfree energy still needs to be distributed and solving free energy does not solve the balance of the grid. Dunno about Cryptographers. reply nobodyandproud 4 hours agoparentprevIIRC, Elliptic curve cryptography doesn’t rely on factorization, so there’s already an interim PKC solution in place. I also recall there were many problems with the ECC based algorithms or at least the implementations—something about discrete approximations weakening security? Far beyond my comprehension reply AnotherGoodName 4 hours agorootparentECC is very closely related though (hidden abelian subgroup problem is the category they both fall under). It’s actually concerning because rsa was broken. The reason we’re not using 128bit rsa keys anymore and instead using 2048bit keys is because rsa was broken by the general number field sieve. We’re now all using ecc to avoid working with very large keys but there’s no mathematical proofs that ecc is anymore difficult. In fact it’s widely believed to be the same problem underneath. That may surprise people. ECC, the thing we rely on, is not proven except by the fact that no one has broken it yet just like rsa was until someone broke it. reply k__ 4 hours agorootparentprevThere is also lattice-based cryptography. reply dhosek 4 hours agoparentprevI remember telling my high school students that if they found an efficient way to factor large numbers, they would destroy capitalism and a large number of them got very excited about number theory after that. reply dakiol 3 hours agoparentprevIsn’t this the same as zero-day vulnerabilities? Typically only a bunch of people out there know how to take advantage of such holes, and eventually they get fixed. I guess if public key cryptography gets broken, only a bunch of people would know how to take advantage of it, and eventually it would get fixed. reply shinycode 10 hours agoparentprevFrom what I remember in my math class where we made those cryptography calculations by hand, the teacher many years ago said that the day we could guess prime numbers it will be a disaster because many cryptographic calculations are based on the premise that we can’t guess prime numbers. I don’t know if that changed ? reply PeeMcGee 7 hours agorootparentIt's easy to find primes of a given bit length, and it's easy to multiply them together. It's hard to un-multiply a given number (public key) into its unique prime factors (private key). reply mbreese 7 hours agorootparentBut if we could more easily find primes, the search space for finding those prime factors would be significantly smaller. In my mind, it’s not a question of easy vs hard… it’s a question of fast vs slow. The default algorithm for finding primes is pretty simple, but it takes a lot of math and time. If you reduce the time requirements, then we start to get into trouble. reply atemerev 8 hours agoparentprevThe industry couldn’t even prepare for a bad Crowdstrike update. And yet, it figured things out in a few days or so. The ability to prepare for catastrophic scenarios is overestimated. The ability to survive them is underestimated. reply HeatrayEnjoyer 6 hours agorootparentCS was a software update. RSA is baked into many silicon circuits and firmware ROMs. reply atemerev 4 hours agorootparentWell, hardware is replaceable, too. reply robertlagrant 6 hours agorootparentprevThis would be a lot worse than that. Crowdstrike was bad because everyone lets relatively untested code straight into the Windows kernel - i.e. known incompetence of approach. This would be bad despite massive care taken to have the right approach. reply atemerev 6 hours agorootparentYes, except there is no “massive care”. If people are OK to install other companies’ rootkits to their critical infrastructure, they will not care about anything else, too. reply robertlagrant 1 hour agorootparentThe massive care is the algorithm selection process, the careful implementations, and the long-term observation and correction of the performance of the algorithm implementations. reply digging 3 hours agorootparentprev\"Some people did X\" !== \"All people do X\" reply thedangler 4 hours agoparentprevIf someone did find out how to do it, do you think they would make it public? reply apples_oranges 10 hours agoparentprevWe could always switch to symmeric keys (but key exchange would be somewhat problematic). Also elliptic curves crypto doesn't use primes, so even public key/private key crypto would still be around and secure. reply ertgbnm 5 hours agoparentprevPretty sure that it would require that P=NP if such an event happened. So if factorization was cracked, everything else would be too. reply cvoss 5 hours agorootparentInteger factorization is an NP problem but is not known to be NP-complete. Therefore, we do not know how to solve all NP problems in P time using a hypothetical P time factorization. P =? NP would remain open. reply amelius 5 hours agorootparentprevAre you sure about that? And even if problems can be solved in polynomial time, the constants involved can be prohibitively large. reply keepamovin 9 hours agoprevPeople always think the structure of primes is complex, but it's not really, it's just a recursive structure of the magnitude gaps not landed on by multiples of previous gaps. It doesn't make it easier to \"predict\" without tracking all prior gaps, but it's not essentially a complex structure. Kind of funny that like such a simple structure is so elusive. Sorta like how the 3n + 1 sequence gives rise to such complexity. Or the logistic map with its parameter above the threshold. reply novaRom 7 hours agoparentA generator of \"all primes\" is pretty simple and deterministic. But you cannot simply generate next prime given only prime n without recomputing its non-trivial remainders. That means just a binary representation of a number n doesn't provide enough information to make quick answer what is the next prime. You have to pre-compute some 'pivots' first. Basically, more complexity, but it's still simple and trivial, not even in NP. reply guhbkji 7 hours agorootparent> not even in NP This is incorrect. Integer factorization is NP-intermediate. Very much “in NP”. https://en.m.wikipedia.org/wiki/NP-intermediate Also, saying factorization lacks “complexity” because sieves exist misunderstands both concepts. > In order to talk about complexity classes such as P, NP, and co-NP, the problem has to be stated as a decision problem. > Decision problem (Integer factorization) — For every natural numbers n and k, does n have a factor smaller than k besides 1? > It is known to be in both NP and co-NP https://en.m.wikipedia.org/wiki/Integer_factorization#:~:tex.... reply seanhunter 5 hours agorootparentThat NPI wiki link says integer factorization may be in NP-intermediate iff NPI isn't an empty set, which is unknown at the current time. My understanding is the complexity of factorization is also currently an unsolved problem although no polynomial time algorithm is currently known. Eg https://www.connellybarnes.com/documents/factoring.pdf \"Finally, in computational complexity theory, it is unknown whether factoring is in the complexity class P. In technical terms, this means that there is no known algorithm for answering the question \"Does integer N have a factor less than integer s?\" in a number of steps that is ))(( nPO , where n is the number of digits in N, and P(n) is a polynomial function. Moreover, no one has proved that such an algorithm exists, or does not exist.\" That is supported by the second wiki link you provide, which has \"Unsolved problem in computer science: Can integer factorization be solved in polynomial time on a classical computer?\" in a box at the side. https://en.m.wikipedia.org/w/index.php?title=Integer_factori... reply guhbkji 4 hours agorootparentYou are conflating. Integer factorization is unsolved and it’s decision problem is in NP. IF’s decision problem’s complexity “may be in NP” because the question of whether P equalling NP is unknown. Meaning IF is NP, but may well be P if P=NP. If P!=NP then IF is NP. reply klyrs 2 hours agorootparentNo, IF is unquestionably in NP. The definition of NP is that a purported solution can be checked in polynomial time. That's it. Factorization can be verified by multiplication, in polynomial time, therefore the problem is in NP. Perhaps you're confounding NP with NPC? Recall that P is a subset of NP. Not sure what you mean by \"IF's decision problem\" though. Primality is in P. reply keepamovin 6 hours agorootparentprev> Integer factorization is NP-intermediate People backing up math with wikipedia links is never a good look. Particularly when those references contradict the points they seemed they were trying to make: Since it is also true that if NPI problems exist, then P ≠ NP, it follows that P = NP if and only if NPI is empty.[your NPI reference] So... if you've shown FACTORING is NPI then you've proven P ≠ NP, I guess, too? Hahaha! :) reply lmpdev 9 hours agoparentprevAh yes nothing simpler than providing the foundational theory to one of the most rigorous and intellectually intimidating areas of mathematics - number theory /s reply odyssey7 9 hours agorootparentThey’ve got the fundamental theorem of arithmetic. What more could they want? reply keepamovin 8 hours agorootparentI think that misses the point which is that the simplicity is overlooked in the common descriptions of primes as \"random\" or a great \"mystery\". reply odyssey7 8 hours agorootparentYes, it’s difficult to predict where such an understanding might lead. If it reframes and redefines all of number theory, then we might call it one component of the foundational theory of number theory. Analogously, if someone proves that P = NP, then that will be great, but the significance of lambda calculus and Turing completeness will remain. If the proof is constructive and practical, we’ll just have to reprioritize and update the list of algorithms we teach to undergrads, issue performance-enhancement updates to some software libraries, and patch any security vulnerabilities. Otherwise, we’ll only need to change a chapter or two in the Theory of Computation courses that universities are increasingly deprioritizing. reply guhbkji 7 hours agorootparent> if someone proves that P = NP > we’ll just have to reprioritize and update the list of algorithms we teach to undergrads, issue performance-enhancement updates to some software libraries, and patch any security vulnerabilities. Wow, your optimism sure is something. What are you patching and with what? How do you “patch any security vulnerabilities” when said vulnerability is “all of our security research, except one time pad, is now so obsolete we are unsure if security based on computational complexity is at all practical anymore”? reply keepamovin 8 hours agorootparentprevNah, it's not that complex. Did you ever take introductory number theory? Anyway, I think you missed the point that the description is really simple, and overlooked. Hahaha! :) reply zxcb1 6 hours agoparentprevWhy isn't this considered a solved problem? https://en.wikipedia.org/wiki/Information_theory https://en.wikipedia.org/wiki/Computational_irreducibility https://en.wikipedia.org/wiki/Aperiodic_tiling reply sameoldtune 3 hours agorootparentI don’t understand how your links relate to primality. reply zxcb1 19 minutes agorootparentAsk AI https://x.com/stephen_wolfram/status/1762286847567495414 reply timmb 7 hours agoprevSomething inspiring about this: \"In dedicated Friday afternoon thinking sessions, he returned to the problem again and again over the past decade, to no avail.\" reply eismcc 6 hours agoparentI recall that Richard Hamming used to also reserve Friday afternoons to deep/big thinking. Sounds wonderful. reply hennell 4 hours agorootparentFriend of mine worked used to block off his friday afternoons for 'weekly review'. Which was part big thinking, part end of week nap, and mostly avoiding colleagues who had tricky tasks 'needed first thing monday' they had forgotten to bring up before. reply huyvanbin 2 hours agoprev> “At first sight, they look pretty random,” says James Maynard, a mathematician at the University of Oxford. “But actually, there’s believed to be this hidden structure within the prime numbers.” What would the pattern of primes hypothetically look like? Is there expected to be some kind of closed form formula? If the Riemann hypothesis were proven, what would be the next step to understanding the distribution? Or is the proof itself expected to hold this answer? reply testaccount135 9 hours agoprev\"they pulled some unorthodox moves to finally break Ingham’s bound\" Why is taking methods from other fields an unorthodox move? I come from an engineering background an there it is the common case. The usage of harmonic analysis is a staple in many fields (audio, waves, electrical analysis, statistics) and of course the algorithms are pure math under the hood. If I want to find a reaccuring structure in an underlying system, wouldn't it be normal to try different plotting techniques and choose the one that suits my problem best? reply gavagai691 3 hours agoparent\"Save for Maynard, a 37-year-old virtuoso who specializes in analytic number theory, for which he won the 2022 Fields Medal—math’s most prestigious award. In dedicated Friday afternoon thinking sessions, he returned to the problem again and again over the past decade, to no avail. At an American Mathematical Society meeting in 2020, he enlisted the help of Guth, who specializes in a technique known as harmonic analysis, which draws from ideas in physics for separating sounds into their constituent notes. Guth also sat with the problem for a few years. Just before giving up, he and Maynard hit a break. Borrowing tactics from their respective mathematical dialects and exchanging ideas late into the night over an email chain, they pulled some unorthodox moves to finally break Ingham’s bound.\" This quote doesn't suggest that the only thing unorthodox about their approach was using some ideas from harmonic analysis. There's nothing remotely new about using harmonic analysis in number theory. 1. I would say the key idea in a first course in analytic number theory (and the key idea in Riemann's famous 1859 paper) is \"harmonic analysis\" (and this is no coincidence because Riemann was a pioneer in this area). See: https://old.reddit.com/r/math/comments/16bh3mi/what_is_the_b.... 2. The hottest \"big thing\" in number theory right now is essentially \"high dimensional\" harmonic analysis on number fields https://en.wikipedia.org/wiki/Automorphic_form, https://en.wikipedia.org/wiki/Langlands_program. The 1-D case that the Langlands program is trying to generalize is https://en.wikipedia.org/wiki/Tate%27s_thesis, also called \"Fourier analysis on number fields,\" one of the most important ideas in number theory in the 20th century. 3. One of the citations in the Guth Maynard paper is the following 1994 book: H. Montgomery, Ten Lectures On The Interface Between Analytic Number Theory And Harmonic Analysis, No. 84. American Mathematical Soc., 1994. There was already enough interface in 1994 for ten lectures, and judging by the number of citations of that book (I've cited it myself in over half of my papers), much more interface than just that! What's surprising isn't that they used harmonic analysis at all, but where in particular they applied harmonic analysis and how (which are genuinely impossible to communicate to a popular audience, so I don't fault the author at all). To me your comment sounds a bit like saying \"why is it surprising to make a connection.\" Well, breakthroughs are often the result of novel connections, and breakthroughs do happen every now and then, but that doesn't make the novel connections not surprising! reply remus 9 hours agoparentprevUnorthodox is maybe a bit strong, but what they're saying is that it's a novel application of an existing technique from another field. Fairly often you will see big breakthroughs like this in maths, where someone has the insight to see that there are parallels between two seemingly unconnected areas of maths, and you can use ideas from one area to give you insight in to the other area. The tricky bit is that these connections between areas are not usually obvious, so to see the similarity can require a considerable step in understanding. reply sameoldtune 3 hours agoparentprevIt’s kind of silly. Just a reporter reporting. You could say that every discovery in mathematics involves some “unorthodox” move, since the orthodoxy is all that is known so far. reply hyperbolablabla 7 hours agoprevEvery time I hear about James Maynard it really solidifies my opinion that he's one of those once in a generation geniuses. He's already contributed so much to prime number theory, it really feels like there might be a proof of the Riemann Hypothesis within my lifetime. reply markjspivey 1 hour agoprev\"analyze this for hidden underlying structure or emergent properties\" https://chatgpt.com/api/content/file-HFFSXBEAtdR1fbum5ZCElog... reply Aachen 1 hour agoparent\"missing or invalid access token\" reply wood_spirit 10 hours agoprevI’m curious as I hadn’t seen it before and it’s gripping: Is the patterns showing in a polar plot of the prime numbers a recent discovery or is it long known and just used as an illustration? What is it called and what is its history? reply zimpenfish 9 hours agoparentNumberphile[1] and 3b1b[2] (with a particularly good explanation of why it happens) have done good videos on the prime spiral. [1] https://www.youtube.com/watch?v=iFuR97YcSLM [2] https://www.youtube.com/watch?v=EK32jo7i5LQ reply taneliv 10 hours agoparentprevhttps://en.wikipedia.org/wiki/Ulam_spiral for more reading, Sacks spiral is from 1994. reply thom 10 hours agoprevI’m both a layman and a simpleton, but seeing Guth’s comments, surely it can’t be a new idea that the fundamental interpretation of primes is something to do with waves and harmonics? reply impendia 4 hours agoparentAnalytic number theorist here -- \"Fundamental interpretation of primes\" is a bit much, but this has been understood for a long time. The short version of the story is - The primes are closely related to the Riemann zeta function, which is more-or-less cobbled out of them; - The Riemann zeta function has a lot more symmetry than one might initially expect, and harmonic analysis is how you prove this; - The (still unproved) Riemann Hypothesis is that the zeta function has still more symmetry beyond what we've been able to prove. reply fredgrott 8 hours agoprevIf you plot the Gauss and Riemann curves in a specific space you see something more magical.... To see what I am talking about as in trivial and non-trivial zeros see this wikipedia animation https://en.wikipedia.org/wiki/File:Riemann3d_Re_0.1_to_0.9_I... Basically, it implies that there is another relationship between real and imaginary numbers we have not yet stumbled upon.... And,this has implications upon finding the gravity theory as Riemann math is involved in quantum mechanics.... Strange science that primes is or might be involved in gravity theory.... reply RIMR 2 hours agoprevHow is this any different from Sach's original work from 2003? https://naturalnumbers.org/sparticle.html The organized patterns of primes and composites was an understood feature of the Sack's Spiral since the day he published his findings online. reply gxs 2 hours agoprevReminds me of a story where some egghead friend of mine had a friend that was a researcher at a state school in California. In his research, he found something like getting unenriched uranium to react (please excuse my complete lack of familiarity with the subject). Apparently some government agency stepped in, classified his research and asked him to start. Makes me where else this might have happened - there must be some interesting stuff out there. reply igtztorrero 4 hours agoprev3 years ago, somebody post on HN, an animation about prime numbers, it was beautiful looking how prime numbers show a pattern, it looks like the image in this article reply nyc111 9 hours agoprev“This left a small but unsettling possibility that many zeros could be hiding out right at three-quarters.” Ok, but if zeros there are found some mathematicians may as well call them “trivial zeros.” Can there be an objection to that? reply 10 hours agoprevnext [2 more] [dead] xanderlewis 10 hours agoparentBegone, LLM slop. reply codeduck 9 hours agoprevnext [6 more] [flagged] seanhunter 9 hours agoparentThat this subject [imaginary numbers] has hitherto been surrounded by mysterious obscurity, is to be attributed largely to an ill adapted notation. If, for example, +1, -1, and the square root of -1 had been called direct, inverse and lateral units, instead of positive, negative and imaginary (or even impossible), such an obscurity would have been out of the question. - Gauss reply trashtester 8 hours agorootparentI think Geometric Algebra [1] provide a more natural approach to \"imaginary\" numbers than Gauss does above. Not only does these algebras give a more intutive understanding of \"imaginary\" numbers as rotation in a plane (and not simply an alternative R2). They also extend nicely into all sorts of applications in Physics, Machine learning, etc where Lie groups are needed. And there is nothing preventing us from defining e1*e2 as i, and use the regular notation for Complex Analysis where the Group Theory aspects are not needed. [1] https://www.youtube.com/watch?v=PNlgMPzj-7Q reply g15jv2dp 8 hours agoparentprevInstead of expressing your knowledge and superiority by metaphorically rolling your eyes without contributing anything, how about you give a better explanation? Because honestly, I find these two kind-of \"okay\". And because this is HN, based on past experience, I need to preface with the fact that I'm a professor of math. So no need to start by questioning my knowledge on the topic, just get straight to the point. reply codeduck 7 hours agorootparent> So no need to start by questioning my knowledge on the topic, just get straight to the point. Undergrad physics, so you are obviously more versed in the field than I am. But, speaking as someone with some small background in this, I would hope that an article on 'science.org' that mentions Gauss and Riemann would go into slightly more detail than i = sqrt(-1). Even a two-liner description of the real and imaginary plane would be an improvement and would possibly motivate people who knew very little about the area into going and researching. The entire article is about possible periodicity in prime numbers - why, then, omit one of the most important things about complex numbers and their relationship to periodic systems? Euler's formula is a beautiful thing, and I say that as a luddite. And as for the harmonic analsys as \"something in physics used to separate sounds and their notes\" - I mean... that's like saying \"Moby Dick\" is a book about a whale. Yes, it's technically correct, but there is such a lost opportunity to describe just how all-encompassing Fourier Analysis is and how it naturally ties back to the complex numbers mentioned previously. So, as demanded, here: For inputs, the function takes complex numbers, which are two-dimensional numbers with one coordinate on the real number plane and the other on the so-called \"imaginary\" plane. Complex numbers are fundamental to the description of many periodic systems such as waves, cycles, orbits etc. harmonic analysis, which is a discipline that originated as the study of the composition of sound but was extended by mathematicians like Taylor and Fourier into a broad system of numerical analysis that is widely used in everything from number theory to neuroscience. It would have taken very little additional effort, but the results would be rather different - showing paths forward rather than walls saying \"this is all that there is to this\". reply ZoomZoomZoom 7 hours agorootparentThe definitions given do not advance the explanation of the topic of TFA one bit but just boggle down the reader with irrelevant details. It's already not easy to digest by a casual reader, why make it harder for them? Just the mention of a \"two-dimensional number\" is already an utter fail, everybody knows you need two numbers for a 2D coordinate. reply xpil 9 hours agoprevJust use 42 everywhere reply NiloCK 5 hours agoprev [–] I've been fascinated by this question since I learned the sieve of eratosthenes as a kid. The meta logic of it is so simple: Primes are specifically the numbers that are left over after the structured numbers (composite) ones are removed. Everything - [structured numbers] = [ chaos? the abyss? some meta structure? ] reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "A recent breakthrough in prime number theory has generated significant interest, with notable mathematicians like Terence Tao discussing its implications.",
      "The breakthrough involves new bounds on large values in Dirichlet's theorem, presented by James Maynard and Larry Guth, which could have long-term impacts on number theory research.",
      "The discovery has sparked discussions about its potential effects on cryptography, particularly concerning the security of RSA encryption and the industry's preparedness for such theoretical advancements."
    ],
    "points": 286,
    "commentCount": 124,
    "retryCount": 0,
    "time": 1722497670
  },
  {
    "id": 41122920,
    "title": "Foobar2000",
    "originLink": "https://www.foobar2000.org/",
    "originBody": "Overview Download Mac Mobile Components Screenshots Support SDK foobar2000 is an advanced freeware audio player for the Windows platform. Latest news 2024-05-21 New releases of old versions! Some of latest bug fixes have been backported to foobar2000 v1.5 and v1.6 series. Versions 1.6.18 and 1.5.12 can be downloaded from old versions page. Additionally, version 1.5.12 was properly tested on old hardware; unintended SSE CPU requirement present in previous releases has been removed. 2024-05-20 foobar2000 mobile v1.5 has been released. This version introduces new skin file format which can be edited using commonly available tools. Download Android APK... 2023-12-18 foobar2000 v2.1 final has been released. Download... foobar2000 for Mac v2.6 final has also been released. Download foobar2000 for Mac... View all news advertisement dBpoweramp mp3 Converter music conversion perfected Trusted by 30 million people, easy conversion between audio formats PerfectTUNES a helping hand for your audio collection Add or upgrade Album Art, De-Dup and check for ripping errors dBpoweramp CD Ripper CD ripping taken seriously Secure Ripping from the inventors of AccurateRip, fast & bit-perfect CD ripping Main features Supported audio formats: MP3, MP4, AAC, CD Audio, WMA, Vorbis, Opus, FLAC, WavPack, WAV, AIFF, Musepack, Speex, AU, SND... and more with additional components. Gapless playback. Easily customizable user interface layout. Advanced tagging capabilities. Support for ripping Audio CDs as well as transcoding all supported audio formats using the Converter component. Full ReplayGain support. Customizable keyboard shortcuts. Open component architecture allowing third-party developers to extend functionality of the player.",
    "commentLink": "https://news.ycombinator.com/item?id=41122920",
    "commentBody": "Foobar2000 (foobar2000.org)260 points by citruscomputing 22 hours agohidepastfavorite170 comments imiric 22 hours agoIt's great to see that fb2k is still around and well :) It's remarkable how they've kept the same UI since its inception, 21 years ago. It was clean, simple and intuitive back then, and still is today. Same goes for the website, now that I think of it. A true testament that simplicity trumps trend-chasing. It was my main music player after Winamp released the awful version 3.0, and I never looked back. I don't use Windows much these days, but mpv serves me well as a barebones audio player, and occasionally I do use Quod Libet on Linux, which has similar design sensibilities as fb2k. reply rchaud 3 hours agoparent> It's remarkable how they've kept the same UI since its inception, 21 years ago. Easy to do when you don't have bosses breathing down your neck about adding in podcasts and audiobooks, then nudging users into engaging with that stuff first so that they don't have to pay as much to the music rights holders. reply raxxorraxor 3 hours agoparentprevIt also just has superior functionality. Want to mirror your front channels to your back channels? Easily done in foobar2k, while many other media players already fail here, even those whose main task is to do audio output. reply qwerty456127 21 hours agoparentprevDespite somehow liking WinAmp 2 more than WinAmp 3, I could never understand why do people consider WinAMP 3 awful. Nevertheless I just switched to foobar2000 on Windows and DeaDBeeF on Linux because their UIs just are perfectly bullshit-free practical pragmatic tools and I came to feel I want a tool rather than a show. reply themerone 21 hours agorootparentWinAmp 3 was bloated, slow, and unstable. It was bad enough that they threw out the code and released WinAmp 5 which was based on the code from WinAmp 2. reply donatj 20 hours agorootparentYep, Wasabi, the XML driven UI toolkit was just too slow for PC's of the time. reply a0123 20 hours agorootparentprevPeople got used to a fairly simple and efficient UI. Version 3 was a bit of an abrupt change. A bit like today when your favourite social network completely revamps its UI for no apparent reason and makes it look fancier without adding any interesting functionality (and usually removes a couple). It's hard to come back from that. reply rchaud 3 hours agorootparentprevWinamp 3 with its default \"Modern\" skin was very sluggish, even on decently specced computers in 2003. If you replaced the default with a Winamp classic skin, it immediately sped up, but defaults are powerful, so most users probably left it as is. reply rightbyte 5 hours agorootparentprevI guess you might wonder the same thing if installing Windows Vista on a recentish computer. reply serf 15 hours agorootparentprev>Despite somehow liking WinAmp 2 more than WinAmp 3, I could never understand why do people consider WinAMP 3 awful variety of reasons. mine: it broke a huge amount of visualizers/dsps/skins. reply a0123 20 hours agoparentprevA remnant of simpler times. Foobar and VLC, any other software that has always worked and remained pretty much the same? reply imiric 14 hours agorootparent> A remnant of simpler times. I think it has more to do with the authors and their principles, and less with the times. There are plenty of counterexamples from that era: all major browsers, the Sonique audio player (which I loved for the UI novelty), Winamp itself, etc. > any other software that has always worked and remained pretty much the same? mpv is in that league for me, and it's much more recent. Then, of course, there are very stable CLI and power user software that has existed for decades: Vim, Emacs, BSD and Linux coreutils, etc. Some of these are not necessarily simple under the hood, but I use them because they do one thing well (or in the case of Vim/Emacs as much as I want them to do :)), and I know that they're not going to disappear or drastically change as so many software does. reply The_Colonel 14 hours agorootparentprev\"simpler\" is not how I remember foobar2000. I used to use it (±15 years ago) because of its extreme configurability (e.g. in terms of layout). Configuring foobar2000 felt kind of like building your own music player. YMMV reply piaste 5 hours agorootparentI remember installing some VERY pretty but very complicated setups from deviantart, and then having to fix the inevitable bugs in the panel layout scripts, every one of which was just one right-click away which was extremely cool. IIRC, they were in a sort of PHP-looking scripting language? I had very little coding experience before then, so it was kind of a trip trying to debug why the lyrics panel would freak out under certain scenarios :D reply totetsu 14 hours agorootparentprevI started using it again recently and was struck by just how much config I had to do to get it back as I remembered it. It is both annoying and amazing reply defrost 14 hours agorootparentprevSimple to use, with a smart editable layout configuration for those that chose to go down that rabbit hole. I'm still using it to this day, with little more than an album tree, a playlist window, and an album art thumbnail that optionally all fold away. I've been down the configurationplugin trail, good fun for those of us that enjoy that kind of thing but it iswas simple and clean from a fresh install. reply orthoxerox 11 hours agorootparentprevIrfanView. I tried replacing it several times with something slicker-looking, but no other picture viewer is as fast as IrfanView. reply RunSet 5 hours agorootparentI thought \"I doubt it is faster than FastStone\" but when I went looking for benchmarks all I could find was this forum post from 2011. https://www.donationcoder.com/forum/index.php?topic=25334.0 Which does confirm that Faststone is faster but much water has passed under the bridge since 2011. reply orthoxerox 5 hours agorootparentThat's an interesting benchmark, but I am more interested in a cold start test on a much smaller file (think 2MP, not 1200MP), because that's my usual use case. reply RunSet 5 hours agorootparentI agree. That is another problem with the benchmark- it gives the gold medal to ACDsee, which in my experience has the longest cold start of the three. reply zecg 4 hours agorootparentprevThe batch editing is also handy reply potamic 9 hours agorootparentprevAnyone knows what they do different to achieve such speed? reply tvshtr 19 hours agorootparentprevVLC is getting a a major UI overhaul, it's pretty much finished actually and should be released soon. reply jolj 14 hours agorootparentprevTotal Commander reply freep1zza 11 hours agorootparentprevmIRC reply signaru 19 hours agoparentprevI use Audacious on Ubuntu as I can almost get the same UI configuration as foobar2000, tabs of playlists which can be made on the fly or from saved files. A music player app is something I always use on the background, so all the fancy visualizations or album art are not so useful for me. It's also sad that the default music player on Ubuntu (Mate) doesn't have a volume control out of the box. reply DidYaWipe 5 hours agoparentprevFoobar2000 was always better than WinAmp. WinAmp was the best example of why standard UI affordances evolved. reply rchaud 3 hours agorootparentNo, Winamp was the last example of broadly used \"appliance\" software that wasn't inextricably tied into a megacorp's business model. iTunes and Windows Media Player were both bloated because of the e-store baked into the back end. reply mostlysimilar 4 hours agorootparentprevDisagree. Winamp skins are the highlight of a better era of computer interfaces. reply codr7 21 hours agoparentprevre: Quod Libet; thank you, these kinds of recommendations are invaluable for finding good tools. Especially these days with all the noise. reply out_of_protocol 21 hours agoparentprev> the same UI Haha, it's not the same even for any specific version. With plugins and ability to move panels around, it's hard to say all these UIs are the same player. Search for \"foobar2000 theme\" in google images reply zokier 20 hours agoprevThere is certainly something intangibly attractive on this era and style of software. On top of my head I'm thinking fb2k, mpc (and its forks), virtualdub, utorrent (the original 1.x series), irfanview, kerio firewall (classic 2.x series), putty, even maybe mirc and notepad++ to some degree. Small programs, classic Windows style controls, emphasis on staying out of your way, somewhat minimalistic and barebones but still remarkably powerful and capable. These to me represent the golden age of Windows. Of all these programs (and there were many), fb2k is the one that I still use on regular basis while almost all the others have faded away. reply philistine 4 hours agoparentSeeing this from the outside, I can't shake the idea that Microsoft's complete fumbling of offerings for UI development is to blame. There are so many new paradigms in user interface on Windows that led nowhere, are completely inadequate for modern development, and yet are still supported by Microsoft. The company has lost the plot, and we're left with Microsoft even devolving into web apps for the desktop, with the success story of VS Code leading the charge. If Microsoft could find one good path forward for UI development on Windows, we'd want those small boutique apps to get with the times. reply iotku 10 hours agoparentprevI feel like (with no research) these interfaces were designed by programmers first and foremost and have a tight coupling to the actual underlying code. A \"well designed\" interface with \"good\" UI/UX from a proper designer may have best practices, but additional layers of abstraction from the functionality which makes everything feel less direct. reply skydhash 4 hours agorootparentI think (with no research) that people were more respectful of HCI guides. And even skeuomorphic is hard to do well, it’s more grounded in terms of UX. Buttons were actually buttons and icons were more understandable. Now, design is an abstract art challenge. reply deathanatos 22 hours agoprevOne of the great music players out there. Clean, simple UI. Easy to use. Supported far more formats than anything mainstream. Replaygain was a killer feature, and it mostly boggles my mind that it still isn't widespread, (…like non-broken, i.e., dB, volume knobs). reply athoscouto 22 hours agoprevWow, that brings back memories! foobar2000 was my go to player. I used to spend hours curating all my folders with albums and playlists. Funny how fast I switched to a streaming platform when they became widely available around here. reply nickjj 22 hours agoparent> foobar2000 was my go to player It is still my go to player, it works great in Windows 10. reply conductor 22 hours agorootparentAnd it has iOS/Android versions too, which is great if you still prefer file-based players: https://www.foobar2000.org/mobile reply bcraven 11 hours agorootparentI can recommend Blackplayer to fill that niche in a more modern (yet still simplistic) way. I don't see it mentioned much but it is regularly updated and extremely feature-dense. reply ents 22 hours agorootparentprevIt's my go-to in macOS 14.5 as well. I tolerate using Spotify as a player for it's library. A plain list is all I actually want 99% of the time. reply athoscouto 22 hours agorootparentprevI haven't consumed audio and video from files for a while now. Streaming has become so convenient (partly because of internet prices and availability) that I don't see myself coming back. reply lproven 9 hours agorootparentI hear this a lot. I find it always leaves me bemused. The main time I want music is at times when I can't stream: for instance, when travelling, especially when on planes. I specifically want my own music for when I don't have internet. When I do have internet, I mostly listen to digital radio. I have no streaming accounts with anyone, except free accounts. I do not have any payment method set up on my Apple account, and I never have in the ~28 years I had the account. I don't pay for wifi or other additional connectivity, either. I keep a local library of MP3s on my phones, and videos on my set-top computer. I use Foobar for music on my phone, and VLC for video on my STB. It's a bit odd to me that what was hi-tech is now almost Luddite in its refusal of novelty. I really don't see how paying subscriptions for access to stuff that I don't own is any kind of improvement. reply skydhash 4 hours agorootparentIt can be great for checking out stuff, like a membership to some club or a library. As soon as I find something I like, I need it to be locally so I can listen without tracking and possible interference by third-parties. And browsing a curated collection is calmer than searching in those apps. reply lproven 4 hours agorootparentSure, but a free Spotify or Youtube account lets me do that no problem. No need to pay for anything, no need for Apple Music or whatever. reply voxic11 3 hours agorootparentprevHow do you even buy music these days? I know of Bandcamp but its kind of limited in the selection. reply lproven 3 hours agorootparentWell, anachronistic as it may seem, I buy physical media, and rip them. I know it sounds very 20th century, but it works, you really own the stuff in an irrevocable sort of way, and second-hand CDs and DVDs are really cheap these days. I fill about 75% of a 128GB SD card with MP3s. I like paper books, too. I have many thousands of them. reply voxic11 3 hours agorootparentprevHow do you even buy music these days? reply dailykoder 22 hours agorootparentprevThere are times when songs from streaming platforms go away or I get somehow reminded of one very old song from some unknown band that's still somewhere on my hard disk, that I think about going back. I love to have all my songs in one single playlist and then just have them on random. I remember having that from my saved files and then some of those very rare songs come up every now and then. It feels somewhat magical. There are a handful of songs that barely any people know, but they trigger some very nice memories. I think soon (tm) I'll go back. Yes, streaming is convenient, but the algorithm is just unable to recommend me such rare treasures reply Geezus_42 22 hours agorootparentHey, I'm a \"one giant playlist on shuffle\" person too! :D reply skydhash 4 hours agoparentprevStreaming is convenient but their interface is not the greatest for curation and focus listening. Especially with their “lots of whitespace” design. There’s a reason we have list and tables in managers like itunes, calibre and file explorers. I tried adding my favorite albums to Apple Music and it quickly became untenable. Spotify is also awful for that. I have ~500 albums in my main library and various series and collection and it’s a breeze to manage, browse and listen with MPD, MOC, beets, Kid3 and the file explorer. reply dang 21 hours agoprevRelated: Foobar2000 v2.0 Released - https://news.ycombinator.com/item?id=35718802 - April 2023 (2 comments) Foobar2000 - https://news.ycombinator.com/item?id=30054239 - Jan 2022 (215 comments) Foobar2000 - the ultimate audio player - https://news.ycombinator.com/item?id=1305796 - April 2010 (2 comments) reply tryauuum 22 hours agoprevIt's kind of strange I have never seen any other player where you can just click on a folder and play music from it. Like two clicks, one on a folder (which loads the list of tracks) and second to start playing this list of course it's doable in any player but not with such ease reply ZoomZoomZoom 21 hours agoparentBefore foobar2k there was an outstanding player named Apollo[1] with almost a perfect UI: basically, just a playlist grid. It supported associating with directories, of course, so playback was also two clicks away. Just checked, it still works great, although, the limited codec support and no scrobbling is a dealbreaker for me. Same reason I had to ditch it years ago. Would love to peek at the source code of that program. One of the last messages its developer Heikki Ylinen left on his website reads: If you want to know what the future of digital music looks like, I recommend giving Spotify a go. And before anyone says anything, I know it has been done before, but this time it looks like it's been done right. And this is just the beginning. Pretty ironic. [1] https://www.rarewares.org/rrw/apollo.php reply ClueslessTech99 1 hour agoparentprevI was looking for a player that had this functionality when I switched to Linux. Finally settled on Clementine which has both a library & \"file browser\" mode. In the browser mode you can just right click and add the folder to your playlist. Just like in foobar2000. reply AdmiralAsshat 22 hours agoparentprevMy workflow of playing music for about 20 years was right-clicking on a folder in Windows Explorer and selecting \"Play in Winamp\" from the context menu. reply skydhash 4 hours agoparentprevOn MacOS, I used IINA for that. You drag a folder and it plays it, switching by default to Music Mode if it’s audio files.. reply haunter 21 hours agoparentprev>I have never seen any other player where you can just click on a folder and play music from it. VLC. Right click on folder > Play with VLC media player reply haspok 7 hours agoparentprevDeadbeef does exactly this. It is more minimalistic / gets more out of your way, so I love it! reply The_Colonel 14 hours agoparentprevI used to use 1by1 for this. It's a very minimalistic music player (200 KiB) doing exactly this. reply tmcdos 5 hours agorootparentI still use 1by1, more than 15 years. reply enthdegree 21 hours agoprevThe author on why Foobar2000 is not open source: https://hydrogenaud.io/index.php/topic,31222.msg270982.html#... reply fluoridation 21 hours agoparent>The SDK is there to allow people to add whatever features they want. If there is something they can't add with what the SDK provides, then either it requires changes breaking component compatibility (which only I could do even if the source was open), or person trying to implement the feature is doing something seriously wrong (happens very often). \"Implementing that feature would break component compatibility\" is not a valid reason not to release the source. If someone wants to modify the software to implement a feature they want even if it would break compatibility, that's their business. >As for porting to different OSes, sourcecode release won't magically spawn people capable of doing that properly. Somehow no one has written fully functional foobar2000 clone yet. The point of having it open source is that the possibility is there. Right now it's impossible. Someone has to go through the trouble of documenting all the features and then reimplementing them. >Sourcecode loss argument is not really valid, I keep backups on multiple redundant devices. I'd be surprised if someone who spent as much time on programming as I have wouldn't know well enough how to handle this. Two words: bus factor. I see attempts to refute reasons to open source the code, but no reasons not to do it. If the reason is simply \"I don't want to\", that's perfectly fine, and it's all that needs to be said. reply The_Colonel 14 hours agorootparentI think people like this strive for control. Their projects are like their little kingdoms where they have the last say. You might say that they can still retain such total control even in an open source project (OSS doesn't necessarily imply \"democracy\"), but there's still a possibility of a vim/neovim-like split. Bram was also quite opinionated, which led some developers to fork vim. Bram was very clearly quite unhappy about the split in the community, and keeping sources closed will prevent such a scenario. reply beart 20 hours agorootparentprevThe maintainers of foobar have always been very opinionated, for better or worse. I recall it pushed away a chunk of the community at least once in the past. It's just one of those types of projects. reply shiroiushi 11 hours agorootparentIt seems like those types of projects are fairly common in Windows-land, but not at all for other OSes. reply Anthony-G 8 hours agorootparentI’m not so sure about that. As a GNU/Linux user, I don’t think Windows-land has anyone who can cause as much community division as Lennart Poettering did (does?). reply RunSet 5 hours agorootparentprev> Somehow no one has written fully functional foobar2000 clone yet. Deadbeef [0] may not be \"fully functional\" because it doesn't support foobar2000 plugins or some such silliness but it is close enough to play the music library I played under Windows with foobar2000. Sometimes you just have to build over a Zax [1]. [0] https://en.wikipedia.org/wiki/DeaDBeeF [1] https://i.postimg.cc/YS1syndT/image.png reply npteljes 7 hours agoparentprevAll of the listed reasons are humbug, as someone in that threads points it out. The only real reason is that the author wants it so, and that's why it happens. No particular reason or supporting argument is stronger than this will alone. By the way, I haven't seen the author in that thread, just other commenters. Here, however, he addresses the open sourcing idea: https://hydrogenaud.io/index.php/topic,119676.0.html reply Teslazar 16 hours agoprevI'm surprised that AIMP hasn't been mentioned yet. It's also a great old school audio player that was released back in 2006. I transitioned to it when Winamp development was fizzling out. Not sure when that was but I've been using it for a long time. With the 'Pandemic' skin it looks like classic Winamp and has support for visualizations and many other features people tended to like from Winamp. https://www.aimp.ru/ https://en.wikipedia.org/wiki/AIMP reply pks016 11 hours agoparentAIMP is great! I have using it with my Android phone. reply fallinditch 20 hours agoprevOne of the things I loved about Winamp was programming my own visualizations - can't remember if this was a plugin or was built into the main app. But it was most satisfying to generate trippy visuals with extreme granular control. I also liked having control over my skin and panel setup. Also, this is cool for all those über random playlisters: a tool you can use to create a random playlist of X amount of songs from your entire library [edit: and make copies of the random files to a new folder. Useful for making playlists on portable media]. Sorry it was a long time ago and I don't recall what it was called. reply jokoon 49 minutes agoprevFoobar prevents me from switching to Linux Same for paint.net reply hlandau 22 hours agoprevfoobar2000 is so good, and so unmatched, especially with its plugins ecosystem, I use it for my music playback needs under wine on Linux. reply RunSet 5 hours agoparentFoobar2000 is parasitic in the sense that many of the plugins that give foobar2000 its value are open-source ports of open-source software, yet the foobar2000 software that hosts the plugins is proprietary. Feels like when Disney makes a movie version of a public domain folktale and then lobbies to perpetually extend the copyright on it. reply jdc0589 22 hours agoparentprevplugins were great. Measured the speakers at my desk (I built them). generated an inverse impulse response filter, and fed it through a plugin to do full frequency equalization. It was a fun project to play with full range speakers that had no passive filter network whatsoever, all done via software. reply anthk 11 hours agoparentprevMeh. Audacious + pulseaudio/alsa-plugins >>>>> foobar 2000. That for GUI. If you like CLI, mpd+any UI it's a beast. Mocp if you are a minimalist. reply hlandau 2 hours agorootparentThe problem (at least for me) is input format support. Assorted foobar2000 plugins support every obscure tracker format, every obscure video game music format (.vgz, etc.), and then foo_midi lets you render MIDIs not just with Soundfonts but with whatever VSTi DLLs you like. Also support for music files in ZIP files as well as music files in ZIP files in ZIP files (don't ask). That's hard to compete with. reply anthk 42 minutes agorootparentmocp opens MODs/S3M's and so on. Everything else it's handled by fluid/timidity. VSTi's? Pipewire now can do that at system level. >Zip Here in Unix I can just mount archives and disk images. reply vunderba 21 hours agoprevBit of a tangent but it's kind of infuriating to me that I still haven't found anything better than Winamp (or Foobar for that matter) on a modestly powerful Windows machine. Even 20 years ago, I could literally just right-click on an entire folder sitting on my external hard-drive, and it would immediately enqueue all of those files into Winamp. I even had a bunch of Winamp plugins that could automatically handle my NSFs, SID files, tracker files—any format I threw at it, it could handle them seamlessly. It used very little CPU, it never crackled, it never popped, and it never crashed. This wasn't even using any low-latency ASIO drivers or anything fancy. Fast forward decades later and I'm sitting on my Mac M1 desperately trying to find anything that even comes CLOSE to this. The closest thing I found is Cog, but it takes minutes to queue up larger folders. It's ridiculous, and of course I'm one of the lucky individuals who ended up with a Mac with core audio issues where if I'm using more than 35% to 40% of my CPU, the audio pops once every minute/minutes despite clearing out the plist files and trying every other trick, it seems like the basic core audio drivers of Mac are awful stuff. I had a better DAW experience on my Windows machine with ASIO4ALL which shouldn't even be possible. reply sawaali 20 hours agoparentFor macOS Ionica is really really good: https://ionica.app/ For iOS I would suggest my own app Muziqi https://apps.apple.com/us/app/muziqi-for-music-lovers/id6468... reply keybits 13 hours agoparentprevI can recommend Swinsian on macOS: https://swinsian.com/ It's a wonderful music player that handles large libraries and is quite customisable (especially smart playlists). reply haunter 21 hours agoparentprev>Even 20 years ago, I could literally just right-click on an entire folder sitting on my external hard-drive, and it would immediately enqueue all of those files into Winamp. VLC? Right click on folder > Play with VLC media player Works with any media file. Takes like 2 seconds to open my Youtube local backup folder with +10k videos reply vunderba 19 hours agorootparentThanks I'll give it a shot, I've never even tried VLC with audio files before - but I just did some reading up and apparently it has built-in support for SPC and other game music formats out of the box. reply donatj 20 hours agorootparentprevHave you used VLC? It's powerful and compatible, sure, but the UI is janky as all get out. reply haunter 20 hours agorootparentYes I'm using it every single day reply meta-meta 21 hours agoparentprevTotally agree. On Windows, Dopamine https://github.com/digimezzo/dopamine is close to giving me what I want but it crashes frequently and simple things like dragging a directory of music onto it just don't really work. Has to be imported to the DB first. Musicbee https://www.getmusicbee.com/ was kinda promising for a while but bloated and clunky. VLC and Foobar get the job done but the UI is meh. Streaming and iTunes really wrecked everything. reply haspok 7 hours agoparentprevTry Deadbeef. reply cageface 20 hours agoparentprevOn a mac you could give my new app a try: https://plastaq.com/minimoon reply thesuitonym 21 hours agoprevI didn't realize Foobar2000 had a Mac release. And here I've been using Apple Music like a fool! reply ElCapitanMarkla 19 hours agoparentOh really when did that come out? I remember missing Foobar when I switch to OSX about 15 years ago before switching to Spotify not long after. reply LoveMortuus 11 hours agoprevI downloaded it on my mobile device, because I have the issue where some songs are very quiet and some are very loud, so I was looking for a volume normalizer and this is the one (that's zero cost) that was recommended, but I'm not sure if I can tell the difference between using this one and just the normal Metro Music Player. So if anyone knows what I'm doing wrong or if there are better (zero cost) tools that could fix my issue, please advise (I'm looking for Android tools as I don't have a usable Windows/MacOS/Linux machine) reply zelphirkalt 10 hours agoparentA long time ago, I had a music player for windows, which had separate volume control for each track, in 10% steps. With that I could make tracks match volume the best, while of course being a bit of manual effort involved. But one could do it iteratively, when one noticed it was too low or high volume on a track, compared to the others. The player was probably not so good in other regards, but I remember using it for quite some time. It was called Ashampoo media player or similar. reply ksynwa 10 hours agoparentprevCan't say for sure. But I have two ideas. 1. Ensure that your music player has loudness normalization enabled. It's normally called ReplayGain and is disabled by default. 2. Replaygain information is written to the audio file's tags. So check the audio file's tags to see if the tags are there. They start with \"replaygain_\" for most formats and \"r128_\" for opus files. You can install termux on your phone and then it basically becomes a linux computer btw. reply justin66 22 hours agoprevWhy does the author backport fixes to the 1.5 and 1.6 versions? What's significant about recent changes that makes those worth keeping alive? reply stuartd 22 hours agoparentThey mention one reason in the release notes: > unintended SSE CPU requirement present in previous releases has been removed. reply justin66 21 hours agorootparentRemoving that requirement makes sense to me (in the current release or the previous releases), but I'm curious why the previous releases are deemed worth maintaining alongside the current release. What did they do feature-wise in newer versions that makes the old versions desirable to some people, to the point that a user would prefer to upgrade them rather than upgrade to the newest version? It's not about system compatibility: the 2.x line supports Windows all the way back to Windows 7. I'm content to dig into the docs but I was wondering about people's personal experiences with it. One hint in the release notes is that some, but not all, old plugins work in the new version... reply The_Colonel 14 hours agorootparent> It's not about system compatibility: the 2.x line supports Windows all the way back to Windows 7. I wouldn't be surprised if a decent amout of people were still running Windows XP, esp. on old hardware. reply justin66 5 hours agorootparentI don't know how many, but it's a decent enough choice for a jukebox machine or something. reply TiredOfLife 13 hours agorootparentprev1.5 is the last version that supports Windows XP. 1.6 is the last version before the big rework. reply twerkmonsta 21 hours agorootparentprevYeah almost certainly plugin ecosystem reply dqft 5 hours agoprev+ columns ui + waveform minibar you need more? reply Grazester 22 hours agoprevI spent more time configuring the darn thing than listening to music! reply pentagrama 22 hours agoprevBack in the day this was the hardcore nerds' Winamp! reply layer8 21 hours agoparentBack in the day? It still is. reply nipperkinfeet 21 hours agoprevI still use Winamp on my desktop and Foobar2000 on my ARM laptop because they got a ARM64 build. reply indigodaddy 13 hours agoprevI used to use xmplay on windows back in the day.. Anyone remember that one? reply HelloNurse 9 hours agoparentXMPlay crashed so often on SID files from HVSC that I switched to Foobar2000. reply citruscomputing 11 hours agoprevI've been setting up a media player console, and foobar is the sole reason it's running windows. Fantastic piece of software. reply JonChesterfield 11 hours agoparentProbably runs perfectly under wine https://appdb.winehq.org/objectManager.php?sClass=applicatio... reply SuperNinKenDo 7 hours agorootparentIt runs great on wine provided you don't need access to the plugin/skin ecosystem. If you need either of those, something almost always breaks in some totally cryptic way. It's the reason I stopped using it on Linux. Sadly nothing even comes close to foobar2000. It's one of those little Windows gems that make you resent being on Linux just a little bit. reply happytoexplain 22 hours agoprevStill my daily driver when I'm at my PC. reply SeriousM 22 hours agoparentWhere do you get your music from? Back in the old days we used cd rips and sharing platforms to get the mp3s from but nowadays streaming got so convenient. reply tasty_freeze 21 hours agorootparentI'm not the person you are replying to but ... I started buying CDs in 1985 to replace my vinyl collection. Around 2001 is when I ripped all my CDs (800 or so) to mp3, but I kept buying new CDs and ripping them up until CD players disappeared as a standard PC feature. I now buy mp3s from amazon or bandcamp or wherever. Even though I have spotify, I prefer to listen to my own mp3s. The only time I use spotify is when someone says, \"You should check out \". I'll listen to the album a few times on spotify, and if I like it, I will buy the album and then listen to my own mp3s. reply Mashimo 12 hours agorootparentprevBandcamp, traxsource, beatport, beatsource .. they all allow you to legally buy tracks in decent quality. reply Stagnant 20 hours agorootparentprevAs someone who uses foobar daily, I get my music mainly from the streaming platform Deezer. With the hi-fi subscription you get access to high quality audio and there are some unofficial tools that make it possible to download the flac files. It is super convenient for they have extensive metadata, album art and more recently lyrics as well. Occasionally I may download torrents but that is rare nowadays. I also own physical copies for vast majority of the music that I download but I basically only buy them to support the artist and to read the booklet. reply insin 12 hours agorootparentprevSoulseek never went away either reply happytoexplain 19 hours agorootparentprevI mostly listen to my existing collection. Rarely when there is something new I like - music filesharing is still quite healthy. I still use Spotify on mobile, and for the recommendation engine, but the interface is bad and they don't have everything I listen to. reply LM358 21 hours agorootparentprevSharings platforms still exist, they just get less mainstream exposure, for obvious reasons. They are also more exclusive and generally require more effort than back in the days. reply Sakos 21 hours agorootparentIt's still extremely simple to get music without having to put up with snobbish exclusive communities. Most basic solution is getting JDownloader and just copying a YouTube link with a song or playlist. If you want album releases, I could list half a dozen publicly accessible sites off the top of my head that don't require you to sign up and don't require you to beg somebody for an invite and don't require you to fulfill absurd seeding requirements. reply LM358 20 hours agorootparentI don't know where you get that snobbish vibe from (maybe my comment, in which case it wasn't intentional), but of course it's easy to just use yt-dlp or whatever. The places I frequent come with curation, organization, quality control and a community of people who deeply care about music which is something I value a lot. Seeding, uploading and staying in it for the long haul is a lot more work than just buying a Spotify subscription and certainly not for everyone, but as someone who is constantly disappointed by the selection available on streaming services and also need local files for DJing, I couldn't imagine living without it. reply Sakos 20 hours agorootparentI got the snobbish vibe from being in these communities and wasting my time on them. It's just another form of gatekeeping. reply LM358 20 hours agorootparentYou do you. After the takedowns of its predecessors (Napster, Oink, What.cd) some quite literal gatekeeping is required IMO. reply jszymborski 22 hours agoprevAnyone know of a supported Foobar2000 Subsonic plugin? The ones I've seen seem to be abandoned. reply TiredOfLife 6 hours agoparentUnfortunately no. reply jcovik 21 hours agoprevI daily use foobar2000 as my main music player. It is very good and simple music player. reply calvinmorrison 22 hours agoprevDeaDBeeF is a clone for Linux. reply dailykoder 22 hours agoparentI do like deadbeef. It's a nice player, but what I absolutely hate about it is that ctrl-w closes the current playlist (well, that's the hotkey I close my tabs with, too, so that's fine), but you cannot restore that (or am I missing some feature?). And I am a lazy guy that doesn't save his playlist regularly. Is there some feature to make it ask me if I want to close a playlist or just disable that hotkey? I sometimes get frustrated when the wrong window has focus. I was even thinking about implementing such thing myself, but somehow never got around to do it Edit: Also iirc the shuffle function in deadbeef is weird, because it always shuffled tracks in the same order (if the playlist did not change and you started on the same track). It somehow has a 'shuffle' and 'random'. Maybe that's intended reply RunSet 4 hours agorootparentYou might like Audacious[0]. It loads the previously-open playlist by default, which I find a little annoying but apparently is your preference. Audacious has the bare-bones GUI of foobar2000 / deadbeef and also a plug-in architecture. https://audacious-media-player.org/ reply jszymborski 22 hours agoparentprevShould also mention that Foobar2000 works flawlessly with WINE. reply kichik 22 hours agoparentprevThat's a funny name considering it was the Winamp creator's nickname and Foobar2000 itself is a Winamp clone. reply notpushkin 22 hours agorootparentNot sure how fb2k is a Winamp clone. There's a Winamp clone for Linux though, Audacious: https://audacious-media-player.org/ reply kichik 21 hours agorootparentSorry, clone might not be the right word here. Foobar2000 was created out of spite because the creator didn't like what Winamp was doing. I vaguely recall something about bitrate limits and ogg support? It was so long ago and on IRC so no history saved. So it's a replacement? Edit: some more context here: https://forums.winamp.com/forum/developer-center/winamp-deve... https://www.reddit.com/r/software/comments/lqu9u/a_brief_his... reply jasonjayr 21 hours agorootparentprev> foobar2000 was first released in 2002 and developed by Peter Pawłowski, who had previously worked at Nullsoft and developed plugins for Winamp. He created foobar2000 with the audiophile community in mind. The software's mascot and logo icon consists of a white \"alien cat\". From https://en.wikipedia.org/wiki/Foobar2000 . It has WinAmp's DNA somewhere in there, and IIRC it was kicked off soon after AOL had bought WinAmp/Nullsoft. reply anthk 11 hours agorootparentprevWinamp clones for Linux/BSD began with X11AMP, later XMMS, which had a huge amount of plugins, similar to Winamp. Then XMMS was forked upon the GTK2 release with Audacious and another one I can't remember its name. reply Quiark 22 hours agorootparentprevin what way is foobar2000 a winamp clone the only similarity I could see is that it plays music reply rcfox 22 hours agorootparentprevIt's a phrase that fits into a hex value. 0xdeadbeef, 0xcafebabe, etc. reply kichik 21 hours agorootparentYeah he loves that stuff. https://github.com/kichik/nsis/blob/b4f28a7071dcd0bf3bcdb766... reply shmichael 22 hours agorootparentprevHow do you fit r into hex? reply rcfox 21 hours agorootparentI don't know. How? reply mariusor 22 hours agoparentprevWith all due respect, but it's very, very far from being a clone from the point of view of the functionality that foobar provides. reply squidbeak 11 hours agoparentprevA clone in appearance and layout configurability, but it's far from having feature parity from foobar. reply mrinfinitiesx 22 hours agoparentprevI've been using VLC for Linux and mobile mp3s haven't tried FLAC though reply olyjohn 22 hours agorootparentxmms was my go to back in the day for Linux. Hard to beat the small, unobtrusive WinAmp interface and skin support. Now I use Audacious as it still supports WinAmp skins and interface. It's really hard to beat. reply SuperNinKenDo 7 hours agoparentprevI dunno what the experience is like on other distros, but on Arch I've tried 3 or 4 times to run it and something is always going awry, either with the software itself or with some plugin I consider indispensable. reply M95D 11 hours agoprevDid they add support for .m3u with .cue files yet? reply George_Bouras 13 hours agoprevIt is the only player I use after winamp. I like music, and it very convenient, to goto folder and ther just right click and play. Thank you foobar. reply p0w3n3d 8 hours agoprevI use it on my macos reply anta40 2 hours agoparentHow? I found it's been ported to iOS, though: https://apps.apple.com/id/app/winamp/id1664497725 reply antisthenes 21 hours agoprevA great example of what software can and should be. A lightweight audio player/converter without any bloat. reply globular-toast 22 hours agoprevThis was the one piece of software I missed when I made the switch to Linux 15 years ago. Not enough to miss Windows, of course. It worked in Wine but didn't feel quite right. It was sort of the end of me building a curated music collection. It takes time and I just moved on to other things. In all this time I've never found anything as good as foobar2000 was back then and my music collection has languished. reply siva7 11 hours agoprevIt's insensitive to have Rammstein on their example screenshot. reply evanhughes 21 hours agoprevI use foobar2000 to play back my super high quality dsd files. So far the best option to listen via my headphone amp. reply mikojan 13 hours agoprevFoobar2000 was and still is the only software I missed since uninstalling Windows as a teenager (rhythmbox is pretty good though). reply oleg_antonyan 12 hours agoparenttry https://github.com/olegantonyan/mpz/ not even close in terms of features, but it could be enough reply Hamuko 21 hours agoprevI used to use Foobar2000 a lot like 20 years ago and a couple of years ago I tried to use it again when I got myself a Windows gaming PC, and I have no idea how I even used it back then. I felt completely lost trying to replicate what I have these days with MPD (+ ncmpcpp and assorted things). Eventually I just gave up and decided that if I was going to listen to music on my Windows machine, I'd just use Plex in a browser. Eliminated the need to scan for files on a network volume every time I used it too. reply mathnode 22 hours agoprevNope. Even way back then, I was using iTunes on mac and windows to rip and organise my music collection. A quick rsync or an smb mount from a Linux machine made it easy to access my media in VLC or Rhythmbox. The winamp/foobar aesthetics were really cool, but overall offered nothing to the practically or ease of actually buying/ripping/playing your music. But you know, everyone is different and some folks had memorised a sequence of characters that were something like \"FCKGW-...\", install limewire, just to play that live acoustic version of Everlong. reply anthk 11 hours agoparentThis. With alsa-plugins and any console music player (cmus or mocp, cmus it's more collection oriented, mocp enforces you to just use directories and files) and a -rt kernel it was more than enough (if not better) to play huge collection files under Linux. reply blackeyeblitzar 21 hours agoprevI love Foobar but it does not whip the llama's ass. Incidentally, Winamp is apparently going open source: https://about.winamp.com/press/article/winamp-open-source-co... reply thesuitonym 21 hours agoparentI wonder if this will be the new Winamp-in-nothing-but-name or the old-new Winamp 5x builds, or even older builds? reply fluoridation 20 hours agorootparentTo be honest, while I used and loved Winamp for a long time and it would be nice to have the sources even for a 2.x version, the reason it was popular back in the day was because it was the only one (or close enough). Nowadays there's a million ways to play audio files. Audacious even has a mode that imitates the Winamp aesthetics, and I think it can even load Winamp skins. There's not much value in the Winamp sources beyond nostalgia, and if it's about that you can still run ancient builds on modern Windows, although they're not able to play anything. I think the moment to release the sources was when Nullsoft went down. Back then Winamp still had a smidgen of mindshare left. Now everyone has moved on to either streaming or other players. reply blackeyeblitzar 19 hours agorootparentWinamp also had visualizations. It seems that none of the modern players have that. reply anthk 11 hours agorootparentAudacious + ProjectM. reply fsckboy 15 hours agoprev [–] foo and bar, and foobar, have meanings and utility that is undermined by people giving them new definitions and polluting our public namespace. Instead, call the project \"farting in an elevator\" because that's what you're doing. https://en.wikipedia.org/wiki/Metasyntactic_variable * FOO 3. Used very generally as a sample name for absolutely anything.* https://www.dourish.com/goodies/jargon.html A similar injustice, theft of the commonweal, was Microsoft was granted a trademark for \"windows\", as if that was the generic term for... well, \"windows\" reply npteljes 7 hours agoparentIsn't it similar to how your nickname is fsckboy, cleverly iterating over the well-established fsck utility? Or is that something else, because fsckboy is not a published product in the IT space? reply fsckboy 2 hours agorootparentfooboy would be perfectly fine: a doghouse is not a dog. and the namespace for humans is much more \"lexically bound\" so we don't tend to get confused when multiple people are named John, just as we don't get confused with multiple cases of foo used as a metasyntactic variable; in fact, we expect it, unlike foobar2000 which demands exclusivity. Does the \"2000\" in foobar2000 qualify it somehow? No. Do you make sure to say Windows NT 3.1 every time you mention it? no, you say only the qualifying part that makes your point: Windows, or NT, or 3.1 because the term is decomposable. fsckboy does not suggest \"decompose me\" other than etymologically suggesting \"this guy uses unix; this guy doesn't use the gui; this guy is a wheel\" Economists use the term \"widgets\" in their examples. \"Let's say a factory makes widgets, and the cost function is given by...\" If you as a professor were to say \"let's say a factory makes cars...\" you would get responses from the class of \"that doesn't make sense! cars blah blah blah\" it's very convenient to use a variable that does not come freighted with meaning. then there's the case of Little Bobby Tables... reply npteljes 41 minutes agorootparentValid point! This makes foobar2000 not good in a way that fsckboy passes. reply helloplanets 14 hours agoparentprev [–] You are aware that foobar2000 is 21 years old, right? reply fsckboy 14 hours agorootparent [–] you don't realize I railed against it at the time, and before that the \"windows\" debacle? reply helloplanets 13 hours agorootparent [–] Wasn't aware of that, thanks for the context. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "foobar2000, a freeware audio player for Windows, has released bug fixes for versions 1.5 and 1.6, with versions 1.6.18 and 1.5.12 now available for download.",
      "foobar2000 mobile v1.5 has been released, featuring a new editable skin file format, with the Android APK available for download.",
      "foobar2000 v2.1 final and foobar2000 for Mac v2.6 final were released in December 2023."
    ],
    "commentSummary": [
      "Foobar2000 is celebrated for its simple and consistent user interface, maintaining popularity for 21 years due to its functionality and minimalism.",
      "Despite the popularity of streaming services, Foobar2000 remains valued for its configurability and support for various audio formats.",
      "The author of Foobar2000 has opted not to open-source the software, prioritizing control and compatibility."
    ],
    "points": 260,
    "commentCount": 170,
    "retryCount": 0,
    "time": 1722456320
  },
  {
    "id": 41126782,
    "title": "Stop Killing Games – European Citizens' Initiative",
    "originLink": "https://www.stopkillinggames.com/eci",
    "originBody": "EU PETITION TAKE ACTION FAQ PRIVACY POLICY English European Citizens' Initiative Videogames are being destroyed! Most video games work indefinitely, but a growing number are designed to stop working as soon as publishers end support. This effectively robs customers, destroys games as an artform, and is unnecessary. Our movement seeks to pass new law in the EU to put an end to this practice. Our proposal would do the following: Require video games sold to remain in a working state when support ends. Require no connections to the publisher after support ends. Not interfere with any business practices while a game is still being supported. If you are an EU citizen, please sign the Citizens' Initiative! GO TO EU PETITION Need a guide? Select your country of residence: Germany France Italy Spain Poland Romania Netherlands Belgium Czechia Greece Portugal Sweden Hungary Austria Bulgaria Denmark Finland Slovakia Ireland Croatia Lithuania Slovenia Latvia Estonia Cyprus Luxembourg Malta We only use strictly necessary cookies to manage language preferences and showing this banner. ACKNOWLEDGE",
    "commentLink": "https://news.ycombinator.com/item?id=41126782",
    "commentBody": "Stop Killing Games – European Citizens' Initiative (stopkillinggames.com)257 points by edd25 12 hours agohidepastfavorite123 comments petterroea 10 hours agoThis is a great excuse to also ensure the legality of third party reverse-engineering as a legitimate and reasonable reaction to the unavailability of official support. I believe EU law already to a certain degree supports this. Just look at the situation Fisker Ocean Car owners are in at the moment - the company has gone bankrupt, and their fate is in the hands of whoever buys the assets. eSIMs may not be paid for, and there is no guarantee there will be an online service for the cars to phone home to in the future. Some features - like the sunroof - won't work without it. reply graeber_28927 8 hours agoparentThe sunroof needs to phone home to work? reply throwaway48476 8 hours agorootparenthttps://insideevs.com/news/725463/fisker-ocean-owners-bankru... Apparently, isn't the future great? reply robin_reala 7 hours agorootparentBut… what happens if you drive out of coverage? Someone must have said that at some point during the development? reply Sharlin 7 hours agorootparentProbably was admonished for asking inconvenient questions. reply moogly 6 hours agorootparentprevLuckily it doesn't really matter. At that size, it's at most a 400 W panel, so the energy it produces is rather negligible. It was always a \"just because we can\" feature. reply oblio 6 hours agorootparentUnless I'm mistaken, \"sunroof\" in this context doesn't mean solar panels, it's means that big sliding hatch in the roof of the car. reply usrnm 7 hours agorootparentprev\"Good enough for the MVP\" reply NorwegianDude 7 hours agorootparentprevWelcome to 2024, I guess. Let's hope it won't start raining while it's open and there is no coverage, lol. Next year the brakes might require a round trip to the data center too, so I guess we should start to account for network latency when braking. /s reply cchi_co 8 hours agoparentprevSounds like a good idea that can end the problem with discontinuation of official support reply lynx23 6 hours agoparentprevHa, be glad its just a car. I know a true story about the first woman in my country to go through the process of getting a bionic eye. Long story short, she got it. Forward a few years, and the company that built it goes bust, leaving her without support for a technical implant that was experimental at best, meaning, had a lot of issues. Yes, a articular Lem short story comes to mind, although just tangentially related. We're entering a truely scary time. reply theaussiestew 4 hours agorootparentSounds like the plot of Deus Ex Human Revolution. I hope we don't go into that future. reply worble 8 hours agoprevFor extra context, you can watch Ross Scott's videos about his campaign to stop games being killed. Original video with all the different avenues he's trying: https://www.youtube.com/watch?v=w70Xc9CStoE The one specifically about this initiative: https://www.youtube.com/watch?v=mkMe9MxxZiI He's done smaller update videos on how it's been progressing on his channel if you want additional info. reply stavros 10 hours agoprevI've signed this, and, as an aside, I was extremely impressed that the Europa.eu site localized the CAPTCHA to the Greek alphabet. That's some commitment to accessibility by the general public. reply MrGilbert 9 hours agoparentI'm also impressed. I used the \"eID\" functionality, and it just worked flawlessly. I signed it in under a minute. reply diggan 8 hours agorootparentI'm not as impressed, tried to use my Spanish digital certificate and got \"the submitted certificate is not an electronic DNI\". reply oblio 6 hours agorootparentIs it this thing: https://op.europa.eu/en/publication-detail/-/publication/f14... (scroll down to Spain)? reply gschizas 9 hours agoparentprevTrue, never seen a CAPTCHA with Greek letters before! I refreshed it to make sure, I was so confused! Good job! reply heckerhut 10 hours agoparentprevIndeed that’s pretty cool. reply aitchnyu 6 hours agoparentprevWho is the captcha provider? reply tgsovlerkhgsel 6 hours agorootparentI assume they implemented it themselves. It seems to be a very basic letter captcha, not some reCaptcha style \"smart\" risk-based thing. reply Yeul 9 hours agoprevAs I understand it copyright on a videogame is 50 years but the vast majority of games- or all entertainment really- stops making money after a few years. It gets worse if your game has licensed music in it! I think piracy is the best method of preservation because it's removed from a financial incentive. Publishers just aren't going to spend a dime if it doesn't make a buck. reply worble 9 hours agoparent> I think piracy is the best method of preservation because it's removed from a financial incentive. The problem is that piracy doesn't help for always online \"games as a service\" games where the game is killed after the server has shut down. You can't pirate the server because it was never available, and outside of being lucky enough that a few hackers dedicate a lot of spare time to reverse engineering it, that game is gone forever. The point of this initiative is to ensure that game companies have a legal obligation that at the point of shutting down game servers they must either release the server software, patch the game to work offline, or do whatever else to ensure that the game continues to function. It's worth noting that this would only count for games sold as goods i.e you paid a fixed fee at the time of sale with the expectation of owning a product indefinitely. Games with explicit subscriptions such as MMO's would not be subject to this since there was never an expectation of access to the product continuing after the subscription expired. reply Moru 8 hours agorootparentIf you look on the thing you sign when getting a steam account, you don't actually own any of the games. Just like the MMO's, you cant play them when steam or producer decides to shut them down. reply Qwertious 6 hours agorootparent>If you look on the thing you sign ToSes aren't legally binding when they require you to waive your rights. This has been tested in courts repeatedly. reply diggan 8 hours agorootparentprev> you cant play them when steam or producer decides to shut them down. Doesn't Steam actually let people keep a game in their Steam library even if the publisher takes down the store page for the game? reply tadzik_ 8 hours agorootparentThat only gives you the client component though, which isn't very useful when the game servers shut down. Most games these days don't have a self-hostable dedicated server. In case of Steam/Valve specifically it happened a while ago with Counter-Strike: Global Offensive. Valve replaced it with Counter-Strike 2, and while GO's client is still usable, some of its online components are not. reply throwaway48476 7 hours agorootparentI believe csgo on the Xbox still works online. reply SXX 6 hours agorootparentIt's only works because Valve probably have contractual obligations to not break online services for the game until console EOL. This can very well be the case if it was ever possible to actually buy it on Xbox. reply leftyspook 8 hours agorootparentprevIt does. Not sure if publisher can opt-out though. Another point is that Steam DRM is a) optional b) unlike always online GaaS trivial to circumvent reply account42 6 hours agorootparentprevThat's how publishers want thingns to work. But if the store interface gives one impression and the smallprint annother thne it's not clear that the contract is what courts will uphold. It is worth noticing though that Steam has stopped using the word \"Buy\" and instead use terms \"Add to Cart\" and \"Continue to payment\" which are perhaps more ambiguous but still not much so IMO. They did however use \"Buy\" in the past and changing the store interface now should not excempt them from fulfilling the expectations they have set in the past. reply Sakos 8 hours agorootparentprevThere is a historical and cultural loss involved when online only games are shutdown. This isn't simply a problem of \"oh there was never an expectation of eternal access\". It's a problem of us losing historical artifacts because of financial incentives. reply coretx 8 hours agorootparentNot only that, it's capital destruction too. It shrinks your economy. Not to be confused with creative destruction. reply keybored 8 hours agoparentprev50 year copyright on video games is insane. A really good ten year old game could be considered a “classic”, certainly a twenty year old one. SNES games are like 28–33 years or something. Now consider how many of the modern classic PC games are kept playable/relevant (a problem with some older games are things like terrible playing mechanics; graphics less so) by an enthusiast modding community. reply sofixa 8 hours agoparentprev> but the vast majority of games- or all entertainment really- stops making money after a few years I don't think that's universally true. Paradox Interactive are a studio with grand strategy games, and even decades-old games still get new sales of the base game and the DLCs, with a strong user base. reply Qwertious 6 hours agorootparentWhich decades-old games are Paradox getting lots of money from? HoI4 released in 2016, are people really buying the original HoI (from 2002)? reply sofixa 6 hours agorootparentCrusader Kings II and Europa Universalis IV are still seeing high amounts of players, with EUIV in particular getting recent DLCs that sell well. Released in 2013, it's a decade+, and it will be at least a year or two before EUV comes out. reply account42 6 hours agorootparentprevParadox already often sell the base game for peanuts though and mostly make money through new DLCs. reply cchi_co 8 hours agoparentprevPiracy undermines the creators' rights still. And I think that a legal framework should do its job reply throwaway48476 8 hours agorootparentCreators were never supposed to have indefinite rights. Copyright has an expiration date to balance fhe rights of the public and author. reply account42 6 hours agorootparentIn the US the author's rights don't even come into the motivation. They don't exist a priori as free speech would let you share any \"IP\" you want. The temporary monopoly is ONLY granted to encourage more creation, not as a recognition of author rights. In the EU it's a bit more complicated but I still don't see authors rights as a primary motivator for copyright specifically. reply dguest 3 hours agoprevI think people might miss how rules like this can be nice if you are a game developer. As someone who writes software, I'm honestly happy when someone is requiring that the source be open, that my results be reproducible, that my changes are reviewed, etc. Without that my boss is just asking why I waste my time on things with no profit margin but which are quite satisfying if you take any pride in your work. In a lot of cases, just requiring that something work without phoning home will cost developers almost nothing and insulate them from silly cost shaving from the higher ups. reply irusensei 9 hours agoprevReleasing source code or protocol specs for the server side software after the live service is put down would be a good PR bonus for any game corporation. Of course there might be third party IP involved but just publishing a document stating what the server should do is probably good enough to get some good guy points. Besides it might keep the game alive and even generate some residual revenue even though you aren't spending a dime with server infrastructure. reply yawnbox 10 hours agoprevPlease sign if you are an EU citizen. Please share with your EU citizen friends. reply rob74 9 hours agoparentOr rather, take a look at this page: https://citizens-initiative.europa.eu/find-initiative_en?CAT... and consider signing all initiatives that you identify with. I know that preventing their favorite game(s) from being killed off is very important to some people, but in the grand scheme of things, there may be more important causes to support... reply account42 6 hours agorootparentThere can always be more important issues but I would not frame this as being just about silly games either. It's not like other tools have been moving to being more and more dependent on online services and even if the initial change this petition achieves (if it does succeed, which is a slim chance) apply to just games this still provides a precedent for widening the legislation to other software in the future. reply kwhitefoot 1 hour agoparentprevI would have but Brexit put paid to that. :-( reply jagermo 9 hours agoprevSigned. I think this is an important initiative and could either get publishers to support the games longer or release the server-side parts, so that fans can keep them going. Just look at Freelancer, still going strong after 21 years thanks to fans. reply netcan 7 hours agoprevImo... even if they win this, they still lose. Requiring companies to do things they don't want to do... has limits. It's hard to prevent them from doing a crap job. The actual \"solution\" is radically reducing copyright duration. Most revenue is generated during the first N years. reply account42 6 hours agoparentWe should do both - reduce copyright duration to the absolute minimum required for it's goal (to encourage creation of useful science and art, and yes zero might be the optimal term here) while also making sure that benefiting from copyright means the author/company has to ensure that the creation is available to the public after the copyright period. Both things are needed for the copyright deal to be fair to the greater public. reply extraduder_ire 6 hours agoparentprevHow is shorter copyright going to help with games being built with remote kill-switches? The server-side component isn't a thing you even posses. AIUI, reverse engineering or releasing patches to fix such games is already legal in the EU. reply dalmo3 7 hours agoprev> Require video games sold Wouldn't this just incentivise companies to move to a F2P and/or subscription model? There's no expectation that, just because I've downloaded the client, I should be able to use a VPN service after the servers are discontinued. Or use AutoCAD after my licence has expired. You don't need to leave the gaming realm to imagine the unintended consequences of this petition - just look at the hellscape that is mobile gaming. reply BlackFly 6 hours agoparentPossibly, but it is an unmitigated good to incentivize companies to position their relationships with customers honestly. People approach free-to-play games and subscription based games with different attitudes than purchased games. A purchase carries a reasonable expectation of durability. On the other hand, if you sell cosmetic items in your subscription based or free-to-play game, then you have sold something with a reasonable expectation of durability which is somewhat already enshrined in the digital goods laws. If you rent those items for a limited time then the relationship is again honest. If it is reasonable to expect a limited time frame of usage from the software then it is reasonable for the company to state what guarantees they are willing to make for that time frame in a subscription contract. The presumption of durability should carry the weight of law (up to consumables and wear and tear). reply teroshan 6 hours agoparentprevAs I understand, this would also apply to e.g. micro-transactions/cosmetics which would be categorized as 'possessions' if I follow the wording in this proposal. So this would include F2P games, requiring them to provide a way to enjoy those cosmetics. As for subscription-based games, Ross Scott put them in a separate category in a previous video of his [1], as you willingly pay for access to a service which has a known end date (end of the month). Although with the micro-transactions angle in mind, I'm not sure how this changes things. [1]: \"Games as a service\" is fraud, https://www.youtube.com/watch?v=tUAX0gnZ3Nw reply account42 6 hours agoparentprevI don't think this is a good argument - that is, to not hold companies accountable because doing so might get them to do other undesirable things. It's not like the mobile F2P dumpster fire doesn't exist already without the proposed changes and even PC games have moved significantly towards F2P, especially for online titles which are the main concern of the petition. Also while this may not be the current public opinion, F2P generally still involves income via sales - not of the whole game but of tiny portions of it dangled in front of you. Any worthwile rule change would also require those to continue to be available to you when the company decides to shut the servers. reply prmoustache 7 hours agoparentprevwell, we can ban subscription models too ;-) reply t0bia_s 6 hours agoprevAnother (beside DRM policy) reason, to buy games exclusively on GoG. I would never pay for game that need third party launcher for running it and keep updated. For same reason I'm unable to play (and pay for) online games because I don't have control over saved progression and future development of the game. reply account42 6 hours agoparentYou probably already know this but GOG does sell games with online components, including ones tied to a license key (=DRM). So simply only buying from GOG is not enough to escape this madness. reply t0bia_s 5 hours agorootparentWhich are not necessary to use for running single player game. I firewall all games and they run just fine, even for LAN coop. reply thesnide 3 hours agorootparentSo do I. I simply boycott those that need an online server for multiplayer, unless an opensource version exists. LAN or nobuy. Sadely, it seems that simple LAN multiplayer is not fashionable anymore... Yet, I recently restarted some LAN parties and was amazing, even for youngs, when they experience the screams of other players... reply t0bia_s 1 hour agorootparentYes, occasionally we do LAN parties as well. We try to beat a Titan Quest, because they add new datadiscs here and there so we did not finish it yet. Whats your choice for LAN games? reply scanny 6 hours agoprevThis is a great initiative from Ross, fingers crossed it picks up momentum. reply andres_diaz 8 hours agoprevI have a resident permit in an EU country, I can't vote because I'm not a national. Damn it. reply account42 6 hours agoparentOkay? That is generally the difference between a resident and a citizen in a democracy - a citizen gets to have a say in how the country is run, a mere resident does not. reply cchi_co 8 hours agoprevWould it be challenging for small developers financially to design their games to meet these requirements? And for multiplayer online games to live without publisher support... Yet the proposal is a strong step towards protecting! reply NekkoDroid 8 hours agoparent> Would it be challenging for small developers financially to design their games to meet these requirements? I would doubt it. Already the smaller developers are less likely to be part of the current problem, most of those games at least work offline if they aren't already entirely DRM free. And the ones that require online access, when the game is designed to be self-hostable this is 0 problem. I'd almost wager it is more difficult and time consuming ensuring they are the only ones that the game can connect to if they'd publish the server binary. And regarding licensing of server software: you'd need to take into account that you need to publish it down the line when sourcing your dependencies, so I wouldn't count licensing complications a valid excuse, as it's already done with the game software itself. reply throwaway48476 8 hours agoparentprevA source code dump would likely be 'reasonable' and not cost anything. reply RHSeeger 7 hours agorootparentIt's not really as simple as that, though. What if your server code uses paid, 3rd party libraries? reply throwaway48476 7 hours agorootparentAren't these usually source/blob available but require a license to include in a product? reply Moldoteck 7 hours agorootparentprevit doesn't matter as long as you dump the code or patch the games reply Nullabillity 7 hours agorootparentprevToo bad, should have thought of that before taking on the dependency? reply ChrisArchitect 4 hours agoprevRelated from yesterday: Stop Destroying Videogames – European Citizens' Initiative https://news.ycombinator.com/item?id=41121570 reply maccard 9 hours agoprevWhy does this only apply to video games? Why doesn't this apply to apps in general? I don't want to suggest that I'm in favour of sunsetting every game once a publisher or developer is done with it, but there's got to be a middle ground between \"you must ensure that your game can have all online components replaced\" and what we have right now. And I think the sheer amount of work involved in the former for every game combined with perverse incentives from a very small subset of users that cause a disproportionate amount of hassle makes this not a good idea. It's a great example of a change that greatly favours existing companies who could meet the legislation, and will negatively effect smaller games and studios. reply Sakos 8 hours agoparent> perverse incentives from a very small subset of users This is to the benefit of everybody now and in the future. It doesn't matter if only an insignificant fraction of people recognize the importance. reply maccard 8 hours agorootparentThe perverse incentives are people who cheat in multiplayer games. Like it or not, multiplayer games live and breathe on how well they handle this problem. A single cheater in a BR game can ruin the game for 100 people. reply throwaway48476 8 hours agorootparentCheating is a social signaling problem disguised as a technical problem. reply maccard 8 hours agorootparentThe problem is that the desired outcome of the cheater in a multiplayer game is to ruin the experience for others. It's a game of cat and mouse, don't get me wrong, but that doesn't mean that because it's technically impossible to stop all cheating that no efforts should be made. Distilling everything down to \"open good closed bad\" doesn't help anything, as the reality is it's far more nuanced than that. reply throwaway48476 7 hours agorootparentLately successful anti cheating programs have separate matchmaking for cheaters instead of using technical measures to try to stop cheating which will always be bypassed. reply maccard 4 hours agorootparentBy your own measure that's a technical measure that can be bypassed. It also doesn't work, to the best of my knowledge. Here's [0] a thread from a game that tried this, and ultimately went back to using anticheat. > instead of using technical measures to try to stop cheating which will always be bypassed. The word \"stop\" implies that it can be completely eliminated - it can't. But the impact of the cheaters on the rest of the game can be reduced. If you have client side hit detection and no server validation, your game will be unplayable pretty much immediately. If you only offer your game over streaming services, people will use external input devices to give them an advantage. But, the number of people who are willing to buy a Cronus Zen is significantly smaller than the number of people who are willing to download a dll and put it in the folder next to their game. [0] https://x.com/FallGuysGame/status/1305486783858302976 reply exe34 9 hours agoparentprevrelease the source and people will maintain it for you for free. you can't say it's not profitable anymore to keep maintaining something that people paid for and at the same time say it'd hurt your profit if you release it. reply maccard 9 hours agorootparentAgain, why is this just for games? Why are Figma allowed to do this, but EA aren't? reply NekkoDroid 8 hours agorootparentThis is intentionally kept to only games as expanding the scope would include software by a lot of big name businesses which would then try everything in their power to stop this from passing. If it's only limited to games it has less companies trying to shut this down and would set a precidence that this can be expanded or just straight up applied to other types of software. reply user_7832 8 hours agorootparentprevCurious, is there an option to buy and download Figma's software? AFAIK it's only an online server you connect to, right? reply maccard 8 hours agorootparentUnsure. So if a company only offered game streaming they would be exempt from this? reply throwaway48476 8 hours agorootparentXbox yes, stadia no. Depends whether the expiration date is communicated at time of transaction. reply maccard 8 hours agorootparentWhile I disagree with your criteria, I agree with you in principal - it's not black and white, and we could do better as an industry (speaking as an online game developer) to set clearer expectations around what will happen and when it will happen. I would happily and whole-heartedly support a bill that requires some sort of SLA/minimum guaranteed availability for licensed content to be presented along with the payment terms in plain english. Something like \"By making this purchase, XCORP agrees to provide you with an ongoing and updated YGAME until at least DD-MMM-YYYY and after that point makes no guarantee for availability. This date may change but may not be moved earlier without your agreement\". Which is pretty much what we as developers negotiate with cloud providers, third party technology, etc. Note I'm not a lawyer, so please don't critique my wording here. reply throwaway48476 7 hours agorootparentI think such disclaimer pop-ups would be the worst kind of GDPR banner style 'solution' to the problem. Copyright having an expiration was supposed to be a balance of the public interest and author rights. Copyright extension and DRM has absolutely smashed the scales. Once something leaves commercial relevance it should enter the public domain. In the case of software this pretty much requires source code. reply exe34 8 hours agorootparentprevyou got to start somewhere. plus I don't actually use any proprietary software outside of Nvidia' drivers and cuda (and binary blobs in my phone and raspberry pi, and the minix in my cpus and a bunch of stuff I can't remember), so I don't know much about that. reply maccard 8 hours agorootparentIf you don't use any proprietary software at all then surely you don't play any closed source online games? reply drcongo 7 hours agorootparentprevYes, but apart from the Nvidia drivers, cuda, binary blobs in your phone and raspberry pi, and the minix in your cpus, and the stuff you can't remember, what have the Romans ever done for us? reply RHSeeger 7 hours agorootparentprev> release the source and people will maintain it for you for free What about cases where just having the source code isn't enough. Things that use paid third party libraries are a good example. reply Moldoteck 7 hours agorootparentit's up to the ppl. Without server code you can do nothing, with it & third parties it's up to you/volunteers to decide if it's worth it or not to keep alive reply surfingdino 10 hours agoprev> Not interfere with any business practices while a game is still being supported. Needs better explanation. reply vasco 10 hours agoparentThey just mean the companies can still do whatever they want while the game is being supported. It's an extremely poor way of writing that they are only interested in modifying the rules for end-of-life of games instead of regulate existing playable games. The whole thing is poorly written, but the idea is reasonable. reply IshKebab 9 hours agorootparentDefine \"supported\"... This seems like a good goal but I'm not sure they've fully thought it through. reply NekkoDroid 8 hours agorootparentFor DRM protected games that \"phone home\" for verification its when they are unable to reach \"home\" anymore (not just temporary outage). For online game its when the official servers are shut down. Are there any other cases where this initiative would apply that I didn't mention? https://citizens-initiative.europa.eu/initiatives/details/20... > This initiative calls to require publishers that sell or license videogames to consumers in the European Union (or related features and assets sold for videogames they operate) to leave said videogames in a functional (playable) state. > Specifically, the initiative seeks to prevent the remote disabling of videogames by the publishers, before providing reasonable means to continue functioning of said videogames without the involvement from the side of the publisher. reply surfingdino 7 hours agorootparent> Are there any other cases where this initiative would apply that I didn't mention? Music and video sales? How many times people who bought music on one of the Microsoft services had to buy it again, because Microsoft turned off authorisation servers? But in reality this would apply to a lot of software today. reply extraduder_ire 6 hours agorootparentThis is explicitly limited to video games, to keep the scale and scope as achievable as possible. reply eesmith 10 hours agoparentprevThen read the petition itself or the FAQ? reply Quothling 10 hours agoprevI know this is a little unrelated, but I was really disappointed to find that I couldn't use my Danish national digital ID (mitID) to sign this. reply Fethbita 10 hours agoparentIt is because mitID is not a notified eID scheme in the EU. See https://op.europa.eu/en/publication-detail/-/publication/f14... reply pjmlp 8 hours agoprevSigned as well. reply voidUpdate 9 hours agoprevsad english noises reply keybored 10 hours agoprevnext [4 more] [flagged] withinboredom 9 hours agoparentI thought it was about squid game. reply ogogmad 8 hours agorootparentthis would be so much easier in German reply oblio 6 hours agorootparentIt would probably be much easier in a bunch of other languages (Romanian below): Opriți distrugerea jocurilor. versus, if you want to use the most similar words, for maximum confusion: Opriți jocurile distructive. as you see, they're still super visually distinct, despite using the most similar words possible. reply oleganza 10 hours agoprevPeople want to be hooked up on subscription because schools and parents do not preach long-term values (well, maybe only orthodox religious minorities do). We are in this situation because of a shrinking time horizon for the modern society (aka \"high time preference\"). People want instant gratification, buy-now-pay-later, pay attention to the packaging, not content. Most citizens are conditioned to live here and now. Even climate change activists frame the issue (that is supposed to be about long-term thinking) on a very short scale: do something hysterical right now, otherwise the world's gonna end tomorrow. reply pjc50 9 hours agoparentCustomers generally do not want to be hooked on subscriptions, that's a choice that's forced on them by the \"you will own nothing and be happy\" rentier faction. > Even climate change activists frame the issue (that is supposed to be about long-term thinking) on a very short scale: do something hysterical No need for \"hysterical\" in there. But the more and sooner action is taken the better the outcome. reply oleganza 6 hours agorootparentI disagree. Netflix is successful because you get a never ending stream of entertainment for a predictable cost. No need to make consumer decisions on each and every piece of fun. It takes extra effort to avoid this trap. I and my wife had to make a conscious decision to abstain from watching any TV shows because of their addictive structure - same goes for the algorithm feed of reels. If we need to watch a movie in the evening, it must be a complete thing in itself, not a beginning of a 5-season saga. reply Dban1 10 hours agoparentprevinteresting seeing these terms here. I came from reading The Bitcoin Standard book reply sph 9 hours agorootparentThe best part about this book is the first half, about the history of currency, economy and indeed, the concept of time preference. How inflationary or deflationary economies affect human psychology and spending patterns. I recommend it even if one is not really interested in cryptocurrencies. Or watch the author's (Saifedean Ammous) interview on Lex Friedman if you prefer. reply irusensei 9 hours agorootparentGood read but Saifedean is very opinionated and will be probably off putting to the average orange Redditor. I for one can't stand him for more than a few minutes. You always know he will start blabbering about carnivore diets within 5 minutes. reply sph 5 hours agorootparentI never heard him talk about carnivore, but then again I'm pro carnivore so you might conclude my opinion is worthless as well. The average orange Redditor likes an echo chamber, so one should not be concerned about their opinion. The pro-Bitcoin will adore him, the anti-Bitcoin will hate him, a priori and nothing will change their mind. reply pjc50 9 hours agorootparentprevYou don't have to put cranks in your informational diet. reply close04 9 hours agoparentprev> Even climate change activists frame the issue (that is supposed to be about long-term thinking) on a very short scale: do something hysterical right now, otherwise the world's gonna end tomorrow. This looks more like a consequence of the issue you described previously, than part of the issue itself. If everyone is concerned only with the next 5 minutes (and even if they are with the next 5 years), how would you possibly get them to care about the next 50 or 500 years? So you frame it in terms that align with the modern approach of \"only here and now exist\". reply pawelmurias 9 hours agorootparentIt's normal and expected that people won't care much what happens in 50 or 500 years. You will possibly be dead and it's too far away to reliably predict the consequence of event in that time span. reply tokai 9 hours agoprev [–] I rarely think the market is the answer to anything. But this is one of the times were letting the market solve the problem it the actual fix. In the end nothing of value is lost when the Nth ubisoft project is taken offline. And if people keep buying them it is what it is. Triple A slob are not competing actual good games out of the market. reply NekkoDroid 8 hours agoparent [–] When you stop thinking about games as just entertainment but also as an art form you realize that a lot of art has already been lost to time. It's shit to regret down the line when you could have just prevented the loss of art at an earlier point in time. As much as I don't play a lot of AAA games due to how they either play or monetize, it is important to me to preserve them for future times considering I still play a lot of older games and even some games from before I was born. reply tokai 8 hours agorootparent [–] Not all art needs to be preserved. Everything will be lost eventually, and efforts should be withheld for the worthwhile. People that don't work with preservation usually have a kneejerk feeling that we have to save everything for all time, but it is not feasable nor is it commendable. reply mpalmer 8 hours agorootparent> Everything will be lost eventually, and efforts should be withheld for the worthwhile If art was preserved solely on the basis of whether its contemporaries thought it was worthwhile, we'd be in real trouble. reply RHSeeger 7 hours agorootparentIf all art, everywhere was kept forever, we're be in real trouble reply Timon3 5 hours agorootparentWhy, what trouble would we be in? And since we're apparently only dealing in absolutes - would we be in bigger trouble than we'd be in if no art, nowhere was kept for any amount of time? reply throwaway48476 8 hours agorootparentprev [–] If I buy something I should have the choice whether I want to preserve it or not. There are people that collect bread tabs, I toss them but I was still enriched learning from those that do. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A movement is advocating for a new EU law to ensure video games remain functional even after publishers end support, preserving them as an art form.",
      "The proposal includes ensuring no required connections to the publisher post-support and not interfering with business practices during active support.",
      "EU citizens are encouraged to sign the Citizens' Initiative to support this cause."
    ],
    "commentSummary": [
      "The European Citizens' Initiative aims to ensure the legality of third-party reverse-engineering due to the unavailability of official support, particularly for video games and other software.",
      "This initiative is significant as it addresses the issue of digital preservation, ensuring that games and software remain accessible even after official support ends, which is crucial for cultural and historical preservation.",
      "The initiative proposes that game companies should release server software or patch games to work offline when they shut down servers, preventing the loss of access to purchased content."
    ],
    "points": 257,
    "commentCount": 123,
    "retryCount": 0,
    "time": 1722495575
  },
  {
    "id": 41127726,
    "title": "I recreated Shazam's algorithm with Go",
    "originLink": "https://github.com/cgzirim/not-shazam",
    "originBody": "NotShazam 🎵 Demo in Video Description 🎼 NotShazam is an implementation of Shazam's song recognition algorithm based on insights from these resources. It integrates Spotify and YouTube APIs to find and download songs. Installation 🖥 Prerequisites Golang: Install Golang FFmpeg: Install FFmpeg MongoDB: Install MongoDB NPM: To run the client (frontend). Steps Clone the repository: git clone https://github.com/cgzirim/not-shazam.git Install dependencies for the backend cd not-shazam go get ./... Install dependencies for the client cd not-shazam/client npm install Usage 🚴 Start the Client App cd client npm start Serve the Backend App go run main.go serve [-proto ] [-port ] Download a Song Note: A link from Spotify's mobile app won't work. You can copy the link from either the desktop or web app. go run main.go downloadFind matches for a song/recording go run main.go findDelete fingerprints and songs go run main.go erase Example 📽 Download a song $ go run main.go download https://open.spotify.com/track/4pqwGuGu34g8KtfN8LDGZm?si=b3180b3d61084018 Getting track info... Now, downloading track... Fingerprints saved in MongoDB successfully 'Voilà' by 'André Rieu' was downloaded Total tracks downloaded: 1 Find matches of a song $ go run main.go find songs/Voilà\\ -\\ André\\ Rieu.wav Top 20 matches: - Voilà by André Rieu, score: 5390686.00 - I Am a Child of God by One Voice Children's Choir, score: 2539.00 - I Have A Dream by ABBA, score: 2428.00 - SOS by ABBA, score: 2327.00 - Sweet Dreams (Are Made of This) - Remastered by Eurythmics, score: 2213.00 - The Winner Takes It All by ABBA, score: 2094.00 - Sleigh Ride by One Voice Children's Choir, score: 2091.00 - Believe by Cher, score: 2089.00 - Knowing Me, Knowing You by ABBA, score: 1958.00 - Gimme! Gimme! Gimme! (A Man After Midnight) by ABBA, score: 1941.00 - Take A Chance On Me by ABBA, score: 1932.00 - Don't Stop Me Now - Remastered 2011 by Queen, score: 1892.00 - I Do, I Do, I Do, I Do, I Do by ABBA, score: 1853.00 - Everywhere - 2017 Remaster by Fleetwood Mac, score: 1779.00 - You Will Be Found by One Voice Children's Choir, score: 1664.00 - J'Imagine by One Voice Children's Choir, score: 1658.00 - When You Believe by One Voice Children's Choir, score: 1629.00 - When Love Was Born by One Voice Children's Choir, score: 1484.00 - Don't Stop Believin' (2022 Remaster) by Journey, score: 1465.00 - Lay All Your Love On Me by ABBA, score: 1436.00 Search took: 856.386557ms Final prediction: Voilà by André Rieu , score: 5390686.00 Resources 🗃 How does Shazam work - Coding Geek (main resource) Song recognition using audio fingerprinting How does Shazam work - Toptal Creating Shazam in Java Author ✒ Chigozirim Igweamaka Check out my other GitHub projects. Connect with me on LinkedIn. Follow me on Twitter. License 🔒 This project is licensed under the MIT License - see the LICENSE file for details.",
    "commentLink": "https://news.ycombinator.com/item?id=41127726",
    "commentBody": "I recreated Shazam's algorithm with Go (github.com/cgzirim)232 points by ccgzirim 8 hours agohidepastfavorite63 comments halfmatthalfcat 5 hours agoFYI - If this is a true reproduction of Shazam, it’s under patent by Apple through at least March 2025[1]. [1] https://patents.google.com/patent/US7627477 reply Someone 3 hours agoparent“An Industrial-Strength Audio Search Algorithm”, the paper where Shazam describes their algorithm (https://www.ee.columbia.edu/~dpwe/papers/Wang03-shazam.pdf) doesn’t have a clear publication date, but https://www.researchgate.net/publication/220723446_An_Indust... indicates it is from 2003. That patent was filed in the US on 2004-10-21. IANAL, but to me, that’s a point against that patent in the USA. reply refibrillator 1 hour agorootparentActually the provisional patent # 60/376,055 was filed on April 25 2002. So if the paper was indeed published in Oct 2003 then all is well. reply kajecounterhack 1 hour agorootparentprevHow is it a point against the patent if the paper was written by someone under the employment of Shazam? Isn't the point of the patent to award the innovator with the right to profit from the innovation? reply Someone 34 minutes agorootparentThat it was written by someone under the employment of Shazam makes it likely that it describes their algorithm, but for patent protection, what matters is that you can’t apply for a patent for an invention that has been published. https://www.science.org/content/article/patent-first-publish...: “According to U.S. law, a patent cannot be obtained if an invention was previously known or used by other people in the U.S., or was already patented or published anywhere in the world. Furthermore, publicly using or selling an invention more than 1 year prior to filing a patent application completely bars you from ever winning a patent on that invention. […] In Europe, for instance, there is no 1-year grace period--the chances of winning patent protection is lost the instant an invention becomes public” reply mgillett54 35 minutes agorootparentprevYou only get a one year grace period after first public discloser to file for a patent in the US. So if the dates in this scenario are: - paper in 2003 - patent 2004-10-21 Only if the paper was released between 2003-10-22 and 2003-12-31 would it meet the one year grace period requirement. Looks like it’s not relevant in this case since they got a provisional patent in 2002, but that’s likely what the above was referring to as “a point against that patent”. reply Thaxll 3 hours agoparentprevI remember a popular HN post from 10 years ago, that was pulled or the source was pulled because Shazam legally threatened the disclosure of the algorithm. I think it's actually the Google drive file pdf capture from OP's article. reply refibrillator 3 hours agorootparentHere is a link to that HN thread from 2013: https://news.ycombinator.com/item?id=5723863 reply maeln 5 hours agoparentprevSo not enforceable anywhere else than in the U.S. reply concerndc1tizen 29 minutes agorootparentAny seller of software would be liable for selling software to US customers without a patent license. I'm curious about the legal consequences of freely distributed software (e.g. open source). I wonder if the author/provider could be held liable if they: - knowingly (passively) or actively market to US customers (e.g. provide support) - are aware that US users are using it, and take no actions to prevent its distribution etc. Can someone share their knowledge on this? If European software incidentally infringes a US patent, and it is distributed freely, is the provider then liable? E.g. is Github basically liable for restricting US users from access to (distributing) patent infringing software? reply colejohnson66 4 hours agorootparentprevThere are other patents for their implementation, and all are filed in multiple countries. Look at the blue sidebar under \"Worldwide applications\". The linked one is just for the US version of a singular patent. It had applications in 14 other countries and WIPO, 6 of which are still active (plus US). reply csmpltn 37 minutes agoparentprevIt's: (1) deriving a simple fingerprint from the FFT of the audio signal (2) simple indexing (3) simple similarity search You need the signatures of all music on earth for this to work though ;) reply acedTrex 3 hours agoparentprevSo you are saying to clone the repo now reply amelius 5 hours agoparentprevFigure 1 looks interesting since it has both a time and frequency axis, when usually signals have either a time __or__ frequency axis. Now I'm curious how the Fourier (?) transform of a signal at a __single__ given timepoint is even defined ... reply jamessb 4 hours agorootparentThe concepts you are looking for are the short-time Fourier transform and spectrogram: https://en.wikipedia.org/wiki/Short-time_Fourier_transform https://en.wikipedia.org/wiki/Spectrogram reply earthnail 2 hours agorootparentprevJamessb already linked to the right terms. One thing to add is that there is always a tradeoff between time and frequency resolution on short time Fourier transforms. You just can’t have both. It’s always a somewhat unsatisfying tradeoff that still works well in practice. reply 01HNNWZ0MV43FF 1 hour agorootparentI found this out when I was trying to turn an ordinary 5 dollar thrifted musical keyboard into a midi controller by plugging it into my PC, putting it on \"sine wave\" and using a Goertzel detector The latency for detecting audio-frequency waves is quite bad This also stymied my desire to put digital audio onto a vinyl record :( literally not enough bandwidth reply throwaway2562 4 hours agoparentprevSoon! reply mathfailure 5 hours agoparentprevnext [2 more] [flagged] halfmatthalfcat 5 hours agorootparentI thought my comment would be obvious but anyone using this code for profit within a jurisdiction that honors this patent would be exposed to potential litigation from Apple. reply shoggouth 4 hours agoparentprevI was under the impression that patents aren’t enforceable on open source projects. I assume I am wrong? reply colejohnson66 4 hours agorootparentYes. Just because something is open source doesn't mean it's unbound by IP laws. reply ndriscoll 1 hour agorootparentIt's not whether \"IP\" laws apply; it's whether source code itself is in scope for patents. Source code is a description of an algorithm, which in principle is what the software patent is supposed to be providing anyway. Patents shouldn't be relevant here for the same reason they aren't relevant to what you write in e.g. a textbook on signal processing where you might find an exact description of how Shazam works. Compiling and running that source code on your computer/as part of a wider system may violate a patent, but my impression was that patents are not relevant to the actual code. Are there test cases in the US around pure source distribution of a patented algorithm? Particularly post-Alice? reply concerndc1tizen 25 minutes agorootparentI wonder if the massive amount of open source software can now be used as elaborate 'prior art' in a way that basically invalidates any software patent that is awarded after the source had been made available? I.e. if any algorithm was already implemented, in some variation, then the patent is not valid? For example, for the infamous Amazon 'one click purchase', if a similar pattern was used, maybe a 'one click start vacuum cleaner robot', would it that patent then be invalid? reply lights0123 3 hours agorootparentprevPatents are enforceable in the US for even personal use without distribution. reply VierScar 5 hours agoparentprevI dunno how software patents work but I was under the impression that unless you basically copy paste their code, the courts wouldn't consider it patent infringement as you can't patent the function, but rather the specific thing itself which for software is the exact code itself. But if I'm not understanding something please correct me. reply mcfedr 53 minutes agorootparentSoftware patents are magic, you just start your process with 'on a computer do X' and because computers are a piece of hardware you can patent anything you like reply wlesieutre 4 hours agorootparentprevYou’re thinking of copyright, which covers a specific creative expression. Patents are more general on how something is done and would cover different code that works the same way. reply amelius 5 hours agorootparentprevThis cannot be true because if you copied a physical design and made a few irrelevant modifications then it's still infringement. reply dawnerd 3 hours agorootparentprevOverly simplistic: patents is the process not strictly design. Edit: just to be clear there are design patents too, but I don’t think they’d be granted for software. reply jokoon 51 minutes agoprevThis is useless unless you have all the songs on earth Algorithm don't matter, only data matters reply 0cf8612b2e1e 2 minutes agoparentAlthough, would be curious how good you could get to isolating to a single artist. If you had say one exemplar fingerprint per artist, could an out of dataset fingerprint from their discography cluster to that artist? Obviously not for artists who transitioned musical styles. Or is the algorithm more feature hash than a clusterable feature vector? reply nwsm 3 minutes agoparentprevHere we have an open-source algorithm that is useful to anyone with data. It doesn't have to be music reply 38 43 minutes agoparentprevthe opposite of what you said is true reply yazmeya 4 hours agoprevI enjoyed this talk at the DAFx17 conference by Avery Wang, co-founder of Shazam. It goes a little into the theory behind the algorithm, and looks at some of the more practical issues (background noise, etc.): https://www.youtube.com/watch?v=YVTnj3OIhwI reply DevX101 1 hour agoparentAdding this to the watch list. Reading this paper was one of the first times I got a 'wow' moment around computing algorthms. reply vegabook 5 hours agoprevRecently found Shazam is less accurate - somehow soundhound is giving me better results. On Shazam I'm getting a lot of results from Asian musical traditions which is great, if it wasn't the wrong song. Maybe they need to improve the algo if they've increased the range of music they will select from? Seems now there's a lot more hash table collision[1]. [1] https://github.com/cgzirim/not-shazam?tab=readme-ov-file#resources--card_file_box reply cglan 5 hours agoparentSoundhound has always been better than Shazam. It can even pick up people singing and extremely quiet songs reply jedberg 3 hours agorootparentIn my sample of one song, I have to disagree. I played Watermelon by Mezerg, which is admittedly not very popular, and Soundhound couldn't get it with two tries, but Shazam picked it up in less than two seconds. reply robbomacrae 1 hour agorootparentI work at SoundHound. If it didn't get it in two tries it's likely we didn't have that song in the database. Both Shazam and SH have knowledge gaps. reply blackeyeblitzar 7 minutes agoprevI’ve heard that the Google phones have a built in music recognition feature that is the best implementation of this stuff. Anyone know what their approach was? Apart from that I always have felt Soundhound was better than Shazam reply Cieric 3 hours agoprevWhile the project does look nice to use and modify. I'm not sure I personally would have posted it yet. - The instructions seem not to be the best to get it up and running (e.g. \"cd not-shazam\" and just a few lines later \"cd not-shazam/client\") - MongoDB is needed but information on how to hook it up/use it are absent (I would make the DB swapable and provide something less intrusive like sqlite) - If replacing MongoDB is not possible, I would provide a dockerfile and a docker compose to allow easy startup and testing. - The client npm install has 8 critical vulnerabilities, these might not actually matter but it makes me hesitant to continue testing - You might not care about the patent or the copyright, but I would still change the name at the very least. Github itself is located in the US and will remove the project if they receives a DMCA. - Last, this might not be as important, I would add a way to add songs from wav files. Not everything I'd want to test this with is on spotify or youtube. I'm not saying this to discourage you or anything, I just think the project needs that little extra bit of polish. Minor things will cause people to discredit or ignore a project. If I get around to it I might make a PR for the project. I want to experiment with audio matching outside of the music space, and your project seems like it'll be the easiest to modify. Edit: Formatting reply strongly-typed 1 hour agoprevThis is really cool. I’ve been itching to try building this exact kind of thing as part of my bucket list. reply ccgzirim 1 hour agoparentThanks. I'm glad it inspires you! It'd be awesome to see you take it on. You can clone it and develop it further. reply euroderf 55 minutes agoprevRun it as a daemon that displays every song in a UI notification ? reply theabhinavdas 23 minutes agoparentYou deserve reddit gold for this idea reply nwsm 2 minutes agorootparentI love spyware! reply KomoD 6 hours agoprevIf you insert Spotify songs, wouldn't it make more sense to output Spotify songs too? reply ccgzirim 5 hours agoparentIt would actually. But Spotify doesn't allow direct downloads so I had to find the songs on YouTube and download them from there. reply written-beyond 4 hours agorootparentYou're a G reply DandyDev 4 hours agoprevIsn’t the whole point of Shazam that you don’t know the song and want to find it? If you don’t know the song, hoeven you provide a Spotify link? reply zild3d 4 hours agoparentthis is a demo of the algorithm, not a full app / hosted service using it with a pre-populated database. The spotify link would be to fingerprint the song and add it to the database reply ccgzirim 4 hours agorootparentYou're right. The Spotify link is used solely to get details about the song. These details are then used to search for and download the song from YouTube. Afterward, the fingerprint for the song is created and added to the database. reply paxys 3 hours agoparentprevThe idea is that you add every Spotify song in the database, and then run your match against them. reply anticristi 3 hours agoprevI wonder how long until someone will simply smoosh a billion songs into a \"large song model\" and make all signal processing knowledge irrelevant. reply immibis 2 hours agoparentYou mean Suno? reply hactually 5 hours agoprevreally decent and nicely done Golang! I'll pull and play with it tomorrow! reply ccgzirim 3 hours agoparentThanks! I appreciate the compliment on my Golang; This is actually my first full-fledged project with the language, haha. Feel free to reach out if you have any issues running it. reply Philip-J-Fry 2 hours agoprevI think you've leaked your developer key here... https://github.com/cgzirim/not-shazam/blob/main/spotify/yout... reply zadokshi 2 hours agoparentDoes this mean he could accidentally get a $1 million credit card bill from google from someone using his key without his permission? (I don’t know how it works with google.) reply ccgzirim 1 hour agoparentprevOops... Thank you. I've disabled it. reply wmichelin 1 hour agoprevHardcoded sleeps for some reason, nice /s https://github.com/cgzirim/not-shazam/blob/888070f3434acbc0a... reply rvnx 20 minutes agoparentIt's to go around the ban of the IP / account by Spotify and to be softer with them, you have to wait between two requests to download songs. reply msie 42 minutes agoprev [–] I enjoyed reading the Go source. As opposed to the time I had to read some Ruby code. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "NotShazam is a song recognition tool similar to Shazam, utilizing Spotify and YouTube APIs.",
      "The project requires Golang, FFmpeg, MongoDB, and NPM for installation and setup.",
      "Users can clone the repository, install dependencies, and run commands to download songs, find matches, and manage fingerprints."
    ],
    "commentSummary": [
      "A developer has recreated Shazam's algorithm using the Go programming language and shared it on GitHub.",
      "The original Shazam algorithm is patented by Apple until at least March 2025, raising potential legal issues for those using or distributing the recreated version.",
      "The project has some technical and usability issues, such as incomplete setup instructions and critical vulnerabilities in dependencies, which need addressing for broader adoption."
    ],
    "points": 232,
    "commentCount": 63,
    "retryCount": 0,
    "time": 1722508161
  },
  {
    "id": 41125980,
    "title": "PyTorch – Torchchat: Chat with LLMs Everywhere",
    "originLink": "https://github.com/pytorch/torchchat",
    "originBody": "Chat with LLMs Everywhere torchchat is a small codebase showcasing the ability to run large language models (LLMs) seamlessly. With torchchat, you can run LLMs using Python, within your own (C/C++) application (desktop or server) and on iOS and Android. What can you do with torchchat? Run models via PyTorch / Python Chat Generate Run chat in the Browser Run models on desktop/server without python Use AOT Inductor for faster execution Running in c++ using the runner Run models on mobile Deploy and run on iOS Deploy and run on Android Evaluate a model Highlights Command line interaction with popular LLMs such as Llama 3, Llama 2, Stories, Mistral and more PyTorch-native execution with performance Supports popular hardware and OS Linux (x86) Mac OS (M1/M2/M3) Android (Devices that support XNNPACK) iOS 17+ (iPhone 13 Pro+) Multiple data types including: float32, float16, bfloat16 Multiple quantization schemes Multiple execution modes including: Python (Eager, Compile) or Native (AOT Inductor (AOTI), ExecuTorch) Installation The following steps require that you have Python 3.10 installed. # get the code git clone https://github.com/pytorch/torchchat.git cd torchchat # set up a virtual environment python3 -m venv .venv source .venv/bin/activate # install dependencies ./install_requirements.sh Commands The interfaces of torchchat are leveraged through Python Commands and Native Runners. While the Python Commands are enumerable in the --help menu, the latter are explored in their respective sections. python3 torchchat.py --help # Output usage: torchchat [-h] {chat,browser,generate,export,eval,download,list,remove,where,server} ... positional arguments: {chat,browser,generate,export,eval,download,list,remove,where,server} The specific command to run chat Chat interactively with a model via the CLI generate Generate responses from a model given a prompt browser Chat interactively with a model in a locally hosted browser export Export a model artifact to AOT Inductor or ExecuTorch download Download model artifacts list List all supported models remove Remove downloaded model artifacts where Return directory containing downloaded model artifacts server [WIP] Starts a locally hosted REST server for model interaction eval Evaluate a model via lm-eval options: -h, --help show this help message and exit Python Inference (chat, generate, browser, server) These commands represent different flavors of performing model inference in a Python enviroment. Models are constructed either from CLI args or from loading exported artifacts. Exporting (export) This command generates model artifacts that are consumed by Python Inference or Native Runners. More information is provided in the AOT Inductor and ExecuTorch sections. Inventory Management (download, list, remove, where) These commands are used to manage and download models. More information is provided in the Download Weights section. Evaluation (eval) This command test model fidelity via EleutherAI's lm_evaluation_harness. More information is provided in the Evaluation section. Download Weights Most models use Hugging Face as the distribution channel, so you will need to create a Hugging Face account. Create a Hugging Face user access token as documented here with the write role. Log into Hugging Face: huggingface-cli login Once this is done, torchchat will be able to download model artifacts from Hugging Face. python3 torchchat.py download llama3.1 Note This command may prompt you to request access to Llama 3 via Hugging Face, if you do not already have access. Simply follow the prompts and re-run the command when access is granted.* Additional Model Inventory Management Commands Running via PyTorch / Python The simplest way to run a model in PyTorch is via eager execution. This is the default execution mode for both PyTorch and torchchat. It performs inference without creating exporting artifacts or using a separate runner. The model used for inference can also be configured and tailored to specific needs (compilation, quantization, etc.). See the customization guide for the options supported by torchchat. Tip For more information about these commands, please refer to the --help menu. Chat This mode allows you to chat with an LLM in an interactive fashion. python3 torchchat.py chat llama3.1 Generate This mode generates text based on an input prompt. python3 torchchat.py generate llama3.1 --prompt \"write me a story about a boy and his bear\" Browser This mode allows you to chat with the model using a UI in your browser Running the command automatically open a tab in your browser. streamlit run torchchat.py -- browser llama3.1 Server Note: This feature is still a work in progress and not all endpoints are working This mode gives a REST API that matches the OpenAI API spec for interacting with a model Desktop/Server Execution AOTI (AOT Inductor) AOTI compiles models before execution for faster inference. The process creates a DSO model (represented by a file with extension .so) that is then loaded for inference. This can be done with both Python and C++ enviroments. The following example exports and executes the Llama3.1 8B Instruct model. The first command compiles and performs the actual export. python3 torchchat.py export llama3.1 --output-dso-path exportedModels/llama3.1.so Note If your machine has cuda add this flag for performance --quantize config/data/cuda.json when exporting. For more details on quantization and what settings to use for your use case visit our customization guide. Run in a Python Enviroment To run in a python enviroment, use the generate subcommand like before, but include the dso file. python3 torchchat.py generate llama3.1 --dso-path exportedModels/llama3.1.so --prompt \"Hello my name is\" Note: Depending on which accelerator is used to generate the .dso file, the command may need the device specified: --device (cudacpu). Run using our C++ Runner To run in a C++ enviroment, we need to build the runner binary. scripts/build_native.sh aoti Then run the compiled executable, with the exported DSO from earlier. cmake-out/aoti_run exportedModels/llama3.1.so -z `python3 torchchat.py where llama3.1`/tokenizer.model -l 3 -i \"Once upon a time\" Note: Depending on which accelerator is used to generate the .dso file, the runner may need the device specified: -d (CUDACPU). Mobile Execution ExecuTorch enables you to optimize your model for execution on a mobile or embedded device. Set Up ExecuTorch Before running any commands in torchchat that require ExecuTorch, you must first install ExecuTorch. To install ExecuTorch, run the following commands. This will download the ExecuTorch repo to ./et-build/src and install various ExecuTorch libraries to ./et-build/install. Important The following commands should be run from the torchchat root directory. export TORCHCHAT_ROOT=${PWD} ./scripts/install_et.sh Export for mobile Similar to AOTI, to deploy onto device, we first export the PTE artifact, then we load the artifact for inference. The following example uses the Llama3.1 8B Instruct model. # Export python3 torchchat.py export llama3.1 --quantize config/data/mobile.json --output-pte-path llama3.1.pte Note We use --quantize config/data/mobile.json to quantize the llama3.1 model to reduce model size and improve performance for on-device use cases. For more details on quantization and what settings to use for your use case visit our customization guide. Deploy and run on Desktop While ExecuTorch does not focus on desktop inference, it is capable of doing so. This is handy for testing out PTE models without sending them to a physical device. Specifically there are 2 ways of doing so: Pure Python and via a Runner Deploying via Python Deploying via a Runner Deploy and run on iOS The following assumes you've completed the steps for Setting up ExecuTorch. Deploying with Xcode Deploy and run on Android The following assumes you've completed the steps for Setting up ExecuTorch. Approach 1 (Recommended): Android Studio Approach 2: E2E Script Eval Note: This feature is still a work in progress and not all features are working Uses the lm_eval library to evaluate model accuracy on a variety of tasks. Defaults to wikitext and can be manually controlled using the tasks and limit args. See Evaluation Examples Eager mode: python3 torchchat.py eval llama3.1 --dtype fp32 --limit 5 To test the perplexity for a lowered or quantized model, pass it in the same way you would to generate: python3 torchchat.py eval llama3.1 --pte-path llama3.1.pte --limit 5 Models The following models are supported by torchchat and have associated aliases. Model Mobile Friendly Notes meta-llama/Meta-Llama-3.1-8B-Instruct ✅ Tuned for chat . Alias to llama3.1. meta-llama/Meta-Llama-3.1-8B ✅ Best for generate. Alias to llama3.1-base. meta-llama/Meta-Llama-3-8B-Instruct ✅ Tuned for chat . Alias to llama3. meta-llama/Meta-Llama-3-8B ✅ Best for generate. Alias to llama3-base. meta-llama/Llama-2-7b-chat-hf ✅ Tuned for chat. Alias to llama2. meta-llama/Llama-2-13b-chat-hfTuned for chat. Alias to llama2-13b-chat. meta-llama/Llama-2-70b-chat-hfTuned for chat. Alias to llama2-70b-chat. meta-llama/Llama-2-7b-hf ✅ Best for generate. Alias to llama2-base. meta-llama/CodeLlama-7b-Python-hf ✅ Tuned for Python and generate. Alias to codellama. meta-llama/CodeLlama-34b-Python-hf ✅ Tuned for Python and generate. Alias to codellama-34b. mistralai/Mistral-7B-v0.1 ✅ Best for generate. Alias to mistral-7b-v01-base. mistralai/Mistral-7B-Instruct-v0.1 ✅ Tuned for chat. Alias to mistral-7b-v01-instruct. mistralai/Mistral-7B-Instruct-v0.2 ✅ Tuned for chat. Alias to mistral. tinyllamas/stories15M ✅ Toy model for generate. Alias to stories15M. tinyllamas/stories42M ✅ Toy model for generate. Alias to stories42M. tinyllamas/stories110M ✅ Toy model for generate. Alias to stories110M. openlm-research/open_llama_7b ✅ Best for generate. Alias to open-llama. While we describe how to use torchchat using the popular llama3 model, you can perform the example commands with any of these models. Design Principles torchchat embodies PyTorch’s design philosophy details, especially \"usability over everything else\". Native PyTorch torchchat is a native-PyTorch library. While we provide integrations with the surrounding ecosystem (eg: Hugging Face models, etc), all of the core functionality is written in PyTorch. Simplicity and Extensibility torchchat is designed to be easy to understand, use and extend. Composition over implementation inheritance - layers of inheritance for code re-use makes the code hard to read and extend No training frameworks - explicitly outlining the training logic makes it easy to extend for custom use cases Code duplication is preferred over unnecessary abstractions Modular building blocks over monolithic components Correctness torchchat provides well-tested components with a high-bar on correctness. We provide Extensive unit-tests to ensure things operate as they should Community Contributions We really value our community and the contributions made by our wonderful users. We'll use this section to call out some of these contributions! If you'd like to help out as well, please see the CONTRIBUTING guide. Troubleshooting CERTIFICATE_VERIFY_FAILED Run pip install --upgrade certifi. Access to model is restricted and you are not in the authorized list Some models require an additional step to access. Follow the link provided in the error to get access. Installing ET Fails If ./scripts/install_et.sh fails with an error like Building wheel for executorch (pyproject.toml) did not run successfully It's possible that it's linking to an older version of pytorch installed some other way like via homebrew. You can break the link by uninstalling other versions such as brew uninstall pytorch Note: You may break something that depends on this, so be aware. Filing Issues Please include the exact command you ran and the output of that command. Also, run this script and include the output saved to system_info.txt so that we can better debug your issue. (echo \"Operating System Information\"; uname -a; echo \"\"; cat /etc/os-release; echo \"\"; echo \"Python Version\"; python --version || python3 --version; echo \"\"; echo \"PIP Version\"; pip --version || pip3 --version; echo \"\"; echo \"Installed Packages\"; pip freeze || pip3 freeze; echo \"\"; echo \"PyTorch Version\"; python -c \"import torch; print(torch.__version__)\" || python3 -c \"import torch; print(torch.__version__)\"; echo \"\"; echo \"Collection Complete\") > system_info.txt Disclaimer The torchchat Repository Content is provided without any guarantees about performance or compatibility. In particular, torchchat makes available model architectures written in Python for PyTorch that may not perform in the same manner or meet the same standards as the original versions of those models. When using the torchchat Repository Content, including any model architectures, you are solely responsible for determining the appropriateness of using or redistributing the torchchat Repository Content and assume any risks associated with your use of the torchchat Repository Content or any models, outputs, or results, both alone and in combination with any other technologies. Additionally, you may have other legal obligations that govern your use of other content, such as the terms of service for third-party models, weights, data, or other technologies, and you are solely responsible for complying with all such obligations. Acknowledgements Thank you to the community for all the awesome libraries and tools you've built around local LLM inference. Georgi Gerganov and his GGML project shining a spotlight on community-based enablement and inspiring so many other projects. Andrej Karpathy and his llama2.c project. So many great (and simple!) ideas in llama2.c that we have directly adopted (both ideas and code) from his repo. You can never go wrong by following Andrej's work. Michael Gschwind, Bert Maher, Scott Wolchok, Bin Bao, Chen Yang, Huamin Li and Mu-Chu Li who built the first version of nanogpt (DSOGPT) with AOT Inductor proving that AOTI can be used to build efficient LLMs, and DSOs are a viable distribution format for models. nanoGPT. Bert Maher and his llama2.so, which built on Andrej's llama2.c and on DSOGPT to close the loop on Llama models with AOTInductor. Christian Puhrsch, Horace He, Joe Isaacson and many more for their many contributions in Accelerating GenAI models in the \"Anything, Fast!\" pytorch.org blogs, and, in particular, Horace He for GPT, Fast!, which we have directly adopted (both ideas and code) from his repo. License torchchat is released under the BSD 3 license. (Additional code in this distribution is covered by the MIT and Apache Open Source licenses.) However you may have other legal obligations that govern your use of content, such as the terms of service for third-party models.",
    "commentLink": "https://news.ycombinator.com/item?id=41125980",
    "commentBody": "PyTorch – Torchchat: Chat with LLMs Everywhere (github.com/pytorch)202 points by constantinum 15 hours agohidepastfavorite32 comments fbuilesv 9 hours agoI'm not well versed in LLMs, can someone with more experience share how this compares to Ollama (https://ollama.com/)? When would I use this instead? reply Star_Ship_1010 2 minutes agoparentBest answer to this is from Reddit \"how does a smart car compare to a ford f150? its different in its intent and intended audience. Ollama is someone who goes to walmart and buys a $100 huffy mountain bike because they heard bikes are cool. Torchchat is someone who built a mountain bike out of high quality components chosen for a specific task/outcome with the understanding of how each component in the platform functions and interacts with the others to achieve an end goal.\" https://www.reddit.com/r/LocalLLaMA/comments/1eh6xmq/comment... Longer Answer with some more details is If you don't care about which quant you're using, only use ollama and want easy integration with desktop/laptop based projects use Ollama. If you want to run on mobile, integrate into your own apps or projects natively, don't want to use GGUF, want to do quantization, or want to extend your PyTorch based solution use torchchat Right now Ollama (based on llama.cpp) is a faster way to get performance on a laptop desktop and a number of projects are pre-integrated with Ollama thanks to the OpenAI spec. It's also more mature with more fit and polish. That said the commands that make everything easy use 4bit quant models and you have to do extra work to go find a GGUF model with a higher (or lower) bit quant and load it into Ollama. Also worth noting is that Ollama \"containerizes\" the models on disk so you can't share them with other projects without going through Ollama which is a hard pass for any users and usecases since duplicating model files on disk isn't great. https://www.reddit.com/r/LocalLLaMA/comments/1eh6xmq/comment... reply JackYoustra 11 minutes agoparentprevProbably if you have any esoteric flags that pytorch supports. Flash attention 2, for example, was supported way earlier on pt than llama.cpp, so if flash attention 3 follows the same path it'll probably make more sense to use this when targeting nvidia gpus. reply jerrygenser 9 hours agoparentprevOlamma currently has only one \"supported backend\" which is llama.cpp. It enables downloading and running models on CPU. And might have more mature server. This allows running models on GPU as well. reply Zambyte 6 hours agorootparentI have been running Ollama on AMD GPUs (which support for came after NVIDIA GPUs) since February. Llama.cpp has supported it even longer. reply tarruda 5 hours agorootparentHow well does it run in AMD GPUs these days compared to Nvidia or Apple silicon? I've been considering buying one of those powerful Ryzen mini PCs to use as an LLM server in my LAN, but I've read before that the AMD backend (ROCm IIRC) is kinda buggy reply SushiHippie 4 hours agorootparentI have an RTX 7900 XTX and never had AMD specific issues, except that I needed to set some environment variable. But it seems like integrated GPUs are not supported https://github.com/ollama/ollama/issues/2637 reply darkteflon 9 hours agorootparentprevOllama runs on GPUs just fine - on Macs, at least. reply Kelteseth 8 hours agorootparentForks fine on Windows with an AMD 7600XT reply amunozo 8 hours agorootparentprevI use it in Ubuntu and works fine too. reply ekianjo 7 hours agorootparentprevit runs on GPUs everywhere. On Linux, on Windows... reply gleenn 12 hours agoprevThis looks awesome, the instructions are basically a one-liner to get a Python program to start up a chat program, and it's optimized for a lot of hardware you can run locally like if you have an Nvidia GPU or Apple M processor. Super cool work bringing this functionality to local apps and to just play with a lot of popular models. Great work reply boringg 3 hours agoprevCan someone explain the use case? Is it so that I can run LLMs more readily in terminal instead of having to use a chat interface? I'm not saying it isn't impressive being able to swap but I have trouble understanding how this integrates into my workflow and I don't really want to put much effort into exploring given that there are so many things to explore these days. reply daghamm 12 hours agoprevDoes pytorch have better acceleration on x64 CPUs nowadays? Last time I played with LLMs on CPU with pytorch you had to replace some stuff with libraries from Intel otherwise your performance would be really bad. reply gleenn 11 hours agoparentI can't find it again in this doc but pretty sure it supports MKL which at least is Intel's faster math library. Better than a stick in the eye. Also certainly faster than plain CPUs but almost certainly way slower than something with more massively parallel matrix processing. reply sva_ 8 hours agoparentprevx86_64* reply suyash 2 hours agoprevThis is cool, how can I go about using this for my own dataset - .pdf, .html files etc? reply ein0p 1 hour agoprevSelling it as a “chat” is a mistake imo. Chatbots require very large models with a lot of stored knowledge about the world. Small models are useful for narrow tasks, but they are not, and will never be, useful for general domain chat reply ipunchghosts 7 hours agoprevI have been using ollama and generally not that impressed with these models for doing real work. I can't be the only person who thinks this. reply diggan 7 hours agoparentSame conclusion here so far. Tested out various open source models, maybe once or twice per month, comparing them against GPT-4, nothing has come close so far. Even closed source models seems to not far very well, so far maybe Claude got the closest to GPT-4, but yet to find something that could surpass GPT-4 for coding help. Of course, could be that I've just got used to GPT-4 and my prompting been optimized for GPT-4, and I try to apply the same techniques to other models where those prompts wouldn't work as great. reply wongarsu 6 hours agorootparentThey won't beat Claude or GPT-4. If you want a model that writes code or answers complex questions use one of those. But for many simpler tasks like summarization, sentiment analysis, data transformation, text completion, etc, self-hosted models are perfectly suited. And if you work on something where the commercial models are trained to refuse answers and lecture the user instead, some of the freely available models are much more pleasant to work with. With 70B models you even get decent amounts of reasoning capabilities reply ekianjo 7 hours agorootparentprev> various open source models what models did you try? There's a ton of new ones every month these days. reply diggan 7 hours agorootparentMost recently: Llama-3.1, Codestral, Gemma 2, Mistral NeMo. reply codetrotter 6 hours agorootparentWhich parameter counts, and which quantization levels? reply bboygravity 7 hours agoparentprevI wrote an automated form-filling Firefox extension and tested it with Ollama 3.1. Not perfect, quite slow, but better than any other form fillers I tested. I also tried to hook it up to Claude and so far its flawless (didn't do a lot of testing though). reply Dowwie 4 hours agoparentprevCan you share what kind of real work you're trying? reply derefr 3 hours agoparentprevWhat's your example of \"real work\"? Most \"well-known-name\" open-source ML models, are very much \"base models\" — they are meant to be flexible and generic, so that they can be fine-tuned with additional training for task-specific purposes. Mind you, you don't have to do that work yourself. There are open-source fine-tunes as well, for all sorts of specific purposes, that can be easily found on HuggingFace / found linked on applicable subreddits / etc — but these don't \"make the news\" like the releases of new open-source base models do, so they won't be top-of-mind when doing a search for a model to solve a task. You have to actively look for them. Heck, even focusing on the proprietary-model Inference-as-a-Service space, it's only really OpenAI that purports to have a \"general\" model that can be set to every task with only prompting. All the other proprietary-model Inf-aaS providers also sell Fine-Tuning-as-a-Service of their models, because they know people will need it. --- Also, if you're comparing e.g. ChatGPT-4o (~200b) with a local model you can run on your PC (probably 7b, or maybe 13b if you have a 4090) then obviously the latter is going to be \"dumber\" — it's (either literally, or effectively) had 95+% of its connections stripped out! For production deployment of an open-source model with \"smart thinking\" requirements (e.g. a customer-support chatbot), the best-practice open-source-model approach would be to pay for dedicated and/or serverless hosting where the instances have direct-attached dedicated server-class GPUs, that can then therefore host the largest-parameter-size variants of the open-source models. Larger-parameter-size open-source models fare much better against the proprietary hosted models. IMHO the models in the \"hostable on a PC\" parameter-size range, mainly exist for two use-cases: • doing local development and testing of LLM-based backend systems (Due to the way pruning+quantizing parameters works, a smaller spin of a larger model will be probabilistically similar in behavior to its larger cousin — giving you the \"smart\" answer some percentage of the time, and a \"dumb\" answer the rest of the time. For iterative development, this is no problem — regenerate responses until it works, and if it never does, then you've got the wrong model/prompt.) • \"shrinking\" an AI system that doesn't require so much \"smart thinking\", to decrease its compute requirements and thus OpEx. You start with the largest spin of the model; then you keep taking it down in size until it stops producing acceptable results; and then you take one step back. The models of this size-range don't exist to \"prove out\" the applicability of a model family to a given ML task. You can do it with them — especially if there's an existing fine-tuned model perfectly suited to the use-case — but it'll be frustrating, because \"the absence of evidence is not evidence of absence.\" You won't know whether you've chosen a bad model, or your prompt is badly structured, or your prompt is impossible for any model, etc. When proving out a task, test with the largest spin of each model you can get your hands on, using e.g. a serverless Inf-aaS like Runpod. Once you know the model family can do that task to your satisfaction, then pull a local model spin from that family for development. reply simonw 2 hours agorootparent\"There are open-source fine-tunes as well, for all sorts of specific purposes\" Have you had good results from any of these? I've not tried a model that's been fine-tuned for a specific purpose yet, I've just worked with the general purpose ones. reply jiratemplates 9 hours agoprevlooks great reply aklgh 9 hours agoprev [–] A new PyTorch feature. Who knew! How about making libtorch a first class citizen without crashes and memory leaks? What happened to the \"one tool, one job\" philosophy? As an interesting thought experiment: Should PyTorch be integrated into systemd or should systemd be integrated into PyTorch? Both seem to absorb everything else like a black hole. reply smhx 9 hours agoparent [–] it's not a new PyTorch feature. It's just a showcase of existing PyTorch features (including libtorch) as an end-to-end example. On the server-side it uses libtorch, and on mobile, it uses PyTorch's executorch runtime (that's optimized for edge) reply BaculumMeumEst 8 hours agorootparent [–] Did not know executorch existed! That's so cool! I have it on my bucket list to tinker with running LLMs on wearables after I'm a little further along in learning, great to see official tooling for that! https://github.com/pytorch/executorch reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Torchchat is a versatile codebase enabling seamless execution of large language models (LLMs) across platforms like Python, C/C++, iOS, and Android.",
      "Key features include interactive chat in CLI or browser, desktop/server execution without Python, faster execution with AOT Inductor, and mobile deployment.",
      "Supported models include Llama 3, Llama 2, Stories, and Mistral, with a focus on usability, simplicity, extensibility, and correctness, backed by extensive unit tests and community contributions."
    ],
    "commentSummary": [
      "PyTorch has introduced Torchchat, a tool for integrating Large Language Models (LLMs) across various platforms, including mobile and native apps.",
      "Torchchat offers more flexibility and customization compared to Ollama, which is better suited for easy integration with desktop/laptop projects.",
      "Torchchat supports advanced features like flash attention for NVIDIA GPUs and uses libtorch on servers and executorch on mobile devices."
    ],
    "points": 202,
    "commentCount": 32,
    "retryCount": 0,
    "time": 1722484094
  },
  {
    "id": 41124472,
    "title": "SnowflakeOS: Beginner friendly and GUI focused NixOS variant",
    "originLink": "https://snowflakeos.org/",
    "originBody": "SnowflakeOS GitHub Discord Matrix Simple, Immutable, Reproducible SnowflakeOS is a NixOS based Linux distribution focused on beginner friendliness and ease of use. Alpha Download Not yet ready for daily use! SnowflakeOS GitHub Discord Matrix chat Twitter Mastodon Source",
    "commentLink": "https://news.ycombinator.com/item?id=41124472",
    "commentBody": "SnowflakeOS: Beginner friendly and GUI focused NixOS variant (snowflakeos.org)197 points by tkz1312 19 hours agohidepastfavorite134 comments binkHN 18 hours agoThe site is bereft of details, but it appears to be related to https://snowfall.org, which has a little more detail. reply mtndew4brkfst 17 hours agoparentI'm a user of Nix for about seven years and finally decided back in March, during the second rehash of $sponsor controversy, that I'll stop investing and move away from the tech as soon as I have a suitable replacement. I've been critical of Nix for a variety of reasons along the way but one of those reasons is how so many people (and consultancies) seem hell-bent to set up their own little fiefdoms within the community. The community is already niche, we certainly didn't need people purposely driving further fragmentation and incompatibility with these frameworks with bad bus factor and NIH designs. I've seen a lot of tribalism and cargo culting around some of the other efforts in this vein, too. reply bsimpson 15 hours agorootparentI believe Snowflake is one of Jake Hamilton's projects. He's trying to make Nix more approachable through GUI tools etc. Unfortunately, he's also part of the mob that chased the founder out of the Nix project and decided it should be yet another battleground for identity politics. Like you, seeing the community entertain these stupid political fiefdoms makes me want nothing to do with NixOS. However, I might stick with it out of laziness though until SteamOS runs on 3rd party hardware. The Jovian project is a Nix-based SteamOS clone that's been working well on my Legion Go, and I don't want to spend the time back in tinkerland finding something to replace it. reply mtndew4brkfst 15 hours agorootparentLet me be very direct - I disagree quite a lot with your characterizations in this post. If anything, I am probably much more closely aligned with Jake's \"personal politics\", since I also signed the first open letter about rejecting military sponsorship for future events. I felt the second open letter was not well thought out or well argued, so I didn't sign that one, but I do think it's clearly a net positive for Eelco to step way way back and that he has been in no way contributing to healing or progress during this debacle. I resented people building fiefdoms because they're often commercially motivated and used to drive consulting engagements. They fragment the community on a deeply technical level, ruining code reuse and interoperability, for negligible technical improvements. I don't have any idea what the authors' views on project governance or human rights are, that wasn't a factor for me. reply sshine 12 hours agorootparent> it's clearly a net positive for Eelco to step way way back and that he has been in no way contributing to healing Just let people do their thing. You’re not a bad person if you have nothing wise to say about people being hurt, and lots to say about resolving dependency constraints. > fragment the community on a deeply technical level, ruining code reuse and interoperability Most Nix consultancies I encounter make highly reusable flakes. flake-parts, flake-utils, fenix. They have a small commercial spot in their package’s namespace, and the first reason you look them up is “I wonder if they’re doing other smart Nix things that I can copy”, and they usually do. reply kortilla 14 hours agorootparentprev> rejecting military sponsorship for future events Presumably you reject everything supported by money from DARPA? reply deletedie 13 hours agorootparentHe's rejecting the sponsor, not the product reply pjmlp 13 hours agorootparentI always find this moral duality quite interesting, the product only exists because of the sponsor. reply talldayo 5 hours agorootparentYou seem to be unfamiliar with the situation, then. The sponsor wasn't for NixOS itself, but a related in-person event. NixOS had existed for literal decades prior to this. reply diffeomorphism 11 hours agorootparentprevNo, it not because of \"the\" sponsor, but because of sponsoring in general. Replace the sponsor by any other company/institution/patreon/.... reply kortilla 13 hours agorootparentprevI highly doubt he would reject DARPA as a sponsor for NixOS. This was just celebrated by a bunch of safety people that have significant overlap with NixOS security goals: https://www.darpa.mil/program/translating-all-c-to-rust reply viraptor 13 hours agorootparentprevInsert \"yet you participate in society. curious!.jpg\" reply kortilla 13 hours agorootparentYou don’t understand that meme. DARPA is direct military money for a bunch of tech people are happy with supporting. They just pretend it’s not the military so they don’t have to have any hard moral conflicts. reply viraptor 12 hours agorootparentOh I do. We're chatting now on an evolution of DARPA network. If anyone rejects all DARPA projects, they're not on the internet. Yet you can be on the internet and make things a bit better by rejecting military sponsorship/influence in things you're involved in today. reply kortilla 12 hours agorootparentI should have been more clear. This set of people that don’t like sponsorship from Boeing, Lockheed, etc would absolutely swoon over a DARPA grant. reply darthrupert 11 hours agorootparentprevIn what way does rejecting military sponsorships make things better? reply mtndew4brkfst 6 hours agorootparentGonna answer your question at face value. Sponsorships are generally acknowledged with quid-pro-quo advertising opportunities - otherwise they'd be called silent donations. In the case of tech conferences like the inciting incident, that means your logo everywhere, maybe an ad spot in between talks, and booth space. You might get some intangible reputational benefits from whatever other sponsors are present if they are viewed as highly prestigious or respected. Might even have opportunities to do a talk by one of your employees, we've all been to conferences where a vendor conspicuously also has a talk that coincidentally features their products heavily. All in all, it can elevate your perceived legitimacy in various ways. Advertising might get you more business or more applicants and thereby grow your reach and success. In terms of my personal values I'm a pacifist. I don't want to see something I like(d), something I made modest code contributions to, used to advertise for a commercial military organization that manufactures equipment for violence. It's the same way a vegan probably doesn't want to see advertisements by the beef farming industry or that someone who cares about renewable energy and sustainability doesn't want to see sponsorship by someone whose holdings are a huge stake in coal mining and fossil-fuel power plants. In the case of the inciting incident, it wasn't a case of massive dollar amounts, it was ~$5k USD and it wouldn't have jeopardized the conference at all to say no thank you. reply darthrupert 5 hours agorootparentYeah, it makes sense if you're a pure pacifist, the \"all violence is wrong\" -type. I'm more of a pragmatic pacifist myself, which allows or even carefully supports violence for suppressing violence. I believe the USAF is generally speaking aligned with me on that. Which is why I'm not unhappy when they work with FOSS. reply talldayo 4 hours agorootparentI think the opposite of pragmatic pacifism is the military-industrial market. The expansion and brinkmanship of weapons development brings out the absolute worst qualities in privately owned businesses. If you think lock-in is bad when it's your phone or email account, imagine how horny investors get suggesting DRM for hand grenades. This escalates because the goal of defense companies isn't to defend America, but to make as much money as they can get away with. I'd like to think that I'm pragmatic as well, which is why I won't deny that NixOS would likely get used in conflict with or without event sponsor deals promoting it. However, if your in-person events pivot from a technically-focused gathering of like-minded individuals to a war council bankrolled by Anduril, I'd expect most attendees to be angry. Especially once you consider that the United States sponsors the export of weapons to countries that don't use violence for justifiable or proportional causes. reply exe34 12 hours agorootparentprevall you're doing is making DARPA funding have even more reach and success! reply bfrog 4 hours agorootparentprevThe second letter saying TL;DR \"fuck you Eelco, kind regards\". I'll never understand the motives here. Never. Please let me know when you've spent decades creating something and I'll be sure to shit all over you in kind. reply srid 15 hours agorootparentprevMeta-note to readers who are not completely familiar with the conflicts in the NixOS community. This is a good summary, The NixOS Conflict in Under 5 Minutes https://news.ycombinator.com/item?id=41126034 reply hitekker 2 hours agorootparentPutting aside the accusations of activist ideology, this paragraph seems key: > At a properly run company, if you are caught eating someone else's sandwich from the fridge, your boss will confront you and say \"hey, Bob, don't eat Ted's sandwiches.\" That will be the end of it. In an organization with weak leadership, however, the entire company will receive an email from HR in the afternoon dictating a company-wide seminar on sandwich theft prevention, a #sandwich-theft chatroom will be created, posters depicting sandwich thieves in an encircled red X will appear on the walls, etc. The latter is more akin to what happened in the Nix case I outlined. There was no leadership in place to deal with an isolated sandwich theft, so it now needed to discuss policies with the goal of ending sandwich theft forever and punishing all sandwich thieves globally. As an outsider, it looks like Nix had a weak leader who refused to mediate differences between people. He didn’t do what was right and just. His problem, and his irresponsibility, became everyone else’s problem and responsibility. A power vacuum but also a moral vacuum. reply ajb 13 hours agorootparentprevInteresting, but not convinced of its impartiality. There's a strange attempt here to link labour union organising to social activism, which is incorrect and ahistorical. And also irrelevant to nix, which is a community rather than an employer. Individual union organisers might also be social activists, but effective union organisers know that they need to a appeal to all employees regardless of their politics. And historically unions have been just as socially unreconstructed as companies, and subject to the same process of social activists pushing for their reform. reply anon291 5 hours agorootparent> Individual union organisers might also be social activists, but effective union organisers know that they need to a appeal to all employees regardless of their politics One need only look at labor's reaction to the Teamster's president's speech at the RNC to realize that this is clearly not the case. reply imp0cat 12 hours agorootparentprevThere are no impartial reporters, you gotta take it all in and decide for yourself. reply Eisenstein 9 hours agorootparentWhen a person is deeply involved with something that turned into a conflict and then they write their history of it, as is the case with the link above, then I would say that framing them as a 'reporter' is not accurate. reply srid 3 hours agorootparentOut of curiosity - what makes you think that the author of the link above, Chris McDonough (incidentally an author of the Pyramid Python web framework), is \"deeply involved\" with the NixOS conflict? reply Eisenstein 1 hour agorootparentIt is a firsthand account of someone in the community. They referenced no sources and gave a description of events based entirely on memory. They claimed their own involvement and interest in the outcomes. reply martinsnow 12 hours agorootparentprevWhy do these people always have to ruin good projects? reply irusensei 9 hours agorootparentPower tripping. Ever wonder why projects become \"foundations\" with heavy emphasis on non technical bureaucratic bloat, committees, forums, \"community managers\" with way too much power and so on? reply kreyenborgi 8 hours agorootparentThe main reason to become a foundation is to have some legal entity to deal with money. Some times projects get grants or donations or google summer of code mentor payments, and that can either go into a random account of whoever happened to be in contact with the donor, or it can be properly managed by a foundation with agreed-upon guidelines on where to store money and what it can be used on. reply nicce 11 hours agorootparentprevBecause it is good and people want to do selfish things. reply martinsnow 11 hours agorootparentThe end result is fragmented projects, worse developers and less activity. Congratulations. You got your social point across to the detriment of everyone. reply Eisenstein 13 hours agorootparentprevI don't know much about it but that summary seems completely unreliable: * it reads like the result of 'there was a power struggle and my side lost' * it falls back constantly to overly simple cause-and-effect answers to complicated problems * it clearly is trying to paint certain people as villains and dissecting their imagined motivations while excusing or ignoring the motivations of others reply yjftsjthsd-h 14 hours agorootparentprev> However, I might stick with it out of laziness though until SteamOS runs on 3rd party hardware. It's unofficial and I've not personally tried it, but isn't that https://github.com/HoloISO/releases ? reply Modified3019 14 hours agorootparentprevBazzite and ChimeraOS are good contenders for that use case if you weren’t aware of them, to the point that I am plannng on using one for setting up a system as a “gaming console” for a family member and an email howto should be good enough for minimal tech support on my part. reply tracker1 3 hours agorootparentJust setup ChimeraOS on an 8845HS box this past weekend and really liking it. I do wish there were a few more emulators configured in the box, and there are some rough edges (the second activated controller is always controller 1 in games for some reason). It's been relatively nice all around. I do wish there was some slightly better platform specific documentation though. reply ParetoOptimal 15 hours agorootparentprevnext [8 more] [flagged] mongol 15 hours agorootparentThank you for illustrating the problem with the Nix community so succintly. When someone brings up those words, I know immediately to distance myself from them. reply aktuel 13 hours agorootparentIt's more a problem of society in general. Freedom (like power) is a two-edged sword. Some people get drunk on it. reply lynx23 12 hours agorootparentprev+1 reply darthrupert 12 hours agorootparentprevIf they don't like fascists, why are they against the only serious anti-fascist force on this planet? reply lucideer 10 hours agorootparentWhat's the only serious anti-fascist force? reply brabel 8 hours agorootparentI suppose that's the American led industrial military complex? I bloody hate war and the military, but I have to agree with that one. While Russia, China & co. keep moving closer and closer to the fascism of pre-WWII world, the collective West seems to be the only force countering that, though parts of the US politics is showing signs of also falling into the seductive philosophy of fascism. reply PlutoIsAPlanet 8 hours agorootparentprevThese people wouldn't know what a fascist was even if Hitler took a dump in their cornflakes. Meaning of the word has been twisted and manipulated to refer to anyone who has a different opinion on something, to the benefit of actual neonazis and fascists. reply jm4 17 hours agorootparentprevI’ve noticed the same things, but I think it’s a symptom of Nix being so polarizing in the first place. I can’t think of another piece of software I dislike so much but I’m willing to put up with it because it’s just that good. Like I can’t wait for someone to come up with a better version. I suspect I’m not alone, and it causes some people to try to abstract away all the warts and sharp edges with these frameworks. Ultimately, it probably comes down to project leadership. There doesn’t seem to be a clear vision, consensus or anybody who can do some wrangling to get things going in a direction. reply ilc 17 hours agorootparentPeople have tried with things like guix and there's a few other Nix spinoffs. The issue is that: Nix/NixOS is here and JUST good enough. So replacing it will be hard. What is come up with has to solve things so much better that the community who has invested in NixOS and others sees enough light that it is worth moving over. That's gonna be rough. Given how hard nix (the language) is to deal with, I won't call it impossible, but... I will say, the successor is more likely to succeed if NixOS totally implodes, and I might go as far as to say... only if it implodes or offers substantial back compatibility so people can migrate. reply generalizations 16 hours agorootparentAs someone who has been vaguely watching the NixOS ecosystem, but never looked closely enough to see what those sharp edges are - is there a writeup somewhere, maybe a blog post or two, that goes over what's so good and bad about Nix? reply mtndew4brkfst 16 hours agorootparentThe most common critiques I personally see are that the syntax and language is unappealing for many folks, and that the docs are pretty frequently some combination of sparse/haphazard/stale. In my time I very often had to go read raw source to understand how to properly use some less-trivial constructs. I have enough of an FP background to find the language tolerable but not yet pleasant, or even particularly capable. It's absolutely a fair thing to not enjoy. The other major criticism that I think is even more defensible and less subjective is that incremental adoption is not very fun. Many things that are well supported on a mainstream Linux distro will not work OOTB in NixOS until some kind soul contributes the Nix-specific implementation of that thing. In some cases that's not even fundamentally possible. So you run into lots of cases where the first hit on a Google search will solve this thing if you're on Debian, but you're looking at hours of triage to do the same thing on NixOS instead. I have plenty of examples about things that are uniquely possible with NixOS too, but I don't like to evangelize anymore. reply ilc 14 minutes agorootparentprevTo answer the good part: If you've used a normal linux distro and installed GNOME.. and then decided \"That was dumb.\" and wanted to go back...and realize, you can't. There is no real way to get rid of Gnome sanely. (I can say the same of KDE and other massive packages.) On Nix, I can, I just remove it from the configuration, and basically reapply my config. No damage done. For tools I'll want to try out or maybe use 2 times in my life, I can just run them in shells that have them, and not add them. This all adds up to a much more pleasant experience. I won't say flawless, but... it beats much of what is out there. I do think people can take it to an extreme which isn't useful. I still have declarative dotfiles, unlike some. But, for just managing the OS and packages. I've found nothing better. Realize: Things that are clusterfucks to package like python are still clustefucks. But... otherwise... 9/10 would install again, language can take a long walk off a short pier. reply pxc 16 hours agorootparentprevIt's not exactly a writeup or review, but Ian Henry's blog series How to Learn Nix captures the surprises, good and bad, that a newbie exploring Nix is likely to encounter. Some of the problems he encounters may be outdated, as Nix and its documentation have both evolved since the start of the series. His experience is also somewhat shaped by his decision to rely solely on the documentation and the software itself for guidance, which he held to for quite a long time-- if you seek help from others earlier on you may get stumped less often. But overall it captures very well what getting to know Nix and its docs is like, including the emotional reactions to sharp edges. https://ianthehenry.com/posts/how-to-learn-nix/ reply aliasxneo 15 hours agorootparentprevI've been in the ecosystem for years, including working with core maintainers and using it professionally in a large context. I'll just summarize what ultimately turned me away: 1. The community is extremely polarizing. Not just politically, but even from just being a general contributor. Depending on who reviews your PR, you can have a very pleasant experience to a downright demeaning one. I get that every community isn't perfect, but after years of dealing with generally the same problem people, I just quit contributing. 2. The Nix language itself is relatively simple to grasp, but for one reason or another people tend to build it up into a rat's nest that becomes nigh impossible to reverse engineer. Because of it's laziness, the error messages are generally unhelpful, and debugging is nothing but pure pain. 3. The thing that makes Nix great (reproducibility) is also it's greatest pain point. Depending on your language, your packaging experience may be simple to downright infuriating. At one point I just stopped packaging NodeJS/Typescript applications and resorted to other means (and this, of course, tended to anger the fanatics). Bottom line is that most software wasn't built with Nix's constraints in mind which means it's generally always a battle to get things packaged correctly. 4. The kingdom building has continued to be a major problem. Just watch the Nix Discourse for a week and you'll likely see the same problem space reinvented at least a few times. For whatever reason, in the Nix world, it feels like _everyone_ thinks they can do it better. This becomes a serious problem when it comes time to actually producing things in Nix. In my time using it professionally, I had to change \"libraries\" dozens of times due to lack of maintenance/abandonment. I swear each programming language must have a dozen different libraries for packaging, each with strange bugs and missing implementations. I am one of the hopeful that something new and better will come out of Nix, but I have high doubts it will come from the community itself. reply kstenerud 14 hours agorootparentExactly this. My NAS and hypervisor run on NixOS, but I'm probably going to replace them with Debian again once I get around to it. Immutability and reproducibility are nice, but not nice enough to put up with the crazy. reply OhSoHumble 10 hours agorootparentprev> The community is extremely polarizing. Not just politically, but even from just being a general contributor. Depending on who reviews your PR, you can have a very pleasant experience to a downright demeaning one. I get that every community isn't perfect, but after years of dealing with generally the same problem people, I just quit contributing. God, I feel this. I ended up just stop trying to seek help because most of the time I'd come across the MOST self-righteous people I've ever met. I don't think Nix will ever be easy to use because half the community genuinely does not care about their fellow human beings enough to write software for their fellow human beings. reply spease 32 minutes agorootparent> I don't think Nix will ever be easy to use because half the community genuinely does not care about their fellow human beings enough to write software for their fellow human beings. This matches my experience as well. I’ve been trying to use nix either as a system package manager, package manager, or OS since 2019. It was first recommended to me in 2016. I’ve tried to use it for C++, Python, and Flutter development. I’ve tried to use it on MacOS and NixOS. There doesn’t seem to be any use case where it’s usable for regular people. I can use it, sometimes, but more often than not it breaks and fixing it becomes the project over the project I was trying to use it for, before I have to give up and abandon it for conventional, less aspirational but actually usable tools. Just the other day it broke because of a MacOS beta update. The suggested fix in a PR to reinstall it didn’t work. The uninstall instructions didn’t work. In the end, after some manual fidgeting and more ad hoc suggestions on PRs plus some informed guesswork on my part having to do with the ca store at various stages, I was able to restore my install to functioning. Every time I ran the install it was text-based and filled my screen with intermediate commands and asked me whether it should execute some command that nobody but a POSIX skilled person would understand. Even after trying to tell it not to bother me. The community has seemed obsessed with flakes that will fragment the ecosystem and lock nixpkgs into backwards compatibility (to some practical degree). Meanwhile when I tried to contribute back to nixpkgs, and an update broke my patch (a derivation that made specifying application derivations roughly as easy as homebrew), no one on the forums could tell me how to fix it. Now it seems like the community, or some fraction of it, is chasing social perfection while their own tool is in such a half-baked state that I can’t recommend it to anybody, and almost nobody technical that I interact with recognizes it. Meanwhile, in the time that nix has been…doing whatever it’s been doing, docker has become the de facto standard for reproducible environments. It’s hypothetically not as good, but practically it’s a whole lot easier to use, so now nix has to push back an entrenched competitor if it wants to become more than just this weird niche tool that nobody’s heard of. I guess if the community doesn’t care if people use their work or not, I can’t blame them if they want to spend their free time on theoretical solutions. But it seems more inability to recognize other people’s hardships and arrogance rather than intentional neglect. Someday I really hope someone figures this out, because having a cross-platform cross-purpose cross-language declarative package manager would be awesome. EDIT: Also, one thing that’s bothered me about the recent Nix drama has been how they treat their “own” people. What I’ve heard or seen project leadership or moderation doing has come across as capricious, spiteful, and entitled towards people who have invested huge amounts of time into Nix; regardless of the politics of the individuals involved. It’s turned me off from continuing to invest in Nix either as a contributor or a user (I was even questioning fixing my preexisting install, but I figured deciding on an alternative and switching right then would take more time). I’m hoping an alternative comes to light, or somehow I’ve misjudged the situation. reply mtndew4brkfst 15 hours agorootparentprevEvery point matches my experiences to a T. Well said. reply ilc 15 hours agorootparentprevThis matches what I see when I read the code base. reply ilc 15 hours agorootparentprevThe biggest one is: There's 1001 poorly documented ways to do things. So until you learn to read nix, have a nix LSP etc. It is a major PITA. You can be reading a .nix file and be like... \"What the ... is that?\" And sadly, you know you'll inflict it on some poor person later. reply pxc 15 hours agorootparentI've never used a language server for Nix but I do use the repl. Are any of the language server implementations good these days? reply mtndew4brkfst 15 hours agorootparentI most frequently used https://github.com/oxalica/nil and there is a C++ one I haven't tried that reuses code directly from the NixCpp implementation. reply crvdgc 6 hours agorootparentprev> only if it implodes or offers substantial back compatibility so people can migrate. Yeah, at this point, any successor would have to be compatible with nixpkgs, which means to embed the nix language in some way. My best migration experience is the vim->neovim one. It (almost) fully supports vimscript and yet runs Lua side-by-side, paving a great way to the full Lua adoption. reply dangus 15 hours agorootparentprevReplacing it is easy. I replaced it by never using it, and just using traditional Linux and traditional configuration management. Or for every use case where that setup sucks, using the containerization ecosystem of my choice instead. I personally struggle to figure out where the combination of those tools is failing anyone where Nix comes in and saves the day. All I ever hear about it is that it's a great concept and a great thing ruined by excessive difficulty and too many downsides. In that sense I'd rather stick to the devil I know. reply AJRF 7 hours agorootparentprev> I'm a user of Nix for about seven years and finally decided back in March, during the second rehash of $sponsor controversy, that I'll stop investing and move away from the tech as soon as I have a suitable replacement. Same for me. We were exploring the use of it across our company for doing the building part of our containers, but the seeping in of identity politics made me rip the whole initiative up, it's simply too risky as you can see very likely paths towards fragmentation and disruption if you use this tech. Such a shame. reply thower34234324 17 hours agorootparentprevWhat about GUIX ? I tried using it, but the slow-repos, and weird bugs on my laptop (which needs proprietary blobs) put me off. I very much would prefer using scheme to Nix lang but the eco-system is far smaller. reply brabel 7 hours agorootparentI really like the idea and architecture of GUIX and I find it like a better design overall than Nix... but unfortunately, being under the GNU, support for proprietary firmware and Operating Systems (i.e. Mac and Windows) makes it really hard for most of us who are using those systems and don't really feel like running a VM just to use whatever software. I wish they had a separate spinoff that just made sure their software can run on Windows and MacOS, something like exists for emacs, but I think that the challenges are pretty big as they appear to rely on Linux-only APIs? reply justahuman74 14 hours agorootparentprevDo we just need a compromise-happy downstream of guix, much like ubuntu of debian? reply mtndew4brkfst 16 hours agorootparentprevYeap, proprietary software and firmware are dealbreakers for me too. reply heisnotanalien 13 hours agorootparentprevI don't know much about the project but as an outsider it all just seems totally insane! People writing letters with screenshots of actions really? Liking a post becomes the equivalent to going on a political march or something? I can't help wonder if a lot of these problems would be avoided by more collaborative in person/talking and frankly more emotional awareness. It's all cognitive left-brain stuff - where is the emotional centre? reply esafak 17 hours agorootparentprevMoving to what? reply mtndew4brkfst 16 hours agorootparentUnfortunately still TBD. If I didn't have to support MacOS Guix would be somewhat attractive. I've also come around to enjoying systemd and have an Nvidia GPU in one machine, which are both things Guix doesn't wish to support either. If Nix disappeared overnight I'd probably be using chezmoi to fill in somewhat for Home Manager and mise to fill in somewhat for devShells, and some ansible to try to fill the gaps, and fairly bitter about it. I'm philosophically opposed to containers in the dev feedback loop, as I want native installation and performance for my language toolchains and editor and such. reply binwang 16 hours agoparentprevThe site you mentioned seem to just link to a bunch of GitHub repos. Neither site answers the questions new users care about the most, like why should I use this new OS and who are the people behind the project. reply hyperhopper 17 hours agoparentprevHow ironic that the post for the beginner friendly OS isn't beginner friendly reply mushufasa 6 hours agoprevCool! I had a friend using nixos as desktop daily (he also needed for development work at his company) and he ran int osome real usability issues, but which had nothing to do with the gui. For example, we were at a wework, and he could *NOT* connect to the corporate wifi and had to just use the 'guest' access. The corporate network requires a cert and is tied to your wework account id. I could do it on Ubuntu by following instructions. He tried following the same instructions, me even helping him over his shoulder, and it just simply did not work, even after we walked through all the same steps that I had done on ubuntu. We were both on gnome desktops. And using similar devices. So something was wrong with how the OS handled the networking, not related to the GUI or hardware. reply carlhjerpe 5 hours agoparentNixOS is very \"unopinionated\" and really quite shit after installation, there are a lot of things a normal distro would bundle and enable that nixos doesn't. Your colleagues problem is not spending years on his config! reply gessha 4 hours agorootparentAnecdotal evidence: A lot of the “normal” distros woild have the same problem 5-10 years ago. reply aniviacat 18 hours agoprevIs this still being worked on? The most recent commits in the pinned Github repos are two months old. For a project that considers itself \"Alpha\" and \"Not yet ready for daily use\" that's a pretty long time of inactivity. reply georgyo 18 hours agoparentIn the non-pinned, non-auto updated repos, I see commits from two weeks ago. Though the main contributors are pretty active with nixpkgs, so a lack of commits here doesn't necessarily mean they aren't working on improving snowflakeos, but working on getting improvements they need implemented upstream. reply Carrok 16 hours agoparentprevSheesh. People have lives. Such an absurdly high standard we place on open source maintainers. reply port19 3 hours agorootparentIn the alpha stage Also, how hard can it be to touch up on docs or some other small parts at least once a week? If you don't have the time for that maybe don't start a new project? reply Carrok 3 hours agorootparentMaybe they’re moving. Maybe they’re on vacation. Maybe they’re getting married or divorced. Maybe a family member just died. You want weekly doc updates? It’s open source my friend, make a PR or shut the hell up. Thanks for making my point for me. This is an absurd standard. “Don’t start a project uness you can commit to weekly updates for perpetuity.” reply aniviacat 2 hours agorootparentNo need to be rude. If someone creates a website for a project they are obviously trying to present it to potential users. That is at odds with not working on making the project actually usable. But as a different comment suggested, the project does still seem to be worked on, so I remain hopeful we might one day see a user friendly NixOS derivative mature. reply Carrok 1 hour agorootparentI was joking. However, as an open source maintainer myself I have had many people actually be rude to me for not doing X fast or often enough. No one owes you anything. Even if they committed the sin of making a website for the project. reply pxc 18 hours agoparentprevYeah, I think it is still being worked on. It's only got a handful of contributors. reply xarope 16 hours agoprevWhen I tried nix, I had the most utility from doing a nix-shell -p to get different envs for trying out different versions of apps/environments for dev work. But for a full system, given universal blue and other variants (e.g. bazzite seems to be having a lot of success on the steam deck), does nix still make sense? reply rgoulter 15 hours agoparent> for a full system ... does nix still make sense? In many ways, Nix is often \"second best at everything\". -- Since Nix can be difficult to deal with, it may often be a better choice to use some other tool for any particular use case. e.g. maybe using asdf is a better way to fetch tools (compared to nix-shell), or docker-compose is a simple way of running project-specific services locally (compared to devenv), or fedora silverblue is a simple way of running an immutable OS (compared to NixOS). I'd like to think that the benefits from buying into Nix allow easily getting the advantages. e.g. Nix is a more expressive way to build a Docker image or a VM compared to using a Dockerfile or Packer. For system wide configuration, NixOS allows system-wide configuration declared from a single starting point (possibly composed of several modules), and has those immutable OS benefits like trivial rollbacks. reply zxexz 15 hours agoparentprevIME, with flakes, yes. Fork nixpkgs and remove what you’re not using, manually cherry pick what you want. That’s not advice I’ve heard anyone give before, but it’s so nice to just have a a distro that is yours, and everything has a purpose. Not advice, just something that works for me on my personal machines. reply tkz1312 8 hours agoparentprevnixos is unmatched as a server OS, and a lifestyle choice as a desktop distro reply rcarmo 12 hours agoparentprevI use both now. I find Nix more useful for server environments (and sandboxes). For interactive use, Bluefin/Bazzite are nicer since they tend to cater to their own happy path. reply hakube 8 hours agoprevoh great. Another distribution. I think we need more developments on the Desktop Environments and less on new distros reply slightwinder 8 hours agoparentTo be fair, this is not just another flavor of Debian or fedora, but about a new promising strain, of which so far only a low number of flavors exist. So it might does add some value to the game. reply coretx 9 hours agoprevStart & sell as a charity, cash in as a commercial enterprise. The #1 scam in vogue right now. reply darby_nine 5 hours agoparentWhat does \"charity\" mean outside of the context of christianity? reply im3w1l 14 hours agoprevThis is a bit of an old video (11months) but it looks sleek https://www.youtube.com/watch?v=1XW3mMmN4VM reply colordrops 18 hours agoprevThis seems great, and I think would be an amazing distribution, but it doesn't seem that much visible progress has been made in a long while. If there is indeed progress happening behind the scenes, it would be much better if the devs did this in a more visible fashion, and did some evangelizing to attract more contributors and traction. reply Shekelphile 18 hours agoprevthe words 'beginner friendly' and nixos don't belong anywhere near each other reply yjftsjthsd-h 18 hours agoparentI can't see any reason they couldn't go together. Fully using nix is a trip off the deep end of the learning curve, but there's nothing preventing a beginner using a predefined nixos configuration so long as they stay inside the guiderails. With a bit of care, it should even be possible to let them enable whole add-in .nix files to do things like \"check this box to enable proprietary nvidia drivers\" (which includes a predefined module that handles that). reply poikroequ 14 hours agoparentprevActually, I think nixos could be a wonderful base for a beginner friendly OS, by limiting the user to very specific configurations which have been well tested. Don't allow the user to shoot themselves in the foot. But if you allow the user to start writing or modifying nix configurations, then all bets are off. reply zebomon 15 hours agoparentprevI think it should be pretty easy to pick up for anyone who has experience with any other Linux distro, or even just experience with command line. The docs were clear and current when I got started with it. reply tkz1312 8 hours agoparentprevhaving the raw power of nix/nixos hidden behind a normie friendly UI layer has insane potential. It basically eliminates any potential for horrible dependency conflicts and gives users an undo button for all but the deepest (i.e. bootloader / firmware) level changes to their system. nixpkgs is also the most comprehensive and up to date linux package set by a huge distance. reply Cloudef 16 hours agoparentprevI can see something where nix is used for the immutable base, and then the user installs apps using flatpak or similar. Kinda like how fedora silver blue and other immutable distros work. reply esjeon 18 hours agoparentprevArch has always been 'beginner friendly' according to Arch users, so why can't Nix? /s But, yeah, Nix can be really nasty to troubleshoot because of the lack of information. The Nix documentation is still PITA, and the much of usual Linux guides (which are everywhere on the internet) won't apply to Nix systems. You have to learn a lot. If what you want is a simple system with a web browser and some games, this should mostly work, but Fedora Silverblue would provide much more integrated and solid DE for that purpose. Being image-based release-based distro, it does offer pretty decent UX. Nix is rolling release, and everything is scattered just like Arch. reply thower34234324 16 hours agorootparentIn fairness, nixos is way easier to setup than arch; it also has a stable channel. The sharp bits only come to bite when you want to touch nix-lang (eg. write a flake; create a new package etc.). reply darthrupert 11 hours agorootparentYeah this is accurate. I've installed arch several times over the last decade and can mostly do it by heart without consulting the docs... but the amount of possible choices is just crazy and keeps going up. Also, things like disk encryption is easy to get wrong, leading to another boot from the usb/mount everything/fix loop. Nix has a graphical installer, which makes most of these choices for you. Different projects have added similar installers on top of Arch too, making its indtallation as easy. And in actual use Arch is much simpler. reply colordrops 18 hours agoparentprevThat's the whole point of snowflake OS. You obviously didn't spend any time looking into the project. The idea is to have GUIs that configure the OS like any other distro, and write and build the Nix configs behind the scenes. reply Qwertious 16 hours agorootparentWill the GUI write my custom package nixfile for me? Writing a configuration.nix isn't hard, but that's all that Snowflake sounds like it does. reply colimbarna 15 hours agorootparentIf you want to go beyond writing a configuration.nix then you don't want a beginner friendly anything. Configuration.nix does at least as much as any user-friendly operating system does. reply SAI_Peregrinus 6 hours agorootparentQuite a lot of the beginner-unfriendliness of NixOS is from the need to write your own packages. It's got the biggest repo out of all distros, but it's still pretty easy to need software that isn't in nixpkgs. Even easier if you're developing software, since then you need a Nix derivation to have a development environment which can build your software. reply ParetoOptimal 15 hours agorootparentprevThe goalposts isn't writing custom packages, it is accessibility and reproducibility benefits of NixOS to non-programmers. reply yjftsjthsd-h 13 hours agorootparentprev> Will the GUI write my custom package nixfile for me? What distro provides a GUI to write custom package specs for you? reply pxc 10 hours agorootparentA good editor and an LLM could maybe do something sort of useful for helping people customize packages. Used sparingly alongside programmatic generation of Nix code and old-fashioned templating, maybe it could even be reliable enough to be a win reply wejick 17 hours agoprevI have zero experience with nix, but I understood it has good build tool that many people use. But on what way nix is immutable I never know, anyone kind enough to explain ? reply somnic 15 hours agoparentFor the vast majority of files, whether those are executables, config files, or libraries, nix doesn't just put them in standard locations for Linux systems, but instead puts them in /nix/store/ with a directory derived from a hash of all its inputs and dependencies. For example, I have mpv in the nix store at /nix/store/08a907bw4csdc44408a992lnc9v2802c-mpv-0.38.0 and this has the default config, the binaries, completions, libraries, etc. Since the directory is titled based on the hash of the various inputs that go into building the package, when I run an upgrade it's not going to overwrite the old version of mpv, but instead it's going to put the new version in the nix store as well, at a different directory. Until you collect garbage, to clear out the old versions of things you're not using any more, nothing is deleted. So while you can add and delete entries to the nix store, each entry itself is read-only once it's been built, and thus immutable. reply senectus1 17 hours agoprevnext [3 more] [flagged] jm4 17 hours agoparentWhat’s wrong with it? It’s really a good description of what it is and Nix users immediately recognize the association. It’s a great name if you are trying to attract Nix people. reply pxc 16 hours agorootparentAs I'm sure you know, 'snowflake' has become a pejorative. But in the end I agree with you: that sarcastic usage is a recent and unimportant fad. Words have multiple connotations and those connotations are often context bound. And the intricacy and uniqueness of actual, literal, snowflakes are beautiful and interesting. reply websap 17 hours agoprevnext [10 more] [flagged] yjftsjthsd-h 17 hours agoparentNix is the Latin word for snow, hence its logo, and so a friendlier version/wrapper calling itself something snow-based in English seems very appropriate. reply g15jv2dp 16 hours agoparentprevIt's a very common word. Why should one company be allowed to appropriate it? reply badlibrarian 14 hours agorootparentThe dozen entries at the US trademark office may offer guidance. reply otabdeveloper4 12 hours agorootparent> US trademark office Good suggestion, I'll get right on it after the Chinese, Indian and German office. reply badlibrarian 12 hours agorootparentYup, that's how it works... for obvious reasons. reply yjftsjthsd-h 13 hours agorootparentprevMy non-lawyer understanding is that trademarks are pretty narrowly scoped; a database company and a Linux distro seem unlikely to be confused. So this is an excellent point, but maybe not the way you meant. reply badlibrarian 13 hours agorootparentTrademarks are monitored by prepaid, cocksure corporate attorneys who generate expensive-to-respond-to paper ultimately subject to the whims of judges and juries. It's often best to avoid a crowded space. Coconut and Swimwear/pajama vendors? Sure. Multi-billion dollar SaaS that hosts conferences? Maybe don't give them a reason to notice you. reply DaSHacka 13 hours agorootparentprevIronically, the mere fact alone that there are so many different entries for one word offers its own form of guidance. reply g15jv2dp 12 hours agorootparentprevThe existence of a dozen entries for that word reinforces my point... reply aktuel 13 hours agoprevWinter is coming. reply FounderBurr 15 hours agoprevI’m sure the flake/snow/water euphamisms are very clever but any ideas what this actually is or does? reply sweeter 14 hours agoparentIts a Nixos based Linux distribution where the Nix config and Nix flake is written for you and configured using a GUI. It attempts to bring the benefits of Nix to people who don't care to learn the insanity that the Nix language is (I say this as a full-time nixos user) a Nix Flake is basically just a file to pin packages against a specific version (ie go.mod cargo.lock etc...) you then write a config that defines your system state and packages that you want to be available. reply earthling8118 3 hours agorootparentThe language is absolutely not the problem. It's not a particularly difficult or complex language at all. In fact, it's pretty elegant and easy to understand the language. It's the things built on top of it that are difficult. reply drdaeman 12 hours agorootparentprev> learn the insanity that the Nix language is What's wrong with it? I'm not fond of the standard library (esp. the mkOverride and its friends), but the language itself feels fine. (Or am I just too used to it?) Personally, I would've preferred statically-typed language with proper GADTs, but Nix is far from what I'd call \"insanity\". Malbodge is insanity, JavaScript is a mess (mainly because of its birth defects), Nix is... not a dream language, has a few odd bits that one needs to get used to, but feels quite okay. reply pasc1878 11 hours agorootparentI understand Nix the language if it is all in one file. But try to call one file from another - it is confusing - the parameters are not explicit like a function call - they suddenly appear - adding more arguments is odd. Modules are not simple imports they add options and config to \"help\" you. I do wish they had used a well documented language with some form of modules rather than invent their own idiosyncratic one. reply drdaeman 2 hours agorootparentNix-the-language imports are dead simple: https://nixos.org/guides/nix-pills/05-functions-and-imports#... - `builtins.import ./foo.nix` makes it like we had `./foo.nix` copied and pasted in place of it. If we want to pass something, we make contents of `./foo.nix` a function (thus the frequently seen `import ./foo.nix {}` or `import ./foo.nix { inherit bar; }`). It’s the nixpkgs’ module convention system that is a little bit less straightforward as it relies on some conventions: https://nixos.wiki/wiki/NixOS_modules#Module_Imports_vs_buil... Oh, and Flakes have inputs (which are closer to built-in module system, as IIRC Flake support is baked into Nix itself rather than being a part of Nixpkgs like the module system), which is another different convention, but it all boils down to using `builtins.import` somewhere deep down the chain, all extra semantics in the libraries. Again, I would've preferred a language with module system built-in but it's not a bad design either - it's just minimalistic. IMHO, Ruby and Perl can be more confusing than this - and they're still sane (if we don't intentionally start having fun with their metaprogramming capabilities). But then Flakes probably wouldn't be a thing, so minimal core has its advantages too. Or disadvantages, as it all depends on the viewer. Either way, it’s all well documented. I still forget how it works now and then, but that’s my memory/attention span problem rather than a Nix/Nixpkgs issue. reply 1propionyl 15 hours agoparentprevPresumably it comes from the aphorism \"every snowflake is unique\", which ties into Nix flakes as being uniquely identifiable units of distributed software. reply megaloblasto 14 hours agoprev [–] I think Snowflake is an awesome project and addresses a lot of the complaints that newcomers have about NixOS. However, I don't personally use it. I've used NixOS to build an OS that is exactly what I want, and I can easily reproduce it on any machine and seamlessly run any of my projects on any of my devices. It has completely solved dependency hell for me. I don't exactly understand the complaints that Nix is hard to use. So is the C programming language. So is advanced mathematics. These things aren't meant for everyone to use. They are specific tools that solve specific problems and they do it well. Personally I think Nix should be a lot smaller. I think it should be a small set of tools that allows you to build reproducible systems and avoid dependency hell, and not too much more then that. Everything else should be up to the user. If you don't see the use, then there are so many other wonderful Linux distributions that will probably suit you better. I don't mean to be too harsh, I just think Nix is one of the most incredible pieces of software I've ever used, and I get tired of the hate. reply imiric 14 hours agoparent> I've used NixOS to build an OS that is exactly what I want, and I can easily reproduce it on any machine and seamlessly run any of my projects on any of my devices. That's great, but you've already passed the steep learning curve, gotten familiar with all the tooling and concepts, and know how to troubleshoot things when they go wrong. For many new users of Nix, these are major hurdles for adoption. The core principles of Nix are great: reproducibility, isolation, ability to revert to a previous state, etc. The problem is the UI to achieve all of that. I haven't used SnowflakeOS, and it's the first time I'm hearing about it, but if it can have the same benefits of NixOS while making the UI friendlier for new users, then it's a huge win in my book. I think that all operating systems should have these features, whether Nix itself is the one to deliver them or not. FWIW, I've used Nix(OS) for many years, and still can't say that I'm comfortable with it. It always takes me time to research and tinker when it behaves in unexpected ways, or to find out how to do a certain thing with it. This should just not be the case, even though it's partly on me for not sitting down to understand it thoroughly. The thing is that most people, even those technically minded, don't have that kind of patience. So anything developers can do to improve usability can bring these benefits to a larger user base, which is a noteworthy goal. reply conradludgate 11 hours agoparentprev [–] The last 3 times I tried to learn nix either 1. It just hasn't worked (excessive linking errors on macos) 2. Barrage of information. Should I use home manager? Use global config? I should be using overlays or flakes? There's too much going on and I've found too much conflicting information online. I'm not going near nix probably for another 3 years. It has a lot to fix before I can invest time into trying to learn it yet again reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "SnowflakeOS is a new, beginner-friendly Linux distribution based on NixOS, designed to simplify the user experience.",
      "The project is currently in its alpha stage, indicating it is not yet stable or suitable for daily use.",
      "Users and developers can connect and contribute through platforms like GitHub, Discord, Matrix, Twitter, and Mastodon."
    ],
    "commentSummary": [
      "SnowflakeOS is a user-friendly, GUI-focused variant of NixOS, designed to make NixOS more accessible through graphical configuration tools.",
      "The project is in its early stages with limited recent activity, and the website lacks detailed information.",
      "Some users are concerned about fragmentation and internal conflicts within the Nix community, prompting them to look for alternatives like SnowflakeOS."
    ],
    "points": 197,
    "commentCount": 134,
    "retryCount": 0,
    "time": 1722467171
  },
  {
    "id": 41130042,
    "title": "Stable Fast 3D: Rapid 3D Asset Generation from Single Images",
    "originLink": "https://stability.ai/news/introducing-stable-fast-3d",
    "originBody": "Introducing Stable Fast 3D: Rapid 3D Asset Generation From Single Images Product 1 Aug Key Takeaways: Stable Fast 3D generates high-quality 3D assets from a single image in just 0.5 seconds. Built on the foundation of TripoSR, Stable Fast 3D features significant architectural improvements and enhanced capabilities. The model has applications for game and virtual reality developers, as well as professionals in retail, architecture, design and other graphic-intense professions. The model is available on Hugging Face and is released under Stability AI Community License. Access the model easily on Stability AI API and on Stable Assistant chatbot and share your 3D creations in a 3D viewer and play with them in Augmented Reality. Get started with a free trial. We are excited to introduce Stable Fast 3D, Stability AI’s latest breakthrough in 3D asset generation technology. This innovative model transforms a single input image into a detailed 3D asset in just 0.5 seconds, setting a new standard for speed and quality in the field of 3D reconstruction. How It Works Users start by uploading a single image of an object. Stable Fast 3D then rapidly generates a complete 3D asset, including: UV unwrapped mesh Material parameters Albedo colors with reduced illumination bake-in Optional quad or triangle remeshing (adding only 100-200ms to processing time) Here is a video describing how the model works and the improvements vs previous models. Stable Fast 3D's unprecedented speed and quality make it an invaluable tool for rapid prototyping in 3D work, catering to both enterprises and indie developers in gaming and virtual reality, as well retail, architecture and design. You can also use the model easily on Stability AI API and on Stable Assistant chatbot where you can share your 3D creations in a 3D viewer and play with them in AR (on Augmented Reality (WebXR) compatible devices). Use Cases Stable Fast 3D has several use cases in gaming and movie production. Use the fast inference time during pre-production, where experimentation is key Static assets for games (Background objects, clutter, furniture) 3D models for E-commerce Fast model creation for AR/VR Speed Meets Quality Stable Fast 3D outperforms competitors in several key areas: Unmatched speed: 0.5 seconds per 3D asset generation on a GPU with 7GB VRAM or in close to a second on Stability AI API High-quality UV unwrapped mesh and material parameters Reduced illumination entanglement in textures Ability to generate additional material parameters and normal maps Compared to our previous SV3D model, Stable Fast 3D offers dramatically reduced inference times - 0.5 seconds versus 10 minutes - while maintaining high-quality output. View fullsize Research and Development Stable Fast 3D builds upon our previous work with TripoSR, but features a completely retrained model with significant architectural changes. These improvements allow for explicit mesh generation and incorporate novel techniques for fast textured mesh creation. A technical report on Stable Fast 3D is available here and highlights how we achieve fast inference speeds with reduced baked illumination and material parameters. View fullsize View fullsize Availability Stable Fast 3D model code is available on Github and model weights and demo space on Hugging Face. Stable Fast 3D is released under Stability AI Community License that allows non-commercial use and commercial use for individuals or organizations with up to $1M in annual revenue. Above this threshold, contact us for Enterprise Licenses. The model is also accessible via our API, and on Stable Assistant. The Project page is available here. Image Licenses Images in this blog post taken from GSO (License), OmniObject3D (License), as well as Stable Assistant. To stay updated on Stable Fast 3D and other Stability AI developments, sign up to our Newsletter, follow us on Twitter, Instagram, LinkedIn, and join our Discord Community. 3D Guest User",
    "commentLink": "https://news.ycombinator.com/item?id=41130042",
    "commentBody": "Stable Fast 3D: Rapid 3D Asset Generation from Single Images (stability.ai)191 points by meetpateltech 3 hours agohidepastfavorite57 comments timr 3 hours agoFor all of the hype around LLMs, this general area (image generation and graphical assets) seems to me to be the big long-term winner of current-generation AI. It hits the sweet spot for the fundamental limitations of the methods: * so-called \"hallucination\" (actually just how generative models work) is a feature, not a bug. * anyone can easily see the unrealistic and biased outputs without complex statistical tests. * human intuition is useful for evaluation, and not fundamentally misleading (i.e. the equivalent of \"this text sounds fluent, so the generator must be intelligent!\" hype doesn't really exist for imagery. We're capable of treating it as technology and evaluating it fairly, because there's no equivalent human capability.) * even lossy, noisy, collapsed and over-trained methods can be valuable for different creative pursuits. * perfection is not required. You can easily see distorted features in output, and iteratively try to improve them. * consistency is not required (though it will unlock hugely valuable applications, like video, should it ever arrive). * technologies like LoRA allow even unskilled users to train character-, style- or concept-specific models with ease. I've been amazed at how much better image / visual generation models have become in the last year, and IMO, the pace of improvement has not been slowing as much as text models. Moreover, it's becoming increasingly clear that the future isn't the wholesale replacement of photographers, cinematographers, etc., but rather, a generation of crazy AI-based power tools that can do things like add and remove concepts to imagery with a few text prompts. It's insanely useful, and just like Photoshop in the 90s, a new generation of power-users is already emerging, and doing wild things with the tools. reply leetharris 3 hours agoparent> For all of the hype around LLMs, this general area (image generation and graphical assets) seems to me to be the big long-term winner of current-generation AI. It hits the sweet spot for the fundamental limitations of the methods: I am biased (I work at Rev.com and Rev.ai), but I totally agree and would add one more thing: transcription. Accurate human transcription takes a really, really long time to do right. Often a ratio of 3:1-10:1 of transcriptionist time to original audio length. Though ASR is only ~90-95% accurate on many \"average\" audios, it is often 100% accurate on high quality audio. It's not only a cost savings thing, but there are entire industries that are popping up around AI transcription that just weren't possible before with human speed and scale. reply toddmorey 2 hours agorootparentAlso the other way around: text to speech. We're at the point where I can finally listen to computer generated voice for extended periods of time without fatigue. There was a project mentioned here on HN where someone was creating audio book versions of content in the public domain that would never have been converted through the time and expense of human narrators because it wouldn't be economically feasible. That's a huge win for accessibility. Screen readers are also about to get dramatically better. reply qup 2 hours agorootparent> a project mentioned here on HN where someone was creating audio book versions of content in the public domain Maybe this: https://news.ycombinator.com/item?id=40961385 reply toddmorey 1 hour agorootparentThat's the one! Thanks! reply timr 2 hours agorootparentprevI agree. I think it's more of a niche use-case than image models (and fundamentally harder to evaluate), but transcription and summarization is my current front-runner for winning use-case of LLMs. That said, \"hallucination\" is more of a fundamental problem for this area than it is for imagery, which is why I still think imagery is the most interesting category. reply llm_trw 2 hours agorootparentprevIs there any models that can do diarization well yet? I need one for a product and the state of the art, e.g. pyannote, is so bad it's better to not use them. reply throw03172019 1 hour agorootparentDeepgram has been pretty good for our product. Fast and fairly accurate for English. reply kkukshtel 2 hours agoparentprev> This general area (image generation and graphical assets) seems to me to be the big long-term winner of current-generation AI I think it's easy to totally miss that LLMs are just being completely and quietly subsumed into a ton of products. They have been far more successful, and many image generation models use LLMs on the backend to generate \"better\" prompts for the models themselves. LLMs are the bedrock reply mitthrowaway2 2 hours agoparentprev> it's becoming increasingly clear that the future isn't the wholesale replacement of photographers, cinematographers, etc. I'd refrain from making any such statements about the future;* the pace of change makes it hard to see the horizon beyond a few years, especially relative to the span of a career. It's already wholesale-replacing many digital artists and editorial illustrators, and while it's still early, there's a clear push starting in the cinematography direction. (I fully agree with the rest of your comment, and it's strange how much diffusion models seem to be overlooked relative to LLMs when people think about AI progress these days.) * (edit: about the future impact of AI on jobs). reply timr 2 hours agorootparentI mean, my whole comment is a prediction of the future, so that's water under the bridge. Maybe you're right and this is the start of the apocalypse for digital artists, but it feels more like photoshop in 1990 to me -- and people were saying the same stuff back then. > It's already wholesale-replacing many digital artists and editorial illustrators I think you're going to need to cite some data on a claim like that. Maybe it's replacing the fiverr end of the market? It's certainly much harder to justify paying someone to generate a (bad) logo or graphic when a diffusion model can do the same thing, but there's no way that a model, today, can replace a skilled artist. Or said differently: a skilled artist, combined with a good AI model, is vastly more productive than an unskilled artist with the same model. reply cjbgkagh 2 hours agorootparentWhat happens when the AI takes the low end of the market is that the people who catered to the low end now have to try to compete more in the mid-to-high end. The mid end facing increased competition has to try to move up to the high end. So while AI may not be able to compete directly with the high end it will erode the negotiating power and thus the earning potential of the high end. reply sroussey 2 hours agorootparentWe have watched this same process repeat a few times over the last century with photography. reply llm_trw 2 hours agoparentprev>For all of the hype around LLMs, this general area (image generation and graphical assets) seems to me to be the big long-term winner of current-generation AI. Let me show you the future: https://www.youtube.com/watch?v=eVlXZKGuaiE This is an LLM controlling an embodied VR body in a physics simulation. It is responding to human voice input not only with voice but body movements. Transformers aren't just chatbots, they are general symbolic manipulation machines. Anything that can be expressed as a series of symbols is a thing they can do. reply ibash 3 hours agoparentprev> anyone can easily see the unrealistic outputs without complex statistical tests. This is key, we’re all pre-wired with fast correctness tests. Are there other data types that match this? reply sounds 1 hour agorootparentSoftware (I mean the product, not the code) Mundane tasks that can be visually inspected at the end (cleaning, organizing, maintenance and mechanical work) reply batch12 2 hours agorootparentprevAudio to a lesser degree reply CuriouslyC 3 hours agoparentprevImage models are a great way to understand generate AI. It's like surveying a battlefield from the air as opposed to the ground. reply thrance 2 hours agoparentprevHonestly, I am still to see an AI generated image that makes me go \"oh wow\". It's missing those 10 last percents that always seem to elude neural networks. Also, the very bad press gen AI gets is very much slowing down adoption. Particularly among the creative-minded people, who would be the most likely users. reply jokethrowaway 38 minutes agorootparentHop on civitai There's plenty of mindblowing images reply derefr 2 hours agoparentprevI would argue the opposite — image generation is the clear loser. If you've ever tried to do it yourself, grabbing a bunch of LoRAs from Civitai to try to convince a model to draw something it doesn't initially know how to draw — it becomes clear that there's far too much unavoidable correlation between \"form\" and \"representation\" / \"style\" going on in even a SOTA diffusion model's hidden layers. Unlike LLMs, that really seem to translate the text into \"concepts\" at a certain embedding layer, the (current, 2D) diffusion models will store (and thus require to be trained on) a completely different idea of a thing, if it's viewed from a slightly different angle, or is a different size. Diffusion models can interpolate but not extrapolate — they can't see a prompt that says \"lion goat dragon monster\" and come up with the ancient-greek Chimera, unless they've actually been trained on a Chimera. You can tell them \"asian man, blond hair\" — and if their training dataset contains asian men and men with blonde hair but never at the same time, then they won't be able to \"hallucinate\" a blond asian man for you, because that won't be an established point in the model's latent space. --- On a tangent: IMHO the true breakthrough would be a model for \"text to textured-3D-mesh\" — where it builds the model out of parts that it shapes individually and assembles in 3D space not out of tris, but by writing/manipulating tokens representing shader code (i.e. it creates \"procedural art\"); and then it consistency-checks itself at each step not just against a textual embedding, but also against an arbitrary (i.e. controlled for each layer at runtime by data) set of 2D projections that can be decoded out to textual embeddings. (I imagine that such a model would need some internal \"blackboard\" of representational memory that it can set up arbitrarily-complex \"lenses\" for between each layer — i.e. a camera with an arbitrary projection matrix, through which is read/written a memory matrix. This would allow the model to arbitrarily re-project its internal working visual \"conception\" of the model between each step, in a way controllable by the output of each step. Just like a human would rotate and zoom a 3D model while working on it[1]. But (presumably) with all the edits needing a particular perspective done in parallel on the first layer where that perspective is locked in.) Until we have something like that, though, all we're really getting from current {text,image}-to-{image,video} models is the parallel layered inpainting of a decently, but not remarkably exhaustive pre-styled patch library, with each patch of each layer being applied with an arbitrary Photoshop-like \"layer effect\" (convolution kernel.) Which is the big reason that artists get mad at AI for \"stealing their work\" — but also why the results just aren't very flexible. Don't have a patch of a person's ear with a big earlobe seen in profile? No big-earlobe ear in profile for you. It either becomes a small-earlobe ear or the whole image becomes not-in-profile. (Which is an improvement from earlier models, where just the ear became not-in-profile.) [1] Or just like our minds are known to rotate and zoom objects in our \"spatial memory\" to snap them into our mental visual schemas! reply earthnail 1 hour agorootparentI think you’re arguing about slightly different things. OP said that image generation is useful despite all its shortcomings, and that the shortcomings are easy to deal with for humans. OP didn’t argue that the image generation AIs are actually smart. Just that they are useful tech for a variety of use cases. reply puppycodes 53 minutes agoprevI really can't wait for this technology to improve. Unfortunately just from testing this it seems not very useful. It takes more work to modify the bad model it approximates from the image output than starting with a good foundation from scratch. I would rather see something that took a series of steps to reach a higher quality end product more slowly instead of expecting everything to come from one image. Perhaps i'm missing the use case? reply MrTrvp 1 minute agoparentPerhaps it'll require a series of segmentation and transforms that improves individual components and then works up towards the full 3d model of the image. reply woolion 1 hour agoprevThis is the third image to 3D AI I've tested, and in all cases the examples they give look like 2D renders of 3D models already. My tests were with cel-shaded images (cartoony, not with realistic lighting) and the model outputs something very flat but with very bad topology, which is worse than starting with a low poly or extruding the drawing. I suspect it is unable to give decent results without accurate shadows from which the normal vectors could be recomputed and thus lacks any 'understanding' of what the structure would be from the lines and forms. In any case it would be cool if they specified the set of inputs that is expected to give decent results. reply quitit 1 hour agoparentIt might not just be your tests. All of my tests of img2mesh technologies have produced poor results, even when using images that are very similar to the ones featured in their demo. I’ve never got fidelity like what they’ve shown. I’ll give this a whirl and see if it performs better. reply mft_ 2 hours agoprevI'm really excited for something in this area to really deliver, and it's really cool that I can just drag pictures into the demo on HuggingFace [0] to try it. However... mixed success. It's not good with (real) cats yet - which was obvs the first thing I tried. It did reasonably well with a simple image of an iPhone, and actually pretty impressively with a pancake with fruit on top, terribly with a rocket, and impressively again with a rack of pool balls. [0] https://huggingface.co/spaces/stabilityai/stable-fast-3d reply talldayo 3 hours agoprev> 0.5 seconds per 3D asset generation on a GPU with 7GB VRAM Holy cow - I was thinking this might be one of those datacenter-only models but here I am proven wrong. 7GB of VRAM suggests this could run on a lot of hardware that 3D artists own already. reply calini 3 hours agoprevI'm going to 3D print so much dumb stuff with this. reply jsheard 3 hours agoparentThey're still hesitant to show the untextured version of the models so I would assume it's like previous efforts where most of the detail is in the textures, and the model itself, the part you would 3D print, isn't so impressive. reply mft_ 2 hours agorootparentYou can download a .glb file (from the HuggingFace demo page) and open it locally (e.g. in MS 3D Viewer). I'm looking at a mesh from one of the better examples I tried and it's actually pretty good... reply jayd16 2 hours agorootparentprevYou know I do wonder about this. If its just for static assets does it really matter? In something like Unreal, the textures are going to be virtualized and the geometry is going to be turned in to LODed triangle soup anyway. Has anyone tried to build an Unreal scene with these generated meshes? reply jsheard 1 hour agorootparentUsually the problem is the model itself is severely lacking in detail, sure Nanite could make light work of a poorly optimized model but it's not going to fix the model being a vague blob which doesn't hold up to close scrutiny. reply kaibee 1 hour agorootparentGenerate the accompanying normal map and then just tesselate it? reply yazzku 2 hours agorootparentprevI was going to comment on the same; these 3d reconstructions often generate a mess of a topology, and this post does not show any of the mesh triangulations, so I assume they're still not good. Arguably, the meshes are bad even for rendering. reply dlivingston 2 hours agorootparentPresumably, these meshes can be cleaned up using standard mesh refinement algorithms, like those found in MeshLab: https://www.meshlab.net/#features reply Keyframe 2 hours agorootparentHopefully that's in the (near) future, but as of now there still exists 'retopo' in 3D work for a reason. Just like roto and similar menial tasks. We're getting there with automation though. reply fragmede 51 minutes agoparentprevhueforge reply Y_Y 1 hour agoprevIt really looks like they've been doing that classic infomercial tactic of desaturating the images of the things they're comparing against to make theirs seen better. reply ksec 1 hour agoprevGiven the Graphics Asset part of AA or AAA Games are the most expensive, i wonder if 3D Asset Generation could perhaps drastically lower that by 50% or more? At least in terms of same output. Because in reality I guess artist will just spend more time in other areas. reply hansc 1 hour agoprevLooks very good on examples, but testing a few Ikea chairs or a Donald Duck image gives very wrong results. You can test here: https://huggingface.co/spaces/stabilityai/stable-fast-3d reply specproc 3 hours agoprevBe still my miniature-painting heart. reply msp26 3 hours agoprevYou can interact with the models on their project page: https://stable-fast-3d.github.io/ reply bloopernova 3 hours agoprevCloser and closer to the automatic mapping drones from Prometheus. I wonder what the optimum group of technologies is that would enable that kind of mapping? Would you pile on LIDAR, RADAR, this tech, ultrasound, magnetic sensing, etc etc. Although, you're then getting a flying tricorder. Which could enable some cool uses even outside the stereotypical search and rescue. reply pzo 38 minutes agoparentYou already have depth anything v2 that can generate depthmap in realtime even on iPhone. Quality is pretty good but probably will be even improved in the future. Actually in many ways those depthmaps are much better quality than iPhone Lidar or Truedepth camera (that cannot handle transparent, metalic, reflective surfaces and also they have a big noise). https://github.com/DepthAnything/Depth-Anything-V2 https://huggingface.co/spaces/pablovela5620/depth-compare https://huggingface.co/apple/coreml-depth-anything-v2-small reply sorenjan 2 hours agoparentprevYou don't need or want generative AI for mapping, you \"just\" need lidar and drones for slam. https://www.youtube.com/watch?v=1CWWP9jb4cE reply alsodumb 2 hours agoparentprevAre you talking about mapping tunnels with drones? That's already done and it doesn't really need any 'AI': it's plain old SLAM. DARPA's subterranean challenge had many teams that did some pretty cool stuff in this direction: https://spectrum.ieee.org/darpa-subterranean-challenge-26571... reply nycdatasci 3 hours agoparentprevHigh-res images from multiple perspectives should be sufficient. If you have a consumer drone, this product (no affiliation) is extremely impressive: https://www.dronedeploy.com/ You basically select an area on a map that you want to model in 3d, it flies your drone (take-off, flight path, landing), takes pictures, uploads to their servers for processing, generates point cloud, etc. Very powerful. reply thetoon 3 hours agorootparentWhat you could do with WebODM is already quite impressive reply nextworddev 1 hour agoprevFor those reading from Stability - just tried it - API seems to be down and the notebook doesn't have the example code it claimed to have. reply kleiba 2 hours agoprevThis is good news for the indie game dev scene, I suppose? reply jayd16 2 hours agoparentThe models aren't really optimized for game dev. Fine for machinima, probably. reply quantumwoke 3 hours agoprevGreat result. Just had a play around with the demo models and they preserve structure really nicely; although the textures are still not great. It's kind of a voxelized version of the input image reply nwoli 2 hours agoprevHuggingface space to try it https://huggingface.co/spaces/stabilityai/stable-fast-3d reply causi 1 hour agoprevMan it would be so cool to get AI-assisted photogrammetry. Imagine that instead of taking a hundred photos or a slow scan and having to labor over a point cloud, you could just take like three pictures and then go down a checklist. \"Is this circular? How long is this straight line? Is this surface flat? What's the angle between these two pieces?\" and getting a perfect replica or even a STEP file out of it. Heaven for 3D printers. reply ww520 2 hours agoprev [–] This is a great step forward. I wonder whether RAG based 3D animation generation can be done with this. 1. Textual description of a story. 2. Extract/generate keywords from the story using LLM. 3. Search and look up 2D images by the keywords. 4. Generate 3D models from the 2D images using Stable Fast 3D. 5. Extract/generate path description from the story using LLM. 6. Generate movement/animation/gait using some AI. ... 7. Profit?? reply nwoli 2 hours agoparent [–] Pre generate a bunch of images via sdxl and convert to 3d and then serve nearest mesh after querying reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Stable Fast 3D generates high-quality 3D assets from a single image in just 0.5 seconds, making it highly efficient for various industries like gaming, VR, retail, and architecture.",
      "Built on TripoSR, it features significant improvements, including fast textured mesh creation and reduced illumination entanglement, and is available under the Stability AI Community License on Hugging Face.",
      "Accessible via Stability AI API and Stable Assistant chatbot, it allows users to share and play with 3D creations in Augmented Reality, with model code on GitHub and demo on Hugging Face."
    ],
    "commentSummary": [
      "Stability AI has introduced \"Stable Fast 3D,\" a tool for rapid 3D asset generation from single images, capturing significant interest in the tech community.",
      "The tool promises to generate 3D assets in just 0.5 seconds on a GPU with 7GB VRAM, making it accessible for many 3D artists and potentially reducing costs in game development and other industries.",
      "Despite some mixed results in early tests, the technology shows promise for enhancing creative workflows, particularly in indie game development and 3D printing."
    ],
    "points": 191,
    "commentCount": 57,
    "retryCount": 0,
    "time": 1722525369
  },
  {
    "id": 41130620,
    "title": "Flux: Open-source text-to-image model with 12B parameters",
    "originLink": "https://blog.fal.ai/flux-the-largest-open-sourced-text2img-model-now-available-on-fal/",
    "originBody": "Announcing Flux by Black Forest Labs: The Next Leap in Text-to-Image Models Team Features & Labels Aug 1, 2024 • 2 min read Prompt: Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture. Flux, the largest SOTA open source text-to-image model to date, developed by Black Forest Labs—the original team behind Stable Diffusion is now available on fal. Flux pushes the boundaries of creativity and performance with an impressive 12B parameters, delivering aesthetics reminiscent of Midjourney. To play around with the model now, check out the demo page here on fal. Prompt: Portrait of a bearded man with dark hair wearing red sunglasses and a light gray Patagonia fleece jacket. He has a serious expression and is looking directly at the camera. The background shows a blurred outdoor scene with rocky terrain and a vibrant pink and purple sunset sky. The lighting gives the image a warm, golden-hour glow. The overall mood is rugged yet stylish, with a touch of adventure. BFL has released three three variations of the model, all available all on fal: FLUX.1 [dev]: The base model, open-sourced with a non-commercial license for community to build on top of. fal Playground here. FLUX.1 [schnell]: A distilled version of the base model that operates up to 10 times faster. Apache 2 Licensed. To get started, fal Playground here. FLUX.1 [pro]: A closed-source version only available through API. fal Playground here. Prompt: Close-up of LEGO chef minifigure cooking for homeless. Focus on LEGO hands using utensils, showing culinary skill. Warm kitchen lighting, late morning atmosphere. Canon EOS R5, 50mm f/1.4 lens. Capture intricate cooking techniques. Background hints at charitable setting. Inspired by Paul Bocuse and Massimo Bottura's styles. Freeze-frame moment of food preparation. Convey compassion and altruism through scene details. With the integration of fal's cutting-edge inference engine, you can run Flux models up to 2x faster than with eager torch. This results in faster processing times while maintaining the exceptional quality and detail. Key Features: Enhanced Image Quality: Generate stunning visuals at higher resolutions. Advanced Human Anatomy and Photorealism: Achieve highly realistic and anatomically accurate images. Improved Prompt Adherence: Get more accurate and relevant images based on your inputs. Exceptional Speed: Benefit from the speed and efficiency of Flux Schnell, ideal for high-demand applications. Prompt: A giant potato in sunglasses and a Hawaiian shirt lounges on a beach towel surrounded by colorful beach balls and flip-flops. Nearby, anthropomorphic fruits play beach volleyball. In the background, a lighthouse sand sculpture stands next to an ice cream truck with a giant cone, serving treats to cheerful beachgoers. The scene captures a fun, playful summer vibe with the sound of waves crashing nearby. Visit the fal Playgrounds or the API documentation and see firsthand how epic these models are.",
    "commentLink": "https://news.ycombinator.com/item?id=41130620",
    "commentBody": "Flux: Open-source text-to-image model with 12B parameters (fal.ai)185 points by CuriouslyC 2 hours agohidepastfavorite52 comments burkaygur 1 hour agohi friends! burkay from fal.ai here. would like to clarify that the model is NOT built by fal. all credit should go to Black Forest Labs (https://blackforestlabs.ai/) which is a new co by the OG stable diffusion team. what we did at fal is take the model and run it on our inference engine optimized to run these kinds of models really really fast. feel free to give it a shot on the playgrounds. https://fal.ai/models/fal-ai/flux/dev reply tikkun 1 hour agoparent> We are excited to introduce Flux I'd suggest re-wording the blog post intro, it reads as if it was created by Fal. Specific phrases to change: > Announcing Flux (from the title) > We are excited to introduce Flux > Flux comes in three powerful variations: This section also comes across as if you created it > We invite you to try Flux for yourself. Reads as if you're the creator reply burkaygur 52 minutes agorootparentThanks for the feedback! Made some updates. reply tikkun 36 minutes agorootparentWay better, nice reply nextos 47 minutes agoparentprevThe name is a bit unfortunate given that Julia's most popular ML library is called Flux. See: https://fluxml.ai. This library is quite well known, 3rd most starred project in Julia: https://juliapackages.com/packages?sort=stars. It has been around since, at least, 2016: https://github.com/FluxML/Flux.jl/graphs/code-frequency. reply minimaxir 2 hours agoprevThe [schnell] model variant is Apache-licensed and is open sourced on Hugging Face: https://huggingface.co/black-forest-labs/FLUX.1-schnell It is very fast and very good at rendering text, and appears to have a text encoder such that the model can handle both text and positioning much better: https://x.com/minimaxir/status/1819041076872908894 A fun consequence of better text rendering is that it means text watermarks from its training data appear more clearly: https://x.com/minimaxir/status/1819045012166127921 reply dheera 1 hour agoparentThank you. Their website is super hard to navigate and I can't find a \"DOWNLOAD\" button. reply minimaxir 1 hour agorootparentNote that actually running the model without a A100 GPU or better will be tricker than usual given its size (12B parameters, 24GB on disk). There is a PR to that repo for a diffusers implementation, which may run on a cheap L4 GPU w/ enable_model_cpu_offload(): https://huggingface.co/black-forest-labs/FLUX.1-schnell/comm... reply CuriouslyC 1 hour agorootparent3090 TIs should be able to handle it without much in the way of tricks for a \"reasonable\" (for the HN crowd) price. reply fl0id 1 hour agorootparenthigher ram apple silicon should be able to run it too. if they don't use some ancient pytorch version or something. reply dheera 38 minutes agorootparentprevYou don't need an A100, you can get a used 32GB V100 for $2K-$3K. It's probably the absolute best bang-for-buck inference GPU at the moment. Not for speed but just the fact that there are models you can actually fit on it that you can't fit on a gaming card, and as long as you can fit the model, it is still lightyears better than CPU inference. reply smusamashah 1 hour agoprevTested it using prompts from ideogram (login walled) which has great prompt adherence. Flux generated very very good images. I have been playing with ideogram but i don't want their filters and want to have a similar powerful system running locally. If this runs locally, this is very very close to that in terms of both image quality and prompt adherence. I did fail at writing text clearly when text was a bit complicated. This ideogram image's prompt for example https://ideogram.ai/g/GUw6Vo-tQ8eRWp9x2HONdA/0 > A captivating and artistic illustration of four distinct creative quarters, each representing a unique aspect of creativity. In the top left, a writer with a quill and inkpot is depicted, showcasing their struggle with the text \"THE STRUGGLE IS NOT REAL 1: WRITER\". The scene is comically portrayed, highlighting the writer's creative challenges. In the top right, a figure labeled \"THE STRUGGLE IS NOT REAL 2: COPY ||PASTER\" is accompanied by a humorous comic drawing that satirically demonstrates their approach. In the bottom left, \"THE STRUGGLE IS NOT REAL 3: THE RETRIER\" features a character retrieving items, complete with an entertaining comic illustration. Lastly, in the bottom right, a remixer, identified as \"THE STRUGGLE IS NOT REAL 4: THE REMI Otherwise, the quality is great. I stopped using stable diffusion long time ago, the tools and tech around it became very messy, its not fun anymore. Been using ideogram for fun but I want something like ideogram that I can run locally without any filters. This is looking perfect so far. This is not ideogram, but its very very good. reply treesciencebot 1 hour agoprevYou can try the models here: (available without sign-in) FLUX.1 [schnell] (Apache 2.0, open weights, step distilled): https://fal.ai/models/fal-ai/flux/schnell (requires sign-in) FLUX.1 [dev] (non-commercial, open weights, guidance distilled): https://fal.ai/models/fal-ai/flux/dev FLUX.1 [pro] (closed source [only available thru APIs], SOTA, raw): https://fal.ai/models/fal-ai/flux-pro reply layer8 1 hour agoparentRequires sign-in with a GitHub account, unfortunately. reply wavemode 1 hour agorootparentI think they may have turned on the gating some time after this was submitted to HackerNews. Earlier this morning I definitely ran the model several times without signing in at all (not via GitHub, not via anything). But now it says \"Sign in to run\". reply treesciencebot 1 hour agorootparenti just updated the links to clarify which models require sign-in and which doesn't! reply seveibar 13 minutes agoprevwhenever I see a new model I always see if it can do engineering diagrams (e.g. \"two square boxes at a distance of 3.5mm\"), still no dice on this one. https://x.com/seveibar/status/1819081632575611279 Would love to see an AI company attack engineering diagrams head on, my current hunch is that they just aren't in the training dataset (I'm very tempted to make a synthetic dataset/benchmark) reply Havoc 26 minutes agoprevBit annoying signup...Github only...and github account creation is currently broken \"Something went wrong\". Took two tries and two browsers... reply SirMaster 26 minutes agoprevI tried: \"Moe from The Simpsons, waving\" several times. But it only ever drew Lisa from The Simpsons waving. reply tantalor 1 hour agoprevSeems to do pretty poorly with spatial relationships. \"An upside down house\" -> regular old house \"A horse sitting on a dog\" -> horse and dog next to eachother \"An inverted Lockheed Martin F-22 Raptor\" -> yikes https://fal.media/files/koala/zgPYG6SqhD4Y3y_E9MONu.png reply colkassad 34 minutes agoparentIndeed: https://fal.ai/models/fal-ai/flux?share=e7e98018-fd69-45c0-9... reply minimaxir 52 minutes agoparentprevIt appears the model does have some \"sanity\" restrictions from whatever its training process is that limits some of the super weird outputs. \"A horse sitting on a dog\" doesn't work but \"A dog sitting on a horse\" works perfectly. reply bboygravity 28 minutes agoparentpreva zebra on top of an elephant worked fine for me reply j1mmie 57 minutes agoprevI'm really impressed at its ability to output pixel art sprites. Maybe the best general-purpose model I've seen capable of that. In many cases its better than purpose-built models. reply fl0id 1 hour agoprevMmmh, trying my recent test prompts, still pretty shit. F.e. whereas midjourney or SD do not have a problem to create a pencil sketch, with this model (pro), it always looks more like a black and white photograph or digital illustration or render. It is also like all the others apparently not able to follow instructions on the position of characters. (i.e. X and Y are turned away from each other). reply robotnikman 44 minutes agoprevThis is amazing! I thought it would be a few more years before we would have a such high quality model we could run locally. reply cwoolfe 53 minutes agoprevHey, great work over at fal.ai to run this on your infrastructure and for building in a free $2 in credits to try before buying. For those thinking of running this at home, I'll save you the trouble. Black Forest Flux did not run easily on my Apple Silicon MacBook at this time. (Please let me know if you have gotten this to run for you on similar hardware.) Specifically, it falls back to using CPU which is very slow. Changing device to 'mps' causes error \"BFloat16 is not supported on MPS\" reply UncleOxidant 1 hour agoprevOther flux ai things: https://fluxml.ai/ , https://www.flux.ai reply dinobones 1 hour agoprevI wonder if the key behind the quality of the MidJourney models, and this models, is less about size + architecture and more about the quality of images trained on. It looks like this is the case for LLMs, that the training quality of the data has a significant impact on the output quality of the model, which makes sense. So the real magic is in designing a system to curate that high quality data. reply pzo 14 minutes agoparentI would agree - midjourney is getting a free labour since many of their generations are not in secret mode (require pro/mega subscription) so prompts and outputs are visible to everyone. Midjourney rewards users to rating those generations. I wouldn't be surprised if there are some bots on their discord that are scraping those data for training their own models. reply jncfhnb 1 hour agoparentprevNo, it’s definitely the size. Tiny LLMs are shit. Stable Diffusion 3’s problem is not that that its training set was wildly different, it’s that it’s just too small (because the one released so far is not the full size). You can get better results with better data, for sure. And better architecture, for sure. But raw size is really important the difference in quality for models, all else held equal, is HUGE and obvious if you play with them. reply 42lux 1 hour agoparentprevIt's the quality of the image text pair not the image alone but midjourney is not a model it's a suite of models that work in conjunction. They have an llm in the front to optimize the user prompts, they use SAM models, controlnet models for poses that are in high demand and so much more. That's why you can't really compare foundation models anymore because there are none. reply TechDebtDevin 2 hours agoprevDamn this is actually really good. reply kennethwolters 2 hours agoprevIt is very good at \"non-human subjects in photos with shallow focus\". Really curious to see what other low-hanging fruits people are finding. reply CuriouslyC 1 hour agoparentCheck out reddit.com/r/stablediffusion, it's been handling everything people have thrown at it so far. reply PoignardAzur 2 hours agoprevAm I missing something? The beach image they give still fails to follow the prompt in major ways. reply swatcoder 1 hour agoparentYou're not. I'm surprised at their selections because neither the cooking one nor the beach one adhere to the prompt in very well, and that first one only does because it prompt largely avoids much detail altogether. Overall, the announcement gives the sense that it can make pretty pictures but not very precise ones. reply CuriouslyC 2 hours agoprevHF page: https://huggingface.co/black-forest-labs reply SV_BubbleTime 2 hours agoprevWow. I have seen a lot of promises made by diffusion models. This is in a whole different world. I legitimately feel bad for the people still a StabilityAI. The playground testing is really something else! The licensing model isn’t bad, although I would like to see them promise to open up their old closed source models under Apache when they release new API versions. The prompt adherence and the breadth of topics it seems to know without a finetune and without any LORAs, is really amazing. reply jncfhnb 1 hour agoprevLooks like a very promising model. Hope to see the comfyui community get it going quickly reply lovethevoid 1 hour agoparentIts already available for comfyui reply jncfhnb 38 minutes agorootparentIt’ll need time for the goodies beyond the base model though I would guess reply asadm 2 hours agoprevThis is actually really good! I fear much better than SD3 even! reply yjftsjthsd-h 1 hour agoprev> FLUX.1 [dev]: The base model, open-sourced with a non-commercial license ...then it's not open source. At least the others are Apache 2.0 (real open source) and correctly labeled proprietary, respectively. reply mikejulietbravo 1 hour agoprevWhat's the tl;dr on a difference from this to SD? reply minimaxir 1 hour agoparenttl;dr better quality even with the least powerful model and can be much faster reply zarmin 1 hour agoprevWILD Photo of teen girl in a ski mask making an origami swan in a barn. There is caption on the bottom of the image: \"EAT DRUGS\" in yellow font. In the background there is a framed photo of obama https://i.imgur.com/RifcWZc.png Donald Trump on the cover of \"Leopards Ate My Face\" magazine https://i.imgur.com/6HdBJkr.png reply kevin_thibedeau 27 minutes agoparentDT coverlines are very authentic. Garbled just like the real thing. reply og_kalu 2 hours agoprevYou can try the models on replicate https://replicate.com/black-forest-labs. Result (distilled schnell model) for \"Photo of Criminal in a ski mask making a phone call in front of a store. There is caption on the bottom of the image: \"It's time to Counter the Strike...\". There is a red arrow pointing towards the caption. The red arrow is from a Red circle which has an image of Halo Master Chief in it.\" https://www.reddit.com/r/StableDiffusion/s/SsPeQRJIkw reply KennyBlanken 2 hours agoprev [4 more] [flagged] wavemode 2 hours agoparent [–] Hmm I was able to try the model myself (generated a handful of images) and didn't log in. reply SV_BubbleTime 2 hours agorootparent [–] It’s a fal login, which is linked/federated with GitHub if you have done that before. It takes zero time to “make an account”. reply wavemode 1 hour agorootparent [–] I think they may have turned on the gating some time after this was submitted to HackerNews. Earlier this morning I definitely ran the model several times without signing in at all (not via GitHub, not via anything). But now it says \"Sign in to run\". reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Black Forest Labs has announced Flux, a new text-to-image model with 12 billion parameters, available on fal.",
      "Flux offers three variations: FLUX.1 [dev] (open-source, non-commercial), FLUX.1 [schnell] (distilled, faster, Apache 2 Licensed), and FLUX.1 [pro] (closed-source, API access).",
      "Key features include enhanced image quality, advanced human anatomy and photorealism, improved prompt adherence, and exceptional speed, making it suitable for high-demand applications."
    ],
    "commentSummary": [
      "Flux is an open-source text-to-image model with 12 billion parameters, developed by Black Forest Labs and optimized by fal.ai for fast inference.",
      "The model is available in three versions: schnell (Apache-licensed), dev (non-commercial), and pro (closed source), and can be tried on fal.ai or replicate.com.",
      "While some users reported issues with spatial relationships and prompt adherence, the model has generally received positive feedback for its quality and speed, though it requires significant GPU resources to run locally."
    ],
    "points": 185,
    "commentCount": 52,
    "retryCount": 0,
    "time": 1722528199
  },
  {
    "id": 41127446,
    "title": "Coinbase awarded a $500k bug bounty",
    "originLink": "https://hackerone.com/coinbase/hacktivity",
    "originBody": "HackerOne It looks like your JavaScript is disabled. To use HackerOne, enable JavaScript in your browser and refresh this page.",
    "commentLink": "https://news.ycombinator.com/item?id=41127446",
    "commentBody": "Coinbase awarded a $500k bug bounty (hackerone.com)185 points by alexcos 9 hours agohidepastfavorite138 comments vishnugupta 7 hours agoLooked around and they seem to be a company rather than an individual? https://www.certik.com One of its co-founders is a Yale professor https://www.linkedin.com/in/zhong-shao-545b754/ One is at Columbia University https://www.linkedin.com/in/guronghui/ Interesting! reply miohtama 3 hours agoparentCertiK is also notoriously bad reputation auditor company, having black hats on their payroll, and promoting scam projects. reply lagniappe 2 hours agorootparentblack hats working for an auditing company is like being mad that your dentist cheated on his taxes. your teeth look great either way. reply anvil-on-my-toe 1 hour agorootparentMore like having a drug dealer in your AA group. reply sophacles 1 hour agorootparentMost AA groups have a few drug dealers. reply RIMR 2 hours agorootparentprevYou want former black-hats only, with a reputation of being a white-hat hacker in the present day. Handing tons of sensitive customer information to people actively engaged in black-hat hacking and scams is a terrible idea. reply koolba 9 hours agoprevThere doesn’t appear to be any details on the site besides the recipient: certik Anybody familiar with that name is probably chuckling right now. reply danielvf 6 hours agoparentFor those looking for context: https://news.ycombinator.com/item?id=41128441 reply mtmail 9 hours agoparentprevI'm not familiar. What am I missing? reply koolba 8 hours agorootparentThey perform audits of crypto projects. The idea is that you’re certifying that the code is not going to immediately steal people’s money. Quite a few of their clients have gone on to do that with relatively simple vulnerabilities. To the point where “certik audit” is a meme about not providing any actual assurances (and thus implying they are incompetent). There also was the story a month or two ago where they actually took funds from a bug bounty target and eventually did give it back: https://blockworks.co/news/krakens-cso-confirms-certik-retur... reply oersted 8 hours agorootparentI know this is rather obvious and has been repeated to death but: There's just absolutely no point to crypto if you end up having to trust institutions that are fundamentally less trustworthy than mainstream financial institutions and regulators, even if they have plenty of issues too. reply robxorb 7 hours agorootparentYou don't have to trust those institutions. You can custody your own crypto without them, pay for services, etc. What's holding the safety level back ironically is the overbearing regulations making individual financial sovereignty a pain. reply oersted 6 hours agorootparentTrue, but let's be realistic, there is no practical way to get crypto outside of exchanges for a normal user, and that's a serious trust bottleneck. And if you are looking to use crypto as real currency, then you'd expect there to be a complex ecosystem of lenders, insurance, and markets around it, money is not just about buying consumer items. In general, it turns out that it's very hard to build a crypto wallet that both is easy to use for regular people and doesn't take the control of your keys away from you. Also let's not ignore that the crypto system itself is not magical and can have plenty of security issues too. At this point we can be fairly confident that BTC and ETH are safe, they have been battle-tested, but this is still about trust. When you get into smart contracts and other complex usages of blockchains, who knows what bugs they might have, there is zero enforced oversight. Crypto only ensures that it will work how it is programmed to work, but the programming could be wrong. reply freedomben 5 hours agorootparentI agree with your main point, and mostly agree with you about practicality, but there are some options such as the trezor wallet. reply jnwatson 1 hour agorootparentTrezor is another dependency you have to trust. I actually have the skills to evaluate such a device if I had a few weeks of spare time. Expecting the average joe to have that ability is folly. We have a system of laws and contracts and enforcement that allows someone to trust their bank account without a great deal of sophistication. reply johnmaguire 6 hours agorootparentprevWell that and the fact that the Bitcoin blockchain is now nearly 600GB. reply dboreham 5 hours agorootparentA mere bagatelle. Check the size of Ethereum. reply mensetmanusman 5 hours agorootparentprevHas anyone predicted its size over the next 100 years? reply BetaDeltaAlpha 2 hours agorootparentNew blocks are capped at 4096 bytes (plus some metadata), figure one every 10 minutes and there's your growth rate. It's slower than the growth of storage/$$$ reply johnmaguire 1 minute agorootparentOf course if you're buying a 14\" Macbook Pro, the upgrade to 2TB will cost you $400. Or $1,000 if you want 4TB (on top of the cost of upgrading the processor to the Max chip - necessary for that option.) nl 7 hours agorootparentprevYou missed the point here. They were pointing out that crypto users rely on these worse-than-worthless audits and as an example how it wasn't until threatened with traditional law enforcement certik gave tokens back. > What's holding the safety level back ironically is the overbearing regulations making individual financial sovereignty a pain. There is absolutely no evidence of this. reply robxorb 6 hours agorootparentI don't get what you're saying. The reality is, that because of KYC/AML laws it's difficult for ordinary people to replace cash with crypto, which - if it were easy - would be a superior form of money and transacting as any amount from tenths of a cent to billions, moves frictionlessly. reply oersted 6 hours agorootparentYou do have a point there, KYC/AML does tend to make a few large exchanges a trust bottleneck. But still, would you bet a billion dollars that whatever crypto system you are using has no bugs, vulnerabilities or backdoors? Are you going to audit the whole codebase yourself and trust your technical assessment? Do you even have access to the code that is deployed? reply robxorb 1 hour agorootparentThis is a very important issue you raise. In terms of the blockchains themselves, they all have a kind of built-in bounty, in that if on-chain funds have inherent risk of being lost or taken due to faults in the system, this will have happened - as the biggest / most popular systems are valued in the multi-billions. Ie, a huge bounty if an exploit exists. To my knowledge, this has not occurred to date with any of the major systems themselves. It's important not to mistake the above with a different issue of trusting applications development built on blockchain projects. Almost all blockchains have kind of two layers of functionality. The base layer allows self-custody and transfer. Above that, people can build other things using smart contract languages, or hardware solutions, or software that interacts with the chain. Those can have huge bugs or be outright scams. It's a bit like HTTPS could be provably secure, but that doesn't mean if you visit https://dodgy-website.com-dodgy.tk you're protected against it doing something dodgy. The different is while HTTPS is limited in its user-facing application, the base layer of say Bitcoin or Ethereum isn't so much. People can securely store and transact any amount with anyone worldwide, sometimes in seconds, with complete finality and determinism, without needing to trust anyone in between. In almost all cases, you also have access to the code, and can build it yourself. But as mentioned, the built-in bounty acts as your best security. Eg, if there was a hole in the base layer of Bitcoin right now, there's hundreds of billions up for grabs. reply sofixa 3 hours agorootparentprev> which - if it were easy - would be a superior form of money and transacting as any amount from tenths of a cent to billions, moves frictionlessly. We already have that in many countries. Yes, it's subject to AML/KYC regulations, and? Why is that a problem? It's only a problem if you want to remain anonymous (which you don't, really, with crypto), which is a very niche use of money. A lot of it related to crime too, which makes it hard to justify. reply robxorb 2 hours agorootparentIt's a problem because AML/KYC laws are created and enforced by governments, who sometimes are also the criminals such laws are supposedly created to protect us all from. Under a corrupt regime, crypto is a potential corrective force. If governments are acting fairly, some of crypto's use-cases will simply not be adopted en masse. If they're not acting fairly, it will all have huge take up. In that sense it's like a check and balance on democratic values. This has demonstrably been the case in many countries. Governments that come down extremely heavy-handed against it, are almost certainly themselves either corrupt in the worst case, or against common democratic principles of freedom and personal sovereignty in the best case. The common BS trotted out is that crypto os used for financing terrorism. The reality is, cash is used for financing terrorism, banks are used for financing terrorism, and governments are used for financing terrorism. Why target only crypto for this? Because it's a ruse. It's being targeted for other reasons. A government truly \"for the people, and by the people\", would welcome the people being more easily able to transfer value between each other and hold it closer to them without a middle-man they need to trust. reply ryandrake 36 minutes agorootparent> Why target only crypto for this? Because it's a ruse. It's being targeted for other reasons. What are those reasons? I'm not doubting you, I actually don't understand. reply pxx 6 hours agorootparentprevlol reply klntsky 6 hours agorootparentprevIf something in a particular group of things is bad, it does not mean that the whole is bad. reply TechDebtDevin 3 hours agorootparentprevIm not into crypto either but this is a gross generalization. There are zero trust protocols within some crypto ecosystems and some of the world's top crypto PhDs work on these projects. There are just so a lot of amateur devs and uneducated users trying to make a buck, of which get exploited by a much more sophisticated party who also wants to make a buck, sounds like pretty much any other capital market just much more blatant. reply simfree 2 hours agorootparentRather than relying on the idea that you're more sophisticated than everyone else who could steal from you, you could just leave your money with a mainstream financial institution that's regulated. reply xtracto 41 minutes agorootparentThat's a problem where I live. If I want to buy USD to protect me from my country's currency inflationary trend, I have to fill up cases of green bills , and risk going to banks with stashes of pesos to change for usd. Or, I can buy USDT and move it to my cold wallet and call it a day. reply mschuster91 2 hours agorootparentprev> There are just so a lot of amateur devs and uneducated users trying to make a buck, of which get exploited by a much more sophisticated party who also wants to make a buck, sounds like pretty much any other capital market just much more blatant. Yeah, but if you get wronged on normal capital markets you can complain at the authorities and get your money back. Your bank goes bust? FDIC covers up to 250k per account. Your credit card company doesn't side with you in a dispute or your bank's customer \"service\" department acts up? Call the CFPB, and you'll get a call from somewhere very high up the bank's chain who actually has the power to make things happen to make sure you withdraw your complaint. A public traded company does bullshit to mislead investors? The SEC will tear them a new hole. And so on. In the crypto world, you're left to deal with all of that on your own. Maybe the police will file a fraud complaint that won't lead anywhere. reply karaterobot 4 hours agorootparentprevPlease please please please please don't make this the 10,000th identical thread about is crypto bad or extra bad. Oh rats, too late. reply Suppafly 2 hours agorootparent>Please please please please please don't make this the 10,000th identical thread about is crypto bad or extra bad. Oh rats, too late. To be fair, it's a little hard not to when crypto is so bad. reply netsharc 8 hours agorootparentprevIt's so funny when crypto banks get robbed and they turn to the FBI to ask them to get the robbers... reply kybernetikos 7 hours agorootparentI see no problem with this. Crime doesn't stop being crime just because its happening to virtual assets. Maybe some crypto folks want to disconnect from the rest of society, but I don't think that's very many of them. reply FireBeyond 2 hours agorootparentMany folks said the Silk Road had made drug dealing \"harmless\". What they really meant was \"harmless to me\". Because it does nothing for anyone else in the chain to make it safer. There's also a non-zero sum of crypto proponents that think a large swathe of things that are illegal \"IRL\", should be non-criminal because ... \"online\". reply Suppafly 2 hours agorootparentprev>Crime doesn't stop being crime just because its happening to virtual assets. Sure, but there is a reason that real banks have tons of laws and regulations. It's more or less not a crime to steal crypto because it's not a thing that's protected by law. And crypto bros are doing everything they can to keep it from being protected by law while whining that the law isn't able to help them. reply 15155 1 hour agorootparent> because it's not a thing that's protected by law Unequivocally false in the United States. Despite what computer professionals may sometimes think, judicial opinions and most of our legal system are based on what a \"reasonable person\" would believe. Judges don't agree with the \"Neener neener neener! The terms are exactly X!\" methodology, typically. A reasonable, everyday person (and therefore a judge) would consider a party being deprived their valuable assets as theft, absent some form of agreement. Invariably, the reply incoming is \"codeislaw,\" but that's absolutely not the case in every circumstance. reply yieldcrv 3 hours agorootparentprevI don’t really get the amusement. Just because some crypto users were allergic to “centralized institutions” what does that have to do with anyone else? In this meme, why isn’t the permissionless aspect seen as not gatekeeping who is involved? reply bboygravity 7 hours agorootparentprevThe entire point of crypto is there's no need to trust institutions. The only person you need to trust is your counterparty. Any \"service\" that goes against this is basically normal money except way worse. That doesn't mean crypto is broken or useless. It just means scammers gonna scam. Nice example: Bitcoin ETFs completely miss this point. Is a Bitcoin ETF actually backed by real Bitcoin? Nobody really knows, but judging by Wallstreet's track record and who's behind it (Blackrock and Coinbase) the answer is almost certainly: no, your ETF order is not hitting a lit exchange and no it's not backed by anything and no, the SEC doesn't care. reply NoboruWataya 7 hours agorootparentBitcoin ETFs are not trying to replace money or leverage the benefits of bitcoin themselves, they are just providing a way for investors to speculate on interest in bitcoin. Same way that you would not buy an auto industry focused ETF and expect to be able to get into it and drive off. reply ryandrake 30 minutes agorootparentGold ETFs[1] are backed by physical bars of gold sitting in a vault somewhere. I would expect a \"bitcoin ETF\" to be backed by actual bitcoins on the blockchain, proportional to the investor's stake. 1: https://etfdb.com/themes/physically-backed-gold-etfs/ reply SXX 6 hours agorootparentprev> Is a Bitcoin ETF actually backed by real Bitcoin? At least for BITW ETF addresses are disclosed and you can verify it yourself. For others there is actually on-chain intellegence that let's approximate how they moving BTC itself. I mean there is always a lag between fund adjustments, but you can pretty much verify that BlackRock actually hold a lot of BTC. https://platform.arkhamintelligence.com/explorer/entity/blac... reply cyanydeez 7 hours agorootparentprevBy trust, whats actually being proffered is identity. In the real world trust is something thats tied to people, then to organizations, etc. Online, to trust is more than just security reply oersted 6 hours agorootparentIndeed, trust is about knowing that a counterparty has a strong incentive to act with goodwill. For important things, the incentive is that they will be punished by the justice system if they don't act with goodwill. Without a real-world identity and a reasonable guarantee of enforcement, it's a lot harder to establish any kind of serious trust, possibly fundamentally impossible. reply vishnugupta 6 hours agorootparentprev> The only person you need to trust is your counterparty. ...and all the miners, the backing infrastructure, internet and so on. reply kybernetikos 6 hours agorootparentNot really. None of those people can steal your cryptocurrency. The level of trust you have to have in them is very low. reply oersted 6 hours agorootparentWell, you do need to trust that the crypto system is working as advertised. Crypto is not immune to bugs. Precisely why untrustworthy auditing, like certik, is a big problem. reply vishnugupta 6 hours agorootparentprevIt's not about stealing crypto. If I'm selling 1KG gold in exchange for crypto I need to trust the mining infrastructure that authorised the transaction. reply yieldcrv 3 hours agorootparentprevthe point is the choice, and there is a flaw in your discussion A) the smart contract audit is a choice, certik is one player providing them, there are many players and its a choice that consumer and investors misuse the point of those audits to even make the make. certik provides disclosure of vulnerabilities, consumers chose to see that as a greenlight instead of an objective decision to participate or not B) your ensuing conversation about exchanges has nothing to do with what certik does or has made a meme for. so thats the conversation you actually wanted to have the whole time, a copy pasted “look! Crypto mentioned, my time to generically complain about it” discussion, but not one really relevant here. certik and others are just providing cybersecurity, its a sector that needs it, there is demand for it and thats as deep as it goes. if your crusade is to reduce demand for it, its an ineffective and redundant use of energy at this point. reply user90131313 8 hours agorootparentprevThey are %100 corrupted people and stealers.That story a month ago is mind blowing. Black hat type reply gnfargbl 8 hours agorootparentprevThat's just the classic attack/defence asymmetry though, no? When playing defence you have to find every reachable vulnerability. When playing attack, you have to find one. reply londons_explore 8 hours agorootparentIt highlights the fact that even experts can't find every bug in code, and therefore you probably shouldn't be using code as the only security for a monetary system. reply qqqult 8 hours agorootparentprevCrypto security audit company that used to be decent & somewhat respected then scaled out and hired many more security auditors with questionable skills and morals (such as exploiting bugs in projects they're paid to review & help). The running joke is that protocols with no security audits are safer than protocols with security audits done by CertiK. reply montenegrohugo 8 hours agorootparentprevCertik has a terrible rep in the crypto ecosystem They're ostensibly an audit/security firm, but miss many vulns Most egregiously recently they tried to blackmail Kraken, a big exchange, for $2m reply jiripospisil 8 hours agorootparentWell, \"certik\" does translate to \"little devil\"... reply oersted 8 hours agorootparentYes I believe the direct translation is simply \"imp\". reply user90131313 8 hours agorootparentprevoh so the founders already had the idea. so no surprise at all reply forty 7 hours agoparentprevWhat should we understand? It looks like the H1 account is the actual company, at least they link to their website. Is the company doing bug bounty? Or is this a creative way to pay for an audit? reply 1023bytes 7 hours agoparentprevConspiracy theory - they bought it from someone else for PR reply Max-Ganz-II 8 hours agoprevI have to say, I did not have a positive first experience with H1. Probably mainly my misunderstanding, but H1 did not help in any way. I opened an account, filed a report - I can easily crash Amazon Redshift as an unprivileged user. Provided the DDL/SQL to do so - dead simple, two statements, issue them and boom. I received a reply, something like, \"we have closed the report, if you can demonstrate a working issue we'll investigate further\". I was confused, replied and asked for explanation. No reply. I tried going to their Support, 403 - doesn't work via Tor browser - no use for an anonymous report. And that seems to be it - end of road. I don't understand, no replies, no support, and I've disclosed valuable information and I have no idea what H1 have done or are doing with it (if it's been made public, for example). (I asked on HN for advice. One line of reply was that this is not an exploit, but a bug, which I can see. OTOH, when I filled in the severity rating form, there was nothing in that where I was evidently going against the grain of what was expected, so I'm not wholly sure. Any further advice in replies now gratefully received.) reply authorfly 7 hours agoparentAs someone on the other side - we get spurious reports and people who cause DoS but only for that account in non-realistic scenarios regularly. Unfortunately it is hard to tell the two apart or wise to get into debates about these topics - people start demanding money for \"issues\" you and every other web host in your industry is aware of (for example client side XSS modifying what appears on the screen... yes, really, they'll argue for cash). reply hannob 7 hours agorootparent> Unfortunately it is hard to tell the two apart That's kinda a \"you had one job\" situation. Yes, it's hard to review security reports, and separate legit ones from bogus ones. But that's what these plattforms advertise they do. They regularly do a very bad job. reply bawolff 2 hours agorootparent> That's kinda a \"you had one job\" situation. Yes, it's hard to review security reports, and separate legit ones from bogus ones. Security engineers aren't telepaths. Yes sometimes reviewers dont do a good job, but i think you are severely underestimating how incomprehensible incoming reports can be sometimes. It is not always worth it to spend 6 hours trying to figure out what someone is talking about. reply ryandrake 14 minutes agorootparent> Yes sometimes reviewers dont do a good job, but i think you are severely underestimating how incomprehensible incoming reports can be sometimes. Yes, and this also goes for bugs filed by the public, sometimes comments/requests in public Open Source projects. There are lots of examples of incomprehensible communication and then there's also argumentative communication (that usually gets increasingly argumentative and ad hominem as the reply chain continues). Based on viewing a sampling of public bug reports my company gets (including security incident reports), I would not want to be the agent who acts as liaison by replying and clarifying with the bug reporter. Most public reports are polite and constructive but it's shocking how high a percentage are not, and become increasingly unprofessional as the discussion continues. reply bornfreddy 7 hours agorootparentprevI think you misunderstood GP: > Unfortunately it is hard for the reporter to tell the two apart reply fouc 3 hours agorootparent>As someone on the other side that's the reviewer of the report, it's actually: > Unfortunately it is hard for the reviewer to tell the two apart reply ta988 7 hours agorootparentprevI can confirm that, we have had extremely annoying ones but they are a minority. Some of the participants are really good and that compensates. reply londons_explore 8 hours agoparentprev> crash [...] as an unprivileged user. DoS stuff typically wouldn't qualify for most bug bounties. Thats probably why you got ignored. Most services aren't awfully interested in fixing this sort of thing - they'll just wait for someone to try and DoS at scale, then have the oncall team put in some extra regex on the input which blocks that specific expensive/crashing query. reply nicman23 8 hours agorootparentso what are you saying is to sell it and then it will get fixed :P reply arbll 8 hours agorootparentwell good luck finding a buyer, there's very little practical use for a DoS on a service that is usually not exposed to the public internet reply saagarjha 8 hours agorootparentprevIf you can find a buyer… reply cnity 8 hours agoparentprev> One line of reply was that this is not an exploit, but a bug Denial of service is absolutely a security problem, so I don't think whoever gave this advice is correct. Sounds like a frustrating experience. reply bawolff 2 hours agorootparent> Denial of service is absolutely a security problem \"Security problem\" isn't a binary. DoS can be an issue, but often it is acceptable risk. Especially if your DoS is minor. E.g. i can crash the server by sending 50 Gbps of data to it, is not usually a security issue in context. In the parent post they implied they needed privleged access to exploit. That probably makes it not a security issue as it can only be triggered by a trusted user. Additionally most bug bounty programs disallow DoS, due to some combination of reports being low value, and testers being idiots, so it might be out of scope right from the bat. reply vdfs 8 hours agorootparentprevNot if you DoS your own instance only reply olalonde 8 hours agorootparentprevBut who gives DDL/SQL access to untrusted users? It seems to be a rather unusual scenario. reply andyferris 8 hours agorootparentIt is AWS redshift - a Postgres compatible SQL service. You interact with it via SQL. reply orf 8 hours agorootparentYes, but generally you don’t give SQL access to the internet or completely unauthenticated users. Any user could likely cause issues for Redshift by running completely nuts queries that exhaust all the servers resources. Is “shit SQL” a bounty worthy issue reply andyferris 7 hours agorootparentI see, I misunderstood. Yes, having the power to crash your own instance might not be a security issue per se. reply Max-Ganz-II 6 hours agorootparentprevGood point. The problem I know of is a bit different, in that it is a direct and immediate server crash. It's not a denial of service by making the cluster slow. It's run-query, crash-server. You are right of course that any normal user can issue crazy queries which hog resources, and hammer performance. reply orf 5 hours agorootparentI would just reach out to AWS directly: why go through hacker one? They have a direct email and are responsive. If the issue meets their criteria then you get a payout. reply arbll 8 hours agorootparentprevA scenario where as an attacker: - You have raw access to the DB - You don't have enough privileges to get something more valuable than crashing the DB - You don't care to get noticed/caught Does sound pretty unlikely reply Max-Ganz-II 6 hours agorootparentJust as an aside, I don't think your query is directly logged. I've not actually checked, so I don't know, but knowing how logging works on RS, I think the cluster crashing will mean your killer query is not logged. Your session will have been logged by the time the cluster crashes. OTOH, maybe you were logged in for some time first, or there's connection pooling, or you slipped the query into an existing connection's query stream, and so on. Actually, thinking about it, I think you could reduce the problem to a single query, rather than two, which would help cover tracks. reply olalonde 7 hours agorootparentprevI assume the exploit only takes down your own instance, not the whole AWS redshift service. If it's the latter, it should obviously be rewarded with big $. reply Max-Ganz-II 6 hours agorootparentYes and yes :-) reply gcr 5 hours agorootparent“Yes” as in “yes, my exploit takes down all of redshift”? Or “yes” as in “yes it only takes down my instance” ? reply bflesch 7 hours agorootparentprevI see you have never reported a DOS on H1. High-profile millionaire engineers will go out of their way to argue with you that DOS of their TOP100 website is in fact not a security problem. These people don't even know about CIA triad and are gatekeeping four-figure bounty payouts while earning five figures or more every month. I'm extremely salty about this. reply llm_trw 7 hours agorootparentOne of these days I'll move to Cuba and run all the long list of exploits I've been told aren't exploits by overpaid idiots. https://www.youtube.com/watch?v=pQMuSotWCEs reply wepple 3 hours agoparentprevBugcrowd is no different. The folks doing Triage often don’t comprehend even simple security issues. I’m convinced it’s largely designed to keep people from going full disclosure rather than actually getting bugs fixed. reply bawolff 2 hours agorootparentAs someone who worked on the other side (i.e. at a previous job i handled incoming bug bounty reports) a big part of why we used H1 is that it can be exhausting dealing with reporters. Often the reports are non sensical. Even the one's that are real, often there will be very minor issues that the reporter feels should get top payout. Sometimes reporters are very demanding and rude. At the same time you can't just throw out the crazy reports, because sometimes the crazy looking emails actually have the legit vulns. H1 exists because once you start offering money the crazies start to show up, and its a lot of work to keep up with it. (That's not to say that you are entirely wrong either. I am sure some less scrupolous companies do have that goal. However a lot of the time its simply that the vuln has low impact so its low priority. Depending on how the company is managed, often there is dysfunction where the security team lacks the ability to get things prioritized) reply bflesch 7 hours agoparentprevI feel the same. IMO H1 is a face-saving filter layer for megacorp tech employees so the issues don't bubble up to their bosses via media reports. They tarpit you, send junior people into the ticket who don't understand the issue, and in the end they try to refuse payouts as much as possible. Meanwhile megacorp tech employees with wikipedia articles spend time to explain how \"their platform\" is not affected by an issue, even though you show them a POC. Of course, things like DOS is not in scope. It's worse than arguing with layers about a contract, because there is so much face-saving and CYA going on. reply TheDong 8 hours agoparentprevYeah, sure, and if someone gives me access to their redshift, I could just run \"SELECT digest('foo', 'sha256');\" in a loop, which takes redshift CPU and thus costs them lots of money. If you give an attacker access to run arbitrary queries in your database, it's already pretty bad news, even without a crash. reply Max-Ganz-II 6 hours agoparentprevThank you everyone who replied. I feel like I have a better understanding now of the situation and what happened with H1, and I feel better about it. I will now see if I can figure out how to wipe everyone's RS clusters instantly with a single command, so I can report something on H1 after all :-) reply StrauXX 9 hours agoprevIs this the highest single bounty ever payed? The only other paymnts in this range I can think of are the yearly rewards by Google. But then again thats not really a bounty. reply SushiHippie 8 hours agoparentAt least on Hackerone this seems to be by far the highest Bounty https://hackerone.com/hacktivity/overview?queryString=disclo... The next highest bounty is $200k from Shopify and then again Coinbase with $115k reply tromp 7 hours agorootparentA $250K bounty was paid for uncovering a bug in Grin: https://forum.grin.mw/t/ann-bug-bounty-awarded-to-david-burk... reply compsciphd 6 hours agorootparentprevwe had a talk yesterday by our H1 people to the company and a Q was asked how our bounty values with in with the industry norm. Part of the answer (IIRC, and it was to help understand how different sectors place bounties at different amounts) included that for some crypto things, bounties have gone up to $1mil (but I could be misremembering, it was at the end of a day of lots of talks and I was exhausted). reply KomoD 8 hours agorootparentprev> At least on Hackerone this seems to be by far the highest Bounty You can't know that, not all bounty amounts are disclosed, and there's also private/confidential programs. reply danielvf 6 hours agoparentprevTwo months ago someone a 2 million dollar bug bounty, and it was top on HN. [0] So, no this is a good bounty but still on the small size for a huge crypto project / company. [0] https://news.ycombinator.com/item?id=40710201 reply estensen 6 hours agoparentprevsaurik got $2.1M from Optimism/Boba Network via Immunefi https://www.saurik.com/optimism.html reply BillFranklin 9 hours agoparentprevSomeone got a $10m bounty in another crypto platform Wormhole reply ackbar03 8 hours agorootparentThat sounds more like a ..um.. ransom than bounty.. reply yieldcrv 1 hour agorootparentThe ransom would have been a few hundred million So, no. Crypto organizations float closer to the same market value of exploits that you see blackhat organizations like NSOGroup pay. Its just FAANGs that refuse to value them correctly and put up barriers of entry for pennies. reply piyush_soni 8 hours agoprevIn the Right panel on the page: $1,996,583 Total bounties paid I don't know if I should feel happy or concerned about the security policies of a company that has already given 2 million USD in bug bounties :). reply SheinhardtWigCo 8 hours agoparentYou should be far more concerned about the ones that have given $0. reply welder 7 hours agorootparentI want to offer rewards (my site is on H1) but they require I sign up for a minimum $50k/yr subscription to enable that feature. I don't think that's a reason for concern, just means it's a smaller company. reply grumple 7 hours agorootparent50k a year is insane. It's just a messaging platform. Advertise your own bug bounties and just have them email you, voila. reply cyanydeez 7 hours agorootparentprevIt means you can afford to be more secure. Poverty is just a basic gateway. I imagine hackers have to do some calculus on bigger vs little, since usually larger targets are more valuable, buy smaller are likely less secure. reply danielvf 6 hours agoprevHere's some context, and some fun drama. One month ago this same company found a bug with a 2 million dollar bug bounty. The bug would let them drain funds from a crypto exchange by sending funds to the exchange on the blockchain, but then after sending, reverting the part of the transaction that sent the funds, while keeping the overall transaction alive. The software at the exchange was fooled into counting the reverted transfer as actually happening. [0] So what do you do when you find an incredibly critical bug with 2 million dollar bug bounty? CertiK researchers choose to steal 3 million. Then when they stole it, they exchanged the bulk of the coins for other coins, and sent some of the funds to an OFAC sanctioned entity. CertiK did not report the massive bug that they were exploiting live, in the wild, in public view, for ten days. When they finally did report it for the 2 million dollar bug bounty, CertiK did not mention the 3 million dollars that they stole. When confronted about it, they referred all questions to the sales team, who made demands and refused to return the money. Two weeks of refusing to return the money pass by, and before the head of security at the exchange posts on Twitter the story [1], without naming the company. So what do you do now there's a now a story out there that some researchers stole 3 million and won't return it. CertiK chose to confirm everything on their official Twitter, loudly proclaim that the team that stole the money was them, and claim that the exchange was persecuting them by threatening legal action for the return of the stolen funds. CertiK founders also retweeted these tweets. After a firestorm of twitter drama, by the end of the day, CertiK promised to return the stolen funds. So CertiK is just some random team of anonymous people, right? Nope. CertiK is 2 billion market cap, company, headquartered in the US, just did 230 million dollars worth of fund raising. (CertiK does have a long reputation for working in ways that no one could conclusively prove if their actions were from evil or from incompetentance.) [0] https://x.com/danielvf/status/1803780167027871878 [1] https://x.com/c7five/status/1803403565865771370 [2] https://x.com/CertiK/status/1803450205389402215 reply sofixa 3 hours agoparentI wonder, how do laws apply here? Crypto is like monopoly money, there is no value outside of what people assign to it, is unusable outside of that specific context, and the \"value\" can disappear in seconds. If you steal someone's monopoly money, are you liable for theft of the equivalent of that monopoly money's exchange rate on the market (say, it's a rare edition you can sell on Ebay)? Or like virtual currency in an online game. If someone steals your Robux, can you complain to the FBI? reply currymj 2 hours agorootparentgenerally yes to both. it's imperfect but the legal system already has longstanding ways of valuing illiquid assets that don't have straightforward market prices (art, houses, used cars, etc.). in this case who knows what kind of tokens they stole, but if it was Ethereum or Bitcoin, those markets are liquid enough that you don't even have this problem. reply stefan_ 2 hours agorootparentprevNY is prosecuting two brothers for a crypto related \"crime\", Matt Levine has a good summary: https://archive.ph/zA4Wd In my mind, the people that loudly proclaim to want nothing to do with the rules beyond whats in the code get to have their cake. reply RIMR 2 hours agorootparentprevCrypto is not like monopoly money, Crypto is treated legally as a financial security. Stealing $3M is a serious federal crime. reply Suppafly 2 hours agorootparent>Crypto is treated legally as a financial security. Source? If that were true wouldn't it have to be regulated the same way as other securities? reply vishnugupta 5 hours agoparentprevThis should be the top comment on this thread! reply dankwizard 9 hours agoprevwhat was it reply vdfs 9 hours agoparentMost likely a bug reply gkanai 6 hours agoprevCertik is widely used in the blockchain industry for smart contract audit/verification. reply tshanmu 9 hours agoprevcertik appears to be a web3 smart contract audit company reply rvz 8 hours agoprev [–] Again, we have another 6-figure winner on finding a vulnerability in a crypto exchange and the payouts are way more than the average bug bounty these days (especially for critical bugs). For crypto skeptics and those who REALLY hate crypto, this is a great opportunity to turn your passion of hating all over it into a lucrative hunt for bugs like this one and to make a massive killing from the payouts. Just think about it. reply rty32 8 hours agoparentCost/benefit analysis? What is the chance I would someday get a $500k payout, starting from near zero experience today, with the help of a little bit of luck? reply saliagato 7 hours agorootparentCan't comment on the cost (varies depending on who you are and what you do in your life) but the benefit is really high. source: I started from 0 and the very first bounty I submitted (related to CEX) was valued to $100k+ reply Loughla 7 hours agorootparentHow long did that take? How long was the 0 to reward process, and how much time did you spend? reply modernerd 8 hours agoparentprevCrypto skeptics probably don't trust crypto firms to pay the \"rewards up to $15,000,000\" bounties advertised at places like https://immunefi.com/. Immunefi has a similar payouts table to h1's at https://immunefi.com/bug-bounty/ implying people are getting paid, but it could boost credibility by linking to write-ups and findings from researchers if any exist. reply bugtodiffer 6 hours agorootparentNobody should trust these companies to do that. I bet you this was lots of persuasion for them to pay out this bounty. You wouldn't have gotten this bounty if you had this bug. reply cyanydeez 7 hours agorootparentprevWhenevrt i see a crypto disxussion with dollar signs, im forced to ask if thw payment is in actual dollars or dollar equivelents. Aftetall, bitcoin isnt a currency and is more like a stockmarket as when you try to extract large value from it you typically cause its real price to decline. reply modernerd 6 hours agorootparentPayments seem to be in Ethereum, based on the description of the \"Immunefi vault platform\": > This project utilizes a decentralized vault for their bounty rewards to ensure trust by showing that they have the collateral to cover their bounties. Payments are processed directly on-chain inside the Immunefi webapp. https://immunefi.com/bug-bounty/beanstalk/ An interesting side-effect is that you can view payments from the public vault for each project, for example: https://etherscan.io/address/0x66Efac6e6d58D4058CF017E66a003... Top payment so far is 3 payments of about 8,500 USD to the same recipient. The maximum claimed achievable payment is 1.1m USD. It does at least imply that they've set aside magic beans to pay researchers, and that someone is being paid from the bean fund, for whatever that's worth. reply bawolff 2 hours agorootparentprevThe real sketch ones is when the payout is in their custom altcoin since if you find a truly show stopper bug, their altcoin might end up going to 0 once you report it. reply nl 6 hours agorootparentprevUnless they are paying multi-billion dollar bounties in BTC, USDC, USDT or ETH it's not big enough to really move the market. reply yieldcrv 1 hour agorootparentprevMore and more process in USDC the hackernews post a few months ago had someone earn $2,000,000 which was paid instantly in USDC. this is freely redeemable for USD on Circle and Coinbase some other firms pay out in a vesting schedule of their own tokens, so you rely on the exchange rate and liquidity just as with RSUs. reply hgomersall 7 hours agoparentprevOr you can spend your short life doing something actually useful. reply Nextgrid 5 hours agorootparentI’m not a fan of crypto, but it’s not like non-crypto tech (which is mostly about collecting people’s personal data and wasting their time with ads) is any more useful. Crypto at least is easy to ignore as a user. Every other company out there that wants me to handover my personal data and “engage” is less so. reply bawolff 2 hours agoparentprevYou can believe that crypto is \"secure\" and still be a crypto-skeptic. reply twelve40 7 hours agoparentprev> make a massive killing from the payouts do you have, you know, like some data on those massive payouts? other than one data point? reply wasteduniverse 8 hours agoparentprev [–] If I hated crypto companies, why would I help find bugs for them? reply lifty 7 hours agorootparent [–] I think the OP was obvious. To make money. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "Coinbase awarded a $500k bug bounty to CertiK, a company specializing in auditing crypto projects, despite its controversial reputation.",
      "The discussion underscores the challenges and skepticism surrounding crypto security audits and their impact on trust within the crypto ecosystem.",
      "Users debate whether the reliance on audits contradicts crypto's promise of trustless transactions, highlighting the role of regulations and the financial incentives for identifying vulnerabilities."
    ],
    "points": 185,
    "commentCount": 138,
    "retryCount": 0,
    "time": 1722505225
  },
  {
    "id": 41125544,
    "title": "Don’t Let Your Domain Name Become a “Sitting Duck”",
    "originLink": "https://krebsonsecurity.com/2024/07/dont-let-your-domain-name-become-a-sitting-duck/",
    "originBody": "July 31, 2024 14 Comments More than a million domain names — including many registered by Fortune 100 firms and brand protection companies — are vulnerable to takeover by cybercriminals thanks to authentication weaknesses at a number of large web hosting providers and domain registrars, new research finds. Image: Shutterstock. Your Web browser knows how to find a site like example.com thanks to the global Domain Name System (DNS), which serves as a kind of phone book for the Internet by translating human-friendly website names (example.com) into numeric Internet addresses. When someone registers a domain name, the registrar will typically provide two sets of DNS records that the customer then needs to assign to their domain. Those records are crucial because they allow Web browsers to find the Internet address of the hosting provider that is serving that domain. But potential problems can arise when a domain’s DNS records are “lame,” meaning the authoritative name server does not have enough information about the domain and can’t resolve queries to find it. A domain can become lame in a variety of ways, such as when it is not assigned an Internet address, or because the name servers in the domain’s authoritative record are misconfigured or missing. The reason lame domains are problematic is that a number of Web hosting and DNS providers allow users to claim control over a domain without accessing the true owner’s account at their DNS provider or registrar. If this threat sounds familiar, that’s because it is hardly new. Back in 2019, KrebsOnSecurity wrote about thieves employing this method to seize control over thousands of domains registered at GoDaddy, and using those to send bomb threats and sextortion emails (GoDaddy says they fixed that weakness in their systems not long after that 2019 story). In the 2019 campaign, the spammers created accounts on GoDaddy and were able to take over vulnerable domains simply by registering a free account at GoDaddy and being assigned the same DNS servers as the hijacked domain. Three years before that, the same pervasive weakness was described in a blog post by security researcher Matthew Bryant, who showed how one could commandeer at least 120,000 domains via DNS weaknesses at some of the world’s largest hosting providers. Incredibly, new research jointly released today by security experts at Infoblox and Eclypsium finds this same authentication weakness is still present at a number of large hosting and DNS providers. “It’s easy to exploit, very hard to detect, and it’s entirely preventable,” said Dave Mitchell, principal threat researcher at Infoblox. “Free services make it easier [to exploit] at scale. And the bulk of these are at a handful of DNS providers.” SITTING DUCKS Infoblox’s report found there are multiple cybercriminal groups abusing these stolen domains as a globally dispersed “traffic distribution system,” which can be used to mask the true source or destination of web traffic and to funnel Web users to malicious or phishous websites. Commandeering domains this way also can allow thieves to impersonate trusted brands and abuse their positive or at least neutral reputation when sending email from those domains, as we saw in 2019 with the GoDaddy attacks. “Hijacked domains have been used directly in phishing attacks and scams, as well as large spam systems,” reads the Infoblox report, which refers to lame domains as “Sitting Ducks.” “There is evidence that some domains were used for Cobalt Strike and other malware command and control (C2). Other attacks have used hijacked domains in targeted phishing attacks by creating lookalike subdomains. A few actors have stockpiled hijacked domains for an unknown purpose.” Eclypsium researchers estimate there are currently about one million Sitting Duck domains, and that at least 30,000 of them have been hijacked for malicious use since 2019. “As of the time of writing, numerous DNS providers enable this through weak or nonexistent verification of domain ownership for a given account,” Eclypsium wrote. The security firms said they found a number of compromised Sitting Duck domains were originally registered by brand protection companies that specialize in defensive domain registrations (reserving look-alike domains for top brands before those names can be grabbed by scammers) and combating trademark infringement. For example, Infoblox found cybercriminal groups using a Sitting Duck domain called clickermediacorp[.]com, which was a CBS Interactive Inc. domain initially registered in 2009 at GoDaddy. However, in 2010 the DNS was updated to DNSMadeEasy.com servers, and in 2012 the domain was transferred to MarkMonitor. Another hijacked Sitting Duck domain — anti-phishing[.]org — was registered in 2003 by the Anti-Phishing Working Group (APWG), a cybersecurity not-for-profit organization that closely tracks phishing attacks. In many cases, the researchers discovered Sitting Duck domains that appear to have been configured to auto-renew at the registrar, but the authoritative DNS or hosting services were not renewed. The researchers say Sitting Duck domains all possess three attributes that makes them vulnerable to takeover: 1) the domain uses or delegates authoritative DNS services to a different provider than the domain registrar; 2) the authoritative name server(s) for the domain does not have information about the Internet address the domain should point to; 3) the authoritative DNS provider is “exploitable,” i.e. an attacker can claim the domain at the provider and set up DNS records without access to the valid domain owner’s account at the domain registrar. Image: Infoblox. How does one know whether a DNS provider is exploitable? There is a frequently updated list published on GitHub called “Can I take over DNS,” which has been documenting exploitability by DNS provider over the past several years. The list includes examples for each of the named DNS providers. In the case of the aforementioned Sitting Duck domain clickermediacorp[.]com, the domain was originally registered by , but it appears to have been hijacked by scammers by claiming it at the web hosting firm DNSMadeEasy, which is owned by Digicert, one of the industry’s largest issuers of digital certificates (SSL/TLS certificates). In an interview with KrebsOnSecurity, DNSMadeEasy founder and senior vice president Steve Job said the problem isn’t really his company’s to solve, noting that DNS providers who are also not domain registrars have no real way of validating whether a given customer legitimately owns the domain being claimed. “We do shut down abusive accounts when we find them,” Job said. “But it’s my belief that the onus needs to be on the [domain registrants] themselves. If you’re going to buy something and point it somewhere you have no control over, we can’t prevent that.” Infoblox, Eclypsium, and the DNS wiki listing at Github all say that web hosting giant Digital Ocean is among the vulnerable hosting firms. In response to questions, Digital Ocean said it was exploring options for mitigating such activity. “The DigitalOcean DNS service is not authoritative, and we are not a domain registrar,” Digital Ocean wrote in an emailed response. “Where a domain owner has delegated authority to our DNS infrastructure with their registrar, and they have allowed their ownership of that DNS record in our infrastructure to lapse, that becomes a ‘lame delegation’ under this hijack model. We believe the root cause, ultimately, is poor management of domain name configuration by the owner, akin to leaving your keys in your unlocked car, but we acknowledge the opportunity to adjust our non-authoritative DNS service guardrails in an effort to help minimize the impact of a lapse in hygiene at the authoritative DNS level. We’re connected with the research teams to explore additional mitigation options.” In a statement provided to KrebsOnSecurity, the hosting provider and registrar Hostinger said they were working to implement a solution to prevent lame duck attacks in the “upcoming weeks.” “We are working on implementing an SOA-based domain verification system,” Hostinger wrote. “Custom nameservers with a Start of Authority (SOA) record will be used to verify whether the domain truly belongs to the customer. We aim to launch this user-friendly solution by the end of August. The final step is to deprecate preview domains, a functionality sometimes used by customers with malicious intents. Preview domains will be deprecated by the end of September. Legitimate users will be able to use randomly generated temporary subdomains instead.” What did DNS providers that have struggled with this issue in the past do to address these authentication challenges? The security firms said that to claim a domain name, the best practice providers gave the account holder random name servers that required a change at the registrar before the domains could go live. They also found the best practice providers used various mechanisms to ensure that the newly assigned name server hosts did not match previous name server assignments. [Side note: Infoblox observed that many of the hijacked domains were being hosted at Stark Industries Solutions, a sprawling hosting provider that appeared two weeks before Russia invaded Ukraine and has become the epicenter of countless cyberattacks against enemies of Russia]. Both Infoblox and Eclypsium said that without more cooperation and less finger-pointing by all stakeholders in the global DNS, attacks on sitting duck domains will continue to rise, with domain registrants and regular Internet users caught in the middle. “Government organizations, regulators, and standards bodies should consider long-term solutions to vulnerabilities in the DNS management attack surface,” the Infoblox report concludes. This entry was posted on Wednesday 31st of July 2024 08:06 AM A Little Sunshine Latest Warnings Time to Patch Web Fraud 2.0 APWG Dave Mitchell Digicert Digital Ocean DNSMadeEasy Eclypsium Hostinger Infoblox Matthew Bryant sitting duck domains Steve Job",
    "commentLink": "https://news.ycombinator.com/item?id=41125544",
    "commentBody": "Don’t Let Your Domain Name Become a “Sitting Duck” (krebsonsecurity.com)179 points by mfkp 17 hours agohidepastfavorite73 comments Neil44 6 hours agoSo you point your nameservers at a third party, let your account with that third party expire, then someone later on can create an account at third party and resume control of the DNS zone? I mean yeah, but you mustn't care much about the domain and any credibility it has will evaporate quickly. reply josefresco 1 hour agoparentI had something similar happen to a client using Cloudflare. The attacker somehow was able to establish a new account(s) at CF that used the same free nameservers as my client. When my client's domain expired the attackers added the domain in their CF account, and were then able to control DNS. I reported it to CF security but I'm not sure if the loophole was closed. What I don't know is how the attacker was able to get an account with the same nameservers which are seemingly assigned at random (maybe not?). Maybe they just own/operate thousands of CF accounts? Update: CF claims to have closed this loophole: https://github.com/indianajson/can-i-take-over-dns/issues/10 reply meowface 33 minutes agorootparentHow exactly does this happen in practice? When you add a domain to a Cloudflare account, can that domain actually \"expire\" and no longer be attached to the account? Or can the account itself and all the domains in it expire? I don't see why Cloudflare would do this. If you stop paying for a paid tier, I figure your account and the domains associated with it would still exist in the free tier. I can see how this could happen if you manually remove the domain from your account but don't change the nameservers (at least before they fixed it so the previous nameservers will never be assigned to the same domain in the future), but when would Cloudflare automatically expire the domains from an account or automatically expire an account itself? (I can potentially see this happening for providers that don't have free tiers.) reply lcnPylGDnU4H9OF 59 minutes agorootparentprevNot sure if you're emphasizing \"claims\" because you find it dubious so perhaps it's worth noting that the statement is coming from someone who claims (heh) to be an engineer at CF rather than someone working in PR/marketing. In case that affects the reader's view of the statement. reply remram 43 minutes agorootparentprevI don't understand what the \"loophole\" is. You say the domain expired...? reply amiga386 3 hours agoprevThis is how I understand the exploit, can someone please confirm if I have the right idea? 1. I register a domain name -- example.com -- with a registrar like NameCheap. They tell Network Solutions (the .com registry) to add records on my behalf like below, which means the rest of the internet asks NameCheap's nameservers when they want to look up my domain. example.com. 172800 IN NS ns1.namecheaphosting.com example.com. 172800 IN NS ns2.namecheaphosting.com 2. For no reason, I ask NameCheap to change those NS records to another company's nameservers, such as Hurricane Electric, which I am NOT a customer of example.com. 172800 IN NS ns1.he.net example.com. 172800 IN NS ns2.he.net 3. Hurricane Electric (HE) are \"exploitable\"; one of their customers claims to be tranferring a domain to HE, example.com (my domain!), HE doesn't verify the actual ownership and they let it happen. 4. Now this HE customer has control over my domain... because I told my registrar to change the NS records to HE's nameservers. Why would I ever do that? My understanding is this should never happen, I have no reason why I'd want to make such a change. ICANN have a policy on domain transfer between registrars: https://www.icann.org/resources/pages/transfer-policy-2016-0... -- and transferring a domain should only be done with the gaining registrar (HE in my example) putting an explicit request to the losing registar (NameCheap in my example), and the losing registrar getting to decide yes or no to the transfer. So... how are there a million or more domains at risk this way? Is it old practises that haven't been corrected? How would this work? reply cortesoft 2 hours agoparentThis is kinda how it works, but not how it would work in practice. The issue would be more like: 1. Register your domain with namecheap, and you want to have digital ocean run your DNS, so you point the domain to use their name servers. 2. A few months later, you decide to stop using digital ocean DNS, so you delete all your records… but you forget to change your NS record at namecheap, so now someone else can now add that DNS name to their digital ocean account. This would only happen if your aren’t actively using the DNS name, which would allow you to have it point to a NS you aren’t controlling. reply layer8 1 hour agorootparentBut the easy fix is just to change the NS records back to something you control. Somehow I don’t understand the problem. reply NoahKAndrews 1 hour agorootparentIt's easy to fix if you own the domain, but it still happens. The idea is to find ways to address the problem with the DNS providers so that it doesn't happen at all. reply davchana 1 hour agorootparentprevGitlab also had same issue few weeks ago. Gitlab, once static pages are published, gives you a URL with gitlab.io ending. You can use your custom domain or subdomain by pointing CNAME or A record to Gitlab. What users would do is, add DNS records to their DNS Manager to point their custom domain to Gitlab Pages, later will delete the Gitlab pages when not wanted any more. Scammer will simply point that same domain to his fake repository, thus hijacking customer domain. Gitlab then made customer add a Txt Record for verification of domain. Scammer's txt record value is different from customer txt record, scammer can't modify DNS records. reply apitman 50 minutes agorootparentIs there a similar mitigation that would work when you're using the 3rd party nameservers (a la Cloudflare), and not just a CNAME? reply buzer 2 hours agoparentprevFrom what I understand the issue is more that people point domain to a DNS service, use it for a while and then remove their account (/domain from the account). Now someone else can add it to their account. This is unlikely to be an issue on their primary domain but could be for e.g. subdomains or some marketing domains that aren't really in use anymore. Or cases where domain is just be squatted. reply nickburns 2 hours agoparentprevNamecheap is not a losing registrar, HE is not a gaining registrar, and the transaction you describe with Namecheap requesting that they update your registration's nameservers to HE's is not a domain transfer. You're conflating registration with nameserver assignment. reply amiga386 2 hours agorootparentI'm not trying to conflate it, but I'm trying to imagine why you would ever switch your domain's NS entries away from your current registrar's nameservers, and the only reason I can think of is that you'd want a registrar transfer -- which should and I think does have more ownership checks around it. However, other posters have given a more plausible example: you have server hosting with someone who isn't also a registrar, so for simplified management, you get your registrar to point your domain's nameserver at the server hosting company's nameservers, delegating it all to them... now you just need one customer portal to update all your hosting and DNS entries... and then you leave the hosting company (maybe the bill's too much), and you also forget to clean up the NS records, pointing them back to the real registrar's nameservers, so they're still pointing at this server hosting company you're no longer a customer of. The hosting company isn't a registrar and is under no obligation to follow ICANN policies, so they can give the domain to some other customer of theirs without doing any verification. (I'm not sure they can do domain ownership validation, if they're not a registrar themselves) reply nickburns 1 hour agorootparentI personally keep my domain registrations and zone files separate as a matter of security policy. I place as much importance on vetting reputable DNS providers as I do registrars. Nameserver assignment remains with the ICANN-accredited registrar. (I would also never maintain a registration nor a zone file with a web/cloud hosting service.) reply vel0city 1 hour agorootparentprevI've often run my registrars separate from my nameservers. Maybe I'm self hosting my nameservers. Maybe the nameservers are tied to the rest of my hosting (for ease of dynamic hosting) but want the ability to rapidly migrate if the hosting provider goes down. If the registrar is my nameserver host, good luck changing the SOA and NS records when SHTF at your host. reply davchana 1 hour agorootparentprev> so they can give the domain to some other customer of theirs without doing any verification Hosting company can not \"give\" the domain to anybody. If domain is still pointing to Hosting with NS records, anybody could make an account at Hosting, and add that domain. Now that scammer controls whats visible at Domain, but he is not yet the owner of domain. Owner is who control and can change NS records. Scammer can change all other records, but not NS. NS is at original domain registrar. Original owner can very easily change the NS and cut the scammer out of everything (& should). Gitlab used to be like this. You add a domain to Gitlab. You add an A record to your domain registrar or NS Manager. Now your domain shows your Gitlab Page. After few months, you don't want the pages anymore. You delete the project from Gitlab. You ignore to delete the A Record. Scammer adds that domain to his Gitlab, and shows his content at your domain. Now Gitlab asks you to add a verification TXT record when adding any domain. Scammer's veri record is different. He can't prove that he owns the domain. reply amiga386 16 minutes agorootparent> Hosting company can not \"give\" the domain to anybody. > Gitlab used to be like this That's what I'm saying. Hosters can \"give\" a domain (i.e. control of that domain's records on their nameserver only) to someone else, because they're not registrars and aren't _required_ by some painful business contract with ICANN to have to take change of ownership seriously. They should require a domain validation challenge to add a new domain, like your Gitlab example, but it doesn't seem like anyone can make them. So therefore the onus is currently on the domain owner not to leave their domains' NS records pointing at nameservers they don't control! reply davchana 1 hour agorootparentprev> why you would ever switch your domain's NS entries away from your current registrar's nameservers, I want my domains at dynadot or namecheap or hexonet, but want CloudFlare to manage all DNS. CF doesn't support al ccTLDs. reply metadat 12 hours agoprevFrom TFA: > There is a frequently updated list published on GitHub called “Can I take over DNS,” which has been documenting exploitability by DNS provider over the past several years. https://github.com/indianajson/can-i-take-over-dns Whoa, names like Digital Ocean, Google Cloud, Linode, Hurricane Electric - all classified as fully vulnerable. reply kortilla 12 hours agoparentBecause it’s not an attack. What am I missing here? This doesn’t feel any different than letting your domain expire. reply nickcw 11 hours agorootparentI think the DNS provider is missing some due diligence. What happens is Alice creates some DNS records for example.com which is registered elsewhere. Everything is fine. At some point (maybe Alice forgets to pay the bill) the DNS records expire. A bit later Bob makes an account at the same DNS provider and makes DNS records for example.com. This is possible because Alice's records have been deleted. Bob has now effectively taken over example.com The due diligence missing is that the provider could have kept a record that the DNS records were owned by Alice. They should have been asking questions (or doing additional validation) when Bob tried to create new ones for example.com. reply marcosdumay 5 hours agorootparentHow can the DNS provider decide if Alice actually wants Bob to set her DNS, or if Bob is doing it without permission? You just shouldn't point your domain into DNS providers that aren't providing DNS for you. If you go and add them to your domain, it's reasonable for the provider to decide that what they are doing is correct. Anything you add here (are people thinking about some hard to write TXT record? It surely looks like so) will break more things than it fixes. reply nickburns 4 hours agorootparentVerification link sent to registrant's email address. Change not processed until verification occurs. This is generally the level of diligence (i.e. emailed verification link) that registrars are held to. DNS providers should be held to the same when the requesting account isn't the same account that created the 'earlier' zone file for a given domain at the very same provider. reply marcosdumay 4 hours agorootparentLots and lots of people don't use their own emails on the DSN information. Maybe we should add a requirement that the zone register sends some notification on behalf of the DNS provider. That could work, at least on the TLD level. reply nickburns 3 hours agorootparentRegistrant contact information is maintained by the registrar. The failure of a Registered Name Holder[1] to furnish up-to-date contact information with its Registrar[2] may result in the forfeiture of rights[3] up to and including the suspension or cancellation of the registration itself.[4] Point being that, short of transfer Auth-Codes[5], a verification link sent to the registrant's email address by the DNS provider is the functional equivalent of nearly the most that a registrar may be required to do in order to contact and/or verify a registrant. [1] https://www.icann.org/resources/pages/ra-agreement-2009-05-2... [2] https://www.icann.org/resources/pages/ra-agreement-2009-05-2... [3] https://www.icann.org/resources/pages/benefits-2013-09-16-en [4] https://www.icann.org/resources/pages/registration-data-accu... [5] https://www.icann.org/resources/pages/auth-2013-05-03-en reply marcosdumay 3 hours agorootparentThe registar knows the person's email. But the DNS service often does not. So the only way the DNS service can get a notification to the domain owner is if it's forwarded by the registar. reply nickburns 3 hours agorootparentThe registrant's email address is made part of the WHOIS directories, whether obfuscated by a privacy service or not. It's publicly accessible information in accordance with § 1.1(a)(i) and (a)(iv) of ICANN's stated Mission.[1] The DNS provider absolutely can send a notification to the registrant without having to 'go through' (meanining interact with) the registrar. Even a third-party privacy service merely exists as a notification broker. Any notification sent by the DNS provider would simply pass through onto the registrant directly. [1] https://www.icann.org/resources/pages/governance/bylaws-en/#... reply buzer 2 hours agorootparentprevFrom what I have seen the common way to protect against this is that the DNS service assigns you a random set of DNS servers for your zone (like ns-1887.awsdns-43.co.uk, ns-378.awsdns-47.com, ns-1029.awsdns-00.org, ns-557.awsdns-05.net for reddit.com). All of these must be added to your domain registrar. reply dvzk 1 hour agorootparentI might misunderstand something here, but essentially, the authoritative DNS provider should only need to: (1) check for existing NS records upon registration, (2) never reassign a name server matching #1, and (3) refuse to serve DNS responses from non-assigned name servers. It seems like the vulnerable providers either respond from or assign prior NS hosts, sometimes with randomized lottery thrown in, which only reduces the takeover probability. reply meowface 21 minutes agorootparentI believe you are correct. This is how Cloudflare fixed the issue and how every other provider could fix it. Just may be (considered) a lot of work by providers that currently throw ns01.provider.com and ns02.provider.com at everyone. Krebs's article also mentions it: >What did DNS providers that have struggled with this issue in the past do to address these authentication challenges? The security firms said that to claim a domain name, the best practice providers gave the account holder random name servers that required a change at the registrar before the domains could go live. They also found the best practice providers used various mechanisms to ensure that the newly assigned name server hosts did not match previous name server assignments. reply hk__2 9 hours agorootparentprev> The due diligence missing is that the provider could have kept a record that the DNS records were owned by Alice. They should have been asking questions (or doing additional validation) when Bob tried to create new ones for example.com. Isn’t that this covered by e.g. OVH that sends you at least a dozen of emails before your domain expires? reply nickcw 8 hours agorootparentThis is the DNS records expiring rather than the domain. On most providers DNS records are provided for free as part of having other services (eg a VM) so there is no incentive for the provider to nag you about your DNS records expiring. They are very likely to nag you about your VM expiring without mentioning the DNS records. reply lelanthran 8 hours agorootparentprev> Isn’t that this covered by e.g. OVH that sends you at least a dozen of emails before your domain expires? In this \"attack\" the domain is not expired. reply belorn 8 hours agorootparentprev> A bit later Bob makes an account at the same DNS provider and makes DNS records for example.com. A dns company that goes into commercial relationship with a customer should try to prevent themselves from being used in a crime. DNS registrars are already very much used to this since fraudulent registrations are common place, and top registries generally demand some minimum standards when dealing with it. It is not a major leap to demand something similar from dns services. The issue is kind of similar to account creation bugs, where a user name ALICE (all caps) can masquerader as user Alice. If the new user claims to be alice, they either have to log in with the old account (alt using an account restoration process), or they have to validate that they are in control of the domain name. Validating a sub domain is fairly easy, but even a bare domain is doable using unique ns records, alternatively using any third-party validations (e-id, company registrations, etc.) that other part of society is already using for validation. I see this as a purely dns industry problem that can be solved using existing tools and expectations. reply CGamesPlay 11 hours agorootparentprevMy question is, after this point, can Alice reclaim her domain? Is there any way to automate verification of domain name ownership outside without DNS? reply OJFord 9 hours agorootparentShe hasn't lost the domain, she's lost the ability to control its DNS at the provider she's currently using (the nameservers she set). So as sibling says it's a case of changing the ns to some other provider, or else I suppose a support case to somehow prove you do own the domain, so please assign control back to your account. reply jsheard 6 hours agorootparentWell, if the email address you use at the registrar is under the domain the attacker now controls, they can hijack it and potentially escalate to taking over your registrar account as well. Hopefully you have 2FA set up and your registrar enforces it properly. reply 3np 3 hours agorootparentAnd, y'know, use a separate domain for admin email. reply OccamsMirror 10 hours agorootparentprevShe just needs to change her nameservers at the registrar level. reply detourdog 8 hours agorootparentprevDNS is the verification of ownership. Paying your bill and having a receipt is the verification. reply detourdog 5 hours agorootparentThinking back more I realize that when I first registered my domain there was no money involved. I remember when ethical discussions of charging for domain names. The justification is that buying the domain name proved ownership. I suppose it was also meant to discourage people piping dict into the registration process. There was a land rush for nouns such as pets.com. reply throwaway48540 11 hours agorootparentprevThis definitely feels like an attack. One time I forgot to update my name servers after removing the domain from DigitalOcean and some spammer took it over. Another time I wanted to use DigitalOcean with my domain but I can't add it, because someone else has registered it. reply xmprt 56 minutes agorootparentAfter removing the domain from DigitalOcean did you use the domain anywhere else? It just seems strange to me that you can forget about a domain after explicitly removing that domain from a third party provider. reply handsclean 10 hours agorootparentprevThe difference is whether it can be fixed. An expired domain is hard because we don’t actually know the attacker isn’t legitimate until they misuse the domain. In the case of hosting hijacking, though, the domain still has a legitimate owner, and the hosting provider is giving somebody else access without that owner’s permission. I’d blame the domain owner if they pointed their domain off at some malicious host, but the point here is that it’s hosting providers we consider trusted and legitimate that are doing this, and they can stop doing it, they’re just choosing not to. reply Terretta 4 hours agoparentprevGoDaddy and SquareSpace (now that Google's DNS shifted) are notable by not being listed. reply jorams 2 hours agorootparentThat's probably because they won't host your DNS without having the domain registered with them. reply Brajeshwar 12 hours agoprevUK.GOV has a good guide on \"Keeping your domain name secure.\" https://www.gov.uk/guidance/keeping-your-domain-name-secure reply rozenmd 12 hours agoparentTFA reminds me that most people miss the basics (eventually letting their domain expire), which is a much bigger threat than domain takeover: - Enable 2FA - Check that your domain is set to auto renew - Lock your domain from transfer - Check your payment details - Use a reputable domain registrar - Be sure you actually own your domain - Extend your domain registration - Be aware of any TLD-specific rules around renewals from: https://onlineornot.com/guidelines-to-help-avoid-losing-your... reply precommunicator 8 hours agorootparentIf your domain name is critical to you, pay 10 years in advance where possible, and still extend every year, to keep this 10 year buffer. reply detourdog 8 hours agorootparentI did a 100 year registration. This was under $1;000 about 10 years ago. The status only show 10 year increments. I did it with network solutions. reply zaphirplane 5 hours agorootparent100 years is too long, you will completely forget to renew reply bongobingo1 8 hours agorootparentprevDo you worry about the registra going down during that time? I guess ICANNs records should include the lease length and as long as you can prove you exist at the correct physical address or whatever you can \"reassign\" it to a down stream registra? reply detourdog 7 hours agorootparentThe domain pre-exists ICANN. I guess I’m counting on money and receipts still being being valid. If I ever find myself with a fear that hints at a breakdown of society or the monetary system I pull back and reorient my perspective. If society fails planning likely won’t help. reply xmprt 54 minutes agorootparentI think a lot of people make bets like this that are very black and white. It's also very possible that something goes wrong at the registrar and your receipts aren't accepted because they don't have any records of it on their end. And society doesn't collapse but you're still screwed. reply layer8 1 hour agorootparentprevIt’s safer to regularly have a transaction with the registrar. This serves as a sanity check that they keep record of your registration. Without any interaction, a lot can go wrong over decades, and you might notice only too late. reply pricechild 11 hours agoparentprevIronic as last I checked (admittedly 2016) .uk domain transfers saw no verification: https://pricey.uk/blog/uk-domain-transfers-are-scary/ > I registered a new domain at one registrar and immediately asked they change the IPS tag to another. A coworker [saw] ... the tag change, but then I got distracted looking for cake/looking over their shoulder. They set up a new account at the second registrar and claimed the domain, using no secret information and without either registrar or Nominet gaining my consent. To be clear, the IPS was (is?) publicly visible. So you could poll a list of domains looking for it. It's worth noting that even if you registered .co.uk with e.g. Gandi, you still get a separate Nominet account with it's own authentication. It doesn't matter if you add 2FA etc - after such a transfer, the domain was registered to a different nominet account. reply ChrisArchitect 4 hours agoprevActual report: https://blogs.infoblox.com/threat-intelligence/who-knew-doma... (https://news.ycombinator.com/item?id=41120214) reply everfrustrated 3 hours agoprevPart of this problem is authoritative dns server operators not sharding their zones. The only provider I know who does this correctly is AWS Route 53. Your zone gets assigned 4 unique authoritative servers from a set of namespaced shards. eg ns-2048.awsdns-64.com Someone else can create a zone for the same domain but will map to different shard so no real world effect. Always surprising to me that hardly any providers do it. reply Uvix 1 hour agoparentAzure DNS does the same. reply octopoc 3 hours agoprevWhat happens if you set your name servers to e.g. Digital Ocean then go to Digital Ocean and try to add your domain name there but you find that an attacker has already created that domain name under their account? They were watching the name server records on your domain. reply vel0city 44 minutes agoparentI always set up at least the basics of the zone first, then point the nameservers. Why would you point to nameservers that know nothing of the zone?! reply sybercecurity 3 hours agoparentprevI'd change the registration info at the registrar - park the zone if you must. That would at least stop the attack from continuing (caches would still have the attacker's responses). The best defense is to set up the delegation at the host first, then set up the delegation information at the registrar. A stub zone is could be run indefinitely (as long as there were no name collisions) before a formal delegation from a TLD is set up. Gives you time to set things up the way you want before it is reachable from global DNS tree. reply Joeboy 10 hours agoprevSomewhat related question: I have a (obscure) domain that I'm planning to let expire soon. Is there anything I could / should do to stop it being used for questionable purposes? reply belorn 7 hours agoparentCreate a permanent redirect to any other site should transfer any search \"scores\" onto the new site. You can also request google to de-list the domain from search, which should reset any value that the domain has acquired from the time you owned it. If the account is validated on large platforms, it should be a good idea to remove those from the account as a way to signal the platform that it is no longer validated on that site. reply 8organicbits 2 hours agoparentprevDelete any accounts you've created using that domain, those could be taken over by the new owner. Especially important if you ever used email on the domain. reply sybercecurity 3 hours agoparentprevSome TLDs/registrars let you park registrations. They won't appear in the DNS, but they can't be registered by anyone else. Or there is a delegation to some internal hosting service that the registrar operates that is an empty zone (i.e. no A, MX, etc.) so there is nothing reachable. I've done this with zones I've had for a while - it sucks since you want to be a good net citizen and not let the zones be used for spam/attacks. You end up paying for a domain for years after you stopped needing it. reply kxrm 10 hours agoparentprevOnce you let your domain expire you no longer have any say over what happens with the domain so no, not really. I would just recommend cleansing the domain from any systems you may have used it on and ensuring that you have no other technical ties the domain. Treat it just like any other domain you do not own. reply pabs3 3 hours agoparentprevFirst, let ArchiveTeam know, so that we can save anything public you have on the domain to archive.org so it will persist beyond the expiry. https://archiveteam.org/ reply hk__2 9 hours agoparentprevIf you don’t own the domain then you have no say over what’s it’s used for. The only thing you can do is not to let it expire. reply loopdoend 12 hours agoprevIsn’t this the same as the spammy bear attack? reply 256_ 4 hours agoprevFrom TFA: > DNSMadeEasy founder and senior vice president Steve Job That name surprised me. I thought it couldn't possibly be real. I looked it up and apparently that's actually his name; presumably no relation to the plural one who ran Apple. Most articles seem to write his first name with an N to make it more believable. reply StuntPope 2 hours agoprev [–] The Gell-Mann Amnesia is strong in this story and thead. As I posted on Krebs' article: This is neither news nor new. There have been prior panics around this “water is wet” type issue going back at least a decade. (Search up “Floating Domains – Taking Over 20K DigitalOcean Domains via a Lax Domain Import System” – and others). I also wrote about this on CircleID from the DNS operator’s perspective (“Nameserver Operators Need the Ability to “Disavow” Domains”) – after this same issue was used to DDoS attack another DNS provider by delegating a domain to their DNS servers without having setup an account there, and then doing a DNS reflection attack on that domain. That was over ten years ago. The fact that people can delegate their own domains to somebody else’s nameservers without ever properly setting up a zone on those nameservers, or ever keeping track of where THEIR OWN DOMAINS point is 100% the responsibility of the domain owner – and to varying degrees a function of their REGISTRAR – who is the only entity that has any control over it. It’s a weird flex for corporate registrars who purport to be “high touch” and exclusive, to simply shrug their shoulders and turn a blind eye to their own clients’ obviously broken and vulnerable nameserver delegations. For our part this is specifically one of things we actively monitor and alert our clients about. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Over a million domain names, including those from Fortune 100 companies, are vulnerable to cybercriminal takeover due to authentication weaknesses at major web hosting providers and domain registrars.",
      "Research by Infoblox and Eclypsium highlights that many large hosting and DNS providers still have this vulnerability, allowing cybercriminals to hijack domains and conduct phishing attacks.",
      "Solutions being explored include using random name servers and ensuring new name server hosts do not match previous assignments, but better cooperation among stakeholders is needed to mitigate these risks."
    ],
    "commentSummary": [
      "If a domain's account with a third-party nameserver expires, someone else can take control of the DNS zone, compromising the domain's credibility.",
      "Cloudflare had a loophole where attackers could take over domains by creating new accounts with the same nameservers, but this issue has reportedly been fixed.",
      "The primary solution is to ensure that NS (Name Server) records are updated and controlled by the domain owner to prevent unauthorized takeovers."
    ],
    "points": 180,
    "commentCount": 73,
    "retryCount": 0,
    "time": 1722477612
  },
  {
    "id": 41126685,
    "title": "Study: Consumers Actively Turned Off by AI",
    "originLink": "https://futurism.com/the-byte/study-consumers-turned-off-products-ai",
    "originBody": "Hype Trough Study Finds Consumers Are Actively Turned Off by Products That Use AI byVictor Tangermann \"When AI is mentioned, it tends to lower emotional trust, which in turn decreases purchase intentions.\" Jul 31, 5:32 PM EDT Getty / Futurism \"When AI is mentioned, it tends to lower emotional trust, which in turn decreases purchase intentions.\" Trough Luck Researchers have found that including the words \"artificial intelligence\" in product marketing is a major turn-off for consumers, suggesting a growing backlash and disillusionment with the tech — and that startups trying to cram \"AI\" into their product are actually making a grave error. As detailed in a new study published in the Journal of Hospitality Marketing & Management, researchers presented 1,000 respondents with questions and descriptions of products. Surprisingly — or perhaps not, depending on your perspective — they found that products described as using AI were consistently less popular. \"When AI is mentioned, it tends to lower emotional trust, which in turn decreases purchase intentions,\" said lead author and Washington State University clinical assistant profess of marketing Mesut Cicek in a statement. \"We found emotional trust plays a critical role in how consumers perceive AI-powered products.\" Strong Pass In an experiment, the researchers found that a group of participants were far less likely to purchase a smart television when its description included the words \"artificial intelligence.\" A separate group was far more likely to buy it when the words were omitted from an otherwise identical description. For \"high-risk\" purchases such as expensive electronics or medical devices, the effect was even more pronounced, with Cicek suggesting that consumers are more wary of monetary loss or danger to physical safety. \"We tested the effect across eight different product and service categories, and the results were all the same: it’s a disadvantage to include those kinds of terms in the product descriptions,\" Cicek said. That kind of growing mistrust is symptomatic of a much larger trend. Earlier this year, technology research and consulting firm Gartner found that the hype surrounding generative AI had passed the \"peak of inflated expectations,\" which is marked by \"overenthusiasm and unrealistic projections.\" Companies are feverishly trying to stuff what they claim to be AI into every product, from dating apps to automated car salesmen — despite glaring shortcomings that have yet to be solved and mounting, astronomical costs. And consumers are getting tired of their desperate attempts to capitalize on all the hype. \"Marketers should carefully consider how they present AI in their product descriptions or develop strategies to increase emotional trust,\" said Cicek. \"Emphasizing AI may not always be beneficial, particularly for high-risk products. Focus on describing the features or benefits and avoid the AI buzzwords.\" More on AI: Meta's AI Says Trump Wasn't Shot Share This Article",
    "commentLink": "https://news.ycombinator.com/item?id=41126685",
    "commentBody": "Study: Consumers Actively Turned Off by AI (futurism.com)161 points by 12_throw_away 12 hours agohidepastfavorite172 comments mrtksn 9 hours agoJust an anecdote but I had a small mobile app that would make people pay money for the premium features, and (surprising for me) many people happily paid. Although the app had very positive reviews, it wasn't growing fast enough to make it into a meaningful income. So I told myself, why don't I add AI stuff on it like an AI assistant as a primary way of interaction? Everyone loves AI, it's the future! Then the app retention tanked, as well as the install numbers and no purchase was made after that. People didn't even bother with leaving bad reviews. Maybe we are in this strange situation where the people who make the products are so hyped about this new tech but the consumers are really hating it. Like the artificial sweeteners maybe? \"0 calories and the same taste with the sugar? Why would anybody ever use sugar again, right? Lets short the sugar cane and corn fields and put all our money into artificial sweeteners production equipment and chemicals\" reply noobermin 9 hours agoparentSincerely, everyone in my real life I know bemoans AI hype. The only really love it has is in memes (things like voice swaping, singing politicians, things like that). I'm surprised people on HN have no exposure to such people. reply edanm 8 hours agorootparentHow many people in your life \"hate AI\" but love that feature in Google Photos that lets you search your photos by a person's name? People don't generally like or dislike the combustion engine. They like the ability to get from place to place faster. reply temac 7 hours agorootparentProbably when writing \"hate AI\" here the meaning was hate the often useless text chat bot. Google Photo face recognition was there before the new hipe and is probably not designated talked by primarily as \"AI\" by the general public. reply YeahThisIsMe 7 hours agorootparentPeople also like privacy, and most of the time \"AI\" means \"your stuff is going to our servers\". I don't need or want that from most applications, especially a photo viewer. reply xboxnolifes 41 minutes agorootparentMost everyone I know in real life do not care about that kind of privacy. They happily upload anything to anywhere on the internet. The people who do care tend to fall in one of two categories: More tech inclined (programmers), or the same kind of person who doesn't use online banking because they are afraid of losing their money. reply benterix 6 hours agorootparentprev> most of the time \"AI\" means \"your stuff is going to our servers\". It almost always does but only because it is offered this way, it is not a hard technical requirement. There is nothing that would prevent offering a standalone version running locally for customers with their hardware powerful enough. reply jsbisviewtiful 44 minutes agorootparentprev> love that feature in Google Photos that lets you search your photos by a person's name? Is that even considered AI by the hype/marketing machine? It's been around longer than these new language models. reply navjack27 7 hours agorootparentprevIt was never AI as people are using it today. Back in 2014 2015 2016 or whatever it was just facial recognition. In fact there's nothing smart about it. It detects the face and then you put a name to the face. It does nothing else. reply ben_w 7 hours agorootparentI'm old enough to remember when the ability for machines to recognise faces was in the same category as flying cars: tech demos in the news, but you couldn't use them in any practical sense. reply edanm 6 hours agorootparentprevA constant theme in AI is that as soon as something is achieved, it becomes \"no longer AI\", just tech. That's kind of my point. Nobody cares what you call it or how it works, they care about the actual value they get out of the feature. Also, back in 2014, it wasn't \"just\" facial recognition. It was the dawn of the new age of Deep Learning, bringing capabilities that had never existed before. reply iainctduncan 4 hours agorootparentprevSure, but what car maker is yelling \"Combustion engine in here, it's SO AMAZING!\" - and would you trust one who is? reply tim333 1 hour agorootparentA lot of the ones with amazing combustion engines are a bit pricey. The Koenigsegg Gemera engine is cool. reply maximilianthe1 3 hours agorootparentprevJeep Grand Cherokee Trackhawk has a combustion engine, it's SO AMAZING! reply prisenco 8 hours agorootparentprevI bemoan AI but it's been disheartening as the hype spreads everywhere. It feels like everyone is building an AI startup. Maybe I'm naive, but it doesn't feel like we're done building the boring stuff yet. reply mdm12 8 hours agorootparentWe're not done building the boring stuff or solving the hard problems either. One is, well, boring and the other is...hard. Easy enough to proxy out prompts to OpenAI for your next funding round, though. reply pjc50 9 hours agoparentprevhttps://news.ycombinator.com/item?id=41119245 - as I said last time, it's become a cheapness signal. reply tim333 1 hour agorootparentI'm a bit wary that something calling itself AI may be like Siri or some bad customer service bot. reply rsynnott 4 hours agoparentprev> Maybe we are in this strange situation where the people who make the products are so hyped about this new tech but the consumers are really hating it. This isn't that strange. There have been a number of things that people have tried to push upon consumers over the last few decades that just haven't landed. Notable examples: 3d TVs, metaverses. reply navjack27 7 hours agoparentprevNo this is actually exactly 100% it. It's not a strange situation it is just simple irrational exuberance for AI. Consumers do actually hate it. They don't want to be around it and they don't want it anywhere. reply ElFitz 5 hours agoparentprevThere’s the issue that many products seem to consider AI to be a feature in itself, and market it as such. People don’t care about it. They just want to do whatever it was they wanted to do. It doesn’t matter wether the tool uses hardcoded empirical heuristics, a hand-crafted statistical model, AI, or leprechauns. reply frde_me 9 hours agoparentprev> Maybe we are in this strange situation where the people who make the products are so hyped about this new tech but the consumers are really hating it. I think everyone is tired of conversing with a chatbot over text by now. But there are ways of integrating AI without making the primary interactions a pain. I'm also a bit puzzled by why people think it's a good idea in the first place Using a chatbox as a way to do primary interactions? Nope. But use that same AI to quickly summarize reviews for a product into a digestible format that I can easy glance at, or ignore? That last one actually saves me time, and doesn't harm my user experience, so why not? reply InsideOutSanta 8 hours agorootparentMost LLM-based chat user interfaces are just so terrible. They seem interesting on a surface level, because it feels like they should be able to help with whatever issue you have, and the demos make it look as if they do, but in reality, they almost never do anything. They just pretend to be a human who has the ability to actually do something. When Microsoft showed Windows Copilot, what they showed made it feel like you could do things like tell it to \"create a new user account with the name John and the password 285uoa29tu and put the picture of a dandelion as the profile picture,\" but you can't. It can't really do anything, other than give you (often misleading) advice on how you can do things yourself. People have learned that. They have learned that these chat LLMs are just a facade used to waste their time, a simulacrum not of a human being, but of the outward appearance of a human being. It's another hurdle companies put in place for people to jump across before they can talk to an actual person who has the actual ability to do something for them. So when people see \"AI\", they don't see \"helpful tool,\" they see \"an obstacle I have to get rid of to actually get anything done.\" Who would want to pay for that? reply mrtksn 9 hours agorootparentprevI agree, IMHO people don't like to interact with AI, but they love it when the tedious work is done by AI. The interaction part is cool at first until your curiosity about the tech itself vanishes. The current AI tech has some very useful use cases and its here to stay but its not replacing human interaction or the Human-Computer interface as I previously believed. The AI pin, Rabbit and who knows who else failed in attempting to replace human interactions or screen UI with speech or text. Chatbots look so deceivingly capable but they are completely useless when it comes holding authority and trust. Every real human will always provide you with accurate information best to their knowledge and when they fail on it(sometimes in bad faith) its considered a big deal and can lead to anything from being angry with to not trusting that person ever again(therefore ignoring that person when possible) and in some cases imprisonment of the person. AI lying is too cheap to warrant a human interaction. It's pure waste of time when it comes to doing anything consequential. reply benterix 6 hours agorootparentprevMaybe because chatbots in general, not just AI chatbots, are a terrible idea in the first place? And even in the cases where idea might be somewhat OK (instead of wading through tons of support documents or FAQs just ask a question and get redirected to the answer) it usually is implemented terribly. Honestly, what's the point of even considering implementing it if the only interaction will be \"I want to talk to a human\"? reply klyrs 5 hours agorootparentprev> But use that same AI to quickly summarize reviews for a product into a digestible format that I can easy glance at, or ignore? You want to give them more plausible deniability in lying to you about reviews? reply beowulfey 7 hours agoparentprevIn my experience, the people in my friend group are wary of AI because of the potential it has to eliminate jobs. I think the generally negative connotation comes from this \"replacement of human effort\" interpretation. If it can be done cheaper and easier with AI, that will naturally supplant effort a human could have made. Since non-techies are often the people being displaced in this scenario, it doesn't sit well with them when AI shows up in a product they like. (For what it's worth, I mostly agree with this sentiment.) reply madaxe_again 8 hours agoparentprevThe current wave of AI stuff is likely not indicative of how AI will be used in consumer-facing businesses in the future. At the moment, it’s there for all to see, be it as a chatbot or whatever - but the real applications will be under the hood, not directly interacting with the consumer, doing everything from market microsegmentation to tailored recommendations to diagnostics, credit scoring, criminal profiling, fraud detection, and all of the things that currently rely on sub-optimal human-crafted algorithms or even hand-cranking. So all in all, what consumers think of AI is almost neither here nor there, as they are not the primary market - business and government are. reply red-iron-pine 2 hours agorootparent> The current wave of AI stuff is likely not indicative of how AI will be used in consumer-facing businesses in the future. wut. the first real deployments we've seen of LLMs are chatbots, esp. those aimed at consumers. hence all of the \"sell me a Chevy for $1\" memes. > At the moment, it’s there for all to see, be it as a chatbot or whatever - but the real applications will be under the hood, not directly interacting with the consumer, doing everything from market microsegmentation to tailored recommendations to diagnostics, credit scoring, criminal profiling, fraud detection, and all of the things that currently rely on sub-optimal human-crafted algorithms or even hand-cranking. That's already a thing, and is what FB and GOOG (or banks like Ant Financial, etc.) have been making money off of for years. reply conartist6 7 hours agorootparentprevIn other words, its job will be perpetual-bias-perpetuator! I cannot fucking wait. reply ben_w 7 hours agorootparentCould be. One of the annoying things is that when the AI has a bias people agree with, they say \"algorithms can't be biased!\", yet when the AI has one they do disagree with \"it's so unfair they've made it woke/racist [delete as appropriate]\". Reality is difficult, AI is difficult, statistics is difficult, everything is difficult. Accidental bias is almost inevitable no matter what, and that's one of the things GDPR is there for, to make sure errors can be fixed. reply anonymousab 2 hours agorootparentThe EU AI act that went into force today also spells out some limitations. I think it would have been fun to require companies using AI to prove/show exactly why it makes a determination or decision, upon request, if it's being used to make decisions where we say that such biases should not be perpetuated. That this is burdensome or not yet possible with current LLM limitations is a problem to solve (or \"tough shit\") for the companies creating or using this technology; a necessary reckoning that they should have been forced to face from the onset. reply lotsofpulp 9 hours agoparentprev>Like the artificial sweeteners maybe? >\"0 calories and the same taste with the sugar? Why would anybody ever use sugar again, right? Lets short the sugar cane and corn fields and put all our money into artificial sweeteners production equipment and chemicals\" No one ever thought this because low calorie sweeteners taste different than refined sugar. Even cane sugar tastes different than high fructose corn syrup. Also, they are all chemicals. Everything is. Stevia is even extracted from a plant, just like cane sugar or corn syrup. reply mrtksn 9 hours agorootparentIt's hypothetical example for a product that is supposed to be a replacement to something we readily use but has an issue like being too expensive/rare/hard to make. I don't know much about sweeteners, for me its this thing that you can use instead of sugar if you are concerned about calories. reply cqqxo4zV46cp 9 hours agorootparentprevIt is incredibly obvious what is colloquially meant by “chemicals”. There’s no such thing as a fish. Blah blah blah. Don’t be tone-deaf in the name of scoring an extra point online. reply rcxdude 8 hours agorootparentIt's obvious, but worthless. It's an entirely subjective metric, easily gamed by marketing, and correlates poorly with things that actually matter. reply lotsofpulp 8 hours agorootparentprevOther than to baselessly denigrate, it is not obvious to me what is meant by “chemicals”. reply harimau777 5 hours agorootparentA working description might be some combination of: - Synthesized or highly processed versions of or replacements for a normally natural or well established substance; often for the purpose of cost. E.g. high fructose corn syrup, artificial flavors, rayon, chrome tanned leather, etc. - Synthesized or highly processed substances that promise to provide the advantages of a natural or well established substance but without any of the drawbacks. E.g. sweeteners without calories, waterproofing sprays that promise breathability, anti-stick coatings that don't require the care of cast iron, replacing metal with light weight plastics, etc. For me it tends to come down to two rules of thumb that my life experience has given me: - Highly processed products (particularly food) tend to be unhealthy. - There is no free lunch. If some new material promises to eliminate the drawbacks of an existing material, then it probably has different drawbacks that you don't know about yet. reply consteval 50 minutes agorootparent> There is no free lunch This is just a heuristic, and honestly barely that. It's a belief. Often there really is free lunch, and that's just progress. Sometimes I think people like to pretend otherwise because it's comforting to deny yourself of convenience. Aspartame really is zero calories. And it really is safe. Yes, much safer than sugar. No, it doesn't magically make you gain weight. No, it doesn't cause cancer (feeding rats 500 coke bottles worth of aspartame doesn't count!). Yes, it's less carcinogenic than red meat. From a health standpoint it's better in every single way. Of course taste is another thing all together, and subjective. Point being, yes things CAN just be better. reply anonymousab 2 hours agorootparentprevThe people posting about chemicals-in-the-food and stuff like that in my area definitely don't see high fructose corn syrup as a chemical - \"it comes from corn and corn is grown in fields\" is all I ever got out of that discussion - but definitely do see stevia as one. Maybe the definition is more of a regional thing. Or maybe it's just more BS. In any case I don't think it's remotely consistent or concrete. reply Eisenstein 8 hours agorootparentprevWhat is colloquially meant by 'chemicals'? I usually take it to mean 'a substance with a name that I don't understand and that I think isn't natural and that I want to imply is not good for you' and there is no definition beyond that. It is perfectly reasonable to point out that this is irrational. reply Nursie 8 hours agoparentprevMy tech friends mostly find it interesting. On top of that some of them find it a little threatening, others (like me) are somewhat concerned about the ethics of hoovering up a significant proportion of human creativity and then charging money back to people for the output of models based on it. My non-tech friends, particularly the more creative ones hate AI and will actively avoid it. They see a way for rich tech bros to put real people out of jobs. They see ahead of them an internet drowning in AI shit (on an internet already drowning in non-AI shit), further enshittifying their day to day interactions. And they see yet another ludicrous hype cycle. My challenge to AI-using folks is the same as it was to blockchain people - make a product with compelling, amazing features. Don't mention AI, just sell it on how awesome it is and how amazing the capabilities are. Use AI/ML under the covers to achieve that awesomeness without trying to ride the hype wave. Then you'll have achieved something. The difference is, of course, that I imagine that AI will (and to some extent already does) deliver on that... reply ogou 9 hours agoprevI travel often in Europe and see these AI assistants on many websites and apps now. Two things generally happen when I have tried to use them. First, nothing actionable is possible. They can't actually do anything. No trip changes, refunds, connections, or baggage tracing. It takes a significant amount of time to get to to the response, \"Sorry I can't help with that, please call xxx during business hours or visit our website at xxx.\" Second, they invariably end up as marketing funnels with upsells offered in place of solutions. I see that as the main source of anger from others in airports. They try to deal with something and end up in marketing loops. When I see AI assistance as a travel feature I assume it is not only going to be useless, but actively disruptive to my experience. reply Nursie 5 hours agoparent“Yet another layer I have to fight through before I can speak to someone who may actually be able to do something useful” Yup. reply Quothling 10 hours agoprev> they found that products described as using AI were consistently less popular. Branding the mistakes LLM's get as hallucinations was sort of brilliant in my opinion, it was a good way to disguise the fact that LLM's are mostly just really lucky. In my anecdotal experience it hasn't worked out too well though, so maybe it wasn't that brilliant? Anyway, parts of how the AI impacts our business (solar energy + investment banking) has been through things like how Microsoft Teams was supposed to be capable of transcripting meetings with AI. Now, we're an international organisation where English is at best the second language for people, and usually the third, so this probably has an impact on it, but it's so bad. I know I'm not personally the clearest speaker, especially if I'm bored, but the transcripts the AI makes of me are so hilariously bad that they often become the foundation for the weekly friday meme in IT. Which may be innocent enough, but it hasn't been very confidence building in the higher ups who thought they wouldn't have to have someone write a summary for their meetings, and in typical top brass style didn't read the transcripts until there was some contract issue. This along with how often AI \"hallucinates\" has meant that our top decision makers have decided to stop any AI within the Microsoft platform. Well every thing except the thing that makes power point presentations pretty. So our operations staff has had to roll back co-pilot for every non-IT employee. I don't necessarily agree with this myself, I use GPT quite a lot and while github co-pilot might \"just\" be fancy auto-complete it's still increased my productivity quite a lot as well as lowering my mental load of dealing with most snippets. That isn't how the rest of the organisation sees it though, they see the mistakes AI makes on areas where no-mistakes are allowed, and they consider it untrustworthy. The whole Microsoft debacle (I used chatGPT to tell me how to write \"debaclable\") where they wanted to screenshot everything all the time really sunk trust with our decision makers. reply tssge 5 hours agoparent>but the transcripts the AI makes of me are so hilariously My experience on AI transcripts is different: I use auto (AI) generated captions on YouTube for every video and while there sure are some mistakes with especially names and specialized words, in general it is highly understandable. So much so that that I miss the auto generated captions when they're not available. Even if real captions are available, on occasion I have to swap out from the human made captions to the auto generated AI captions, because believe it or not in some cases the AI generated captions are actually better with less mistakes! I find that rather impressive from the AIs side. reply akira2501 8 hours agoparentprev> but the transcripts the AI makes of me are so hilariously bad They improve significantly with microphone quality. I have a professional voice recording setup I use with Teams and the transcripts are usually around 90% accurate. A tool like AWS transcribe tends to get 95% on my voice work. reply ksaj 10 hours agoprevThey're turned off on the lingo showing up everywhere, regardless of its relevance (or lack thereof). It's similar to when the Internet first started becoming commercial, and people were revolted by terms like \"information superhighway\" etc being thrown around so excessively. Eventually everybody grew into it, and we can't imagine life without the Internet. AI is having that same moment right now. The breathless hype bombardment will eventually give way to normalcy just the same. reply louthy 9 hours agoparentI think this is true, but it's worth expanding, because it's not just lingo. Personally, I am sick of seeing AI generated images in blogs, advertising campaigns, and in social media posts. There's a weird uncanny valley to them that always puts me off. I think subconsciously it makes me devalue whatever the image is attached to. I might end up being negatively biased toward a blog author, or refuse to engage with a company that is using AI based imagery. Of course, it's likely that we'll get past that point, where AI generated images aren't in the uncanny valley, but until then it's off-putting. Recently I had an email from someone praising my open source work and it was clearly AI generated, which felt completely insincere. And so, misuse of AI in situations where it makes the human being that interacts with it balk isn't good either. As you say the language is annoying: \"AI powered\" or similar language is just meaningless to most people. People are not turned off by features in software that 'just work' because there's some AI running quietly behind the scenes. They're put off by bold claims that don't actually materialise and the human/AI interaction-boundary that can sometimes lead to more effort on the part of the human. AI is a technique used by software engineers, we shouldn't need to talk about it at all (except to each other and maybe VCs). We don't market our apps as \"Relational database powered\", in time we won't mention AI at all. reply whstl 9 hours agorootparentTo me the problem is not just being in the uncanny valley: even when they are realistic they are often way too mediocre! Not just the visuals but the content as well. It's always stuff that nobody would bother drawing or staging to take a photograph. And I associate it with laziness, low effort, low quality, throwaway content. Same for AI generated text: it's super easy to see when something is AI generated and follows a pattern. Those patterns get quite tiring to read after a while. In hotel websites, for example, there's often AI text that is obviously converted from existing tabular data. I would prefer to have proper UX for the data instead of the text. With text it's harder to scan for specific information or to compare between pages. reply louthy 8 hours agorootparent> even when they are realistic they are often way too mediocre! 100% agree and wish I’d also made that point in my post! It’s like it’s taken the average of human creativity, so everything is average. The unrelenting blandness is definitely offensive. reply ksaj 7 hours agorootparentYou describe it like an oxymoron: Extremely mediocre. Because it is based on a really big average. Having said that, it is exactly why training an AI on AI output results in utter crap. This has been known since before AI, so it's funny to see it arising in this industry. reply ksaj 8 hours agorootparentprevThere are easy examples that prove both sides. Depending on your use, the current state of AI does some amazing things. It also is being pigeonholed into areas where it is not yet ready. There are a LOT of examples out there on that. A hobby of mine is using AI to find bizarre ways to code things that aren't the normal way of thinking of the problem. Obviously it isn't practical, but it is fun. I most recently got ChatGPT to generate Pi from a random length string of 5's like this: ~~~ from math import sin, radians def fives(repeat: int) -> float: repeated = 1 / int('5' * repeat) value = sin(radians(repeated)) * (10 ** (repeat + 2)) return value ~~~ Yes, it uses a repeating string of 5's to generate pi. Call it with \"fives(18)\" as an example. This is a cleaned up version of what ChatGPT gave me, but all the same, it works. A string of 5's can give you progressively more accurate estimations of pi - more 5's, more accurate pi. Bizarre question to ask an AI, but playing like this is how eventually discoveries are made, since it is capable of coming up with working answers. (Edit: corrected markdown copy-pasta weirdness. You can copy/paste but have to remove the extra indents HN adds. It's normal python, you know how to do it.) reply whstl 8 hours agorootparentThis is interesting, but that's because you started with an interesting question, and probably also because you know how to code. The problem with AI blogspam (and AI image spam) and is that most of it is not even interesting to begin with: the desired result and the prompts are already terrible, so even if it was custom drawn or written by a professional, it would be crap. With AI, because of the lower barrier to entry, people don't care about spending a few cents building garbage. This is why I doubt more quality AI will help. :/ reply ksaj 7 hours agorootparentSpam (and porn) industries are highly opportunistic, in that they exploit every new technology, often before more productive uses are found for them. Unfortunately this is just one of many that gets treated the same way. The professionals using AI (and even then, a minority of them) actually spend the time to ensure they're getting quality results. Even AI requires some massaging to get what you actually want. It's a tool. Not a miracle. A carpenter doesn't just bang a nail once and expect things to hold together. I'm not a particularly good coder. I'm just interested in the oddities that can be shown through code, and am just (barely) savvy enough to see it through. I only had a vague idea how you could get pi from a string of 5's, but it wasn't very hard to get ChatGPT to code it for me once I described it. The same can be done with a randomish length string of 9's, but I'll leave that for others to discover. reply plasticeagle 8 hours agorootparentprevBut... This code just outputs almost-zero. It clearly just sets `repeated` to a number very close to zero, takes the sin of it - which will also be close to zero - and then multiplies that by a small number. I don't think this is how discoveries are going to be made. What am I missing here? reply ksaj 8 hours agorootparentIt outputs a very close estimation of pi every time. The slash-* is from how HN interprets the code (poorly). Here's a corrected one using a margin: from math import sin, radians def fives(repeat: int) -> float: repeated = 1 / int('5' * repeat) value = sin(radians(repeated)) * (10 ** (repeat + 2)) return value fives(18) Cut/paste that into your python repl, and make sure the lines are intact without the HN extra indents. Change the 18 to any int you want (except it overflows at 308... easy to fix, but not worth bothering). It might be close to zero... but it's much more like 3.14... when you run it. reply plasticeagle 8 hours agorootparentYes, that does fix it. But using `sin`, and `radians` means that you equation to generate pi already has pi in it. reply ksaj 7 hours agorootparentSure. But make the connection with the 5s. It isn't just copying that pi. It is getting there in a very non-direct route. You can do the same with 9s, for the same reason you might be picking up on if you don't trivialize that there is another pi in the mix. You can't escape it when you're talking about circular things, regardless. Every proof or non-coincidental estimate of pi (ie: not 22/7) out there has pi embedded in the proof somehow. Dismissing it is like saying the Pythagorean theorem is bollocks because they also add up to the same number of degrees. Even though you're describing it in lengths, the degrees don't disappear. This code is very much like that. Just not triangular. reply valicord 5 hours agorootparentThe thing is that in this particular case it does in fact just copy the pi. You're essentially calculating radians(x)*180/x, which by definition is equal to pi. The radians function is doing all the heavy lifting, unlike say using the Taylor series or some other approximation approach. reply ksaj 2 hours agorootparentIt is doing this: sin(555555555555555555), where the 5's are an x number of 5s that increasingly converges on pi, and calculates the correct decimal placement. It's not (quite) as trivial as just copying the pi. reply valicord 1 hour agorootparentNope, that is not what it does. First, sin(x) ~= x for small x. Second, 1000.../555... = 1.8. Neither of these have anything to do with pi. With these in mind, the program can be simplified as sin(radians(repeated)) * (10 ** (repeat + 2)) = radians(repeated) * 100 * 1.8 / repeated = repeated * pi / 180 * 180 / repeated = pi The main and only reason you get pi in the end is that the radians function is defined as radians(x) = pi * x / 180, which requires knowing the value of pi to begin with. So this program is basically an equivalent of multiply_the_argument_by_pi(555) / 555 except with a few layers of completely unnecessary math on top of it to obscure the magic trick. reply ewoodrich 9 hours agorootparentprevLately I’ve been seeing Reddit ads with clearly AI generated marketing images and it just makes me assume the company is an unserious fly-by-night operation and/or a one person company. The most embarrassing recurring ad I’ve seen lately is for some kind of device management IT solution with AI generated MacBooks where the Apple logo is completely mangled. No idea how you could overlook that or notice it but somehow think it doesn’t cheapen your company’s image. reply louthy 9 hours agorootparent> it just makes me assume the company is an unserious fly-by-night operation and/or a one person company Exactly this. Any serious company would manage their brand seriously. Even if you're a one person bootstrapped startup, you should take your brand seriously and get some artwork commissioned. It isn't that expensive and makes a massive difference to how you're perceived. Using AI generated images says to me (rightly or wrongly) that you take shortcuts. So, if you take shortcuts with your brand, what's your product like? reply nicholassmith 9 hours agorootparentprevWhilst watching the Olympics I've seen an eToro ad a few times that is very clearly AI generated, it wasn't exactly a confidence builder in a financial platform. reply outofpaper 9 hours agorootparentprevAbsolutely, AI's impact is clear-cut. When it works seamlessly, it fades into the background, letting non-engineers enjoy our creations. But when it falters, it distracts and adds no value. Our focus should be on delivering flawless creations that provide real value, regardless of the technology behind them. reply j45 9 hours agorootparentprevThe generations are so basic that they make the brand look cheaper. You pretty much have to be at the cutting edge of generative ai to generate images, etc, but it still may have a shelf life. reply ksaj 9 hours agorootparentThis is absolutely true. Sonu is an AI music creator. Regardless of music style, I can immediately identify it. There are some very obvious (to me, anyway) musical choices it makes with both notes, and their delivery. Rick Beato (YouTube music personality, for lack of a better description) pointed out his kids can tell, but he can't. I think, at least with Sonu, the moment the sound clicks, you can't not hear it when it's there, whether the song is pop, metal, country, classical... it has that specific sound that can't be ignored when you notice it. reply Nursie 8 hours agorootparentTry out udio. I was absolutely blown away by it. It's clear that it has been trained on everyone's real output, ever, and their \"You can't request the styles of real artists\" is just a figleaf. But the output is impressive. reply ksaj 7 hours agorootparentThe idea that you can insert words like \"Doors\" and hope it uses but not knowingly bits from \"The Doors\" is pretty much the opposite of a figleaf. People often put things like that in their prompts, and confirmation bias tells them it worked when they run it a few times and get something that sounds like The Doors, even though the meaningless bit of prompt you gave it was simply ignored. The similarity is because of your words and description of the style. Period. Writing \"Yngwie\" in the prompt will get you arpeggios, but they sound nothing like him. Just as another example. Because the prompt is giving the AI genre cues only, and nothing so specific as actual Yngwie arpeggios, scales and ladder riffs. reply Nursie 6 hours agorootparentNot convinced, sorry. The “figleaf” is the service saying “Oh we can’t use artists in prompts, here, let me use a prompt that looks suspiciously like a set of tags from a specific music site instead” nod wink. And then the underlying model quite often fills in a well known voice and style. And that’s if the service spots the artist was in there and substitutes anyway, which it doesn’t always. So regardless, prompts may or may not be giving detailed Yngwie arpeggios to the model, but the model is clearly trained on them and can reproduce eerily similar music and voices to any given artist when given the right triggers. It’s (IMHO) clearly plagiarism on a massive scale. Great fun to play with though. (To be crystal clear, my contention is not “they are doing some dodgy prompt stuff to make their model produce known artists”, it is that their model is very good at spitting out massively ripped-off voices and styles. It is their attempts to cover this with “we don’t allow you to specify an artist!” that are the figleaf over the nature of the model) reply j45 8 hours agorootparentprevUdio seems to pull it off more often. The other day I had someone mention to me their copywriting prompts were still looking basic.. and right away I knew his process was basic or dated. reply 0xEF 9 hours agoparentprevI disagree, partially. Yes, we are tired of the hype, but we are also tired of the focus on generative AI. I don't want AI to write stories, make pictures or be my girlfriend. Those are things best left to humans. I want AI to optimize my home or business's HVAC, help with database administration, tell me what I can cook with the random stuff in my fridge, maybe even help with project management. We're getting there, but the spotlight needs to turn from the \"creative\" tasks to the boring administrative tasks we don't want to do. We're not sick of AI. We're sick of it being used for the wrong things. reply TheRoque 9 hours agorootparentSure, but the companies have a different plan. The creative and skilled tasks are also where you have to hire the most expensive employees to do the job, and so cutting them is a dream for most investors. From a pure business standpoint the things \"best left to humans\" are the ones where the human is the cheapest option for the same result. Nothing more, nothing less. reply 0xEF 7 hours agorootparentYou are correct. My comment could also be read as \"we are sick of companies putting profits over people with this disasterously cancerous 'growth at all costs' mindset.\" The AI boom is just the latest boil on our collective behinds, with that in mind. reply TheRoque 1 hour agorootparentI 100% agree with you, it shows the limit of the system we've built and something might need to change reply ksaj 9 hours agorootparentprevWhen all you have is a hammer, everything looks like a nail. This definitely applies with the current state of AI. reply bsenftner 8 hours agorootparentprevYour desires are exactly where I've been working. I've been considering calling the company \"Boring AI: productivity tools for real work\" or something like that. I've been integrating LLMs into the internal structure of applications, so you can actually tell a spreadsheet bot \"hey, I need this DNA table used to color a graph using this address table of people in this area\" and a spreadsheet with graph is generated in under a minute. Likewise, I've integrated a collection of 'bot attorneys that can provide serious legal advice, and is in use at an immigration law firm. reply 0xEF 8 hours agorootparentThis sounds great. If you habe a development blog or github, etc, I'd love to follow along. Also, random idea for the company name; EnnuAI. A play on \"ennui\" promoting something like \"hey, we do the tedious and boring stuff so you don't have to!\" Not much of a marketer myself, but thought I'd throw it your way. reply bsenftner 6 hours agorootparentI don't have a dev blog. Takes too much time to keep it up to date, and my github repos are private. But I discuss that I'm doing in a few places: https://blog.blakesenftner.com/blog/13 https://www.linkedin.com/pulse/my-cat-really-concerned-ai-bl... reply keybored 9 hours agoparentprev> Eventually everybody grew into it, and we can't imagine life without the Internet. Because a lot of us are addicts. reply cchi_co 8 hours agorootparentAn essential tool for communication, education, work, entertainment, and commerce... The Internet or AI am I talking about? reply keybored 7 hours agorootparentAah if AI is gonna be that it hasn’t reached that point yet. reply ksaj 7 hours agorootparentIn 1994, you would have said that about the Internet. And it was only starting to look important when Y2K came about. Then everybody got it. reply keybored 6 hours agorootparentOk.. I’m sure I will feel embarrassed in five years when AI is that important for saying that it wasn’t essential in 2024 (but could eventually be essential). reply ksaj 9 hours agorootparentprevGuilty as charged. reply Piskvorrr 10 hours agoparentprev...as soon as as the hype wave recedes, and vendors stop sticking the current-hot label onto everything. \"MOUSE WITH AI\" (*with a button that opens a browser window, how very innovative. But wait, it's a browser window pointed to an AI assistant!!!) reply ksaj 9 hours agorootparentGuitar players know this as well. A lot of pedals and DAW (digital audio workstation) plugins electronically mimic old analog hardware. Everyone claims the software version is crap, not realizing just how much of their favourite music is using it. I saw an interview with Tony Iommi (Black Sabbath) and right behind him was a rack with a Pod Pro amp simulator. I recognized it because I have one, and indeed, you can easily dial in his tone and typical amp sounds. But I'm left wondering how many Sabbath fans noticed that he's using digital modeling these days, or if they can even tell when he started doing that. People don't like change. It takes a lot of marketing hype to create motion for change to happen. And most people won't even notice it happen. Just like with Sabbath albums. reply TheRoque 9 hours agorootparentPoorly used generative AI is obvious to spot though reply BlobberSnobber 5 hours agorootparentprevThe logitech app has a chatbot for some god-forsaken reason reply surfingdino 7 hours agoparentprevInternet was useable from early on and became more friendly to less technical users as time went by. AI generated bullshit output is of no use whatsoever and customers are turned off by being told that it's the future when this shit doesn't work. Remember messenger chatbots? Where are they now? Same fate awaits AI. reply ksaj 6 hours agorootparentPeople were turned off by the text-only gopher and related protocols. It improved and we now have the modern web. Messenger-style chatbots abound today. They're everywhere. As well, you have Twitter and Youtube bots that are the grown up version of the irc bots from days gone by. reply danpalmer 11 hours agoprevImportant clarification: consumers are turned off by AI marketing material. I'd be interested to see real studies into consumer satisfaction with AI features in existing products. My gut feeling is that people don't like (visible) AI in things they use, but that's biased by me reading online reporting about the failings of these features, I wouldn't be too surprised if it turns out people mostly like them. reply amluto 10 hours agoparentI am certainly turned off by “AI” customer support. The ones I’ve encountered are actively terrible, and I’d rather click through a tree of first-level fix-it-yourself advice than get walked through it by a stunningly poor AI. But sure, it would be spiffy if Siri was more capable, as long as it didn’t become susceptible to injection attacks from my photo album in the process… reply ksaj 10 hours agorootparentWhen The Weather Network first included an AI chat function, one of their sample questions was about stargazing. I asked the exact same question to see what kind of response it would give, and it said that it couldn't answer because weather does not affect star gazing. Really? I took a screencap, because this was such an epic example of why companies should actually test things before giving public access to them. reply Piskvorrr 9 hours agorootparentCan you actually test a component that is, by design, a black box? (\"by design\" of the current models. Yes, the systems could be re-made traceable. But then it would also turn out on how much pirated material the LLM has trained, and hoo boy would the IP lawyers show up. That's the con: \"if it's a blackbox, you can't prove whence the corpus, nyah nyah!\") reply prisenco 8 hours agorootparentI brought this up in a previous HN thread, it's what I call \"probabilistic UX\". https://news.ycombinator.com/item?id=39954719 We don't have much experience building automated systems that are non-deterministic. Normally, in computer engineering, if we couldn't predict the results of an operation, we'd consider that operation buggy, broken or at best, flaky. Building consumer user interfaces for black box magic is a whole new ballgame. reply surfingdino 7 hours agorootparent> We don't have much experience building automated systems that are non-deterministic Our brains evolved to turn chaos into patterns that help us survive. Determinism is good from that point of view and nondeterministic behaviour is discarded as useless. Nature in general operates in a deterministic way, a banana tree doesn't randomly produce kittens. AI and LLMs in particular are nothing but misinformation and IP appropriation systems. No wonder people reject them. reply ImHereToVote 4 hours agorootparentI bet that if you included an expensive verification step by GPT 4 a lot of errors would go away. reply ksaj 9 hours agorootparentprevGood call. A case that is actively in court right now, is based on a point that you can sorta remake Johnny Be Good with Sonu. However, to do so, you have to already break copyright law by feeding it copyrighted lyrics. I did their experiment, but instead of \"Go, Johnny, Go, Go Go!\" I put in lyrics like \"Run, Forrest, Run, Run, Run\" (a Gump reference) and described the music style accordingly. It came out exactly like you'd expect. And the case is demonstrating a mirage where if you steal the song's actual lyrics, describe the style, you'll get something akin to what they might have written... except that there's no way to prove then that the model has even heard that original song before, because you gave it the lyrics and the style, and the rest is clearly bound to be similar as a result. reply sensanaty 9 hours agorootparentprevOur \"testing\" involves sending it 50 prompts and seeing if it bullshits too much and revising the prompt until it bullshits to acceptable levels. I suspect that's how the model makers test it as well, just fling crap at the wall and see which wall lets the most crap slide off of it (but never all of it) reply ksaj 9 hours agorootparentThis is called Fuzzing. And it is a major component of software testing. Especially in infosec, but I digress. The reasoning behind it is exactly the same. reply DelightOne 10 hours agoparentprevEvery time I hear it contains AI it sounds like the features' outcome will be uncertain. Especially with more experience. If your feature were good you wouldn't have to mention AI to show it is awesome. More than not AI is used as an excuse for the feature to be bad. reply keybored 4 hours agoparentprevOkay then at what point do the users become reliable narrators? The AI cheerleaders can take comfort in that AI is in the hands of the average person now—but they also have to contend with any negative reactions as well. AI isn’t some behind the scenes technology (any more). And companies with their “AI” gimmick often highlight it with a star or something. People can chat with these things as easily as doing a Google search. reply afarviral 11 hours agoparentprevI tend to agree. If you asked about a feature which uses some kind of ML under the hood to deliver that feature you'd different results. I think companies should urgently pull back on mentioning AI at all if they want any credibility at this point. reply viraptor 10 hours agorootparentYup. \"do you like that you can search for a name in your photo album\" will get different answers then asking about AI. reply rsynnott 4 hours agorootparentThat was never previously marketed as 'AI', though (I suspect because when CV started seeing this sort of application, the memory of the _previous_ AI winter was still fairly fresh, so everyone carefully avoided the term). In marketing, 'AI' tends to mean _generative_ AI these days. reply ksaj 9 hours agorootparentprevThat is a problem with Facebook, where people can tag you in images, even if you don't notice or approve it (you can opt out, but that's the opposite of what is optimal). Funny to see that come up again, but in a different context. reply viraptor 7 hours agorootparentThere's lots of different implementations. For example Immich (https://immich.app/) is fully self-hosted and does local recognition. It doesn't have to be an online service stealing your data. reply rsynnott 4 hours agoparentprevI'd buy that people like \"AI\" features writ large; automatic image classification on your phone, say. However, I'm not convinced anyone much likes the existing applications of LLMs (mostly terrible obstructive chatbots, and blogspam). reply wokwokwok 10 hours agoparentprev> I'd be interested to see real studies into consumer satisfaction with AI features in existing products mmm... I guess.... I mean, a feature that is not 'obviously AI' is just a feature; even if you normalized it against 'normal' features with no AI as part of them, surely the deviance from random noise would be negligible? In a double blind test, you would have three cohorts; control, placebo and treatment (ie. AI). Since the placebo and treatment groups would receive the same feature with or without AI, you'd be looking at absolutely nothing meaningful in the data you collect. > I wouldn't be too surprised if it turns out people mostly like them. How can users POSSIBLY have a positive / negative / ANY KIND of meaningful response to a feature based on the unknown backend implementation? If you put a chatGPT interface on your product and don't put an AI label on it, I guess most people, not being completely stupid, will not meaningfully distinguish between it and the equivalent feature with \"Artificial Intelligence\" painted on the side. An AI chat bot is an AI chat bot. You're not fooling anyone by calling it an 'intelligent assistant' instead of 'chatGPT'. :P I mean, I'm just guessing, you could study it. ...but, I guess it's probably not worth bothering. It's probably more likely the take-away here is: Make your product amazing; if it uses AI, hide that fact that it uses AI if you can. reply viraptor 10 hours agorootparent> would receive the same feature with or without AI, I'm not sure how you'd do that, given many features wouldn't exist without AI. We don't know how to implement them that way. The only existing choices are \"no feature\" and \"AI feature\". reply everdrive 8 hours agoprevAI is being pushed everywhere, and I couldn't hate it more. I don't want an AI assistant. I don't want to \"talk\" to a computer. I don't want a company diving mindlessly into the next trend just because they're afraid of being left behind. As others have said, it's a sign that a company doesn't really know what it's doing. I hear executives brag that they put all their emails through an AI assistant. This just tells me two things: they're apparently bad at articulating themselves, and no one is actually reading their emails. reply plasticeagle 8 hours agoparent\"If you couldn't be bothered to write it - why should I be bothered to read it?\" - Some Internet Wag. That's the thing, isn't it. AI output is so low-effort that it may as well not exist at all. Just send me the prompt instead, if you're going to do that. reply moffkalast 7 hours agorootparenthttps://i.imgur.com/k1dIVRr.jpeg When an entire culture is built on constant pointless pretense, is it really surprising that there is considerable effort put into optimizing it? reply netcan 7 hours agoprevI don't think it's disillusionment with the tech. Consumers barely touch the tech. It's disillusionment with the marketing I think this goes beyond just consumers. If you listen in on a random companies' strategic planning... Any project with \"ai\" in its title is likely to be bullschtick. \"AI enabled\" is our 2024 \"now with electrolytes.\" reply zacksiri 10 hours agoprevI wonder if the same sentiment applies to products using .ai TLDs. The thing about AI is it reminds me of what Steve Jobs said about speeds and fees. People care about \"1000 songs in your pocket\" not \"30GB hdd\". AI seems to be the \"30GB hdd\" and people don't always relate AI to how it's going to help them. reply ksaj 9 hours agoparentWe keep saying \"Any sufficiently advanced technology is indistinguishable from magic\" while forgetting that technology only becomes good when we don't think about the technology anymore. It works like magic. How many users know the difference between MFM and RLL hard drives? Now keep progressing that technology wise. People only know and care that they got bigger and faster. Do users care that the file system may or may not be self-defragging? reply ecjhdnc2025 9 hours agoparentprevEvery time I see a .ai TLD I just assume it's owned by a grifter. It saves time. *shrug* reply blibble 8 hours agoprevAI becoming associated in consumers minds with cheap useless garbage is the best thing that could have happened AI is the shovelware wii game of the 2020s I wonder what this will do to the YC S24 batch... https://www.ycombinator.com/companies?batch=S24 reply sensanaty 7 hours agoparentWow, basically every single company there incorporates AI into their pitch or even name somehow... I mean I respect the grift I guess, but I'm not surprised in the least that people are quickly growing tired of it all. Some of the ideas I'm seeing on that list are just straight up idiotic, but since it leverages AI somehow it's suddenly a good idea, I guess... reply mtndew4brkfst 5 hours agoparentprevAI is the shovelware wii game of the 2020s Man, I wish shovelware games had been a temporary problem we grew out of. The Switch store is still riddled with them, and the PSN store has some obvious grift as well. All of the \"Jumping \" SKUs that are just achievement fodder, for example. reply Lerc 9 hours agoprevThis does not surprise me, this is a new technology that people are wary of. People are far more aware of marketing techniques these days an know that when a device is advertised as having trendy feature X, it probably doesn't have anything to do with the meaningful aspects of the feature. Consider how many atomic themed products there were in the 60's. We can be thankful that the only way most of these were actually atomic is in that they were made of atoms. The naivety if those days has gone. Information (true or not) travels so quickly now , everyone is a bit jaded. Many are outright nihilistic. It's worth noting that people's opinion of AI in product is distinct to the actual AI itself. I'm not in a position to find the reference right now, but I remember reading about a study which showed people felt that when given artworks to judge, the ones they were told were by AI were inferior. This was independent from whether or not each piece was actually by an AI or a human. reply isleyaardvark 3 hours agoprevIt's quite simple. Consumers realize either consciously or not that saying \"AI\" means the added AI will make the product: 1. cheaper 2. worse It's invariably used as a cost-cutting measure that is quick, cheap, and worse. Companies use AI art because they are too cheap to hire a real artist that would make better art. Companies use AI chatbots because they are too cheap to hire real customer service agents who could actually help people. If a company slapped a label on a bag of chips that said \"Now with fewer chips and less flavor!\", I'm sure that would turn off consumers as well. reply Animats 11 hours agoprevLLMs have solved the problem of blithering at scale. Unfortunately, this mostly benefits advertisers. reply eightman 11 hours agoparentThe use case for AI is spam. reply fuzzfactor 11 hours agoparentprevIt hasn't even gotten as uncanny as it could be yet. Somebody must be fast-tracking straight to enshittification. reply solarkraft 7 hours agoprevIt means unreliable. I saw an ad for a cool scheduling app. Once they mentioned it‘s „AI powered“ (why??) I started worrying about it randomly missing events. reply EdwardDiego 9 hours agoprevThe fact that every C-suite in America simultaenously decided \"We need AI in our product. Look, just jam it in somehow, you'll make it fit\" is, I'm sure, unrelated. AI is a keyword for investors currently, that's all. Like all the companies that previously sprouted a blockchain unrelated to their core product. reply sensanaty 7 hours agoparenthttps://www.ycombinator.com/companies?batch=S24 Someone else linked it above, but after seeing this, yeah no wonder people are getting tired of it. Basically every single company in the batch mentions AI. reply kreyenborgi 8 hours agoparentprevI've even seen AI being used as an argument for destroying more wilderness in order to build power plants – so we can \"stay ahead of the AI revolution with green power\", just like at some point blockchain was. reply iainctduncan 5 hours agoprevThis is not at all suprisinging to me. In general, companies underestimate the intelligence of the consumer and are pretty bad at imagining being a consumer looking at their company. We are all being indundated with AI hype, and it's almost all telling companies \"you can save money by getting AI to do a mediocre-to-ouright-shitty versions of this work instead of hiring people\". As a consumer, why would I choose a company optimizing for their margins at the expense of my experience? Touting AI has become a warning sign that the company is doing this. reply KronisLV 8 hours agoprevI really like something like GitHub Copilot and Copilot Chat, because they help with boilerplate and simple functions, as well as lower the barrier for doing some exploratory work and iterating. Something like Phind is even better in those cases where you care about looking into the actual sources that are returned, as opposed to just testing the output for your needs. I also like general purpose chat/writing/instruct models and they're a nice curiosity, even the image generation ones are nice for either some placeholder assets, texture work, or some sometimes goofy art. HuggingFace has some nice models and the stuff that people come up with on Civitai is sometimes cool! Video generation is really jank for now, I wonder where we'll be in 20 years. Overall, I'm positive about \"AI\", but maybe that's because I seek it out and use it as a tool, as opposed to some platform shoving it down my throat in the form of a customer service bot that just throws noise at me while having no actual power to do anything. There are use cases that are pleasant, also stuff like summarizing, text prediction, writing improvements, but there are also those that nobody asked for. reply doodaddy 8 hours agoprevAs a term, “AI” has become synonymous with “new”. And “new” has become synonymous with “good”. We are in an age where age is a liability. If it’s not new it’s old, and old isn’t good. And it’s all sad because it’s simply not true. But marketing teams wide and far are pushing this narrative. And I think companies are encouraging their marketing teams to do it because it’s an easy way to dress up a half-baked product, hiding it behind a buzzword. But I don’t think it’s a signal to consumers as much as a signal to investors and competitors. Since when does the consumer care about which technology was used to build a product? Has a consumer ever said “wow this product is so good it must have been built with Rust!” The bottom line is it shouldn’t matter and it doesn’t. People need features, not technology, even though many of them confuse the two. reply n_ary 3 hours agoprevFor me personally, when I see \"AI\" suddenly popping up on something I am subscribed to, 8/10 times, there is some sort of chatbot suddenly added there; nothing ground breaking, nothing cool(that didn't exist before), just a random chatbot! Secondly, I am slightly burntout looking at all the \"BlockChain\", \"distributed\", \"Crypto\" for like last decade and now suddenly the same products(and products from same people) did a swap of \"crypto\" or \"blockChain\" with \"AI\". Needless to say, my mind is jaded from all those scammy blockchain peedlers that when I see an \"AI\" (e.g. TodoAI, like wtf? I just want to add some text and dates and want to check those when am done or just show me a notification if I forgot..), I just feel like someone is trying to scam me. Also, I noticed that some products suddenly hiked the price after adding the \"AI\" in their featureset, which wouldn't feel scammy(because inflation happened), but if I see some crappification of the product post AI, it just leaves a bad taste that next time I see anything with \"AI\" as feature, I assume it is also some crap. I know, don't judge a book by fathers and children must not be judged by deeds/sins of their fathers but what can I say. Also, most of the products are clearly proxying stuff to ChatGPT with a system prompt, you can actually sense it, if you have used OpenAI apis. Which causes me extra pain, because c'mon, you are selling me a proxy with a prompt and charging me like $5.99/month! reply sensanaty 10 hours agoprevOnce you look past the initial reaction of \"oh cool a computer can do this!?\" You quickly start running into the limitations. And if you're in a product team building some AI feature (aka calling an OpenAI API 90% of the time), you realize even more how laughably useless it is in actuality. For example Notion. They have an AI feature, and it's hilariously useless. It can barely even summarize things, yet alone write the rest of the document for you. Yet they push it constantly onto you with no way of disabling the crap. What I have noticed is that the marketing people are in love with it, because it lets them generate the useless drivel they spam people with easier than before. I suspect they never used their brains much, but now they don't even have to at all! Coincidentally, scammers also love it for similar reasons... reply fhd2 9 hours agoparentSame here. I know a number of sales and marketing people that just _won't_ shut up about ChatGPT, trying to get me to use it more the way it's useful to them. I know for a fact that there's nothing in it for them promoting it to me, they're honestly just in love. They do use it to write drivel. They write promotional posts, mass emails and LinkedIn requests, briefs for their conferences and events... The typing speed of one of these guys was about two words per minute, ChatGPT probably really does save him hours. I noticed he mostly uses voice input. When I say stuff like I want to think about what points to make he'd get confused, he'd just ask ChatGPT what points he could make. He doesn't even think about that part anymore. I can certainly see how those kinds of people will push product teams to integrate assistant features and happily promote them. It really does seem to be life changing for them. Personally, I can't relate though. reply fch42 8 hours agoprevThere is value way beyond the immediate service given in a human to human interaction; we're social animals after all and tend to derive a form of pleasure out of \"being with others\". In the same sense that granny went praying the rosaries Saturday evening before mass, because that also got her the coffee and cake with her friends ahead of that, and the chats afterwards. Just like the person at the till chatting with the cashier, the person talking to the surgery's receptionist (and not just about booking in the doc), or the talk with the pharmacist about how and when best to take the prescription medicine (and since we meet monthly for that anyway ... give me the gossip and the events in town as well) - this used to happen because, quite frankly, \"efficient\" communication and \"efficient\" human to human interaction is not what we seek. It'd be rude. And that's where the whole chatbot, AI or no, thing falls a little. No matter how smarmy or even actually helpful that chat thing is, it doesn't shake my hand, won't do me favours, probably not take me to the shops after work, and ask me whether I need help or why I look sad. Nor complement me on my eyes. I don't know; at least in me, the herd animal roars loudly enough that I feel unvalued whenever I am forced to interact non-physically. The distance can be felt. And to me, that is not a \"protective distance\" but an \"excluding\" one. Makes me more lonely. reply charlieyu1 9 hours agoprevNot surprising at all, there is a big trend of using AI for cutting costs while producing stuff with minimal quality. Once the initial hype is over, the consumers will hate how repetitive it is. reply ksaj 9 hours agoparentThe cost is currently offloaded to the AI providers. OpenAI is apperently burning cash like crazy, in that their revenue is far lower than their expenses. For now, during its formative years anyway. Once the initial hype is over, we will just take it for granted that the software we're using is doing something with AI. The costs will have to either be solved, or flipped to the consumer, though. Right now, it's a free-for-all, and worth taking advantage of, if you can. reply tmpfs 7 hours agoprevThink about trying to get customer service from any company now, we all end up talking to AI bots that don't actually help at all. No wonder the public perception is bad, our experience of AI is often based on these automated services which actually make our lives more frustrating. reply indigo0086 5 hours agoprevOne thing I and probably many others notice about AI integration is it places incorrect operation on the user's plate. If the user gets a wrong answer, well just remember ai tends to do that. People are trying to find ways to make a truly intuitive ai interface that isn't just a text box you chat with. With adequate error recognition and correction integrating ai shouldn't be something the user notices other than the time it takes to process. This would be another issue as integrating ai just adds a time lag on those operations which can depress user sentiment in another way reply ecjhdnc2025 9 hours agoprevIt's this simple: generative AI is poisoning culture. Everyone knows this -- even the people pushing it. We know what it is doing to art, what it is doing to just being able to find a book on amazon, what it is doing to reviews, to website searches, to authenticity everywhere. Splitting hairs about whether people think it's the terminology or the functionality is absurd. Stop making generative AI products that are the cultural equivalent of breaking into the community pool solely to piss in it. People don't really want this. They have an instinct that a lot of AI products are little more than grift (trained by their experiences with \"Web 3.0\"). And this study is showing that. reply jillesvangurp 8 hours agoparent\"Everyone knows this\", \"People don't really want this\". No they don't. Phrasing like this is typical for people who want to persuade others that their opinions are somehow widely shared. It's a cheap rhetorical trick. Populists use this all the time. That doesn't make it any more true. Some people might want that to be true (including you apparently). But most people haven't got a clue when they are using AI or aren't using AI and can't articulate what it is and are perpetually confused about anything technical. You are probably right about everyone getting a bit worn out about everybody blabbing about the topic. That's because most of those people don't make any sense. And of course there are a lot of products that are pretty bad that advertise their supposed AI qualities. So understandably, people are a bit put off by that. If you read a lot of stuff that uses phrasing like you just used, you are likely suffering from confirmation bias. That's a thing that causes people to genuinely believe they are right about something because they unconsciously avoid consuming information that disagrees with their views and seek out peers and sources of information that confirm them. Everything they see and hear confirms them in their biases. A lot of media sources actually prey on this by feeding lots of (AI generated, of course) content that deliberately manipulates groups like this. All this study really shows is that people are tired of vague AI features that never really deliver on their promises. But they happily read a lot of stuff on twitter, linkedin, youtube, etc. blissfully unaware that they are consuming a lot of generated content that is fed to them by an AI that decides what they should consume next. All those supposed AI haters are hopelessly addicted to things like Tik Tok, Instagram, and what not. The trick with selling AI is to not talk about it. People love magic. Just don't tell them how it works. reply ecjhdnc2025 8 hours agorootparent> But most people haven't got a clue when they are using AI or aren't using AI and can't articulate what it is and are perpetually confused about anything technical. But you said... > Phrasing like this is typical for people who want to persuade others that their opinions are somehow widely shared. It's a cheap rhetorical trick. Populists use this all the time. That doesn't make it any more true. Is it only a problem when someone you disagree with does it, then? \"Most people haven't got a clue\" is also something populists say, I think you will find. I tend not to write off whole swathes of people as non-technical. There's no such simple thing as a non-technical person, and people can like or dislike stuff without having a deep understanding of how it works. Generative AI is pretty widely distrusted and reviled; we know the damage it is going to do to trust and culture. It is poisoning the well of AI development. Studies like this shouldn't be a surprise. reply krapp 9 hours agoparentprevThe only thing that is going to stop generative AI is companies using it not making as much money as they expected. It's probably going to take a crash and another AI winter. Maybe I'm too blackpilled on AI already but I absolutely believe companies will just keep throwing money at it until it's literally existentially impossible to do so, just because the promise of the capitalist version of free energy (delusional as it may be) is just too great to resist. The degree to which our culture is already largely controlled and manufactured by corporations and sold to us without our input or consent is a separate conversation we should have, collectively, because AI is just pissing harder into an already pissed in pool in that regard. reply ecjhdnc2025 8 hours agorootparent> because AI is just pissing harder into an already pissed in pool in that regard. It is, and I agree. But I suspect you agree with me that this is not how people feel. If you see someone lying on the street, bloodied, and you don't help, expect to be judged by that person about as harshly as they judge the person who beat them up. Corporate culture has never come for art and writing as dismissively and callously as generative AI does. This isn't pop stars and TV. This is coming to the artist who has self-taught oil paintings, the photographer who has built their own artistic camera, the pencil sketch artist who has learned photorealistic sketching and saying \"hey, I know your work is almost impossible to share with people already and sharing it is the thing that makes you feel good... but I'm going to make that worse by drowning it in autogenerated shit. Oh and hey, you know how you developed a style and sold a couple of things? I've trained my system so that your customers can just generate work in your style without even giving you money, so that should make you happy, right? Happy customers are good.\" This is not a mere extension of corporate culture. This is a callous, systematically careless, dismissive kick in the face to people on the ground. And we all feel it, either on our own behalf as creative people, or for those artists we admire. reply krapp 9 hours agoparentprevThe only thing that is going to stop generative AI is companies using it not making as much money as they expected. It's probably going to take a crash and another AI winter. Maybe I'm too blackpilled on AI already but I absolutely believe companies will just keep throwing money at it until it's literally existentially impossible to do so, just because the promise of the capitalist version of free energy (delusional as it may be) is just too great to resist. The degree to which our culture is already largely controlled and manufactured by corporations and sold to us without or input or consent is a separate conversation we should have, collectively, because AI is just pissing harder into an already pissed in pool in that regard. reply dmd 7 hours agoprevLogitech's *mouse driver* now has AI in it[0]. [0] https://www.logitech.com/en-us/software/logi-options-plus.ht... reply peanut_worm 7 hours agoprevAI just means “annoying chatbots and low quality content” to most people reply perlgeek 8 hours agoprevI'd love to see more products use some machine learning in ways that fit their current UI paradigms. For example: * You enter an ambiguous search term into a search engine. It shows you some results, but it also shows you some buttons to filter by meaning. For example if you've entered \"universal\", it could give you an option to filter out all pages where \"universal\" appears as the name of the film studio, without a hack like excluding \"universal films\", but actually deciding based on context * If you've touched up a few photos the same way, an image processing program could give you a suggestion for a touch-up for the next photo, along with options to tweak it * In an email program, if you've moved a few emails to a folder, it could suggest a selection of other emails to move to the same folder, or maybe suggest to you a mail rule that would do it for you in future. ... and please, provide an option to switch it off. reply tauntz 9 hours agoprevAnecdotal evidence but my reaction to seeing a Google product release mentioning anything related \"Gemini AI\" makes me subconsciously assume that they made the product worse by including a totally unrelated and barely working feature that nobody asked for. The only reason for most of these features is, I assume, that there's a requirement now for all PMs to ship something with \"Gemini AI\" in its title or they won't get a promotion ¯\\_(ツ)_/¯ reply gwervc 5 hours agoparentThe good thing is that going by Google track record, the feature will live only a few years. reply HPsquared 9 hours agoprevI think it's the association with \"AI-generated slop content\". People associate the use of AI in an existing area as being a poor-quality facsimile of the real thing, whatever the \"real thing\" is. That, or an unnecessary addition causing annoyance (aka Clippy) On the other hand, for genuinely new use-cases where AI is central and beneficial, I'd be surprised if there was a negative reaction. It is \"new shiny thing\" vs \"cheap plastic imitation\". Reminds me of The Graduate \"One word. Plastics.\" reply amrocha 9 hours agoparentThere are no genuinely new use cases for AI reply HPsquared 9 hours agorootparentHigh speed of generating content is new. reply pona-a 8 hours agorootparentSEO have farms existed previously, and as far as I can tell, their unwilling consumers weren't really asking for more at higher bandwidth but with even less accuracy. reply HPsquared 7 hours agorootparentFor one predefined type of content maybe, but not on the kind of quality and versatility that appeared in the last year or two. You couldn't just randomly say \"hey Google, code me up a PowerShell script that does x, y and z\" and have a back-and-forth discussion. This is completely new. reply rsynnott 4 hours agorootparentprevBut the content is _bad_. Nobody, or virtually nobody, wants an increased supply of bad content. There's already far more than enough of that. reply cchi_co 8 hours agoprevI think, in some ways, it is just annoying for people to see it 'everywhere.' Some see it as a buzzword without substantial value reply snakeyjake 5 hours agoprevAs far as I can tell, AI is only useful for: 1. Making really, really, REALLY, shitty \"art\" 2. Writing nonsensical and boring short stories or bland written-by-committee memos that make you sound like a soulless AI 3. Creating summaries that are pathetic compared to the first paragraph of any wikipedia article on literally any topic (also, they are often 100% wrong) 4. Acting as a useless, actually worse that useless due to being both useless and time wasting, wall between you and a human who can actually do something \"assistant\" 5. Looking at images and telling me if there's a cat or a fruit in them 6. Being a worse chatbot than ELIZA was 50 years ago 7. Writing code that, if it is anything more complex than something you can copy and paste from Stack Overflow and have work, you have to spend more time fixing than if you had just written it yourself But it is very good at bombarding users with an infinite stream of garbage content that is cheap and effortless to create so it will eventually devour everything. reply poikroequ 7 hours agoprevAI is not being marketed to consumers. AI is being marketed to investors. reply kebsup 8 hours agoprevI'm building a flashcard language learning app, and the Meta ad with the phrase \"AI-powered\" performs better than all other variations, so depends. reply Scarblac 7 hours agoparentMy first association with flash card apps is that it's extremely tedious to create the cards for what you're trying to memorize, so if AI can help with that, that may be worth it. reply GuB-42 6 hours agoprevMany consumers have a working bullshit detector. And they are starting to understand that \"AI\" is usually a meaningless buzzword. And people don't like being bullshitted. And even to those who think there is real meaning behind it, do you really think people want \"intelligence\" everywhere, artificial or not. People don't want their toaster to be intelligent, they just want it to toast. So what is an AI powered toaster? A toaster you have to argue with regarding how you want your bread toasted? And in many cases that's what happens when you replace a push button with an \"AI assistant\", so people are not wrong about it either. reply samdung 10 hours agoprevIn just a few months every website that has had a customer support chat-plugin seems to have become 'AI Powered'. And all they seem to do is go on in a circular drivel. reply sensanaty 9 hours agoparentI work for a company providing those kind of solutions and yeah, the mandate from above is that we need to build an AI bot that will replace real human CS agents. The \"vision\" from our CEO is that he wants to replace 95% of all human interactions with the bot, to which the dev team in unison exclaimed \"what the fuck?\". It's literally just calling the OpenAI APIs with some overly complex system prompt. It is laughably useless, constantly lies, but some of our bigger (read: soul-less corpo) customers love it because they can get rid of a portion of their CS team even further than they've already been doing. From what I've noticed, it's mostly marketers, spammers/scammers, and the C-level and their investor buddies that are excited about AI, and the not-so-cynic in me can't see it for anything else other than a way for them to fire people en-masse to make more money by automating their jobs away, regardless of if the quality is horrendous or not. I think we're already reaching a point where regular people are kind of sick of all the AI shit, though. Who knows, maybe people start abandoning anything that smells of AI en-masse? It's nice to dream, anyway. reply senectus1 11 hours agoprevI sat in on a weekly MS meeting where they spruik their products a few days ago. AI/CoPilot/Chat-GPT was mentioned 100 times in the 34 mins I was in it. ( I was tallying, cause I'm sick of it) And thats not including text on the presentation. just the times the words were said. reply afarviral 11 hours agoparentDid you tell the CEO? Tell the prick. reply bfrog 7 hours agoprevYeah I’d rather not be part of the experiment thank you. If something takes intelligence to do I want to talk to a human that can help do it. AI isn’t going to magically help solve problems with technology. Frankly I’m tired of technology. I miss people. reply rsi_triad 10 hours agoprevnext [2 more] [flagged] vmfunction 10 hours agoparentThe analogy between AI and Adult Diapers is not too far off. reply feverzsj 11 hours agoprev [–] AI is still far from profitable, except for scam. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A study in the Journal of Hospitality Marketing & Management found that mentioning \"artificial intelligence\" in marketing decreases consumer trust and purchase intentions.",
      "Researchers surveyed 1,000 respondents and noted that AI-labeled products were less popular, especially for high-risk purchases like expensive electronics or medical devices.",
      "The study advises companies to focus on product features and benefits rather than emphasizing AI, highlighting a broader trend of consumer fatigue with AI hype."
    ],
    "commentSummary": [
      "A study indicates that consumers are often turned off by AI features, leading to decreased user retention and no new purchases in some cases.",
      "There is a noticeable disconnect between the enthusiasm of tech creators for AI and the actual preferences of consumers, who find AI overhyped and poorly implemented.",
      "While AI can be useful in specific contexts, such as Google Photos' face recognition, it frequently fails in customer service roles, causing frustration among users."
    ],
    "points": 161,
    "commentCount": 172,
    "retryCount": 0,
    "time": 1722494339
  },
  {
    "id": 41122793,
    "title": "Cardie – An open source business card designer and sharing platform",
    "originLink": "https://github.com/nfoert/cardie",
    "originBody": "Live Server WikiReleases Design a unlimited number of business or information cards about yourself, share a link or QR code to them, print it out, and save other people's cards to your virtual wallet for later. Once you've created a card you can get analytics data on how your cards are getting visited, you can edit your cards as things change, and you can keep cards private so only people with a link to your card can see it. Important Cardie is currently in an open alpha. Things will be rapidly changing and bugs are to be expected. Installation First, clone this repository using the following command git clone https://github.com/nfoert/cardie Then, navigate to that directory and create a new python virtual environment cd cardie python3 -m venv .venv Activate the virtual environment using the command for your system (Linux is used here) and install the required dependencies source ./.venv/bin/activate pip install -r requirements.txt Next, create a django superuser and make and migrate the models cd cardie python manage.py createsuperuser python manage.py makemigrations python manage.py migrate Now just run the server using the following command, or run the Start server task in your Visual Studio Code python manage.py runserver Finally, navigate to http://127.0.0.1:8000/admin and log in using your new administrator account. Create a new Server object and be sure to configure the ip to be http://127.0.0.1:8000. Additional steps for Production installation This depends on what server hosting provider you're using. However, there's a couple environment variables you need to set and there's a run command. Set the following global environment variables: DJANGO_ALLOWED_HOSTS -> ${APP_DOMAIN} (This works on DigitalOcean, this may not work on every hosting provider) DJANGO_SETTINGS_MODULE -> cardie.settings_production DJANGO_LOG_LEVEL -> WARNING STATIC_URL -> /static/main SECRET_KEY ->(Generate this using django.core.management.utils.get_random_secret_key(). If possible you should encrypt this value in your hosting provider.) DEBUG -> False DATABASE_URL -> ${db.DATABASE_URL} (This works on DigitalOcean, this may not work on every hosting provider) To Do There's lots of things that need implemented or changed in this project. Please see TODO.md. Contributing I'd love to see contributions to this project! Please check out the issues page to see what things currently need fixed or added. Additionally, check TODO.md for a rough todo list of things that need implemented, and the wiki for some information on how to work with some of the existing systems.",
    "commentLink": "https://news.ycombinator.com/item?id=41122793",
    "commentBody": "Cardie – An open source business card designer and sharing platform (github.com/nfoert)155 points by nfoert 23 hours agohidepastfavorite52 comments atum47 54 minutes agoThis reminds me of a certificate editor I did for a star up back when I was a intern during my college years. The whole thing was to have custom certificates for several types of events, workshops and courses digitally signed. I was responsible for developing the editor. I end up creating a \"word art\" online. You could add text, titles, images, backgrounds, some effects... You could export a PDF, image... All in vanilla JavaScript running on the browser. It was so much fun. It's a shame I don't have the final product to show. reply bityard 3 hours agoprevThe one time I needed to design a business card, I just used Inkscape and sent it off to a printing company. The physical card turned out better than expected. Unfortunately the business is no longer around, so presumably I am better at making business cards than running a business. reply singpolyma3 3 hours agoparent> Unfortunately the business is no longer around, so presumably I am better at making business cards than running a business. Classic reply layer8 4 hours agoprevI would have named the project “cardigen”. ;) reply cyanydeez 20 hours agoprevDo people stil do business cards? reply iancmceachern 15 hours agoparentYes, in some circles it's weird to use them, but in my experience those circles are the weird thing. Those circles are usually software folks and startup folks in places like the SF bay area, etc. In those situations everyone trades linkedin profiles or adds eachother to contacts as we are standing meeting eachother. That leads to very weird social interactions which are the norm in these circles but are definitely not normal social behavior in the broader world. In the broader world, everyone has a card. It would be weird if you were giving a police report and the deputy told you his linkedin profile address, or whatever. Same for your plumber, business card make sense and a aren't going away. reply lowkey 6 hours agorootparentLast night after leaving a local tech event in Austin I stumbled into an ‘AI Industry’ reception which turned out to be all high powered government officials and lobbyists. I had my Popl NFC/QR code business card but they all had old school business cards. So it’s not just plumbers but also big tech lobbyists and former secretary of states who live and breath paper business cards. reply derefr 15 hours agorootparentprevBut, whether in a personal or a business context, I don't do... either of these things? Mostly, if I'm meeting someone for the first time in person, then it's either through friends, or at an event. If it's through friends, I just... meet them. No \"connect.\" We have a conversation. We say goodbye. If I want to reach out to them later, I ask the friend I met them through to reach out for me. Simple and 100% effective. If it's at an event, I might ask for, say, their Twitter handle. (Or, if they're an artist, their Instagram handle; or if they're a maker, their Etsy store; etc.) But I won't interrupt the conversation to write it down, let alone add them right then and there. I'll just remember the handle, and if I really care, I'll write it down after the end of the conversation. Or, if I care slightly less, I'll forget it (or not bother to ask for it) and then if I decide I care later, I'll google their name + the name of the city we were in (or the city they're from) + their occupation and/or company they said they worked for. ...and outside of those two contexts, then I'm likely not meeting the person for the first time in person, so I don't want/need a card. My plumber? They're already in my house. I presumably called them. I know who they are. I found them online, probably. \"Their card\" is their website/Facebook page/etc. A deputy at a police station? I don't even need to know their name. They're a public servant with a uniquely role in their department. I'm guaranteed to be able to look them up at any time by role on the police department's website, and/or call the police department's non-emergency number and ask for them by role. reply iancmceachern 15 hours agorootparentThe first situation doesn't apply, I don't generally give my business card out in personL situations either, and let relationships organically happen as they do. That's not this. Thanks for the second example, it gets right to my point. Yes, in San Francisco if you ask the average professional for their Twitter handle that may be a way to contact them, etc. In much of the broader world its weird to assume people have one (I don't). It's weird to assume that that would be the way to contact them. Most of the world still uses email, phone and whatsapp/etc replacements for such to communicate. If I'm meeting someone for business purposes I want to know their business name, address, phone number and email. I don't want to know their recent tweets, etc. I just want to know what number to call when I want that service. reply derefr 14 hours agorootparent> I just want to know what number to call when I want that service. I have literally never once in my life been in the situation of wanting to hire someone to provide me a service after the first time I met that person, in person. Heck, I have literally never once in my life ended up with the knowledge that someone provides a defined service I would want, after a first in-person conversation with them. Because people who aren't weird entrepreneurs/founders/\"personal brand\" marketers, don't market themselves in the sort of small talk they make on a first meeting. And likewise, when I'm talking to someone who doesn't read as a weird entrepreneur/founder/\"personal brand\" marketer, I don't ask them what they do as a first-step way of getting to know them. Because for most people, that's not the thing they want to talk about upon first meeting someone! It's not the most exciting and novel and conversationally-fascinating thing about them! It's just some boring shit and they want to get away from it when they're not at work! (Or, worse yet, it's something they're embarrassed to admit — like that they're currently unemployed — and you're throwing a wet blanket on the conversation by steering it toward work!) I have been in the situation of being e.g. over at a friend's place, and the friend has a tradesperson or housekeeper or babysitter or something drop in. But you know who I ask for the service provider's contact info? Not the service provider. The friend! In fact, I would go even further. I lived much of my life in a small farming community; I only moved to a big tech-hub city as an adult. If someone in my small farming community who I didn't know came up to me and started trying to sell me their services... I would actively distrust them as a service provider! I wouldn't just not call them; I'd do my own research, and if I saw that person among the results, I'd be biased toward skipping over them as an option. I would feel spite toward them for having acted upon a belief that they could force themselves into a top-of-mind position in my mental rankings for their service, without me even expressing interest. I'd feel about them the same way I feel about businesses that take out interstate billboard ads, or maybe people who try to force flyers into the hands of passers-by. --- But that's getting a bit beyond the point, because more people are \"weird\" entrepreneurs/founders/\"personal brand\" marketers these days than you'd think. It's not just an SF thing, or even a big-city thing. No matter where you go in the world, I promise you that all the stalls at the farmer's markets will have some kind of social-media handle on their banners. Your plumber almost assuredly does have a Facebook Page (whether they personally made it or asked someone to make it for them.) Your local campground — literally just a big flat patch of grass — almost assuredly has explicitly submitted (paid!) listings to 4-5 different camping directories. My local thrift shop runs For Sale By Dealer ads on Craigslist. Heck, my 45-year-old second cousin, who has lived her whole life in one of the poorest parts of the Philippines with spotty electricity and no running water, has a sari-sari store — and the sari-sari store has a Facebook Page. The gig economy is real. All business owners have to market themselves in some way; and if they haven't lived in a cave for the last 30 years, they'll know that some potential clients will only do their research online — so they'll ensure they can be found online, somehow or another. So it's really just employees that need business cards. In theory. But even then: why do you need to reach out to an employee, anyway? You can just reach out to the business they work for. (The one single exception I can think of, is if you interact with / pay the business, but all the \"employees\" are still gig workers or contractors, and the employees' services are not interchangeable. Like, say, hairstylists who rent chairs at a salon, and might be gone from that salon the next time you visit. I could imagine getting a stylist's business card. ...but, weirdly enough, they don't tend to use them! They — like most \"artist\" types — tend to point you to their portfolio website / Instagram page!) reply iancmceachern 14 hours agorootparentI agree with you. Many of the situations you describe here would be weird situations to just bust out a business card in. I'm not advocating for walking up to random people selling your services and giving out cards, agreed. What I am saying: In situations where it makes sense, like trade shows, conferences, introduction meetings, business mixers or meet snd greets, situations where we are expected and encouraged as attendees to \"do business\" it can be very convenient to have a small piece of paper with your professional info on it so everyone doesn't have to carry notebooks or bust out our phone all the time. It is also very convenient in situations where I have performed a service for a client and I can give them a card and say keep this, if you have any problems reach out, or I can put a card in with the hardware I ship them. I've also had people give my card to others. It's the best $10 I've ever spent (career wise) reply derefr 4 hours agorootparent> trade shows, conferences, introduction meetings, business mixers or meet snd greets Alright, sure. I will admit that this is the \"obvious\"-at-first-glance use for business cards. I thought this way myself, until the rubber hit the road. I'm a weird entrepreneur/founder person. And I do attend industry conferences myself. And the first time I went to one, I did get business cards printed, expecting to need to use them. At that first conference, when it was just me and my cofounder, no employees yet — my company didn't bother to get a booth at that conference. Instead, since we were in a B2B positioning, and the people with the booths at the conference were our potential customers, we just walked around talking to them, trying to hook them as customers in between their (non-applicable) attempts to hook us as customers. But you know what? Despite the high levels of engagement and \"huh, that's a great idea, I bet we could use that\" — there was zero measurable impact from the \"handshake outreach marketing\" we did at that conference. Nobody ever funneled in having mentioned meeting us at that conference (despite us handing out at least 500 cards between the two of us); nor did anyone sign up mentioning that one of their employees told them about us due to them hearing about us from the conference. Why? If I had to guess, it's because the people we were talking to at these trade shows fell into one of two buckets: • early-stage businesses / one-man shops like us — where we were talking directly to the founders at the booth, but where the founders weren't yet at the stage where they had money to spend on services like ours, instead having to do everything that they could themselves to scrape by. • salespeople sent to these conferences by larger companies: people who had selling dealflow authority within their company; but who had no buying dealflow authority — or even buying proposal authority — within their companies. (And I do understand that; I've found over the years that our own salespeople have been sometimes a bit too easily swayed by good rhetoric, \"crying wolf\" with breathless excitement over potential partnerships that are on flimsy ground business/product/engineering-wise. Salespeople are people with an ear for a good pitch — which is what lets them create a good pitch themselves; but it also means that a pitch with good structure can excite them, even without something meaningful behind it. Like an artist being excited by post-modern art with no underlying message.) Which together add up to the conclusion that, at least for us... trade-shows just weren't a good fit for selling our product. After a few more attempts, we just stopped bothering. (We do market at trade-shows now that we have the money for it. Booths, sure, but more importantly, ads in nearby airports during the days of the conference, sponsoring talks or conference-room names, etc. That's all just to build brand recognition, not for brand value education. And that does have a measurable impact. It turns out that the people we want to reach aren't manning the booths; they're the ones who drop into the city on the day of the conference with an eye toward making big handshake deals with specific vendors. And you can only reach them passively/ambiently.) > It is also very convenient in situations where I have performed a service for a client and I can give them a card and say keep this, if you have any problems reach out, or I can put a card in with the hardware I ship them. I guess that's fair... but I would say that you're actually limiting yourself by using a business card in that situation. Business cards are the way they are because — at the time of their inception — you might be meeting someone on the street where the two of you won't have any other way to carry small pieces of paper than slipping them into your wallets; so a stiff card, made of relatively-cheap card-stock, that fits well into a wallet, is an ideal form-factor. But if you're already providing the customer a service, and want to get repeat business, and/or want to cross-sell them on your other services? Think bigger. Think brand-value education. Think brochures. (In fact, for a concrete example, think about a restaurant: until very recently, most restaurants that did a lot of phone-in orders would drop a paper menu in with every order. That's effectively a brochure; they're doing an exhaustive cross-selling on all their other offerings!) --- One final piece of evidence that supports neither side of the argument: artists/makers at craft fairs. These are people who normally only get to do one transaction with you, and don't have time to build any brand recognition — you're probably looking at the product, not at the ad copy. They don't expect you to write down their handle, even if you buy something from them. And for a lot of product categories (e.g. soap, handbags, ceramic figures, etc) there's no good place on the product itself to place any marketing info. The smart artists/makers at these fairs, will slip a business card (or something very much like one — I reiterate that the business-card form factor isn't necessary here) into anything you purchase from them. The funny thing, though, is that the only thing these artist/maker business cards have on them, are the artist's/makers's social-media handles (i.e. the same ones that are printed on the banner of the booth.) As such, interestingly enough, the artists/makers will often turn their \"business card\" into a good of its own — something people would want to display for its own sake — but which is given out for free with purchase of any other item. E.g. someone at an art fair who makes vinyl stickers, will make a vinyl sticker of a stylized version of their brand logo / brand mascot, with the social-media handle snuck in somewhere on it, and that will be their \"card.\" Some people see these on the table and try to buy them! reply sghiassy 13 hours agorootparentprevI met a helpful SMB lawyer this way and btw, I’ve have literally never once in my life ever written a comment as long as yours reply derefr 4 hours agorootparent> I’ve have literally never once in my life ever written a comment as long as yours I get this sort of reply almost every time I write a \"divisive\" comment. I write a lot, I admit; but it doesn't take me particularly long to do so, and would take me a lot longer if I tried to edit it down. Maybe all the words aren't necessary, but IMHO all the points I made were: anything I left out would be brought up as an easy rebuttal, and I don't want to spend hours going back and forth on \"gotchas\" that I could just head off at the pass. People don't get mad at this communication style when I use it in a non-debate (e.g. \"fun thing I learned\") context. Why does it suddenly rile people up so much when it's used for debate? (Is it because people generally expect textual debate to work like verbal debate — where rhetorical \"interrupts\" about a person not being immediately perfectly clear and precise the first time they make a point, are considered \"invalidations\" of that argument, even if the person wasn't done making the point? And once people are allowed to have an arbitrarily-long \"turn\", they can fully clarify their initially-messy points, so the people who ride on rhetorical \"interrupts\" have no ammunition left other than \"that was too long\"?) reply zknow 10 hours agorootparentprevfwiw I'm an entrepreneur/business owner far from the software business, and I've be asked a few times for a business card so I'm going to get one just to have it handy. reply Stedag 15 hours agoparentprevFor conferences and trade-shows where there is an expectation to network. My company gives us conventional cards with little qr code v-cards. I only needed a handful of cards for a recent event as I'm not one of the sales engineers. When I realized I wouldn't have any in time if I requested them, I saw it as an opportunity to understand the v-card format and qr codes and write https://github.com/Stedag/qr_card which generated them and I just cut a out a couple sheets of card stock. My favorite part is that I could set the note for my contact in their phone to be specific to the event while not being sneaky: \"NOTE: Met at robotics summit 2024 :)\" reply LikeAnElephant 19 hours agoparentprevYep, I do. It's a baseline expectation in my experience when working within less technical industries. reply throwadobe 17 hours agorootparentwithin any industry, really, even technical ones... \"Tech\" seems to be the exception. reply bityard 3 hours agoparentprevSure. I would go so far as to say if you consider yourself a professional in your field and don't have a business card, you are probably missing out on networking opportunities. (Not because you don't have a business card, but because you aren't exposing yourself to situations where people would ask for one.) reply singpolyma3 3 hours agoparentprevAfter accruing a big bag of them which I honestly never looked at again, I stopped. Accepting one from someone is considered polite in some circles, but ultimately meaningless reply getlawgdon 14 hours agoparentprevYes. Go to any conference or trade show or people-convergent event, nearly just about anywhere, particularly one that is even just vaguely not \"tech\" since, like, Bay Area bubblism seems to be the exception, and you'll find cards being traded like...trade show business cards. reply tomwheeler 14 hours agoparentprevWhen I applied for a business visa for India earlier this year, I had to submit a business card as part of the application process. Since my company doesn't issue them, I created one of my own. I even printed it in case an immigration officer wanted to see it when I arrived there. reply Brajeshwar 15 hours agoparentprevNot necessarily but here is how I do (I'm in the technical industry). I will try to initiate the iOS Bump thingy > if not goes to a backup tool called HiHello[1] (universal) > then the business card. Of course, if I'm in the company of either Japanese or if I see people handing out printed business cards, I have my super well-done minimal but still beautiful paper business card. The paper ones lasts a very long time (years) these days. 1. I stumbled on HiHello (I think on HackerNews) and I can use this by just swiping the home screen for the widget and don't have to ever open the App. https://www.hihello.com reply bicx 17 hours agoparentprevHonestly, if you’re in a job where you meet potential connections in person, it’s a lot easier to give someone a card with your info rather than to tell them how to find you on the internet and hope they remember. reply onionisafruit 15 hours agorootparentI was at gophercon last month, and I vowed to get calling cards before next year. Getting out your phone and typing contact info is awkward by itself. Add in my hearing loss and it gets even worse. reply dewey 12 hours agoparentprevI thought they were dead too, then went to some networking events that are not just people in tech and realized I’m the only one without. reply djstein 15 hours agoprevlove to see this running as a django app! reply EGreg 14 hours agoparentwhy specifically django? reply johng 20 hours agoprevPretty neat! reply pavlov 20 hours agoprevBut does the font selection include Silian Rail and Romalian Type? “Look at that subtle off-white coloring. The tasteful thickness of it. Oh my God, it even has a watermark…” reply chefandy 16 hours agoparentI believe his was actually a small caps variant of Garamond. reply throwanem 14 hours agorootparentThere's a letterpress shop in Washington with a lot to say, and apparently a product line, on this topic: https://hobancards.com/blogs/thoughts-and-curiosities/americ... reply stavros 11 hours agorootparentWell that was an interesting read. I never realized the cards were so middling, even having a typo on them. reply tithe 16 hours agoparentprevStill on the wait list to get into Dorsia... reply JanisIO 17 hours agoparentprev“Let’s see Paul Allen’s Card!” reply bryanrasmussen 14 hours agoprevI can't help but feel there should be some sort of endorsement of this by Paul Allen, and maybe a few other famous owners of business cards. reply epcoa 12 hours agoparentI think you mean this guy https://youtu.be/4YBxeDN4tbk?si=lc31U_SHzLGk7Qy6 reply bryanrasmussen 12 hours agorootparentI actually meant these guys https://www.youtube.com/watch?v=pgeEAGVmok4 but sure, he's also a good spokesperson! reply zx8080 19 hours agoprevDesigning business cards has nothing to do with sharing them. Someone there wants some free data? (With privacy policy page showing error 500 for the demo) reply nfoert 18 hours agoparentMy initial thoughts for this project is it's intended to be a place for you to create a digital business card as a place to put links and other information, it's more like a Linktree than an actual business card, although I do want the user to be able to print out their cards to be used physically eventually. reply Nijikokun 19 hours agoprevWhy do I need an account to make a card? Shouldn't that only be required if I want to share / save the card? reply nfoert 18 hours agoparentRight now it's a bit simpler to have the user create their account first, as it's mostly intended for them to immediately be saving it into their account so they can have it ready to be shared with others, or to print out once that feature gets added. In future having an option for the user to test it out first would be a good idea though reply serial_dev 13 hours agorootparentYeah, I don't see the point of forcing users to create an account just to try out the app. I wouldn't be surprised if you had an extremely large percent of garbage input in your database. Thankfully, you didn't actually verify the email address, but if you did, that's probably the point where I would have gave up. reply nfoert 1 hour agorootparentYeah, that’s a good suggestion thank you, I will be implementing a way for people to test it out and then create the account only if they want to save/share the card. And yes I can confirm, there is quite the amount of garbage data. Thank you for the feedback! reply aperezalbela 17 hours agoprevPassing username and password as HTTP Headers doesn't seem like a good idea reply throwaway837r2 1 hour agoparentI'm curious about what makes it a bad idea. What is the difference between sending it as a header compared to sending it as form data? If someone has access to headers, they probably also have access to the body. reply nfoert 16 hours agoparentprevYeah you're right, that's definitely not the the most secure. Do you know of a more secure alternative I could try instead? reply aperezalbela 15 hours agorootparentI'd suggest using forms.Form for a LoginForm containing e.g. username = forms.CharField(max_length=150) password = forms.CharField(widget=forms.PasswordInput) and then a view to instantiate form with request.POST (if request.POST) like: form = LoginForm(request.POST) and then if form.is_valid() you can clean data using username = form.cleaned_data['username'] and the same for password. Then: user = authenticate(request, username=username, password=password) and then check if user is not None then login(request, user) Note that login and authenticate come from django.contrib.auth import authenticate, login Hope that helps. reply nfoert 1 hour agorootparentThank you, Django Forms do look promising. I’ll definitely look into more secure alternatives to the current implementation. reply singpolyma3 3 hours agorootparentprev...how is that more secure? reply mcsniff 20 hours agoprev [–] I have to have an account to put text on a background...and your privacy policy page currently throws http error 500. https://cardie-uwtwy.ondigitalocean.app/privacy reply nfoert 18 hours agoparent [–] Thanks for pointing that out, I figured out why that's happening, it'll be fixed in the next release And it's currently in open alpha, it's not yet finished. I have a lot of plans on how to offer more customization options in future. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Cardie allows users to design, share, print, and save business or information cards, with features like analytics and privacy settings.",
      "The project is currently in open alpha, meaning it is subject to rapid changes and potential bugs.",
      "Installation involves cloning the repository, setting up a virtual environment, installing dependencies, and configuring a Django server."
    ],
    "commentSummary": [
      "Cardie is an open-source platform for designing and sharing digital business cards, with future print options planned.",
      "The project is currently in open alpha, with more customization options and improvements, such as testing without account creation and enhanced security measures, being developed.",
      "The platform aims to provide a modern alternative to traditional business cards, similar to services like Linktree."
    ],
    "points": 156,
    "commentCount": 52,
    "retryCount": 0,
    "time": 1722455437
  }
]
