[
  {
    "id": 41133917,
    "title": "CrowdStrike representatives issue trademark infringement notice to ClownStrike",
    "originLink": "https://clownstrike.lol/crowdmad/",
    "originBody": "Oh No! The Clown Services Company is coming after ClownStrike! Update August 2, 2024 The Saga Continues! CloudFlare “took down” the site, see below! Neat! We made the top of Hacker News The Clown Services Company is a company used by companies like CrowdStrike to submit bogus takedowns and commit cyberbullying. It seems as though CrowdStrike is not exactly a fan of this site, understandable… it is a parody site after all… Don’t worry though! They will definitely solve all their problems by sending a baseless takedown notice to CloudFlare! (sarcasm) Received Morning of July 31, 2024 Unfortunately for them, I don’t really care about their feelings, and how upset this site makes them, or how much they cry at night knowing that there are people out in the world making fun of CrowdStrike for causing the worst IT outage in the world (so far!). Stranding millions of airlines passengers, and causing billions of dollars worth of damage… We finally know what caused the global tech outage - and how much it cost What we know about CrowdStrike’s update fail that’s causing global outages and travel chaos CrowdStrike fixes start at “reboot up to 15 times” and get more complex from there Major outages at CrowdStrike, Microsoft leave the world with BSODs and confusion Microsoft says 8.5M systems hit by CrowdStrike BSOD, releases USB recovery tool How a software update from cyber firm CrowdStrike caused one of the world’s biggest IT blackouts Chaos and Confusion: Tech Outage Causes Disruptions Worldwide Widespread IT Outage Due to CrowdStrike Update CrowdStrike outage explained: What caused it and what’s next Of course, I did not want to piss off CloudFlare either, and I’m most definitely not trying to put CloudFlare in the middle on this… so I told CloudFlare that I will take the site off of CloudFlare; however, it is staying on the internet… Reply Sent Morning of August 1, 2024 CloudFlare (ClownFlare?) apparently didn’t read the above though… because I received the following from CloudFlare: Received Morning of August 2, 2024 Of course, I couldn’t just ignore this. I of course replied to CloudFlare: Reply Sent Morning of August 2, 2024 It is unfortunately well known that the DMCA is used by corporate cyberbullies to take down content that they disagree with; but, is otherwise legal. The Counternotice system is also hillariously ineffective. The DMCA requires service providers to “act expeditiously to remove or disable access to the infringing material;” yet, it gives those same “service providers” 14 days to restore access in the event of a counternotice! The DMCA, like much American legislation, is heavily biased towards corporations, instead of the actual, living, breathing, citizens of the country. It’s absolutely asinine and I would love absolutely nothing more than to have a lawsuit “win” against CrowdStrike. That would be absolutely amazing for marketing! Especially given the timing of such events… Additionally, using the Digital Millenium Copyright Act to attempt to takedown a parody site for Trademark Infringement is absolutely hillarious. There are several ways that anyone is allowed to use a trademark belonging to “others.” This is considered “Fair Use.” Fair Use is an important aspect of trademark and copyright law. It is a right to use trademarks and copyrighted works for parody, criticism, transformative works, news reporting / journalism, education, etc. Corporate cyberbullies don’t like that anyone else has rights. Again, I don’t care, because the only thing that matters is the law, and what a court thinks about it. Luckily… Parody is a well recognized “right” for “fair use” TRADEMARK LAW: PARODY and the Fine Line Between Humor and Trademark Infringement Supreme Court Ruling Confirms Limits on Parody Defenses to Trademark Claims Satire and Parody in the Recent SCOTUS Decisions Laugh It Off: A Guide to Parody Under U.S. Trademark Law Parody Products: When Should Brand Owners “Smile or Laugh” and When Should They Sue? Additionally, there is a statutory exclusion for “Any noncommercial use of a mark” in 15 U.S. Code § 1125 (c)(3)(c). Seeing as how this site is an obvious parody, that any “reasonable person” would be able to cleary identify AND there is no commercial use, no product being sold, no money being made in any way, shape, or form… You can go straight to hell CrowdStrike. This is fair use. Fuck your feelings. Now… Return to Clownin’ P.S. Don’t your lawyers have more important shit to be doing right now anyway? P.P.S. btw George you look great in a clown suit: The above image of George Curtz is by CrowdStrike, Inc., CC BY-SA 4.0 https://creativecommons.org/licenses/by-sa/4.0, via Wikimedia Commons. License for this derivative work is also under CC BY-SA 4.0 🤡 😂 P.P.P.S. P.P.P.P.S Still need help getting your CrowdStrike issues resolved? See Below!",
    "commentLink": "https://news.ycombinator.com/item?id=41133917",
    "commentBody": "CrowdStrike representatives issue trademark infringement notice to ClownStrike (clownstrike.lol)1126 points by clownstrikelol 21 hours agohidepastfavorite221 comments cj 20 hours agoFWIW: CSC is a company that other companies hire to act on its behalf. It's very likely that the company you work for uses CSC as it's registered agent in the State of Delaware for administrative purposes (CSC doesn't really do anything other than exist on paper and file annual forms to satisfy legal and compliance requirements necessary for companies to exist in the US). I wasn't aware they file DMCA requests on behalf of companies... that seems off brand for them. (After writing the above) turns out CSC has a Online Brand Protection service. https://www.cscdbs.com/en/brand-protection/ I wouldn't be surprised if: 1) Crowdstrike incident takes down internet 2) Crowdstrike files a claim on their cyber insurance policy which includes coverage for brand protection 3) Crowdstrike (or their insurance company) buys some brand protection service, like the one offered by CSC 4) This guy receives a takedown When I started writing this comment I was intending to defend CSC. But after googling I think CSC's brand protection services are to blame. Seems to be having the opposite effect for Crowdstrike considering they paid to have their brand \"protected\" and now this guy's site is getting lots of traffic! reply chatmasta 18 hours agoparentIt’s ironic that Crowdstrike could be suffering reputational damage due to a failure mode they didn’t realize existed in the services provided by a vendor they hired to protect them from reputational damage. Maybe this will give them some empathy for their users who bought their services to protect their infrastructure. reply darby_nine 18 hours agorootparent> It’s ironic that Crowdstrike could be suffering reputational damage due to a failure mode they didn’t realize existed in the services provided by a vendor they hired to protect them from reputational damage. If you spend enough time around VC's it becomes difficult to imagine how this doesn't happen more often. Many times companies grow too quickly for a clearly seasoned veteran of the market to get a chance to take the wheel. Combine this with \"nobody ever got fired for purchasing IBM\" and you get a perfect storm for taking out the IT infrastructure for an entire culture—all you need is a majoritarian marketshare and you can take out an entire people. reply not2b 17 hours agorootparentI think it's going to shift. Airlines in particular are probably going to decide that they can't afford to take another hit like this, and come up with a way to limit the damage if a software update (even from Microsoft) is broken, and come up with a way to test updates before pushing them to all devices. reply VistaNumba1 12 hours agorootparentAh, got it. So instead they'll just keep doing what they were already doing for half their systems: Keeping them without updates for decades. Those terminals survived, afterall. reply alephnerd 17 hours agorootparentprev> come up with a way to test updates before pushing them to all devices This is SOP for plenty of purchasers already. Some orgs just don't have the ability to build processes like that. reply quantified 17 hours agorootparentprevI think the leaders of Crowdstrike should be considered clearly seasoned veterans. George Kurtz was high up at McAfee. But maybe Cathleen Anderson is a little new to the chief of legal role. reply subpub47 18 hours agorootparentprevYou don't need empathy when you have a captive market. I'm afraid we're about to enter the \"lol fuck you, what're you gonna do, leave?\" stage of this organization. reply evilduck 18 hours agorootparentCrowdstrike has several competitors, CarbonBlack, McAfee, Sophos, PaloAlto, etc. Sure, they're all equal shades of shitty, but that's a different issue. reply sowerssix 17 hours agorootparentFor what it's worth, McAfee is now called Trellix, and they now have what used to be called FireEye in their product line too. reply EvanAnderson 16 hours agorootparentprev> Sure, they're all equal shades of shitty, but that's a different issue. You can choose which digital shotgun is strapped to your organizational forehead. reply jamwil 14 hours agorootparentI’ll take several different shotguns each strapped to a different limb please. reply Nition 17 hours agorootparentprevOkay, well done, it's hilarious how perfectly this works for both the parent comment and the CrowdStrike bug. reply paranoidrobot 13 hours agoparentprevI am quite certain that CSC won't proactively send Cease and Desist/takedown notices without first confirming with the customer that they want it done. Someone at CrowdStike had to say \"Yes, send the takedown for this\". I base this on prior experience working at places which used CSC brand protection (among other services) reply account42 10 hours agoparentprevLol they actually registered clownstrike.com and have it redirect to crowdstrike.com. https://who.is/whois/clownstrike.com reply freehorse 3 hours agoparentprevThey also apparently own the clownstrike.com domain [0] and this is since 2012, crowdstrike itself exists since 2011, so they must have hired them since close to the beginning. But could be that now they are probed to do damage control after the incident (though as always this tactic tends to disperse more damage than control it). [0] https://www.whois.com/whois/clownstrike.com reply jjguy 19 hours agoparentprevBased on how well CrowdStrike has managed their response to date, this is a plausible scenario. reply aragonite 19 hours agoparentprevReminds me of that time when Mike Bloomberg's lawyers preemptively registered 400 .nyc domains for him, apparently without his knowledge, many of which are hilariously negative (MikeIsTooShort.nyc, MikeBloombergIsADweeb.nyc, GetALifeMike.nyc etc.): https://www.huffpost.com/entry/michael-bloomberg-nyc-domain-... reply defrost 19 hours agorootparentSo, Mike, tell us, your lawyers, what slur cuts the deepest so that we may register it in public to protect you . . . reply bag_boy 17 hours agorootparent“Okay, 1 down and 399 to go” reply batch12 19 hours agorootparentprevI bet that brainstorming session was a blast reply fsckboy 17 hours agoparentpreva trademark claim is not DMCA, copyright only. and what is shown on the page is Cloudflare boilerplate about DMCA, not Crowdstrike. if Crowdstrike did use the DMCA form as a way of getting attention, that still serves as \"notice\" of the trademark infringement which Clownstrike has graciously acknowledged receipt of reply toast0 19 hours agoparentprev> I wasn't aware they file DMCA requests on behalf of companies... that seems off brand for them. CSC is a well know high value domain registrar. Similar to MarkMonitor. I'm not surprised CSC does brand protection, also similar to MarkMonitor. When I was at an employer that became a MarkMonitor customer, we didn't have enough domain business to meet the minimum spend, so we started using the Brand Protection \"for free\". Sometimes they have a hair trigger, we had our own accessory apps taken down occasionally. ¯\\_(ツ)_/¯ Previous registrar was NetworkSolutions, lol; they had a customer service agent get phished, and the phishermen set new NS records for several domains, including ours. Major PITA. reply znkynz 19 hours agorootparentHave used CSC for domain / brand protection. They offer a reputable service in this space, but i must admit, i developed the view that CSC much be a surreal place to work - i just couldn't figure out what/how/why motivates people to their mission. [obv, employee compensation] reply Dalewyn 19 hours agoparentprev> Seems to be having the opposite effect for Crowdstrike considering they paid to have their brand \"protected\" and now this guy's site is getting lots of traffic! Streissand Effect. reply BenjiWiebe 17 hours agorootparents/ss/s/ That was fun. reply batch12 19 hours agoparentprevWhere they may have messed up is with the use of crowdstrike's branding. I've worked for a company that had a near 100% success rate with taking over domains that used their branding. Not just taking down the site, but taking ownership of the whole domain. reply _heimdall 17 hours agorootparentWere any of those success for violation of copyright or trademark when used in parody? I don't know if it would hold up, or how long it would even be between a domain registrar handing it over and having a day in court, but there does seem to be a good case for this being a protected use of CrowdStrike's protected branding. reply tyingq 17 hours agorootparentUntied.com lasted for a a really long time, but did eventually get taken down based on copyright. https://en.wikipedia.org/wiki/Untied.com reply account42 10 hours agorootparentThat ruling is only relevant if the operator of clownstrike.lol is in Canada. The US in particular has much better protections for parody than most countries. reply batch12 16 hours agorootparentprevYeah, there were a few. I believe they had to demonstrate that there was a risk that a customer could be misled or something. reply account42 10 hours agorootparentprevTrademark is about protecting customers not for companies to protect their image. reply Daviey 7 hours agorootparentSorry, do you mean morally, by intent/design or legally? reply dheera 18 hours agoparentprevI actually thought CSC was a parody website ... it just seems a bunch of buzzword fluff and no products. Just \"solutions\" which at other companies is usually code for \"we don't actually have anything to sell\". reply new299 20 hours agoprevI wonder to what extent companies consider the reputational damage these kinds of enforcement actions cause. I recently came across this when googling for information on a small Biotech startup: https://udrp.adr.eu/decisions/detail?id=65fab3e46fc02956a010... Will probably be the first thing I remember when I hear their name. reply fxtentacle 20 hours agoparentOh wow, they sued someone who used his last name as a domain name because they feel like their trademark should allow them to prohibit him from using his family name ... And obviously they registered their trademark after he started using his name. reply wlesieutre 18 hours agorootparenthttps://en.wikipedia.org/wiki/Nissan_Motors_v._Nissan_Comput... reply account42 10 hours agorootparentAlso https://en.wikipedia.org/wiki/Microsoft_v._MikeRoweSoft reply cowsandmilk 19 hours agorootparentprev> And obviously they registered their trademark after he started using his name. Actually, the company’s trademarks are from 2017 and he got his name via marriage in 2020. Still a stupid suit reply freehorse 19 hours agorootparentYes, but they registered it in 2022, which makes the case even more hopeless. reply runeb 17 hours agorootparentprevCuriously, Scipio is also arguably one of the most famous family names from Roman Antiquity. https://en.wikipedia.org/wiki/Scipio_Africanus reply bitwize 19 hours agorootparentprevPrince Rogers Nelson's given name was a registered trademark of Warner Music. It took that whole stunt with him changing his name to Love Symbol #2 to get them to relent. reply fuzztester 18 hours agorootparentwow. i didn't know that prince was the same as prince rogers nelson (only vaguely remembered the name prince as a musician from dances at high school), so googled his name: https://en.m.wikipedia.org/wiki/Prince_(musician) reply diego_sandoval 19 hours agoparentprevMr. Scipio had to provide evidence, lose his privacy and justify his use of the domain name to avoid losing it. That is enough proof to conclude that this UDRP thing is deeply unfair and should not exist. \"First come, first served\" is much more fair than this \"burden of proof falls on the defendant\" nonsense. We'll have to replace ICANN with something better at some point. reply tgsovlerkhgsel 16 hours agorootparentUDRP is meant to address obvious, intentional, malicious domain squatting, where someone registers a domain with your trademark and then extorts you for it. I believe it serves that purpose reasonably well. There are three criteria that ALL have to be met (1. identical or confusingly similar to your trademark, 2. registrant doesn't have a legitimate reason, 3. registered/used in bad faith). In cases where these are met, it's pretty clear that the owner should be losing the domain. I think it would make sense to add a rule that someone who issues a spurious UDRP request should be required to pay the domain holder some default amount of compensation for the hassle, but overall, I think this is a process that makes the Internet better, not worse. reply diego_sandoval 13 hours agorootparentWhat would have happened if Scipio refused to provide his marriage papers? Would he have lost the domain? How could he know beforehand? If I was in his position, I would definitely feel the implicit threat of \"if you're not willing to provide all the info we're requesting, you lose your domain\". > 2. registrant doesn't have a legitimate reason, 3. registered/used in bad faith I've read arbitration cases where \"The Expert\" says (simplifying): \"the site is being used for illegal activities, so there's no legitimate use\", when no actual court or official institution has declared that the site's content is illegal*. So, you're at the whims of some \"Expert's\" opinion of what's legitimate, even if it may eventually contradict the actual justice system of your country. I have very little trust on the competence and fairness of UDRP arbitration. * And it's not a case where the things are evidently illegal, it's very debatable if they are. reply tgsovlerkhgsel 3 hours agorootparent> even if it may eventually contradict the actual justice system of your country. As I understand it, either side can escalate to the justice system in the end. reply fsckboy 17 hours agorootparentprevHe's worried about his privacy? He reveals all on his website https://www.christian-scipio.de/ reply diego_sandoval 12 hours agorootparentWhat matters is the general case. We shouldn't be required to expose our personal lives to be able to retain our domain names. reply arp242 18 hours agoparentprevHe was even willing to sell it for €5,000. If they had just paid that relatively small sum instead of getting all triggered that someone might ask money they would have had the domain. Hilarious. Good on this Christian fella for winning. What a bunch of idiots. This does bring up a question though; I've had arp242.net for a long time, and obviously that's not my actual name. Can some company register \"arp242\" as a trademark and hijack my domain? reply devrand 17 hours agorootparentI think they generally give a lot of weight to someone who registered the domain well ahead of the said company registering their mark. Though you might run into trouble if you started using the domain in bad-faith against that company (ex. impersonating them). In your example, you had that domain well in advance, it's your self-identified pseudonym that predates said mark, and it's actively being used to host your personal website. That seems like a pretty strong defense. reply Y_Y 9 hours agorootparentprevFor the record, common law generally doesn't have a solid concept of actual/legal/\"real\" name, if you're known by a name then it's your name. My birth cert, bank accounts, passports etc. are issued in various jurisdictions with various names. I'm not an international man of mystery or tax cheat, but I'm known by various equally legitimate names. It is a bit of a bother when someone around they must all be identical, but there's no crime or deception. reply arp242 6 hours agorootparentThat is perhaps true in some Common Law jurisdictions (US?), but not for much of the world, including some Common Law jurisdiction such as the UK and Ireland. The first name I use daily is different from what's on my passport and I've gotten into trouble with this in both the UK and Ireland. reply Y_Y 5 hours agorootparentI'm not sure on what we disagree. It is my understanding that what I said applies to the UK and Ireland, there are formal ways to register a name change, but it is not necessary and it is possible to \"change\" your name simply by having people refer to you using the new name. As I mentioned, this will cause some difficulty with people and organisations who assume names are unique and immutable(c.f. [0]), but that's not a legal issue and is no different to someone not coping with any other unusual but allowable circumstance. [0] https://www.kalzumeus.com/2010/06/17/falsehoods-programmers-... reply arp242 2 hours agorootparent> there are formal ways to register a name change, but it is not necessary and it is possible to \"change\" your name simply by having people refer to you using the new name. Try opening a bank account like that. I can guarantee you it's not going to work; they will want to see a passport and proof of address with exactly the same name. I've been rejected by banks just because the utility bill shortened my second middle name to just \"P\". This seems true for pretty anything of substance: government, tax, banks, insurance, health care, things like that. I'm not a lawyer and don't know how it works according to the letter of the law, but de-facto, you will have a \"legal name\". reply fsckboy 17 hours agorootparentprev>He was even willing to sell it for €5,000. so he didn't much care about it as his email address as he generally used his other domain christian-scipio.de? https://www.christian-scipio.de/contact reply devrand 15 hours agorootparentIt sounds like they intended to use it as the primary e-mail domain for himself and family. They claimed that they had already switched to using it. However, the total window of time here is small. They registered the domain in late November 2023 and this UDRP was filed in late February 2024. It also sounds like initial contact to try to acquire the domain occurred in early December 2023... so only a couple days after it was registered. reply InvaderFizz 17 hours agorootparentprevThey can try through the UDRP, but your easy defense is to point that the date registered exceeds their TM by years. The UDRP would be highly likely to end in your favor should you dispute. reply jrs235 18 hours agoparentprevIt brings more eyeballs and attention to them when they do this and makes uninformed or unopinionated people view them negatively. https://en.m.wikipedia.org/wiki/Streisand_effect reply herman_toothrot 19 hours agoparentprevRIP Uzi Nissan of Nissan Computer Company. reply Terr_ 18 hours agoparentprevKinda wish the company got more than a slap on the wrist for such nonsense. > While the Complainant may have 'sailed very close to the wind' in this case [...] the Complainant's conduct in this case does not appear to fall squarely into the realm of any of the above mentioned [Reverse Domain Name Highjacking] circumstances. Therefore, the Panel has decided not to make a finding of RDNH on this occasion. The Panel however cautions the Complainant to only invoke the [Uniform Domain-Name Dispute-Resolution Policy] Policy in the future in circumstances under which the Complainant is able to identify the bases and adduce evidence in respect of all three UDRP Policy grounds. So yeah, name-n-shame on their leadership such as *checks* CEO Pierre Chaumat and friends. [0] [0] https://scipio.bio/news/scipio-bioscience-appoints-new-ceo-t... reply erredois 19 hours agoparentprevRemindes me of someone I met a long time ago that had the Zeppelin last name, and could not use on Facebook because and agreement between Facebook and the band Led Zeppelin blocked it. reply djbusby 18 hours agorootparentYet, someone squatting my trademarked name (profile URL) on FB and I can't get it. reply sva_ 17 hours agoparentprevPerhaps survivorship bias, in that most go under without a fight and we never hear of them. reply richbell 19 hours agoparentprevWhen I opened that link, I didn't except to be captivated by what is otherwise a boring procedural document. Shame on SCIPIO. reply hcfman 6 hours agoparentprevVery interesting this. Disappointing that they did not add any extra punishment for being bastards to the complainant reply jojobas 19 hours agoparentprevRemember how KPMG claimed nobody is allowed to link to their site? I 'member. reply subpub47 18 hours agoparentprevThey don't. What are we going to do? Nothing. reply gonzo41 18 hours agoparentprevWell it worked out for Beyonce and when she trademarked her kids name https://www.bet.com/article/86lls7/beyonce-wins-blue-ivy-tra... reply madaxe_again 19 hours agoparentprevIn my experience, businesses which are the most vigorous about pursuing frivolous IP claims and lawsuits are usually dishonest entities which themselves trample and steal the IP of others. I have twice found myself defending my IP rights when a business in one case, a government ministry in another, attempted to dispute my right to use the work that they had themselves stolen, wholesale. reply Subsentient 19 hours agoprevI am delighted to inform CrowdStrike that they have just done additional, extensive, damage to their brand, and will no doubt have just emboldened those who were tempted to sue them. Your unethical behavior and abuse of the DMCA will be used to punish you. If you succeed in getting ClownStrike taken down, you will be hated even more. Have fun annihilating your brand, reputation, and customer/industry trust and goodwill. reply hcfman 6 hours agoparentSometimes companies completely change their name after reputation damage. Maybe they are attacking clownstrike because they had intentions of escaping reputational damage by changing their name to clownstrike ? reply hcfman 6 hours agorootparentIf clownstrike is taken, maybe they can try clownstruck? reply hcfman 6 hours agorootparentWould I get sued if I made a company called clownstruck? There's quite a lot of difference, unless they really identify with the sentiment. reply hcfman 5 hours agorootparentprevWould clownstrikken be okay ? reply hcfman 5 hours agorootparentprevPerhaps coulro-strike ? reply mmaunder 20 hours agoprevThis is why you want to remove as many intermediaries between your content and your audience as possible. Ideal scenario is your own ASN and a pipe with a commit and your own physical box. The only takedown target is your upstream bandwidth provider. From there you’re adding takedown targets: hosting provider, edge cache/firewall provider, commercial CMS, etc. So pick your middle ground carefully. I’d suggest that choosing a commercial CMS makes you an easy target. Apparently so does choosing Cloudflare. reply actionfromafar 20 hours agoparentNext up - Cloudstrike.com? reply readyplayernull 18 hours agorootparentClownflare.com https://news.ycombinator.com/item?id=41132328#41133504 reply SXX 19 hours agorootparentprevAirStrike.com - considering downtime of so many airlines. reply airstrike 19 hours agorootparentSadly I know from personal experience that that's been registered for a long time... reply inopinatus 19 hours agoparentprevIn this case Cloudflare, in a spasm of comprehension failure, soiled themselves further by proving unable to distinguish between a trademark complaint and a copyright complaint, and erroneously labelled the former as the latter. Irrespective of the fair use merits on display, the DMCA simply does not apply to trademark disputes. reply akira2501 19 hours agorootparentSince this is \"their core business\" it's hard to believe that this material misrepresentation wasn't knowing or willful. I believe they've partially opened themselves to a counter suit on this point. reply FireBeyond 18 hours agorootparentExcept... in the 26 years the DMCA has been around and all the millions (billions?) of claims that have been made via it, want to guess how many people or organizations have been faced perjury repercussions? Starts with \"Z\". Ends in \"ero\". reply jbombadil 19 hours agorootparentprevYeah, my guess is that CloudFlare uses CrowdStrike as their EDR and thus have a cozy business relationship with them... reply aeyes 17 hours agorootparentprevFrom my experience receiving a few of these I came to the conclusion that Cloudflare only forwards these DMCA requests, they don't review them at all. reply nvy 19 hours agoparentprevCloudflare only stands up to bullies when the CEO feels personally attacked. reply fortran77 17 hours agorootparentMore like ״caves in to bullies.” reply jojobas 19 hours agoparentprevhttps://madattheinternet.substack.com/p/where-the-sidewalk-e... reply janmo 17 hours agoprevI am familiar with CSC, and have received a multitude of fake DMCA takedown requests from them.They make it look like a DMCA but logos are usually trademarks (TM) and not copyright protected (c). So you cannot send a DMCA. Basically their strategy is to flood the internet with fake DMCA, targeting everything that isn't seen as positive for the brand. I 100% ignore their requests, and so far nothing has happened, keep in mind they send millions of it. reply ronsor 20 hours agoprevJudging by the amount of upvotes this post has received, I believe CrowdStrike has made a major PR mistake. reply boomboomsubban 17 hours agoparentIf years from now CrowdStrike is known as \"that company that sends bogus DMCA claims over parodys\" then this is a huge success. Even a negative distraction might be good for them right now reply NBJack 19 hours agoparentprevStreisand Effect in full force here. This is more than just a PR mistake now. I look forward to it being picked up by major news outlets. reply nerdponx 20 hours agoparentprevWho cares if it doesn't hurt revenue? reply rainsford 19 hours agorootparentI certainly don't want to claim everyone on Hacker News is a high powered CISO making EDR purchasing decisions for their Fortune 500 company or whatever, but I feel like there are enough people with actual influence who read this site that if I was a security company (or any tech company) I wouldn't want front page stories that make me look petty about getting rightly clowned on after a fuck-up of galactic proportions. reply WheatMillington 18 hours agorootparentI mean... is THIS going to be the thing to tip you over the edge? Not last month's shenanigans, but THIS? reply NohatCoder 0 minutes agorootparentThere is the difference that this mistake is much simpler. A lot of business people will understand that having a litigation team without even the most basic Streisand filter is a newbie mistake. How they should have/could have protected themselves against the big breakdown is a lot more complicated, even for tech people. hot_gril 17 hours agorootparentprevAlso, the name \"Crowdstrike\" was already worse than the name \"Clownstrike\" reply subpub47 18 hours agorootparentprevSeriously. If the last 20 years of fuckery haven't been enough, nothing short of a nuclear holocaust will make people stop and reconsider. reply sophacles 18 hours agoparentprevI believe the brand reputation company made a mistake on behalf of crowdstrike. I doubt anyone at crowdstrike was involved directly. reply account42 9 hours agorootparentDoes it matter? If they authorized a brand reputation company to harass random third parties without runnit it by them firs then it's still their fault. reply rsingel 19 hours agoprevCloudflare's lawyers should have told Crowd strike to kick rocks. The DMCA's copyright provisions apply only to copyrighted content not trademarks. Cloudflare could have told these clowns to go kick rocks without incurring any liability and could have threatened them with filing fake DMCA claims. reply Terretta 18 hours agoparent> Cloudflare's lawyers should have told Crowd strike to kick rocks. Not all ISPs use provisions in the DMCA that let them put the burden back on the claimant. A few do. In general, if ISPs or CDNs have a free plan, they can't, as bad actors leverage these free plans in bulk. But ISPs or CDNs that charge actual money to known customers will generally not take down until all legal avenues to keep their client online are exhausted or someone upstream from them blinks which threatens the rest of their customers. It's not a question of getting what you pay for so much as being sure that everyone using the same provider is paying, and having a discussion with the provider before it happens instead of during. You also need all links to play it this way, or you have to host in a different jurisdiction, which may not be possible for some data/content. There are ISPs, CDNs, DNS registrars, data center facilities, backbone providers, who don't take down before asking questions, so if you need to be in the USA, find those. // I have been both a provider refusing to take a client down for nonsense, and a client of those upstream who refused to take us down when our clients were under threat. And yes, when this would happen we spent money rather than cave if the mega corp insisted to go to court, yes the mega corps lost (typically instantly), and yes we donated to EFF. reply bhelkey 17 hours agoparentprev> Cloudflare could have told these clowns to go kick rocks without incurring any liability If Cloudflair didn't remove the content and the content was infringing they could lose their safe harbor protections [1]. In this case the website is obviously parody. This highlights the problems with DMCA. Fraudulent DMCA requests incur cost but are almost never penalized. [1] https://www.dmca.com/FAQ/What-is-a-DMCA-Takedown reply poizan42 17 hours agorootparentNot if the DMCA takedown notice wasn't valid in the first place. (By valid I mean it correctly follows the requirements in the DMCA, one of them being that it must be for copyright. It does not apply to other kinds of IP, nor does it apply to other violations of the DMCA such as the anti-circumvention provision cough youtube-dl cough) reply rsingel 15 hours agorootparentThis is correct and exactly why Cloudflare should have thrown this in the green compost bin the moment it showed up, and written back to say if you send us this kind of trash again, we will sue you. reply jsheard 20 hours agoprevCrowdStrike/CSC has owned at least clownstrike.com and clownstrike.net since 2012, but they weren't on the ball with those new TLDs it seems. reply freehorse 19 hours agoparentThis is true [0]! But even more surprisingly clownstrike.com redirects to crowdstrike.com. I am surprised why they may have thought this is a good idea, but it means that we can actually use clownstrike.com instead to reference it in the web. [0] https://www.whois.com/whois/clownstrike.com reply shakna 18 hours agorootparentIt's fairly par for the course, for big business. For example: https://www.microsoft.sucks/en-au/microsoft-365 reply freehorse 11 hours agorootparentI assume they intend to redirect misspells, and they unintentionally include domains making fun of them, but it is still funny and stupid they do it. reply Avicebron 20 hours agoparentprevI get it, staying on the ball in fast-changing dynamic environments can be tough, good thing they don't run an EDR reply scintill76 20 hours agorootparentTheir TLD scraper created a file of nothing but zeroes, so the registration script crashed and went into a bootloop trying to read it. reply bitslayer 19 hours agoparentprevI worked at company_name when the .xxx top level domain became available, and my boss was sure that we should buy company_name.xxx. I talked them out of it. Luckily no one has maliciously registered company_name.xxx all these years later. I guess it could happen any day now. reply account42 9 hours agorootparentDoes rule 34 apply to corporations? reply xanderlewis 20 hours agoparentprevIt’s quite surprising to me that they thought to do that, although maybe I’m just naive. I wonder what other parody names and altered versions they own… reply jsheard 20 hours agorootparentCSCs whole deal is securing domain names for huge brands, they probably have people whose job involves thinking of derogatory domains like that so they can grab them pre-emptively. The people behind the .sucks TLD turned that into an incredible grift, they charge an exorbitant amount (about $300 a year) because they know every big brand will buy brand.sucks no matter what. reply SXX 19 hours agorootparent.sucks TLD sounds like genious idea made real. http://microsoft.sucks redirect to Microsoft.com and they pay for it. reply duskwuff 20 hours agorootparentprevI worked for a company where MarkMonitor proactively registered domains for us which were likely typos of our brand (e.g. example.com -> examlpe.com, exmaple.com, etc), and would hunt down registrations of new domains which appeared likely to be phishing sites. They didn't catch everything, but they were pretty good. reply volkl48 20 hours agoparentprevI mean, there's now what, 2,000 TLDs and growing? I'm not sure it's going to be practical to own every likely parody domain at every TLD. reply djbusby 18 hours agorootparentA big company can afford it. Drop in the bucket. reply tamimio 18 hours agoparentprevAh, what?! So, there was already a running joke about CrowdStrike being a clown one? Otherwise, why buy it and redirect to it? What about DoubtStrike? reply AHOHNMYC 3 hours agoprevFair parody user script response: // ==UserScript== // @name Clownin' // @namespace Clown Division // @include * // @version 0.0.1 // @author AHOHNMYC // ==/UserScript== /* This is also parody, like one in https://clownstrike.lol/crowdmad */ [ {'original': 'crowdstrike', 'parody': 'ClownStrike'}, ].forEach(clown => { tw = document.createTreeWalker(document, NodeFilter.SHOW_TEXT, el => el.textContent.toLowerCase().includes(clown['original'])); while(tw.nextNode()) tw.currentNode.textContent = tw.currentNode.textContent.replaceAll(new RegExp(clown['original'], 'ig'), clown['parody']) }); reply wanderingmind 19 hours agoprevStreisand effect in full play. Many people even in HN might not have known this parody site before, but will now know and actively engage with it. It's a shame people running these multi hundred billion dollar industries, never seem to learn basic unintended consequences of actions in socio-economic dynamics. reply nerdponx 4 hours agoparentThe consequences are virtually nonexistent. They know what they are doing. There is nothing to learn. reply hot_gril 17 hours agoparentprevSay 1000 HN users visit this site. So what? reply dh2022 19 hours agoprevIf ClownStrike wanted to take down the site they should deploy another buggy update. They will take the site down along with the rest of the Internet… reply not2b 18 hours agoparentOnly those sites that continue to allow every CrowdStrike update to go instantly to every device without any sanity testing would be hit by the next one. Competent IT departments will recognize that they can't risk their business in this way any more. Airlines in particular will have to recognize that they can't afford the hundreds of millions of dollars in losses that could come from a repeat of this, from either CrowdStrike or Microsoft, and come up with a way to update only test systems first. reply para_parolu 15 hours agorootparentThey didn’t consider first time. Why would they change mind? I believe most companies will still run security theater with crowdstrike or whatever other provider reply MarkusQ 20 hours agoprevCrowdStrike definitely has the chops when it comes to taking sites down, I'll give them that. reply eftychis 20 hours agoparentI guess this site is using Linux or BSD and they had to venture outside their usual modus operandi to DMCA... /s reply rhabarba 19 hours agorootparentDon't forget that Clownstrike took down Linux systems in April. reply indigodaddy 18 hours agorootparentFalcon sensor has been causing kernel panics / memory stacktraces / and insanely high load for years on Linux boxes (RHEL 7/8 mostly where I was at), not just in April. reply rhabarba 18 hours agorootparentAh, I did not hear about that before. Thank you. reply throwup238 19 hours agorootparentprevDid they try to misformat the DMCA take down notice in the hope that it takes down Cloduflare's parser? That sounds like something they would do. reply zitterbewegung 19 hours agorootparentprevOr a Mac. Also, I think kernel module like systems on macOS (ktext) got eliminated from current versions. reply Natsu 19 hours agorootparentprevThey are quite capable of taking down Linux servers too: https://www.techspot.com/news/103899-crowdstrike-also-broke-... reply subpub47 20 hours agoprevSurely those resources could be better spent on functional Uber Eats gift cards. reply tonetegeatinst 20 hours agoparentI heard they canceled the gift cards or they didn't work. reply ganeshkrishnan 19 hours agorootparentThis is preposterous! I already ordered chicken chowmein with it reply neilv 19 hours agoprevCrowdStrike is arguing that their customers might mistake \"ClownStrike\" for their brand? reply insane_dreamer 19 hours agoprevIf they could just get you to install Falcon on your server, they wouldn't need the DMCA to take your site down ;) reply EADDRINUSE 20 hours agoprevIronically the site takes me back in time to the Attrition era, where sites like these were used as defacement to point out similar clownishness. Well done. reply tomxor 19 hours agoprevClownprotection. \"We are the clowns behind clowns, we file baseless DMCAs so you don't have to\" \"Just sit back and watch Barbra the clown do all the heavy lifting to destroy what's left of your already tainted brand\". reply yannk 18 hours agoprevI doubt clownstrike.lol is a legit website: I didn't get asked if I wanted to accept cookies. reply nicce 9 hours agoparentYou just found a website that does not collect more data than it needs to function. reply b3ing 7 hours agoprevIsn’t this allowed as a Parody? Or do they need to state it up front like first thing on the page reply Rothnargoth 19 hours agoprevHope they implement a link shortener on that domain with the endpoint \"/deploy/patch/globally/unchecked/\". reply failrate 19 hours agoprevIf they want it down, they just need to convince that website to use CrowdStrike. reply latentsea 18 hours agoprevEasiest way to take down the site is just install crowdstrike on it. reply willguest 19 hours agoprev'antifraud.response@cscglobal.com' doesn't seem to understand what fraud is, which is more than a little concerning reply karaterobot 18 hours agoprevI'd have guessed the legal team would have better ways to spend its time right now than pursuing action against an obvious parody. So, this seems like it could be an empty threat to me. But if they intend to proceed, they'd better hurry before Crowdstrike itself collapses under the weight of the lawsuits against it. reply jml7c5 18 hours agoprevFor reference, this is the site as it appeared when it garnered the DMCA notice: https://web.archive.org/web/20240727134616/https://clownstri... reply hajkflk 19 hours agoprevWhat would they do if CrowdStrike were the first search result for \"miserable failure\"? https://en.wikipedia.org/wiki/Google_bombing#Other_search_en... reply lijok 19 hours agoprevDid they try offering clownstrike a $10 uber eats gift card for them to take it down? reply tamimio 18 hours agoprevWhere’s the infringement when the name doesn’t even match?! “Crowdstrike” vs “Clownstrike”? Or is it illegal now to rhyme words? After what happened, that company should be dismantled for good. reply arp242 18 hours agoparent> is it illegal now to rhyme words Trademarks have always applied anything that could reasonably be confused with it. So yes, it is illegal to rhyme trademarks. But trademarks has also long since allowed for parody and other usage that doesn't harm the trademark owner. That's why it's a nonsense request, not because of the rhyming. reply akira2501 17 hours agorootparent> anything that could reasonably be confused with it. Trademarks only apply to _related_ goods and services. > it is illegal to rhyme trademarks Not necessarily. The standard is \"confusingly similar\" or \"likelihood of confusion.\" There are many words and phrases which rhyme incidentally where trademark protection would not apply or where damages would not be granted. The confusion also has to apply specifically to the brand or the product. If your trademark fails to be associated with either of those things it can be invalidated. reply kevincox 17 hours agorootparentprevTrademarks protect against confusing consumers. I don't think any reasonable person looked at this website and thought CrowdStrike launched a rebranding or was in any way involved. reply arp242 17 hours agorootparentNo of course not, because it's clearly a parody. I already said that. reply tamimio 18 hours agorootparentprev> So yes, it is illegal to rhyme trademarks. Do you have any real life examples of that? reply arp242 17 hours agorootparentDo you also want me to prove the sky is blue and that sex causes babies? It's trademark basics that it applies to anything that can reasonably be confused with it. But please, try starting up Goodle Search or Matflix Streaming and let us know how that went for you. reply tamimio 17 hours agorootparentI don’t know why you are getting defensive. I asked a clear question on something that I have little knowledge about, and it seemed you do, so it’s a good chance for you to provide more information or details about the topic. Not everyone here is a trademark lawyer. That being said, I did a quick search on both “goodle” and “matflix” and I didn’t find any trademark wars or articles about them. However, I did find fully functional sites with these names. reply defrost 16 hours agorootparentprevMat Goodle and Katie Perry might want to weigh in on that: Katy Perry v Katie Perry: Singer loses trademark battle https://www.bbc.com/news/entertainment-arts-65421964 reply account42 11 hours agoprevWhy is Buttflare even honoring a \"DMCA takedown request\" for trademark infringement? reply jimt1234 17 hours agoprevDoes anyone have experience with these trademark/DMCA takedown requests? I'm curious, do receivers of these requests really do any sort of due diligence on the requests? Or, do they just rubber-stamp them, and pass them onto the targets of the requests? For example, if I hit YouTube/Google with a trademark/DMCA takedown request, claiming to own the name, \"Mr. Beast\", and I provide some phoney registration number, they're not gonna act it on...are they? reply insane_dreamer 19 hours agoprevThe only way to prevent this from happening again (by CloudStrike or a future incompetent company) is for CloudStrike to be sued out of existence. reply INGSOCIALITE 19 hours agoprevthey are also sending dmca notices to etsy to take down parody stickers reply facorreia 18 hours agoprevTo be fair, it's easy to confuse clownstrike.lol with clownstrike.com. reply discordance 19 hours agoprevHow does CrowdStrike even have a business left to defend? Are companies still using their service? reply bigstrat2003 19 hours agoparentYes, of course there are. They may yet lose their customer base, but it takes more than a week or two for customers to jump ship en masse. reply hot_gril 18 hours agoparentprevI'm surprised their stock didn't fall further. Would think user trust is everything for this kind of company. Maybe it goes to show how numb a lot of traditional companies are to computer downtime. reply subpub47 18 hours agorootparentHedge funds weren't the ones stuck at airports for days waiting for flights. reply hot_gril 17 hours agorootparentThey probably were, though reply swayvil 20 hours agoprevThey'll change their company name inside a year. Bet on it. reply insane_dreamer 19 hours agoprevThat video is genius. reply 486sx33 20 hours agoprevCrowdstrike is evil ! reply delduca 19 hours agoprevThe attempt to silence will likely backfire; the site will become famous. reply AcerbicZero 20 hours agoprevMust be contract renewal time, and they're rushing to pad the numbers ;) reply thewileyone 16 hours agoprevDon't call it ClownStrike ... call it ClownsTrike :) reply mistercow 20 hours agoprev> I’m most definitely not trying to put CloudFlare in the middle on this… so I told CloudFlare that I will take the site off of CloudFlare; however, it is staying on the internet… I mean that’s kind, but the whole point of DMCA safe harbor provisions is that they aren’t in the middle of this. They send along the notice, you file a counter notice, and that’s it for their involvement, yeah? If CrowdStrike wants to press the issue, they go after you, not CloudFlare. reply akira2501 19 hours agoparentI think he's attempting to point out that CloudFront's basic value proposition is meaningless if a random third party company can automatically destroy your websites with a single letter. Worse still, the letter is obviously incorrect for a trademark dispute, possibly illegal as a result, and should have never made it to the customer before being reviewed or followed up on by internal staff. My read was \"sorry you guys don't want to do your job so I'll just take my business elsewhere. goodbye.\" reply tgsovlerkhgsel 19 hours agoparentprevIn the meantime, though, even if you submitted a counter-notice, your content gets taken down for 14 days. That's likely why he migrated away. reply insane_dreamer 19 hours agoparentprevYeah but you don't want to keep getting emails from Cloudflare or have them kick you off anyway since they don't want to keep getting emails either. reply nicce 19 hours agoprevAbsolutely the most hilarious thing I have seen for a while. Thank you. reply asdefghyk 20 hours agoprevHow would I find these other ClownStrike parody sites ? reply tamimio 18 hours agoparentSomeone should make an awesome list! reply cynicalsecurity 17 hours agoprevThose clowns from CrowdStrike are digging themselves even deeper, aren't they. What a circus. reply Proziam 18 hours agoprevAfter all the security events, including the most recent. And after learning they didn't even deploy basic techniques like canary builds to prevent these events. And now this. The pattern seems to reveal that CS truly has no concept of risk management whatsoever. In finance this level of recklessness would get you banned from the industry. reply xyst 19 hours agoprevLawyers making bank on the billables for these bullshit DMCA claims. Unless it’s their internal/inhouse submitting these claims. The brand/rep of crowdstrike is already tarnished. Why let the pain continue via the Barbara Streisand effect? Not only are they technically incompetent, but now they are also petty. Poor decision making to be honest. (note: “csc” also owns crowdstrike.sucks and clownstrike.sucks) reply stuckkeys 15 hours agoprevHaha this is pretty funny. Cloud strike should worry about loosing the driver certification instead of chasing after parody sites. reply hcfman 9 hours agoparentI thought that parody was a legally protected concept ? reply ffhhj 18 hours agoprevSurprisingly clownstrike.com redirects to the parodied site. They are ready for the worst, ironically. reply hatsunearu 20 hours agoprevthat's really pathetic. they should own up to the mistake reply Alupis 20 hours agoparent> they should own up to the mistake They did! They issued $10 Uber Eats Gift Certificates that were revoked minutes later[1]. What, you didn't get to use yours in time? [1] https://news.ycombinator.com/item?id=41058261 reply damonlrr 16 hours agoprevHow did this go from #1 down to like 20 so quickly? hmmm.... conspiracy reply hot_gril 19 hours agoprevEh, there's a point where the parody is angrier and less funny than the subject, and this is well past that. Someone has too much time on their hands. reply dmitrygr 20 hours agoprevSee also: https://en.wikipedia.org/wiki/Streisand_effect reply xanderlewis 20 hours agoparentDo not click the link above. Its viewing has been officially outlawed. I’m warning you. Do not look. reply actionfromafar 20 hours agoparentprevIt's hard to top the attention they already got though. From specialised vendor to house-hold name. reply system2 18 hours agoprev\"CrowdStrike, Inc., CC BY-SA 4.0 https://creativecommons.org/licenses/by-sa/4.0, via Wikimedia Commons. License for this derivative work is also under CC BY-SA 4.0 \" reply kurthr 20 hours agoprevWell, if you don't protect your trademark? It was how most people at M$ were referring to them last week. edit: OMG, I thought it would be obvious I'm kidding. I guess garbage HN comments win garbage HN prizes. Maybe there will be a supreme court ruling that George Kurtz has to wear a clown nose due to the Krusty precedent? reply jjulius 20 hours agoparentThere's \"protecting your trademark from genuine copyright infringement\" [nods], and \"trying to silence legal parody via weak trademark arguments\" [shakes head]. reply hn_acker 20 hours agorootparent> There's \"protecting your trademark from genuine copyright infringement\" You mean \"genuine trademark infringement\". reply jjulius 20 hours agorootparentTouché, thank you! reply lcnPylGDnU4H9OF 18 hours agorootparentTo be fair, they actually sent a copyright infringement notice for this alleged trademark infringement. You were just describing their behavior! reply sophacles 18 hours agorootparentTo be fair, a trademark logo is also copyright protected... It's art. If crowdstrike lost the trademark, they'd still own the copyright on that logo. reply bhartzer 20 hours agoprev [–] What I don't understand is why companies and brands like this just don't use NameBlock or a similar domain blocking service like GlobalBlock. They literally can block domain names that have their company name or brand in them from being registered (up to 500 variations of their domain). It's literally like $99/year to place a block. Saves a lot of the hassle of having to deal with parody and phishing sites and trying to take them down. Just block the domain(s) from being registered in the first place. reply fxtentacle 19 hours agoparentThis reads kind of like an advertisement. Plus it's subtly wrong. My experience with the NameBlock API is that for those $99/year, they'll allow you to automate purchasing all similar domains. But then you have to pay registration fees on all of those domains, too. It's only $10/month per typo domain that you buy, but it sums up really quickly. reply bhartzer 19 hours agorootparentYou're thinking of some other service, not NameBlock or GlobalBlock. There's no automated purchasing of all similar domain names. You don't pay registration fees, as the domains that end up being blocked will never be registered by anyone (not even you). There literally is a block on the variations, it works at the Registry level not the registrar level. reply 8organicbits 18 hours agoparentprevThe offending TLD here is .lol, which is not one of the TLDs they support. This would not have helped in this instance. https://globalblock.co/included-extensions/ I'm also seeing much higher pricing: https://www.101domain.com/global-block.htm reply bhartzer 16 hours agorootparentGlobalBlock is owned by GoDaddy, and pretty much covers the TLDs/extensions that are owned by GoDaddy Registry. NameBlock is a separate company than GlobalBlock, and covers a different set of TLDs/extensions. reply 8organicbits 3 hours agorootparentI didn't grab the pricing info for NameBlock because it requires you to sign an NDA to even see the pricing. I also don't see a list of TLDs they support. reply voltaireodactyl 19 hours agoparentprevHow does that work in practice? Are you just paying them to lease it so you don’t have to? reply bhartzer 19 hours agorootparentIf you place a block on a brand/companyname (a string of characters), then no one can register a domain name that contains those strings of characters. They also block up to 500 variations (placing a block on 'paypal' would get 'paypa1' blocked as well. Those domains that are blocked won't be 'parked', someone trying to register the domain that's blocked, it will just say it's not available for registration. reply cortesoft 19 hours agoparentprevI don't think you could block \"clown\" or \"strike\". reply bhartzer 19 hours agorootparentYes, they could place a domain block on \"crowdstrike\", and variations of that would be blocked, such as cr0wdstrike, crowdstr1ke, etc. reply giltron 17 hours agorootparentI doubt it. They are protecting against variations of \"crowdstrike\"...Not every variation of domains with the word \"strike\" in it. That would go beyond reasonable. reply 0x1ch 20 hours agoparentprevYou'd be surprised. I recently parked some big name domains ending in various common TLDs in the world of government contracting. They did utilize some sort of parking or service to do it for them, but certainly not enough. reply josephcsible 18 hours agoparentprev [–] How can such services exist? Why would the registrars listen to them? reply bhartzer 16 hours agorootparent [–] The domains are blocked at the registry level, not the registrar level. reply josephcsible 14 hours agorootparent [–] Okay, why would the registry listen to them? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Clown Services Company, a parody site, faced a takedown notice from CrowdStrike, leading to CloudFlare removing the site.",
      "The site owner argues that the DMCA is often misused by corporations to remove legal content, particularly parody, which is protected under Fair Use.",
      "Despite the takedown, the site gained significant attention, making it to the top of Hacker News, highlighting issues with DMCA misuse and corporate influence."
    ],
    "commentSummary": [
      "CrowdStrike issued a trademark infringement notice to ClownStrike, a parody site, which ironically increased the site's visibility.",
      "CSC, a company managing administrative tasks like brand protection, likely sent the notice on CrowdStrike's behalf.",
      "The incident underscores the Streisand Effect, where efforts to suppress information inadvertently amplify it, highlighting the risks of aggressive brand protection tactics."
    ],
    "points": 1126,
    "commentCount": 221,
    "retryCount": 0,
    "time": 1722548300
  },
  {
    "id": 41132669,
    "title": "Russ Cox is stepping down as the Go tech lead",
    "originLink": "https://groups.google.com/g/golang-dev/c/0OqBkS2RzWw",
    "originBody": "Groups Conversations All groups and messages Sign in     passing torches to Austin and Cherry 40,378 views Skip to first unread message Russ Cox unread, Aug 1, 2024, 1:40:26 PM (yesterday)    to golang-dev Hi all, Starting September 1, Austin Clements will be taking over as the tech lead of Go: both the Go team at Google and the overall Go project. Austin is currently the tech lead for what we sometimes call the “Go core”, which encompasses compiler toolchain, runtime, and releases. Cherry Mui will be stepping up to lead those areas. I am not leaving the Go project, but I think the time is right for a change. It’s important to remember that tech lead—like any position of leadership—is a service role, not an honorary title. I have been leading the Go project for over 12 years, serving all of you, and trying to create the right conditions for all of you to do your best work. Large projects like Go absolutely benefit from stable leadership, but they can also benefit from leadership changes. New leaders bring new strengths and fresh perspectives. For Go, I think 12+ years of one leader is enough stability; it’s time for someone new to serve in this role. In particular, I don’t believe that the “BDFL” (benevolent dictator for life) model is healthy for a person or a project. It doesn’t create space for new leaders. It’s a single point of failure. It doesn’t give the project room to grow. I think Python benefited greatly from Guido stepping down in 2018 and letting other people lead, and I’ve had in the back of my mind for many years that we should have a Go leadership change eventually. If you haven’t worked on the compiler toolchain or runtime, you may not know Austin or Cherry well. Austin has been working on Go at Google since 2014, Cherry since 2016. Their judgment is superb and their knowledge of Go and the systems it runs on both broad and deep. When I have general design questions or need to better understand details of the compiler, linker, or runtime, I turn to them. I’m very excited that we have such great new leaders available for this change. I have full confidence in Austin and Cherry stepping up, as well as in Roland Shoemaker continuing to lead Go security and Rob Findley and Hana Kim continuing to lead Go tools and IDE support. I am going to consciously step back from decision making and create space for Austin and the others to step forward, but I am not disappearing. I will still be available to talk about Go designs, review CLs, answer obscure history questions, and generally help and support you all in whatever way I can. I will still file issues and send CLs from time to time, I have been working on a few potential new standard libraries, I will still advocate for Go across the industry, and I will be speaking about Go at GoLab in Italy in November. I will be shifting my focus to work more on Gaby and Oscar, trying to make useful contributions in the Go issue tracker to help all of you work more productively. I am hopeful that work on Oscar will uncover ways to help open source maintainers that will be adopted by other projects, just like some of Go’s best ideas have been adopted by other projects. At the highest level, my goals for Oscar are to build something useful, learn something new, and chart a path for other projects. These are the same broad goals I’ve always had for our work on Go, so in that sense Oscar feels like a natural continuation. I am incredibly proud of the work we have all accomplished together, and I am confident in the leaders both on the Go team at Google and in the Go community. You are all doing remarkable work, and I know you will continue to do that. The exact details of this transition are yet to be decided. Part of the point of this mail is to ensure that we can discuss those details publicly. Austin and I are both committed to making the change seem like a non-event except for the Go project becoming stronger and better. Again, I’m not leaving Go and will still be around and participating as an individual contributor. Please always feel free to continue to reach out whenever you need anything. And my thanks and congratulations to Austin and Cherry for stepping into their new roles. Best, Russ Daniel Martí unread, Aug 1, 2024, 5:49:54 PM (20 hours ago)    to golan...@googlegroups.com Hi Russ, Thanks for all of your work and dedication. Looking back at the biggest changes and milestones in the project in the past ten years, like modules and generics, it's clear that you played a key part in ensuring their long-term success. I've only met Austin and Cherry a couple of times but I definitely agree that they are great choices going forward. I hope you enjoy your well deserved time as an individual contributor - I think we're all looking forward to what you'll be able to contribute with the new role. Speaking of the transition and its details - would this be a good opportunity to restart the compiler and runtime meeting notes thread, which I always found pretty useful to skim through? I'd also love to see the compiler and runtime office hours calls come back :) Rob Findley and the rest of the tools folks already do a great job at being transparent with the community via Slack and our regular golang-tools calls - the runtime and compiler planning and decision making is a little opaque in comparison at the moment. Thanks again, and stick around!   , trying to make useful contributions in the Go issue tracker to help all of you work more productively. I am hopeful that work on Oscar will uncover ways to help open source maintainers that will be adopted by other projects, just like some of Go’s best ideas have been adopted by other projects. At the highest level, my goals for Oscar are to build something useful, learn something new, and chart a path for other projects. These are the same broad goals I’ve always had for our work on Go, so in that sense Oscar feels like a natural continuation. I am incredibly proud of the work we have all accomplished together, and I am confident in the leaders both on the Go team at Google and in the Go community. You are all doing remarkable work, and I know you will continue to do that. The exact details of this transition are yet to be decided. Part of the point of this mail is to ensure that we can discuss those details publicly. Austin and I are both committed to making the change seem like a non-event except for the Go project becoming stronger and better. Again, I’m not leaving Go and will still be around and participating as an individual contributor. Please always feel free to continue to reach out whenever you need anything. And my thanks and congratulations to Austin and Cherry for stepping into their new roles. Best, Russ Robert Engels unread, Aug 1, 2024, 11:36:31 PM (14 hours ago)    to Daniel Martí, golan...@googlegroups.com Thanks Russ. Go wouldn’t be what it is without your efforts. Always classy and respectful - which is a skill unto itself. On Aug 1, 2024, at 5:49 PM, 'Daniel Martí' via golang-devwrote:  -- You received this message because you are subscribed to the Google Groups \"golang-dev\" group. To unsubscribe from this group and stop receiving emails from it, send an email to golang-dev+...@googlegroups.com. To view this discussion on the web visit https://groups.google.com/d/msgid/golang-dev/954963f0-3772-4e18-bc45-caaaa0ee5b82%40mvdan.cc. cuong.m...@gmail.com unread, 2:15 AM (12 hours ago)    to golang-dev Hi Russ, Thanks for all your works for making Go becomes what it is today. I hope you will enjoy your time and having fun as an IC. Congrats Austin and Cherry, I'm looking forward to see your excelent works with your new roles. See you online! Cheers, Cuong  Andrey Bokhanko unread, 7:56 AM (6 hours ago)    to golang-dev Thanks you Russ for all the efforts and contributions! Congratulations to Austin and Cherry! пятница, 2 августа 2024 г. в 01:49:54 UTC+3, Daniel Martí: Speaking of the transition and its details - would this be a good opportunity to restart the compiler and runtime meeting notes thread, which I always found pretty useful to skim through? I'd also love to see the compiler and runtime office hours calls come back :) +1 :-) Yours, Andrey === Advanced Software Technology Lab Huawei  George Adams unread, 8:04 AM (6 hours ago)    to golang-dev Russ, On behalf of the Go team at Microsoft, I want to thank you for your incredible leadership over the past 12+ years. Your work has laid a strong foundation for Go, and we’re grateful for everything you’ve done. Congratulations to Austin and Cherry on their new roles! We’re excited to see where they’ll take the Go project and are confident they’ll do a fantastic job. It’s great to hear you’ll still be involved. Your work on Gaby and Oscar sounds intriguing, and we’re looking forward to its impact on the community. The Microsoft Go team is here to support and collaborate with you all. Cheers to the future of Go! Best, George Adams ~ Go Group Manager, Microsoft  Bartłomiej Płotka unread, 8:04 AM (6 hours ago)    to golang-dev Thanks Russ for all the incredible work 💪🏽 Oskar project looks epic, can't wait to use the solution like that in all our OSS repos at Google and beyond! Kind Regards, Bartek Plotka @bwplotka  Josh Bleecher Snyder unread, 9:43 AM (4 hours ago)    to Russ Cox, golang-dev +2   -- You received this message because you are subscribed to the Google Groups \"golang-dev\" group. To unsubscribe from this group and stop receiving emails from it, send an email to golang-dev+...@googlegroups.com. To view this discussion on the web visit https://groups.google.com/d/msgid/golang-dev/CAA8EjDQpSVZo_NMOAbJTXJnPK5rODD7-DMdDD8EM4Xsn1jg92g%40mail.gmail.com. Cherry Mui unread, 10:00 AM (4 hours ago)    to golang-dev On Thursday, August 1, 2024 at 6:49:54 PM UTC-4 Daniel Martí wrote: Hi Russ, Thanks for all of your work and dedication. Looking back at the biggest changes and milestones in the project in the past ten years, like modules and generics, it's clear that you played a key part in ensuring their long-term success. I've only met Austin and Cherry a couple of times but I definitely agree that they are great choices going forward. I hope you enjoy your well deserved time as an individual contributor - I think we're all looking forward to what you'll be able to contribute with the new role. Speaking of the transition and its details - would this be a good opportunity to restart the compiler and runtime meeting notes thread, which I always found pretty useful to skim through? I'd also love to see the compiler and runtime office hours calls come back :) Thank you for bringing this up! I think the meeting notes and the office hours are great opportunities for transparency and engagement between the compiler/runtime team at Google and the community, and we want to keep them going. We'll post an update on the mailing list when we have the next office hour scheduled. Thanks, Cherry  eric lagergren unread, 11:22 AM (3 hours ago)    to golang-dev Thanks for all you’ve done for Go. Your leadership and engineering has been top notch. A small anecdote: I learned to program about 10 years ago, starting with Go. Choosing Go was pretty much an accident, but I’m very glad I did. For 10 years now you’ve been a great role model both as a leader and an engineer. You are always very thoughtful and informative. The Go community is as well, and that doesn’t happen by accident. Thank you!   Reply all  Reply to author  Forward",
    "commentLink": "https://news.ycombinator.com/item?id=41132669",
    "commentBody": "Russ Cox is stepping down as the Go tech lead (groups.google.com)688 points by bojanz 23 hours agohidepastfavorite317 comments ainar-g 23 hours agoThank you, rsc, for all your work. Development in Go has become much more enjoyable in these 12 years: race detector, standardized error wrapping, modules, generics, toolchain updates, and so on. And while there are still things to be desired (sum types, better enum/range types, immutability, and non-nilness in my personal wishlist), Go is still the most enjoyable ecosystem I've ever developed in. reply everybodyknows 22 hours agoparentNomination for RSC's greatest technical contribution: module versioning. Absolutely fundamental to the language ecosystem. https://research.swtch.com/vgo-intro reply trustno2 11 hours agorootparentThe interesting thing is - this went pretty much against the community at the time. At the time, the community seemed to have settled on dep - a different, more npm-like way of locking dependencies. rsc said \"nope this doesn't work\" and made his own, better version. And there was some wailing and gnashing of teeth, but also a lot of rejoicing. That makes me a bit sad that rsc is leaving. On the other hand, I don't really like the recent iterator changes, so maybe it's all good. Btw if you reading this rsc, thanks a lot for everything, go really changed my life (for the better). reply yencabulator 23 minutes agorootparentPlenty of people in the community considered dep way too messy to be the real solution. reply nasretdinov 11 hours agorootparentprevIterators definitely have one of the strangest syntaxes I've seen, but if you promise not to break the language you better not introduce new syntax without a Major reason (like generics, but even those actually introduced next to no new syntax, even re-using interfaces o_O). reply foldr 10 hours agorootparentIterators don’t really introduce any new syntax, strange or otherwise. reply jdnendjjd 9 hours agorootparentThat's what he said reply foldr 8 hours agorootparentIn part of the comment yes, kind of, but the comment begins by saying \"Iterators definitely have one of the strangest syntaxes I've seen\". As there is no syntax specific to iterators in Go, I find this a bit hard to understand. reply nasretdinov 26 minutes agorootparentWell, yes, that's the thing: you don't get any special syntax for generators (like \"yield\" keyword), which makes them look quite weird compared to other languages that have native support for them. You need to have very clunky and verbose syntax (at least I view it as such) which consists of having to define an extra nested closure and use a function pointer that was passed to you. Having a new keyword would allow for a much nicer looking generator functions, but that would break all existing tooling that doesn't yet support that keyword (and potentially break existing programs that use yield as a variable name or something like that). reply makkes 6 hours agorootparentprevs/syntax/API/ It's not that hard to understand what OP means. reply mseepgood 5 hours agorootparentIt's just the visitor pattern, taught in software engineering 101. A function that takes a callback function that gets called for each visited value. Nothing strange about it. Many standard library functions such as sync.Map.Range or filepath.Walk have always used it. The new thing is that it now gets easier to use on the caller side. reply maxmcd 21 hours agorootparentprevAgreed, see the index of those posts: https://research.swtch.com/vgo Other contenders I find myself sharing and re-reading: - https://swtch.com/~rsc/regexp/regexp1.html - https://swtch.com/~rsc/regexp/regexp4.html - https://research.swtch.com/bisect - https://research.swtch.com/zip reply kiitos 2 hours agorootparentprevFundamentally broken model of versioning, but I guess nobody really cares. reply jeremyloy_wt 1 hour agorootparentCan you elaborate on what problems you have with the MVS algorithm? reply agumonkey 13 hours agorootparentprevOne I enjoyed a lot (a lot) was this one https://research.swtch.com/pcdata Hope he gives us more in the future thanks rsc reply nvarsj 1 hour agorootparentprevNot really a fan at all. Dep and its predecessors followed kiss principles, were easy to reason about, and had great support for vendoring. I’ve wasted so much time dealing with “module hell” in go, that I never dealt with in the prior years of go usage. I think it has some major flaws for external (outside Google) usage. reply LudwigNagasena 18 hours agoparentprev> non-nilness Ah, I still remember this thread: https://groups.google.com/g/golang-nuts/c/rvGTZSFU8sY/m/R7El... reply yencabulator 18 minutes agorootparentEveryone just keeps repeating the same old gripe, without bothering to read the responses. Go needs a null-like thing because the language forces every type to have a zero value. To remove the concept of zero value from Go would be a major change. reply thayne 15 hours agorootparentprevWow, that's painful to read. Separating the concept of pointers and nullable types is one of the things that I think go having from the beginning would have made it a much better language. Generics and sum types are a couple of others. reply ahoka 8 hours agorootparentFalse things programmers believe: All reference types should be able to take a null value. It's impossible to write complex and performant programs without null. It's impossible to write complex and performant programs without pointers. References always hold a memory address in a linear address space. (Not even true in C!) Every type is comparable. Every type is printable. Every type should derive from the same common type. All primitive types should support all kind of arithmetic the language has operators for. The only way to extend an existing type is to inherit from it. What else? reply pwdisswordfishz 7 hours agorootparentEvery type must have some sort of a default value. (A generalization of the first item, really.) reply twic 3 hours agorootparentprevIt's going to be much faster to enumerate the true things programmers believe. reply dgb23 2 hours agorootparentprevWithout pointers in some form or another, you can’t refer to allocated memory. You can change the name of pointers but they are still pointers. reply thayne 1 hour agorootparentIt is possible to write complex and performant programs without allocating memory. And in some languages, where you only operate on values, and never worry about where something is stored, allocation is just an implementation detail. reply dgb23 46 minutes agorootparent> It is possible to write complex and performant programs without allocating memory. I assume you mean by only allocating on the stack? Those are still allocations. It's just someone else doing it for you. > And in some languages, where you only operate on values, and never worry about where something is stored, allocation is just an implementation detail. Again, that's someone else deciding what to allocate where and how to handle the pointers etc. Don't get me wrong, I very much appreciate FP, as long as I do information processing, but alot of programming doesn't deal in abstract values but in actual memory, for example functional programming language compilers. reply bayindirh 4 hours agorootparentprev> It's impossible to write complex and performant programs without pointers. Well, I'd rather not copy around a multi-hundred-megabyte (or gigabyte) 3D object around to be able to poke its parts at will. I'll also rather not copy its parts millions of times a second. While not having pointers doesn't make impossible, it makes writing certain kinds of problems hard and cumbersome. Even programming languages which do not have pointers (cough Java cough), carry pointers transparently prevent copying and performance hits. reply marcosdumay 1 hour agorootparentWell, looks like the GP missed a very common false fact: The operations written in a program must literally represent the operations the computer will execute. This one stops being true on high-level languages at the level of x86 assembly. reply LudwigNagasena 2 hours agorootparentprev> Every type is printable. It’s 2024, every type is jsonable! reply lnggahc 7 hours agorootparentprev> It's impossible to write complex and performant programs without null. Well, clearly there is a need for a special value that is not part of the set of legal values. Things like std::optional etc. are of course less performant. If I can dream, all of this would be solved by 72-bit CPUs, which would be the same as 64-bit CPUs, but the upper 8 bits can be used for garbage collection tags, sentinel values, option types etc. reply sapiogram 6 hours agorootparent> Well, clearly there is a need for a special value that is not part of the set of legal values. There's a neat trick available here: If you make zero an illegal value for the pointer itself, you can use zero as your \"special value\" for the std::optional wrapper, and the performance overhead goes away. This is exactly what Rust does, and as a result, Option, Option>, etc are guaranteed to have zero overhead: https://doc.rust-lang.org/std/option/index.html#representati... reply dwattttt 7 hours agorootparentprev> If I can dream, all of this would be solved by 72-bit CPUs, which would be the same as 64-bit CPUs, but the upper 8 bits can be used for garbage collection tags, sentinel values, option types etc. https://www.cl.cam.ac.uk/research/security/ctsrd/cheri/cheri... Address space is 64bit, pointers are 128bit, and encode the region the pointer is allowed to dereference. And there's a secret 129th bit that doesn't live in the address space that gets flipped if the pointer is overwritten (unless it's an explicit instruction for changing a pointer) reply sirsinsalot 7 hours agorootparentprevNever met a programmer that thought these things were true. reply thayne 4 hours agorootparentA few of those myths are stated as fact in the aforementioned thread. reply klabb3 8 hours agorootparentprev> Wow, that's painful to read. And the dismissive tone of some people including Ian. But to be fair before Rust there was definitely this widespread myth in the dev hivemind that nullable pointers is just the cost of performance and low level control. What’s fascinating is how easy and hindsight-obvious it was to rid code of them. I’ve never had to use pointers in Rust and I’ve worked on quite advanced stuff. reply lupire 6 hours agorootparentNullable pointers are fine for those who need them. What we're asking for is non-nullable pointers. reply p1necone 17 hours agorootparentprevWow, that discussion is infuriating. I'm shocked that many people on there don't seem to understand the difference between compile time checks and runtime checks, or the very basics of type systems. reply noelwelsh 10 hours agorootparentMany people on here as well! :-) Reading the comments on this post is stepping into an alternative universe from the PL crowd I usually interact with. Very conservative. It's quite interesting. reply skybrian 15 hours agorootparentprevI think people do understand the basics of static type systems, but disagree about which types are essential in a \"system language\" (whatever that is). An integer range is a very basic type, too, conceptually, but many languages don't support them in the type system. You get an unsigned int type if you're lucky. reply fooker 27 minutes agorootparent> An integer range is a very basic type, too, conceptually Just signed vs unsigned makes this a complex topic. reply edflsafoiewq 11 hours agorootparentprev> An integer range is a very basic type, too Not really, its semantics get hairy almost instantly. Eg does it incrementing it produce a new range? reply randomdata 11 hours agorootparentThe semantics are always complex. The same type of question arises for all basic types. For example, what does adding a string to an integer produce? Or do you give up on answering that and simply prevent adding strings and integers? When one wants to add them they can first manually apply an appropriate type conversion. That is certainly a valid way to address your question – i.e. don't allow incrementing said type. Force converting it to a type that supports incrementing, and then from that the developer can, if they so choose, convert it back to an appropriate range type, including the original range type if suitable. Of course, different languages will have different opinions about what is the \"right\" answer to these questions. reply noelwelsh 10 hours agorootparentI think you're confusing the type and value level. The original statement was about a range type, that is something like an integer that is statically constrained to a range of, say, 1..4 (1, 2, 3, 4). To work with this as a type you need to have type level operations, such as adding two ranges (which can yield a disjoint range!), adding elements to the range, and so on, which produce new types. These all have to work on types, not on values. If 1..4 + 5..8 = 1..8 this has to happen at the type level, or, in other words, at compile-time. Range types are very complicated types, compared to the types most people deal with. Converting a string to an int is very simple to type (String => Int if you ignore errors) and adding integers is also simple to type ((Int, Int) => Int) reply skybrian 4 hours agorootparentA range type could be very simple if it were just used for storage - you couldn’t do anything with it other than passing it around and converting it to something else, and there would be a runtime check when creating it. But such a thing would be useful mostly for fields in data structures, and the runtime checks would add overhead. (Though, perhaps it would replace an array bounds check somewhere else?) reply foldr 7 hours agorootparentprevOP is just saying that you don't have to permit operations such as addition or incrementation on range types, in which case you don't need the corresponding type-level operations. reply noelwelsh 6 hours agorootparent> That is certainly a valid way to address your question – i.e. don't allow incrementing said type. Force converting it to a type that supports incrementing, and then from that the developer can, if they so choose, convert it back to an appropriate range type, including the original range type if suitable. The quoted part above is an argument for dependent types. The conversion back to a range type creates a type that depends on a value, which is the essence of dependent typing. reply foldr 6 hours agorootparentNo, I think the idea is that you'd get a runtime exception if the value was outside the range. No need for dependent types. It is no different conceptually from casting, say, a 64-bit integer to a 32-bit integer. If the value is outside the range for a 32-bit integer, then (depending on the language semantics) you either raise a runtime error, or the result is some kind of nonsense value. You do not need to introduce dependent types into your language to enable such casts (as long as you're willing to enforce the relevant checks only at runtime, or forego such checks altogether). reply noelwelsh 6 hours agorootparentI think the original comment is imprecise. E.g. \"don't allow incrementing said type\" can be read as either \"don't allow incrementing values of said type\" or literally as don't allow incrementing the type. I can see both your and my interpretation, depending on how one chooses to read the comment. reply dwattttt 7 hours agorootparentprevI regularly find quite smart people assume Rust's references must be fat pointers to handle lifetimes, and check them all at runtime. reply jrimbault 11 hours agorootparentprevIt's like they don't speak the same languages. reply paride5745 35 minutes agoparentprevI wish they would opt for ARC instead of a GC, to have a more deterministic memory objects lifecycle. Other than that, I agree with your comment. reply tapirl 3 hours agoparentprevDon't forget that the semantic change of traditional 3-clause \"for\" loops: https://go101.org/blog/2024-03-01-for-loop-semantic-changes-... Because of this change, Go 1.22 is actually the first Go version which seriously breaks Go 1 compatibility, even if the Go official doesn't admit the fact. reply kiitos 2 hours agorootparent> since Go 1.22, every freshly-declared loop variable used in a for loop will be instantiated as a distinctive instance at the start of each iteration. In other words, it is per-iteration scoped now. So the values of the i and v loop variables used in the two new created goroutines are 1 2 and 3 4, respectively. (1+2) + (3+4) gives 10. I think you are assuming more guarantees than are actually guaranteed. You have a well-documented history of making incorrect claims about Go compiler and runtime behaviors, so this isn't surprising. > since Go 1.22, you should try to specify a Go language version for every Go source file What on Earth?? Absolutely 100% not. reply dgb23 2 hours agorootparentprevAre there cases where people actually rely on the previous behavior? I always assumed that it was considered faulty to do so. reply rsc 1 hour agorootparentThere were certainly buggy tests that relied on the old behavior. We didn't find any actual code that relied _correctly_ on the old behavior. https://go.dev/wiki/LoopvarExperiment reply dgb23 21 minutes agorootparentLove it, even though it must have been incredibly confusing when old tests failed at first. The assumption being that the tests were correct. They _passed_ all those months or years! I'm just also watching your YT video on testing and enjoying it very much! reply vyskocilm 22 hours agoparentprevWell written list of what made Go better language during last years. I'd add iterators, the recent big thing from Russ. reply galkk 20 hours agorootparentWow. I haven't followed Go for a while, thanks for that note. Iterators are very nice addition, even with typical Go fashion of quite ugly syntax. reply kjksf 4 hours agorootparentJust last week I've implemented an iterator for my C++ type and lol to your comment. It was fucking nightmare compared to how you (will) implement an iterator in Go. I didn't study the reason why Go chose this way over others. I do know they've considered other ways of doing it and concluded this one is best, based on complex criteria. People who make value judgements like this typically ignore those complex consideration, of which playing well with all the past Go design decisions is the most important. Frankly, you didn't even bother to say which language does it better or provide a concrete example of the supposedly non-ugly alternative. reply galkk 3 hours agorootparentC#, python - here are the most mainstream examples of syntax that doesn’t look alien. reply mseepgood 8 hours agorootparentprevThey don't have any syntax that differs from the previous Go versions. reply valyala 9 hours agorootparentprevIterators and generics go against the original goals of Go - simplicity and productivity. They complicated Go language specification too much without giving back significant benefits. Iterators and generics also encourage writing unnecessarily complicated code, which makes Go less pleasant to work with. I tried explaining this at https://itnext.io/go-evolves-in-the-wrong-direction-7dfda8a1... reply nasretdinov 14 minutes agorootparentI'm sure I can agree about generics. In many cases Go code is already fast enough, so other things come to play, especially type safety. Prior to generics I often had to write some quite complicated (and buggy) reflection code to do something I wanted (e.g. allow to pass functions that take a struct and return a struct+err to the web URL handlers, which would then get auto-JSONed). Generics allow to write similar code much easier and safer. Generics also allow to write some data structures that would be useful e.g. to speed up AST parsing: writing a custom allocator that would allocate a large chunk of structs of a certain type previously required to copy this code for each type of AST node, which is a nightmare. reply jdnendjjd 8 hours agorootparentprevThis argument is brought up again and again, but it is just wrong. Go had both generics and iterators from the get go. Just not user defined ones. Thus it is obvious that the creators of the language always saw their need for a simple and productive language reply eweise 4 hours agorootparentNot obvious to me. We just implemented a streaming solution using the iterator interfaces. They are just functions so reading the code its easy to understand. Adding special language support only serves to obfuscate the actual code. reply joeblubaugh 4 hours agorootparentprevI do agree with his point that the implicit mutation of the loop body for an iterative will be difficult to debug. reply sharno 16 hours agoparentprevI’m sure if Go had nullable types and/or sum types from the beginning, it’s have been much more popular reply hu3 16 hours agorootparentI'm sure of the opposite given the ideas behind Go's design. reply segfaltnh 15 hours agorootparentprevIt's already quite popular. I'm less convinced there's a large pile of people wishing for a fairly high performance garbage collected language that are not using Go because of this. There just aren't many viable alternatives. reply ReleaseCandidat 14 hours agorootparentJava and C# being the obvious (and more performant) alternatives. And compared to them, Go already wins because of not being, well, \"enterprisey\". And with that I mean less the languages itself, but also the whole ecosystem around them. reply pjmlp 13 hours agorootparentGo's is already \"enterprisey\" enough, thanks to Kubernetes ecosystem. reply wordofx 11 hours agorootparentFor the 3 people who actually need Kubernetes. reply valenterry 5 hours agorootparentprevThere are definitely lots, I'm one of them. I use Scala, which is very powerful and imho much nicer language than golang. But the tooling and other support is slow and subpar. But I just can't go back to a brain-dead language(!) like golang because it hurts to program in such languages to me. So I hope that either golang catches up with Scala's features, or that Scala catches up with golangs tooling. And I think there are many similar people like me. reply lupire 6 hours agorootparentprevGo has nullable types! We want non-nullable types! reply chuckadams 3 hours agorootparentI blame C# for the confusion. Think of it this way: the ability to explicitly express a type Foo|null implies the existence of a non-nullable Foo as well. IOW it’s shorthand for “nullable and non-nullable types”. reply foldr 7 hours agorootparentprevPerhaps, but other languages that look a lot like Go with these additions (e.g. OCaml) have not gained much popularity, despite getting much more love on forums like HN. It's important to remember that the people expressing strong opinions about sum types on the internet are a tiny and non-representative fraction of working programmers. reply lupire 6 hours agorootparentOCaml has a huge number of challenges besides \"popular language plus sum types\" reply tomcam 22 hours agoprevIMHO Go has been one of the best-managed open source projects ever. Hats off to Google for supporting it. reply hoten 22 hours agoparentWhat are some things that make it well managed? reply cookiengineer 12 hours agorootparentThe reluctancy to introduce new syntax too quickly (looking at you, TC39 and Babel) makes go an almost maintenance free language. If you learned idiomatic go, you can maintain and patch other libraries in the ecosystem very quickly. Unified codestyle, unified paradigms, unified toolchain. It's a language with harsh opinions on everything. If you manage to get over your own opinions, you'll realize that any opinion upstream is better than no opinion downstream. That's why go's toolchain isn't as messed up as npm, yarn, grunt, gulp, webpack, parcel, babel and other parts of the ecosystem that have no conventions and are therefore as a result very expensive to maintain. reply tentacleuno 11 minutes agorootparent> The reluctancy to introduce new syntax too quickly (looking at you, TC39 and Babel) makes go an almost maintenance free language. Could you provide some examples of this? From knowledge of the pipeline operator proposal[0], moving fast and breaking things isn't always a priority. It goes without saying that Babel is an external collection of modules that don't fall under the TC39 umbrella, so they're able to iterate at a much greater cadence than the official specification (and you obviously need to explicitly opt-into using it.) [0]: https://github.com/tc39/proposal-pipeline-operator/commit/da... (first commit; Nov 9, 2015, which is 8 years, 8 months, 24 days ago) reply serial_dev 12 hours agorootparentprevThis! In Go, a feature needs to have an extremely good reason to be added, and even then it's only added with care and caution. In other languages, pointless features are added because maintainers are afraid, or not empowered to say... \"yeah, we get it, but no, we will not add cruft to the language because you can't write your own 2 line function to achieve the same, no matter how hard you dunk on us on Twitter, it's take it or leave it, but you won't tell us how to run this project\" reply pansa2 10 hours agorootparent> pointless features are added because maintainers are afraid I wouldn't have described language designers' feelings that way, but you're absolutely right. For example, witness the recent features added to Python with little more justification than \"other languages have it\". It's pure FOMO - fear of missing out. reply vbsd 7 hours agorootparentWould you expand on the Python issue? I find recent Python additions either useful or non-intrusive, I wonder which ones you think are born out of FOMO. reply Cthulhu_ 10 hours agorootparentprev\"Other languages have it\" is a disease that's struck many languages in the past decade+, notably Javascript which added partial OOP support (classes but initially no access modifiers), or Java which added functional programming constructs via Streams. I mean granted, Java needed some tweaks for developer ergonomics, and I'm glad they finally introduced value types for example, but I now find that adding entire paradigms to a language is a bad idea. In the case of Go, yes it needed generics, but in practice people don't use generics that often, so thankfully it won't affect most people's codebases that much. But there's people advocating for adding more functional programming paradigms and syntax like a function shorthand, which is really frowned upon by others, because new syntax and paradigms adding to the things you need to know and understand when reading Go. Plus at the moment / the way the language is designed, FP constructs do not have mechanical sympathy and are far slower than their iterative counterparts. reply klabb3 8 hours agorootparentprevYes about the language but also Google understands that both tooling and standard library is more important than the language. All of that makes Google internal maintenance much much better. Another artifact of google3 was the absolute shitshow of GOPATH and abysmal dependency management – because Google didn’t really need it, while people outside suffered. When they added go mod support Go became 10x more productive outside of Google. Go is almost an anti-language in that sense, reluctantly accepting shiny lang features only after they’ve been proven to address major pain points. It’s almost more an “infrastructure deployment toolkit” than a language. Which strangely makes it extremely pleasurable to work with, at least for network-centric applications. reply daghamm 4 hours agorootparentprev\"That's why go's toolchain isn't as messed up as npm, yarn, grunt, ...\" And let's be honest, Rust toolchain is pretty messed up too. Want to cross-compile with go? Set the GOOS variable and you are done. On Rust you need to curl-sh rustup, switch to nightly, add new targets, add target to your cargo and cross fingers it works this week. reply quectophoton 3 hours agorootparentTo be fair, with Go it's still painful to work with private repositories. And I'm invoking Cunningham's Law here when I say there's no convenient way to do so. If you want to use a private repository (let's say it's a private GitHub repository), then you either have to do it the bad way (setting up your own GOPROXY and setting it up securely, which implies also ensuring it's not leaking your source code elsewhere for \"analytics purposes\"), or the worse way (doing brittle text replacement using weird git config stuff). Or the annoying way of using a vanity import, and host that package in your domain with HTTPS using a wildcard certificate. But that would require either (1) only allowing access through WireGuard and hoping whatever reverse proxy you use has a plugin for your DNS registry; or (2) letting your VPS provider terminate DNS (e.g. Hetzner load balancer), but filter by IP address in your VPS firewall settings ensuring your public address (IPV4 /32 or IPV6 /64) is always up-to-date in the firewall. Or using `replace` in `go.mod`, but these don't work transitively so these only work on \"root\" projects (i.e. they are ignored in dependencies), so I don't think this really counts as a solution. I would have liked some way to force SSH access for a specific package, instead of HTTPS. Like for example `go.mod` supporting a `require-private` to use instead of `require` (or whatever similarly convenient directive for `go.mod` that implies authenticated SSH access is required). Or in other words, say I have a package `github.com/_company/project`, and it depends on `github.com/_company/dependency`. I want to be able to do: git clone 'git@github.com:_company/project.git' 'project' cd 'project' go mod tidy # Should just work. `go mod tidy` should just work without complaining about `github.com/_company/dependency` not existing (because it's a private repository only accessible through SSH). (EDIT: Still, I'm agreeing with the point that Go's tooling is better than most other things I've tried. My only complains are this one about being inconvenient to use private repositories, and also that by default it leaks package names to Google whenever you do `go mod tidy`.) reply hop_n_bop 2 hours agorootparent1) git config --global url.ssh://git@github.com/.insteadOf https://github.com/ 2) export GOPRIVATE='github.com/_company/*' reply quectophoton 1 hour agorootparent>> or the worse way (doing brittle text replacement using weird git config stuff). reply cookiengineer 36 minutes agorootparentprevI'm not sure I understand the problem statement. You can use e.g. this inside a go.mod file: require some/library v0.0.0 replace some/library => ./external/library ------ /external is a folder inside the project repo /external/library is a git submodule of the private repo. ------ Alternatively maybe go mod vendor can help managing the dependencies that aren't accessible via https? I am not sure what go should do if a library repo in the dependencies tree isn't accessible, because that's the job of git, not go modules? reply _the_inflator 10 hours agorootparentprevClutter death that creeps in any language, as I see it. To this day, only a small subset of JS syntax is used; I cannot recall anyone besides me ever using method chaining like .map .filter, etc. There is a reason why almost every good language is somewhat akin to C to this day, and maybe people started over to get rid of the noise. reply matwood 6 hours agorootparent> I cannot recall anyone besides me ever using method chaining like .map .filter, etc. Interesting. That's all anyone on my team ever used once it became available. But, it highlights the point with Go. Working with Go for just a little while means I can easily read and work with nearly any Go project with a very short ramp up. reply jessekv 6 hours agorootparentprevHaha interesting. I actually like .map/.filter/.find/etc. in JS and comprehensions in Python. I find they communicate the intent of the programmer really clearly as compared to a for-loop. reply KronisLV 12 hours agorootparentprevWith it being so consistent and predictable, I wonder why it hasn’t displaced .NET and Java in the enterprise for back end development. Maybe because a framework like ASP.NET or Spring that covers like 80+% of the enterprise needs hasn’t quite emerged? Or perhaps we just need to give it a decade or so. There are still very few Go jobs in my country, most are either .NET, Java or PHP. reply trustno2 11 hours agorootparentGo doesn't really lend itself that much into code with a lot of abstraction layers. If you try to do that, you will start to run against the language. The more enterprisey software usually have lots of layers for organizational reasons, and go doesn't really fit there. So I don't think it will really be a hit in the enterprise. yes there are orm solutions and DI frameworks and all that, but they always feel like they don't belong in the language. (Also, java and .net and php are much older and have much bigger enterprisey ecosystem.) I have seen go replacing the php stack though, and in some way the \"original\" python stack - but python now has ML. reply jen20 6 hours agorootparent> usually have lots of layers for organizational reasons The ridiculous number of layers in Java or C# are more of a skill and guidance issue than anything else. Older languages don’t always mean over-attempted-abstraction (think C, for example). reply trustno2 5 hours agorootparentI have worked in enterprises and the layers are usually an organizational issue that just acts as code issue. Structure of code often reflects structure of your company. The code is often maze of layers because the company is a maze of sub-committees. Java/C# fits more neatly in there. Although with Go, what can happen is that there is a maze of microservices. Maybe that's not that much better. reply pjmlp 5 hours agorootparentprevNever seen CORBA and COM written in C, I guess. Enterprise Architects will do their beloved architectures with whatever languages are the tool of the day. reply cookiengineer 11 hours agorootparentprev> ASP.NET or Spring (Disclaimer: I don't agree with HTMX rendering HTML chunks on the backend side, and I think that APIs should be HTTP-cacheable and use REST/JSON) Currently I am trying to get better at using Go with WebAssembly for the frontend. I love to use the webview/webview bindings to build local GUIs, but the need for redundant code in JavaScript for client data transfers and input data validation are annoying me a bit much. I am trying to find out a paradigm that could benefit from the strength of JSON marshalling, with the idea that you can map routes to structs, for example, and where a unified \"Validate() (bool, error)\" method as an interface is enough to use the same structs on both the frontend and backend, for both serialization and validation/sanitization. Having said that, I think that what's missing the most in go right now is a good UI framework for the web, but it's hard to find a paradigm that fits nicely into the language while also being able to handle dynamic data/refreshes/render loops without getting too bloated too quickly. reply wordofx 11 hours agorootparent> and I think that APIs should be HTTP-cacheable Rendering html on the server does not make it not cacheable. The vast majority of people do not need graphql or shift their compute to the client with a junk react app with adhoc json endpoints everywhere. reply KronisLV 10 hours agorootparentI think server side rendering can often be pretty comfortable to use! That said, I’ve also worked with JSF and PrimeFaces project and the ones I’ve seen have been more burdensome from a maintenance perspective and also more buggy than most SPAs that I’ve worked with. I’ve also seen large monoliths where the tight coupling slows updates down a whole bunch, as opposed to the presentation being in a SPA that’s separate from an API that can be more limited in its scope (nothing wrong with using ASP.NET and Spring for just an API). Heck, I’ve migrated a SPA from the now defunct AngularJS to Vue and it felt better than having a legacy project that’s stuck on an old version of Spring and PrimeFaces because there’s so many moving parts that when you try to update anything, everything breaks. Plus, turning a SPA into a PWA is a fairly pleasant experience. I don’t think most folks need GraphQL though, especially when we can barely do RESTful API correctly and not even all places use OpenAPI specs and tooling, making client code impossible to generate (even SOAP did a better job in that particular regard with how widespread WSDL was). reply Philip-J-Fry 11 hours agorootparentprevGo is displacing .NET where I work for backend development. We still use .NET for Windows GUIs but any sort of server code is mostly Go going forward. reply Cthulhu_ 9 hours agorootparentprevIt's not yet an enterprise language; along the languages/frameworks, there's a huge ecosystem of QA, monitoring, security, etc solutions in the Java/.NET space that just isn't there in Go. I mean there's a slow shift, I keep hearing of \"rewriting a Java codebase to Go\", but it'll be a slow process. And especially the bigger projects that represent 30 years of Java development will and should be reluctant to start rewriting things. reply pjmlp 5 hours agorootparentprevThankfully, it is enough that it is a must in DevOps space. reply lifty 8 hours agorootparentprevIn my enterprise neck of the woods Go is steadily taking over backend development. reply classified 6 hours agorootparentprevWell, if you compare against the absolute bottom of the barrel, it's not too hard to look good. reply lopkeny12ko 10 hours agorootparentprev> Unified codestyle The moment I got my first compile error due to an unused variable and an unused import, made me realize Go is not a serious programming language. reply Cthulhu_ 9 hours agorootparentI wonder who hurt them, that is, how much did unused variables/imports hurt at Google for them to make those a compiler error? Insofar I know it, I can imagine C/C++ caused some issues like that because it's hard to figure out whether an import is used, but an unused import does have a cost. reply rsc 1 hour agorootparenthttps://research.swtch.com/deps#watch_your_dependencies > Creeping dependencies can also affect the size of your project. During the development of Google’s Sawzall—a JIT’ed logs processing language—the authors discovered at various times that the main interpreter binary contained not just Sawzall’s JIT but also (unused) PostScript, Python, and JavaScript interpreters. Each time, the culprit turned out to be unused dependencies declared by some library Sawzall did depend on, combined with the fact that Google’s build system eliminated any manual effort needed to start using a new dependency.. This kind of error is the reason that the Go language makes importing an unused package a compile-time error. reply foldr 6 hours agorootparentprevI think the fundamental reason behind this behavior is just Go's rejection of the concept of compiler warnings. Unused variables must either be A-ok or trigger an error. They chose the second option for unused variables. Some other code smells are considered A-ok by the compiler and need to be caught by linters. reply jen20 6 hours agorootparentThe problem with such rejection is that every serious project written in Go has invented compiler warnings outside the compiler, with linters. reply kjksf 4 hours agorootparentWhy is it a problem? `go vet` is part of Go toolchain so the designers very much understand and acknowledge that code can have issues that are not always errors. The distinction they made is very simple: an error is something that is always wrong and a vet warnings is something that is possibly wrong but not always. They made a judgement call to split the responsibility: compiler only reports errors, other tools, including `go vet`, can tell you about other issues. For example: passing a large struct by value to a function is potentially a performance problem but it's also correct code. If you ever tried to compile C++ code with different compilers you would know why it's a wise decision. The set of warnings is vast and not standardized so you take C++ source from project. It compiles for them but doesn't compile for you because you use different compiler or enabled different set of warnings. At which point you either try to get the other project to \"fix\" something that isn't an issue for them or you do stupid, pointless, time consuming work adjusting your build system. The same would happen in Go and it would be a reusability killer. You use some library in your program but it doesn't compile because you decided to use more strict set of flags. Lack of warnings switches also simplifies the toolchain. In go it's just `go build` and it works. In C++ you have to write some kind of makefile because everyone executes `cc` with different set of flags. reply foldr 5 hours agorootparentprevIs this a problem? Linters are also used with lots of languages that do have compiler warnings. Go just removes the no man’s land between honest-to-goodness compiler errors and linter warnings about code smells. I see no issue with having the latter handled entirely by tools designed for the job. reply lioeters 7 hours agorootparentprevThe moment you see that you had misspelled a variable name by a single character when the compiler warned you about an unused variable, you'll realize Go is a serious programming language. reply biomcgary 16 minutes agorootparentThis has saved me minutes of confusion so many times. reply tommica 10 hours agorootparentprevWhy not? Pretty sure it's used in a lot of places, so it does seem quite serious if a language. reply tomcam 13 hours agorootparentprevYour question answers itself. It's growing in popularity in every year and has apparently suffered exactly zero scandals or embarrassing gaffes of any kind. Just not fucking up is huge in making any serious enterprise successful and very, very difficult to achieve. reply treyd 13 hours agorootparentJust from the top of my head there's the Google proxy shenanigans and the telemetry proposal that they backed down from. There may be others I'm not aware of. reply kjksf 3 hours agorootparentExplain how Google proxy \"shenanigans\" are any different than \"npm proxy shenanigans\" or \"cargo shenanigans\" or \"pip shenanigans\". It's a service to improve Go ecosystem with anti-spoof security design (which can't be said about those other code download services). telemetry design is actually very thoughtful, limited and reasonable about what and how much data it sends. Motivation for sending the data is clear (improving Go). It's only a scandal for unreasonable people. reply ein0p 21 hours agorootparentprevAlmost zero drama and almost no feature creep or breaking changes. The team seems to have a focus, and does not change it easily. That is important for a programming language, and it doesn’t happen organically. reply truncate 16 hours agorootparentCouldn't agree more. Always felt community had trust in the team. Its not the fanciest language, but whatever they push for usually works. In contrast, recently I've had to deal with Swift, and they are often pushing like 10 features, but each of them is full of holes and annoyances. Great respect for doing the boring of keeping it stupid and simple. reply gunapologist99 19 hours agorootparentprevExactly. And it's in writing! The backwards compatibility promise: https://go.dev/doc/go1compat reply richardwhiuk 21 hours agorootparentprevI suspect all the drama happens internally. reply zja 16 hours agorootparentAre there any Go team members that don’t work for Google? It’s a lot easier to remain civil/avoid drama when people know each other personally, and work together at a big company with an HR department. reply markkrj 16 hours agorootparentDoes ex-googler counts? Then Filippo Valsorda... reply tomcam 13 hours agorootparentprevOne reason I consider it so good reply moogly 6 hours agorootparentprev> almost zero drama Hm. Wasn't (the lack of) generics pretty drama filled? Especially the way they fought against it for so long. reply quectophoton 3 hours agorootparents/fought against it/rejected superficial proposals that were mostly about syntax bikeshedding and didn't include enough research on how the proposal would play along with the rest of the language and ecosystem/ reply Onavo 17 hours agorootparentprevThey are the programming language equivalent of GitHub repos that maintain a low open issue count by closing most issues as \"won't fix\" or \"won't build\". reply segfaltnh 15 hours agorootparentYep. It takes a lot of bravery and I appreciate it! reply lolinder 17 hours agorootparentprevYes. And? Programming languages more than almost any other type of project end up swamped with thousands of competing requests to implement mutually incompatible features. Some languages do better than others at saying no, and those languages tend to be the ones that achieve widespread adoption. reply pansa2 14 hours agorootparent> Some languages do better than others at saying no, and those languages tend to be the ones that achieve widespread adoption. Unfortunately that’s not at all true - Go is a real outlier here. If it were true, we’d all be writing C instead of C++, Lua instead of Python and ES5 instead of TypeScript. reply flohofwoe 12 hours agorootparentFWIW I switched from C++ to C about 7 years ago and never looked back (can't quite escape C++ completely though because some important libraries are still written in C++ unfortunately). I vastly prefer TS to JS, Python and Lua though. reply pansa2 10 hours agorootparent> I switched from C++ to C about 7 years ago and never looked back I'm definitely considering the same, and you're right - it's not C++ itself that appeals to me at all, it's the libraries. I'm not sure what C libraries I'd use for collections (instead of the STL and Abseil [0]), or in lieu of CLI11 [1] or Dear ImGui [2]. [0] https://abseil.io/about/design/swisstables [1] https://github.com/CLIUtils/CLI11 [2] https://github.com/ocornut/imgui reply hsaliak 5 hours agorootparentDearImgui’s coding style is a good compromise. reply cookiengineer 12 hours agorootparentprevThe choice is yours. Don't blame your choices on other people's opinion that you don't agree with. Everything in life is a tradeoff. If you don't agree with the available languages, make it better. That's the power of open source :) reply randomdata 11 hours agorootparent> The choice is yours [pansa2]. Who gave him control over what sees widespread adoption? reply ein0p 16 hours agorootparentprevGood reply ahci8e 19 hours agorootparentprevAlmost zero drama, yeah. I do remember the dep drama though... reply justinclift 17 hours agorootparentAnd the telemetry drama. reply vdqtp3 19 hours agorootparentprevThe cost being that they [generally speaking] ignore proposals, pull requests, and new features - even if they are valuable to their users and AREN'T breaking. reply segfaltnh 15 hours agorootparentMostly this comes down to recognizing the value of simplicity. I like Rust and Go, but I am infinitely grateful that Go is as minimal as it is. I wouldn't have had as much success ramping my team on Rust. reply sidewndr46 19 hours agorootparentprevAbsolutely inaccurate. Pointer de-reference operator had a breaking change after 1.x reply arp242 19 hours agorootparentI don't recall this off-hand; which change was that? reply tweenagedream 17 hours agorootparentprevI mean they did say almost no breaking changes, depending how much has changed in the language, a small handful of breaking changes in niche use cases may be considered almost none by some. I'm not sure I would say the comment is absolutely inaccurate. reply dom96 21 hours agorootparentprevZero drama is easy when you get paid (a lot) to work on something. reply muratsu 21 hours agorootparentHuhhh? Have you ever worked at a large enough company where stakeholder interests are not aligned? reply IshKebab 21 hours agorootparentThat's private drama. For all we know there has been loads, but it's private so you can't see it. reply ncruces 19 hours agorootparentWhere would you expect to see this drama unfold if it were private? Nowhere? That'd be incredible opsec. Code review happens in public, not on GitHub but on Gerrit. The main issue tracker is public, on GitHub. Proposals are largely handled on the issue tracker. There are public mailing lists, etc. Surely, there are face to face private meetings. And there are likely also private issue trackers, mailing lists, and etc. And, yes, sometimes, a seemingly arbitrary decision pops up, that was clearly discussed elsewhere. But these comments seem to come from people who never even tried to contribute, or deal with the process. I've done docs fixes as a total newb, had to convince the Windows maintainer to let me fix a Windows issue (that a year later produced flaky tests, which I fixed), made and got a proposal accepted, have a project in the linkname hall-of-shame, which led to another successful proposal to open up APIs (which then failed tests on some platforms, which I fixed). All with little drama, pure engineering. reply Maxatar 21 hours agorootparentprevGetting paid has nothing to do with drama. Plenty of high paid people get involved in drama and infighting across all walks of life including tech. reply segfaltnh 15 hours agorootparentPretty sure Musk gets a decent paycheck, and manages to be involved in plenty of drama. reply goalonetwo 21 hours agorootparentprevI would rather say that it is easy to have zero drama when most of the committers come from a single large companies. reply sangnoir 21 hours agorootparentprevAnd yet we've had lots of drama in Linux and Redhat mailing lists, involving people paid to work on the respective projects, and using their work email. reply ein0p 21 hours agorootparentprevThat’s unfair. There’s plenty of drama in projects with all sorts of funding situations. Look at eg Rust. Lots of drama and it’s anyone’s guess if the code you wrote a year ago would work today. reply lkirkwood 21 hours agorootparent> It's anyone's guess if the code you wrote a year ago would work today Is that true? In what sense? I was under the impression the editions took care of that. reply seeekr 21 hours agorootparentNot true, not sure why GP said that. Been writing Rust for many years and code does not just break on compiler upgrades. Super stable overall, including the wonderfully evolving ecosystem! reply nottorp 5 hours agoparentprevI did mean to ask: who \"owns\" Go for all practical purposes? I suppose in theory it's some independent entity/commitee/whatever, but who pays the majority of the people working on it? Google? reply diggan 3 hours agorootparent> but who pays the majority of the people working on it? Google? Checking the 20 top contributors from https://github.com/golang/go/graphs/contributors Google: 10 Unclear: 7 Tailscale: 1 Canopy Climate: 1 Isovalent: 1 Just checking the GitHub profile and not doing any deeper digging, so take it with a grain of salt. reply dzonga 19 hours agoparentprevI think this is a side effect of golang having failed at the mission to replace C++ or even Java, becoming a replacement for ruby / python etc for API's. makes the project's goals align with users not about conquering the world anymore. as that battle is lost to Rust, Zig etc. reply dgb23 1 hour agorootparentGo is definitely used for stuff that rivals their Rust/C++ etc. counterparts in terms of performance and general quality. Caddy and docker pop right into my mind. I‘ve also seen databases, image processing and other nitty gritty systems programming related projects in Go. People also love to write CLI apps in Go that do a lot of heavy lifting like esbuild or k6 etc. The sweet spot for Go seems to be IO heavy programs. It allows for just enough control to get good performance for a lot of use cases that bleed into systems programming. reply bborud 9 hours agorootparentprevI thought the mission was to replace C++ for a many things at Google. You can't really lose to someone you are not competing with. The choice of managed memory is a pretty obvious hint that Go isn't a general direct competitor to C/C++. And neither Zig nor Rust have replaced C++ to any meaningful degree. Nearly everywhere it would count I still will have to deal with C++ for years, if not decades, to come. reply jgowdy 14 hours agoparentprevYeah, only supporting glibc behaviors and ignoring the ELF standard at will really qualifies as best managed. /s reply rsc 1 hour agorootparentI replied to the other copy of this comment: https://news.ycombinator.com/item?id=41136122. reply TheDong 14 hours agoparentprevnext [6 more] [flagged] hdesh 14 hours agorootparent> Basically, the Go team is a bunch of old white dudes, which already means the project is poorly managed from the start This seems like a broad generalization. Can you please elaborate? reply TheDong 13 hours agorootparentnext [5 more] [flagged] dash2 13 hours agorootparentThat argument completely makes sense (I don’t know if it’s true, because I know absolutely zero about the go community, but it’s a sensible argument). It’s a pity that to make it, you initially used the shorthand of “old white dudes“ - a derogation based on people’s race, sex and age. reply hellojesus 12 hours agorootparentprev> Special attention like having diverse people in positions of power. You realize that selecting people based on \"diverse\" qualities is the very act of racism/sexism/whatever-ism, right? You propagate what you claim to oppose. reply mseepgood 13 hours agorootparentprevWhat? The only Plan 9 people that were on the Go team I know of are Thompson, Pike and Russ. I'm pretty sure that neither Thompson nor Pike know what 4chan is. Russ, being the younger one, probably has heard of it, but I doubt that he ever used it. I've never heard them make sexist jokes. On the contrary, I have heard Pike and rsc speak out for diversity in software engineering and social justice quite often. reply sneak 12 hours agorootparentprevIndividual people cannot be diverse. reply alphazard 20 hours agoprev> I don’t believe that the “BDFL” (benevolent dictator for life) model is healthy for a person or a project It's interesting that the best projects have BDFLs, and that the best BDFLs are skeptical of their own power. reply knighthack 14 hours agoparentI've noticed: competent people who aren't interested in leadership tend to make the best leaders. As compared to people who want to be leaders, for the sake of being known as a 'leader', but have neither the competency nor accountability to be leaders. reply singron 4 hours agorootparentAs long as they aren't so disinterested that they become absentee leaders. It's rare for huge successful projects you've heard of, but I think the typical project is more likely to have this problem, although maybe it's just incompetence too. reply saghm 17 hours agoparentprevWithout taking a stand on the first half of that, I don't think it's particularly surprising that the best BDFLs are skeptical of their power. I'd argue the main benefit of having a single person with the power to make a unilateral decision is that it provides a way around the gridlock that tends to occur whenever there are a wide variety of stakeholders involved;. a project whose leader feels warranted to overrule decisions that have a strong consensus is a lot less likely to build up a community to the point that anyone is aware of the project. reply darby_nine 19 hours agoparentprevI don't think this is true. Python had a BDFL and it didn't seem to benefit much from it. I'm not sure what other projects this attitude draws from. Off-hand I'd guess it causes less drama but no appreciable increase of quality, just like other forms of bureaucracy. Meanwhile there's entire landfills of failed projects with single owners who couldn't bend enough. We just don't find this worth discussing. Of course this won't happen, but a man can dream. reply vbezhenar 14 hours agorootparentPython became #1 language in the world. Which factors lead to this success is debatable, but leadership role can't be dismissed. reply SatvikBeri 15 hours agorootparentprevHere are some other projects that benefited from BDFLs in my opinion: * Keras * Ruby * Clojure * Zig * OCaml * Vim * Elixir I think all of these have ended up being unusually coherent. I may not agree with their design philosophy, but there clearly is one. reply dgb23 1 hour agorootparentA perhaps important clarification: Many of those, including Linux as far as I know, simply started as projects that were driven by single authors with a strong vision and remarkable diligence. Then people flocked to those projects, but with the understanding and appreciation of that vision. I don’t think any of them wanted to be BDFLs for the sake of power. They were the original authors and _made_ something useful. I don’t think any of them took over an existing project and declared themselves dictators. Ironically they all would be way too opinionated to do so. reply dash2 13 hours agorootparentprevConversely, projects without clear leadership include rust (recently) and R, and I think they suffer for it. A very widespread system for organising people is to have a single responsible decision-maker, supported, monitored and advised by a committee. We see that through politics and business, and a lot of the best open source projects seem to do the same thing. reply gpderetta 10 hours agorootparentIMO C++ would have benefitted from having a BDFL for a bit longer as well. reply kovac 9 hours agorootparentprevLinux, OpenBSD? Perhaps to an extent Mutt too. reply giraffe_lady 5 hours agorootparentprevBut php, one of the most notoriously chaotic mainstream languages, has a bdfl. And lua, arguably more disciplined than all of the ones you listed, has not. reply chuckadams 3 hours agorootparentPHP is governed by an RFC process requiring a 2/3 majority vote of a couple dozen core devs. This has been the case for nearly 20 years now. Rasmus rarely even votes these days. reply hermanradtke 4 hours agorootparentprevRasmus is not the BFDL for PHP. reply anamexis 19 hours agorootparentprevLinux/Linus Torvalds stands out as another notable BDFL. reply gunapologist99 19 hours agorootparentAnd Daniel Robbins at Gentoo, who recently (and sadly) stepped down from Funtoo as well. reply darby_nine 18 hours agorootparentprevI'm not intimate with Linux as a project, but this is an attractive argument for it. Unfortunately my main experiences with Torvalds are motivated by his chewing out people on mailing lists for something stupid they said rather than fending off varied interests, which makes him look far more petty than competent. reply arp242 17 hours agorootparentOnly those instances make the news. And then get repeated time and time again. It's a super-biased view not at all representative of his day-to-day behaviour. Also I've never seen Torvalds \"chewing out people on mailing lists for something stupid they said\", it's always been someone breaking something or something along those lines. That is: doing stupid. And it's also experienced maintainers Torvalds feels should have know better. You can like or dislike Torvalds' style, but this little student from Finland created the world's most successful open source project, so I think he's probably doing one or two things right. He may not be perfect, but being hung up over a few incidents over a 30-year time period is perhaps not too brilliant, and insinuating incompetence over this is quite the take. Imagine every outburst you have is public and pointed to for years to come. reply rectang 15 hours agorootparentTorvalds also listened, learned and improved. If we want people to respond to constructive criticism constructively, it's uncharitable and counterproductive to pigeonhole them as they were at a point in time. reply Capricorn2481 4 hours agorootparentprev> it's always been someone breaking something or something along those lines Not only is this a complete lie, but God forbid there's a process in place to catch these things instead of verbally abusing your coworkers for making mistakes, which Linus has done himself. > Imagine every outburst you have is public and pointed to for years to come You may be surprised to learn that the rest of us don't talk to anyone like this. > but being hung up over a few incidents over a 30-year time period That's a great way to make it sound old but he actually gets angrier as time goes on. https://lkml.iu.edu/hypermail/linux/kernel/1510.3/02866.html reply lakdna 4 hours agorootparent> You may be surprised to learn that the rest of us don't talk to anyone like this. The moral superiority is misplaced: https://news.ycombinator.com/item?id=41017195 But I am not surprised. CoC proponents universally do the same as the people they criticize. Only the application of rules is selective. reply arp242 3 hours agorootparentprev> You may be surprised to learn that the rest of us don't talk to anyone like this. You do. By outright claiming that I'm lying when I share what I've seen. Of course with no substance to back it up. Let me tell you: I've seen what I've seen. Have I seen an incomplete picture? Almost certainly. Am I wrong? Perhaps. Am I lying? No. Your post is extremely aggressive, pretty darn toxic, and explicitly the sort of stuff that's not appropriate here. Do better next time. Doubly so if you want to get all high and mighty. reply kfgahs 9 hours agorootparentprevLinux started on Usenet, and that was the normal communication style. People simply did not take it seriously back then, it was understood to be partly humorous. Linus doesn't even rant frequently either. People point to the same 10 messages over and over again. He also tolerates when someone snaps back at him, unlike in projects with double standards like CPython where the old boys can do whatever they like but you are not allowed to criticize back or point out their numerous mistakes, segfaults, threading bugs and generally low code quality. reply groby_b 20 hours agoparentprevThe only people worth having in power are the ones that don't want the power. This extends well beyond OSS projects. reply riwsky 3 hours agoparentprevRemember when they tried to king George Washington? reply carapace 18 hours agoparentprevThe whole idea is a joke, it's right there in the name. It was a recognition of the \"facts on the ground\" of GvR's role as the creator of Python, it was never seriously meant as a principle of project management. It's descriptive not prescriptive, eh? The idea got reified all out of hand. reply rsc 1 hour agorootparentThe wording may be a joke but the concept is real and widely used. reply dondraper36 22 hours agoprevrsc, thank you very much for all the hard work on the language that brought me into software engineering. Despite playing around with several programming languages, Go still feels like home. The development experience is terrific and I really appreciate how unapologetically simple and responsible the language and its creators have been. Good luck and all the best in all your endeavours! reply rsc 21 hours agoparent> rsc, thank you very much for all the hard work on the language that brought me into software engineering. You're quite welcome, and thank you for this comment. I never expected when we started that Go would have such a positive impact on people's lives, bringing new people into programming and software engineering. That's definitely the impact I'm most proud of. reply xh-dude 1 hour agorootparentThanks for helping the OEIS site stay alive. I was absolutely delighted by it the first time I visited it, decades ago. Equally delighted when I visited recently and saw some “Russ Cox” contributed. reply geoka9 21 hours agorootparentprevThank you guys from another fan! Go literally saved my career as a software dev: got burned out around 2014, tried Go as therapy and have been a happy gopher ever since :) reply apitman 13 hours agorootparentprevI've been programming for 20 years and Go has proven to have more gravity than any other language I've used. When I just need to get something done, it's what I reach for. Thank you for your part in building such a useful tool. reply captainkrtek 15 hours agorootparentprevSame sentiment as the above poster. I’ve been working with Go since 2014, after using many languages before, and none match the ease and efficiency of development for my work. Thank you so much! reply slekker 11 hours agorootparentprevThank you very much rsc! Golang not only helps me feed my family but also I created many friendships from using it :) reply Thaxll 22 hours agoprevRSC has a really good blog: https://research.swtch.com/ reply furyofantares 19 hours agoparentThis is the first time I'm noticing that rsc would be an initialism for the blog. reply rsc 1 hour agorootparentMe too! reply jjice 21 hours agoparentprevIncredible blog. I've said it on this site before, but his series on regular expressions is insanely high quality and the fact he just posted it there for all of us is a huge privilege. reply mikhailfranco 5 hours agorootparentYes, I certainly benefitted very much from the series. Here is the first episode - devastating, convincing, easy to understand and very well written: https://swtch.com/~rsc/regexp/regexp1.html reply rtpg 15 hours agoprevgofmt probably has alone saved so much time across the world (and is upstream from every other language ecosystem basically saying \"ok let's just autoformat\"). I hate what autoformatters do to my code, but I love not having to talk about spacing anymore. reply rob74 11 hours agoparentInterestingly enough, I hate autoformatters (and use spaces instead of tabs) in every other language, but in Go you just get used to the way gofmt formats your code from the beginning, and then start to appreciate that you don't spend as much time on it anymore, so it's not a problem (at least for most people). reply arp242 6 hours agorootparentI've seen a number of autoformats for other languages be way too obsessive about formatting every little detail and edge case, to the point where it just becomes silly. 100% consistency is a fool's errand, and also contributes very very little Once you deal with some major issues (braces, spacing) you very quickly get diminishing returns. reply j2kun 17 hours agoprevTIL about the project he's going to focus on: https://go.googlesource.com/oscar/+/refs/heads/master/README... An LLM-based architecture for helping maintain OSS projects. Seems cool. reply zmj 20 hours agoprevThanks Russ! Putting tooling on a first-class basis was revolutionary, and it's still Go's standout feature. reply simonz05 22 hours agoprevhttps://www.youtube.com/watch?v=wwoWei-GAPo — Project has come a long way since this. Happy that it's still around and thriving. I don't think we expected that in 2009. I don't believe Go would have been where it is without Russ. His contribution to the project has been tremendous. Thanks Russ. reply nasretdinov 21 hours agoprevRuss gave us proper vendoring and generics: two things I thought I'd never see in Go... Thanks a lot for the effort! reply bruckie 19 hours agoparentIan Lance Taylor did a lot of the work on generics, too. Thanks to both, and the rest of the team! reply valyala 9 hours agoparentprevWhile vendoring is great, generics is bad addition to Go, since they complicated Go type system too much [1]. This makes typical Go code with generics hard to read and hard to maintain. [1] https://go.dev/blog/type-inference reply klartd 19 hours agoprevThanks for all the Go contributions! I disagree on one point that has nothing to do with Go. Python has not benefitted from GvR stepping down. The new \"leadership\" is non-technical, tyrannical and has driven almost all true open source contributors away. Development has stalled except for the few corporate contributions of doubtful quality. The atmosphere is repressive and all that matters is whether you have a position of power at Microsoft/Instagram/Bloomberg. It is not necessarily the fault of these companies. They may not know that their generosity is being abused. reply the_duke 12 hours agoparent> Development has stalled except for the few corporate contributions of doubtful quality. Do you have some data to back that up? The stats on Github seem to show healthy activity. 700+ merged PRs from 120+ contributors in the last month [1]. There seems to have been a big influx of new contributors in the last few years. [2] [1] https://github.com/python/cpython/pulse/monthly [2] https://github.com/python/cpython/graphs/contributors reply purpleidea 22 hours agoprevHuge news! I hope the new leadership remembers that keeping golang small and simple was its greatest strength. Adding generics was too much, and while I think there are some important small cases when it's valuable, in practice people are using it when they shouldn't. I'd also like to see less google control of the project. I'm certainly thankful for golang as it made my https://github.com/purpleidea/mgmt/ project possible! Thanks Russ! reply p1necone 16 hours agoparent> Adding generics was too much, and while I think there are some important small cases when it's valuable, in practice people are using it when they shouldn't. Strongly disagree. Beyond very simple codebases lack of generics means either duplicating a bunch of code or eschewing type safety - neither of those things are particularly attractive to me. I can't imagine writing code in a strongly typed language that doesn't have support for generics. Even if you don't use them directly it's almost certain you're using libraries that would be forced to be less ergonomic or type safe because of a lack of generics. reply akira2501 14 hours agorootparent> or eschewing type safety Type casts are checked. > that doesn't have support for generics. We get first class functions and compiled closures with zero syntax overhead. It's entirely manageable. > or type safe because of a lack of generics. Case in point: sort.Slice(). It lacks ergonomics, otherwise, entirely usable. That being said, the generic version is faster and easier to use, so they are not without purpose, but they're not fundamental to large scale design either. Used without caution they can become a burden in and of themselves. I like them just fine, but I could completely live without them. reply zarzavat 13 hours agorootparentBTW this kind of thing is why I don’t use Go. Generics are a basic language feature for a statically typed language. Go needs a lot more features to be usable, like better error handling, but the ultra-conservative community that opposes any changes is a drag on the language and makes developing in it a miserable experience. reply akira2501 13 hours agorootparent> needs a lot more features to be usable I guess what I'm caught up on is the idea of \"usable\" is entirely subjective. To my eyes and fingers, Go has been fine without generics, and since their addition I've only used them once to clean up an odd bit of code around instantiating \"module\" like initializers. > and makes developing in it a miserable experience. Subjective or not I find this a bit harsh. I spent years in an environment where C was the only option that could be used and Go is a complete dream compared to this. You may dislike the environments, you may find fault with them, but there are many examples of both of them being used to build large and complex systems that aren't completely \"miserable\" to work on. I wonder if the split is something like \"batteries must be included.\" I don't feel this way. I'm content to mine up Zinc and Copper and forge my own batteries if needed. I'm not at all put out by this. reply lenkite 11 hours agorootparentPlease search/replace all `map[x][y]` in your Go projects with `map[sting]interface{}` in order to be honest and consistent with your opinion. And explain to all your stakeholders that you have done so because generics is bad. You have been using a generic data-structure since Go 1.0 but did not realize this. reply akira2501 10 hours agorootparent> in order to be honest and consistent with your opinion Did you mean replace `map[string]string` with `map[string]interface{}`? You should take a look at Go's runtime map code. This is not a \"generic\" data structure. It's an unsafe data structure with some thin compiler sugar on top of it which is also something worth taking a look at. For example see how it handles something like `m[\"x\"]` versus `m[12]` or a map using structs as keys. Put it in Godbolt then chase down the various runtime implementations you encounter. Unless I'm misunderstanding you, then I apologize, but what else did you mean? > explain to all your stakeholders that you have done so because generics is bad. I also write code based upon engineering principles and not on the difficulty of explaining it to my peers or customers. I'm more concerned with the results they experience when they use the software. > generic data-structure What we call \"go generics\" has nothing to do with \"typed go maps.\" To the extent that I've needed something \"generic\" up until they were formally introduced into the language careful interface design was enough to cover 90% of use cases. For the ones that weren't a map holding a function which wrapped a type-checked cast operation did the rest. So all we're left with is the ability for the current go generics to automatically populate functions into your compiled image based upon instantiated and optionally constrained type usage rather than some explicit and planned mechanism implemented through interface. reply lenkite 9 hours agorootparentApologies for the stupid typo. Anyways, I think we will need to simply agree to disagree because of this statement: > I also write code based upon engineering principles and not on the difficulty of explaining it to my peers or customers. I believe that difficulty of explaining code to \"my peers or customers\" is a basic engineering principle. Also, I consider what the compiler does behind the scenes as irrelevant as long as you have reasonable performance and usability qualities. That's one of the fundamental principles of abstraction after all. Btw, the inventor of the C programming language also said this. Dennis Ritchie -> \"Code should be written for humans first, machines second\" reply rob74 11 hours agorootparentprevInteresting that they write \"I don't use Go\" but are still convinced that \"developing in it [is] a miserable experience\". So, which one is it now? I think many people would be positively surprised if they tried Go approaching it with an open mind, but all the FUD spread on HN and similar forums prevents that... reply illusive4080 5 hours agorootparentprevThis is why I prefer Rust over Go. Go is far too simple. reply trustno2 11 hours agorootparentpreverror handling is what I like about go. ok errors.As is a little stupid, I'll give you that. But that's all. reply dblohm7 21 hours agoparentprev> Adding generics was too much I strongly disagree. Sure, like anything in programming, generics can be misused. But even comments can be misused! OTOH I am able to build things in Go with generics that I would not be very happy building without them. reply gary_0 18 hours agorootparentThe thing people dislike, I think, is that actually implementing generics and handling all the syntactical and compilation edge cases is complicated and ugly. But generics as a high-level concept are wonderfully simple and useful (\"let me use different types with certain code constructs without having to manually duplicate them, and stop me from doing anything that doesn't make sense\"). It would be a far easier call for languages to add them if they were just a bit of syntactic sugar instead of a whole new section in the manual. (I do think adding generics was a good call; practicality trumps a fussily clean design, in my book.) reply jen20 14 hours agorootparentprev> But even comments can be misused! And arguably are in Go, where they are used for all kinds of things that are not inline documentation! reply nasretdinov 21 hours agorootparentprevYeah I agree. Due to Go's slow moving approach we'll see the biggest impact of generics much later, when they become more prominent in the standard library. A lot of those APIs are necessarily not type safe now and generics would close that gap quite nicely reply simonz05 22 hours agoparentprev> I'd also like to see less google control of the project. That doesn't look like is going to happen — the leadership change announced here seems to me to continue on the Google path. Both Austin and Cherry are relatively unknown outside Google and are to my knowledge not active in the community outside Google. reply rsc 22 hours agorootparent> Both Austin and Cherry are relatively unknown outside Google and are to my knowledge not active in the community outside Google. I don't believe this is true at all. They are both highly active in external Go development, far more active than I have been these past few years. (It's true that neither gives talks or blogs as much as I do.) reply simonz05 21 hours agorootparentI understand and respect your perspective on Austin and Cherry’s involvement in the Go community. Their contributions may indeed be less visible but still impactful. However, the community’s perception of leadership is crucial, and visibility plays a big part in that. For instance your long form blog adds context to decisions you’ve taken in the past. I hope their active roles will become more apparent, fostering a stronger connection with the broader Go community. reply arp242 22 hours agoparentprev> I'd also like to see less google control of the project. What does this even mean? Google basically just finances the project, but doesn't really \"control\" anything, never mind that \"Google\" isn't a monolithic entity in the first place. reply purpleidea 21 hours agorootparentThey could be a non-google employee. They could let the community vote on who new leaders are, etc... reply arp242 21 hours agorootparent> They could let the community vote on who new leaders are, etc... Who is \"they\"? Who is \"the community\"? Who qualifies for a vote and who doesn't? I never contributed any code to the Go compiler or stdlib, but have contributed to some aspects of the \"wider ecosystem\", including some things that see fairly broad usage, and am (coincidentally) wearing a 2018 GopherCon t-shirt as I write this. Do I qualify? Does someone who has been writing Go for a year qualify? A week? Someone who never even wrote Go code? Someone who sent in a single patch to stdlib? And how do you verify all this? Saying \"let the community vote\" is easy, but if you think about it for more than a second you will realize there's tons of difficulties and that it doesn't really work. I also don't really know of any project that works like this: it's pretty always a fairly small group of \"core contributors\" that get to decide. reply tempest_ 20 hours agorootparentWhat do you mean it doesnt really work? There are a large number of programming languages and open source projects and a large number of approaches to this problem. Python, Postgres, Rust.. A small amount of core contributors doesn't mean they all have to come from a single corporate entity either. The notion that only Google could shepherd a programming language is hilarious. reply arp242 20 hours agorootparent> The notion that only Google could shepherd a programming language is hilarious. I never said anything of the sort. I said that \"let the community vote on who new leaders are\" doesn't work. Python, PostgreSQL, and Rust don't work like that either; it's just members of a fairly small \"core team\" that can vote, or some variant thereof. I have no inside knowledge here, but I'll stake a good amount of money that the Go core team had a lot of discussions about this, and de-facto, it's more or less the same as having a vote – except maybe a bit less formal. And Go would obviously be fine without Google, just as Rust was fine without Mozilla. But why bother? It's working fine as it is and Google wants to spend the money on developer salaries, so why not let them? People get far too hung up on \"Google bad\". I say this as someone who doesn't even have a Google account or Chrome installed. reply tempest_ 20 hours agorootparentI think Googles good will in recent years is the problem. I think Rust is better divorced from Mozilla, and Go would be better if it was divorced a bit from Google for a lot of the same reasons. reply arp242 19 hours agorootparent> I think Googles good will in recent years is the problem. I don't really follow what you mean with that. People keep going on that Big Tech needs to invest more in open source projects and maintainership. \"But no, not like that!\" Hmkay... In the end, the people doing the work get to decide. That's how it works everywhere. Go originated at Google and many (though far from all) of the core people working on it are still paid by Google. The people doing the work seem to have no problem with this relationship, so standing on the sidelines shouting \"no no, do the work differently!\" is not really brilliant IMO. And as I said, I don't see Google \"controlling\" anything. What does that even mean? Larry Page deciding what happens in the next Go release or something? reply bborud 9 hours agorootparentprevIt is tempting to look at the election in the US and ask what will determine the outcome - who has the policies that will make peoples lives better or who can come up with the most effecive derogatory nickname for the opponent and stoke the most fear. I've worked at Google, I've used Go for about 8 years at this point and I've met a few of the key Go figures at some point. I have to say that I have _no_ idea who would be best to run the project. And neither do you. This isn't politics where the winner gets to vanquish their enemies and make themselves and their friends and family rich. It's developing and maintaining a programming language. The only real reward you'll get is admiration IFF you do a good job. Do a crap job and you ruin the project and/or become a pariah. I would rather have those people who make up the core leadership tell me who should run the project since they not only know the technology, but they know the people and they know how to provide continuity. Continuity and discipline is all-important. I'd prefer it if whoever runs the project works for Google since that is where Go was born. In part for continuity reasons and that Google has proven to be a very good home for Go, but also because it is good to have direct access to an organization that has resources to support you. reply chmike 2 hours agoprevhumor: I wonder if the upvotes are cheerings that he finally stepped down or a respectful salute. I give my respectful salute. Go is awesome and I hope it will continue to progress in that direction. Thank you Russ Cox reply hgyjnbdet 21 hours agoprevOut of interest, why are people so confident in Google when it comes to Go, yet every other day there's articles about how Google can't be trusted in related to Dart/Flutter which are soon to be abandoned? reply arp242 21 hours agoparentI don't really know anything about Dart or Flutter, but they're entirely separate teams within a huge organisation. It's entirely possible that one team does an excellent job, whereas the other doesn't. I keep repeating this: but \"Google\" is not a monolithic entity. People aren't \"confident in Google\", they're \"confident in the people working on Go\" (or not: you can decide that for yourself). reply quectophoton 2 hours agoparentprevI don't trust Google. I trust specs[1], multiple implementations[2], and how easy it is to bootstrap a compiler[3]. [1]: https://go.dev/ref/spec [2]: https://gcc.gnu.org/onlinedocs/gccgo/ (even if feature parity isn't quite there yet) [3]: Instead of requiring double-digits compilation steps that each take too long to be reasonable. reply bufo 21 hours agoparentprevBecause Go has massive traction both inside and outside of Google, whereas Dart/Flutter never got big traction. reply surajrmal 16 hours agorootparentDart only found a real good use case fairly recently. Given its explosion in usage since then, I think it may very well be more popular that go in several years. reply smithcoin 3 hours agorootparentCurious- what is the use case? reply hgyjnbdet 1 hour agorootparentI think they mean Flutter, and Darts truly cross platform abilities. reply euroderf 9 hours agoparentprevI get an early-UNIX / Bell-Labs vibe from the entire Go project. New Jersey all the way. The ecosystem is too sleek and practical to abandon. My 0.02€, ymmv. reply tedunangst 16 hours agoparentprevAt any point in recent history, I would have been pretty happy sticking with the last release of go for quite some time. Flutter always feels like it's the next release that's going to be the good one. reply nu11ptr 21 hours agoparentprev> Google can't be trusted in related to Dart/Flutter which are soon to be abandoned source? reply hgyjnbdet 20 hours agorootparentI'm not agreeing with that assessment but recently: https://news.ycombinator.com/item?id=40997745 https://news.ycombinator.com/item?id=40184763 Among others. Again I'm not saying I agree, I'm just saying you don't see the same with Go. reply patmorgan23 20 hours agorootparentprevOff the top of your head, name 3 projects/apps that use Dart/Flutter, now do the same for go. reply LVB 16 hours agorootparentThere are probably more Flutter apps about than you’d think, and at least on Android you can look for yourself: https://x.com/kevmoo/status/1819112503722627286 reply bitpush 20 hours agorootparentprevIf you cant name 3 projects/app that use Dart/Flutter that just shows your bias. Can you name 3 apps/projects that use COBOL? -- This is akin to asking, \"Quick, name 3 books written in Persian. Huh, you cant name them? Must be a dead language\" reply randomdata 12 hours agorootparent> Can you name 3 apps/projects that use COBOL? Does this imply that you see COBOL as having a trustworthy future, making it a great choice for a new greenfield application? reply 57 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Russ Cox announced that Austin Clements will become the tech lead of the Go project starting September 1, with Cherry Mui assuming Austin's previous responsibilities.",
      "Leadership changes are intended to bring fresh perspectives, with Russ Cox remaining involved as an individual contributor and focusing on new projects like Gaby and Oscar.",
      "Community members expressed gratitude for Russ's leadership and suggested resuming compiler and runtime meeting notes and office hours for better transparency."
    ],
    "commentSummary": [
      "Russ Cox is stepping down as the Go tech lead, prompting community gratitude for his significant contributions, including the race detector, standardized error wrapping, modules, generics, and toolchain updates.",
      "Users have shared wishlists for Go's future improvements, such as sum types and better enum/range types, reflecting ongoing community engagement and interest in the language's evolution.",
      "Discussions highlight Cox's impactful work on module versioning and debates on recent changes like iterators, underscoring his influence on the Go ecosystem."
    ],
    "points": 689,
    "commentCount": 317,
    "retryCount": 0,
    "time": 1722540595
  },
  {
    "id": 41139149,
    "title": "The upstream cause of the youth mental health crisis is the loss of community",
    "originLink": "https://www.afterbabel.com/p/the-upstream-cause-of-the-youth-mental",
    "originBody": "Share this post The Upstream Cause of the Youth Mental Health Crisis is the Loss of Community www.afterbabel.com Copy link Facebook Email Note Other Discover more from After Babel Using moral psychology to explain why so much is going wrong Over 89,000 subscribers Subscribe Continue reading Sign in The Upstream Cause of the Youth Mental Health Crisis is the Loss of Community We've forgotten what community really means. Seth Kaplan Aug 02, 2024 105 Share this post The Upstream Cause of the Youth Mental Health Crisis is the Loss of Community www.afterbabel.com Copy link Facebook Email Note Other 28 Share Intro from Zach Rausch and Jon Haidt: Today, we publish our third post on what we now call the “first act” of The Anxious Generation: the loss of community. (The second act is the loss of the play-based childhood. The third act is the rise of the phone-based childhood.) In our first post, Zach discussed Robert Putnam’s essential work on the decline of social capital and trust, which happened in part because new individualizing technologies (such as television) emerged and participation in local and communal activities waned. As communities weakened and trust eroded, so did the play-based childhood. In the second post, we featured an essay by Seth Kaplan, author and lecturer at Johns Hopkins who studies fragile states. In it, he argued that to restore the play-based childhood, we must first rebuild strong in-person local communities. In this post, Seth takes his argument one step further, asserting that the upstream cause of the youth mental health crisis is the loss of community. As we are offered new virtual ways to connect with one another, Seth contends that we are only growing further apart. We note that the first generation to move its social life onto social media platforms immediately became the loneliest generation on record. There is a spectrum of approaches that we as a society can take to address the crushing loneliness of Gen Z and Gen Alpha. On one end is doubling down on technology, typified by the recent introduction of the creepy AI “friend” orb, which young people can wear around their necks so that they always have a “friend” to talk with. On the other end is to focus on strengthening the real-world human communities and neighborhoods we live in. Seth advocates for the latter and provides us with a roadmap to get there. — Zach and Jon Jonathan Haidt and Zach Rausch argue that the loss of community is one of three factors behind the deterioration in youth mental health, along with the decline of play and the emergence of phone-mediated childhood. But in this article, I argue that it’s actually the dominant factor since it is upstream from the other two. The rapid spread of smartphones in the early 2010s triggered the dramatic uptick in mental distress among youth, but this happened especially in places where the social system supporting them was already hollowed out. As Rausch writes, kids who live in well-rooted “real-world communities … spending more time engaging in their local community – attending religious services, working, spending more time with trusted adults, and spending more time with their friends in person” — are less likely to experience the harms of the phone-based childhood. Where community is strong, the impact has been softened. In this post, I argue that kids need real-world community to thrive and that the weakening (and even breakdown) of neighborhood communities across many countries explains many of the problems facing youth today—from screen addiction and the decline in mental health to rising drug addiction and growing loneliness. Share What is Community? The term “community” is often used, but its meaning is rarely articulated. It is sometimes conflated with a “sense of community,” which can be produced by working with a dedicated group of volunteers or in a close-knit organization. But, an actual community is more permanent and is much harder to create. A prototypical community consists of most or all of the following: A web of overlapping, affect-laden associations and relationships that crisscross and reinforce each other; A set of shared values, norms, and goals—a common culture that unifies and constrains; A common identity, ideally based on a common history and narrative and recognition of mutual interdependence; Shared rituals that celebrate the group, its past, and future; High levels of trust; High levels of commitment, with limited options for (or high costs to) exit; Recognition of and respect for common authority figures who guide the group’s decision-making; Keystone actors and institutions that bridge and bond different members together; A diverse range of skills and personalities that can contribute complementary things of value (e.g., money, time, expertise) to the group; Role models who exhibit the cultural behaviors that the group should ideally replicate or at least aspire to; Exhibiting a high degree of inclusiveness by actively seeking to encompass every member who shares the same identity or location; Capacity to strongly encourage through moral suasion certain norms of conduct and, if necessary, sanction misconduct. As we can see from this list, a community requires a commitment to a certain social order—and usually to a place—that, by definition, must constrain some choices. In return for security, support, and belonging, members surrender some of their freedom. This explains why creating community in America today is so difficult—few want to compromise their ability to make choices. This is especially true among those with the resources and/or capacity to relocate as soon as a better opportunity beckons—the very people whose leadership and role-modeling communities can ill afford to lose. Why Kids Need Real-World Community Much of a child’s learning and formation is absorbed from the environment rather than directly taught by adults; behavior is better shaped by modeling than by lecturing. The institutions (e.g., schools, churches, and parents’ groups) and norms (e.g., regular family dinners, neighborhood play dates, and the expectation that adults will monitor streets) around us shape our kids' lives in ways we sometimes fail to consider because they are subtle. These institutions and norms determine the strength of families, interfamily networks, neighborhood relationships, and communal support systems. They shape each kid’s attitudes toward relationships, technology, and life goals. For example, when adults and older kids in my neighborhood model kindness, generosity, and responsibility to one another, my kids learn that these are the norms we should all aspire to in a way that no textbook or teacher (or parent) can instruct. When my religious neighborhood turns off technology for one day a week—on Shabbat—we are showing our kids that embodied relationships and interaction are more important than our phones and virtual networks. These institutions and the norms thus have an enormous influence on the choices parents and kids make every day, and on how vulnerable the latter are to various challenges like smartphones, drug use, and gang involvement. As I documented in a previous essay at After Babel, unsupervised, child-directed play was in decline long before kids had smartphones. Why? Because place-based institutions and the communities they support were in decline. Instead of spending time with peers in the neighborhood (the norm for millennia because we all lived in place-based communities), kids were already spending much of their time outside of school at home with televisions, computers, or video games. More affluent children had many of their activities organized for them by their parents, putting them in a variety of highly structured functional groups with different kids rather than repeatedly playing freely with their neighbors. This oversupervision or “coddling”—the subject of the 2018 book co-authored by Greg Lukianoff and Jon—made the attractions of smartphones and social media even more appealing. The newest devices and apps are just one more chapter in the transformation of American childhood. Many praise the myriad benefits that smartphones and social media are said to bring; online connection can give a person a sense of “community,” we are told. We can find new friends, discover just about any idea imaginable, network, and even date through our phones. We can video chat with hundreds of people simultaneously from far-flung locations. We can pursue learning largely untethered from any physical space. Based on all of this, it would be easy to assume that place doesn’t matter. I disagree. Physical place actually matters far more than we realize, especially as our lives become ever more placeless. As Jon writes in The Anxious Generation, only real-world (place-based) social relationships and interactions have the four features that have characterized human interactions for millions of years. Such interactions are embodied, they are synchronous, they involve one-to-one or one-to-several communications, and they have a high bar for entry and exit. In contrast, virtual interactions are typically disembodied and asynchronous, involve one-to-many communications, and have a low bar for entry and exit. The challenge today is that smartphones and other digital devices bring so many interesting experiences to children and adolescents that they cause a serious problem: They reduce interest in all non-screen-based forms of experience. Virtual networks are not only insufficient replacements for communities, but their proliferation makes the establishment of communities more difficult. We’ve Forgotten What Community Is Community—and the relational security blanket it provides—is essential to the health and well-being of our children. Yet, over the last two generations, the U.S. has moved from a “townshipped” society in which neighbors regularly communicated and collaborated with each other through a host of place-based institutions to a “networked” and technologically-driven one in which local neighborhoods, schools, churches, and civic organizations are less important, and therefore they have weakened over time. “The Quest for Community,” in the words of Robert Nisbet, continues unabated, but today, the term “community” is often used in ways that are aspirational and limitless (e.g., many online advertisements for new social networks)—quite different from the original meaning of the term. Indeed, it’s a good example of “term inflation” — the stretching of a good idea to promote values and goals quite different from what is meant. Image. “Build a thriving community.” Thinkific Academy. Why? Perhaps fewer individuals have any experience of what community really means. Young people are marketed to and formed by the twin pursuits of convenience and choice while simultaneously being told that a person’s chief purpose is to express themselves (usually through consumption). This vision of the good life is part of the next generation’s socialization. It feels “natural” to them, and yet it does little to prepare them for the demands and delights of membership in a community. Community differs significantly from friendships, social networks, or what is experienced online. Whereas communities offer mutual support in times of good and bad and are bolstered by robust institutions and norms encouraging frequent, positive interactions, care and concern for one another, and ample opportunities to work together towards common goals, the alternatives typically fall short on these elements. While one-to-one relationships, a string of individual 1:1 relationships, or participation in an online group can provide some benefits—including a feeling of connection—they fall far short of actually producing community, which requires overlapping institutions and activities, things that are very hard to achieve if you don’t share a physical place with one another. Virtual groups are transitory and thin rather than permanent and thick. They cannot provide the dense web of supportive social ties that act like a security blanket when in need or the breadth of informal supportive daily interactions that are the lifeblood of a true community. Most online networks, for example, are instrumental, serving to connect people with a common history or interest or need together, as with Facebook or Discord Groups. They offer a stream of messages and connections, useful information, entertainment, and sometimes notes of support — from known and unknown people. Some of these sell themselves as online communities — think of the concept of “finding or creating community” through hashtags — where users find photos and videos of other people who share like-minded views (and then they like, comment, and share those photos and videos). But these fall far short of the meaning of community. On the net, online groups are more transactional, engendering little sense of mutual responsibility, and not necessarily useful when you need help nor protective when you are vulnerable. The norms of mutual support are significantly weakened and there is little of the sense of common destiny that a place-based community produces. Who would you rather call when in trouble - a real person you see regularly down the block from you or someone online who you have never met in person? Image. “What makes up a YouTube Community.” Source: WixEncyclopedia It’s worth noting that online communities are also voluntary, with many being platforms built for expression or personal advancement. Few provide the diversity of personalities, experiences, income levels, and outlooks that were common in most neighborhoods a few decades ago. Few provide the incentives to earn recognition through the force of character rather than a performative act about oneself. Few provide multifaceted psychological and practical support when needed for members who feel vulnerable or fall into practical difficulties. None of this is to say that online networks and relationships don’t have significant value. In some cases, the virtual world can enhance pre-existing real-world relationships and groups. In others, it can connect people who would never meet otherwise. My point, however, is that we need to recognize that they are not sufficient replacements for what real-world in-person relationships and communities offer and that we should have a clear view of the limitations, which are significant. Leave a comment Restoring Community I moved to my current neighborhood, Kemp Mill, just north of Washington, D.C., 12 years ago to raise a family and (mostly) put an end to my nomadic wanderings. It offered something that few neighborhoods could—a real community with high levels of hospitality and social trust. It is as institutionally thick as any place I have been in America, with these institutions nurturing the deep social ties and tight web of associations that bind us together and enhance our lives in countless invisible ways. The benefits of such ties are apparent every time we face a difficulty—whether it involves safety, technology, or a pandemic. Images. The Kemp Mill neighborhood. Bake sales, kids playing, and presents from neighbors. When COVID-19 struck Kemp Mill, we found that our in-person networks had prepared us to weather such a challenge. A large number of volunteers appeared, ready to distribute food, masks, and medicine to the homebound and set up outdoor pods for kids to play. While many schools around the country went virtual for extended periods of time, ours made every effort to reopen within months by leveraging the medical talent in the neighborhood to develop nuanced procedures to safeguard everyone. Streams of volunteers supplemented what school staff could manage. Meanwhile, synagogues organized new virtual activities for kids and shifted their many programs for adults online. Neighbors hosted social gatherings in their front yards and encouraged kids to spend time together in the back yards. In sum, neighborliness and helpfulness were the default behavior. While I often hear about the negative aftereffects of COVID when meeting educators and parents elsewhere, I do not hear the same complaints from the families in our school. I am thus not worried about social media’s impact on my kids. As a strong kids-centered community, we do not need the government’s help to restrict kids’ use of social media. Our school and the parents of our children’s classmates already carefully monitor what information children consume. Youth get their phones at a later age than elsewhere in America, and our schools do not allow them anywhere near a classroom. Moreover, most receive older-style cell phones that cannot access social media. My kids are active readers, borrowing books from the local library and subscribing to compelling magazines and book subscriptions. And they regularly spend joyful time with their classmates and neighboring kids, going hours and hours together talking, playing board games and cards, singing, competing in sports, or just walking around—with no phones in sight. In observing our faith, our whole community also regularly spends time (on the Sabbath and major holidays) with no access to any media at all. Parents model that they too know how to set their phones aside and attend to real community, in space and time. Subscribe If you are a parent and want to join or build a community to enmesh your kids in, what can you do? Here are a few ideas to get started. First, you can select a place to live based on its social wealth. When my wife and I were ready to have kids, we were determined to find a supportive community to live in. We spent a year checking out half a dozen options between New York City (where we lived) and Washington, D.C. (where I was doing more work). In most cases, we visited, stayed overnight, met lots of people, and asked lots of questions. In the end, we chose the D.C. suburb where I live now—a warm, welcoming, and institutionally rich place. Second, consider how you can befriend neighbors and other parents in your immediate vicinity. Try the 8 Front Door Challenge, which helps you plan and host a Get-Together with neighbors closest to you. Participate in organizations or activities in your neighborhood. Spend time in places where people congregate locally. Organize a block party or play street. Create a neighborly block. Third, leverage local institutions to build neighborhood community. Schools are best placed for this because of their direct ties to local families and kids, but libraries, local businesses, houses of worship, and any other entity with strong ties to your locale can play an important role. A parents’ group based on the families from the schools in your neighborhood would not only build stronger ties between families but also provide a platform to organize activities where residents get to know each other and develop a stronger sense of mutual support and trust. Working with the local library to organize activities in or geared towards your specific neighborhood would create an opportunity for residents to meet one another. A church, synagogue, or mosque could more proactively embrace the neighborhood, as members of Parish Collective do. As for businesses, many have an active interest in building social ties with neighbors. Might they want to hold events, contribute to building community, or invest in some way to strengthen local relationships among neighbors? In general, it’s always easier if you find allies among your neighbors, build partnerships with existing institutions, and leverage the assets (cultural, environmental, educational, economic, etc.) you already have locally. Think incrementally, building momentum step by step rather than thinking there is a magic bullet. Conclusion While it is important to debate youth use of social media, and whether the government should regulate it, what is missing from this discussion is the strength of “the little society” that kids inhabit daily. There are real tradeoffs in using social media, and external factors heavily impact the mix and balance between the positives and negatives involved. As Zach writes, kids “rooted in their real-world communities” are “less likely to move their lives so deeply into the virtual world.” Instead, they “continue to spend more time with friends and trusted adults in person. They are, therefore, less likely to become anxious and depressed when they trade in their flip phones for smartphones, and they are also better able to find social support, which may make online harms less painful.” What matters for our kids is not online connections, but in-person relationships; not just individual friendships but the strength and abundance of neighborhood institutions. Robust communities will foster hundreds of relationships and dozens of place-based institutions engendering trust, fraternity, mutual support, and stewardship. These will shape how we raise our kids and how they will, in turn, raise their own. Share 105 Share this post The Upstream Cause of the Youth Mental Health Crisis is the Loss of Community www.afterbabel.com Copy link Facebook Email Note Other 28 Share Previous A guest post by Seth Kaplan Seth D. Kaplan is a leading expert on fragile states, societies, and communities. He is a Professorial Lecturer in the Paul H. Nitze School of Advanced International Studies (SAIS) at Johns Hopkins University and author of four books.",
    "commentLink": "https://news.ycombinator.com/item?id=41139149",
    "commentBody": "The upstream cause of the youth mental health crisis is the loss of community (afterbabel.com)326 points by throwup238 4 hours agohidepastfavorite298 comments kelseyfrog 2 hours agoWell, yes, we've doubled down on mediating social interactions through economic relationships. Most of the interactions adults have in their lives are with or in the framing of economic relations. Homes, are being invaded with tablets and mobile devices which bring along with them framing interactions as economic relations through ad and consumer frames. Workplaces are inherently settings of economic relations, and third places outside of the consumer setting are becoming extinct because they are non-monetizable. This last category, non-consumer third places are formerly the domain of kid-friendly community-building activities. When we talk about creating more of these and the response is, \"they aren't economically viable,\" it's exactly the kind of economic calculus framing that I'm talking about. reply goethes_kind 1 hour agoparentI'm in my 30s but I'm feeling this so hard. Growing up we used to have these kid/youth centres that were run by local Catholic organizations. We used to hang out there after school. Ostensibly the point was that there'd be 30 minutes of catechism doctrine, but we didn't really care about that. To us it was just a the place where everyone would be. I miss that so much. A place where you can just go and meet people your age, without any reason to be that and without having to pay an entrance fee. Now as a grown up we have community centers, which are run, not by the Church, but by sort of hippie-lefty people. But it's not really the same atmosphere, because you go there, and it's just one demographic of people. It's not quite the same. There's also pubs and climbing gyms which people often use as low effort places where one can mingle, but again, it's not quite the same. I don't like drinking multiple times a week and I really don't like climbing. reply fragmede 1 hour agorootparentYou don't like being drunk that much, or like climbing, but, were your parents really that Catholic? We, as humans, need a dream to build towards, be in service of, and find our place in. What are we doing here and why are we doing it? For those of us who haven't figured it out yet, attaching to someone else's purpose gives us one and we don't have to figure it out ourselves. You need to find religion, just don't call it that. Find your dream that's impossible and work towards making it possible. figure out your role in making that possible. and then work on it. as hard as you can. find others along the way. reply rjzzleep 15 minutes agorootparentParent poster doesn’t want to have to drink to socialize. And bar meets are just that. It’s actually a huge problem in society. Ever stream something or go to the cinema ? What does it show you? You’re happy => you drink to celebrate. You’re sad => drink out of sorrow. You want to hang out with friends => you go for drinks. DEFCON for example perpetuates that same behavior. Sure, one part is loss of community, but the other half is toxic social behavior that is perpetuated by Hollywood. The people that don’t like this but want to belong will perpetuate this cycle for fear of getting ostracized. reply StopTheWorld 2 hours agoparentprevProfessor Michael Rosenfeld at Stanford does research on how heterosexual couples in the US meet ( https://web.stanford.edu/~mrosenfe/ ). In 1940, over 50% met via friends or family. About 36% met at school. In 2021, about 20% met via friends or family. About 10% met at school. Over 50% met online. So the majority of US couples are now meeting via profit-maximizing corporations. He has a 2019 paper on this (and it has only increased since that paper). reply lawlessone 1 hour agorootparentI'm surprised dating sites work well enough that 50% of customers meet via it. They've no incentive to help you leave. reply autoexecbat 1 hour agorootparentThey probably have some internal churn targets to hit, else people will start to figure out that the app isn't worth their time and try a different one reply flappyeagle 33 minutes agorootparentIt creates a much worse problem actually. Why have a committed relationship when you can always press a button to look at hotties and have a pull at the sex slot machine? If they design the system right, their audience just won't marry or have long term stable relationships reply kevinob11 5 minutes agorootparentI can think of a few reasons why people want (either already or after enough pulls of the slot machine) a committed relationship. Though to be clear, just because I think the other more stable thing is valuable to folks even with the availability of the sex slot machine, I still don't love businesses trying to push slot machines or any kind really. reply jprete 55 minutes agorootparentprevThat's both a horrible thought and a near-certainty. reply darby_nine 30 minutes agorootparentprevThey just need to work once. Who knows how many failed attempts at finding someone preceded the one that suck. reply itishappy 33 minutes agorootparentprevCustomer success stories are free advertising. reply loa_in_ 28 minutes agorootparentAnd the need for the service doesn't need to be fabricated, it's innate. reply KittenInABox 51 minutes agorootparentprevIt might not be dating sites. I've heard of people in WoW guilds dating back in the day. reply itishappy 32 minutes agorootparentI have a friend who met her husband on an old Dance Dance Revolution forum! reply dv_dt 52 minutes agorootparentprevHasn't the divorce rate also gone down. So one question is if the method of meeting is improving that rate reply bilbo0s 43 minutes agorootparentYeah. Marriage rate and divorce rate have plummeted since 1940. Probably not much to do with electronic media there. A lot more likely that financial and social pressures are squeezing what were previously considered cultural imperatives. ie - church, marriage, home ownership, etc. reply vegadw 1 hour agoparentprevWhat frustrates me is that, it seems (Read as: the following is just my vibe) that the majority of 3rd places left are religious in nature, but I, personally, don't want to be religious or raise children that are. There are some options, of course, but they're limited and often of poor quality, at least locally. Libraries are trying to adapt to fill this gap, and maker spaces spring up but most don't have funding to be good - or if they do, that funding brings things that ruin the spirit. Once you're looking for a place as an Adult, especially without kids, the number of relevant events and things to do drops quickly too - so these same children aren't going to find better options as they grow older. reply phil21 1 hour agorootparentThe mad rush to as quickly abolish religious practices in mainstream U.S. culture without any form of societal replacement is puzzling to me. I am no fan of religion having grown up in an exceedingly religious environment. But it was always completely obvious to me even as a child that the primary purpose of religion was to form local communities and have others with shared values to rely on. We seem to be doing it with more than just religion these days, but it’s the canary in the coal mine. Lack of investment in your community will very rapidly erode any sort of high trust society you once had within a single generation. Once it’s gone, it’s pretty much gone for good. I believe no one is talking about this aspect of WFH either. It’s taking away maybe the last “socially expected” regular commitment to your local community. Your daily life is not supposed to be lived in complete social comfort with planned interactions with a tiny group of people being your sole source of socialization. At times you should be feeling uncomfortable or obligated in some community or social setting or you are not growing as a human being. I don’t think the office is the best place at all for this, but for many folks I know it was their last social interaction of any sort outside of family. I’ve been unable to articulate these thoughts very well for decades now - since my late high school days I was already the crazy guy telling friends I was really worried how our hobbies and social interactions were so much less investment on average than our grandparents generation. On average having a bunch of Quake guild buddies is simply not the same as my grandpa who had a bunch of fishing buddies. It’s been on my mind for quite some time, and I think the data is starting to show those concerns were legitimate. reply nineplay 1 hour agorootparentI understand what you mean, I grew up in a church with a youth group and group friends which I valued. However I also grew up with constant anxiety about sin and hell. It still gets back to me when my insomnia is bad. So churches and church membership aren't necessarily a net-positive. I too wish there was some sort of community my family could belong to. But I'm not taking my kids to church anytime soon. reply Taylor_OD 1 hour agorootparentprev> he primary purpose of religion was to form local communities and have others with shared values to rely on I just don't think that is true for or to many, likely most, religious people. Community is an aspect but at its core it's a religion. You can't be a part of the community without believing, or at least pretending to believe, in the religion. reply Wytwwww 1 hour agorootparentYou can't because the only people remaining (or the overwhelming majority) in those communities are people who are actually religious and take the whole thing pretty seriously. In the past (of course it depended on the exact time and place) occasionally going to church even if many treated it mostly as a formality was the default for most people. Even if you didn't chances are that you couldn't ignore it entirely because you still had some links to the community surrounding it through family members, various events etc. reply TylerE 35 minutes agorootparentprevWhat you’re describing is basically Unitarianism. reply throw7 11 minutes agorootparentprevThere was a post recently about dunbar's number and it seemed straightforward to me, while reading it, that what it's really revealing is what it takes to scale above dunbar's number and that what we call \"religion\" is exactly that \"binding\" and \"reification\". \"Religion\" in this case is not just about religion either, but also nations. The U.S. has our gods, such as Washington & Hamilton, and places of worship such as the \"temples\" in D.C., but we've also censored leaders like Jackson & Lee, and torn down slave-owning statues. We're living through a deconstruction of history and rebuilding an inverted digital world. I don't think it's been productive. It actually almost feels like an end to history to me. reply Filligree 1 hour agorootparentprev> The mad rush to as quickly abolish religious practices in mainstream U.S. culture without any form of societal replacement is puzzling to me. > I am no fan of religion having grown up in an exceedingly religious environment. But it was always completely obvious to me even as a child that the primary purpose of religion was to form local communities and have others with shared values to rely on. It is a problem, but… religion isn’t true. How do you square that with any sort of culture that values reality? reply scruple 3 minutes agorootparentThe church that I was raised in and grew up in for the first 18 years of my life... I became a militant atheist when I left that church at 18, close to 30 years ago. In my 30s, I started to drift between Zen Buddhism, Druidry, wicca, paganism, looked into Daoism, and on and on it went. And I finally realized, quite recently, that I had a God-shaped hole running right through the center of me. I still haven't quite figured out what to do about that, I've been looking deeply into Eastern Orthodox Christianity because I find it very compelling, and I have no interest in going back to Protestantism and am deeply troubled by the Catholic Church and it's hierarchy, but I have my doubts and skepticism still. Regardless, I personally find all of that to be vastly preferable to whatever the fuck is happening to us in the absence of Christendom. reply bigstrat2003 49 minutes agorootparentprevI am surprised this needs to be pointed out, but people generally believe their religion to be true and do not find it at odds with reality at all. That doesn't mean you have to agree with them just because they believe it, but it is certainly not the case that religion is false in a provable sense, nor that religiosity is incompatible with valuing reality. reply WorkerBee28474 1 hour agorootparentprev> How do you square that with any sort of culture that values reality? You examine all cultures and find that, despite their claims, none truly value reality. Then you choose to believe, or have experiences that lead you to believe, one that explicitly says that there is more to life than what you can see. reply the_snooze 1 hour agorootparentprev>How do you square that with any sort of culture that values reality? Empiricism doesn't help you with the questions of \"who are my people?\" or \"what matters?\" You can make a legitimate case for some of religion's claims being empirically unsound, it doesn't take away from the fact that religion is very effective at giving a lot of people meaning and community, orthogonal to those specific claims. reply Barrin92 1 hour agorootparentIt's arguably only effective if you genuinely believe the truth claims of the faith. There is this sort of strange very online revival of \"trad\" beliefs but you can literally tell that the people are trying to gaslight themselves into believing something they don't. Sort of a split-brain religion at best. Nietzsche's aphorism about God being dead was correct, as was his prediction about the future. Religion wouldn't immediately die out but it would take increasingly pathological forms, it's arguably why religion has taken such a political turn as the capital 'f' Faith portion is just gone. reply benreesman 1 hour agorootparentprevIt seems in 2024 that one simply chooses their religion. Arbitrary GDP growth in a finite environment isn’t true either, it’s just another convenient fiction. More recently the AI doom/effective altruist community has just made some hypothetical AI thing into a god. Even rational things like environmentalism and social progressivism have taken on many of the trappings of a religion. It might be time to start judging which faith-based organizing principles produce the best outcomes. reply simianparrot 1 hour agorootparentprevReligion is literally false but metaphorically true. Our brain filters existence through metaphors. I’m not religious but my metaphors of understanding reality are built on a culture that was for thousands of years until the state got separated from church within my lifetime here in Norway. And it hasn’t made things better. reply 2snakes 1 hour agorootparentprevThere are certain elements that are not true. But other ones are true. There are many ways to alleviate suffering. reply krapp 58 minutes agorootparentGod is not true, at least not the sense that any religion claims (God as an abstraction and a meme is as real as any other, as real as Harry Potter or Slenderman) Claims of absolute moral right or authority derived from divine right are not true. Claims made by the religious that belief in God is a prerequisite to morality, community or cultural identity are not true. Claims made by religious teachings about the nature of the universe are not true. So what does that leave? Philosophy, ethics and cultural mythology? Why do we need to keep religion around for any of that, any more than we need alchemy when we now have chemistry? reply hiAndrewQuinn 7 minutes agorootparentFalse beliefs are often much more instrumentally useful than true beliefs. I notice I usually walk away from conversations with fellow believers about the nature of God, the Bible etc feeling closer to and more trusting of them even compared to if I talk with them about e.g. trolley problems or what their take on moral realism is, especially if I later confirm they in fact walk the walk by living in a way which agrees with those principles. There's just something about the religious framing that gives it that extra kick. The actual question of whether God is real is irrelevant. I just assume they're playing ball the same way I am, and that's often enough to kickstart the friendship. dmkolobov 16 minutes agorootparentprevGrowing up in Nashville I've frequently heard that religion is a prerequisite to ethics. While I disagree in principle, I struggle to come up with an example where philosophy and ethics are discussed in a secular setting outside of school(academia included) and politics. It would not surprise me that on the whole our society is worse off for lack of a widespread secular tradition of discussing these concepts with your community. edit: substitute \"secular setting\" for \"secular state\", definitely not arguing for the integration of church and state. reply ryandrake 1 hour agorootparentprevIt seems to me that a lot of the \"community\" hole left by religion declining is being quickly filled in by politics, which itself is taking on quasi-religious attributes. reply pnut 30 minutes agorootparentMaybe it always was one and the same.. separation of church and state in Western culture was a hard won, radical political innovation not very long ago. And Christians today are a highly motivated special interest group in the States, openly attempting to lock their social agenda into law. See also sharia law. reply Animats 1 hour agorootparentprev> The mad rush to as quickly abolish religious practices in mainstream U.S. culture without any form of societal replacement is puzzling to me. In the US, it's been a slow process over 35 years, since 1991.[1] England and Wales are much further along - believers are below 50%. But Islam is on the way up in the UK, at 6%. The high-intensity religions, the ones that require religious activity once a day or more, seem to be thriving. [1] https://www.pewresearch.org/religion/2022/09/13/how-u-s-reli... reply TylerE 33 minutes agorootparentThe rise of Islam in UK is due to immigration from Islamic countries, not natives converting. reply trimethylpurine 1 hour agorootparentprevFacebook makes money by advertising someone else's products, while religious organizations make money by advertising their own. Is the devil somewhere in those details? Could the disingenuousness of advertising be interfering with the desired authenticity of personal relationships? reply giobox 1 hour agorootparentprevI've found the only way to make friends/community as an adult outside of religion, at least for me, is to go to events relevant to my hobbies and interests. Yes it's difficult, but communities for just about everything are out there if you put yourself out there. If you choose events that occur regularly I've found you get to know people and make friends just by trying to become a regular face too. If you don't have a hobby/interest with a local group, you can try picking new ones until you find one that clicks too. It does take some effort initially though. The shared interest is critical to removing barriers to making those relationships for me. reply marcosdumay 1 hour agorootparentprevReligious places didn't use to be indoctrinating. Nowadays they mostly are, because religions have to justify them economically. My guess is that \"place\" have become a way too expensive good, that people just can't afford to share for free. reply hoosieree 21 minutes agorootparentprevI've had the exact same feeling. I think this is some latent cultural zeitgeist that more people are starting to notice. My thought was to start a \"philosopher's club\", for Platonic friendships. Right now it's just me and one neighbor meeting every 2 weeks for coffee, but I think an ideal size might be around 3-4 \"regulars\" plus 2-5 sporadic attendees. Big enough to get boisterous but small enough to carpool. reply fn-mote 56 minutes agorootparentprevI hear you, but it sounds like you’re saying you want program that delivers high value without paying for it. The way to make this happen is get out there and volunteer your big dollar software engineer time to make it happen. Use all of the knowledge about how to get things done that you get from reading HN, join a team, and start building. My volunteering experience has been amazing, but there were some negative experiences where it was clear we should have required more buy-in or up front investment. reply vegadw 23 minutes agorootparentI'm willing to help, but as one person, I can only do so much. Hyper-locally, it's actually a problem of community here instead of money anyway. There's a half-way decent maker-space, but it's all old men. Think \"ham radio guys\" stereotype. They're knowledgeable, but without any young blood (and the artistic pursuits younger people tend to bring) it's not fun. reply mitthrowaway2 1 hour agorootparentprevLibraries are a great place to be, enjoy, learn, and relax, but a terrible place to meet new people. You're not really supposed to talk, and most people don't go there expecting to interact with a stranger or strike up a conversation. reply odo1242 20 minutes agorootparentLibraries are trying to do that (with community events, conference rooms, etc.) though. Depends on the library. reply vegadw 23 minutes agorootparentprevIt depends. Many libraries host events on a regular basis where socialization is half the point. reply api 20 minutes agorootparentprevYou could even go so far as to say that third spaces that are tied to political, religious, or other types of groups are \"monetized\" in the sense that they exist to further the cause of growing that group. What's nearly extinct is neutral third spaces with zero agenda. reply andrepd 1 hour agorootparentprevSports, hobby groups, book clubs? There are plenty of options to meet like-minded people other than churches. reply benreesman 1 hour agorootparentThe extent to which such a list is accurate and complete is the extent to which it’s a great list of startup ideas to destroy some community institution, make it impossible to do without an app, and put ads on it. reply Eisenstein 42 minutes agorootparentMaybe in your experience. It isn't in mine. You can make due with email lists and flyers and word of mouth and if someone tries to push an app for it everyone is welcome to ignore it. reply darepublic 1 hour agorootparentprevChess clubs in my city mostly closed down due to online games. I remember the largest club owner complaining of this in the early 2000s reply Taylor_OD 1 hour agorootparentprevYeah, this really is the key. I've moved several times as an adult, and my new friend group always comes from doing sports or some hobby regularly with the same group of people. reply sologoub 2 hours agoparentprevTo take this a step further, I’d argue such framings encourage either creation or amplification of risk perceptions in order to sell the remedy (and for political gain), at least in the US. Kids aren’t really allowed much autonomy the way even their parents enjoyed. All interactions are in a sense supervised and structured. reply zemvpferreira 2 hours agoparentprevTrue. I have personally integrated this idea fully by trying to hire/work with friends and family whenever possible. After years trying to see people weekly and failing miserably, this is best hack I have found. Caveat emptor, takes discipline and patience from everyone but it's great to see loved ones daily, fully engaged in a project. It helps that I can afford to have hobby businesses. reply MarkMarine 21 minutes agoparentprevThe rise of (lowercase L) liberalism and replacement of feudal society’s requirement that you be part of the community with the commodification of every relationship we have is the root cause here. We’re just late enough in this transition to really feel it, and people are looking at symptoms and seeing cause. reply pickledish 2 hours agoparentprevIf anyone's interesting in reading more along these lines (the weird state we've gotten into where everything in our lives needs to be viewed through an economic lens for some reason, and the damage it causes) -- check out the book \"Capitalist Realism\" by the late Mark Fisher -- I really enjoyed it! https://www.goodreads.com/book/show/6763725-capitalist-reali... reply gary_0 1 hour agoparentprevA lot of the things people used to do on the Internet for fun, they now do for money or \"points\" (or the subconscious desire to do for money if they become successful enough). In the past, things you posted online tended to get a small number of manual responses from people you had a chance of forming an actual relationship with. Now, a good deal of interaction is mediated by a corporate algorithm (or an up/downvote button). People are also a lot more aware of automated actors (ie. bots). In general, people seem to do a lot less unstructured leisure activity and social interaction. Quantitative goals are imposed by social expectations, gamified ad-funded software, or economic anxiety. Be sure to like and subscribe. reply ChartMaster22 37 minutes agorootparentYou could extend this even further to discussions about media that was traditionally used to escape, like sports, movies, even books. A lot of interactions regarding sports is focused on \"advanced analytics\" and highlighting obscure data points above all else, e.g., Team X is the fourth team on the West coast since 1970 to score Y points through N games. People rarely talk about how much they enjoy a movie, but everyone is quick to discuss box office numbers and Rotten Tomatoes scores. Books too now have an entire subculture associated with their economic framing (\"buy books from local bookstores!\") rather than actual discussions of the material. reply andrepd 1 hour agoparentprevAnd even \"economically viable\" here is actually shorthand for \"able to provide short-term monetary gain which can be captured by a private entity\". Because things like quality education, parks, non-car centric infrastructure, etc. are actually EXCELLENT investments even from an economic perspective. reply RickS 2 hours agoparentprevThis is positively gut wrenching in its accuracy. Really well captured. reply jlos 1 hour agoparentprev> we've doubled down on mediating social interactions through economic relationships We've doubled down on marketplaces to mediate interactions because they are rational systems. Rational systems like marketplaces, elections, and bureaucracies are the sine qua non of liberalism, which both ends of the political spectrum advocate for in their own ways. The right typically advocates more for marketplaces and corporations (i.e. market-based bureaucracies) and the left typically advocates for more government managemeant (election based bureaucracies). Rational systems are in constrast to local cultures based on tradition, biology, and shared history. Its why there is so much homogenization in farming, music, clothing, architecture, etc. The upside is that rational systems allow for scale, propserity, and individual liberty on an unprecedented level. On the downside, rational systems are fundamentally dehumanizing. We mediate everything through marketplaces because we've don't have any place for non-rational organizing principles (locality, biology, shared history, etc) reply vishnugupta 2 hours agoparentprevOn point and well articulated! reply ToucanLoucan 2 hours agoparentprevThis is both a loss in and of itself, and is also a rational response by people within this system. Everything MUST make money because everyone is FUCKING broke. People don't monetize their hobbies for fun, they do it because they're barely scraping by and the notion of spending time on things that don't make money is so beaten out of us that it feels wrong to do it. We can't go anywhere without spending money, we can't do anything without spending money. I shit you not my wife and I wanted to visit a park the other day and realized the parks dept now has paid parking stalls. The PARK. An outdoor space, supposedly paid for by my tax dollars, that because of it's distance from me is not feasible to walk to (and because the streets here are fucking terrifying) now charges me to park my vehicle there, so I can get some nature. Just un-fucking-believably apple pie in the window sill, burgers and fries, fireworks on the fourth American. I am so goddamn tired of every interaction I can have requiring money. I just want somewhere to go that's nice to be that doesn't demand my fucking credit card. reply jamil7 1 hour agorootparentI think it’s pretty reasonable to expect people with cars to pay for parking? reply rangerelf 1 hour agorootparentI don't think so; the streets are paid for by whatever vehicular taxes, the sidewalks are paid for by property taxes, there's income and sales taxes for additional financing; charging for parking is just adding salt to the wound. In fact... hear me out. It might be that, those that own the paid private parking lots in high traffic areas exacerbate the parking issues in contested areas, creating pressure on free parking areas; then they lobby to put parking meters in those free areas because \"the city needs all the money it can get\" (ehh, it shouldn't, it doesn't), and voilá, no more free parking anywhere. Just a thought. reply mschuster91 31 minutes agorootparent> and voilá, no more free parking anywhere. Well... yes, that is precisely what's needed to wean America off its unhealthy dependence on cars. Come over here to Europe, visit our cities where you can actually walk on a sidewalk, where you can live without a car just fine because everything you need can be reached safely on foot, by bike or with public transport. reply snozolli 1 hour agorootparentprevNot at a public location that's too far or unsafe to walk to. We should have much higher density, high quality housing with plenty of public, walkable green spaces. They calling it \"15-Minute Cities\" now, but I always called it Tokyo. reply ToucanLoucan 1 hour agorootparentprevAt a lot at a shopping mall, sure. At a park in the suburbs, IMO significantly less so. Especially when ostensibly my property taxes are already paying for the fucking park. reply collingreen 45 minutes agorootparentI understand your frustration but I expect there are a lot of things that go into that decision. I expect adding a fee to parking makes it possible to enforce time limits, to remove squatting, and to ensure there are actually spots available. I doubt it is for the money but even if it is the park systems tend to be horribly underfunded (and often have to be held up with private donation money). A lot of our broken things are because someone with too many responsibilities and too little resources has to make a choice between a bunch of bad options and I wonder if this is similar. From your rant we know you'll pick free open spots compared to paid open spots but what if the choice is between paid open spots and no spots at all? Or worse, paid open spots or shady looking cars parked all day selling drugs? It seems like the more effective change is more parks but imagine the pushback if someone tried suggesting that! You're angry that you already pay taxes and now you have to pay again to have a special spot right at the park you can park your car in. Imagine the backlash if someone had the audacity to suggest raising your taxes for new parks. \"I already pay for parks! I won't even use 95% of them! Why should I have to pay just because I'm a homeowner!\" I can hear my dads voice saying some of these things and it reminds me of his complaints about funding schools with property taxes and I see how people like him pivot this into \"the socialists just trying to punish the straight white men\". It all makes me sad. reply sethammons 17 minutes agorootparentit is a public space. we all pay for it via taxes. if it is criminal ridden, hire police. if there are squatters, hire police. charging parking at a non accessible location to a public resource, I'm sure you could find a solid argument for that being racist. charging for parking at a public park feels like charging to get to the voter polling location. it should be obviously wrong. reply ToucanLoucan 20 minutes agorootparentprev> From your rant we know you'll pick free open spots compared to paid open spots but what if the choice is between paid open spots and no spots at all? I wouldn't know, there weren't any free spots, open or otherwise, for consideration. > Or worse, paid open spots or shady looking cars parked all day selling drugs? I'm not sure what constitutes a shady car in your mind. I'm pretty sure no one in my neighborhood sells drugs. I know that cuz I have to leave my neighborhood to buy the drugs I want. All things being equal I'd much prefer to just buy them in stores but for some insane reason we're still carrying on the war on drugs despite it being linked, in ink and in recordings, directly to the Nixon administration wanting to prevent black people and hippies from voting, so we make do the best we can. > It seems like the more effective change is more parks I mean, we have plenty of parks. Some days they're pretty damn busy but most days they're not. I'm blessed to be a remote worker so I can also just go there (or you know, used to be able to!) and work for a bit too. > but imagine the pushback if someone tried suggesting that! You're angry that you already pay taxes and now you have to pay again to have a special spot right at the park you can park your car in. Imagine the backlash if someone had the audacity to suggest raising your taxes for new parks. I actually pay pretty high taxes for my area. The trade-off is our snow collection is extremely good and the roads are well kept, as are the parks for that matter (now marred with stupid ass parking meters but alas). I'm not opposed in the slightest to paying taxes. I participate in my local government, and I'm planning to bring this up at the next meeting because frankly I think it's bullshit that we're being asked to pay to park there when we're already funding that department. If they need more money or are running at a shortfall, that problem should be addressed with our community like everything else is, with a tax bump if required. I'm frankly infuriated that this was done not just from the principles of it but also because somehow it was done in a way that completely went under the radar of the city council I participate in. This was a huge change and should've been discussed. > \"I already pay for parks! I won't even use 95% of them! Why should I have to pay just because I'm a homeowner!\" Yes my position would be very unreasonable if it was even remotely this. Thankfully it's not. FWIW I also am fine with paying for our schools too. reply iwontberude 1 hour agorootparentprevWe should be friends, I like the way you think. reply M4rkJW 49 minutes agorootparentprevWhat—or who—made the streets terrifying? reply trimethylpurine 1 hour agorootparentprevI'm wondering if it comes with the size of the city. Everyone wanting to live in the same place at once is a logistical nightmare that won't be solved in our lifetime. One can compromise; a medium sized city with rapid growth offers high pay, low cost lifestyles that don't rely on genius politicians to have the answers. Such a city simply faces smaller, more solvable problems. Parking is free everywhere in at least one such city of 1M. And several others I've lived in or visited. reply alexfromapex 2 hours agoparentprevThis is so accurate. There's been lots of talk of enshittification and it really is just everything now. Monetizing the well in modern capitalism means poisoning it. It all can be traced back to lobbying in politics. They need to ban money from politics immediately and everything will improve. reply whythre 1 hour agorootparentThat just means the money moves in stealthier ways. Instead of soft corruption you get hard corruption. reply andrepd 1 hour agoparentprevIt's kinda impressive how often Marx's 19th century diagnoses of the ills of capitalism prove themselves true in the 21st century. reply benreesman 1 hour agoparentprevIt goes by various names (“trad life”, etc.) but whatever you call it the premise is dystopian and terrifying: people now become celebrity influencers on the back of appearing to live some semblance of a historically normal life. For many that’s now the unattainable dream: a community with values that sit still long enough to even aim at upholding them, a robust partnership early enough in life to start a family the biological way, children who can look forward to the same. On the surface there is a culture war around this, and it’s true that the old model had serious problems with admitting other lifestyles. That needed fixing, but not by obliterating the model that works for most people with overwhelming precedent. The real culprit as always is the “monetization” of everything, a baton that has now firmly been passed from finance people to Silicon Valley people. The #1 post on Y-Combinator’s news site is in some sense the central locus in the observable universe for this. reply hot_gril 2 hours agoparentprevAnything is economically viable if enough people want it. reply meowkit 2 hours agorootparentPoint == missed Its a tragedy of the commons style problem. The viability has to come from a group effort - as soon as there is a single entity running the show the economic incentives will warp or collapse the 3rd place into something different. reply kelseyfrog 2 hours agorootparentIt's also a framing problem[1]. If we were creating an encyclopedia of ways third places are killed or aborted, centralization would definitely be a failure mode. I'd add, the belief that projects should be financially self-sufficient and the fiscal individualistic belief that I shouldn't pay for things I don't personally benefit from. There is a sense of fairness, that makes sense in isolation, yet have these downstream effects when applied to public goods like third spaces. \"Kids are always on their phones,\" and \"Youth programs and parks should be financially self-sufficient\" are downstream contradictions of the primary belief. 1. among infinite ways to analyze it reply hot_gril 2 hours agorootparentprevWhat single entity did you have in mind? An HOA will spend dues on parks, a regular city will spend taxes on parks. A luxury apartment will have common spaces or even activities. They make these expenditures because enough residents will pay extra for it. And a church will run community events paid for by donations. No \"brought to you by Carl's Jr.\" Tragedy of the commons is when there's no big entity with rules, and everyone does their own thing. reply throwway120385 1 hour agorootparentWhat often happens in these small community organizations is one or two volunteers join and begin to do a bunch of work to \"transform\" the organization and expand its reach. They inevitably become \"indispensable\" to the new organization, which they have wrapped around themselves like a cloak. Then they squeeze it around themselves until everyone leaves and the organization's soul has been sucked out. They move on to other organizations in the same area with a \"resume\" or \"bio.\" You'll often see these people everywhere in your community, and they may approach you very quickly to get you involved in their organizations. They are in constant need of new volunteers to burn out on their pet projects. They also constantly promote themselves and are always telling you about what they are doing with other organizations both to recruit you and to make sure everyone knows how \"indispensable\" they are. These people are poisonous to community organizations because they will not abide any consensus-driven process that doesn't lead to agreement with them. reply hot_gril 1 hour agorootparentNot sure about the resumé part, but I've seen these authoritarian volunteers. They still don't ruin everything. And I think my local church has enough of them that they cancel each other out :D reply ant_li0n 1 hour agorootparentprevA housing development will create parks because they are required to do it. This is not market forces at work. reply hot_gril 1 hour agorootparentThere are definitely fancier HOAs with bigger and nicer parks and common spaces than the others, and I don't think it's because they have different city rules. reply apsurd 16 minutes agorootparentHOA style commons solutions means a city becomes thousands of micro, private, exclusive spaces. Perhaps better than everyone sitting in their homes getting amazon deliveries every few hours. but this isn't what people mean when they say public community spaces. We need interconnectedness across income, ideology, generation, education, etc, for stable democracy. reply weberer 3 hours agoprevI've noticed an uptick recently of large brands to start referring to themselves as \"The [Brand] Community\". The author pointed out Youtube here (who in an Orwellian manner calls their ToS \"community guidelines\") but I've also seen it with many other multi-million dollar companies such as Reddit, Twitter, etc. Young people today are reaching out for real support structures, but only receiving manipulation from corporations that want them to watch ads, while occasionally arguing with pseudo-anonymous internet strangers. reply mym1990 1 hour agoparentThis is another form of locking in the customer, because if at any point a customer wants to distance themselves from the brand, they are always distancing themselves from the \"community\", which is harder to do than leaving a brand. reply pests 40 minutes agorootparentIf you can make a product part of someone's identity then you've won. Reminds me of back when people would slap Apple logos on non-Apple work devices. reply VyseofArcadia 2 hours agoparentprev> I've noticed an uptick recently of large brands to start referring to themselves as \"The [Brand] Community\" I don't think I've ever seen that. What I have seen is non-sponsored people referring to \"the [brand] community\" or \"the [product] community\" as a shorthand way of saying they discuss brand or product with other people with that shared interest on a dedicated Discord server or forum. The Sega community, the Final Fantasy community, etc. reply ChartMaster22 34 minutes agorootparentThe official forum for SAP users is called the \"SAP Community\"[0]. I've seen it in other corporate places too, but this was the first occurrence which came to mind. [0] https://community.sap.com/ reply create-account 2 hours agoparentprevRemember what we will regret on our deathbeds: “I wish I had spent more time arguing with random people on the Internet” reply piva00 2 hours agoparentprev> while occasionally arguing with pseudo-anonymous internet strangers. Even this has been eroding, the amount of comments made by bots I see across reddit/Twitter has increased exponentially since the 2010s. It only got worse after LLMs. reply warkdarrior 2 hours agoparentprevFrankly, same thing with a lot of OSS projects. Everything is a \"community,\" joyously writing code together and following community guidelines while singing and dancing! It's grotesque. reply pirates 1 hour agorootparentI agree, it rubs me the wrong way that simply enjoying or consuming a particular thing or doing certain activities seems to automatically make you part of the “community” of that thing. Or maybe this isn’t really true and is just what I perceive. But I don’t like feeling like I am being spoken for, or have it automatically assumed that everyone partaking in something all share a set of values or community-wide beliefs. reply vishnugupta 2 hours agoprevOne big change I've noticed between growing up in a small town and now where I'm in my mid 40s in a big metro city in India is increased \"transactional\" nature of interactions of my daily life. Back then we had a deeper ties with all those who served us by which I mean vegetable vendor, carpenter, doctor, knife sharpener, cloth shop, grocer, baker and so on. Whenever we interacted with them it would be a small chit-chat, exchange small updates (how's your son doing, is he married yet?) and then finally do the actual purchase. It was to an extent that the carpenter would come by and just hand over a big dining table just because he thought our house deserved/needed it. He wouldn't ask for immediate payment either and also in instalments. Some other times he would come by and borrow some money. All of that is now gone. Every single interaction I have now with vendors is 100% transactional. I don't even know their names nor they mine. It means that I'm now connected only with my immediate family, that's it. It also means that the generation now growing up know only transactional way of interaction with non family/friends. I guess these things eventually add up to the loss of community. reply TbobbyZ 1 hour agoparentMoney is now our God. reply Chris2048 1 hour agoparentprev> I'm now connected only with my immediate family, that's it Are there no other ways to make friends via social activities? reply bustling-noose 2 hours agoprevAbout 9 years ago I traveled to the US from India for education. Smartphones were still not very common in India cause data was not as cheap as it is today. When I was in the bus commuting everyone’s head was buried in their phones. I thought to myself this is such a sad thing. Look outside talk to each other but the every single person had an iPhone and was doing something on the phone. Fast forward to 2024 and every person home here in India is constantly on their phones. In the gym, in the car, at work, everywhere. Naturally kids are also getting hooked on devices. How can you talk to someone when they aren’t even looking at you or paying attention ? Communities and real physical social interaction keep people mentally healthy. All these apps and devices are doing is keeping people away from each other instead. Of course no one wants to admit this but people are addicted to devices and distractions. The sooner they dissociate, the better. reply 01HNNWZ0MV43FF 2 hours agoparentIt can't be treated like drug addiction, though. Most people I know have a _relatively_ healthy relationship with alcohol or cannabis. The addicts, especially of hard drugs, are the odd ones out. With phones, and before that music, and before that newspapers, it's a social norm. If you are trying to talk to people you feel like the weirdo. And I get it, cause I don't like making myself vulnerable. I wish I talked to strangers but it's hard to undo a whole childhood of \"Don't stare, don't bother them, keep to yourself, everyone loves how quiet you are, you're so mature for your age because you never talk, etc.\" reply datameta 2 hours agorootparentI would argue it should be handled exactly like drug addiction ought to be. That is, as a widespread medical issue. But it is more complex than drug abuse due to interaction with people expressly being part of the equation. One's phone is ever available and there are very very few places indoors or outdoors that it isn't considered socially acceptable to use their smartphone for social media. The same is not true for alcohol or cannabis. Most people won't simply walk down the street or hang in a park smoking or drinking. Phone addiction is far more visible. reply JoeAltmaier 2 hours agorootparentprevHm. In Iowa it's thought that 10% of the customers of liquor stores buy 90% of the product moved through the door. That's not 10X the general population. That's 81X. One in nine drink 9X what nine other people do. So, you have a relationship with alcohol, it's likely not a healthy one. It's addiction, all the way down. reply chownie 2 hours agorootparentI'm confused, you paint a picture in which the majority drink moderately and then say \"likely not healthy\" but in your example 90% of the customers, the vast majority, don't have an unhealthy relationship with alcohol. So if you have a relationship with alcohol it is most likely a healthy one, and it's \"addiction all the way down\" for... a minority. reply the_snooze 2 hours agoparentprevWhen I'm out at a sit-down restaurant, I always make a mental note of everyone who has their phone out on the table. It's usually 50-50. Not necessarily using them, but within view, as if they're waiting for something else instead of prioritizing the people who took the time to be physically around them in the same place and time. No wonder lots of people feel disconnected. They forgot how to connect in even the most conducive settings for it. reply ryandrake 13 minutes agorootparentNot only that, but also in people's hands. I've seen on many occasions a couple sitting together at a two-seat table, obviously they're together for dinner, both silently scrolling on their smartphones. Not even saying a word to each other. It's eerie and creepy, like something out of Black Mirror. Last time I pointed this out on HN, most repliers were either defending this behavior or being sarcastic with \"Well why don't you walk over and tell them how to live their lives!\" This has kind of been normalized! reply ninjanomnom 2 hours agorootparentprevPersonally, when I'm in this situation, my phone is out and face down on the table to avoid the discomfort of it digging into me from my pocket. I've also noticed that other people use their phone less when I explicitly take it out and put it to the side. Also, even though I take it out, I never use it unless the conversation has asked for it, like searching an answer for something. reply SoftTalker 2 hours agorootparentprevSometimes I do that because it's just uncomfortable to sit with my phone in my pocket. I agree it's rude to use your phone while you're dining or conversing with a group. reply shigawire 2 hours agorootparentprevCounter point - phones are so large now I don't always want it in my pocket when seated. reply astura 1 hour agorootparentprevPeople take phones and sometimes even wallets out of their pocket when they sit down for comfort. reply noworriesnate 2 hours agoparentprevI've noticed the same thing even on airplanes, where everyone is offline. Unfortunately in that case almost everything is either sleeping, consuming corporate entertainment, or reading books. BUT there are always a few people who are open to talking. I prefer talking to being on the phone when I'm in flight. I get to have a long conversation about 1/4 of flights. If you read old books like Pilgrim's Progress you see people walking towards the same town together, and they always struck up a conversation. Look at the Canterbury Tales: some really great literature that consists just of fellow travelers having a storytelling contest! We are missing so much humanity in our kosher lives. reply volkl48 11 minutes agorootparentAt least in the US, most aircraft have internet now - many people are not offline. And even if they're not paying for the internet service, a number of airlines deliver their free entertainment services through personal devices - so they may be watching the same sort of content that would be in a seatback TV on other airlines. Speaking personally: I also tend to just load entire books onto my phone for flights. Reading on a small screen doesn't bother me. With regards to talking - I like talking to strangers. However, the plane is one of the few places I try to avoid striking up conversations. People around me having loud (and it is loud, because talking quietly on a plane is impossible) conversations for hours about nonsense is something incredibly annoying to be on the receiving end of. While I enjoy actually having a conversation, I also know that by doing it I'll be annoying a half-dozen other people not involved in it but forced to listen to it in an environment where they can't do anything to escape it, and it feels rude to do that - especially since I don't enjoy when I'm in their position. reply QuercusMax 2 hours agorootparentprevIf you like those kinds of storytelling-on-a-pilgrimage stories, I highly recommend Hyperion by Dan Simmons. A large part of the book consists of a group of pilgrims-of-sorts traveling together and sharing stories, which gradually help you understand what's really going on. reply AftHurrahWinch 1 hour agorootparentprevI apologize if this comes across as 'how dare you talk about pancakes when I prefer waffles', but I just want to mention that, like a lot of people, I destroyed my hearing when I was young and now I struggle to hear on busses and planes. If someone talks to me on a plane I say \"Sorry, my hearing is really bad\", and its really embarrassing when they respond by speaking so loudly the whole plane can hear for the rest of the flight. reply pfannkuchen 1 hour agorootparentHave you considered using hearing aids? reply AftHurrahWinch 1 hour agorootparentYes, I've tried two different hearing aids, and they were both worse than useless. They often amplified the wrong voices in the crowd, and not even consistently. It was like listening to the radio and having someone constantly changing stations. If you've got a recommendation for one that is able to identify which voice in the crowd I want amplified, I'd appreciate it! reply strikelaserclaw 2 hours agoparentprevhumans will always take the path of least resistance to spike domaine when given the option - that is why we banned drugs and most of these apps with short form info like tiktok, reels, instagram, twitter - these are pretty much like drugs. I wish i can just throw away my phone and live my life but 'being on' is just an expectation in todays world. reply teaearlgraycold 2 hours agoparentprevI'm not perfect, but I do make a conscious effort to put away my phone when in transit or idling around. Not that it matters much as pretty much everyone else is stuck in their own little world. But I think it's better for my own health. reply xhrpost 3 hours agoprevI've personally noticed that my own value of autonomy has often contributed to a reduction in social activity and community integration. I used to be very selective of what I did with others. If I had an invite from friends and the activity didn't seem immediately interesting to me, I'd decline. I've since learned to say yes more (but not always) to invites and particularly consider ones that are more outside my comfort zone. This does however require a sacrifice of my individualism that is so heavily prized in western culture. reply JohnFen 2 hours agoparent> If I had an invite from friends and the activity didn't seem immediately interesting to me, I'd decline. I have seen many (usually younger) people make this mistake. The mistake is thinking that the point of the activity is the activity itself. It isn't. The point is the genuine social engagement. (Edited to add:) > I've since learned to say yes more Years ago, I learned to change my default answer to things from \"no\" to \"yes\". It has been a key to my career success. But, more than that, I have lived a more interesting life than most as a result of that. Making \"yes\" your default instead of \"no\" increases the chances that something bad will happen, this is true, but it also increases the chances that something good will happen. Personally, I've found that on the whole, the riskier path is the better path. But I'm quite certain that not everyone will feel the same. reply sameoldtune 2 hours agorootparentWas just talking with a friend about this. The reason older people tend to play repetitive card games isn’t because they are captivating, it is just a thin excuse to spend a few relaxing hours together. After a few months of hesitation I’ve gotten some of my friends into playing simple games like euchre and hearts and the quality of our time together has gone up significantly. reply Terr_ 2 hours agorootparentReminds me of a scene from a favorite book-series, where the protagonist is visiting with a recently-retired/convalescent former boss. > “So,” Illyan said at last. “What do a couple of retired officers and gentlemen do on a country weekend?” > [...] “Tradition is, you take the local beer from the village—there’s a woman there who home-brews it, extraordinary stuff—and hang the bottles over the side of the boat to stay cold. When the beer gets too warm to drink, it’s too hot to fish.” > “What season is that?” > “Never, as far as I could tell.” > “Let us by all means observe tradition,” said Illyan gravely. -- Memory by Lois McMaster Bujold reply SoftTalker 2 hours agorootparentprevIDK that hasn't been my experience. When I've gotten together with people to play euchre it's always people who are super competitive about it, get annoyed if you misplay a hand, and don't talk about anything except how good or bad their last hand was. reply alisonatwork 2 hours agorootparentprevInterestingly, I've gone the opposite way in my old age. I realize now how very short life is and how it's absolutely not worth wasting what little free time I have on activities that don't interest me. This goes even moreso in the workplace, where saying yes often leads you into taking on more responsibilities for no extra pay or recognition, unless you simultaneously try to wangle the added work into a schmoozing opportunity, which cuts even more into the time you could have been spending doing something you actually wanted to do if you'd said no. reply zamfi 2 hours agorootparentI suspect people come from different baselines here, which for some means saying \"yes\" more often, and for others saying \"no\". But I think the parent's point is to \"say yes\" more broadly than just when the activity interests you; e.g., if the people are good, interesting people and there will be interesting conversation, the activity may just be an excuse to get together, and not its focus -- and it's too easy to evaluate just the activity alone in response to an invitation. reply kredd 2 hours agorootparentprevGood point. Everything boils down to moderation though, right? My usual attitude is, if I have nothing to do — say yes. If I already have plans, invite my friends, but still do it even if they decline. It’s just my simple way of signalling that I like my friends, and I am happy to spend time with them. Workplace is a different game though, as it will always depend on company, politics and your ambitions. reply fire_lake 2 hours agorootparentprevThis assumes you know what is worth doing in advance and I think we rarely do. reply nradov 2 hours agorootparentprevThere's also a weird mistake among young people in thinking of Republicans versus Democrats as enemies to be shunned rather than the \"loyal opposition\" who just happen to have a different perspective. Becoming a political tribalist cuts out about half your social opportunities. reply BobaFloutist 1 hour agorootparentAgree to disagree. It's pretty hard, and often unrewarding, to bridge such fundamental divides in values. reply nradov 1 hour agorootparentIt's not hard, it just requires compartmentalization. This is a skill that can be learned like any other, and brings rewards in many aspects of life. Give it a try. And if you tune out the media and talk to ordinary Republicans and Democrats you'll usually find that there are few fundamental divides and that they mostly agree on the main points of political and economic philosophy. It's like Catholics and Protestants arguing over the fine points of Christian theology; those might seem important to fanatics but if you take a step back and look at the disputes from the perspective of, let's say, a Buddhist the differences seem trivial. reply diputsmonro 1 hour agorootparentprevI respect that viewpoint and would be happy to adopt it in different times. But it's not as simple as political tribalism. For example - Several of my close friends are trans. For the last decade or so, Republicans have been viciously attacking trans people and several states are actively taking away their rights. The entire right wing media ecosystem uses every chance they can to demonize trans people in the new culture war. After years of these horrible attacks, we're seeing hate crimes against trans people rise. At least two of my friends have been assaulted in the last year or so. How can I fault them for having a gut reaction to not engage with Republicans? And if someone is still happy to call themselves a Republican after all this hate, I think that reflects something about their character. Obviously if I were to vote for Republicans who want to hurt my trans friends (which is almost all of them), I could never look them in the eyes again. Similarly, I can't have much respect for those who do. The life and safety of my friends and family is the most important thing to me. I am happy to engage in good faith dialogue with conservatives on these topics, but frankly, if I'm out and doing something I enjoy, I'd generally rather not spoil my time talking to someone who is statistically likely to be a hateful bigot. reply y-c-o-m-b 34 minutes agorootparent> How can I fault them for having a gut reaction to not engage with Republicans? And if someone is still happy to call themselves a Republican after all this hate, I think that reflects something about their character. Yes and sometimes it's worth peeling back the layers to find out why they are embodying that character. An offensive strategy creates a defensive response, nothing will ever get resolved that way; it only creates more hostility. Instead, I invest time into knowing what makes that person so stubbornly that way while re-asserting the fact that I do not hold the same values. In at least a few of those cases, those people turned around to become more open to the LGBTQ+ community despite still holding onto their Republican status. That's a win in my book because it's slowly getting them to think more independently. One of my friends was homophobic and would often make homophobic slurs \"he's wearing f*g sandals\". Instead of telling him he's a bad person or laugh along with him to avoid making things uncomfortable, I simply reiterate that I have no issues with people identifying as gay because what people do in their lives is none of my business. I let him know that I've made friends with gay men and never had one make me uncomfortable or feel like they overstepped boundaries; I know that idea is sometimes what makes straight men afraid of gay men. It took some time, but one day he finally let out that he had a weird uncle that would touch little boys and that's what he associates the LGBTQ+ community with. To which I gently pointed out why it's irrational. He's finally starting to come around now. Recently he'd been heard saying he's ok if his daughter ever turned out to be a lesbian. Small step in the right direction... reply saulpw 1 hour agorootparentprevThere are people who vote Republican in private, and they are different from those who loudly proclaim their Republicanism to everyone they encounter. It might be a shame that the private Republicans vote how they do, but that doesn't have to affect their ability to engage with trans people, or vice versa. So I would say the problem is not the ideological divide per se, but the 'identity' politics which makes both sides openly intolerable to each other. Of course, it's problematic because trans people can't keep private in their transness at a game of cards in the way that a radical socialist could. But in modern discourse, we're all encouraged to be loud and proud in order to advance our preferred politics, instead of quiet and demure in order to foster community that transcends politics. reply diputsmonro 1 hour agorootparent> ...but that doesn't have to affect their ability to engage with trans people, or vice versa. I disagree. How am I supposed to trust and feel safe around someone who knowingly voted for a politician who loudly campaigned on removing my rights and demonizing my very existence? A politician who supports an esoteric policy that disadvantages me in some way is entirely different than one who loudly and plainly says that I am less human and should have fewer rights than others. That rhetoric kills people. And it's not a deal-breaker for you? I cannot call such a person a friend. A vote for a Republican in modern times is an expression to trans people that their rights and safety are less important to you than whatever esoteric tax policy or whatever than won your vote. You can value that policy more than the rights of trans people if you want, that's your prerogative. But it will make trans people and their allies trust you a lot less when they discover that you think their rights are just a bargaining chip to be traded away, and justifiably so. What other situations are you willing to throw them under the bus over, not just in politics, but in life? It's not just a matter of pride or preference, but a matter of rights and safety. reply saulpw 32 minutes agorootparentBingo. I'm afraid, internet stranger, that you are part of the problem here. The original topic for this thread was about \"community\" and the mental health crisis. Community brings diverse people into contact with each other, which fosters communication and thus has the potential to heal division and increase empathy. Do you not realize that a lot of people think that abortion is literally murder? That voting for the pro-choice candidate will kill more babies each year than there are trans people? Regardless of how correct you think they are, they also think this is a matter of rights and safety, of life and death. It may be hard to understand, but they believe this as strongly and fervently as you believe what you do. Now you tell me, without some mechanism to bring people of such disparate views together, how does this resolve? An acrimonious dissolution into a red nation and a blue nation? A civil war in which we both try to snuff out opposing views with violence? (Wouldn't that be ironic?) At best, you want your side to win, in perpetuity, until the current generation of bad-ists has died off and your views prevail. But as we see, that doesn't happen. The \"bad\" views continue to be transmitted from generation to generation, fomented by political opportunists, and then we are at constant risk of \"their side\" prevailing in perpetuity. You think 2028 or 2032 will be any better? The only way people change their minds is by coming into contact with other people with different viewpoints over a long period of time. But that involves actual relationships, not beating someone into submission with well-reasoned arguments. (Think about how well that works on you!) And you can't have any kind of relationship if you dismiss a citizen out-of-hand because of how they voted. So you want to make a real difference? Stop being so loud about who you can't be friends with. Don't ask your co-workers about their politics; it's a waste of energy. Talk with your relatives about their actual problems, and steer the conversation away from political rhetoric. Pretend like you want to be a part of humanity instead of apart from it. reply djom 1 hour agorootparentprevnext [3 more] [flagged] diputsmonro 1 hour agorootparentI don't want to get into a giant political debate here, but I would urge you to follow the spirit of this post and actually talk to some trans people, in person, to get their perspective before voting for people who demonize them and take their rights away. All of those are rooted in transphobia. The entire point of those bathroom bills to \"protect women\" is built upon the foundational idea that trans people are dangerous predators who want to assault people. It's a bigoted idea not supported by the data, which is built out of fear, and - appropriate to this whole post - a lack of understanding from never having actually talked to a trans person. reply djom 5 minutes agorootparent> is built upon the foundational idea that trans people are dangerous predators who want to assault people Sorry but this is where you are incorrect. The fundamental concept is that it's male people who, collectively, pose a risk to female people. This is, for the most part, why we have female-only spaces, where women and girls are most vulnerable. There is also the issue of fairness, particularly in sporting competitions. I have actually talked to many trans-identifying people both online and in real life, and it just further confirmed my views. When one interacts with the males in real life, it's blindingly obvious that they are not female, and thus have no business whatsoever using female spaces. In fact I find it quite disturbing that they insist on doing so, even with full knowledge that so many women and girls are opposed to this assault on their boundaries and do not consent to males in their spaces. > before voting for people who demonize them and take their rights away I don't vote Republican, for many reasons. But I'm glad they are pushing back on this issue. There's a lot of pressure within the Democrats to do so too, and right the wrongs they've inflicted upon women and girls. Look up Kara Dansky for example, and her powerful campaigning for women's rights. I think that men in male-dominated communities such as this one often forget that there are huge communities of women who are concerned about this and many other issues that adversely affect women and girls. Why write their views off as irrelevant? bunderbunder 2 hours agoparentprevIf compromise with others is starting to be seen as an affront to one's own sense of identity, it's no wonder people are reporting such a poor sense of well-being nowadays. I grew up before the terminally online era, and I'm not sure we ever saw taking turns doing each other's favorite activity as a sacrifice of our individualism. It was just part of what it means to form meaningful social bonds with other people. Heck, most the time we agreed to spend time together before choosing an activity, because that's where our priorities lied. reply michaelt 2 hours agorootparentI agree with you, but there was certainly some pressure in that direction. You were probably told that if all your friends were doing drugs (or jumping off a cliff) you should think for yourself. And you were probably told it was bad to be a sheep and just follow the crowd. And you probably saw some \"real fans\" of bands/comics/whatever being scornful towards \"phoneys\" who were just \"pretending\". And you might have been given the impression that picking up some new hobby because a cute member of the opposite sex is into it was somehow insincere or cringe-worthy. And if some of the activities were expensive by your family's standards, you might have been asked if you really wanted to do whatever. I can imagine how a person who over-thought this sort of stuff could have ended up thinking they shouldn't, say, go to a baseball game if they don't like baseball. reply loa_in_ 18 minutes agorootparentI think you just wrote down a post mortem of my life's failure reply bunderbunder 2 hours agorootparentprevOkay, but isn't that a little hyperbolic, Karen? All we were talking about doing is playing Super Mario Kart at Becky's house. reply conductr 2 hours agoprevI’m so glad it’s finally happening but also it’s wild to me this conversation feels like it’s just beginning. The Anxious Generation book seems to have been what was needed for people to see what, to me anyways, was common sense and actually question their silly iPad at 6months old parenting styles. As it’s picking up steam, I’ve been hearing stories recently about how our local “school district decided to ban phones from classrooms” and just yesterday it was “the school will no longer allow food delivery services to drop off food”. Like, educators, WTF, why was that ever an option? In my days long ago, 80s-90s primary school, there was a zero tolerance policy for this stuff. Why was it ever deemed allowable? I can see letting kids keep their phone in their locker or create some storage solution for it. For emergency purposes. But in emergencies, the parent should be able to call the office and they can fetch the kid. It worked just fine in the days of landlines. It’s hard for me to understand the parenting styles that demanded and allowed this stuff to take place, because I’m sure it was parent driven. But there’s so much else to the parenting styles that are contributing to all this stuff. Banning outdoor play and independence is why they’re online so much and why the arcades and third places all disappeared. I say all this as a parent of an almost 6 year old boy, doing everything I can to shield him from the wacky parenting style that seems to be the norm and provide him places of community and activities away from screens. He won’t have a phone until he drives, or maybe just a basic flip phone if we think we need a communication line to reach him when he’s a bit older. reply kahmeal 19 minutes agoparent>I say all this as a parent of an almost 6 year old boy, doing everything I can to shield him from the wacky parenting style that seems to be the norm and provide him places of community and activities away from screens. He won’t have a phone until he drives, or maybe just a basic flip phone if we think we need a communication line to reach him when he’s a bit older. This is possibly a bit extreme, imo. In a world that is ever increasingly digital, responsible exposure is without a doubt necessary; However, it seems that one could also inadvertently foster naiveté and ignorance of our digital reality, which has its own potential pitfalls. The \"right\" answer is probably somewhere in the middle. As usual. reply philip1209 2 hours agoprevThe books the authors cite are great and worth reading. Some personal observations: - The USA lacks a unified cultural identity now. There are lots of reasons for this. But, it's considered taboo to express a love of the USA - which hurts our community + culture. - People put a lot of effort into work, and work is becoming more transactional. No more \"life-long employment with the buddies\" kind of situation. - America went from poor to rich, but still behaves like a developing economy. Public healthcare + public education + low-income housing availability are poor, while there's a big class of people who can afford private education + private healthcare + McMansions. I think this deteriorates the idea of \"we're all in this together\" because there's such unequal opportunity. - Wars used to be a way to unify a country, but we're in the era of proxy wars - which don't have the same aligning effect. reply ativzzz 2 hours agoparent> But, it's considered taboo to express a love of the USA I don't agree. Every sporting event still plays the national anthem and often has soldiers or military involvement or mentions I see US flags all the time, all over the place. There are certain forms of \"love\" of the USA that are more politically one-sided that may be more taboo if you live in an area where most people are on the other side. reply parpfish 1 hour agorootparentthere are a lot of people that like the national anthem and fly flags, but that's for a distinct slice of america. one tribe likes flags and overt patriotism, the other side does not. if i see a person with a flag sticker on their car, i can probably guess a lot of their unrelated political opinions reply pphysch 1 hour agorootparentprevTo me there is a profound difference between the flag-waving, corporate, pinko-hating, anti-social pseudo-patriotism exemplified by Reagan, which is still popular today, and actual patriotism. \"Patriotism\" as superficial brand-loyalty versus patriotism as lifelong civil-service. reply dukeyukey 2 hours agoparentprevSpeaking as a non-American who visited for the first time last year: > But, it's considered taboo to express a love of the USA American flags _everywhere_' Like seriously, I visited both liberal areas (Seattle) and conservative areas (Spokane's surrounds) and y'all patriotic as _fuck_. > Wars used to be a way to unify a country... Also because the US is just not threatened by anyone. I'd hope that going back to being the Arsenal of Democracy for Ukraine (and maybe Taiwan or South Korea if things go bad) would've tied the US together, but man I was wrong there. reply Balgair 1 hour agorootparent> I'd hope that going back to being the Arsenal of Democracy for Ukraine (and maybe Taiwan or South Korea if things go bad) would've tied the US together, but man I was wrong there. I mean, it's not like we need to be rolling out a B-29 every minute or an aircraft carrier a week to defeat Russia there. Just cleaning out some of the stock from the 80's held them off for months. Logistically, the war in Ukraine just isn't very taxing to maintain a psuedo-stalemate. If anything, NATO+ wants to keep this ulcer open for as long as it can in Russia, bleed them white. reply Wytwwww 1 minute agorootparentAt a certain point (probably to a large extent already) Ukraine will simply run out of manpower. Demographically it was in a very poor state to begin with to such a degree they had to keep the MINIMUM age of conscription at 27 and lowered it to 25 a few months ago. There were only ~2.6 million men aged 15 to 30 and another 3 million in their 30s back in 2022. Around 0.6-0.8 million Ukrainian men have left the country for the EU (18-60, but I assume it's highly skewed towards lower ages). A significant proportion (probably the majority) of those that remain in the country are not particularly motivated, capable or otherwise keen about going to the frontline. It's hard to tell but looking at estimates > 150k have died or been severely wounded and presumably a several times more suffered lighter injuries. This isn't WW1/2. Poorly trained and/or highly unmotivated men are not very combat effective and mobilizing such a large proportion of population as back then is not feasible (especially considering that men in their 30s and 40s have been doing most of the fighting). So how long do you think Ukraine can hold out if we extrapolate the casualties rates from the last 12-24 months or so? By the time the West fully ramps up military production it might be too late. reply silverquiet 2 hours agoparentprevI don't disagree with the comment, but whenever people talk about a \"love of the USA\", I always want to ask what is it that you love? To stereotype a bit, I'm guessing that it will not be the federal government (despite a strong reverence for the flag of that government). reply filoleg 2 hours agorootparentI guess it is about the spirit of it, just all the incongruent different groups of people coming together and making something greater than the individual sum of them happen. And just the whole grander idea of forging your own destiny, no matter how risky the odds are. Sure, it flies in the face of harsh reality quite often, but that’s not the point. And we can definitely gripe about current immigration policies. And of course, that spirit doesn’t feel like it holds true in a big chunk of the US. But to me personally, that’s why NYC feels sort of magical. It’s that whole idea solidified in flesh. As an immigrant, I can tell you that my hypothetical future in my old country was doomed from the start. The US, with all its imperfections and flaws, let me do my own thing and carve my own path from nothing (parents working minimum wage, so basically zero connections and funds). All while making me feel more at home than my old country ever did in every single way (from interactions with people to absolutely any other aspect of my life). Again, this isn’t to discount tons of issues that the US has (just like any other large country would). However, I just struggle to think of any other country where I could’ve ended up where I am right now, as an immigrant. And that, to me personally, is what the (idealized) spirit of the US is all about. reply CitrusFruits 2 hours agorootparentprevI'll preface this with saying there are other countries that do many of the following things I say better, but there are many many countries that do things worse. Additionally, I've found most people who have trouble loving the U.S.A. haven't had the privilege of traveling to any of the 130+ countries of the world that have a GDP per capita of less than $15K. Those countries can be awesome in their own right, but they also can help highlight how privileged the U.S. is in many areas. I love the USA because of its infrastructure, it's natural beauty, the principles of its governmental structure, the diversity of people (and food!), how it provides opportunity for people who want that opportunity, for its strong civil rights, and for its natural resources. We can do better to protect and grow all those things I mentioned, but it doesn't mean they don't exist in the first place. reply philip1209 2 hours agorootparentprevThe deeper issue is that a pessimism about our country will become self-fulfilling. So, it's not useful. I think the USA is amazing in that it attracts the most ambitious people in the world, provides relative stability for them to work and live, and that it has managed to create such a stable society given the heterogeneous nature of its culture. It has a lot of problems, but I'd much rather be here than in the communist former-country my mom was born in. reply Mountain_Skies 2 hours agorootparentEver consider that perhaps cramming a community full of the most ambitious people in the world might have a bunch of negative consequences for that community? reply batshit_beaver 1 hour agorootparentSurely it has positive consequences too? reply veryfancy 2 hours agorootparentprevEveryone’s got a basket of things they can love or hate about this place when they’re in the mood to love or to hate. That’s something to love, I think. reply snozolli 1 hour agorootparentprevI always want to ask what is it that you love? - Public lands. Most states have National Parks in them. Every state has state parks. These generally give enormous freedom of enjoyment to vast areas of land and are accessible to most. - General freedom. We've all seen videos of abusive cops, but the fact is that's still rare. If you want to launch a business, you'll likely be able to find a location, understand regulations, and form the legal entity without paying off officials. We have corruption, but it's generally at high levels and invisible to the general public, so you don't feel the pervasive effects. - Economy. Sure, I miss the 90s tech boom, but the US has the most advanced tax system in the world, and a highly effective banking system that spurs the economy. It's far from perfect, but it's better than a whole lot, and most people take it for granted. I think we peaked in many ways between 1995 and 2012, but if we can clean up our act and make it through the new era of Robber Barons and foreign interference, we'll be in a really good place again. Edit: - ADA. To my knowledge, no other county has as good of regulations benefiting the handicapped and disabled. From accessible businesses and buses to readable signage to minimum doorway widths in homes. reply stnmtn 2 hours agorootparentprevThe absolute natural beauty and diversity of geography that the USA has is one of the things that make me love it. The \"newness\" of USA compared to Europe is also something that I really like about it. reply samatman 1 hour agorootparentprevIt's the flag of the nation. Not the flag of the federal government. There are symbols which are more directly associated with the government, such as the Great Seal of the United States. You will see patriotic expressions involving that symbol rather less, although the bald eagle, our national totem, is quite popular. Some countries have a separate state and civil flag. The United States is not among them. If you're asking why Americans love our nation, I don't know how to answer that question. reply carapace 2 hours agorootparentprevThere's no taboo, that's ridiculous. I love the US-of-A and I don't care who knows it. God bless America, and apple pie and moms. I love the people, even though we're mostly stupid and crazy. I love the land, even though it's drenched in the blood of the people of the First Nations and of each other. I love that we fight to repudiate and destroy the evil of slavery, even though we aren't done yet. And yeah, I even love the Federal Government. Sure it's a gnarly bureaucracy that makes mistakes, but most of the time it pretty much works. And there are so many really cool bits, like the USGS. And the vast majority of the people in the Federal workforce are decent folk just doing their best. So yeah, we have a lot of problems, but we're doing our best and the story isn't finished yet. I love the USA. (I also love the rest of the world too. It's not an either-or thing.) reply hot_gril 2 hours agoparentprev\"it's considered taboo to express a love of the USA\" is not really true in most of the country. I moved out of one of the few places where it is. reply lisper 2 hours agoparentprev> it's considered taboo to express a love of the USA American here. First-generation immigrant. Came from Germany at age 5. This misses a crucial part of the problem. It is considered taboo to express a love of the USA in certain social circles. In others, it is considered taboo not to express a love of the USA. The problem is that the two sides have very different ideas of what \"loving the USA\" means. Among the first group (liberals) the USA is envisioned as an inclusive melting pot where all are welcome. Among the second group, the USA is envisioned as a set of values to which one is required to subscribe in order to be included; to include those who do not subscribe to these values would change the character of the nation to the point where it would not longer be the USA. These values include innocuous things like baseball and hot dogs, to abstract ideals like \"freedom\", less abstract ideals like capitalism, and quasi-religious ideals like \"family values\". Lately these have started to morph into religious ideals up to and including the (false) idea that an essential part of the national character is to be a Christian theocracy. So it's not that expressing a love of the USA is taboo, it's that conservatives have managed to co-opt loving the USA and make it part of their brand. Expressing love for the nation, flying the flag, singing the national anthem, etc. are nowadays seen as expressing tacit support for conservatism in general, and the Republican party and Donald Trump in particular. This is the reason that liberals avoid them. For me personally, I have always felt that some of the common rituals associated with \"loving the USA\" were kind of weird. Take the Pledge of Allegiance, for example. I get pledging allegiance to the nation, but to the flag? That has always struck me as bizarre. The flag is just a symbol, a token. Why would anyone pledge allegiance to a flag? But to question this, especially as a minor in a public school, turns out to be unwise. reply diputsmonro 1 hour agorootparentI agree with and second every word of that. I grew up in the US during the 9/11 era, and I was just old enough to recognize the horrible nationalism that it spread through the entire country. How am I supposed to celebrate the flag of a country that invades the wrong country under false pretenses and rallies behind dumb propaganda like \"freedom fries\" to support it? How am I supposed to be proud of a country that chooses someone like Donald Trump as it's leader? (and is close to doing it again!) I do generally love the supposed ideals of the US, and I would like to call myself a patriot - but it is difficult to do when criticism of the US (which is the whole point of a democracy) is met with \"love it or leave it\" type responses from people who cover themselves in the flag. Real patriots want their country to improve via constructive criticism and change. But most conservative \"patriots\" in this country view any criticism as \"hating America\". Their \"patriotism\" is just fetishism for the traditions and symbols - which is why they cover every item they own with the flag. In that context, the flag and \"patriotism\" can be very divisive, and those who abhor the conservative culture wars here can be very reticent to create the appearance thay they stand with them. reply arrosenberg 1 hour agorootparentprevOn your last point, the next line is literally “and to the Republic for which it stands”. Its just poetic license. reply lisper 1 hour agorootparentWell, yeah, but it seems to put the emphasis in the wrong place, with the republic being an afterthought, secondary to the symbol. Also, being asked to pledge allegiance to anything as a minor seems weird and wrong to me. IMHO it undermines the whole concept of pledging allegiance, which should be an informed choice, not a ritualistic indoctrination. reply AftHurrahWinch 1 hour agorootparentprevReally great comment! You noted: > The problem is that the two sides have very different ideas of what \"loving the USA\" means. Among the first group (liberals) the USA is envisioned as an inclusive melting pot where all are welcome. Have you had the chance to talk with a 3rd group who believe that the US is malignant and think that the most moral action they can take is to undermine the state? I think there is even an American tradition of that; lots of US students are assigned excerpts from Thoreau's Walden or Civil Disobedience and from one perspective, those texts are arguments that because the US permitted slavery it was malignant and should be 'starved', of our taxes, labor, and participation. I can't and wouldn't argue that Thoreau was wrong to protest slavery by any means necessary, but I also hope that the US doesn't embrace the sort of widespread self-sabotage I see in European protest movements. reply lisper 1 hour agorootparent> Really great comment! Thank you. > Have you had the chance to talk with a 3rd group who believe that the US is malignant and think that the most moral action they can take is to undermine the state? Yes, but I don't think those people can be said to \"love the USA\" under any reasonable interpretation of that phrase. reply AmericanChopper 2 hours agoparentprev> it's considered taboo to express a love of the USA - which hurts our community + culture. Nearly every bullet point the article listed for what makes a strong community was basically just a descriptor for cultural homogeneity, which also touches on a rather controversial taboo. This sort of critique of diversity would be considered hate speech by some. reply AftHurrahWinch 1 hour agorootparent> This sort of critique of diversity would be considered hate speech by some. How wonderful that we have the diversity of thought to find someone who will object to anything, and how fortunate that we have mechanisms to overrule and ignore them. reply KittenInABox 2 hours agoparentprev> - America went from poor to rich, but still behaves like a developing economy. Public healthcare + public education + low-income housing availability are poor, while there's a big class of people who can afford private education + private healthcare + McMansions. I think this deteriorates the idea of \"we're all in this together\" because there's such unequal opportunity. America has had a long history of unequal opportunity. It's kind of founded with unequal opportunity (slavery) and continued to shoot itself in the foot in order to ensure inequality (closing public schools instead of allowing integrated schools is why we have a rise of private schooling to begin with, HOAs existed primarily to ensure the community could enforce that no one could allow a black family to move in by selling their property to blacks). I think of America as a country that is constantly being challenged with the ideals it claims as having against the society it builds which falls short of those ideals. But I don't think this inequality has to do with the recent youth mental health crisis... America has endeavored to be more and more equal by the year. reply jeffbee 2 hours agoparentprev> The USA lacks a unified cultural identity now This is why we need to pursue annexation by Mexico, so we can finally be a country with some culture. reply fergonco 2 hours agoprevJust a data point: In Valencia, Spain, in the 80s, children played in the street with no much supervision from parents. Occasionally we would stop the football match to let a car drive by. Forgetting your keys at home was no issue, you could get a glass of milk in ten different places while you wait for other (more attentive) members of your family. Nowadays there is hardly a place to park your car. Parents don't allow kids to play in the street. And the ones that interact with each other are the ones who lived there in that period. It's very difficult for newcomers to integrate. What are the reasons for this? My take: cars and lack of stay at home mums. They built the social network at that time. They took care of each other children, the were there to help each other. Nowadays households have both adults working (so nobody even asks for salt to the neighbor, all order a pizza instead). reply gmoot 2 hours agoparentWe tried to counteract this with our own children by giving them a lot of freedom. But these things are very network dependent. Yes we let our kids play in the street and bike around the neighborhood, but it is boring because there are not any other kids to play with, so they don't do it much. reply cen4 2 hours agoparentprevWe have 8 billion people on the planet. And there is no plan what so ever to take care of even half of them. It doesn't matter if we see slowing population growth. With globalization there is no reason to be sitting in the same spot. People are on the move. reply hnpolicestate 1 hour agoprevThe articles thesis on loss of community plays a role but has always existed in some context depending upon the individuals location. The primary cause (in my opinion) of the youth mental health crisis and falling happiness rates was the introduction of the smart phone. Blaming social media is a clever cop out, it's the actual device and inability of people to stop looking at it. Totally abnormal to human life. Will we adapt to it over time? Possible, but many people will be lost along the way. reply RangerScience 21 minutes agoparentCounter-take: Smartphone addiction, like other addictions, it a coping mechanism for other issues, see https://www.psychiatrictimes.com/view/what-does-rat-park-tea... > But Alexander wondered: is this about the drug or might it be related to the setting they were in? To test his hypothesis, he put rats in “rat parks,” where they were among others and free to roam and play, to socialize and to have sex. And they were given the same access to the same two types of drug laced bottles. When inhabiting a “rat park,” they remarkably preferred the plain water. Even when they did imbibe from the drug-filled bottle, they did so intermittently, not obsessively, and never overdosed. A social community beat the power of drugs. reply RangerScience 25 minutes agoprevHot take: The upstream cause of this is, essentially, \"the rent is too damn high\". Not necessarily in a sense of housing prices, but - In order to have a community, that community needs a space. (The early 'net was interesting in that \"space\" was cheap/nearly free - IRC, forums, etc, which might be one reason it took over as a social space to begin with) Extremely consistently, I see efforts at forming communities fail simply due to a lack of regular space in which to have them, and from what little I know talking to organizers, it pretty much always comes down to the cost of the space - the rent. This remains true even if the space itself wants to be cheap/free - it has to pay it's own rent, which means it needs dollars from everyone using it. AFAIK, religious institutions get around this through (1) advantageous tax laws and (2) long-term ownership. reply brightball 2 hours agoprevI have to assume that people leaving their home towns to work elsewhere is a huge driving factor of all of this. reply freshlee 2 hours agoparentI think it's not only this, but that the process repeats over and over. I had very deep relationships in high school, forged new ones in college, then both of those ended. I moved to a new city where I started a new job with a bunch of other people in their mid-20's, and we formed yet another community. Then the company laid off or required everyone to move to a new city. New job, same story again. I still start up new friendships at work, but it feels less and less worth it each time and so I try a little less hard year by year, because you're working against impersonal forces that will upend your social structures on a whim, and it feels like a treadmill to try to keep them intact. reply veddox 2 hours agoparentprevI've begun thinking in that direction too, after seeing how my peers have been moving all over the country in the last few years - first for uni, then for a job, then another job... I'm one of the movers myself, and I know why I moved, but I feel the cost of lost relationships quite heavily. reply dnissley 1 hour agoparentprevAmericans move less than they ever have these days: https://www.nytimes.com/2019/11/20/us/american-workers-movin... reply hot_gril 1 hour agoparentprevI recently moved. Most of my new friends aren't from here, they came here for work, but they consider it their own city now and are part of the community. It's different in a \"commuter city\" like San Francisco. That means the majority of people don't even live there during the day, and even their job might be temporary. Unfortunately most are there to make money, not friends. reply brightball 15 minutes agorootparentYep, exactly. And if your families aren't around, that will have an impact the moment you decide to have kids. Available grandparents make everything about raising children easier, especially for working parents. And then the grandparents will connect the kids with their friends, their friends families and grand kids too. And so on. reply reducesuffering 2 hours agoparentprevThat has only been declining while youth mental health got worse. reply brightball 1 hour agorootparentIt has been with remote work but think of how much break down is already in place. reply constantcrying 2 hours agoprevNo, absolutely not. Young people are more connected than they have ever been before, just now they are connected in some of the most unhealthy and detrimental manners possible. Instead of connecting with friends in real life, they form communities on social media, in discord channels, in video games, etc. The consequences are just barely starting to show themselves. As for the why, I think they are many reasons. The Internet is obviously an attractive and addictive place, but cities have gotten so much worse as well. Where I live the playgrounds I used to go to as a child are now full of drug dealers... reply raziel2p 2 hours agoparentThe article clearly states that the connections you mention don't make up a community: > Many praise the myriad benefits that smartphones and social media are said to bring; online connection can give a person a sense of “community,” we are told. We can find new friends, discover just about any idea imaginable, network, and even date through our phones. We can video chat with hundreds of people simultaneously from far-flung locations. We can pursue learning largely untethered from any physical space. Based on all of this, it would be easy to assume that place doesn’t matter. > I disagree. Physical place actually matters far more than we realize, especially as our lives become ever more placeless. reply throwway120385 2 hours agor",
    "originSummary": [
      "The youth mental health crisis is attributed to the weakening of real-world communities due to technological advancements, leading to increased loneliness and mental distress among youth.",
      "Experts Jonathan Haidt and Zach Rausch highlight the decline in community and play-based childhood, alongside the rise of phone-based childhood, as significant factors.",
      "Seth Kaplan stresses the importance of rebuilding strong local communities, emphasizing that real-world interactions offer support and security that virtual connections cannot."
    ],
    "commentSummary": [
      "The youth mental health crisis is attributed to the loss of community and genuine social connections.",
      "Economic relationships now dominate social interactions, with homes and workplaces focused on consumerism and economic viability.",
      "The decline of physical community spaces and the rise of superficial online interactions have exacerbated mental health challenges among the youth."
    ],
    "points": 331,
    "commentCount": 299,
    "retryCount": 0,
    "time": 1722609650
  },
  {
    "id": 41138701,
    "title": "Hackberry-Pi_Zero – A handheld Linux terminal using Raspberry Pi Zero 2W",
    "originLink": "https://github.com/ZitaoTech/Hackberry-Pi_Zero",
    "originBody": "Hackberry-Pi_Zero A handheld Linux terminal using Raspberry pi Zero 2W as Core with 4\" 720X720 TFT display and the original BlackBerry Keyboard Questions or need more info? Join my Discord Channel! About this handheld The main reason why I design and built this handheld cyberdeck is to treat this as a lernning tool and also a funny toy for the hackers. It is powered by a raspberry pi zero 2w and a 4\" 720X720 TFT display. Here are some Main Features: Main Processor: Only compatible with Raspberry Pi Zero 2w. Display: 4\" 720X720 high resolution TFT display. Dual Swappable battery Design: Replace your battery in 10 seconds without killing the power! Battery Type: Nokia BL-5C. You can buy it anywhere in the world. Battery Life: In my testing: 3.5 hours using the desktop, 5 hours on the commandline. Keyboard Mouse Combo: Yes, this cyberdeck has keyboard and mouse combo on board. You can choose blackberry Q10 or Q20 keyboard. Fully customizable keymap: You can connect the keyboard with a computer and customizable the keymap through VIAL easily. 3 USB2.0 Ports: This handheld has 3 USB2.0 Ports, you can use it with USB-Stick or 4G Module Dongle or any USB thing. Charging Ampere: 1A charging rate; this handheld can be fully charged within 3 hours. Stemma I2C Port: This device has a Stemma I2C port on board, you can connect with any I2C sensors. TF card Slot: There is an external TF card Slot. You can replace your OS image very easily. Block Diagram Get started Introductionvideo How to turn on the HackberryPi? Turn the red switch to the right position and then press the red button to the left side of the red switch to power the USB Hub Controller Chip otherwise the keyboard can't be used! At the same time the indicator for the battery voltage will be turned on. Keyboard The keyboard type is blackberry Q10 or Q20 keyboard. Both have the same keyboard layout. There is a red switch on the left side to decide if the keyboard controller communicates with the HackberryPi or with other device through the USBC-Port underneath. The idea about this is you can connect the keyboard with your computer and customize the keymap using VIAL or the handheld can be used as an emergency keyboard mouse combo. How to change the keymap? Put the red switch to the lower position, connect the keyboard with your computer, open VIAL page, then you can customize the keymap yourself. Different Operating System You can install Kali, Raspberrypi OS, or Retropi and many other OS into HackberryPi. This page will tell you how to install the display driver in a different operating system. Basic Tutorial How to change font size in terminal Dimension and Weight Dimension of HackberryPi: 139.4x82x15.7mm Weight without battery: 151.7 Gram Weight with battery: 189.7 Gram Where to buy BBQ10 keyboard version BBQ20 keyboard version",
    "commentLink": "https://news.ycombinator.com/item?id=41138701",
    "commentBody": "Hackberry-Pi_Zero – A handheld Linux terminal using Raspberry Pi Zero 2W (github.com/zitaotech)312 points by felixr 5 hours agohidepastfavorite67 comments teraflop 2 hours agoThis looks like a pretty cool device! However, I was immediately curious about how the \"dual battery\" feature works. The IP5306 power-management IC seems to be designed only for a single battery, and as far as I can tell from the schematic[1], the two battery connectors are just directly connected to each other in parallel (across VBAT and GND). This seems really sketchy. If you plug in two batteries that are not at the same state-of-charge, then you're going to get a very large current flowing from the higher-voltage battery to the lower-voltage one, probably significantly exceeding the batteries' rated current limits. At best this wastes a lot of power and generates a lot of heat, and at worst it could be a fire hazard. [1]: https://github.com/ZitaoTech/Hackberry-Pi_Zero/blob/main/Sch... reply fecal_henge 1 hour agoparentAt best this wastes a lot of power and generates a lot of heat, and at worst it could be a fire hazard. - you just described my high spec HP laptop. reply johnklos 1 hour agoparentprevI read this part: > Replace your battery in 10 seconds without killing the power! as a suggestion that you'd have four batteries total, and you'd have two that're fully charged, and you'd replace one battery, and within seconds you'd replace the other. Or at least that's how I'd do it. I've recently read up about power management and battery charging, and want to make a charge controller than can connect two separate banks. I wonder how hard it'd be to change the IP5306 in the Hackberry Pi Zero to handle the two batteries separately. reply diggan 1 hour agoparentprevI understood it as it'll use only one of the batteries, but you can swap between which is used. So initially, you have two charged batteries, while using only one. Once you run out of power in the first one, you'll switch to the second, and now the first one could be swapped to a fully charged one. Blue/green deployments, but for batteries basically. reply teraflop 1 hour agorootparentIt would be convenient if it worked that way, but since the batteries are connected across each other in parallel, they will both be discharged simultaneously. And as soon as you hot-swap one of the nearly-discharged batteries for a charged one, it'll be more-or-less short circuited across its discharged counterpart. To do what you describe, you would need additional components to \"switch\" one battery at a time into the power path. (This can be done with a single transistor if you're only worried about current flowing in one direction, but I believe it's trickier if you want to support both charging and discharging in the same circuit.) reply dheera 4 minutes agorootparent> but since the batteries are connected across each other in parallel Connecting LiPo batteries in parallel is a fire hazard, you could have a higher-charged cell suddenly dump current into a lower-charge cell at a rate much larger than they are designed to handle. reply zitterbewegung 1 hour agoparentprevIf you ran it with one battery would you not have the problem ? reply teraflop 1 hour agorootparentThere's no problem if you use one battery, and there should also be no problem if you use two batteries and charge/discharge them both simultaneously (because then the voltages are matched). The problem shows up when you try to \"hot-swap\" just one of the batteries and replace it with one at a different state of charge, as the README claims you can do. reply fecal_henge 1 minute agorootparentWhat is the expectation here about functionality? They are using some kind of COTS battery system to keep the cost down, but at the consequence of this safety qustion. Should these people expect any buyer to antipate this? Its not really a consumer product after all. I think there is no shortage of battery management ICs, but the number that can arbitrate between external power/battery A/Battery B certainly eliminates 97% on your Digikey parametrics. reply ndsipa_pomu 3 hours agoprevOh great! Another awesome looking cyberdeck that I want to own and will find absolutely no practical use for. I've added myself to the waitlist already. reply IgorPartola 2 hours agoparentSee I do have a use for this kind of thing, but not exactly. I have a few desktop towers and Raspberry Pi devices that sometimes due to upgrades or random acts of Zeus absolutely fail to boot up. I want some ability to connect a keyboard and a screen to these so I can see the actual boot screen. Normally for me this involves lugging the device to my office and connecting it to my office monitor and keyboard which is highly inconvenient given that some are in the attic. Instead I want a small screen and keyboard in one device I can hook up to an HDMI or VGA or mini HDMI or just a serial port + USB for keyboard. Something lightweight I can carry anywhere. And no that doesn’t need its own computer but it might be nice to have one to be able to hook it up to the network and download and transfer files to the broken machine or be able to download and quickly boot off a rescue image or some such. These are rare enough problems that I don’t actually bother building a device like that but every time they do happen I wish I did. reply password4321 2 hours agorootparentI too have this use case troubleshooting headless computers around the house. I saw an ad for https://www.aurga.com and bought one for $84. It connects to an app on my Android phone as display, keyboard, and mouse. Minor discussion 7 months ago: https://news.ycombinator.com/item?id=38609526 Long ago I bought a mini keyboard + mouse combo for input; the custom wireless USB dongle edition I have (strongly preferred over Bluetooth when troubleshooting) is no longer for sale. https://amzn.com/dp/B00I5SW8MC reply shepherdjerred 2 hours agorootparentLogitech has similar devices. This isn't the one I own, but it's close. https://www.amazon.com/Logitech-Wireless-Keyboard-Touchpad-P... reply rft 1 hour agorootparentI have that keyboard and gifted one to my parents. Our use case is the odd chance you need to input text or use a browser on a Smart TV. Works so much faster than the on screen keyboard. With many Smart TVs just being Android under the hood, it just works. I find for server troubleshooting, I usually have no problem grabbing a random USB keyboard. The bigger problem is finding a screen at a convenient location and connecting that one. It often was easier to carry my server to the screen instead of the other way. On the topic of niche input methods, I also have an \"air mouse\" [1] with a full keyboard on the back for my Kodi system or when connecting my desktop to the TV. I essentially never need to use it, but it has come in handy. [1] https://www.amazon.de/gp/product/B0B1HKWFQV reply CitrusFruits 1 hour agorootparentprevI have one of these and it's great for this sort of thing. The whole keyboard runs off one AA battery which lasts forever, and it even has a storage spot for the USB dongle. reply rft 2 hours agorootparentprevThis looks quite interesting, thanks for the link. It does seem to require a native viewer instead of having a web interface. I would really prefer just a website like the PiKVM. Might still get it. I have to do an off-topic rant though. The marketing page you linked to does not really state what this device does. It has a nice look into the case and a lot of buzzwords, but nothing like a small section with \"HDMI Input\" or \"USB keyboard emulation\". Even the shop page is somewhat light on details, but it at least shows (in GIFs only) that it works as a display and has a USB port. If I wasn't given your comment as context, I would likely not have gotten the use case and closed the tab. Based on the form factor being similar to a Fire TV stick etc. I would have assumed you plug it into a Hotel TV or similar to work on that. EDIT: Saw your edit now and I think it is kind of funny that the old HN thread is also mentioning the marketing. reply password4321 1 hour agorootparentprevOn the other end of the spectrum, searching https://hn.algolia.com/?query=handheld%20comments%3E0&sort=b... I found the $1000 8\" GPD Pocket 3 which supports Windows 11 and KVM discussed in 2021: https://news.ycombinator.com/item?id=29110603 https://gpd.hk/gpdpocket3 reply walterbell 1 hour agorootparentpreviPad + HDMI input dongle can be an HDMI monitor. iPad + GetConsole app + Redpark [1] USB-serial cable = serial console. The missing piece is USB keyboard emulation, but serial->arduino [2] might work. iPad + $40 RISC-V piKVM-alike [3] is another option. [1] https://redpark.com/usb-c-serial-cable [2] https://www.sjoerdlangkemper.nl/2022/11/16/running-etherkey-on-arduino-leonardo/ [3] https://sipeed.com/nanokvm reply shepherdjerred 2 hours agorootparentprevI have this exact same problem. I wonder how they solve this issue in datacenters and if that solution could apply to the home setting. reply T3OU-736 2 hours agorootparentprevI _think_ you are describing (minus the screen) what a PiKVM and similar would give you. reply rft 2 hours agorootparentI can confirm that getting a PiKVM has very much eliminated lugging around my server or a screen. Having some form of display input would be the one feature I would wish to add if given the choice. Not having HDMI-In, e.g. via capture card, makes sense in this form factor and power budget, but would make this an instant buy for me. I would really enjoy having a small, very portable device to debug things with. I recently got linked to a CCTV tester [1] that at least handles the display part. Sadly it does not seem to have keyboard emulation. It might be possible to hack this in as this is an Android tablet at its core and the USB controller might support gadget mode. [1] https://www.rsrteng.com/products/ipc-9800movtadhs-pro reply GardenLetter27 2 hours agoprevIt looks cool, but I've found the Steam Deck is the only portable computer that's versatile enough for me to actually use for all sorts of different stuff. reply johnklos 1 hour agoprevI'd love one of these! I just built a portable enclosure with a charge controller, USB hub, ethernet and four 18650 batteries. While The Hackberry Pi Zero would've been a lot easier (assuming I'd've just bought one instead of making it myself), the only downside is the battery life. My application is for having a server that travels with me and is on 100% of the time, sometimes running on battery for hours at a time. This, though, is so much smaller... It's definitely something to consider when they're shipping. Edit: just read, \"Main Processor: Only compaticable with Raspberry pi zero 2w.\" I wonder why it's not compatible with the original Zero. Is it just that the drivers and preinstalled OS are 64 bit? Even though the 2W is more performant per watt, it still takes more absolute power. Hmmm. reply mafuyu 1 hour agoprevMy pet peeve with RasPi for these types of handheld projects is that they don't support suspend, and don't have a true poweroff state. Even in poweroff, they sit there consuming a bunch of current. Beepy is a similar project that uses a RasPi Zero, and their approach is to cut power to the RasPi entirely with a management MCU. On my Beepy, I switched to a Radxa Zero instead and ported over any relevant kernel modules and device tree overlays, because it has an Amlogic SoC that actually supports suspend. reply jll29 1 hour agoprevI want my Blackberry back badly, and this project is giving me hope. The case it a bit too big, there are still battery issues, and of course a 5G card + microphone + loudspeaker need to be added. But perhaps the day will come that I can roll that wheel to view my emails again, use that excellent small keyboard to reply without having to touch glass. reply neon_me 3 hours agoprevWould love to see \"real phone\" version w gsm/lte module and at least a day lasting battery (optimization) reply oneplane 3 hours agoparentIsn't that what the PinePhone and Librem 5 are? They don't have an embedded physical keyboard and do have a touchscreen, so the physical features are slightly different, but otherwise they are still a mobile ARM linux computer. reply Y_Y 2 hours agorootparentThe touchscreen is a big difference though. You need to run some kind of graphical environment to handle the touch input and then it's slow and you have a crappy keyboard. I love my pinephone, but even with sxmo I find it unresponsive and hard.to work on. The keyboard shell for the pinephone is good, but changes the form factor then. reply tetris11 1 hour agorootparentNokia N900 has a pinephone port reply wifipunk 3 hours agoprevI've been wanting to build my own handheld ever since I picked up a 3d printer so the last few months I've been checking these builds out. The blackberry keyboard is my favorite part of the build, definitely going to do the same for mine. Looks great with the casing. reply deepspace 2 hours agoparentI am working on the same kind of thing. For me the ideal keybaord/screen combination was the Keyboard Featherwing from Adafruit https://www.adafruit.com/product/4818 . Unfortunately, it is a discontinued product. I managed to snag one of the last ones, but I am reluctant to use something that I cannot get any more of. reply anotherjesse 4 hours agoprevHas anyone built something like this in the hiptop/sidekick format? If not, this might be a good second option for hacking together a chat device for LLMs with notes I had been thinking about using https://www.lilygo.cc/products/t-deck as a base - but prefer using Linux to microcontrollers reply garciasn 3 hours agoparentI miss my Hiptop(s). Nothing has come close to that experience since. I could carry on 10 AIM conversations, IRC, and be doing browsing and email while typing at ~100 WPM. reply afandian 4 hours agoprevI bought the Bluetooth keyboard from this maker, ZitaoTech. The fit and finish was excellent. Highly recommended. reply atrus 5 hours agoprevThis is one of the very few Cyberdeck kinda things that looks like it could be actually useful. I love it! reply bloopernova 4 hours agoparentI have a vague idea of what my ideal Cyberdeck would be, no idea if there's anything like this already: One of those super-wide small screens, 1920x720 or thereabouts, with the screen split into 2 terminals. Since I'm wishing, I'd also like that screen to have a 300 to 600ppi e-ink screen built in to a layer, so that when the colour screen is off, the e-ink is visible. A PC, x86_64 or arm64, built into the screen, with lots of ports, IO, compatible with Pi hats/shields. For extra coolness, a pluggable system like Framework so if someone wants a real RS232 port, they can get one. With USB-C power so I can use any powerbank or other compatible power supply. A Keychron lightweight Alice-style keyboard, folding a bonus, QMK mandatory, standard bluetooth and/or USB. reply zitterbewegung 4 hours agoprevWow this is amazing it’s the best cyber deck I have ever seen or would consider using. I wonder if you could get rid of one battery and shove in a 4g LTE modem connected to a usb port. reply rogerpeters 2 hours agoprevAre there any compact 4G/5G boards which can be plugged into this for outside connectivity? Last I looked, these breakout boards were far too cumbersome. reply forinti 2 hours agoprevIt's nice, but I would use something with a bit more memory. An Orange Pi Zero 2W with 4GB maybe. 512MB nowadays is only practical if you don't use a GUI. reply notpeter 4 hours agoprevVery similar to the Beepberry. Exciting to see someone else building into that form factor. Also love to fun to see the Nokia BL-5C battery (originally introduced in the Nokia 3650 in 2003) still alive and kicking 20years later. https://blog.beeper.com/2023/05/16/beeper-x-sqmfi-beepberry/ reply jsheard 4 hours agoparentThat appears to have been renamed to the Beepy, and the product page now has the repurposed Blackberry keyboard blurred out. Did whoever owns the corpse of Blackberry go after them for trademark infringement? https://beepy.sqfmi.com/ reply dchuk 4 hours agoprevThis form factor is so tempting. I’ve gotten close to pulling the trigger on the minimal phone like 5 times but just don’t know if I can actually reasonably switch from my iPhone and not end up annoyed with the change (https://www.minimalcompany.com/). But a calm, keyboard oriented device just seems great. reply smashah 4 hours agoparentThe N900 (or N810) form factor is also great, especially for CLI commands/coding. There was a team trying to bring it back to life (neo900) reply ntw1103 4 hours agoprevLooks super awesome. I've been slowly working towards building pretty much the same thing, but haven't had enough time to finish. I added myself to the wait list. Intend to purchase 3 if I'm able to. Getting everything into such a nice packet is very cool. reply keheliya 4 hours agoprevAmazing! How hard will it be to replace the screen to an eInk one similar to the beepberry/beepy? I love everything except the screen, and I assume eInk will be the perfect match considering the terminal and power consumption. reply bee_rider 4 hours agoprevIt looks neat. It is a shame, though, to use an RPi and not exploit the GPIO pins a little more. Maybe add a slot on the side to fit some probes or something? I guess the Pi is all digital anyway so maybe the pins are not as interesting… reply boguscoder 4 hours agoparentPins are still pretty handy though. Tangential to the OPs use case, but I use my Zero 2 as a debug probe (with openocd) for few MCUs (mostly Pi Pico), and it comes out $$$ cheaper than JLink’s official one and analogs reply amelius 4 hours agoparentprevIt has DAC/ADC ports, I suppose. reply rbanffy 4 hours agoprevIf it used the Blackberry Passport format (and screen) I'd love it even more. reply amelius 4 hours agoprevIs there a page where they describe where they sourced the components, e.g. screen and keyboard? reply walterbell 3 hours agoparentAmazon has vendors listing BB Q10 parts, including keyboard and LCD for < $20, https://www.amazon.com/s?k=blackberry+q10+keyboard+replaceme... Fairberry has a PCB design for adding Q10 keyboard to any mobile phone with a USB port, https://github.com/Dakkaron/Fairberry reply marcodiego 4 hours agoprevI wonder if simply adding one of these ESP with GSM builtin would turn this into a practical linux phone. reply hawski 2 hours agoparentUnfortunately advertised battery life isn't practical. Though maybe with software enchantments it could get there. reply wildzzz 4 hours agoparentprevThe GPIO port is accessible under the back cover so I could easily see add-on modules that could piggyback on. Design a small backpack to use the existing latch, add some tiny pogo pins and the module could be easily swapped out. A lorawan transceiver and a GPS receiver would be an excellent pair. reply prmoustache 4 hours agoparentprevYou'd need an additionnal micro and speaker, or at least some usb-c headset but yeah this give some ideas. Also battery life would probably sink. reply 83457 3 hours agoprevLooks like it could be a great pocket device for pico-8 development. reply grugagag 3 hours agoparentThat’s my thoughts as well. I ordered a uConsole from clockworkPI, long waitlist there. This is tempting me again. I feel this may have even better ergonomic qualitty for my personal taste and appeara more portable. reply 83457 3 hours agorootparentEvery time I see a little game/dev device with a square screen I think about pico-8. The devterm looks like it could be a good device too as you could have pico-8 running on one side with code editor taking up the rest of the screen. https://www.youtube.com/watch?v=5XC5lC9nGWM reply ngcc_hk 1 hour agorootparentprevOrder one. Dead on arrival. Gave up. Now may think to savage at least the rpi … reply grugagag 21 minutes agorootparentSorry to hear. How many months after you ordered it did you actually receive it? Im taking a gamble on this but wasn’t aware they do no testing before shipping. reply swores 4 hours agoprevI wasn't expecting to see buy now links, so I wasn't too disappointed when I did see them but found they both say out of stock - was completely ready to impulse buy the BB Q20 keyboard version (or either, really!) and hope that having registered to hear it more being sold I'll be able to get one. I'd almost be tempted to try to put one together myself, but it's not something I'd find particularly easy and there's other stuff I'd rather spend time on. But might be tempted... reply anonzzzies 4 hours agoprevShame it's not available for purchase at the moment. Would like one. reply joemazerino 3 hours agoprevAwesome work. Know any surplus stores that carry BB keyboards? reply jejeyyy77 1 hour agoprevnice! reply idiotsecant 3 hours agoprevI want this so bad. reply starik36 3 hours agoprevThere is also the Tindie Null 2 kit - it's built around Rapsberry Pi Zero 2W. I picked one up several years ago and built a gameboy replacement of sorts. It was a lot of fun. Lots of soldering. https://www.tindie.com/products/ampersand/null-2-kit/ reply more_corn 5 hours agoprev [–] This is super neat! Well done. Very well done. I love the dual battery, hard power switch, good keyboard. I know how hard it is to do these right and I’m impressed. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Hackberry-Pi_Zero is a handheld Linux terminal built using a Raspberry Pi Zero 2W, featuring a 4\" 720x720 TFT display and a BlackBerry keyboard.",
      "Key features include dual swappable Nokia BL-5C batteries, customizable keymap via VIAL, and support for multiple operating systems like Kali and Raspberry Pi OS.",
      "The device offers 3 USB 2.0 ports, a Stemma I2C port, and a TF card slot, making it versatile for various applications."
    ],
    "commentSummary": [
      "The Hackberry-Pi_Zero, a handheld Linux terminal using Raspberry Pi Zero 2W, has sparked interest for its design and potential use cases, particularly in troubleshooting headless computers and portable computing.",
      "Key concerns include the safety of the \"dual battery\" feature, with multiple users highlighting the fire hazard of connecting LiPo batteries in parallel and the complexity of modifying the IP5306 IC to handle two batteries separately.",
      "Users are also discussing alternatives and enhancements, such as using eInk screens for better power consumption, integrating 4G/5G connectivity, and leveraging GPIO pins for additional functionality."
    ],
    "points": 312,
    "commentCount": 67,
    "retryCount": 0,
    "time": 1722605677
  },
  {
    "id": 41135671,
    "title": "Peerfetch – Peer-to-Peer HTTP over WebRTC",
    "originLink": "https://github.com/ambianic/peerfetch",
    "originBody": "peerfetch Peer-to-peer HTTP over WebRTC. Implements an http client wrapper (similar to HTML fetch) and a corresponding server side HTTP proxy over WebRTC DataChannel. Allows direct secure access from a web browser to edge devices (IoT or servers) hidden behind a firewall. Highlights: Excutes in safe application space (no sudo) End to end encryption No custom VPN setup needed No cloud middleman for data tunneling No dynamic DNS service required No custom firewall rules required Programming language agnostic. (Currently available in JavaScript and Python) Hello World example See this README for a step by step Hello World example. How it works For an in-depth technical discussion and project background, see this blog post. Hands-on Workshop Here is the recording of a peerfetch workshop hosted by Python Austin. Use cases: Direct user access from a web app to private home security camera without sharing footage with a cloud provider. IoT device mesh with direct p2p communication. Personal web apps can share data directly (files, notes, photos) only with the end user without exposing a public IP address. Federated learning - ML models can train on local user data and share learned states directly with each other without a centralized model aggregation server. Used by Ambianic UI PWA Ambianic Edge",
    "commentLink": "https://news.ycombinator.com/item?id=41135671",
    "commentBody": "Peerfetch – Peer-to-Peer HTTP over WebRTC (github.com/ambianic)237 points by Vt71fcAqt7 16 hours agohidepastfavorite62 comments tarasglek 12 hours agoDoing http over webrtc is how https://camect.com works to let one access cameras own private server via their ui. They have a centralized bit for auth and then use webrtc and a physical nvr to serve your videos maximally efficiently...so there is low risk of their cloud becoming a financial burden that they cancel ala google nest cams It's a super nice architecture reply kabes 12 hours agoparentSo from your explanation I get that they use webrtc for videos. But then what do they use http over webrtc for? Do they serve the UI as well over webrtc? reply tarasglek 11 hours agorootparentTheir ui is also hosted on the nvr, they serve ui assets over webrtc reply londons_explore 7 hours agoparentprev> have a centralized bit for auth Theoretically they could get the camera itself do auth, and then the server becomes fully 'dumb', and need not even be service specific. reply tehlike 2 hours agorootparentOauth is nice and convenient. reply Saris 6 hours agoparentprevSounds kind of similar to Frigate but packaged up ready to go, neat. reply tehlike 2 hours agorootparentI am an early backer and have been using it for few years bow. Camect is great. reply sitkack 12 hours agoprevhttps://github.com/webtorrent/webtorrent https://hn.algolia.com/?dateRange=all&page=0&prefix=false&qu... reply robertclaus 14 hours agoprevClever idea. Begs the question of why you would use http if you already have a bidirectional webRTC connection, but I guess it depends on the application. reply ongy 11 hours agoparentProvide a server on-prem at the customer, but allow them a hybrid access to the system. Via cloud when necessary, \"local\" (by WebRTC) when possible. While we could just open a local port, using the cloud to arbitrate gives us a common product vision, and proper authN/authZ. Also allows us to pull the latency down to single digit milliseconds. The regional relays are double digit. When we use relays that aren't regional it's a couple hundred. reply throwawaymaths 14 hours agoparentprevYou can securely serve a webpage from a server behind NAT without creating a VPN and without https certificated reply dlenski 14 hours agorootparentI suppose the persistence of IPv4 has broken all of our brains, but with IPv6 you can just Not Have NAT, and just have normal end-to-end connectivity to any random box in your home from outside. (And yes, I do this. Works great.) reply klabb3 10 hours agorootparentIPv6 can get rid of NAT which is one of the most annoying hurdles. It unlocks the type of use case where technical people can host something from home for fun, although many can’t access it because both parties need ipv6. But if you set your sights higher and want to build true p2p apps for non-techies, or if you want “roaming” servers (say an FTP server on your laptop), there are more obstacles than NAT, in practice: - Opening up ports in both a residential router and sometimes the OS or 3p firewall. Most people don’t know what a port is. - DNS & certs which require a domain name and a fixed connection (if the peer moves around across networks, eg a laptop or phone, DNS is not responsive enough) reply concrete_head 13 hours agorootparentprevWould you be willing to share a few details on how you do this. And how do you prevent someone spamming your devices or is the risk so low you don't care? Unfortunately most ISP's in my area don't dish out IPv6 addresses without ridiculous monthly charges. I hope one day it becomes more commonplace. reply jeroenhd 10 hours agorootparent> Unfortunately most ISP's in my area don't dish out IPv6 addresses without ridiculous monthly charges If you've got an IPv4 address that responds to ICMP, HE's https://tunnelbroker.net/ offers free IPv6 ranges (a bunch of /64s and a /48) for free. You can configure a tunnel to work through many routers, but with some setup you could also have something like a Raspberry Pi announce itself as an IPv6 router. Sites like Netflix treat HE tunnels as VPNs, though, so if you run into weird playback errors, consider configuring your device's DNS server/network not to use IPv6 for that. As for your questions: > how you do this Open port 8888 to (prefix):abcd:ef01:2345:56, or whatever IP your device obtains, in your firewall. It's the same process as with IPv4, except you can use the same port on multiple devices. > And how do you prevent someone spamming your devices or is the risk so low you don't care? While some services have started scanning IPv6, a home network from a semi-competent ISP will contain _at least_ 2^64 IPv6 addresses. Scanning the entire IPv6 network is unfeasible for most automated scanners. reply ffsm8 11 hours agorootparentprev> And how do you prevent someone spamming your devices or is the risk so low you don't care? That's the job of a firewall and is unchanged between ipv4 and IPv6. Theyre both equally vulnerable to denial of service attacks reply justsomehnguy 8 hours agorootparentprevThey need to find them first. reply immibis 7 hours agorootparentprevYou just plug a device into your network. The device acquires an address. You can type that address into another device on the Internet to attempt a connection to your device. If your device is running a web server that allows access from the whole Internet, this brings up the home page. If you have a firewall, tell the firewall to enable connections to that web server from the whole internet. What do you mean by spamming? People are scanning the Internet the whole time to see what's there, and it isn't a threat unless you are doing something terribly insecure. Scanning IPv6 is impossible in practice anyway, due to the high number of available addresses. reply ycombinatrix 27 minutes agorootparentprevThis supports UDP/unreliable data streams in the browser tho. reply throwawaymaths 13 hours agorootparentprevThere's something nice about being anonymous behind a communal v4 gateway. Also can you get an tls cert for a ipv6 number address? Or are you punching through using only ssh or unencrypted stuff? reply dgl 12 hours agorootparent> There's something nice about being anonymous behind a communal v4 gateway. IPv6 lets you do this -- nearly every client will use privacy addressing, so your (default) source address rotates daily. However you can still connect to the machine on its main (non-privacy protected) IPv6 address. reply chgs 11 hours agorootparentThe /64 doesn’t change, it’s unique to your network. It’s broadly equivelent of the /32 you get. CGNat adds a layer of privacy that a public /32 (ipv4) or /64 (ipv6) doesn’t give. reply klabb3 10 hours agorootparentTangentially, these “privacy” addresses are such an ipv6-ism of small theoretical value at the expense of extra complexity and noise. If ipv6 had been “ipv4 but now with 100% more bits”, I suspect we would have come a lot further in global deployments. reply immibis 7 hours agorootparentIPv6 literally is that, plus a few pretty minor changes. SLAAC? Literally a hack that accidentally caught on because some vendor implemented it sooner than DHCPv6 for some reason. It was intended that everyone would use DHCP just like before. And that's the biggest difference from v4 other than the address format. reply yjftsjthsd-h 3 hours agorootparentOkay, but that's not a minor change. Regardless of why it caught on, SLAAC completely changes how addresses are handed out, and is in many/most environments a requirement if for no other reason than that Android explicitly refuses to implement DHCPv6 ( https://issuetracker.google.com/issues/36949085 ). And once SLAAC is in play, suddenly privacy problems come up and you kind of need to jump through the extra hoops to avoid, y'know, putting your MAC address in every single packet you send over the public internet. reply klabb3 3 hours agorootparentprev> plus a few pretty minor changes They might sound minor but in practice they violate assumptions that are really crucial for implementations. Everyone who deals with addresses must make decisions about how and what to do in face of these quirks. Another example is the zone identifier string. So how do you store them efficiently in memory or a db? Golang did a really clever thing with netip but the implementation was not easy. Oh well maybe we can always ignore and strip it? Maybe, depends on the use case. The point is going from exactly 32 bit to 128 bit + sometimes maybe a variable length string (max length, encoding, allowed chars?) is not a small change for something so important and ubiquitous as ip. reply oarsinsync 41 minutes agorootparentprev> SLAAC? Literally a hack that accidentally caught on because some vendor implemented it sooner than DHCPv6 for some reason. The history I recall is very much a academics designing theoretical standards vs operators who actually implement the damn things. The academics designed the standards around the use of SLAAC deliberately and intentionally. DHCPv6 was the ‘hack’ that operators implemented after the fact. I’m sure there’s an RFC somewhere that’ll prove this one way or another, if anyone else reading this cares enough to determine for sure (Duty Calls). reply justsomehnguy 8 hours agorootparentprevUntill you can access ISP logs you can never tell anything more than 'this client accessed from $ISP from, probably, maybe, $CITY' reply _zoltan_ 11 hours agorootparentprevYou miss the point: that /56 or /64 is still assigned to you, while a NAT gw might serve 1000s of people. reply immibis 7 hours agorootparentprevI think they mean CGNAT. My mobile phone connection goes through CGNAT so it's impossible to identify my individual phone by its IPv4 address, whereas my home address uniquely identifies my home, at least for a limited period of time. Sometimes this is good and sometimes this is bad. Sometimes you want to be anonymous and sometimes you want to be delineated from the people who are being anonymous. reply fulafel 13 hours agorootparentprevThough WebRTC works great with IPv6 too. Then the use case would be running it on a server that has incoming connections firewalled. reply hcfman 13 hours agorootparentprevThere’s lots of ipv6 available. But it’s not everywhere yet reply dingi 13 hours agorootparentprevI don't think that's possible without a jump server. If all peers are NATed, there is no way doing p2p without a jump server. WebRTC is a giant rabbit hole itself. reply evbogue 13 hours agoparentprevThis idea makes me want cjdns and/or yggdrasil over websockets. reply immibis 7 hours agorootparentDon't you want static peering setup for them? reply whitehexagon 13 hours agoprevIs there a way to do this without the signaling server? reply iod 9 hours agoparentWebtorrent Use a free signalling server from the webtorrent community. You can skip the torrent part of the implementation and just use the signalling, it's awesome. You can use a libraries like: https://github.com/webtorrent/bittorrent-tracker https://github.com/subins2000/p2pt to get started. For me, I found the protocol is simple enough where I just use small vanilla javascipt implementation to talk to the websocket servers to generate the signalling messages. I wish more people knew about this and realize how easy it can be to bring WebRTC to their applications. List of some free webtorrent trackers: wss://tracker.openwebtorrent.com wss://tracker.files.fm:7073 wss://tracker.webtorrent.dev ---> Usage stats for the last one: https://tracker.webtorrent.dev Some free stun servers for NAT traversal: stun:stun.cloudflare.com stun:stun.l.google.com:19302 reply nhkcode 6 hours agorootparentThis is super cool and almost makes it possible building PWAs that only need a dumb http server to deliver the app as a bunch of static files and still allow users to synchronize data between their devices. It still depends on the tracker but if the user could change the tracker it sounds like it's currently the best way to get clients to communicate with each other without depending on a server provided by the PWA. reply catapart 7 hours agorootparentprevThank you for this! I knew this shit was done by someone already and I've spent two years resisting the urge to re-invent this wheel. p2pt is exactly what I knew was possible and have been looking for! reply turblety 12 hours agoparentprevI think the closest you might get is something like the bittorrent dht. There are still bootstrap servers for the first few connections, but there's really no getting away from that, right? https://github.com/webtorrent/bittorrent-dht reply tfolbrecht 12 hours agoparentprevNot with the three major browsers and NAT unfortunately. https://developer.mozilla.org/en-US/docs/Web/API/WebRTC_API/... reply dmotz 3 hours agoparentprevYou might be interested in my side project Trystero https://github.com/dmotz/trystero It abstracts away the work of signaling and connects peers via open decentralized networks like BitTorrent, Nostr, MQTT, IPFS, etc. reply fullspectrumdev 1 hour agorootparentNot had time to read through the docs properly, but would this work for CLI apps (Node compiled to an executable?) or similar? The problems this solves look interesting for a few CLI tools I want to build :) reply wuiheerfoj 12 hours agoparentprevcheck out NAT hole-punching in libp2p: https://docs.libp2p.io/concepts/nat/hole-punching/ scroll down a bit for the STUNless/TURNless bit reply Sean-Der 7 hours agoparentprevYep! If you do one non-browser WebRTC agents https://github.com/pion/offline-browser-communication This could be possible browser to browser! I don’t think that has ever been an official use case reply thrdbndndn 10 hours agoprev(Aside) speaking of WebRTC, but is there any solution to record videos that is done by webRTC? There are already more than enough tools that can record HLS and Dash, but I haven't find anything, not even PoC that can record video streams transited via WebRTC (e.g. agora.io). reply HyprMusic 10 hours agoparenthttps://recordrtc.org/ should be able to do it. reply Sean-Der 6 hours agoparentprevDo you want this in the browser or a specific language? reply thoronton 10 hours agoprevI don't get it. Where is the signaling server and how is it working? reply etherdream 10 hours agoprevI have tried this idea before, combining Service Worker to implement a decentralized website. reply meiraleal 4 hours agoprevIt is really annoying when someone posts an interesting project and HN has a big discussion but when I get to try to lib, it is unmaintained and the last update was 3 years ago. There were great recommendations in this thread tho, thanks a lot! This one looks good: https://github.com/subins2000/p2pt reply evbogue 4 hours agoparentIf we're talking about great p2p WebRTC libraries, try Trystero: https://github.com/dmotz/trystero reply meiraleal 3 hours agorootparentWow, really impressive project! Thanks. reply jiehong 9 hours agoprevNice! Although, an alternative is something like Tailscale. reply localfirst 3 hours agoprevgot excited but the repo hasn't been updated for over 3 years. reply lerpgame 12 hours agoprev [–] its advertising that it’s secure e2e even behind firewall/etc but that’s not true because webrtc will fallback to using TURN server to relay when other methods fail which will break the encryption, just fyi. reply WatchDog 11 hours agoparentWebRTC won’t use TURN unless it’s explicitly configured with a TURN server. Even if it did use a TURN server webrtc is still e2e encrypted. You need to trust the signalling server though. This library seems to do a few other things, which maybe reduces the trust in the signalling server, but I didn’t really read it in enough detail to comment on it. reply Sean-Der 6 hours agoparentprevConnection is E2E encrypted when using TURN. Using TURN has no negative impact on security. The TURN server can see the size/src/dst so that has a privacy implication! reply lerpgame 9 hours agoparentprevi was wrong actually, it doesn’t weaken security as long as the data is encrypted either using DLTS or application layer encryption, please ignore my comment lol. reply strbean 12 hours agoparentprev [–] You can pass configuration to disable ICE entirely. Looks like it's using PeerJS, which defaults to a config of using a Google STUN server and no TURN servers. Not sure if using a STUN server compromises the E2E in some way? reply server_man3000 12 hours agorootparent [–] Why would STUN compromise e2e? STUN just returns your IP reply strbean 11 hours agorootparent [–] I just didn't want to speculate, as I'm not familiar with the security considerations here. But, thinking about it a bit, couldn't a compromised STUN server establish a MITM by lying to you about your IP, and then relaying to you? This old HN comment describes it: https://news.ycombinator.com/item?id=11192610 I don't know if this would break the E2EE here (although if it wouldn't, I'm not sure how a TURN server would either, as that's just a baked in MITM). reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Peerfetch is a peer-to-peer HTTP solution over WebRTC, allowing direct, secure access from web browsers to edge devices behind firewalls.",
      "It features end-to-end encryption, requires no custom VPN setup, cloud middleman, dynamic DNS service, or custom firewall rules, and is available in JavaScript and Python.",
      "Use cases include direct access to private home security cameras, IoT device mesh communication, personal web apps sharing data without a public IP, and federated learning with local user data."
    ],
    "commentSummary": [
      "Peerfetch introduces Peer-to-Peer HTTP over WebRTC, enabling direct communication between browsers without relying on traditional servers.",
      "This approach reduces cloud dependency and enhances privacy by allowing secure data transfer directly between devices.",
      "The project has garnered significant interest due to its potential to simplify web communications and improve efficiency, despite the repository not being updated for over three years."
    ],
    "points": 237,
    "commentCount": 62,
    "retryCount": 0,
    "time": 1722566684
  },
  {
    "id": 41135363,
    "title": "YC closes deal with Google for dedicated compute cluster for AI startups",
    "originLink": "https://techcrunch.com/2024/08/01/google-cloud-now-has-a-dedicated-cluster-of-nvidia-gpus-for-y-combinator-startups/",
    "originBody": "Login Search Search Startups Venture Apple Security AI Apps Events Startup Battlefield More Close Submenu Fintech Cloud Computing Layoffs Hardware Google Microsoft Transportation EVs Meta Instagram Amazon TikTok Newsletters Podcasts Partner Content Crunchboard Jobs Contact Us Startups Google Cloud now has a dedicated cluster of Nvidia GPUs for Y Combinator startups Maxwell Zeff 6:00 AM PDT • August 1, 2024 Comment Image Credits: Harry Murphy/Sportsfile for Web Summit / Getty Images Google Cloud is giving Y Combinator startups access to a dedicated, subsidized cluster of Nvidia graphics processing units and Google tensor processing units to build AI models. It’s part of Google Cloud’s effort to cozy up with promising early-stage AI startups, in hopes some of them will evolve into massive, compute-hungry businesses. “We want to surround them with a lot of love and warmth early in their life cycle so they get familiarized with building and working on the Google Cloud Platform,” said general manager for Google Cloud’s startups and AI business, James Lee, in an interview with TechCrunch. “As they stick around, we grow as they grow, and we become a partner of theirs throughout their life cycle.” Specifically, Google will provide a dedicated cluster with priority access for YC’s Summer 2024 startups, along with $350,000 in cloud credits over two years for each participating startup. The idea is that a future unicorn will fall in love with building on Google Cloud. Five percent of Y Combinator startups over the last 18 years have become unicorns with billion-dollar-plus valuations, YC group partner Diana Hu tells TechCrunch, so it’s a decent bet for Google to make on this partnership. “There’s a lot of excitement that the next generation of startups will probably not just unicorn, but decacorn, and they’re getting built as we speak,” said Hu. “Cloud providers are still catching up in terms of how to price them, but they do know if you catch them early on, you’re going to ride the wave with them.” On the flip side, Y Combinator says it can attract more AI startups to apply by offering generous compute resources alongside its investment and guidance. For early-stage AI startups, Hu says one of the most common issues she hears is that startups are compute-restrained. Large enterprises are able to strike multi-year, massive deals with cloud providers for GPU access, but small startups are often left out to dry. She says partnerships like these go a long way, especially when you have a dedicated cluster — that’s particularly important for training AI models. “For GPU and AI workloads, they’re more like high performance computing workloads in batches. You don’t need the server running all the time, but you need a lot of them in a spiky workload,” said Hu. “So we have a dedicated cluster that YC companies can just use.” As part of the partnership, Google will also offer YC startups $12,000 in Enhanced Support credits and a free year of Google Workspace Business Plus. YC startups can also connect with Google’s internal AI experts through monthly office hours. Startup accelerators and venture capital firms are offering GPU clusters more and more these days. Andreessen Horowitz reportedly has a stash of 20,000 GPUs to attract AI startups. Google Cloud and Y Combinator would not reveal the exact number in this deal, but Hu says it’s sufficient for YC’s foundation model companies to train models on. More TechCrunch Get the industry’s biggest tech news Explore all newsletters TechCrunch Daily News Every weekday and Sunday, you can get the best of TechCrunch’s coverage. Add TechCrunch Daily News to your subscription choices Startups Weekly Startups are the core of TechCrunch, so get our best coverage delivered weekly. Add Startups Weekly to your subscription choices TechCrunch Fintech The latest Fintech news and analysis, delivered every Tuesday. Add TechCrunch Fintech to your subscription choices TechCrunch Mobility TechCrunch Mobility is your destination for transportation news and insight. Add TechCrunch Mobility to your subscription choices No newsletters selected No newsletters Email address (required) Subscribe By submitting your email, you agree to our Terms and Privacy Notice. Tags AI, AI model, Exclusive, Generative AI, Google, google cloud, nvidia, Startups, TC, Y Combinator Startups Acquiring AI talent wholesale Marina Temkin 39 mins ago Welcome to Startups Weekly — your weekly recap of everything you can’t miss from the world of startups. This week we are looking at acquisitions of small startups, two new… AI Character.AI CEO Noam Shazeer returns to Google Ivan Mehta 52 mins ago In a big move, Character.AI co-founder and CEO CEO Noam Shazeer is returning to Google after leaving the company in October 2021 to found the a16z-backed startup. In his previous… Climate Adept Materials’ dehumidifying paint was inspired by trees and semiconductors Tim De Chant 58 mins ago The startup developed a two-material system that helps homes self-regulate their internal humidity. Apps Yelp’s lack of transparency around API charges angers developers Ivan Mehta 1 hour ago When the developers replied to the July 19 email, Yelp sent a deck of pricing tiers with base pricing starting from $229 per month for a limit of 1,000 API… Featured Article Cloud infrastructure revenue approached $80 billion this quarter The cloud infrastructure market has put the doldrums of 2023 firmly behind it with another big quarter. Revenue continues to grow at a brisk pace, fueled by interest in AI. Synergy Research reports revenue totaled $79 billion for the quarter, up $14.1 billion or 22% from last year. This marked… Ron Miller 2 hours ago Security Pharma giant Cencora is alerting millions about its data breach Zack Whittaker 4 hours ago The pharma giant won’t say how many patients were affected by its February data breach. A count by TechCrunch confirms that over a million people are affected. Transportation Self-driving truck startup Aurora Innovation to sell up to $420M in shares ahead of commercial launch Rebecca Bellan 4 hours ago Self-driving technology company Aurora Innovation is looking to raise hundreds of millions in additional capital as it races toward a driverless commercial launch by the end of 2024. Aurora is… Venture Rediff, once an internet pioneer in India, sells majority stake for $3M Manish Singh 8 hours ago Payments infrastructure firm Infibeam Avenues has acquired a majority 54% stake in Rediff.com for up to $3 million, a dramatic twist of fate for the 28-year-old business that was the… Crypto Terraform Labs co-founder and crypto fugitive Do Kwon set for extradition to South Korea Kate Park 10 hours ago The ruling confirmed an earlier decision in April from the High Court of Podgorica which rejected a request to extradite the crypto fugitive to the United States. Apps Meta’s Threads crosses 200 million active users Ivan Mehta 10 hours ago A day after Meta CEO Mark Zuckerberg talked about his newest social media experiment Threads reaching “almost” 200 million users on the company’s Q2 2024 earnings call, the platform has… TechCrunch Disrupt 2024 Connect with Google Cloud, Aerospace, Qualcomm and more at Disrupt 2024 Cindy Zackney 16 hours ago TechCrunch Disrupt 2024 will be in San Francisco on October 28–30, and we’re already excited! Disrupt brings innovation for every stage of your startup journey, and we could not bring you this… Featured Article A comprehensive list of 2024 tech layoffs The tech layoff wave is still going strong in 2024. Following significant workforce reductions in 2022 and 2023, this year has already seen 60,000 job cuts across 254 companies, according to independent layoffs tracker Layoffs.fyi. Companies like Tesla, Amazon, Google, TikTok, Snap and Microsoft have conducted sizable layoffs in the… Cody Corrall Alyssa Stringer 20 hours ago Enterprise Intel to lay off 15,000 employees Maxwell Zeff 20 hours ago Intel announced it would lay off more than 15% of its staff, or 15,000 employees, in a memo to employees on Thursday. The massive headcount is part of a large… AI AI music startup Suno claims training model on copyrighted music is ‘fair use’ Lauren Forristal 21 hours ago Following the recent lawsuit filed by the Recording Industry Association of America (RIAA) against music generation startups Udio and Suno, Suno admitted in a court filing on Thursday that it did, in… Hardware iPad sales help bail out Apple amid a continued iPhone slide Brian Heater 21 hours ago In spite of a drop for the quarter, iPhone remained Apple’s most important category by a wide margin. Venture How filming a cappella concerts and dance recitals led Northzone’s newest partner Molly Alter to a career in VC Rebecca Szkutak 24 hours ago Molly Alter wears a lot of hats. She’s a mocumentary filmmaker working on a project about an alternate reality where charades is big business. She’s a caesar salad connoisseur and… AI Microsoft now lists OpenAI as a competitor in AI and search Maxwell Zeff 1 day ago Microsoft has a long and tangled history with OpenAI, having invested a reported $13 billion in the ChatGPT maker as part of a long-term partnership. As part of the deal,… Startups Sequoia-backed Knowde raises Series C at a valuation cut Rebecca Szkutak 1 day ago The San Jose-based startup raised $60 million in a round that values it lower than the $500 million valuation it garnered in its most recent round, according to multiple sources. Apps Twitter disappears from Mac App Store Lauren Forristal 1 day ago X (formerly Twitter) can no longer be accessed in the Mac App Store, suggesting that it has been officially delisted. Searches for both “Twitter” and “X” on Apple’s platform no… AI Google brings Gemini-powered search history and Lens to Chrome desktop Ivan Mehta 1 day ago Google Thursday said that it is introducing new Gemini-powered features for Chrome’s desktop version, including Lens for desktop, tab compare for shopping assistance, and natural language integration for search history.… AI Heeyo built an AI chatbot to be a billion kids’ interactive tutor and friend Rebecca Bellan 1 day ago When Xiaoyin Qu was growing up in China, she was obsessed with learning how to build paper airplanes that could do flips in the air. Her parents, though, didn’t have… Space Boeing bleeds another $125M on Starliner program, bringing total losses to $1.6B Aria Alamalhodaei 1 day ago While the company was awarded a massive, $4.2 billion contract to accelerate Starliner development in 2014, it was structured as a “fixed-price” model. Transportation Anthony Levandowski bets on off-road autonomy, Nuro plots a comeback and Applied Intuition gets more investor love Kirsten Korosec 1 day ago Welcome back to TechCrunch Mobility — your central hub for news and insights on the future of transportation. Sign up here for free — just click TechCrunch Mobility! Summer road… Enterprise Google Cloud expands its database portfolio with new AI capabilities Frederic Lardinois 1 day ago Google’s new features include Gemini in BigQuery and Looker to help users with data engineering and analysis. Transportation VC darling Rad Power Bikes hit with another round of layoffs Rebecca Bellan 1 day ago Rad Power Bikes, the Seattle-based e-bike startup that has raised more than $300 million from investors, went through another round of layoffs in July, TechCrunch has exclusively learned. This is… Transportation Why Anthony Levandowski returned to his off-road autonomous vehicle roots with AV startup Pronto Kirsten Korosec 1 day ago Five years ago, as robotaxis and self-driving truck startups were still raking in millions in venture capital, Anthony Levandowski turned to off-road autonomy. Now, that decision — which brought the… Space Vast plans microgravity lab on its Haven-1 private space station Aria Alamalhodaei 1 day ago Commercial space station company Vast is building a private microgravity research lab as part of its wider Haven-1 station plans. The module is set to launch no earlier than the… Startups Google Cloud now has a dedicated cluster of Nvidia GPUs for Y Combinator startups Maxwell Zeff 1 day ago Google Cloud is giving Y Combinator startups access to a dedicated, subsidized cluster of Nvidia graphics processing units and Google tensor processing units to build AI models. It’s part of… Image Credits: Harry Murphy/Sportsfile for Web Summit / Getty Images Startups Open source startup FOSSA is buying StackShare, a site used by 1.5M developers Dominic-Madori Davis 1 day ago StackShare is one of the more popular platforms for developers to discuss, track, and share the tools they use to build applications. Featured Article Indian startups gut valuations ahead of IPO push Ola Electric and FirstCry are set to test investor appetite with public listing, both pricing their shares below their previous valuation asks. Manish Singh 1 day ago About TechCrunch Staff Contact Us Advertise Crunchboard Jobs Site Map Legal Terms of Service Privacy Policy RSS Terms of Use Privacy Placeholder 1 Privacy Placeholder 2 Privacy Placeholder 3 Privacy Placeholder 4 Code of Conduct About Our Ads Trending Tech Topics OpenAI’s Voice Mode Intel Layoffs Apple Intelligence Apple Earnings Microsoft Tech Layoffs ChatGPT Facebook X YouTube Instagram LinkedIn Mastodon Threads © 2024 Yahoo. All rights reserved. Powered by WordPress VIP",
    "commentLink": "https://news.ycombinator.com/item?id=41135363",
    "commentBody": "YC closes deal with Google for dedicated compute cluster for AI startups (techcrunch.com)195 points by Astroboy007 17 hours agohidepastfavorite90 comments zhyder 15 hours agoThis link doesn't indicate the credits are exclusive to YC, seems they're open to all AI startups: https://cloud.google.com/startup/apply reply Astroboy007 15 hours agoparentWhile that is true. They state that they are specifically giving every YC company this deal. So you won’t have to hope that they accept you into their program, once you’re in yc you’re guaranteed it. reply sieabahlpark 14 hours agorootparentHonestly I see this as anti-competitive of Google to award only YC companies this benefit. All, specific, or none. reply sokoloff 4 hours agorootparentI see this as competitive rather than anti-competitive. Google does not have a monopoly position here and is competing to become the supplier to these startups. That’s a well-functioning market, I think. reply eru 13 hours agorootparentprevWhy? Google doesn't have any monopoly on compute clusters, in fact they aren't even the market leader. (And for all we know, Google is willing to offer similar deals to other accelerators in return for some compensation.) reply jgalt212 8 hours agorootparentor to boost cloud revenues. one can argue the half the value prop from Google's perspective of AI in the search bar is to pump of cloud revs. After all, an AI search result probably costs 100x to deliver than the standard one. reply bionhoward 5 hours agorootparentOnly the first time, once the answer is optimized, they can keep it for the next one hundred people reply bruckie 4 hours agorootparentAt least as of 2017, 15% of Google searches were novel (had never been seen before) [0]. Assuming that still holds, and generously assuming that it's free to process the other 85%, 100x of 15% is still a big cost increase. [0] https://searchengineland.com/google-reaffirms-15-searches-ne... reply dartos 6 hours agorootparentprevIt’s specifically YC companies. It’s likely so that GCP can get its hooks in these startups early. reply boringg 3 hours agorootparentIts not likely. It is why they are doing it. reply blitzar 13 hours agoparentprevYC startups given startup status and preapproved for \"Google for Startups Cloud Program\" didn't sound as good. reply YetAnotherNick 13 hours agoparentprev> Google will provide a dedicated cluster with priority access This is the key part. Even with the credits there is a GPU shortage. reply sashank_1509 12 hours agoprevIn a startup I worked we received: 230k Google cloud credits, and 180k AWS credits no questions asked. Especially when your company is pre product and not scaling, these cloud credits allow you to iterate rapidly reply PJones2000 11 hours agoparentWe got AWS credits too, but when we wanted to do some serious ML there were never any machines available. Our contact person at AWS just stopped replying to emails when we raised this. While one shouldn't look a gift horse in the mouth, it was just a waste of time and we had more success elsewhere. reply RileyJames 10 hours agorootparentOur experience exactly. AWS credits are advertised everywhere, but seem difficult to utilise. reply 93po 4 hours agorootparenthttps://scientistseessquirrel.wordpress.com/2019/04/16/for-t... reply sashank_1509 5 hours agorootparentprevWe’ve not had issues getting T4 GPU instances from AWS. We faced difficulties provisioning A100 and AWS is annoying that the 2 tiers are either T4 or directly A100’s I think. We use AWS GPU machines for our CI but for serious ML training workloads we use GCP L4 GPU instances. Even in GCP we couldn’t provision or A or H100 (our quota itself is just 1 GPU of these instances) but we’ve never had issues provisioning L4 GPU’s and I think that’s enough for smaller not LLM Scale Models. For LLM scale startups, it’s tough provisioning GPU’s even if you have money. (We’re based in Bay Area btw) reply playacools 3 hours agorootparentprevDid you try this? We've had good luck using capacity blocks, they always seem to have some A100s and H100s available in the next few days. You can just get them yourself, don't have to wait for someone from AWS to help you. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-capa... reply authorfly 6 hours agorootparentprevSame. But in time, I realise, you don't see 90% of the things that block companies. Startups lose their main marketing channel, their plan for scaling is thwarted by quotas or random API limits that were unexpected, core team members leave. The trick is your strategy and what's in place to survive and turn into those waves when they come in the end. Seems like you did this as you had more success elsewhere. reply wil421 1 hour agorootparentIf your business is dependent on big Tech credits and quotas, you’re going to had a bad time. Maybe even lose your business entirely due to an ELUA change. reply Lucasoato 11 hours agorootparentprevWhat kind of machine weren't you able to find? Were they specific H100 or A100 setups? Were your credits bound to one particular region? reply PJones2000 10 hours agorootparentNo, credits weren't tied to a region but even switching to a few other regions we couldn't get hold of machines. We asked if there was a way to search across all regions so we could switch to where the machines were located. No reply. No A100s or H100s at all. We were just looking for more than 24GB VRAM which is not a big ask. I don't understand the AWS credits; however I noticed they asked a lot of questions about our business model, technology and customers. Draw from that what you will. reply twelve40 10 hours agorootparentCredits or no credits, aren't you looking for those machines just like any other AWS customer? Credits are just to reimburse the expenses after you booked something, no? Means that if I go right now and pay in cash i would expect the same luck. reply PJones2000 9 hours agorootparentPossibly. We've tried at monthly intervals and every time, no machine available. The message we're getting from this is don't built on AWS. reply ZeroCool2u 5 hours agorootparentprevI'm forced to operate in AWS GovCloud for my work and it's the same thing, but even worse. Old instance types and there's barely any of them in there. Mind you, there's two GovCloud regions and the East one is even worse! There's basically nothing outside general compute instance types, so you're really stuck with just the West region. P4's are officially available in only 1 AZ, come in exactly 1 size, and are one of the most expensive instances in the region. P3's (initially released in 2018!) are so hard to come by it's infuriating. Meanwhile we have a horde of AWS reps and they all claim there's availability. Really feels like if you need accelerated compute GCP is the better option these days. At least there you can rewrite in Jax if it comes down to it and opt for TPU's. reply moralestapia 5 hours agorootparentprev>elsewhere Where? reply snihalani 16 hours agoprevprivate equity + public equity = unicorns. Thanks openai for the play. next idea I'd love to see: professors getting grants/cloud credits to teach classes on the gcloud reply fragmede 14 hours agoparent> If you're a faculty member at an eligible institution, you can apply for Google Cloud education credits to teach using Google Cloud. The credits grant you a spending allowance as a Cloud Billing account credit, and can be used for all Google Cloud services https://cloud.google.com/billing/docs/how-to/edu-grants#:~:t.... reply bachmeier 9 hours agorootparentWhen I looked into this before, it had the problem that the student/faculty member had to accept unlimited liability if something goes wrong - and when you're learning, things do go wrong. If a student gets a bill for $50,000, what do you do? reply sashank_1509 5 hours agoparentprevDuring grad school, quite a few professors had access to TPU’s from Google Cloud Research Program. I imagine with LLM scale now, it would be much harder to get access, but still possible if you’re from a big name institution. reply scandox 11 hours agoparentprevIt seems your dystopian nightmares are rather passé reply chazeon 15 hours agoparentprevThis is already happening. reply MattGaiser 15 hours agoparentprevIsn't this pretty standard? As a student I got plenty of cloud credit. reply aussieguy1234 16 hours agoprevhow common is it for venture funds to buy bulk cloud services for use in startups they own/invest in? reply Eridrus 15 hours agoparentI have no idea why people are saying this is common. There are plenty of cloud credits programs for startups from GCP, etc, but they are not funded by VCs, they are sales & marketing programs funded by the cloud vendors. A small minority of VCs (AI Grant, a16z, and now YC) have been using their funds to help startups get access to GPUs specifically for the last year and a bit, but there's no need to do a similar thing for general cloud services where there is no shortage. reply ignoramous 5 hours agorootparent> sales & marketing programs funded by the cloud vendors... The more serious ones have their CEOs do the selling: https://www.youtube.com/watch?v=6nKfFHuouzA / https://ghostarchive.org/varchive/6nKfFHuouzA reply jedberg 13 hours agoparentprevIt's not common, but not unheard of. Nat Friedman and Daniel Gross own a cluster of GPUs that they rent back to their startups for below market rates. They essentially trade GPU time for equity. Index Ventures has a deal with Oracle to provide GPUs at no cost to their startups (they pay the bill). reply leohonexus 11 hours agorootparentLink to the cluster's specs: https://andromeda.ai/ reply hodgesrm 15 hours agoparentprev> how common is it for venture funds to buy bulk cloud services for use in startups they own/invest in? Outside of this article, I've never heard of it. In fact it seems kind of illogical because VCs don't necessarily know which infra tech to invest in. (Not their job.) What VCs will do is connect you with public cloud vendor programs for startups or get you access to favorable discounts that are not generally available for small companies. My company benefited from both of these. Edit: clarity reply wmf 15 hours agorootparentOne upside of a monopoly is that it's obvious which tech to use. reply aleph_minus_one 9 hours agorootparent> One upside of a monopoly is that it's obvious which tech to use. Not in the tech of the monopoly, since disrupting the monopoly enables you huge cost savings (example: in its formation years, Google used of-the-shelf computers hold together by Velcro tape instead of expensive servers by the big vendors). reply warkdarrior 15 hours agorootparentprevGoogle is not a monopoly in Cloud, nor in AI, nor in cloud AI. reply wmf 15 hours agorootparentI meant CUDA. (Although in this case Google is also throwing in TPUs.) reply richardw 13 hours agorootparentprevHere’s another: A16z building a stash of GPU’s: https://www.theinformation.com/articles/andreessen-horowitz-... reply adelpozo 15 hours agoparentprevA16z seems to have bought 20K GPUs to be used by the startups they fund. https://www.theinformation.com/articles/andreessen-horowitz-... (July 9) Sorry for the direct link, couldn’t get archive.is to work with this one. reply stingraycharles 16 hours agoparentprevExtremely common, to the point that all major cloud vendors have special VC programs. reply Astroboy007 16 hours agoparentprevi think A16z has a similar model but I believe they own the servers themselves reply alephnerd 16 hours agoparentprevVery common. All the major CSPs have dedicated Startup and VC GTM teams for this reason. For example, Thoma Bravo's VC fund would give a 10-20% discount on a certain major CSP's compute because of the parent fund's significant stake in that company. reply foolfoolz 14 hours agoparentprevvery common. we had many thousands of dollars in cloud provider credits through our investors reply Narkov 14 hours agorootparentNot sure many VC's are actually spending money to get those credits versus being given them for free as a promotional tool. reply p1esk 16 hours agoprevInteresting, I’d expect Google to offer TPUs, not GPUs. reply ipsum2 16 hours agoparent> Google Cloud is giving Y Combinator startups access to a dedicated, subsidized cluster of Nvidia graphics processing units and Google tensor processing units to build AI models. It's both. reply moneywoes 14 hours agoparentprevwhat’s the difference in practice reply michaelt 9 hours agorootparentAt cloud prices, TPUs are cheaper per FLOP but have much worse library support, leading to much higher upfront engineering costs - and you're locked into Google's cloud. On the other hand, essentially every ML project works out-the-box with nvidia GPUs. There's still vendor lock-in to nvidia, but it's more palatable. If you spend $100k of an ML engineer's time to get FooNet to work on TPU, then the cutting edge advances or you pivot and instead you need BarNet support - you might wish you'd spent that $100k just buying a stack of nvidia GPUs. reply martinald 6 hours agorootparentBut also the cost per FLOP will/has/should come down aggressively over time for nvidia, whereas I doubt Google will do the same for TPUs (as they have lock in). Also the hyperscalers as per usual are far more expensive than others - this is an incomplete list https://getdeploying.com/reference/cloud-gpu/nvidia-h100 - GCP seems to be around the $100/hour for the 8xH100 config (similar to AWS). reply robertlagrant 4 hours agorootparent> whereas I doubt Google will do the same for TPUs (as they have lock in) They aren't the incumbent; this would be an incredibly short-term strategy, wouldn't it? reply martinald 3 hours agorootparentI just suspect overall nvidia gpu prices will go down quicker (across the entire market) than more proprietary ones. I could be wrong - but I don't think Google will be want to compete with the general market on a FLOPS/$ metric (they are already way more expensive than cheaper providers) so will end up milking the locked in users. reply Catenu 12 hours agoprevI believe these deals are crucial for attracting people. In my experience, they play a significant role in helping early-stage startups get off the ground. reply latchkey 15 hours agoprevThis is fun validation for what I've been working on for the last year! My startup (Hot Aisle) is all about building, managing and deploying dedicated compute clusters for businesses. At the enterprise level of compute, there is a lot that goes into making this happen, so we are effectively the capex / opex for businesses that don't want to do this themselves, but want to have a lot more control over the compute they are running on. The twist is that while we can deploy any compute that our customers want, we are starting with AMD instead of Nvidia. The goal is to work towards offering alternatives to a single provider of compute for all of AI. You can't do this for others unless you also do it for yourself. As such, we're building our own first cluster of 16x Dell chassis with 128 MI300x GPUs deployed into a Tier 5 data center as our initial rollout. Full technical details are on our website. It has been a long road to get here and we hope to be online and available for rental at the end of this month. One of my goals has also been to get Dell / AMD / Advizex (our var) to offer compute credits on our cluster. Those credits would then get turned around into future purchases to grow into more clusters. It becomes a developer flywheel... the more developers on the hardware, the more hardware needed, the more we buy. This is something unfamiliar to their existing models, so wish me luck in convincing them. Hopefully this announcement helps my story. =) Edit: Getting downvoted. Would love to hear some dialog for why. I don't really consider this an advertisement, so apologies if you're clicking that button for that reason. I'm really just excited about learning about validation of my business model and explaining why. reply reaperman 15 hours agoparentEven if it did feel like an advertisement, it's on topic for this discussion and adds something. That said, maybe it's a bit hard to read? Something about the flow throws me off - that could contribute to downvotes. I don't know. reply fragmede 14 hours agorootparentnah, for some reason voters here have been getting very anti-advertisement lately, as if this site wasn't somehow a giant ad in and of itself. reply latchkey 14 hours agorootparentprevThat's how you know it wasn't written by AI. =) reply npinsker 14 hours agorootparentprevI did not downvote (I upvoted), but I think I can see why others did. Mentioning their startup’s name, right at the top, isn’t a great start for me. OP didn’t need to do that, it means nothing to me, and it doesn’t add anything other than advertising. A few other phrasing choices like “full technical details on our website” evoke a recruiter spiel a little bit, because of wrong time and place — this is a comments section, and to me the writeup is a bit too detailed and overly confident in how interested I am. If I care, I’ll ask, or I’ll go to your profile. Sounds like OP was just excited; unfortunately, the practice of using HN to “organically” advertise startups (particularly through blog posts) is quite common nowadays, and I can’t help being sensitive to it as I feel it doesn’t help discourse. This post was relevant and interesting though; thanks for flagging it as such. reply latchkey 12 hours agorootparentI've been chastised before for not being explicit about my involvement in my own company. reply anxman 12 hours agorootparentprevTIL there’s a downvote on here reply latchkey 12 hours agorootparentFrom the FAQ (linked in the footer): https://news.ycombinator.com/newsfaq.html Why don't I see down arrows? There are no down arrows on stories. They appear on comments after users reach a certain karma threshold, but never on direct replies. Also explained here: https://github.com/minimaxir/hacker-news-undocumented/blob/m... I just voted you up to get one more point closer! reply jonathanyc 14 hours agoparentprevYou asked for an explanation of why you're being downvoted. Here is another comment that is effectively an advertisement, but one that adds value: https://news.ycombinator.com/item?id=41113750 More than anything, your comment just feels like you just copy-pasted it from the blurb you send to investors? For example you say: > ... while we can deploy any compute that our customers want, we are starting with AMD instead of Nvidia... > One of my goals has also been to get Dell ... to offer compute credits on our cluster. ... It becomes a developer flywheel... I mean, OK? The second part in particular (\"It becomes a developer flywheel\") seems totally irrelevant to anyone except a potential investor. Why would I as a customer care about your product being a flywheel?? I can hardly speak for everyone on this website, but I know I'm here first and foremost because I love to learn (c.f. \"If you had to reduce it to a sentence, the answer might be: anything that gratifies one's intellectual curiosity.\"). Even if I were working on a startup similar to yours, your comment doesn't really teach me anything (\"we're building our own first cluster of 16x Dell chassis...\" OK?) Also, quite frankly, I just went to your website and it reads like it was generated by ChatGPT. > In essence, Hot Aisle is not merely a cloud compute provider but a dedicated partner that accelerates the journey of businesses towards HPC advancements, ensuring they navigate the digital transformation landscape with assured resource scalability, enhanced security, and unwavering support. reply latchkey 14 hours agorootparentGreat feedback! I definitely didn't copy/paste it, I wrote that whole comment for this post. The developer flywheel was in response to the mentions of credits in the Google announcement. It isn't my product that is the flywheel, it is the imho smart concept of attracting developers to a solution by giving them credits. \"free drugs\", if you will. This is, in my eyes, a big reason why Nvidia is so popular today and what made the cloud in general, so successful. I'm trying to bring that concept to the AMD ecosystem. Previously, you could only get access to AMD MI (enterprise) class compute, if you had access to super computers like El Capitan and Frontier. I'd like to bring these things to the masses and a big part of that is lowering the barriers as far as possible. reply drivebycomment 12 hours agorootparentHonestly, even with this reply, it's not at all clear what you think this YC-Google deal is validating, and how it's directly relevant to what your startup is doing. It seems stretch to call the annoucement as any kind of validation for your startup, whatever your exact logic is here. Your reply above makes no sense to me. NVidia isn't popular because of any \"free drugs\". Cloud did not become popular simply by giving free credit. It's not at all clear what value your startup is brining to the world. El Capitan is 40MW compute. You can get that much computer from top cloud providers (with money of course) - their combined compute is in tens of GW range, estimate based on their renewable power portfolio. The barrier nowadays is roughly only money, and unless you have magic to lower the price of power and machines, you are not lowering any barrier vs top providers. If you have the magic sauce, it's not clear what that is, at least in the post. reply yanslookup 4 hours agorootparentAs a counterpoint I completely understand how a founder of a company that is competing with Google on cloud AI cluster services is contributing to the discussion by describing (and I guess looking for feedback, investors, new customers, etc. This is HN...) their inventive approaches to providing similar \"credit\" like incentives in the article. Their startup isn't Google. To me, it's interesting to hear how startups are competing with Google. reply latchkey 4 hours agorootparentThanks for the comment. I honestly don't see my company as a competitor to Google though. We're serving the need for individuals and businesses that don't want to use Google in the first place ^. Those of us who feel that there should be alternative hardware available other than just Nvidia, or even cloud solutions. We give full bare metal access to the underlying systems. We work with customers to customize their stack to tailor things to their use case. We're more 1on1 niche and solving for the least common denominator, with best-in-class solutions. Eventually, we are going to run hardware that others wouldn't normally touch and/or we are going to work to get it deployed earlier than any large cloud can. ^ Just as a side note, I'm a long time huge fan and customer of GCP, so please don't take this as bashing Google at all. reply latchkey 4 hours agorootparentprevI like this response a lot. I'm not sure what your experience is in the field, so it is a little hard for me figure out how to reply to you. I'll do my best, but apologies if I get it wrong. The validation is clear to me, but this is my field to recognize that. My business is about building super computers and either renting them piecemeal or whole to people and businesses. This is exactly what Google is doing in this announcement, which I take as validation because I started working on this similar thing, about a year ago now. Nvidia built software and hardware (s/h) before AI. Nvidia ensured that all of their s/h solutions were easily available to developers. AI recognized that the s/h was useful and took advantage of that. An example of \"free drugs\" were to make large gifts of the s/h to colleges [0]. I'm not saying that cloud only got popular with free credit, but it definitely was a contributing factor (just an example: [1]) in the building of many startups. The value of my startup is something I describe above in my original comment. You're dead wrong that the only barrier is money. It is the experience and relationships that we have in building, deploying and running large scale compute. Think of us as a consultancy for super computers. We also have the backing to fund the capex so that businesses don't have to put out millions up front, on rather finicky cutting edge hardware. Not everyone needs 40MW of El Cap, all the time. Not everyone wants to deploy into a cloud, many want to have more control over where their compute and data is located. We work with Dell, AMD and data centers directly to build and deploy these systems. I won't talk about pricing other than to say that both companies are highly incentivized to work together to deploy as much compute as they can, and I'm the one that has joined with them to make it happen. I'd say that there are about 25-30 people involved with us, just to deploy our single first cluster. It is a massive amount of coordination. It takes years of relationship building to even get your foot into the door on this. It is far more complicated than just racking boxes and we already have put the time and effort in to create the blueprint designs for best in class compute. We help companies that want this compute deployed yesterday, to speed up the whole process. I'm sorry if that is not valuable to you personally, but it is to others. [0] https://developer.nvidia.com/higher-education-and-research [1] https://news.ycombinator.com/item?id=39117292 reply CheekyBlunders 15 hours agoprevAny interest in SOCOM (DoD)? reply NKosmatos 6 hours agoprevI know I’m going to be heavily downvoted because not all people have the same sense of humor, but I’m going to make the comment… Does this mean we’ll have a new server to host HN and also get native dark mode? P.S. Yes I know that the server requirements are very low (explained by dang and others) and I also know there are many plugins and hacks to get dark mode ;-) reply LarsDu88 14 hours agoprevThis is great deal for Google and YC startups. reply bushbaba 16 hours agoprevDoes this mean google doesn't have enough external customer demand to fill the needs of it's GPU and TPU resources? reply mirashii 16 hours agoparentOn the contrary, it’s very difficult to get GPUs in GCP and has been for a while. reply outside1234 4 hours agorootparentThere is no way Google would do this if that was the case. This is a classic cloud vendor move to get someone, anyone, using the fixed asset. reply mirashii 3 hours agorootparent> Google Cloud is giving Y Combinator startups access to a dedicated, subsidized cluster of Nvidia graphics They're being paid, so of course they would do it. It's not much different than the reservations that GCP allows you to purchase today. reply holoduke 13 hours agorootparentprevReally? Any source on this? I just started one. Yes i know just one. reply mirashii 3 hours agorootparentA quick search on Google, or r/googlecloud, or one of any number of communities will give some sense. Alternatively, from the article: > For early-stage AI startups, Hu says one of the most common issues she hears is that startups are compute-restrained. Large enterprises are able to strike multi-year, massive deals with cloud providers for GPU access, but small startups are often left out to dry. reply ai4ever 14 hours agoparentprevi had the same reaction. the clouds are unable to sell gpus/tpus for premium rates, and now are forced to give them as incentives and credits to customers reply adin8mon 17 hours agoprevnext [8 more] [flagged] kyrra 16 hours agoparentGoogler, opinions are my own. I don't work on cloud. While AWS is more popular and has more public documentation and blogs, One thing I've heard about gcp that people seem to love a More consistent UI and CLI. Features also tend to interop better. But when you have those is some of your driving goals, it can slow down the rollout of new features. It's also very possible to use gcp without doing lock-in, if you stay away from specialized services like spanner. reply yas_hmaheshwari 15 hours agorootparent> More consistent UI and CLI. Features also tend to interop better I agree with this part of the statement. Having used both AWS and GCP, GCP seems a bit easier to navigate > if you stay away from specialized services like spanner Don't agree with this one. Once you are in one cloud, you are locked-in. Using services like BigQuery, Google pub-sub would eventually lock you in reply scarface_74 5 hours agorootparentprevFormer AWS ProServe employee - I did work in cloud and had some part in quite a few migrations. I did my bid at BigTech and I have no love loss for Amazon. You can not use any service at scale and avoid “lock in”. “Infrastructure has weight”. I’ve seen it take over a year to migrate an organizations VMWare hosted VMs to AWS. No “just use Kubernetes” is not the answer. Every hosted Kubernetes provider has some type of custom metadata you need to add to your configuration. It can be leaky. No “just use Terraform” is not the answer. Providers are unique for each cloud platform and you still have to rewrite everything. Not to mention at scale, you have to deal with the PMO, compliance, training, if you are large enough you might have a physical connection from your Colo to the provider etc.. reply influx 15 hours agorootparentprevA Googler who benefits from GOOG RSU going brrr says Google is better than a competitor. OK? Are you authorized to speak on Google's behalf publicly? reply kyruzic 15 hours agorootparentHe even started his comment like it had been approved by lawyer first lol reply scarface_74 16 hours agoparentprevYes because out of all the things that a startup should be worried about, thinking that one day they might want to host their own cluster of GPUs should be top of mind… reply ruined 16 hours agoparentprevcloud-to-butt extension really spices up this concept reply outside1234 4 hours agoprev [–] So Google can't sell the GPUs to actually paying customers is what this tells me. In contrast with Microsoft where they are GPU limited (don't have enough to sell). reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Google Cloud is providing Y Combinator startups with access to a dedicated, subsidized cluster of Nvidia GPUs and Google TPUs to develop AI models.",
      "The initiative includes $350,000 in cloud credits over two years and additional support, aiming to attract early-stage AI startups to Google Cloud.",
      "This partnership seeks to build long-term relationships with startups, addressing common issues like limited compute resources and aligning with trends of accelerators and VCs offering GPU clusters to attract AI startups."
    ],
    "commentSummary": [
      "YC (Y Combinator) has partnered with Google to offer a dedicated compute cluster for AI startups, providing priority access to Nvidia GPUs and Google TPUs.",
      "The deal ensures YC companies can access these resources without needing separate approval, aiming to help startups iterate quickly.",
      "While some view this as anti-competitive, others see it as a strategic move by Google to attract early-stage startups, addressing past challenges with cloud credits and machine availability."
    ],
    "points": 195,
    "commentCount": 90,
    "retryCount": 0,
    "time": 1722562386
  },
  {
    "id": 41139854,
    "title": "Marshmallow Test Fails to Replicate",
    "originLink": "https://srcd.onlinelibrary.wiley.com/doi/10.1111/cdev.14129",
    "originBody": "srcd.onlinelibrary.wiley.com Verifying you are human. This may take a few seconds. srcd.onlinelibrary.wiley.com 8ad0523b9ac4e25c",
    "commentLink": "https://news.ycombinator.com/item?id=41139854",
    "commentBody": "Marshmallow Test Fails to Replicate (wiley.com)189 points by superposeur 3 hours agohidepastfavorite116 comments rahimnathwani 1 hour agoThe findings of the original study were called into question by a larger 2018 study[0]. The original study had 90 students. Some folks did a study with 900 people. They found the same correlation that the original study did. But when they controlled for household income, they found most of the correlation disappeared. The obvious conclusion is that household income is a predictor of both: - inability to delay gratification, and - higher academic achievement This makes sense when you consider that someone growing up in a poor household may have both: - less reliable/continuous/predictable access to material things, meaning they would rationally seize immediate opportunities rather than taking the risk of a larger future opportunity, and - less academic support Now, this new study (OP) goes even further, finding that the correlation itself is weak. [0] Watts, T. W., Duncan, G. J., & Quan, H. (2018). Revisiting the Marshmallow Test: A Conceptual Replication Investigating Links Between Early Delay of Gratification and Later Outcomes. Psychological Science, 29(7), 1159-1177. https://doi.org/10.1177/0956797618761661 reply biofox 1 hour agoparentPsychology is messy. If you assume that impulse control and the ability to delay gratification is an inherited trait, then the income of parents becomes supporting evidence rather than a confounder. Time to do some GWAS to see if there is indeed a genetic component :) reply Guvante 16 minutes agorootparentWhy do people make up inherited traits and apply them as if that is a legitimate critique? The entire reason they did the marshmallow study is because most studies on impulse control cannot avoid confounding factors. Time value money matters if I am offering you money now vs later. E.g. if you are in debt money later effectively involves the interest earned on that money at likely 25% or worst case 900%. If you aren't in debt the alternative is investing at 7% with risk or 2-5% without risk. Trust is incredibly important. Money now is money now, money later might be money later if they actually fulfill the promise. And this isn't income agnostic as the risk of this varies wildly based on the impact of the money. A \"get back on your feet\" amount of money today or a slightly larger amount in a year implies a lot more risk than some spending money on either case. Additionally while genetic markers have sometimes been effective at predicting even those have trouble with the random nature of gene transference. reply bobcostas55 5 minutes agorootparentAll psychological traits are highly heritable. See eg https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4739500/ reply narag 37 minutes agorootparentprevMaybe the only possible conclusion is that you need much more specific experiments to conclude anything useful. I believe that any experiment that involves the whole life of someone is doomed and useless. reply jncfhnb 1 hour agoparentprevMore simply: people who grow up hungry learn to eat whenever they can because being hungry is awful It doesn’t even need to generalize. This is just a basic food security thing and is part of the reason why obesity is counter intuitively common among people who suffer from food insecurity. reply 1659447091 38 minutes agorootparentAn extreme personal observation of this was my grandmother, who grew up during the Great Depression with 9 siblings. They managed better than most and helped out neighbors (having both land and descending from farmers); she would in her later years (when I knew her) have massive stockpiles of processed long-shelf life food stored everywhere. Also, all the pickled/preserved food from her garden that was left over. For the longest time, I thought it was common to have multiple freezers, and a couple fridges, in a garage stocked with food. Including, months old leftovers from cooking enough of whatever soup/stew for 4-5 full families. reply IanCal 54 minutes agorootparentprevIs that from the study or your interpretation? Being hungry is a lot more of a threshold thing than income. reply jncfhnb 39 minutes agorootparentI’m not sure what you’re trying to claim. Poverty is obviously well correlated with food insecurity. reply adrianN 31 minutes agorootparentThat depends on the country. In rich countries it is rare for poor people to go hungry because food is cheap compared to median income and poverty is defined relative to median income. reply zamadatix 28 minutes agorootparentprevClearly, but they're saying that only attempts to explain why those particularly in poverty had the associated results. When referring back to the original study's actual claims it was more than just correlation with poverty incomes, it was claimed for all incomes and not so obviously linked to food insecurity. reply cma 18 minutes agorootparentOP says: \"Some folks did a study with 900 people. They found the same correlation that the original study did. But when they controlled for household income, they found most of the correlation disappeared.\" So original study didn't control for income. If the original study claimed it across all incomes, and then it mostly went away when others controlled for income, then the delayed gratification strong correlation wasn't really for all incomes, right? reply Guvante 23 minutes agorootparentprevFood insecurity is in the definition of poverty in most places. reply brigadier132 15 minutes agorootparentprevNo, you are the one claiming something in your original comment. What the person you are responding to is insinuating is that what you are claiming is more of the same pseudoscience as the original study. reply fragmede 51 minutes agorootparentprevyeah but that's too simple. as an adult who wants to live as long as possible, if I have to choose between eating one meal today or being able to eating two meals next week, I'm going to ask who the psychopath is that's imprisoned us, because we live in normal world and why would I ever be in that sort of a situation? Seriously, think back to as early as you can possibly remember, then as the marshmallow question. then ask it again to yourself, again and again, until your parents bringing you into a strange room with some weirdos, saying these are your parents now and have a marshmallow, isn't traumatizing reply searealist 58 minutes agorootparentprevFew grow up hungry in America. Certainly fewer than would influence this study. reply therealdkz 51 minutes agorootparentsource? reply KittenInABox 54 minutes agorootparentprevCost of food has grown significantly just in the past year or two. In 2022 alone, there was a 45% increase in food insecurity in children of the USA. [0] 0. https://www.npr.org/sections/health-shots/2023/10/26/1208760... reply searealist 45 minutes agorootparentCommon sense says kids are not growing up hungry. If you look at actual times when they were, like the great depression, kids were rail thin. The opposite is true now. If you read the fine print on these reports they usually boil down to something like: “there is not enough variety in the household”. reply jncfhnb 41 minutes agorootparentYou’re being presented with literal statistics on food insecurity and ignoring what you’re being told. Many people are both food insecure AND fat because food insecurity drives people to eat as much as they can because of the fear of being hungry later. reply azinman2 25 minutes agorootparentIt's not really eat as much as you can, more eat low quality ultra processed foods that are high in empty calories and low in nutrients. reply searealist 21 minutes agorootparentprevThe definition of food security was changed in 2006 to eliminate any reference to hunger. > Low food security: > Households reduced the quality, variety, and desirability of their diets, but the quantity of food intake and normal eating patterns were not substantially disrupted. In other words, by new definitions, if you ever reduce the quality, variety, or even desirability of your food throughout the year, you are considered food insecure. reply telgareith 55 minutes agorootparentprev\"Not even wrong\" reply fardinahsan 1 hour agoparentprevWut? The causation can flow the other way as well. Having high tike preference results in lower household income. And time preference is probably genetic. They literally controlled for the variable they were testing for.... reply Squeeeez 1 hour agoparentprevThe obvious conclusion is not that obvious. You can have genetic traits which affect self-control, for example. reply queuebert 50 minutes agoparentprevIn Table 3, being white is a very significant predictor (p=0.007) of being able to wait at least 7 min, but in Table 7 they don't report white among the races at all. Does this mean the difference among white kids is entirely explained by SES and other covariants? Conversely, does this mean being black has an effect not explained by other covariants? That seems pretty controversial. reply toss1 38 minutes agoparentprev>> less reliable/continuous/predictable access to material things, meaning they would rationally seize immediate opportunities rather than taking the risk of a larger future opportunity THIS — the environment definitely changes what is the most rational behavior. In economics, this is Counterparty Risk — the risk that the other party will fail to fulfill their obligation. E.g., as a vendor it is rational to accept a piece of plastic from a complete stranger without a word, because the issuer of the card is good for the money, and has taken on the problem if the buyer doesn't pay their bill that month. For kids in affluent stable households, it is rational to expect that they'll get the second cookie in 20 minutes. For a kid in an unstable household, being told by someone who neither looks nor talks like they do, that they'll get two cookies in 20 minutes, it's often rational to take what you can get NOW. The marshmallow test measures mainly environmental counterparty risk in everyday events. Seems when controlling for those factors, the 'marshmallow effect' disappears. This is good science. Discover an effect. Generate a hypothesis. Keep testing until you find the limits of that hypothesis, and/or hidden variables. reply searealist 1 hour agoparentprevWhy is it instead not obvious that delayed gratification is a predictor of household income? reply michaelt 43 minutes agorootparentHow would a 4-year-old's ability to delay gratification increase their parents' income? reply hnthrowaway121 36 minutes agorootparentPerhaps if they inherited the ability from a parent, the parent is more likely to have an income as a result of investing in their education for example. reply advael 18 minutes agorootparentI mean, maybe, but this is definitely doing causal modeling backwards Yes, it's possible that there are strong genetic predictors of household income, as a lot of people seem to want there to be for some reason, but when predicting the behavior of a child, their immediate circumstances are a much more parsimonious explanation for their behavior than some genetic factor strongly predicting both the circumstances and the behavior. I'm not saying that genetics being somewhat causally upstream of income is an inherently bad hypothesis, but this kind of correlation analysis doesn't support it as well as it does an environmental influence on time preference reply searealist 15 minutes agorootparentprevThis is the crux of the controversy. Some people think behaviors have 0% genetic inheritance and some people think it’s >0%. To assume low income can only cause low future orientation, but not the reverse, you must be in the former camp. reply dekhn 1 hour agoprevMany details of this particular experiment made me greatly reduce my confidence and interest in social science. I was trained up in quantitative biology- and when I look at studies like this, I see a long list of \"things that could go wrong, leading the investigator to falsely conclude their hypothesis is true\". But in this case, I think the investigator actually didn't care enough about doing high quality research- they simply started with a moral belief/value judgement and ran an experiment and chose to interpret the results to support their \"hypothesis\". And the nature of social science is such that it's really hard to truly run an \"honest experiment\". reply swatcoder 1 hour agoparentYou can read over a hundred years of extensive, exhaustive criticism of most social \"sciences\" for exactly that reason, and many of us grew up with a categorical understanding of a difference between \"hard\" material sciences like physics and chemistry and \"soft\" sciences like social sciences and many subdomains of biology and medicine. But that distinction has largely fallen out of the zeitgeist and many people now just take anything ever published in a \"scientific journal\" as sound. It represents a huge regression in scientific literacy among the public and sets us up for people becoming increasingly skeptical of \"hard science\" conclusions because so much of what they've incorrectly come to accept as science never really was. reply newaccount74 2 minutes agorootparent> people becoming increasingly skeptical of \"hard science\" conclusions A big problem is that \"hard science\" conclusions often only apply to very specific circumstances, but scientists and the general public then extrapolate to more generic situations. The consequence is that a lot of things that are supposedly based on \"hard science\" aren't really proven at all, it's just someone making educated guesses. reply tash9 14 minutes agorootparentprevTrue but there has been a movement towards replicating these high profile findings in the soft sciences. Hopefully that will gain more traction as a lot of the \"newsworthy\" studies are forced to get retracted after failing to replicate. reply bena 8 minutes agoparentprevHell, even the \"Dunning Kruger effect\" is a misapplication of statistics. The effect shows up even with randomly generated samples. Because there are floors and ceilings to the data. If you're low, you can only guess so much further down, so you're likely to overestimate your ability. If you're high, you can only guess so much further up, so you're likely to underestimate your ability. reply jmugan 1 hour agoprevIt's funny. When you first do work, you want the experiment to satisfy your hypothesis. When you are building on work, you also want the replication to succeed. But when it is a famous result like this, you actually want it to fail so people talk about your result. There are uncountable ways that these experiments can be unconsciously and subtly affected by the desire of the experimenter. As an aside, I believe one interesting confounder in the marshmallow test is that it tests more (or at least as much) the subject's trust that the eventual reward will actually be given as it does the subject's ability to wait for the reward. So if you live in an unpredictable environment, it's better to just eat it. reply readthenotes1 1 hour agoparentI recall that your confounder was used as an explanation to wave away the air reproducibility of the marshmallow test, but I do not recall anyone actually ever testing that. This recent article seems to indicate that it's all just horse feathers and so you can make up any confounder you want to explain it away... reply luketheobscure 1 hour agoprevAn alternative interpretation of the Marshmallow Test is that it is a measurement of trust as much as it is of self control. If you don't believe that the researchers are going to give you the two marshmallows, then you're not going to wait. reply layer8 56 minutes agoparentAnd low trust in researchers would explain low incentive for academic achievements. ;) reply readthenotes1 1 hour agoparentprevOr, that it's complete nonsense with no predictability whatsoever so you can make of it what you want reply chairhairair 59 minutes agorootparentI suspect (or hope) that many professional psychologists are beginning to doubt that data acquired in these contrived laboratory settings can provide a window into actual human behavior at all. reply influx 1 hour agoprevHave any famous psychological tests replicated? reply layer8 30 minutes agoparentThe Asch conformity experiment seems to replicate: https://journals.plos.org/plosone/article?id=10.1371/journal... reply dommer 1 hour agoparentprevhttps://www.bps.org.uk/research-digest/ten-famous-psychology... Tricky subject by all accounts reply readthenotes1 1 hour agoparentprevI am pretty sure the test of \"will you publish nonsense as if it were true for fame or money\" has been replicated multiple times in many different fields. reply acover 1 hour agoparentprev. reply Noumenon72 1 hour agorootparentYou can't answer \"Have any famous tests replicated?\" with \"out of 100 studies from the year 2008, 36% replicated\" unless one of those studies was actually famous. reply acover 53 minutes agorootparentTrue, I'm not going to read through the list and decide if any of them are famous for him. reply fragmede 34 minutes agorootparentbut you're going to complain and post about it on the Internet for free. and I'm going to read about it, for free. to readers: hi! reply exe34 59 minutes agorootparentprev> You can't answer Only if you're a frequentist. A Bayesian would see evidence that studies in general fail to replicate, and thus have a better prior for famous ones than 50:50. reply layer8 54 minutes agorootparentAs an aside, such lines of argument regarding credence are not in any way incompatible with frequentism. Few frequentists deny the correctness of Bayes’ theorem. reply jti107 1 hour agoprevanedotally this has held up in my social group. the people that i grew up with and went to school with...the ones that could delay instant gratification and had long term goals ended up doing pretty well in life. the ones that didnt have any plans and just went with the flow did poorly and just getting by. also in my life i notice a big difference in performance from when i had goals/vision for my life vs. going through the motions. IMO i think you need to have goals/vision/standards for all the important areas in your life (hobbies,partner,career,family,relationships) reply digging 1 hour agoparentDid you perform the marshmallow test on your friend as children? If not, I don't even know if you're really talking about the same thing, to be honest. The original study is such a weird and specific phenomenon to which a heroic effort of extrapolation was applied. \"Doing well in life,\" \"delaying gratification,\" and \"long-term goals\" are about as far from concretely measurable traits as you can get. What about a person who always waits to buy games on sale, but has experienced food insecurity and won't pass on free food, even if it's unhealthy? I could go on... there are countless variables when trying to evaluate those traits. What this study is saying is that extrapolating such broad strokes from small indicators is probably not a smart move. reply sdwr 53 minutes agorootparentLife can be a lot like a hologram, where the little things show the whole picture. The marshmallow test is not really testing hunger or self control. It tests how willing people are to align with authority/the bigger picture. The ideal participant isn't someone doing the calculus that 2 > 1. It's someone who recognizes that they are being tested, and cares about that more than any number of marshmallows. The question isn't \"how hungry am I?\", but \"what does adult attention mean to me?\". And that's why all of this stuff will stop replicating eventually, why new psychotherapies revert to the mean - it doesn't have the same amount of meaning for the test-givers after decades of trials. reply digging 48 minutes agorootparent> The marshmallow test is not really testing hunger or self control. It tests how willing people are to align with authority/the bigger picture. I feel you're making the exact same mistake as the original researchers. The marshmallow test is a proxy, but it's impossible to say what it's a proxy for in any given individual. One kid will wait because they're scared the researcher will be angry if they don't. Another kid will wait because they recently learned what marshmallows are, and they actually really want to eat two. A third will not wait, because they've never seen a marshmallow before and would rather try one first before getting two. reply BurningFrog 1 hour agoparentprevThat this personality trait, if it exists, is important for success is pretty obviously true. If you can measure this trait by putting marshmallows in front of 4½ olds is a whole other question. reply abeppu 1 hour agorootparent... and I guess another question is, how stable is this trait? E.g. if we got really used to telling 12 year olds that the marshmallow test finding indicates that the ability to put of immediate rewards for larger later rewards is really important, could you effectively get (slightly older) kids to learn to delay gratification more, such that their performance as small children matters less? Or (more likely) if you raise a generation with more distracting technology, can you destroy a whole generation's ability to patiently wait for a larger reward? reply fragmede 29 minutes agorootparentlet's ask China reply haliskerbas 1 hour agoparentprevCould go either way in my social group. Some folks hit ivy and then ended up at mediocre tech jobs anyway, others hit ivy and struggling to find work. Others went with the flow and still made it to the same mediocre tech jobs. And the ones who failed through school and barely made it through community college have successful small businesses because they were charting their own path the whole time. reply kenjackson 1 hour agorootparentBut what were they doing when they failed school? I feel like there are the Bill Gates, skipping school kids. And the ones I went to school with who just smoked, drank and hung out at the park. I suspect the outcomes were fairly different although might both fit under your same category. reply charlie0 1 hour agorootparentprev> And the ones who failed through school and barely made it through community college have successful small businesses because they were charting their own path the whole time. By definition, it sounds like these folk were able to delay gratification quite well. reply haliskerbas 1 hour agorootparentMaybe it depends on how you look at it? If gratification is \"working on my side project instead of finishing homework due tomorrow\" then it wasn't delayed much, they were gratified the whole dang time! reply circlefavshape 1 hour agoparentprevIMO you do not. I know many people \"doing pretty well in life\" who are opportunistic rather than goal-driven, and having goals for your partner/family/relationships sounds to me like a recipe for disaster reply fragmede 28 minutes agorootparentlets have kids and raise them well is a pretty common shared goal for parents/family reply im3w1l 1 hour agorootparentprevIn regards to the first part of your post, being opportunistic and goal-driven are not necessarily opposites. A person who is both has a plan that they follow by default, but the flexibility to turn on a dime if a better choice opens up. The second part I partially agree with. But establishing a routine like meeting some friend every Thursday evening, that can be good. reply nerdponx 41 minutes agoparentprevThat's why these bunk psychology studies are so insidious. It might in fact be a real effect! But maybe not at the level of babies and marshmallows. reply lolinder 1 hour agoparentprevAgreed. For me the real question isn't whether being capable of delaying instant gratification leads to better outcomes, it's if the marshmallow test accurately measures susceptibility to pursuing instant gratification in the cases that matter. Like, I've never liked marshmallows. A second marshmallow would have been uninteresting to me. And even if it were I could totally see a kid going \"eh, it's just a marshmallow, I'm going to just eat it now and then go think about something else\". Being able to delay instant gratification for greater rewards is only valuable in cases where you actually care about the reward. Someone who applies it everywhere regardless of interest level is just min-maxing life, and it wouldn't surprise me if obsessively min-maxing even little details doesn't correlate with better outcomes. reply wonnage 1 hour agoparentprevthe confirmation bias is biasing reply readthenotes1 1 hour agoparentprevMany years ago, I recall reading in _Columbia History of the World_ that the ability to live in cities, that is civilization, began when people preserved their seed corn so that they could have multiple harvests during the growing seasons. What I remember is that they summarize this as \"Delayed gratification is the root of civilization.\" And while this is pretty early in the history of the world book, I read no further because I doubted I would find anything more insightful in the subsequent hundreds of pages. ... Years later I tried to find that quote and I could not. I still believe it is a valuable insight though even if I hallucinated it. reply digging 1 hour agorootparentWhy don't squirrels live in cities then? reply fragmede 24 minutes agorootparentthey do, along with a large number of rats and other vermin reply FredPret 37 minutes agoprevSome fields of study will always be art, not science. Literature, art, human psychology. A good writer, artist, or therapist can make a truly great contribution. But they cannot conduct disciplined experiments and establish truth numerically. And that is OK. What is not OK is the cabal of academic psychologists who don’t even know that they’re full of shit because they aren’t trained in any of the numerical / “hard” disciplines. (Hard as in well-defined, not difficult). reply lawlessone 2 minutes agoprevTry it on shareholders. reply helsinkiandrew 1 hour agoprevFound this article whilst looking for more details, the same results seem to have been reported for several years, including following the subjects into middle age: https://anderson-review.ucla.edu/new-study-disavows-marshmal... > As the researchers predicted, the study finds only a tiny correlation between marshmallow test times and midlife capital formation. A graduate’s score on the self-regulation index was, however, modestly predictive of their middle-age capital formation, the study finds. reply charlie0 1 hour agoprevMaybe tempting children with marshmallows is a bad proxy for testing delayed gratification, but the thesis about being able to delay gratification leading to success seems to be true as far as I can tell. Anecdotally, all the people I know who can't delay gratification are just scraping by (this includes another SWE who earns a decent amount but is rather impulsive). All those I know who can delay it are doing great. reply suzzer99 1 hour agoprevI've always suspected the marshmallow test measures desire to please the researcher more than anything else. I'm supposed to sit here and stare at this marshmallow for some indeterminate amount of time, just to get one more marshmallow? Offer me a whole bag and we'll talk. Otherwise, you're wasting my time. My marshmallow would be gone before they could finish explaining the task. reply fragmede 18 minutes agoparentMy parents bringing me in, saying researcher is from a big name university and is very smart and do what he says, is going to have a much different effect on me than my step dad coming late to pick me up because my mom dumped me on his lap last minute because she has a new boyfriend and doesn't have time for me now and also my step dad says university is stupid and for geeks and don't believe a word the stupid college girl tells me to, is going to have a biasing effect on the kid! reply llm_trw 1 hour agoparentprevI've eaten a bag of marshmallows today while coding till 4am on a Friday night. Your proxy tests for self control have no power here. reply jpwagner 1 hour agoprevThink of the marshmallow test as a short story by a famous author. It rings with truth, but it's not \"science\". reply superposeur 3 hours agoprevThank god, as I love marshmallows and instant gratification. reply bigstrat2003 1 hour agoparentI submit to you that marshmallows are incompatible with instant gratification, because they're only good when you slowly toast them over a fire until browned on all sides. Cold marshmallows (or marshmallows shoved in the fire and then blown out) are just sad and not worth the calories. reply atonse 1 hour agorootparentIf you added that (offer them marshmallows and a way to toast them), all you've done with that test is identify the foodies :-) (I 100% agree with you about them being toasted) reply bobthepanda 1 hour agorootparentprevThey are also good baked with cereal to produce a sweet bar. reply bigstrat2003 29 minutes agorootparentTouche. That is a good use for them as well. reply Banditoz 38 minutes agoprevI'm confused. How do you access the full text of the article? Why is it behind a $15 charge? reply fragmede 36 minutes agoparentwhy do you expect it for free? what is a reasonable charge, in your eyes?why is that charge reasonable and $15 isn't? reply Banditoz 12 minutes agorootparentI don't know. Usually I see arxiv posted a lot here, and I can access those without issue. If I do pay, do the authors of the paper get my money? reply WhitneyLand 1 hour agoprevSo in a nutshell, one of the greatest failings of science in history comes down to, researchers were under pressure so they caved and compromise their ethics and morals. Even worse, the replication crisis is only one reason that the public has continued to lose faith in science in the post truth era. It’s also the disinformation campaigns that set out to attack whatever’s in a groups interest whether it be politics or the environment. Maybe the coup de grâce will be social media which encapsulates people into bubbles seemingly impenetrable to the truth. reply nyrikki 42 minutes agoparentThis result could happen without any intentional conduct, so ironically you may have made a similar error as the original researchers. While there are very real issues about reproducibility and motivation, rarely do studies actually claim what pop science puts in the headlines. Popper has a better approach with the idea that evidence cannot establish a scientific hypothesis, it can only “falsify” it. It is actually how we write computer programs in the modern era too. The Scientific realism camp is committed to a literal interpretation of scientific claims about the world, but others like myself consider it confusing the map for the territory. But that is the realm of philosophy and not science. While the time scale and wasted effort from the flawed original paper is regrettable, this is the process working in the long run. This paper's falsification is the process working, irrespective of some claims of 'ethics and morals' Studies about humans will always be subject to problems, exactly because of ethics and morals, e.g the tuskegee experiments. reply PaulHoule 1 hour agoprevI'd like to see the 2024 version where the kid who got two marshmallows is fat and the one who didn't want any marshmallows at all is skinny. reply reginald78 9 minutes agoparentFunny interpretation. The single marshmallow kid derided for having no self control or ability to delay gratification was actually harnessing the offered deal as a form portion control to maintain a healthy weight. reply yodon 1 hour agoprevI can speak to this test a bit from experience: as a very young child, I was in a pilot study used to design a large longitudinal study, and my younger sibling was in that large longitudinal study. At about age 4, I ended up literally maxing out the delayed gratification test and being sent home with a ridiculously large bag of M&M's, much to this dismay of my mom. With that as context, I wonder whether some of the changes/lack of reproducibility are actually measures of decreasing economic mobility and economic agency within the US. Early studies on ability to delay gratification were done during the favorable economic conditions baby boomers grew up in. More recent studies were done in eras with far less economic mobility. It's quite likely you'd see a smaller effect today, not because the impact isn't there, but because it's so much harder today to make a significant upward change in your economic status. reply rolph 1 hour agoprevwhen marshmallow tested, i spit on my marshmallow, when asked why i explained \"now noone will want that one\", \"now i get two marshmallows because i waited\" , \"and also a third one cause only i will want it\" reply aqsalose 1 hour agoprevFrom abstract (article is paywalled) >Although modest bivariate associations were detected with educational attainment (r = .17) and body mass index (r = −.17), almost all regression-adjusted coefficients were nonsignificant. No clear pattern of moderation was detected between delay of gratification and either socioeconomic status or sex. Results indicate that Marshmallow Test performance does not reliably predict adult outcomes. I guess the question is whether the covariates that were adjusted for in the regression are true confounders and not, say, something caused by ability to delay gratification. reply m3kw9 1 hour agoprevMaybe when they grow up some of them learned to steer away from instant gratification. Or maybe you need to account for how big luck is in the success in life reply dfedbeef 25 minutes agoprevThat test was already broken a decade ago by Kidd. The socioeconomic part of it is BS and has been known to be for a while. reply bell-cot 1 hour agoprevImagined childish reasoning: I could eat one marshmallow now, and hopefully finish this stupidboringweird test sooner and go home. Or I could be stuck here longer, for one crappy little marshmallow, showing that I know how to play a stupid suck-up little teacher's pet. reply paganel 1 hour agoprevBy this point all the normal people have started ignoring this type of “science”, many of us were ignoring it from the very beginning. Too bad that this quackery has already made its way into many States’ apparatuses, see the obsession about the nudge thing, for example. reply veggieroll 1 hour agoprevI don't like marshmellows. reply rolph 35 minutes agoparentZira : Because I loathe bananas! https://inv.tux.pizza/watch?v=G3Phb8AyrxE reply nineplay 1 hour agoprevI was talking about this a few weeks ago and realized I would eat the damn marshmallow. Researchers do not act in good faith. Maybe they're testing me for delayed gratification. Maybe they're measuring my anxiety levels as I wait for someone to come back with a promised reward. Maybe they want to know how angry I'd get if they come back and said they were out of marshmallows - or come back and flat out ate the marshmallow in front of me. A lot of researchers would happily trick me into thinking I was killing someone if they thought they could get away with it. Its the truth that demolishes all the hand-waving about the marshmallow test - it relies on the subject's trust of the person running the experiment. I wouldn't trust them, why should anyone else? When evaluated that way - particularly when testing on children - the outcome is painfully predictable. - Children who have adults in life that they trust have better outcomes. - Children who do not have adults in their lives who they trust have worse outcomes. reply RRWagner 1 hour agoparentI was a subject in a college psychology experiment when I was an undergrad. The researcher said I would get some amount of $ for each new word in a sequence that I could correctly remember and repeat without error. I mentally made up a story and added each new word to the story. At the end they said that I remembered too many words, more than they had ever anticipated, it was too much $ for them to pay and gave me $5. Later I wondered whether the real experiment was about reacting to being tricked. reply llm_trw 1 hour agorootparentJust remember that the reason why Ted Kazinsky said he bombed the federal government was because he was subjected to MK Ultra experiments in college. I'd say you got a good deal getting two dollars instead of life long trauma. reply rolph 49 minutes agorootparentprevi think verbal contract law would apply here. reply silverquiet 42 minutes agoparentprevIndeed, I couldn't really participate in psychology research because there is almost always an element of deception and I couldn't help but look for it. One extreme example arguably created the Unabomber.[0] [0]https://en.wikipedia.org/wiki/Ted_Kaczynski#Psychological_st... reply error_logic 1 hour agoparentprevHaving been in the former camp to such a heavy degree, I wouldn't have even thought of this dimension as a confounding variable, despite always trying to see that sort of thing. Thank you for the insight. reply vvpan 1 hour agoprevYet another study that \"explains it\" turns out to be false. Good. reply bigstrat2003 26 minutes agoparentI don't think that it's a good thing if a study which seemed promising turned out to be false. The goal is to have explanations of the world, after all. It's better to have learned that something is false than to go on believing the falsehood, but better still is to have something true which explains things. reply error_logic 1 hour agoparentprevFailure to replicate could happen for any number of reasons. The sample populations might not enjoy marshmallows the same way! But, yes, good to be aware of the possibility of both false positives and false negatives. reply vvpan 52 minutes agorootparentIn general the original study felt like a more widely accepted Myers-Briggs of sorts. But as always happens with people and personality related theories the reality is either \"more complicated\" at best or the theory is outright false. reply dudeinjapan 1 hour agoprev [–] They only measured the subjects' \"adult\" life outcomes at age 26. Perhaps the researchers were rushing to publish and unwilling to wait long enough for the effect to replicate. reply Veen 1 hour agoparent [–] Or perhaps there is no effect. reply error_logic 1 hour agorootparent [–] Or perhaps economic mobility has stagnated and external factors dominate. reply wonnage 1 hour agorootparent [–] fixing the structural problems in the economy is so boring, let's blame the marshmallows reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "A 2018 study with 900 participants questioned the original Marshmallow Test findings, which had only 90 participants.",
      "The new study found that the correlation between delayed gratification and academic achievement disappears when controlling for household income, suggesting income is a significant predictor.",
      "The study indicates that the Marshmallow Test may measure trust in researchers more than self-control, highlighting the complexity of psychological traits influenced by both inherited and environmental factors."
    ],
    "points": 190,
    "commentCount": 119,
    "retryCount": 0,
    "time": 1722613773
  },
  {
    "id": 41136974,
    "title": "Null-Restricted and Nullable Types",
    "originLink": "https://bugs.openjdk.org/browse/JDK-8303099",
    "originBody": "OpenJDK ErrorHTML { font-size: 18px; line-height: 1.3; } BODY { display: grid; grid-template-columns: 1fr; grid-template-rows: 100vh; align-items: center; } DIV.root { align-self: center; justify-self: center; } DIV.img { display: flex; justify-content: center; } IMG { margin-bottom: 2rem; align: center; } P { width: 30em; } P.incident { text-align: center; } A { text-decoration: none; } A:link { color: #437291; } A:visited { color: #666666; } A[href]:hover { color: #e76f00; } The site is experiencing technical difficulty. We are aware of the problem and are working to correct the issue. We apologize for any inconvenience.If you need assistance, please email ops@openjdk.org and provide this incident number: 0.5c102017.1722625338.241a3b44",
    "commentLink": "https://news.ycombinator.com/item?id=41136974",
    "commentBody": "Null-Restricted and Nullable Types (openjdk.org)186 points by lichtenberger 10 hours agohidepastfavorite198 comments Sohcahtoa82 4 minutes agoCan someone explain to me how nulls are even a problem? I know the basics of Java and did some basic projects in it for my CS degree, but never used it professionally or in a large project. It seems to me that something somehow being assigned a null is a bug, but one that would stick out like a sore thumb. At some point, you're returning a Null, right? Any code calling a function that can return a Null should know that being handed a Null is a possibility and handle it, right? I'd think that eliminating Nulls is a bandaid over the wrong problem. Or is eliminating Nulls really meant to catch any potential NPE's at compile time as a way for force better error checking? reply jeroenhd 9 hours agoprevThe difference between this approach and the approach C# took when they implemented this a few years ago is intereting. With C#, you enable nullability in a project, and every variable is declared as non-null unless you explicitly mark it as nullable (or use compiler directives to disable nullability for a block of code). With this proposal, all existing variables will be effectively nullable, explicitly nullable, or explicitly non-nullable. Kotlin, another JVM language like Java, also follows the C# approach, assuming everything is non-null unless explicitly marked as being non-null, except Kotlin doesn't have backwards compatibility to worry about. Kotlin also offers a special `lateinit var` declaration for leaving a non-nullable type unassigned until initialization in another method, throwing a special exception on uninitialized access, which is an interesting workaround for some code patterns that this approach doesn't seem to cover. I wonder why the choice to offer three options was made. Why not keep the non-annotated variables as nullable and make annotated variables explicitly non-null instead? I can't think of a reason why you would want to declare something as nullable when not declaring anything automatically makes the type nullable anyway. I think I like C#'s approach better, although this has the benefit of being usable in a legacy code base without having to solve any of the nullability issues. Then again, the C# approach does immediately highlight nullability issues in a code base, whereas this proposal hides them the same way they've always been hidden. Additionally, I find this strange: > One method may override another even if the nullness of their parameters and returns do not match. This feels like a footgun for when a developer overrides/implements some kind of callback and returns null where the overridden method specifies non-null return values. reply ygra 8 hours agoparentI'm currently involved at work with migrating a legacy C# code base to nullable reference types. One thing I'd really like is the explicit marker for non-nullable since it makes it explicit which parts of the code have already been looked at and annotated. For time reasons we've opted to just enable the annotations for now except in a few core places. But we still retain the JetBrains NotNullAttribute and CanBeNullAttribute as markers for now to immediately see where we've made a conscious decision (granted, the latter can be removed since nullable has an explicit marker, but the former has a name conflict with C#'s own feature). So in that sense having the three options would be quite desirable. Especially since a few hundred thousand lines of code aren't that quick or easy to migrate. In another internal project we've been doing this in a different way by sprinkling #nullable enable around the code where we touch it and thus gradually improve nullability coverage (and keep in mind that new code must be in a nullable context). This works as well to make it explicit what is annotated already, but it's a much smaller codebase and team. reply Deukhoofd 4 hours agorootparentWhat we did was to turn on nullability as warnings everywhere. We then went through them project by project, and fixed them. After we were done with a project, we'd turn on WarningsAsErrors for nullable warnings, and know the project didn't need additional fixes any more. reply unscaled 6 hours agoparentprevKotlin does have types with unspecified nullability, although you cannot define it directly. Kotlin calls them \"platform types\"[1], and they're annotated with an exclamation mark (e.g. \"String!\" for a possibly-nullable string) in errors and diagnostics. Both the term \"platform types\" and the exclamation mark symbol are confusing, but other than that Kotlin's approach works quite well. Since Kotlin has nullability from the very beginning, the programmer can't specify platform types directly, but Kotlin still needs to support them to maintain compatibility with underlying platforms that support unspecified nullability, such as the JVM and JavaScript. With this approach, the defaults are still sane[2] (always non-nullable by default — everybody who thinks otherwise has learned nothing from Tony Hoare[2]), but the backward compatibility is maintained. But Kotlin got it easy, Java and C# also need to maintain compatibility with existing source code. Neither Java's approach or C#'s approach seems ideal. The C# approach drastically changes the behavior of the code based on a compiler flag, while the Java approach makes the default into the worst possible choice. I still lean towards the C# solution, because I think making \"maybe-nullable\" the easiest choice, means most programmers will choose it by default. Especially in an enterprise-friendly language like Java. Linters and compiler warnings would help in the long-term, but I think it will be many years before most of the Java code will be properly annotated for nullability. C# users will see more pain in the short term, but they will probably get to the promised land of clear nullability much faster. [1] https://kotlinlang.org/docs/java-interop.html#null-safety-an... [2] https://www.infoq.com/presentations/Null-References-The-Bill... reply simon_void 3 hours agorootparentyou failed to mention that Kotlin has platform types only if it's interoperates with Java. Platform types are for objects that come over from Java code (and therefore have unspecified nullability (assuming the Java code doesn't use nullability annotations)). Admittedly you provided a link that explains this, but how many people will follow the link? And yes, this detail feels kind of important. And yes, future Java (and Kotlin) will only have their version of platform types to interop with old Java code. As a long-time Kotlin user I can only say: Nullability is nice! Once you know it, you won't want to code without it. reply mmis1000 2 hours agorootparentThe type kotlin generated from java code also inserts nullable specifier if java code have @NonNull or @Nullable specified. When kotlin see these exist. It will convert the type to null enforced type instead. Which give you a tool to gradually convert you project to null enforced type if you can't convert it to kotlin at once. reply unscaled 2 hours agorootparentprevI did mention all of this: \"[...] but Kotlin still needs to support [platform types] to maintain compatibility with underlying platforms that support unspecified nullability, such as the JVM and JavaScript.\" To be more accurate, \"platform types\" are not used with JavaScript, but you do get something similar in that case. I haven't worked with Kotlin/JS at all, but from my understanding if you do not have proper type definitions, you have to deal with dynamic types - which are also nullable. reply layer8 7 hours agoparentprevI agree that it is strange. What I would have expected is (1) that on the source-code level T? means nullable (the existing semantics) and T! means non-nullable, and that the default for plain T in newly compiled source code can be specified using a pragma-like declaration per source file, per package-info file, or globally by a compiler switch, and (2) that a subsequent LTS Java release would switch the global default. This would allow easy switching of projects (you can insert/update the pragma in an automated fashion), and also allow keeping the old default when needed. In addition, the existing JSR-305 @Nonnull annotation could have been leveraged as being the way how nonnullable type occurrences are indicated in class files, providing two-way compatibility for old JDKs. reply twic 2 hours agorootparentSounds pretty good. But i think the mode selector has to be in the source code where a reader can see it, which rules out a compiler switch. The current proposal doesn't exclude this possibility in the future, does it. Maybe one day you will be able to declare a class public class! MyClass { or have a package-info file which says package! com.initech.accounting; reply layer8 2 hours agorootparentThe compiler switch would be for emulating (or for disabling) the global switchover that we want to take place at some point. We currently have the wrong default, so to speak, and we’d want to change that at some point. Then it is useful to already be able to do that in earlier releases, and also to be able to revert to the old default in later releases. Otherwise, I agree that the indication should be in the source, at least during the transitional years. In practice, looking for the presence or absence for T? vs. T! will be a good heuristic for whether the code assumes the new or the old semantics. The compiler could also warn or even error out when the code is obviously being compiled with the wrong semantics, that is, if ? or ! are present but all redundant. Regarding the class syntax, you can have multiple (package-private) classes in the same file, so I wouldn’t do that. A simple solution would be to have an optional ! or ? at the very start of the source file (ignoring comments and whitespace), which means a regex could handle it (useful for external tooling), and it would also work in the absence of a package declaration (i.e. in the default package). Another reason to not put it on the package declaration is that it isn’t meant to apply to the whole package. reply jiehong 9 hours agoparentprevAt the end, there is this section: > Providing a mechanism in the language to assert that all types in a certain context are implicitly null-restricted, without requiring the programmer to use explicit ! symbols. Could be nice, even if just as a compiler flag or a module tag. reply dmichulke 9 hours agoparentprevI suppose the reason is backwards compatibility of code, something that Java values a lot more than other languages. Still, I also suppose there's going to be a compiler flag that auto-assumes non-nullability unless specified otherwise. reply jeroenhd 8 hours agorootparentOn the one hand Java is very strict about backwards compatibility (still reserving keywords like const and goto even though they're not used (anymore)), but on the other hand Java 9's module system broke just about every JavaJava 9's module system broke just about every Java = 9 project with Maven libraries made forbut on the other hand Java 9's module system broke just about every JavaProject Loom How would it break any code? You have to explicitly use virtual threads, normal threads are not touched at all and will work as they have always did. And yeah, java has always been “conservative on the language front, state-of-the-art on the runtime” reply whartung 4 hours agorootparentJDK 9 was the impetus, but the real nail was, I think, 17 when a lot of the constraints imposed by the module system became required. Before that folks could pretty much continue as usual with little regard to the module system. After 17, legacy systems needed to start adding runtime options to work correctly. And, as I recall, this was mostly constrained to the dynamic, reflective, and introspective properties. Generic jars and code can still run without the module system. Unfortunately, a lot of the magic in modern Java is through those reflection aspects. So it made moving to 17+ an effort for many legacy code bases. And it should be clear, in general, all of the code was fine. It was all runtime options setting up package permissions that was the problem. Doesn’t make it less frustrating. (And I’m pretty sure 17 was the rubicon for this, but it may have been another version.) reply cesarb 5 hours agorootparentprev> How would it break any code? You have to explicitly use virtual threads, normal threads are not touched at all and will work as they have always did. You often have no control over what kind of thread the caller of your code is using. Code written for the old threading model can and will end up being called by these newfangled virtual threads. If it does something the virtual threads don't like (which, as far as I have heard, includes things like some uses of synchronized blocks), you can have unexpected breakage. reply imtringued 4 hours agorootparentYou're confusing the thread pinning problem with \"breakage\". The problem with some synchronized blocks is that they lead to thread pinning for the duration of the lock. Why is thread pinning bad? Because it means that if one core is idle, but all the threads are pinned to a specific core, you won't get full CPU utilisation. This undermines the performance benefit of virtual threads, because they are supposed to be schedulable via work stealing. reply kaba0 5 hours agorootparentprevThat’s not backwards compatibility, but forwards compatibility, though. And you would really have to go out of your way to introduce such an issue. Certain extreme (e.g. native calls) cases are handled by simply pinning a virtual thread to a real thread. So it would only cause an issue if it was already causing an issue at much smaller thread numbers. And many of these extreme cases are getting “solved” to not pin the thread. reply thayne 4 hours agorootparentprev> That’s not true at all. Besides the package name change with jakarta, all it did is just expose a couple, popular libraries that were depending on runtime internals. Most of this could be fixed by bumping said libraries version. I don't remember the exact details, but I worked on a project that was stuck on java 8 for a long time because some critical dependencies broke in java 9, and it took a long time before they released versions that were compatible with java 9. reply BoardsOfCanada 8 hours agoparentprevMy experience with kotlin and c# is that in kotlin it just works, even with java interop, while in c# nullable value types seem like a far leakier abstraction. reply QVVRP4nYz 9 hours agoparentprev> I can't think of a reason why you would want to declare something as nullable when not declaring anything automatically makes the type nullable anyway. All existing code is \"we don't know if it is nullable until someone reviews it\", that is different than explicitly allowing nulls. To add to confusion all Optional variables should be not-null or using Optional makes no sense at all. reply jeroenhd 8 hours agorootparentOptional is such a weird addition to the language. I hope once this link lands, Optional will go the way of the dinosaur. I use Optional but only to indicate at the API level that something can return null. I hope the chaining ability (?. in many languages, implemented as Optional.map()) will also one day make it to Java. reply neandrake 8 hours agorootparentI don’t even prefer it for indicating that something can return null. In most cases the Option API is more tedious and awkward than a null check and there are existing annotations that can be used to flag nullable return types, for documentation. The only places I’ve found Option to be helpful are where it helps with method composability, or in some hashmaps as a simple way to distinguish between “lookup not previously tried” vs “lookup resulted in no value” vs “lookup resulted in value” - it’s a hack and looked down upon because the Option value itself is null, but I view it the same as “Boolean” being nullable. As long as the details are encapsulated it’s not too problematic. reply usrusr 4 hours agorootparentprevI use Optional quite a lot, but only ever as a poor man's x?.let{f(it.y)} via Optional.ofNullable(x).map(it->f(it.y)).orElse(null); Will it at least get taken care of by escape analysis? These days I'd not even trade the simple but effective approach taken by Kotlin for the full glory of Scala's Option (which is so far beyond the Java Optional). reply joncrocks 8 hours agorootparentprevIndeed, Optional was designed/intended to be used in this way. https://stackoverflow.com/questions/26327957/should-java-8-g... reply unscaled 6 hours agorootparentUnfortunately for Java, Optional in Java is a bit of mess now, until you'll be able to specify nullability. Since T in Optional has unspecified nullability, calling Optional.of() is still unsafe and can result in an NPE, if the argument is null. What's even worse is that APIs that return Optional can just return null for the Optional value itself! This a pretty evil thing to do on purpose, but this could still easily happen by mistake. If you want to make code using optionals null-safe you have to go through quite some hoops and check that both that Optional is neither null nor empty. I hope Java can now change the API of Optional and make it safer. For instance, Optional.of() should require a `T!` argument, while Optional.flatMap() should require that the mapper returns a non-nullable Optional value. Likewise, linters should reject any definition of an Optional that is nullable or has unspecified nullability. reply oftenwrong 5 hours agorootparent>but this could still easily happen by mistake. I have yet to see this ever happen, despite working in Java shops using Optional heavily since it was included in the JDK. I would guess that this is due to developers using better tooling. IDEs commonly provide warnings when returning null, or when violating a \"soft\" nullability assertion marked by an annotation. NullPointerExceptions seem fairly rare. reply unscaled 4 hours agorootparentI do remember seeing this happen firsthand, but I don't remember where. Yes, this is not likely to happen with a good IDE with warnings enabled, and developers not ignoring said warnings. It is even less likely with a strict lint step in your CI/CD which treats all non-suppressed warnings as errors. This should be the standard for every software project in the world. Unfortunately, for many enterprise scenarios, developers are not encouraged (or even discouraged) to apply these best practices. I'm talking about your typical setting with non-technical management, low-salaried or outsourced developers, tech debt rarely being fixed and the only best practices which exist date back to the 1990s or early 2000s. Doubly unfortunate is the fact that shops of this type _overwhelmingly_ favor Java. For better or worse, Java is the #1 enterprise language and the COBOL of the 21st century. As such, something that would be a non-issue in Rust (where few developers would dare push to production code that didn't pass cargo clippy with flying colors), becomes a rather big issue in many shops. reply jonathanlydall 2 hours agorootparentWhile applying practices like treating warnings as errors on a CI server is something that every development team probably should be doing, it’s more a symptom of a generally weak development team than the thing that was holding the team back. If a company policy mandated that it must be on, it would probably not meaningfully reduce poor code because the team was so poor in the first place, they probably don’t understand the problem it solves, so will just work around the now “error” using the least amount of effort to appease the CI server, while still leaving problems in their wake. Strong teams regularly and consistently reflect on their processes towards continuously improving, such teams will naturally move to applying such a practice as it will add value. Weak teams tend to just do what they always did until forced to do something new and even then they do it more cargo cult style than in a way that actually improves the bottom line. reply pjmlp 5 hours agorootparentprevAll the value like types, like Optional, are planned to be value classes or value records, when Valhala lands. reply marcosdumay 2 hours agorootparentprevOptional is a problem with all languages that add nulability control as an afterthought. If I have v = Optional, if v.hasValue() does it mean v.value is not null? How does it interact with the nullability control? If v? has type Optional, how do I write Optional>? (And if you think that type doesn't make sense, you haven't really internalized the \"parse, don't verify\" rule.) If v? doesn't have type Optional, why the fuck both types exist and when should I use each? reply UncleMeat 6 hours agoparentprevIts a footgun, but one chosen for practicality. There have been a number of other nullability annotation frameworks for java in the past that are more complete and correct, but also more difficult to use and understand for a typical developer. A classic example is \"what about nullness of fields defined in constructors?\" After all, there is a real moment in program execution where those fields store nulls. So people try to add things to represent \"nullable, but once non-null it remains non-null forever\" or whatever and then people don't practically use the system because it is too much conceptual complexity. reply lolinder 5 hours agorootparentAnother practical answer is to just accept that an edge case like that is one we won't completely solve for. Kotlin will yell at you if you don't initialize everything in the constructor and will yell at you if you try to use a variable in the constructor before it's declared, but if you call out to another function in the constructor you're on your own and might end up with nulls. That's not complicated to understand, but it eliminates most types of not-yet-initialized nulls in the language. Also, isn't how you handle not-null types in constructors totally orthogonal to which syntax is used for not-null and whether there's a third I-dunno-if-null type? And is a three-way nullability system really simpler to understand? reply pjmlp 7 hours agoparentprevAs someone that works across JVM, CLR and Web ecoystems, dealing with C# approach is still a mess, unless one is lucky enough to only work in greefield projects. It is made worse, by being a C# 8 feature and not usable in libraries that need to stay compatible with .NET Framework (yep still plenty of stuff going on there). reply ygra 7 hours agorootparentAFAIK you can still use it for older frameworks. The compiler embeds the attributes into the assembly when they're known to not be part of the runtime library [−3.7]. You can do the same with the various conditional nullability attributes. [−3.7]: https://sharplab.io/#v2:EYLgHgbALAPgAgZgARwExIMJIN4FgBQSRKyc... reply jacobparker 3 hours agorootparentThe one nullable gotcha with doing this is that the .NET standard library doesn't have nullable annotations in older frameworks. One approach to adding nullable annotations to a large code-base is to go \"bottom-up\" on DLL at a time. The annotations are somewhat viral; if you were to go top-down then as you get to more of the \"shared\" DLLs and add annotations you'll find yourself having to go back and revisit the DLLs you already migrated. In this light, the .NET standard library situation is problematic. Imagine implementing IEnumerable by wrapping another IEnumerable; in .NET framework there are no nullable annotations, so you can get into a situation where you don't add a nullable annotation where you will eventually need one upgrading to newer .NET. This can bubble up throughout your code base, making that eventual .NET upgrade more challenging. I'm not saying its not worth it to do this in .NET framework, but you can very easily add extra work to the inevitable(?) update to .NET 8+. When you get there you could of course temporarily regress and turn nullable stuff back to warnings until you work through that surprise backlog, but nullable is really nice so you might be strongly inclined to not do that... not a huge problem, just something to be aware of! reply pjmlp 6 hours agorootparentprevYeah, those are the kind of tricks I don't like playing, because when things break down, someone has to sort out the mess. reply afiori 9 hours agoparentprev> I can't think of a reason why you would want to declare something as nullable when not declaring anything automatically makes the type nullable anyway. It can more clearly show intent. Is is similar to the argument for using const in javascript: you should use const as much as possible so that when you see a let you know that it is going to be mutated at some point. reply aardvark179 9 hours agoparentprevI think this is all a compromise to allow the introduction of this gradually in a code base and across the standard library. You want to start marking these intentions in interfaces and base classes, but you don't want to immediately invalidate all existing implementations. reply foolfoolz 4 hours agoparentprevhow does the project level null flag work for libraries? lets say a library was written with no nullability flag selected (legacy jar). i import that jar into my code. in my code i enable all variables as non-null by default reply gwbas1c 2 hours agoparentprev> This feels like a footgun for when a developer overrides/implements some kind of callback and returns null where the overridden method specifies non-null return values. I've caught \"null!\" in C# code reviews a few times: My response is usually \"You can't fix your code by yelling at it.\" The reality is that C#'s approach also has some nasty footguns that require understanding the nuances of the \"required\" keyword, and when values are assigned. reply the_gipsy 8 hours agoparentprevThis way Java can claim that it has this feature when comparing to competing languages, without interfering with all the legacy code. It doesn't matter if it's not useful, some manager can just run down a checklist and pick safe ol' Java. reply ajnin 7 hours agoprevLooks good, finally a language-supported way to remove thousands of unnecessary Exceptions and null-checks. But the nullness-narrowing automatic conversions feel wrong. From the proposal : String? id(String! arg) { return arg; } String s = null; Object! o1 = s; // NPE Object o2 = id(s); // NPE Object o3 = (String!) s; // NPE Surely at least the two first cases should yield a compiler error. The last case you're explicit so it's borderline but I'd rather see something like : String s = ... if (s != null) { # Here the compiler knows that the effective type is String! String! ss = s; # OK } Like this no possibility of error. reply slaymaker1907 1 hour agoparentAs someone who has written Java in industry, I'd rather dynamic checks only happen when I explicitly ask for it and have everything else done statically. Bean validation works great since while the object might be incorrect temporarily, I know it's valid as soon as I validate it explicitly (or it gets validated by the framework before entering my code). In fact, I'd even prefer Objects.requireNonNull(s) be used instead since that's even more explicit than the cast in the last case. However, I'd also like for there to be an Objects.unsafeForceNonNull(s) that just bypasses any explicit check unless there's some sort of optimization that would otherwise prevent. The unsafe method lets you implement your own requireNonNull without adding a bunch of complicated static analysis. reply vbezhenar 6 hours agoparentprevIf the first or second example would cause compiler error, it means that you would need to annotate every library usage. Your code will be full of casts on almost every line, until the given library would migrate to null types, if ever. It makes no sense. For example they explicitly saying that standard library will not migrate to null types, at least for now. reply jayd16 2 hours agorootparentYou can still work with the nullable types, as is, from these libraries. You only need to cast/check when you want to use the non-nullability feature. reply Sankozi 6 hours agoparentprev\"It is not a goal to require programs to explicitly account for all null values that might occur; unaccounted-for null values may cause compile-time warnings, but not compile-time errors\" Unfortunately this will only be checked at the runtime. reply ta234234234 7 hours agoparentprevIs it really though? If your problem is introducing null's into the API, I'm not sure that's a language error. I mean I get it, its verbose and cleans things up. But isn't the problem the coders doing it? reply The_Colonel 7 hours agorootparentCoders work with what they have. The work itself is shaped by the tools the workers use to produce it. If you give workers inadequate tools, you can't expect high quality. Java currently doesn't provide any decent (general) solution for the problem of nullability - JSR-305 is a failed spec, Optional is very verbose, doesn't work for many use cases (e.g. isn't Serializable) and funnily enough there's no guarantee the Optional instance is non-null, value types (primitive and the preview support for complex ones) obviously covers only very specific use cases. reply ta10238487475 7 hours agorootparentNot a fan of Optional, or streaming in general; where I've seen it/used it its basically ruined the codebase. I guess I find this defensive stuff a bit on the nose. If its not null, you're still gonna be testing be Non-Optional. reply jeltz 7 hours agoparentprevYeah, the second not being an compile error allows for legacy code to call functions with notnull arguments but I do not think that is necessarily a good thing. Hard to say without using it in practice though. reply vbezhenar 6 hours agorootparentCompiler will insert null checks in the function invocation. It's not a problem. And if you can't gradually migrate old code to null types, it means that most projects will never utilize those types. reply jeltz 3 hours agorootparentYeah, the more I think about it the more O agree with the design even if it surprised me at first. reply rvcdbn 5 hours agoprevIMO there really needs to be a way to mark all variables non-null by default at package or at least a file level. Otherwise there will be a strong safety argument for always using T! syntax on almost every variable and this will just be a lot of noise. reply rileymichael 39 minutes agoparentUnder \"other possible future enhancements\": > Providing a mechanism in the language to assert that all types in a certain context are implicitly null-restricted, without requiring the programmer to use explicit ! symbols. reply foolfoolz 4 hours agoparentprevi don’t think it will be that bad. we have a standard in our projects today that all java variables in code we own are not null. if you would like to have a nullable variable, you must annotate it with @Null this is only an issue at the boundaries of our code where we interact with libraries. i imagine that will be the case with this new syntax as well reply jayd16 3 hours agorootparentIf I understand you, then you're not getting any compiler check support for misuses, correct? reply lolinder 1 hour agorootparentI have to assume they have a lint rule for that. With good tooling compiler error vs lint error is a distinction that matters about as much in practice as parse error vs type error—your editor and CI pipelines will yell at you either way. reply jayd16 3 hours agoparentprevI suppose an aggressive linter could assume unmarked should be treated as non-null and at least demand nullability markup where needed. reply elric 10 hours agoprevArchive link because the site is currently down: https://web.archive.org/web/20240802081039/https://bugs.open... reply xxs 8 hours agoparentAhh they did switch to all loved \"jira\" - no surprises there. reply promiseofbeans 9 hours agoparentprevthe good old hn hug of death reply sebstefan 9 hours agoprev>It is not a goal (at this time) to apply the language enhancements to the standard libraries Speaking from experience being forced to use php, it's a hassle to have ahead-of-time guarantees on your data that you need to strip out or build back up everytime you interact with the (massive) standard library They should be a bit more enthused to add that kind of expressiveness to their STL and make it a first class citizen in the STL reply slaymaker1907 1 hour agoparentI think you're reading \"at this time\" as \"never\" when in reality, they want to do that separately since that sort of conversion is a huge undertaking in its own right. Additionally, separating it into two steps allows them to more easily launch this as a preview feature, get feedback, and then commit to a design before trying to overhaul the whole standard library. If they try and do it all at once, that gives them little room to actually iterate on the feature. reply brazzy 8 hours agoparentprevKey phrase \"at this time\". I'm sure it will become a goal once the feature is established. reply hnthr_w_y 9 hours agoparentprevforced? modern php is a bliss. reply jeltz 8 hours agorootparentHaving worked in modern PHP I have to disagree. Modern PHP is much better than it used to be but it is still much worse than any of the common alternatives (JS, Ruby, Python, Java, ...). reply sebstefan 9 hours agorootparentprevIt's hard defending php in 2024 when you've used the alternatives that exist... It took two major versions to add types to both function arguments and return values and there's still no type-restricted data structures. Think \"array of foo\". Just overall, other than with bash, I've never shot myself in the foot more often than with php I despise that thing with a passion reply jeroenhd 8 hours agorootparentPHP is fine. It's like Python or Javascript, but with dollar signs. I don't generally like duck-typing languages, but PHP is no worse than its competitors. reply jeltz 8 hours agorootparentThe standard library of PHP is still the same old crappy standard library that it used to have with only some minor fixes. The language itself is not that bad (still worse than Python, JS or Ruby) but the standard library is awful. One thing I have to give modern PHP is that Composer is pretty neat, better than NPM and the packaging mess of Python and roughly on par with Rubygems/Bundler. reply jeroenhd 8 hours agorootparentThe PHP standard library has issues for sure (shout-out to real_escape_string), but so do Python and JS (I can't speak for Ruby as I've never used it). JS's \"hide everything behind a few magical objects\" (Math, window, document, etc.) approach isn't much better in my opinion. Python is a bit better, but mostly because Python 3 was a clean break from Python 2. I find the biggest argument for or against PHP in the context of these languages to be \"I find dollar signs aestethically (dis)pleasing\". It's a perfectly valid preference to have, but people talk about PHP like they're still porting Wordpress plugins to PHP 4. reply jeltz 7 hours agorootparentI do not care at all about the dollar sign, but I have worked both in PHP 4 and in modern PHP and I do not think the language has improved much. Other than Composer the dev experince was basically the same. It is still not up to par with Ruby or Python. reply imtringued 4 hours agoparentprevHonestly one of the biggest problems with Java is that they are incrementally improving it, but then the new minimally improved code becomes legacy code for the next incremental feature. Legacy code that uses Optional is a liability for any proposal that uses explicit nullability and non nullability. Record types could have been non nullable by default and so on... reply dtech 9 hours agoprevWould be cool if Java got this feature, explicit optionality at a language level a la T? is an enormous developer QoL in Kotlin and Typescript in my experience. In Java there's tools like NullAway [1] but they're a hassle. Language-level support is leagues better than Optional/Maybe in my experience too because it keeps the code focused on the actual logic instead of putting everything in a map/flatMap railway. [1] https://github.com/uber/NullAway reply j16sdiz 8 hours agoparentBreaking 30+ years of source compatibility? Why? Why don't just use any JVM languages? reply voidfunc 6 hours agorootparentSome us actually work on real software with dozens or hundreds of other devs and not toys. We can't always just \"use any JVM language\". reply imtringued 4 hours agorootparentI wish Oracle would just offer Java editions, where they break syntactical backwards compatiblity, but retain backwards compatibility on the bytecode level. Of course, 99% of the language should stay the same with most of the syntactical changes just getting rid of the annotation mess that proper Java would be. reply twic 2 hours agorootparentprevThis change would not break any source compatibility. reply declan_roberts 1 hour agoprev> In a Java program, a variable of type String may hold either a reference to a String object or the special value null. In some cases, the author intends that the variable will always hold a reference to a String object; in other cases, the author expects null as a meaningful value. Unfortunately, there is no way to formally express in the language which of these alternatives is intended, leading to confusion and bugs. Casually just describes one of the largest sources of bugs in the history of programming. reply rendaw 1 hour agoprevIt's interesting to see this right on the tail of https://jspecify.dev/blog/release-1.0.0/ by Meta et al. That was done AFAIK because JEP-305 died and it didn't seem like Oracle was going to ever do anything about it. Did Oracle do nothing to coordinate here? reply tadfisher 47 minutes agoparentI think you mean JSR-305 [1]. Even though the initiative died in committee, you can still use the reference implementation [2] and hundreds of thousands of projects do so. Most static analysis tools and IDEs support it as well. JSpecify takes advantage of Java 8 features (e.g. annotations on generic type parameters), so it's strictly better, and I believe at least the IntelliJ IDEs support it. [1]: https://jcp.org/en/jsr/detail?id=305 [2]: https://central.sonatype.com/artifact/com.google.code.findbu... reply kstenerud 6 hours agoprevIt's unfortunate that we're learning all of these lessons so late... * things should be non-nullable by default * things should be immutable by default * things should be of the narrowest scope by default So many design decisions for new things make the trade-off of immediate convenience instead of \"falling towards the safe path\" (which requires much more careful design and UX). And we have sooooo many footguns as a result in almost every language, platform, and technology thanks to this cowboy mentality. Civil and electrical engineering have codes. We have lessons-learned, which we re-learn every 30 years or so with the next batch of languages and techs. reply lolinder 5 hours agoparentUnfortunately it seems like Java still hasn't learned the non-nullable-by-default rule—this proposal introduces two new types, with the default un-annotated type still answering :shrug: when asked if it's nullable. reply kaba0 5 hours agorootparentIt’s almost like you can’t change the default without breaking 467482 million lines of code? As they clearly write at the end, they will think of additional proposals, like making non-nullable the default on a per-class/package level. But they don’t have the luxury for that. It’s like, possibly the best language team on earth did think of this tiny little obvious detail. reply kazinator 6 hours agoparentprevIt's unfortunate for Java to be learning these things so late. \"We\" and \"Java\" are not the same. Java is like a third world village learning about boiling water killing germs. reply augusto-moura 6 hours agorootparentThat is definitely wrong. Java is not the only language that does this. From the TIOBE index list[1] (pick any other list if you want): - Only 3 languages from top 20 (Rust, Swift and Kotlin) started with null safety type features, some others developed this over time (JS with TS, Python type hints) - Only 2 (Rust, and Kotlin) languages AFAIK are immmutable by default It is no coincidence that all of these languages are modern and created after the 2000s [1]: https://www.tiobe.com/tiobe-index/ reply unscaled 2 hours agorootparentTo be exact, all of these languages are statically typed and were created or at least started taking their final shape[1] after 2009, when Tony Hoare (who has the best claim for being the one who invented the null reference) coined the term \"Billion Dollar Mistake\" and made the final convincing argument as to why no serious typed language should have null. But it's probably more important than all of these languages have been heavily influenced by the ML/Haskell family of languages. Most ML-influenced languages forbid null references, discourage them or make nullability a part of the type signature. I think the ML-heritage is the key factor, together with Tony Hoare's influence. Languages released shortly after 2009 that have ignored the ML tradition like Go and Dart did not have null-safety. I believe ML-influenced language designers were more attuned to Tony Hoare's call for action and had a good idea about how to make null-safety work smoothly an industrial language. Fortunately for us, nowadays the language designer doesn't have to be a Functional Programming aficionado anymore: null-safety has proven itself as relatively easy to implement and too useful to ignore. --- [1] Rust is the odd one out here: Graydon has started working on Rust as a personal project back in 2006, but that language is bears little resemblence to what we call Rust today. Rust only became more than a personal project around 2009 and the first release (0.1) only came in 2012. Looking around, I find no reference for avoiding null reference in Rust before 2010. reply airstrike 3 hours agorootparentprevSwift is technically \"immutable by default\" as you have to explicitly declare a variable to be mutable with `var`. F# also is immutable by default. Maybe it's not on that \"top 20\" but 20 is an arbitrary cutoff. There are many so many languages being used in production that it's hard to imagine \"20\" is a defensible sample. It's also hard to argue Python has any type safety with \"type hints\". The interpreter doesn't do anything with those hints. Linters and safety don't belong in the same sentence. All in all, that seems like a bad source. reply Hamuko 4 hours agorootparentprevHow do you define \"immutable by default\"? Swift for example has different syntax for mutable variables (`var x = y`) and immutable variables (`let x = y`). reply kstenerud 6 hours agorootparentprevIt's not just Java. It's C, C++, Ruby, Python, Go, BASH, C#, Javascript, PHP, PERL... It's about making our systems human-tolerant. Humans are absolutely terrible when it comes to consistent (or even correct) behavior, so we must design our systems such that the path of lowest cognitive load is also the path of highest safety and least astonishment. For example, C++ has the concept of a const method. And that's great, because you can label which methods won't mutate an object's data. But it's actually backwards. It should be that mutator methods must be marked as such (because they're the ones with a higher likelihood of causing problems), whereas any non-marked method is assumed to be non-mutating. In Rust, you must specially mark mutable objects. In Kotlin, you must specially mark nullable things. Each of these newer languages is taking on some of the lessons learned, but nobody is taking a serious holistic look at human psychology and how it contributes to system failures - it's always just a few pieces here and there that the designers had learned along the way. And then someone comes along and points out a lesson they didn't implement and everyone goes \"Oh. Oops.\" You don't get that in civil engineering because the lessons have been codified (and people who skimp out on them are liable). Psychology really needs to have more of a center focus when designing software systems, because we can't take the human fully out of the works. reply mrkeen 4 hours agorootparent> And then someone comes along and points out a lesson they didn't implement and everyone goes \"Oh. Oops.\" I don't think that's the case here. It's not \"Oh. Oops\". It's \"Yes, we like it that way\". I think that readers of Java source code have the right to see a BufferedReader, and think \"That's a BufferedReader\". Writers of Java source code have decided that that's too onerous. They would like the 'opposite' right - of taking a 0x0000, and declaring that to be a BufferedReader. That's really the core of it. The debates always involve adding extra types, annotations, IDEs or external tooling into the mix, as if nulls naturally arise in nature, and some genius-level engineering is required to mitigate against them. But people routinely include them in their source code. I don't think you can win the war on accidental nulls if you can't swing opinion on deliberate nulls. reply 12_throw_away 34 minutes agorootparentI mean, I don't know if nulls \"arise in nature\" exactly, but null pointers arise quite naturally in computer memory when setting stuff up and tearing stuff down. I agree that it's vastly preferable, in a PL, for nulls to be semantically distinct from live pointers. But still, null pointers model something real, and it took a lot of research to get us to the point where we could build languages that can make the semantic distinction. reply kazinator 6 hours agorootparentprevI didn't mean to imply there's just one village learning about boiling water killing germs. reply soerxpso 6 hours agorootparentprevThat's not true. The Java community in general has known about this for many years, and using Java's `Optional` type for anything nullable has been considered best practice. The reason the language itself has moved slowly is that making core changes to an existing language like this is hard; there are backwards compatibility concerns that are always going to be at odds with correctness concerns, and it's important to hash out the details and make sure that the eventual system they land on is the right one, since it intends to stick around for decades to come. reply mrkeen 4 hours agorootparentOptionals weren't as well-received as you make them out to be. IntelliJ will issue you a warning for using an Optional either as a field, or a method parameter. reply shepherdjerred 1 hour agorootparentThe purpose of Optional, IMO, is to avoid returning null, not to avoid receiving null. It is easy to validate incoming params for null or to check if an internal class field is null. It is much harder to know if some method can possibly return null. To put it another way, Optional as a param/field helps the _author_ of the class, Optional as a return helps the _user_ of the class. Taking an Optional as a field/method parameter just introduces a third state you have to handle: * The Optional is present * The Optional is absent * The Optional itself is null I've worked on codebases that abused this where there is different behavior for each of the three cases. On one hand whoever wrote that code should have thought about the contract of their method a bit more. On the other hand, respecting and looking into _why_ IntelliJ is warning about this behavior would help prevent such mistakes in the first place. But, if you really want it, you can configure IntelliJ not to warn on this inspection. reply ecshafer 6 hours agorootparentprevThat is not a fair description to Java or the team that has created it. Do you actually think that James Gosling, Guy Steele, Brian Goetz, Doug Lea, etc. are not aware of nullability? Java was an early 90s attempt to get C and C++ programmers to write safer code with the technology of the day. The design goal of the language was to get half way to LISP or ML for those C and C++ programmers. In an alternate universe where they had just made Common LISP, does it succeed? Perhaps not. Also consider that Java is a cross platform language, that must be backwards compatible, and work the same via a vm across architectures and operating systems, and basic things like just make variables non-nullable by default are not as simple. reply Sankozi 6 hours agorootparentprevThere are very few languages that got \"things\" better than Java (if I understand kstenerud correctly): * Haskell * Rust * C# (barely) with other .NET languages Any others? If \"Java is like a third world village learning about boiling water killing germs\" then how do you call other main programming languages - C, C++, JS, Python? reply kaashif 5 hours agorootparentC++ has many issues but it has actually supported non nullable references right from the start. Everything is riddled with foot guns and escape hatches but references can't be null. reply Sankozi 5 hours agorootparentC++ is weakly typed language with undefined behaviours baked in. It definitely did not get \"things\" right. And also - you can get nullable references. The following compiles (and often runs) without a problem: int functionWithReference(int &ref) { return ref; } int main() { int* pointer = NULL; return functionWithReference(*pointer); } reply consteval 2 hours agorootparentC++ is not weakly typed, it's just a low-level language. Meaning you can directly interact with memory if you so choose. The same is true in Rust, and YES you can break the type system with unsafe code. However, we understand that this is not really enough to make the language weakly typed. Java and C# ALSO have this problem. You can make everything Object if you want. It'll compile, it'll run, and C#'s ArrayList class worked like this. Also the above will not compile. Because compilers can actually detect if you set a pointer to nullptr and then use it. Here, you didn't use it so maybe the compiler won't complain. But in the general case yes it will complain. You can also get Null references in C# and Java in this same method. You call some unsafe code that directly interacts with memory. That's allowed, and yes it breaks the type invariants. Point being, if you truly want to argue C++ is weakly-typed then you'd also have to argue C# and Java are weakly-typed. Most people don't do that though, so it's just a matter of bias or familiarity. reply cletus 5 hours agoprevMost of my work at Facebook was using Hack. Nullness is a key part of Hack's stype system [1] and this solves so many BS errors. That's not to say you couldn't get a null where you weren't expecting one, particularly because this was a later addition to the language so the code still had a lot of legacy \"mixed\" types that basically mean anything (mirroring the PHP roots where you could pass basically anything). Some questions though. First, what about nullable arrays? There are examples of String![] where the objects can be null but what about the array itself? As a reminder this is entirely legal in Java: String labels[] = null; Does that mean you have to declare it: String![]! labels; ? In Hack, this is easy: vec $foo; // neither foo nor the elements are null ?vec $foo; // the elements are non-null but foo can be null vec $foo; // either can be null In practice, there's really little reason to ever use a null array so the default really should be that something isn't nullable. I understand the issue with Java is that all legacy code assumes nullability so that's an issue. String? id(String! arg) { return arg; } String s = null; Object! o1 = s; // NPE Object o2 = id(s); // NPE Object o3 = (String!) s; // NPE As for this example, shouldn't (2) and (3) be compiler errors? As for the last, I really like Hack's as enforcement operators here rather than Java's casting eg: class A {} class extends B {} void foo(B $b) {} ?B $b = new B(); foo($b); // compiler error A $a = $b as A; // runtime error if $b is null foo($a as B); // runtime error if $a is not a B ?B $b2 = $a as ?B; // $b2 is cast to B if it is one, otherwise null is returned Anyway, the question becomes can you retrofit this to the Java SDK? What does it look like for legacy code? [1]: https://docs.hhvm.com/hack/types/nullable-types reply jayd16 2 hours agoparentPresumably its just : String![]? labels = null; reply sswezey 5 hours agoprevThe formatted JEP link: https://openjdk.org/jeps/8316779 reply lbalazscs 59 minutes agoparentYour link is only for value types, but this one is more general, it's for any type. Obviously the two are related, but not the same. Nullability for value types has performance implications as well. reply Sankozi 7 hours agoprev\"It is not a goal to require programs to explicitly account for all null values that might occur; unaccounted-for null values may cause compile-time warnings, but not compile-time errors\" This is a bad decision. Java is mostly statically typed language, why introduce another dynamic behaviour? Hope there will be easy way to promote such warnings to errors. reply yxhuvud 7 hours agoparentThey can't do that or it will break all java programs in existence. Enforcing that would force all programs to be rewritten to handle null responses everywhere. With this addition they can apply the forced null handling to only operations involving the new types, and thus not break anything. And yes, languages where the type systems force handling null/nil in all cases is a lot nicer. But that is not what the current Java is. This will still be a big improvement. reply Sankozi 6 hours agorootparentIt will only break existing programs if they start introducing Type! into existing APIs. I understand that introducing ! types in existing Java libraries would be nice, but I much prefer the ! mechanism to be more \"correct\". I agree that it will be a big improvement either way. It seems we need some annotation akin to @Deprecated(forRemoval = true). Something like @NotNull(willBeEnforced = true) that would only emit a warning but informs the user that soon there will be a breaking change related to nullability. reply _ZeD_ 7 hours agoprevFinally! I tried many other solutions/workarounds in the past years, like using the eclipse/intellij notnull annotations and the various efforts of projects like https://www.lastnpe.org/ I was wondering how \"enforceable\" these nullness check will be and how they will affect generics (will a \"List!\" be treated like a non-nullable list of nullable strings? and a List ? is the \"unknown nullables\" forwarded to the elements?) reply plmpsu 7 hours agoparentCheckerframework does this well. reply mmaniac 7 hours agoprev> In this JEP, nullness markers are explicit: to express a null-restricted or nullable type, the ! or ? symbol must appear in source. In the future, it may be useful, for example, for a programmer to somehow express that every type in a class or compilation unit is to be interpreted as null-restricted, unless a ? symbol is present. The details of any such a feature will be explored separately. I think this question needs to be answered now. The addition of ? is useless and confusing unless this is planned to eventually happen. I am inclined not to introduce breaking changes and to only have !. reply MBCook 5 hours agoparentIt’s not. The fact that it’s got a ? means a developer explicitly marked it and told you it’s nullable. The lack of a mark means you have to consider it nullable but no one has told you that setting it to null is the right thing. Things may still go wrong if you set it null though. It’s just the contract isn’t explicit in the code. reply jeltz 3 hours agoparentprevNot it is not. They mean different things. String? a = null; String b = null; String? c = \"\"; String d = \"\"; String! aa = a; // Compilation error String! bb = b; // Runtime error String! cc = c; // Compilation error String! dd = d; // Works! reply mmaniac 2 hours agorootparentThanks for clarifying the distinction - that's worse than I thought. When an expression as simple as bb = b can throw something has definitely gone wrong. reply cesarb 7 hours agoprevOne annoying detail of this proposal, is that it swaps the meaning of the nullness markers compared to Kotlin, which uses ! to mean \"it came from Java and had no nullability annotations so we don't know\" and no marker to mean not nullable (https://kotlinlang.org/docs/java-interop.html#notation-for-p...). reply mike_hearn 5 hours agoparentNot a big deal. The exclamation mark only appears in IDE tooltips and things, you can't express it directly. It could therefore be changed without breaking anything. If you want a 'flex type' you have to use type inference: // Java Baz bar() { return new Baz(); } // Kotlin val foo = someJavaObject.bar() foo now has type Baz! but the moment you declare the type of foo explicitly you're forced to pick, and an NPE check is done at that moment. reply drinkcocacola 7 hours agoparentprevIt is indeed annoying. For Kotlin, its advantage is that it had the nullability concept from its inception. For Java, they need to make sure previous code behaviour does not change, meaning that they need to add an additional marker to the explicitly mark \"not null\" types. Probably in some years from now once codebases exclusively use this feature, there would be a way to tell the compiler that the default type (without marker) it is a non-nullable type. reply yas_hmaheshwari 6 hours agorootparent\"Our colleague Alex Buckley, specification lead for the Java language and JVM, likes to say that one of the surprising things is that Java managed to get all the defaults wrong and still succeed\" [Source](https://blogs.oracle.com/javamagazine/post/what-are-they-bui... reply pjmlp 5 hours agorootparentIn that regard, I would say Java is in good company => C, C++, JavaScript, PHP. reply vbezhenar 6 hours agoparentprevThere's no \"!\" syntax in Kotlin for developers. reply jpgvm 5 hours agorootparentCorrect. Platform types are non-denotable. reply dzonga 8 hours agoprevseems all the good things about Kotlin are coming to Java now. I will still prefer to work in Kotlin though as I don't have to deal with things like lombok though Java records are nice. reply esafak 5 hours agoparentBut Java programmers will still use the old idioms, and be stuck with their old code bases. It will take a long time before these things are in the wild, so Kotlin programmers need not worry. reply elric 6 hours agoparentprevJava has a long history of getting inspiration from other languages. Happy to see it's continuing to evolve at a decent pace, while mostly maintaining compatibility with previous versions. reply exabrial 4 hours agoprevUnfortunately, this breaks the language semantics and I don't think it's a very good idea. Java is a static language. If these are a huge problem in your codebase, you can discover the problems using nothing more than static analysis and healthy programming habits. Personally I've never found nulls unintuitive or hard to use. Changing the core of the language to align itself with another fleeting in vogue trend is going to leave us with a bunch of garbage and tech debt when the trend inevitably falls out of style. reply km144 4 hours agoparentIt doesn't seem like this is really focused on changing \"the core of the language\" though, is it? I guess I don't even really get that particular criticism for languages like Java and C# which I always kind of see as \"big tent\" languages. Both have been pretty engaged in adding optional features that allow support for different development paradigms in recent years. There's something to be said about the difference in philosophy here though. Some languages are much more focused on facilitating particular paradigms which is also completely reasonable. Java and C# are well-positioned in the industry to support many optional features and have that be a selling point. To your second point, I mean it's great that nulls are easy for you to use, I'm happy for you. But there are bad and good developers the world over that are contributing to bad practice with null handling when there aren't any guard rails. And not even necessarily because they don't understand null, but in some cases just because they don't think about it. Warnings are a reasonable solution to that IMO. reply crdrost 2 hours agorootparentSo I think the biggest dig for me is that according to this JEP there are times that this code, String? y = null; if (x != null) { y = x.foo; } might trigger a null pointer exception. I don't mind the static error, if say `y` is not nullable but `x.foo` is nullable. But that's not at play in this code. Rather, these exceptions in the JEP come when `x.foo` is a `String!` but for various reasons either it hasn't been initialized yet and perhaps this code is occurring in a parallel thread, or due to various chicanery some null somehow was stored in it. (In the JEP the big case would appear to be that `x` is in this case a class with a static attribute `foo`? \"Note, however, that this rule does not prevent some other class from trying to read the field during the class initialization process; in that case, a run time check detects the early read attempt and throws an exception.\") To me, this is a minor change to \"the core of the language\" that betrays some bigger, more important change that has yet to be made to \"the core of the language.\" Something like null tracking at the JVM level, or forbidding concurrent access to things that are being initialized... or maybe just that classes need new rules around what you can/can't do in their static initializations... some big semantic shift. Also, one of the more intricate parts of TypeScript has to do with types-as-unions, you want to be able to analyze code that says something like, if (x.foo == null) { return; } String! y = x.foo; and make the analysis step that this is legal and type-safe. But TypeScript can only do this because JS multi-threads on a message-passing model. Java doesn't do this, there is a race condition where `x.foo` was not null when the check was made, but then this thread slept for a millisecond while another thread with visibility of `x` modified `x.foo`. So in Java I think you need to correctly mark the above typecheck as \"does not pass\" while the closely related version, String? z = x.foo; if (z == null) { return; } String! y = z; would presumably need to pass static analysis because you can determine that `String? z` is not reachable from any other thread. So your static type-system now needs to have some heuristic \"reachability system\" that it appeals to, and it has to be a heuristic because you're not going to reimplement something as sophisticated as borrow-checking in Java. reply vbezhenar 2 hours agorootparentThis code is not correct for TypeScript because it could be Proxy with getter. It works only because TypeScript types are not checked at runtime. Java approach is correct one. If you want to ensure that value is not changing under your feet, you need to save it to the local variable. reply marcosdumay 2 hours agorootparentprev> might trigger a null pointer exception Every OOP language can behave badly at the data constructors. Every single one has some lightly-communicated rules that you must not break and are hard to verify. reply tln 4 hours agoparentprevHow does it break the semantics? It \"Compatibibly interoperates\" according to the JSR! I don't think wanting not-null is going to be fleeting, but I'm sure with Java's long loooong 30 year history there have to be other \"in vogue trends\" that have left tech debt... Can you point to any? reply jayd16 3 hours agoparentprevYou can not like the proposal but claiming that we can be null safe with just static analysis? c'mon now. reply kelnos 2 hours agoparentprevEliminating null pointer dereferences (or NPEs, in this case) as a class of bugs is not a \"fleeting in vogue trend\". It's a useful and IMO necessary step to make programming less error-prone in general. > Personally I've never found nulls unintuitive or hard to use. That's not the argument. The argument is that it's easy to mess up their use without realizing it, leading to bugs that only show up intermittently at runtime. I'm just disappointed that this JEP doesn't go far enough; the compiler/runtime will automatically narrow types (e.g. auto-cast from String! to String), without warning, and possibly throw NPEs. That should be a compile-time error. reply eklavya 3 hours agoparentprevHow do you know what is or isn't null? reply elric 9 hours agoprevCan't say I'm a fan of the proposed syntax. Random question marks and exclamation marks do not improve the readability of the language. Introducing new symbols wouldn't bother me as much if they made sense. E.g. square brackets make sense for arrays because they denote an area. Equal signs make sense for assignment and equality because of mathy history. But question marks and exclamation marks don't make much sense for nullability. Which is easier to understand? I don't mind a few extra keystrokes if it improves readability. private String? foo; private String! bar; // or private nullable String foo; private nonnull String bar; reply demurgos 9 hours agoparentThere's some precedent in Kotlin, C# and PHP using a postfix marker for nullability. Overall it seems to work good there. Keep in mind that some types may be complex (e.g. when using generics) so using a keyword for the modifier may cause too much verbosity. Verbose is not the same as readable, even if Java is known to confuse the two. This reminds me of some discussions about the \"weirdness budget\". When you introduce some new feature, you want it to stand out and be noticed. But as people get used to it, a terser syntax is fine. Some example are callback syntax in various languages introducing a short-hand form when it got popular, or the move from the `try!` macro to the `?` try operator in Rust. You have to consider a longer time horizon for Java's nullability markers. They may be weird at the start, but I feel that the lighter syntax is a better trade-off when you consider their usage 10 years in the future. Overall, I feel pretty happy with this proposal given their backwards compatibility requirements. I just wish that it had come earlier so `Optional` could enforce non-nullability of its inner type. reply elric 8 hours agorootparent> Keep in mind that some types may be complex (e.g. when using generics) That's exactly why I'm not fond of the question mark, that already has an overloaded meaning in generics. Foo, Foo, Foo, Foo, Foo look pretty confusingly similar. One could argue that ? and * were terrible symbols for use in generics in the first place, but that ship has sailed. I'm sure people (myself included) could easily get used to the syntax, but habituation is not going to stop me from being grumpy :-) reply jeroenhd 8 hours agorootparentThat's a good point, though I would argue that this is caused more by the ? inthan the ? of the nullable type. I've always found the \"? extends\" syntax to be confusing, and I feel like the question mark doesn't even need to be there on a syntax level. I also feel like on a language level, Java shouldn't even need a \"? extends Bar\", but unfortunately Java's generics system isn't strong enough to work without it. And then it gets worse, with Foo and Foo being slightly different, even though it makes no sense at all. reply MBCook 5 hours agorootparentprevTypescript and Swift are somewhat similar in syntax as well. Not 200% but enough it’s very obvious what’s going on. reply bazoom42 9 hours agoparentprevMaybe because I’m used to it from C# and Typescript, but ? and ! seem a perfectly readable to me. Obviously ‘nullable’ is more understandble the very first time you encounter it in code, but this is not what you should optimize for in a professional language (as opposed to a teaching or scripting language). reply gpderetta 6 hours agorootparentThat's the Stroustrup Rule: For new features, people insist on LOUD explicit syntax. For established features, people want terse notation. reply marcosdumay 2 hours agorootparentYes, and that reduces to \"the more a feature is (expected to be) used, the terser should be it's syntax\", because people forget. reply jeroenhd 8 hours agoparentprevIn my opinon, the former syntax is easier to read. I've never found stacking keywords to be a very clear way of annotating types (see C's `unsigned long long`, where the second `long` is a shorthand for `long int`). The whole \"private final static\" chain already detracts from readability, in my opinion. I find the question mark to be quite clear (\"its a string, but is it? Could be nothing!\"), and I find the exclamation mark to be a clear opposite of the question mark. This annotation is also very common in other languages. I don't think it makes sense for Java to invent its own notation here. reply cageface 9 hours agoparentprevNo thanks. The extra noise of these keywords scattered everywhere would be a huge loss in readability in a language that is already way too verbose. As others have said, this is a very common convention in many languages now. You get used to it in a day. It also opens this door for nice sugar like the ?? operator. reply The_Colonel 9 hours agorootparentAgreed, the added verbosity is IMHO the reason why the (useful) keyword final isn't used as widely as it could. reply cageface 8 hours agorootparentOne of the few things I don’t like about Dart is that it uses final for constant values. It seems like a small thing but it adds up. Let would be much better. reply tikkabhuna 9 hours agoparentprevI agree. Golang's use of capital first letter to denote public is the most egregious use of this, for me. Completely non-obvious to newcomers and hard to search through code. reply tgv 7 hours agorootparentI think grep -E '^[a-z]+ [A-Z]' *.go will do. reply oftenwrong 2 hours agoparentprevWhich of these is easier to search for in a book or web page? Which will allow for clearer oral discussion? I prefer using long options in shell scripts for similar reasons. Easier for future maintainers to search for. reply nemetroid 8 hours agoparentprev> Which is easier to understand? After a ten-second explainer? The one with the punctuation marks. This is base vocabulary intended to be used very frequently, so it should be compact and unintrusive. reply nemetroid 6 hours agorootparentToo late to edit, but: > Equal signs make sense for assignment and equality because of mathy history. But question marks and exclamation marks don't make much sense for nullability. I think they do. The question mark expresses uncertainty (\"does this contain an actual String?\") and the exclamation mark expresses certainty (\"this definitely contains a String!\"). reply jeltz 8 hours agoparentprevThe first is easier to understand in a real codebase and not just a tiny snippet like this. The issue is that this is not the only keyword. reply splix 9 hours agoparentprevAnd since one of them may be a default option (i.e., the `nullable` as it's the current state), then it's just: private String? foo; private String! bar; // or private String foo; private nonnull String bar; reply demurgos 8 hours agorootparentYou need an explicit marker for compat with legacy code. The issue defines unspecified as \"a null may occur, but we don't know whether its presence is deliberate\". Explicit nullability fixes the missing information in older code. There could be other ways to mark opting into strict nullability through metadata at the class, module, package or VM level; but fine grained markers are the less disruptive for gradual migration. In particular this keeps the information local instead of relying on an ambient context. reply splix 7 hours agorootparentBut the \"older code\" is already written. And it's written with meaning \"a null may occur\". It doesn't seem to change anything related to legacy. reply demurgos 5 hours agorootparentAgreed that the type system treated `T` as nullable, but code may also have comments, annotations and invariants placing stronger constraints. This means that \"a null may occur\" also lived with \"this won't ever be null but the type system does not let me express it\" and in the absence of marker it's hard to distinguish both cases. reply dtech 9 hours agoparentprevT? is widespread syntax already. E.g. Typescript, C# and Kotlin use it. reply fabianholzer 8 hours agoparentprevAdding new keywords risks breaking code where the keyword is used as variable name, which would be not so far fetched for something like nullable. reply agumonkey 9 hours agoparentprevI'm still more in favor of Option reply haspok 7 hours agorootparent(An Option itself can still be null...) With an Option, you need to .orElse() if you want to access the value it is holding (or map it). With null restricted types you do this check upfront, when you convert a T to a T!, and from then you can use the value without any gymnastics. It is a bit like virtual threads vs effect systems, the monadic IO type gives you far more power, but with great power comes great responsibility (and complexity). If you can get compiler support for the simpler solution that will always be prefereable. reply jeltz 8 hours agorootparentprevSame, since nullability should be the exception then it is a good thing that is more verbose. reply masklinn 8 hours agorootparentThis is perfectly logical in languages which have defaulted to opt-in nullability from the start, but it’s heinous and would actively hinder migration in languages which are trying to transition (or something similar e.g. Swift is non-nullable but objc interop was a major design factor, and objc has absolutely ubiquitous nullability). reply jeltz 7 hours agorootparentNot sure why you think it is heinous but I agree with the other part. In a language where null was the default I do not see a migration path where Option can be used. Option only works for languages where nullability was never a thing. The issue is obvious in how useless the Optional class in Java is. reply shepherdjerred 1 hour agorootparentHow is Optional useless? I've found it to be very ergonomic, though I do wish there was more support for it in the standard library. reply martinsnow 9 hours agorootparentprevEw. reply revskill 8 hours agorootparentWhat does this mean ? reply agumonkey 7 hours agorootparentpreference for added syntax instead of generic type I assume understandable in a way but I'm more fond of types vs syntax reply masklinn 8 hours agoparentprevThe former. `?` and `!` are not modifiers on the variable, they are part of the type. The latter is just complete nonsense. Furthermore, Java is not correctly reinventing the wheel, both `?` and `!` have a lot of prior art as nullability type modifiers e.g. TypeScript, Swift, C#, Zig, … not to mention null-safe operators for which they are absolutely ubiquitous. reply Vt71fcAqt7 8 hours agoparentprevLots of languages already use this syntax. Dart is another besides the ones already mentioned. (It uses \"?\" and has nullable types by default without needing \"!\".) Also it kind of does make sense to me. A Java \"String\" is not actually a String. It's a String or null. It doesn't fit into set notation where null is an empty set, not part of other sets like integers ect. So calling it \"String?\" or \"Integer?\" makes more sense because it denotes that its value may be a String/Integer but it is not guaranteed to be so. reply WhereIsTheTruth 8 hours agoparentprevConciseness is better, for the same reason we don't do: int a = b plus c; It's easy to misguide people with regional words, symbols are universal reply riffraff 7 hours agorootparentConciness is a valid concern, but symbols are exactly as universal as words, just consider the division sign[0] in math, or the assignment operator in programming languages[1]. Plus, Java libraries used @Nullable and @NonNull annotations for >10 years, I doubt they would confuse anyone. [0] https://en.wikipedia.org/wiki/Division_sign [1] https://en.wikipedia.org/wiki/Assignment_(computer_science)#... reply jeltz 7 hours agorootparentprevIn the case of addition I kinda wish we actually did not have one enshrined operator. We have wrapping_add(), saturating_add(), checked_add() and undefined_overflow_add(). Which one should be default? reply elric 7 hours agorootparentprevCome now, that's a disingenuous take. I explicitly mentioned that some symbols make sense while others don't. Obviously the + sign is pretty universally known for addition. Overloading + for string concatenation was probably a more intuitive option than PHP's . concatenation operator. But not every symbol is as ubiquitous as the plus sign. reply MBCook 5 hours agoprevAs a Java developer this is great. I’ve started to use the @Nullable and @NotNull annotations a lot for parameters and return values and they’re very helpful. But they never made it into the language, so it’s only ‘enforced’ by the IDE and it’s a lot more visual noise than ? or ! which I’m already used to from other languages. I can’t wait, I hope it gets in. reply noelwelsh 9 hours agoprevI think we're still in the bashing rocks together stage of programming, but things like this definitely make me smile. Java is not an innovative language and the fact it is evolving towards something better shows that the industry as a whole is moving forward. We can't be more than a decade away from everyone being able to program in a language with the features of ML circa 1983. reply pas 8 hours agoparentScala is doing fine. ;P There's a huge inertia to \"strictly wrong, but already existing\", so there is a bias to keep maintaining those things. (And there are - at least - hundreds of thousands of programmers with huge status quo biases. We saw this mostly as C started to lose a lot of ground, finally, to safer languages with infinitely better tooling. It's that too many people put up with bad bad tools, mostly because they prefer very very incremental changes, and mostly those that give them results in \"functional requirements\".) reply staticlink 8 hours agorootparentScala is doing fine-ish. reply CharlieDigital 8 hours agoparentprev> Java is not an innovative language and the fact it is evolving towards something better... So basically C#? reply ygra 8 hours agorootparentIn this particular case it goes further. C#'s nullable-reference types are useful, have a few problems, e.g. • The feature is compile-time only (unsurprising considering the type narrowing approach is very similar to how TypeScript works) • It interacts weirdly with Nullable for structs since that already came before, uses some of the same syntax, but works differently because it's actually a type at runtime. Java seems to have the nice position here to make it consistent across value types and reference types (assuming Project Valhalla is ever done) and they seem to have opted to retain the types at runtime as well which will cause runtime checks. This may cause gripes about performance, but from a correctness standpoint it's definitely much nicer than just having APIs that tell you that null won't ever occur, only to still have that problem in certain cases. reply pjmlp 7 hours agorootparentprevIronically, given how C# came to be, Microsoft is now a OpenJDK contributor and has their own distribution, turns out it is quite valuable to do so for Azure. Just like 60% of Azure runs Linux workloads, as per official numbers. Interesting the rounds that the world makes. reply xxs 8 hours agoparentprev>Java is not an innovative language Most of the innovation when it comes to concurrency, garbage collection, JIT did come from Java. Syntax - that's more of an opinion/preference. My gripe with yet another \"improvement\" of the language is still the lack of headerless objects (aka value classes) - JEP 401[0] [0]: https://bugs.openjdk.org/browse/JDK-8251554 reply bkail 6 hours agorootparentnullability is directly related to the value classes effort (the top article mentions value classes, and the JEP you linked mentions nullability): in order to get the most benefit out of value classes, you need some way to express guaranteed non-nullability to avoid needing to encode null (imagine Point[] vs Point![]): https://cr.openjdk.org/~jrose/values/flattened-values.html#i... reply xxs 4 hours agorootparent'Value' classes would be useful in arrays only + some version of direct buffer mapping. All other cases are pretty uninteresting when it comes to performance or memory layouts. reply foooorsyth 8 hours agoparentprev>Java is not an innovative language Wild statement. Java certainly was incredibly innovative upon release. It didn’t explode in popularity by accident. reply jeroenhd 8 hours agorootparent\"Java is not an innovative language\" does not mean \"Java was never an innovative language\". I get the feeling Java seems to have suffered from its early success, pioneering things like generics in GC languages, which competitors like C# were able to do better, but only because Microsoft decided to break compatibility between .NET 1 and .NET 2 or because there was no compatibility to break. After that, the language seems to have shyed away from innovation out of fear of breaking things for a long time. In recent years, this has changed, but Java has a lot of language features to catch up on. Project Loom (green threading without coloured functions) is the first innovative thing I've seen Java do in recent history. reply pjmlp 7 hours agorootparentJava has done many nice things, but \"pioneering things like generics in GC languages,\" wasn't one of them. Here is a list of GC languages with generics that predated Java: CLU, ML, Standard ML, Caml Light, OCaml, Miranda, Haskell, Sather, Eiffel, Modula-2+, Modula-3. reply mu53 8 hours agorootparentprevthat was 30 years ago? New Java developers have been born after the original inception and learned the language long after. Reputations change over time. Core Java was staunchly against incorporating any functional features while the rest of the ecosystem was innovating reply Spivak 8 hours agorootparentSure, because Java isn't a functional language. Taking a wait-and-see approach to whether the style of programming will be a fad is defensible choice when you have to support it forever. And it kind of was a fad. The only thing that really came of it in most mainstream langages is passing functions as arguments. I've yet to encounter a code-base in the wild that's actually functional. reply noelwelsh 7 hours agorootparentWhat does functional mean to you? From my POV I see lots of features in Java coming from the functional programming world, but perhaps I have a different understanding of the term to what you do. reply edem 8 hours agoprev [6 more] [flagged] pjmlp 7 hours agoparent [–] Kotlin is only relevant on Android. And before someone tells me how they enjoy Kotlin on the backend, see StackOverflow 2024 results. reply Tainnor 4 hours agorootparent [–] > Kotlin is only relevant on Android Sure, that's why Spring has first class support for Kotlin, but go on. > see StackOverflow 2024 results. The number of people that enjoy Kotlin has absolutely no influence on my ability to enjoy or not enjoy it. reply pjmlp 3 hours agorootparent [–] Spring has first class support for any JVM language that helps them bring money to the table. Groovy and Scala were there first, where are all those Spring apps now? Heck I remeber when Groovy Spring was supposed to take over the Java Web application development, and alongside Grails wipeout all those Rails projects, with regular sessions at local JUGs. It definitly has an influence on available jobs. reply Tainnor 3 hours agorootparent [–] > Spring has first class support for any JVM language that helps them bring money to the table. The Kotlin support is on a complete different level. Go to https://start.spring.io/, you get an option of Java, Kotlin or Groovy - no Scala, Clojure etc. Dedicated Scala support especially never really took off. > It definitly has an influence on available jobs. I worked at two different companies on almost exclusively Kotlin codebases and have interviewed for several more. There are enough jobs to keep me employed with a good salary and even if those jobs disappeared, I would just learn some other language, no big deal. In the meantime, I get to use a language that's actually decently fun to write. I get that the very existence of Kotlin somehow offends you, but you don't have to shout it from every rooftop. There's enough space on the planet for everyone. reply pjmlp 2 hours agorootparent [–] What offends me is the anti-Java culture among Kotlin users, most pushed by Android folks, as if Kotlin would have any meaningful existence without the Java platform and ecosystem. \"Let's rewrite Java in Kotlin, duh\" \"Look how much better Kotlin is than Java boilerplate\" across Android docs, (show Java 8 example as counterpoint, in 2024) Looking forward to Kotlin/Native growing beyond the JVM, then. Otherwise it is really all about JetBrains and Google collaboration on ART. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "Java is introducing null-restricted and nullable types to improve null safety, similar to features in C# and Kotlin.",
      "This proposal offers three options: effectively nullable, explicitly nullable, and explicitly non-nullable, aiming to maintain backward compatibility with existing code.",
      "The new approach is designed to catch potential NullPointerExceptions (NPEs) at compile time, enhancing error checking and code reliability."
    ],
    "points": 186,
    "commentCount": 198,
    "retryCount": 0,
    "time": 1722585772
  },
  {
    "id": 41137658,
    "title": "SQLite vector search extension that runs anywhere",
    "originLink": "https://github.com/asg017/sqlite-vec",
    "originBody": "sqlite-vec An extremely small, \"fast enough\" vector search SQLite extension that runs anywhere! A successor to sqlite-vss Important sqlite-vec is a pre-v1, so expect breaking changes! Store and query float, int8, and binary vectors in vec0 virtual tables Written in pure C, no dependencies, runs anywhere SQLite runs (Linux/MacOS/Windows, in the browser with WASM, Raspberry Pis, etc.) Pre-filter vectors with rowid IN (...) subqueries sqlite-vec is a Mozilla Builders project, with additional sponsorship from Fly.io , Turso, and SQLite Cloud. See the Sponsors section for more details. Installing See Installing sqlite-vec for more details. Language Install More InfoPython pip install sqlite-vec sqlite-vec with PythonNode.js npm install sqlite-vec sqlite-vec with Node.jsRuby gem install sqlite-vec sqlite-vec with RubyGo go get -u github.com/asg017/sqlite-vec/bindings/go sqlite-vec with GoRust cargo add sqlite-vec sqlite-vec with RustDatasette datasette install datasette-sqlite-vec sqlite-vec with Datasettesqlite-utils sqlite-utils install sqlite-utils-sqlite-vec sqlite-vec with sqlite-utilsGithub ReleaseSample usage .load ./vec0 create virtual table vec_examples using vec0( sample_embedding float[8] ); -- vectors can be provided as JSON or in a compact binary format insert into vec_examples(rowid, sample_embedding) values (1, '[-0.200, 0.250, 0.341, -0.211, 0.645, 0.935, -0.316, -0.924]'), (2, '[0.443, -0.501, 0.355, -0.771, 0.707, -0.708, -0.185, 0.362]'), (3, '[0.716, -0.927, 0.134, 0.052, -0.669, 0.793, -0.634, -0.162]'), (4, '[-0.710, 0.330, 0.656, 0.041, -0.990, 0.726, 0.385, -0.958]'); -- KNN style query select rowid, distance from vec_examples where sample_embedding match '[0.890, 0.544, 0.825, 0.961, 0.358, 0.0196, 0.521, 0.175]' order by distance limit 2; /* ┌───────┬──────────────────┐ │ rowid │ distance │ ├───────┼──────────────────┤ │ 2 │ 2.38687372207642 │ │ 1 │ 2.38978505134583 │ └───────┴──────────────────┘ */ Sponsors Development of sqlite-vec is supported by multiple generous sponsors! Mozilla is the main sponsor through the new Builders project. sqlite-vec is also sponsored by the following companies: As well as multiple individual supporters on Github sponsors! If your company interested in sponsoring sqlite-vec development, send me an email to get more info: https://alexgarcia.xyz See Also sqlite-ecosystem, Maybe more 3rd party SQLite extensions I've developed sqlite-rembed, Generate text embeddings from remote APIs like OpenAI/Nomic/Ollama, meant for testing and SQL scripts sqlite-lembed, Generate text embeddings locally from embedding models in the .gguf format",
    "commentLink": "https://news.ycombinator.com/item?id=41137658",
    "commentBody": "SQLite vector search extension that runs anywhere (github.com/asg017)168 points by brylie 8 hours agohidepastfavorite23 comments alexgarcia-xyz 2 hours agoAuthor here, happy to answer any questions! Been working on this for a while, so I'm very happy to get this v0.1.0 \"stable\" release out. sqlite-vec works on MacOS, Linux, Windows, Raspberry Pis, in the browser with WASM, and (theoretically) on mobile devices. I focused a lot on making it as portable as possible. It's also pretty fast - benchmarks are hard to do accurately, but I'd comfortable saying that it's a very very fast brute-force vector search solution. One experimental feature I'm working on: You can directly query vectors that are in-memory as a contiguous block of memory (ie NumPy), without any copying or cloning. You can see the benchmarks for that feature here under \"sqlite-vec static\", and it's competitive with faiss/usearch/duckdb https://alexgarcia.xyz/blog/2024/sqlite-vec-stable-release/i... reply simonw 3 hours agoprevLots more details in Alex's blog post here: https://alexgarcia.xyz/blog/2024/sqlite-vec-stable-release/i... reply rsingel 2 hours agoparentWould this play nicely with datasette? reply simonw 2 hours agorootparentYes! There's a bug in the datasette-sqlite-vec plugin right now but expect a fix shortly. reply Cieric 2 hours agoprevI feel like I've touched a lot of things where something like this is useful (hobby projects). In my case I've done a recommendation engine, music matching (I specifically use it for matching anime to their data), and perceptual hash matching. reply alexgarcia-xyz 1 hour agoparentReally curious to hear about what kind of music embedding models/tools you used! I've tried finding some good models before but they were all pretty difficult to use reply Cieric 1 hour agorootparentIn the past I mainly screwed around with [2] musig as it was fairly easy to modify, right off hand I don't know why I stopped using it. [1] seek-tune (not-shazam) was just post here on hn yesterday, I had to modify it quite a bit to actually get something working in a way I was happy with. Overall it was a little slow, but that's not something I'm gonna fault the author for as the project is still quite new. While browsing around yesterday after messing with [2], I found [3] cpuimage/shazam. It's a little easier for me to screw around with as it's in c, and would probably be the one I try and modify to use this project. Everything is based on the shazam algorithm or something similar, so chunking the audio stream, and fingerprinting it. I was focused on that because it allows me to figure out where OP and ED are in some anime and allows me to add a skip button. Also since anime in the same season typically have the same OP/ED I can use that to try and auto categorize them after the first ones been identified. TL;DR: It's all shazam look alikes, everything else was to annoying to use. [1] https://github.com/cgzirim/seek-tune [2] https://github.com/sfluor/musig [3] https://github.com/cpuimage/shazam reply pjot 2 hours agoprevI’ve done something similar, but using duckDB as the backend. https://github.com/patricktrainer/duckdb-embedding-search reply youngbum 2 hours agoparentDuckdb is an excellent choice for this task, and it’s incredibly fast! We’ve also added vector search to our product, which is really useful. OpenAI’s official examples of embedding search use cosine similarity. But here’s the cool part: since OpenAI embeddings are unit vectors, you can just run the dot product instead! DuckDB has a super fast dot product function that you can use with SQL. In our product, we use duckdb-wasm to do vector searches on the client side. reply rkagerer 1 hour agorootparent>> In our product, we use duckdb-wasm to do vector searches on the client side. Curious, what is your product? Edit: Nevermind, your recent post explained it quite well: https://news.ycombinator.com/item?id=40520073 reply bhl 1 hour agorootparentprevWhat library do you use to compute embedding right now? I'm wondering if it's possible to do both embedding and vector search client-side for a local-first app. reply haolez 38 minutes agoprevWhat's the maximum vector size? reply alexgarcia-xyz 15 minutes agoparentvec0 virtual tables have a hard-coded max of 8192 dimensions, but I can raise that very easily (I wanted to reduce resource exhaustion attacks). But if you're comparing vectors manually, then the `vec_distance_ls()` and related functions have no limits (besides SQLite's 1GB blob limit) reply bodantogat 3 hours agoprevThis sounds useful (I do a lot of throw-away text analysis on my laptop) reply marvel_boy 2 hours agoparentCould anybody explain me a simple example how to do text analysis via this vector search. It just searches for the closer vector? reply alexgarcia-xyz 2 hours agorootparentYou can generate \"text embeddings\" (ie vectors) from your text with an embedding model. Once you have your text represented as vectors, then \"closest vector\" means \"more semantically similar\", as defined by the embedding model you use. This can allow you to build semantic search engines, recommendations, and classifiers on top of your text and embeddings. It's kindof like a fancier and fuzzier keyword search. I wouldn't completely replace keyword search with vector search, but it's a great addition that essentially lets you perform calculations on text reply bodantogat 1 hour agorootparentNice explanation. One use case where keywords haven't worked well for me , and (at least at first glance) vectors are doing better are longer passages -- finding sentences that are similar rather than just words. reply yAak 1 hour agorootparentprevThank you! This was an extremely helpful explanation to me, as someone not familiar on the topic. =) reply simonw 34 minutes agorootparentprevI put together an extensive guide to understanding embeddings and vector search last year: https://simonwillison.net/2023/Oct/23/embeddings/ reply brylie 2 hours agorootparentprevOne use case is for retrieving similar documents, such as when recommending related content. Another use case is retrieving document segments that are similar to a user query and passing them along with the user query to a large language model for improvement in the generated response. Vector search is also better in some ways than keyword search since it can find documents that are semantically similar even when the user may not have used the exact keyword, or even partial keywords like “Postgres” instead of “PostgreSQL.” reply mic47 3 hours agoprevNice. Been waiting for this release to try it out. reply pietz 2 hours agoprev [–] Is this also what turso uses in their \"AI feature\"? reply alexgarcia-xyz 2 hours agoparent [–] No, libsql added custom vector search directly into their library, while sqlite-vec is a separate SQLite extension. The libsql vector feature only works in libsql, sqlite-vec works in all SQLite versions. The libsql vector feature works kindof like pgvector, while sqlite-vec works more like the FTS5 full text SQLite extension. I'd say try both and see which one you like more. sqlite-vec will soon be a part of Turso's and SQLite Cloud's products. Turso's version: https://turso.tech/vector reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "sqlite-vec is a new SQLite extension for vector search, compatible with multiple platforms including Linux, MacOS, Windows, browsers with WebAssembly (WASM), and Raspberry Pis.",
      "It supports storing and querying float, int8, and binary vectors in virtual tables, written in pure C with no dependencies, and is backed by notable sponsors like Mozilla Builders and Fly.io.",
      "Installation is versatile, supporting various package managers such as pip for Python, npm for Node.js, gem for Ruby, go get for Go, cargo for Rust, and plugins for Datasette and sqlite-utils."
    ],
    "commentSummary": [
      "SQLite vector search extension, sqlite-vec, has been released in version 0.1.0 \"stable,\" supporting multiple platforms including MacOS, Linux, Windows, Raspberry Pi, and browsers via WebAssembly (WASM).",
      "The extension is noted for its speed in brute-force vector search and includes an experimental feature for querying in-memory vectors without copying, making it competitive with tools like faiss, usearch, and duckdb.",
      "The release is significant for applications in semantic search engines, recommendation systems, and classifiers, with a maximum vector size of 8192 dimensions, extendable, and no limits on `vec_distance_ls()` functions besides SQLite's 1GB blob limit."
    ],
    "points": 168,
    "commentCount": 23,
    "retryCount": 0,
    "time": 1722595281
  },
  {
    "id": 41135240,
    "title": "Oscar, an open-source contributor agent architecture",
    "originLink": "https://go.googlesource.com/oscar/+/refs/heads/master/README.md",
    "originBody": "Oscar, an open-source contributor agent architecture Oscar is a project aiming to improve open-source software development by creating automated help, or “agents,” for open-source maintenance. We believe there are many opportunities to reduce the amount of toil involved with maintaining open-source projects both large and small. The ability of large language models (LLMs) to do semantic analysis of natural language (such as issue reports or maintainer instructions) and to convert between natural language instructions and program code creates new opportunities for agents to interact more smoothly with people. LLMs will likely end up being only a small (but critical!) part of the picture; the bulk of an agent's actions will be executing standard, deterministic code. Oscar differs from many development-focused uses of LLMs by not trying to augment or displace the code writing process at all. After all, writing code is the fun part of writing software. Instead, the idea is to focus on the not-fun parts, like processing incoming issues, matching questions to existing documentation, and so on. Oscar is very much an experiment. We don't know yet where it will go or what we will learn. Even so, our first prototype, the @gabyhelp bot, has already had many successful interactions in the Go issue tracker. For now, Oscar is being developed under the auspices of the Go project. At some point in the future it may (or may not) be spun out into a separate project. The rest of this README explains Oscar in more detail. Goals The concrete goals for the Oscar project are: Reduce maintainer effort to resolve issues [note that resolve does not always mean fix] Reduce maintainer effort to resolve change lists (CLs) or pull requests (PRs) [note that resolve does not always mean submit/merge] Reduce maintainer effort to resolve forum questions Enable more people to become productive maintainers It is a non-goal to automate away coding. Instead we are focused on automating away maintainer toil. Approach Maintainer toil is not unique to the Go project, so we are aiming to build an architecture that any software project can reuse and extend, building their own agents customized to their project's needs. Hence Oscar: open-source contributor agent architecture. Exactly what that will mean is still something we are exploring. So far, we have identified three capabilities that will be an important part of Oscar: Indexing and surfacing related project context during contributor interactions. Using natural language to control deterministic tools. Analyzing issue reports and CLs/PRs, to help improve them in real time during or shortly after submission, and to label and route them appropriately. It should make sense that LLMs have something to offer here, because open-source maintenance is fundamentally about interacting with people using natural language, and natural language is what LLMs are best at. So it‘s not surprising that all of these have an LLM-related component. On the other hand, all of these are also backed by significant amounts of deterministic code. Our approach is to use LLMs for what they’re good at—semantic analysis of natural language and translation from natural language into programs—and rely on deterministic code to do the rest. The following sections look at each of those three important capabilities in turn. Note that we are still experimenting, and we expect to identify additional important capabilities as time goes on. Indexing and surfacing related project context Software projects are complex beasts. Only at the very beginning can a maintainer expect to keep all the important details and context in their head, and even when that‘s possible, those being in one person’s head does not help when a new contributor arrives with a bug report, a feature request, or a question. To address this, maintainers write design documentation, API references, FAQs, manual pages, blog posts, and so on. Now, instead of providing context directly, a maintainer can provide links to written context that already exists. Serving as a project search engine is still not the best use of the maintainer's time. Once a project grows even to modest size, any single maintainer cannot keep track of all the context that might be relevant, making it even harder to serve as a project search engine. On the other hand, LLMs turn out to be a great platform for building a project search engine. LLMs can analyze documents and produce embeddings, which are high-dimensional (for example, 768-dimensional) floating point unit vectors with the property that documents with similar semantic meaning are mapped to vectors that point in similar directions. (For more about embeddings, see this blog post.) Combined with a vector database to retrieve vectors similar to an input vector, LLM embeddings provide a very effective way to index all of an open-source project's context, including documentation, issue reports, and CLs/PRs, and forum discussions. When a new issue report arrives, an agent can use the LLM-based project context index to identify highly related context, such as similar previous issues or relevant project documentation. Our prototype agent implements this functionality and replies to new issues in the Go repository with a list of at most ten highly related links that add context to the report. (If the agent cannot find anything that looks related enough, it stays quiet and does not reply at all.) In the first few weeks we ran the agent, we identified the following benefits of such an agent: The agent surfaces related context to contributors. It is common for new issue reports to duplicate existing issue reports: a new bug might be reported multiple times in a short time window, or a non-bug might be reported every few months. When an agent replies with a link to a duplicate report, the contributor can close their new report and then watch that earlier issue. When an agent replies with a link to a report that looks like a duplicate but is not, the contributor can provide added context to distinguish their report from the earlier one. For example, in golang/go#68196, after the agent replied with a near duplicate, the original reporter commented: Good bot :). Based on the discussion in this issue, I understand that it might not be possible to do what‘s being suggested here. If that’s the case I'd still suggest to leave the issue open for a bit to see how many Go users care about this problem. As another example, on golang/go#67986, after the agent replied with an exact duplicate, the original reporter commented: Drats, I spent quite a bit of time searching existing issues. Not sure how I missed [that one]. The agent surfaces related context even to project maintainers. Once a project reaches even modest size, no one person can remember all the context, not even a highly dedicated project maintainer. When an agent replies with a link to a related report, that eliminates the time the maintainer must spend to find it. If the maintainer has forgotten the related report entirely, or never saw it in the first place (perhaps it was handled by someone else), the reply is even more helpful, because it can point the maintainer in the right direction and save them the effort of repeating the analysis done in the earlier issue. For example, in golang/go#68183, a project maintainer filed a bug against the Go compiler for mishandling certain malformed identifiers. The agent replied with a link to a similar report of the same bug, filed almost four years earlier but triaged to low priority. The added context allowed closing the earlier bug and provided an argument for raising the priority of the new bug. As another example, in golang/go#67938, a project maintainer filed a bug against the Go coverage tool for causing the compiler to report incorrect sub-line position information. The agent replied with an earlier related issue (incorrect line numbers) from a decade earlier as well as a more recent issue about coverage not reporting sub-line position information at all. The first bug was important context, and the second bug's “fix” was the root cause of the bug in the new report: the sub-line position information added then was not added correctly. Those links pinpointed the exact code where the bug was. Once that was identified, it was also easy to determine the fix. The agent interacts with bug reporters immediately. In all of the previous examples, the fact that the agent replied only a minute or two after the report was filed meant that the reporter was still available and engaged enough to respond in a meaningful way: adding details to clarify the suggestion, closing the report as a duplicate, raising bug priority based on past reports, or identifying a fix. In contrast, if hours or days (or more) go by after the initial report, the original reporter may no longer be available, interested, or able to provide context or additional details. Immediately after the bug report is the best time to engage the reporter and refine the report. Maintainers cannot be expected to be engaged in this work all the time, but an agent can. Finally, note that surfacing project context is extensible, so that projects can incorporate their context no matter what form it takes. Our prototype's context sources are tailored to the Go project, reading issues from GitHub, documentation from go.dev, and (soon) code reviews from Gerrit, but the architecture makes it easy to add additional sources. Using natural language to control deterministic tools The second important agent capability is using natural language to control deterministic tooling. As open-source projects grow, the number of helpful tools increases, and it can be difficult to keep track of all of them and remember how to use each one. For example, our prototype includes a general facility for editing GitHub issue comments to add or fix links. We envision also adding facilities for adding labels to an issue or assigning or CC‘ing people when it matches certain criteria. If a maintainer does not know this functionality exists it might be difficult to find. And even if they know it exists, perhaps they aren’t familiar with the specific API and don't want to take the time to learn it. On the other hand, LLMs are very good at translating between intentions written in natural language and executable forms of those intentions such as program code or tool invocations. We have done preliminary experiments with Gemini selecting from and invoking available tools to satisfy natural language requests made by a maintainer. We don't have anything running for real yet, but it looks like a promising approach. A different approach would be to rely more heavily on LLMs, letting them edit code, issues, and so on entirely based on natural language prompts with no deterministic tools. This “magic wand” approach demands more of LLMs than they are capable of today. We believe it will be far more effective to use LLMs to convert from natural language to deterministic tool use once and then apply those deterministic tools automatically. Our approach also limits the amount of “LLM supervision” needed: a person can check that the tool invocation is correct and then rely on the tool to operate deterministically. We have not built this part of Oscar yet, but when we do, it will be extensible, so that projects can easily plug in their own tools. Analyzing issue reports and CLs/PRs The third important agent capability is analyzing issue reports and CLs/PRs (change lists / pull requests). Posting about related issues is a limited form of analysis, but we plan to add other kinds of semantic analysis, such as determining that an issue is primarily about performance and should have a “performance” label added. We also plan to explore whether it is possible to analyze reports well enough to identify whether more information is needed to make the report useful. For example, if a report does not include a link to a reproduction program on the Go playground, the agent could ask for one. And if there is such a link, the agent could make sure to inline the code into the report to make it self-contained. The agent could potentially also run a sandboxed execution tool to identify which Go releases contain the bug and even use git bisect to identify the commit that introduced the bug. As discussed earlier, all of these analyses and resulting interactions work much better when they happen immediately after the report is filed, when the reporter is still available and engaged. Automated agents can be on duty 24/7. We have not built this part of Oscar yet, but when we do, it too will be extensible, so that projects can easily define their own analyses customized to the reports they receive. Prototype Our first prototype to explore open-source contributor agents is called Gaby (for “Go AI bot”) and runs in the Go issue tracker, posting as @gabyhelp. The source code is in internal/gaby in this repository. The gaby package's documentation explains the overall structure of the code in the repository as well. So far, Gaby indexes Go issue content from GitHub as well as Go documentation from go.dev and replies to new issues with relevant links. We plan to add Gerrit code reviews in the near future. Gaby‘s structure makes it easy to run on any kind of hosting service, using any LLM, any storage layer, and any vector database. Right now, it runs on a local workstation, using Google’s Gemini LLM, Pebble key-value storage files, and an in-memory vector database. We plan to add support for a variety of other options, including Google Cloud Firestore for key-value storage and vector database. Firestore in particular will make it easy to run Gaby on hosted platforms like Cloud Run. Running on hosted platforms with their own URLs (as opposed to a local workstation) will enable subscribing to GitHub webhooks, so that Gaby can respond even more quickly to issues and also carry on conversations. Our experience with all of this will inform the eventual generalized Oscar design. There is much work left to do. Relationship to Gopherbot The Go project has run its own completely deterministic agent, @gopherbot, for many years. That agent is configured by writing, reviewing, and checking in Go code in the golang.org/x/build/cmd/gopherbot package. Having the agent has been an incredible help to the Go project and is part of the inspiration for Oscar. At the same time, we are aiming for an even lighter-weight way to configure new agent behaviors: using natural language to control general behaviors. Over time, our goal is to merge @gabyhelp back into @gopherbot by re-building @gopherbot as an Oscar agent. Discussion and Feedback We are excited about the opportunities here, but we recognize that we may be missing important concerns as well as important opportunities to reduce open-source maintainer toil. We have created this GitHub discussion to discuss both concerns and new ideas for ways that Oscar-based agent can help improve open-source maintenance. Feedback there is much appreciated. Powered by Gitiles| Privacy| Terms",
    "commentLink": "https://news.ycombinator.com/item?id=41135240",
    "commentBody": "Oscar, an open-source contributor agent architecture (googlesource.com)150 points by theptip 17 hours agohidepastfavorite21 comments anotherpaulg 8 hours agoI feel this pain as a solo maintainer of a somewhat popular open source project. More users brings more questions in GitHub issues and Discord. That’s one reason I added interactive help [0] to aider. Users can type `/help ` in the app to get AI help, based on all of aider’s docs. I’ve been considering turning it into a bot for GitHub issues and discord. Dosu [1] is another app in this “triage issues” space that looks really good when I encounter it in the wild. [0] https://aider.chat/docs/troubleshooting/support.html [1] https://dosu.dev/ reply mrwyz 1 hour agoparentI handle this by redirecting all questions (anything that isn't a feature request or a bug report) to the project's community forum (hosted on discourse). Then I wrote and deployed https://github.com/pierotofy/issuewhiz to automatically catch and close issues that are identified as questions. GitHub issues is not the place to ask questions, in my opinion. Here's an example of it in action: https://github.com/LibreTranslate/LibreTranslate/issues/632 It's been working pretty well. reply monkmartinez 1 hour agorootparentThank you for using discourse! It is sooooo much better than discord. I really, really can't stand discord. Searching for an issue or topic is like wading into the ocean looking for a bluegill. reply muixoozie 4 hours agoparentprevHave you tried to apply for GitHub Sponsors? Kinda surprised to see aider.chat is solo maintained. I keep seeing it as one of the best at what it does. Though I haven't tried it out much. I'm waiting for NixOS packaging of it [0]. Note someone wants aider bad enough they put a bounty on it getting packaged in nixpkgs. - [0] https://github.com/NixOS/nixpkgs/issues/330726 reply bogwog 5 hours agoparentprevI think it would be much more effective if \"/help \" just redirected users to a search engine. That won't find stuff on Discord of course, which is a good reason to not use Discord at all. No need to use some elaborate AI solution for such a simple (and long-time solved) problem. reply theptip 2 hours agorootparentHave you actually used a frontier LLM for this usecase? It’s quite different from a search engine. In the case where someone asked your exact precise question including follow-ups, you get the same (or better) results from search. In most cases for a small project, no one has answered your precise question, so you might need to read docs and figure it out. It’s often much quicker to use an LLM here (though sometimes less accurate than the hypothetical matching search result). As a benchmark, try using an LLM vs. search for answering questions about Nix. I find it to be 10-100x more efficient than searching and reading through the docs (including hallucinations and time spent corroborating, since usually I can validate the answer by running some command). This is perhaps a cherry-pick for LLMs, but it should illustrate clearly why “just use search” is missing the value prop completely. reply anotherpaulg 4 hours agorootparentprevThe interactive help has the full context of the user's current aider session: what they're working on in the coding chat, active config settings, their OS & shell, etc. Aider can tailor the help response to exactly their question and situation. It also always links to relevant docs in these help responses. I've pasted doc links in reply to user questions in discord, and I've pasted /help output. The latter is far more helpful, and includes the links as a bonus. reply eddd-ddde 2 hours agorootparentprevSearch engines are not as good, and in my experience search engines don't help _at all_ with questions, unless the question already exists online (and has been answered). The moment your question is more than 5 words long you can forget about it. reply lmeyerov 16 hours agoprevIt sounds like the indexer is go-specific, while aigen and others are going multilingual via treesitter (I believe) I'm curious if there are any projects folks like for the indexing/embedding step, like Git repo -> vector index / graph index of code + comments + docs? (I am not as interested in the RAG, LLM, UX, etc after) reply codelion 14 hours agoparentWe have a patchflow that does that in patchwork - https://github.com/patched-codes/patchwork it is called ResolveIssue - https://github.com/patched-codes/patchwork/tree/main/patchwo... reply lmeyerov 12 hours agorootparentafaict patchwork also sits on top of treesitter for indexing ? https://github.com/patched-codes/patchwork/blob/b24a3ee07040... reply codelion 12 hours agorootparentYes, we also use treesitter. reply seveibar 14 hours agoprevI think they should expand the scope to direct contribution for easy issues (right now Oscar seems mostly for surfacing project information to contributors), I've had a lot of luck using aider + sonnet for direct contribution, and I'm pretty sure you could do it at scale for \"getting-started\" issues. [1] Github bot that does direct contributions https://github.com/tscircuit/bunaider [2] Example contribution https://github.com/tscircuit/checks/pull/8 reply jclulow 14 hours agoparentDear god I want off Mr Bone's Wild Ride. I can't wait for even more pull request spam, now fully automated. reply jamilton 2 hours agoparentprevI think it's good that they're focusing on all the not-code parts of contributing, as you say there are other projects for code contributions. reply keybored 8 hours agoparentprev> > Oscar differs from many development-focused uses of LLMs by not trying to augment or displace the code writing process at all. After all, writing code is the fun part of writing software. reply codelion 12 hours agoparentprevWe also tried to implement a GH Issue to PR workflow in patchwork - https://github.com/patched-codes/patchwork It is a bit hard to get it to work reliably except for small changes. reply LeSaucy 15 hours agoprev [–] Very interesting to see if they are successful, and/or if this type of maintainer load reducing could be adapted to something like ubuntu/debian where maintaining packages is quite time consuming. reply remram 5 hours agoparentThe value of Debian/Ubuntu is that there are people vetting and packaging and testing software. If you remove that and have AI do it, there isn't much left. reply derefr 3 hours agorootparentThis agent isn't claiming to displace that work; more like act as the contribution equivalent of Tier 1 Support in a customer-service setting (where the actual project maintainers would then be Tier 2 Support). Such agents would mostly provide guidance to jumping through the hoops necessary to get your PR in a state where it's mergeable according to the project's contribution guidelines — removing the need for humans to be that guide. (In other words, they'd act as a \"compiler for your PR\" that you could iterate on, with good English-language error messages. IMHO something that should already exist locally — but git has no local reified concept of PRs, so this is hard.) But I would expect that in almost every case, the project's human maintainers would still eventually step in to review the PR, after the bot seems happy with it. --- Mind you, in theory, for a particular set of limited-scope (but frequently occurring) problems, Tier 1 Support agents are usually empowered to solve those problems directly for a customer. And likewise, there could potentially be a set of limited-scope contribution types that a Tier 1 Project Contribution Auditor would be able to directly approve. Things like, say, fixing typos in doc comments (gated by the bot determining that the diff increases semantic validity of the text by some weird LLM \"parseability\" metric.) reply codelion 14 hours agoparentprev [–] We have a few large open source projects already using patchwork to help manage issues and PRs - https://github.com/patched-codes/patchwork reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Oscar is an open-source project designed to automate software maintenance tasks using large language models (LLMs) for semantic analysis and natural language processing.",
      "Unlike other LLM applications, Oscar focuses on non-coding tasks such as processing issues and matching questions to documentation, aiming to reduce the workload on maintainers.",
      "The first prototype, @gabyhelp, has been successfully tested in the Go issue tracker, and future plans include expanding capabilities and integrating with other tools and platforms."
    ],
    "commentSummary": [
      "Oscar, an open-source contributor agent architecture, aims to streamline project maintenance for solo maintainers.",
      "Solutions like interactive help in aider, bots for issue triage, and tools like issuewhiz are being used to manage GitHub issues effectively.",
      "Projects like patchwork and tools like aider + sonnet show promise in automating contributions, though human oversight remains crucial."
    ],
    "points": 149,
    "commentCount": 21,
    "retryCount": 0,
    "time": 1722560977
  },
  {
    "id": 41133390,
    "title": "GitOpper: GitOps Without Kubernetes",
    "originLink": "https://github.com/miekg/gitopper",
    "originBody": "%%% title = \"gitopper 8\" area = \"System Administration\" workgroup = \"Git Operations\" %%% gitopper Name gitopper - watch a git repository, pull changes and reload the server process Synopsis gitopper [OPTION]... -c CONFIG Description Gitopper is GitOps for non-Kubernetes folks it watches a remote git repo, pulls changes and HUP the server (service) process. A sparse (but with full history) git checkout will be done, so each service will only see the files it will actually need. Several bind mounts are then setup to give the service access to the file(s) in Git. If the target directories don't exist, they will be created, with the current user - if specified. This tool does little more than just pull the repo, but the little it brings to the table allows for a GitOps workflow without resorting to Kubernetes like environments. The Git repository that you are using to provision the services must have at least one (sub)directory for each service. Gitopper will install packages if told to do so. It will not upgrade or downgrade them, assuming there is a better way of doing those. The remote interface of gitopper uses SSH keys for authentication, this hopefully helps to fit in, in a sysadmin organisation. The following features are implemented: Metrics: are included see below, they export a Git hash, so a rollout can be tracked. Diff detection: possible using the metrics or gitopperctl. Out of band rollbacks: use gitopperctl to bypass the normal Git workflow. No client side processing: files are used as they are in the Git repo. Canarying: give a service a different branch to check out. The options are: -h, --hosts strings : hosts (comma separated) to impersonate, local hostname is always added -c, --config string : config file to read -s, --ssh string : ssh address to listen on (default \":2222\") -m, --metric string : http metrics address to listen on (default \":9222\") -d, --debug : enable debug logging -r, --restart : send SIGHUP to ourselves when config changes -o, --root : require root permission, setting to false can aid in debugging (default true) -t, --duration duration : default duration between pulls (default 5m0s) For bootstrapping gitopper itself the following options are available: -U, --upstream string : use this git repo to clone and to bootstrap from -D, --directory string : directory to sparse checkout (default \"gitopper\") -B, --branch string : check out in this branch (default \"main\") -M, --mount string : check out into this directory, -c is relative to this directory -P, --pull : pull (update) the git repo to the newest version before starting Quick Start Generate a toy SSH key: ssh-keygen -t ed25519 and make it write to an id_ed25519_gitopper file. Put the path to the PUBLIC key (ending in .pub) in the keys fields of [global] of the following config.toml file. Start as root: sudo ./gitopper -c config.toml -h localhost [global] upstream = \"https://github.com/miekg/gitopper-config\" branch = \"main\" mount = \"/tmp/gitopper\" keys = [{ path = \"keys/id_ed25519_gitopper.pub\", ro = true }, ] [[services]] machine = \"localhost\" service = \"prometheus\" user = \"prometheus\" package = \"prometheus\" action = \"reload\" dirs = [{ local = \"/etc/prometheus\", link = \"prometheus/etc\" }, ] And things should work then. I.e. in /etc/prometheus you should see the content of the miekg/gitopper-config repository. Note that the prometheus package is installed, because package is mentioned in the config file. The checked out git repo in /tmp/prometheus should only contain the prometheus directory thanks to the sparse checkout. Changes made to any other subdirectory in that repo do not trigger a prometheus reload. Then with gitopperctl(8) you can query the server: ./gitopperctl -ilist service @localhost # SERVICE HASH STATE INFO CHANGED 0 prometheus 606eb576 OK Fri, 18 Nov 2022 09:14:52 UTC Services A service can be in 5 states: OK, FREEZE, ROLLBACK (which is a FREEZE to a previous commit) and BROKEN/DIFF. These state are not carried over when gitopper crashes/stops (maybe we want this to be persistent, would be nice to have this state in the git repo somehow?). OK: everything is running and we're tracking upstream. FREEZE: everything is running, but we're not tracking upstream. ROLLBACK: everything is running, but we're not tracking upstream and we're pinned to an older commit. This state is quickly followed by FREEZE if we were successful rolling back, otherwise BROKEN (systemd error) of DIFF (git error) BROKEN: something with the service is broken, we're still tracking upstream. I.e. systemd error. DIFF: the git repository can't be reconciled with upstream. I.e. git error. ROLLBACK is a transient state and quickly moves to FREEZE, unless something goes wrong then it becomes BROKEN, or DIFF depending on what goes wrong (systemd, or git respectively). +-------------------------+| v*OK -------> ROLLBACK ---> FREEZE/ \\| / \\ v||v v| BROKEN DIFF||||+--------+---------+------+ *OK is the start state from OK and FREEZE we can still end up in BROKEN and FREEZE and vice versa. Config File # global options are applied if a service doens't list them [global] upstream = \"https://github.com/miekg/gitopper-config\" # repository where to download from mount = \"/tmp\"# directory where to download to, mount+service is used as path # ssh keys that are allowed in via authorized keys keys =[{ path = \"keys/miek_id_ed25519_gitopper.pub\" },{ path = \"keys/another_key.pub\", ro = true }, ] # each managed service has an entry like this [[services]] machine = \"prometheus\" # hostname of the machine, so a host knows when to pick this up. service = \"prometheus\" # service identifier, if it's used by systemd it must be the systemd service name action = \"reload\" # call systemctl when the git repo changes, may be empty branch = \"main\" # what branch to check out package = \"prometheus\" # as used by package mgmt, may be empty (not implemented yet) user = \"prometheus\" # do the check out with this user # what directories or files from the repo to mount under the local directories dirs = [ { local = \"/etc/prometheus\", link = \"prometheus/etc\" }, # prometheus/etc *in the repo* should be mounted under /etc/prometheus { local = \"/etc/caddy/Caddyfile\", link = \"caddy/etc/Caddyfile\", file = true }, # caddy/etc/Caddyfile *in the repo* should be mounted under /etc/caddy/Caddyfile ] Note that machine above should match either the machine name ($HOSTNAME) or any of the values you give on the -h flag. This allows you to create services that run everywhere, by defining a service that have name (say) \"localhost\" and then deploying gitopper with -h localhost on every machine. Options for each service: machine: the machine where this service should be active. By default gitopper will know the current hostname, but multiple aliases may be given to it via the -h flag. service: what systemd unit file is used to call action on. If service contains an @ a service template unit is assumed and gitopper will then run systemctl enableto enable the service template. action: action to use when calling systemctl . If empty no systemd command will be issued when the repo changes. branch: what branch to use in the checked out repo. Note different branches that use the same repository on disk, will error on startup. package: what package to install for this service. If empty, no package will be installed. user: what user should the git repository belong to. dirs: describe the mapping between directories and files in the repository and on the local disk. local is the on disk name, and link is the relative path of the directory or file in the git repo. If a single file is used, file should be set to true. How to Break It Moving to a new user, will break git pull, with an error like 'dubious ownership of repository'. If you want a different owner for a service, it's best to change the mount as well so you get a new repo. Gitopper is currently not smart enough to detect this and fix things on the fly. Interface Gitopper opens two ports: 9222 for metrics and 2222 for the rest-protocol-over-SSH. For any interaction with gitopper over this port your key must be configured for it. The following services are implemented: List all defined machines. List services run on the machine. List a specific service. Freeze a service to the current git commit. Unfreeze a service, i.e. to let it pull again. Rollback a service to a specific commit. For each of these gitopperctl(8) will execute a \"command\" and will parse the returned JSON into a nice table. Metrics The following metrics are exported: gitopper_service_state{\"service\"}gitopper_service_change_time_seconds{\"service\"}gitopper_machine_git_errors_total - total number of errors when running git. gitopper_machine_git_ops_total - total number of git runs. Metrics are available under the /metrics endpoint on port 9222. Exit Code Gitopper has following exit codes: 0 - normal exit 2 - SIGHUP seen (signal to systemd to restart us) Bootstrapping There are a couple of options that allow gitopper to bootstrap itself and make gitopper to be managed by gitopper. Basically those options allow you to specify a service on the command line. Gitopper will check out the repo and then proceed to read the config in that repo and setup everything from there. I.e.: ... -c config.toml -U https://github.com/miekg/gitopper-config -D gitopper -M /tmp/ Will sparse check out (only the gitopper (-D flag) directory) of the repo gitopper-config (-U flag) in /tmp/gitopper (-M flag, internally '/gitopper' is added) and will then proceed to parse the config file /tmp/gitopper/gitopper/config.toml and proceed with a normal startup. Note this setup implies that you must place config.toml inside a gitopper directory, just as the other services must have their own subdirectories, gitopper needs one too. The gitopper service self is also added to the managed services which you can inspect with gitopperctl(8). Any keys that have relative paths, will also be changed to key inside this Git managed directory and pick up keys from that repo. The -P flag can be given to pull the repository even if it already exists, sometimes you need to the newest version to properly bootstrap. For normal services the \"git pull\" routine will automatically rectify it and restart the service. See Also See this design doc, and gitopperctl(8).",
    "commentLink": "https://news.ycombinator.com/item?id=41133390",
    "commentBody": "GitOpper: GitOps Without Kubernetes (github.com/miekg)128 points by fanf2 22 hours agohidepastfavorite38 comments arjvik 15 hours agoOne of my favorite GitOps tricks is adding a post-recieve.hook with the contents: #!/bin/bash echo -e \"\\e[1;31mUpdating worktree and fetching remotes\\e[m\" git --git-dir=\"$GIT_DIR\" --work-tree=\"$GIT_DIR/..\" reset --hard git --git-dir=\"$GIT_DIR\" fetch origin master while read oldref newref refname; do echo -e \"\\e[1;32mPushed ${refname##refs/heads/}\\t${oldref::7} -> ${newref::7}\\e[m\" done echo -e \"\\e[1;31mRestarting service\\e[m\" # Run whatever command is needed to restart the service So that I can Heroku-style `git push` to my server (an ssh remote named \"deploy\") in order to deploy code! reply dewey 8 hours agoparentI recently set up Dokku for that kind of workflow recently, I'm super happy with my new setup which makes it very easy to throw up quick static pages or just push a Rails app and it'll basically just work Heroku style (It's using Heroku's buildpacks). reply cyrnel 15 hours agoprevGlad to see something like this, if only to point out that even without containers and Kubernetes, a proper deployment tool is a lot more complex than whatever shell script or Makefile you cooked up on your own. Error handling, timeouts, deployment state management, rollback logic, authentication, and a pause feature are the irreducible complexity of a robust deployment method. reply JamesSwift 50 minutes agoparentEhh, I think the capistrano model of deployments is a pretty good 'bare minimum' of features without tooling. Basically, just use a rolling symlink of timestamped deploys: releases/ release-2024-01-01 release-2024-01-02 release-2024-01-07 current -> releases/release-2024-01-07 Make a new one on a new deploy, and only update the symlink on success. Rollback is changing the symlink. Pause is just cancelling the scp. Auth is just linux accounts. Its a simple model. reply fariszr 10 hours agoprevI built something similar, a github action for doing gitops with docker compose (or swarm): https://github.com/FarisZR/docker-compose-gitops-action For other stuff I just use another version of the action to deploy files using Tailscale SSH: https://github.com/FarisZR/tailscale-ssh-deploy reply someguy101010 20 hours agoprevIf you use nixos there's also https://github.com/nlewo/comin reply jeppesen-io 20 hours agoparentThis is interesting - maybe it's time I use flakes... reply lewo 11 hours agorootparentWe have an issue to support non flake deployments: https://github.com/nlewo/comin/issues/30 reply nothrabannosir 11 hours agorootparentprevIf you want a basic version of this you can just use the built-in system.autoUpgrade = { enable = true; flake = \"github:you/dotfiles\"; }; reply zdw 17 hours agoparentprevIs this named from the overweight cat meme? reply lewo 12 hours agorootparentNo, it has been initially developed to manage a \"COMmunity INfrastructure\" and it sounds like the word \"coming\". I didn't know this meme but it's a nice coincidence because this infrastructure is actually a kind of \"CHATONS\" [1] (kitten in french)! Thx for the ref which could be useful for a future logo! [1] https://www.chatons.org/en reply habosa 15 hours agoprevMaybe this should be GitOps without Docker? Which is something that’s pretty attractive to me for personal projects. reply e-Minguez 7 hours agoprevI used https://github.com/kubernetes/git-sync to sync the coredns config and zones so I can have gitops DNS style (coredns can watch for both config and zone changes and reload them dynamically) reply Spivak 20 hours agoprevHighly recommend ansible-pull [1] as well for this job. Not because Ansible is amazing or anything but because every use-case you can think of likely already has a module. [1] https://docs.ansible.com/ansible/latest/cli/ansible-pull.htm... reply hhh 20 hours agoparentI've been using ansible-pull for like 3-5(?) years now, and it's been pretty awesome. We use it to do bare-metal device management. reply btreecat 16 hours agoprevCurious when I might use this over GH Actions or GL Runners? reply quectophoton 31 minutes agoparentAt least three situations that come to mind without even trying to think at all(*), after just skimming the readme: - When you don't use GitHub or GitLab. - When you use GitHub or GitLab, but you don't have write permissions to use the repository (e.g. because you don't own it). - When you just want to deploy a VM image or a container (either one instance, or multiple instances), and be able to shut them down, but don't want to bother updating the repository pipeline references every time. Maybe the image/container is actually a FreeBSD jail created from a ZFS snapshot, with a repository hosted in a NAS. Note: I won't use this project so I'm not trying to justify its existence or usefulness. For all I know, it's just someone's pet project that the author only intends to use themselves, but someone else submitted to HN. (* EDIT: On retrospect this actually comes off as negative, but I meant this as in \"my reasons might not even be all that good\" due to me not being that interested in the first place, and not as a judgement or anything like that. Leaving it as-is for transparency.) reply jyufnlwfnzvbm 14 hours agoprevIs this when you don't require availability reply politelemon 11 hours agoparentYou may or may not be joking, but gitops has been the cause of outages for us in quite a few instances. I have been unable to stress what a terrible idea arbitrarily pulling and applying from git is. I am unable to stress it because that's the overwhelming way that many k8s setups are done, so clearly they cannot be wrong. reply Yasuraka 9 hours agorootparentYour main or release branches should not have untested or unreviewed changes. If they do, they are the cause. Outages after deploying are then just the effect. reply ramon156 10 hours agorootparentprevI'm unsure what the alternative is. Even without gitops people do the same hand labour with the commandline, so why is GitOps specifically bad? reply filleokus 8 hours agorootparentWhen I started out with Kubernetes Gitops hadn't really gained any momentum. We just used normal CI/CD pipeline tooling. For our own apps the pipeline simply built the docker image, pushed it, and then ran kubectl apply. No manual labour, no magic. For third party stuff (like helm charts for ELK or whatever) it was the same but with helm cli/kubectl, without building the image. I don't know why really, but gitops have never seemed that nice for me. It's perhaps kinda useful for third party stuff. But for your own applications, where you need to actually build the docker image and then either manually bump the tag or have some rube goldberg machinery committing to your repos, it just seems annoying. Wanna see the state / source of truth? Use kubectl (or some other tool), we have this whole cluster just for keeping track of the state. Wanna see how/why/by who something was deployed? Look at the CI/CD tooling history. reply zufallsheld 8 hours agorootparentIsn't what you did also gitOps, except that it's push based and not pull based? reply filleokus 8 hours agorootparentWhat's really a True Scotsman? But I wouldn't really say so, no. I think [0] represent what I would consider a gitops pushed based approach, the way we did it differed in two main ways: - (1) We didn't have any \"environment repository\". The manifest files were in the same repository as the application code - (2) Perhaps more importantly: The manifest files did not _exactly_ represent what was deployed. We had a template-variable in the Deployment yaml file, where the Github action substituted the tag that had just been built. To see which version was deployed you either had to look in the cluster, or the Github Action logs. [0]: https://www.gitops.tech/#push-based-deployments reply Unroasted6154 9 hours agorootparentprevIf you use something like ArgoCD (and maybe also Argo Rollouts) you can do the diffing from Git automatically but either put a manual validation step where you have a chance to review the diff or implement some gradual rollout strategy. Also, it's probably wise to use a branch/tagging strategy and not read from head. Bottom line is: GitOps means the source of truth is Git and automation makes sure to avoid drifts. You still have to have a rollout strategy and schedule that makes sense for your usecase. reply lsofzz 9 hours agorootparent> Bottom line is: GitOps means the source of truth is Git and automation makes sure to avoid drifts. You still have to have a rollout strategy and schedule that makes sense for your usecase. THIS. reply jspdown 10 hours agorootparentprevCould you elaborate on this? Why do you think it's a bad idea? reply starttoaster 18 hours agoprevIt's not clear to me what Kubernetes has to do with this project at all. GitOps isn't really synonymous with Kubernetes anyway, so this comes across as throwing the word Kubernetes into something for recognition potentially? But mentioning Kubernetes and conflating GitOps with Kubernetes has me more confused on what this actually solves for me. Seems like the ArgoCD of non-containerized deployments. Which, ArgoCD has something to do with Kubernetes. So I guess I can sort of link in my head the thought process in branding here. But that requires me to know about ArgoCD and similar continuous deployment tools and link that in between GitOpper, GitOps, and Kubernetes somewhere. A bit too much mental gymnastics for the target audience: someone that doesn't use Kubernetes anyway. In my opinion, consider changing your branding to something like \"GitOps-style continuous deployments to non-containerized environments.\" A bit less show-y but at least that's more decipherable, just in my opinion. reply cyrnel 15 hours agoparentThe term is pretty synonymous with Kubernetes since it was coined in a Kubernetes context: https://web.archive.org/web/20200104172859/https://www.weave... reply starttoaster 15 hours agorootparentA Kubernetes tool coined the term but it’s always been about using git to store your manifests for your infrastructure, with some method of synchronization between the current state and what is in the git repo. With that in mind, it makes no sense to call them synonymous, GitOps transcends the concept of a particular tool or ecosystem. reply kelnos 15 hours agorootparentprevRegardless of the term used, GitOps has been a thing longer than Kubernetes has existed. reply danmur 16 hours agoparentprevI found this odd too. It reminded me of a book I read ages ago, sci-fi fantasy where there is a species that is very long-lived but they have a finite memory. Maybe if your memory is a year or two long then GitOps would seem to mean k8s deployments automatically out of git, rather than all the other things. (I think it was by C.S Friedman but I don't remember which one) reply Conscat 2 hours agorootparentPerhaps you are thinking of the My Little Pony fanfiction \"Alicorn Time\" by author AlicornPriest. https://www.fimfiction.net/story/298141/alicorn-time reply MongoTheMad 11 hours agoprevIs this barebones puppet/salt/Ansible? reply tryauuum 7 hours agoprev [–] Correct me if I'm wrong: - GitOps is a fancy word recently created by Gitlab or Github to sound cooler - It means storing your code / services in git and deploying on push It all seems so weird. We had tools like puppet since ice ages which can, after you push to git, reconfigure and deploy whatever you described in your git. Over all your fleet of machines. Am I missing something? reply r1cka 7 hours agoparentYou aren't missing anything. It's just marketing so GitHub/Gitlab stay in the main conversation when DevOps comes up. reply Normal_gaussian 7 hours agoparentprevTo be specific GitOps covers the Ops/DevOps around git. So MRs / RBAC for git all the way through CI to CD. I've seen some stretch it to cover VDI equivalents as well. Basically large orgs ditched all their ops people a while ago to focus on integrated teams, and now its marketable to seperate it out again a new set of terms have come round to help orgs pretend they didn't make mistakes. The term DevSecOps really grinds my gears, gitops I'm more ok with, but still... reply nonameiguess 2 hours agoparentprev [–] You're half wrong. The term was invented by Weaveworks, a company which no longer exists, but it's main product, FluxCD and the GitOps toolkit it is based on, lives on as a CNCF project. There never was and still is not any requirement that you use Github or Gitlab as your Git server to use this or any other GitOps product I'm aware of. I guess you're more 75% wrong because the second statement is still half wrong. Depending on the product you're using, it can work via webhook if the Git server supports doing that, but predominantly GitOps tooling relies upon polling, so you won't necessarily get a deployment immediately going a git push. You'll get it whenever the next poll happens. Also, FluxCD was created specifically for Kubernetes, which is why a product announcement like this is worded the way it is. It worked by storing Kubernetes custom resource manifests in a Git repo, typically for Helm charts or Kustomize \"kustomization\" definitions. Roughly the entire point of this was bringing Kubernetes conventions up to par with what was already common for deployment with configuration management tooling that relied upon server-stored configuration as code. I don't think Weaveworks or anyone else involved was under the impression they were the first to ever have this idea. But I also don't believe (but admittedly don't know) that it was particularly easy in 2017 to use Puppet to manage application deployments in Kubernetes. FluxCD also runs in Kubernetes itself, so you don't need any external infrastructure to do this. Maybe this makes it less weird? Multi-container orchestration nearly a decade ago was a fairly immature ecosystem, so they adopted ideas from configuration management of server fleets. Not all change in the world is greenfield innovation that comes absolutely out of nowhere. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Gitopper is a tool designed for non-Kubernetes environments to watch a remote git repository, pull changes, and reload server processes using a HUP signal.",
      "It supports a GitOps workflow without Kubernetes, performing sparse git checkouts and setting up bind mounts for service access, with authentication via SSH keys.",
      "Key features include metrics for rollout tracking, diff detection, out-of-band rollbacks, and canarying, which allows assigning different branches to services."
    ],
    "commentSummary": [
      "GitOpper is a GitOps tool that operates without Kubernetes, offering an alternative for those not using Kubernetes in their deployment workflows.",
      "The discussion highlights various GitOps practices and tools, such as using post-receive hooks, Dokku, Capistrano, and GitHub actions, indicating a diverse range of deployment strategies.",
      "The post emphasizes that GitOps is not limited to Kubernetes, despite its origins, and can be applied to different environments and tools, making it versatile for various deployment needs."
    ],
    "points": 128,
    "commentCount": 38,
    "retryCount": 0,
    "time": 1722544923
  },
  {
    "id": 41133313,
    "title": "Intel is laying off over 10k employees",
    "originLink": "https://www.theverge.com/2024/8/1/24210656/intel-is-laying-off-over-10000-employees-and-will-cut-10-billion-in-costs",
    "originBody": "Intel/ Tech/ Labor Intel is laying off over 15,000 employees and will stop ‘non-essential work’ Intel is laying off over 15,000 employees and will stop ‘non-essential work’ / After losses, the chipmaker is cutting $10 billion in costs. By Sean Hollister, a senior editor and founding member of The Verge who covers gadgets, games, and toys. He spent 15 years editing the likes of CNET, Gizmodo, and Engadget. Aug 1, 2024, 8:14 PM UTC Share this story Illustration by Alex Castro / The Verge Intel’s on a long, long road to recovery, and over 15,000 workers will no longer be coming along for the ride. The chipmaker just announced it’s downsizing its workforce by over 15 percent as part of a new $10 billion cost savings plan for 2025, which will mean a headcount reduction of greater than 15,000 roles, Intel tells The Verge. The company currently employs over 125,000 workers, so layoffs could be as many as 19,000 people. Intel will reduce its R&D and marketing spend by billions each year through 2026; it will reduce capital expenditures by more than 20 percent this year; it will restructure to “stop non-essential work,” and it’ll review “all active projects and equipment” to make sure it’s not spending too much. “This is painful news for me to share. I know it will be even more difficult for you to read,” reads part of a memo from Intel CEO Pat Gelsinger to staff, which you can also read in full at the bottom of this post. “We will reduce layers, eliminate overlapping areas of responsibility, stop non-essential work...” The company just reported a loss of $1.6 billion for Q2 2024, substantially more than the $437 million it lost last quarter. “Our Q2 financial performance was disappointing, even as we hit key product and process technology milestones,” admitted Gelsinger in the company’s press release. “Our revenues have not grown as expected — and we’ve yet to fully benefit from powerful trends, like AI,” he writes in his employee memo. Second quarter revenue was $12.8 billion, down just 1 percent year over year, and it’s not like all of Intel’s businesses are failing. While Intel has absolutely been losing money on its chipmaking Foundry business as it invests in new factories and extreme ultraviolet (EUV) lithography, to the tune of $7 billion in operating losses in 2023 and another $2.8 billion this quarter, the company’s products themselves aren’t unprofitable. Almost all the losses this quarter and last quarter came from Foundry, while its sales continue to stay relatively stable and its PC and server businesses stay profitable. (The PC sales slump ended earlier this year.) The company is also set to receive up to $8.5 billion in US government funding from the CHIPS Act. But investors didn’t seem happy that the company kept itself on a knife’s edge: over the past two years, before this quarterly loss, it had continued to swing between losses and profits overall, for just $1.1 billion in cumulative profit between Q2 2022 and Q1 2024. “Intel is now the worst-performing tech stock in the S&P 500 this year,” CNBC wrote in April. Related Inside the global battle over chip manufacturing This is Lunar Lake — Intel’s utterly overhauled AI laptop chip There is no fix for Intel’s crashing 13th and 14th Gen CPUs — any damage is permanent From a tech leadership perspective, Intel’s not yet a big player in AI server chips like Nvidia (maybe not even a notable small one like AMD), its relatively recent entry into graphics has yet to impress, and it had to overhaul its flagship laptop chips significantly to address the existential threat of Arm chips from the likes of Qualcomm and Apple, which can offer more battery life than Intel. Like competitors, the company now partially relies on TSMC, not just its own foundries, to help produce some of its most advanced chips. Microsoft recently followed Apple’s lead in ditching Intel chips for its latest slate of consumer hardware, including the Surface Laptop and Surface Pro, and launched its Copilot Plus PC initiative exclusively with Qualcomm, without waiting for Intel (or AMD)’s new flagship laptop chips to join them. Intel is currently dealing with two generations of potentially defective desktop CPUs, though the company currently believes it can mitigate the issue with a software update and doesn’t currently plan recalls. On the company’s earnings call today, Intel CFO David Zinsner just suggested that the company’s next flagship AI laptop chip, Lunar Lake, won’t be enough by itself to turn things around. While he says “the AI PC is a big winner for the company,” and Intel plans to “ramp that product significantly next year to meet market demand,” he also described Lunar Lake as a “narrow targeted product” that relies on “external wafers” (read: manufactured by TSMC, not Intel). Intel also needs to buy the memory it’s including on each chip, as Lunar Lake laptops don’t have separate memory sticks. Those are reasons why Lunar Lake will only modestly improve the company’s situation in 2025, he says. “The good news is the follow-on product, Panther Lake, is internally sourced on [Intel’s own process] 18A and has a much-improved cost structure,” says Zinsner. Lunar Lake is coming as soon as this September. Panther Lake will start ramping in the second half of 2025, but the “huge volume benefits” of that chip won’t come until 2026, says Gelsinger. On server chips, Gelsinger says Intel is “having to fight to win sockets” away from AI chipmakers but that Intel’s own Granite Rapids Xeon server processors are looking “very positive.” Intel plans to reduce spend by billions each year. Here’s how it’ll begin. Image: Intel Intel previously had a big round of layoffs in October 2022, when it also announced it would cut between $8 billion and $10 billion in costs every year through 2025. But the company didn’t shrink all that much as a result. While headcount dipped roughly 5 percent in 2023 (from 131,900 employees to 124,800 employees), Intel hired its way back to 130,700 employees as of March 30th, 2024, its financial records show. Intel says it’ll complete the majority of the layoffs it’s announcing today by the end of 2024, and spokesperson Penelope Bruce confirms that they are new layoffs — the 4 percent dip from 130,700 employees in March to 125,300 employees in June is not included in the total. Gelsinger writes that Intel will offer a “companywide enhanced retirement offering for eligible employees” and let employees broadly apply for voluntary layoffs starting next week — not every employee departure will come as a painful surprise. Intel says it’s now restructuring, suspending its dividend, and spending less, period, but will “maintain its core investments to execute its strategy and build a resilient and sustainable semiconductor supply chain in the U.S. and around the world.” Here’s the full memo from Gelsinger: Team, We have moved our All Company Meeting to today, following our earnings call, as we are announcing significant actions to reduce our costs. We plan to deliver $10 billion in cost savings in 2025, and this includes reducing our head count by roughly 15,000 roles, or 15% of our workforce. The majority of these actions will be completed by the end of this year. This is painful news for me to share. I know it will be even more difficult for you to read. This is an incredibly hard day for Intel as we are making some of the most consequential changes in our company’s history. When we meet in a few hours, I’ll talk about why we’re doing this and what you can expect in the coming weeks. In advance of that, I wanted to preview some of what’s on my mind. Simply put, we must align our cost structure with our new operating model and fundamentally change the way we operate. Our revenues have not grown as expected – and we’ve yet to fully benefit from powerful trends, like AI. Our costs are too high, our margins are too low. We need bolder actions to address both – particularly given our financial results and outlook for the second half of 2024, which is tougher than previously expected. These decisions have challenged me to my core, and this is the hardest thing I’ve done in my career. My pledge to you is that we will prioritize a culture of honesty, transparency and respect in the weeks and months to come. Next week, we’ll announce a companywide enhanced retirement offering for eligible employees and broadly offer an application program for voluntary departures. I believe that how we implement these changes is just as important as the changes themselves, and we will adhere to Intel values throughout this process. Why Now? Since introducing our new operating model, we have taken a clean-sheet view of the business and assessed ourselves against benchmarks for high-performing foundries, fabless product companies and corporate functions. This work made it clear our cost structure is not competitive. For example, our annual revenue in 2020 was about $24 billion higher than it was last year, yet our current workforce is actually 10% larger now than it was then. There are a lot of reasons for this, but it’s not a sustainable path forward. Beyond our costs, we need to change the way we operate – something many of you shared as part of our Employee Experience Survey. There’s too much complexity, so we need to both automate and simplify processes. It takes too long for decisions to be made, so we need to eliminate bureaucracy. And there’s too much inefficiency in the system, so we need to expedite workflows. Key Priorities The actions we are taking will make Intel a leaner, simpler and more agile company. Let me highlight our areas of focus: Reducing Operational Costs: We will drive companywide operational and cost efficiencies, including the cost savings and head count reductions mentioned above. Simplifying Our Portfolio: We will complete actions this month to simplify our businesses. Each business unit is conducting a portfolio review and identifying underperforming products. We are also integrating key software assets into our business units so we accelerate our shift to systems-based solutions. And we will narrow our incubation focus on fewer, more impactful projects. Eliminating Complexity: We will reduce layers, eliminate overlapping areas of responsibility, stop non-essential work, and foster a culture of greater ownership and accountability. For example, we will consolidate Customer Success into the Sales, Marketing and Communications Group to streamline our go-to-market motions. Reducing Capital and Other Costs: With the completion of our historic five-nodes-in-four-years roadmap clearly in sight, we will review all active projects and equipment so we begin to shift our focus toward capital efficiency and more normalized spending levels. This will reduce our 2024 capital expenditures by more than 20%, and we plan to reduce our non-variable cost of goods sold by roughly $1 billion in 2025. Suspending Our Dividend: We will suspend our stock dividend beginning next quarter to prioritize investments in the business and drive more sustained profitability. Maintaining Growth Investments: Our IDM2.0 strategy is unchanged. Having fought hard to reestablish our innovation engine, we will maintain the key investments in our process technology and core product leadership. The Future I have no illusions that the path in front of us will be easy. You shouldn’t either. This is a tough day for all of us and there will be more tough days ahead. But as difficult as all of this is, we are making the changes necessary to build on our progress and usher in a new era of growth. When we began this journey, we set our sights high, knowing that Intel is a place where big ideas are born and the power of what’s possible triumphs over the status quo. After all, our mission is to create world-changing technologies that improve the lives of every person on the planet. And at our best, we have exemplified these ideals more than any company in the world. To live up to this mission, we must continue to drive our IDM 2.0 strategy, which remains the same: re-establish process technology leadership; invest in at-scale, globally resilient supply chain by expanding manufacturing capacity in the U.S. and EU; become a world-class, leading-edge foundry for internal and external customers; rebuild product portfolio leadership; and deliver AI Everywhere. Over the past few years, we have rebuilt a sustainable innovation engine that is largely in place and on track. It’s now time to focus on building the sustainable financial engine needed to drive our performance. We must improve our execution, adapt to new market realities and operate as a more agile company. That’s the spirit of the actions we are taking – knowing that the choices we make today, as difficult as they are, will strengthen our ability to serve our customers and grow our business for years to come. As we take these next steps in our journey, let’s not forget that there has never been a greater need for what we do. The world will increasingly run on silicon – and the world needs a healthy and vibrant Intel. That’s why the work we are doing is so consequential. Not only are we remaking a great company, but we are also creating technology and manufacturing capabilities that will reshape the world for decades to come. And this is something we should never lose sight of as we push forward in pursuit of our goals. We’ll talk more in a few hours. Please come with your questions so we can have an open and honest discussion about what comes next. Update, August 1st: Added more details from the earnings call about Intel’s expectations for its upcoming Lunar Lake and Panther Lake chips. Most Popular Most Popular Intel is laying off over 15,000 employees and will stop ‘non-essential work’ Microsoft Teams is finally cleaning up chats and channels Delta CEO: ‘When was the last time you heard of a big outage at Apple?’ Saudi Arabia proposes World Cup stadium straight out of a cyberpunk dystopia Intel’s crashing 13th and 14th Gen CPUs get two additional years of warranty coverage Verge Deals / Sign up for Verge Deals to get deals on products we've tested sent to your inbox weekly. Email (required)Sign up By submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply. From our sponsor Advertiser Content From",
    "commentLink": "https://news.ycombinator.com/item?id=41133313",
    "commentBody": "Intel is laying off over 10k employees (theverge.com)125 points by ssahoo 22 hours agohidepastfavorite30 comments zamalek 21 hours ago> Intel will reduce its R&D and marketing spend by billions each year through Isn't squandering incredible engineering resources exactly how Intel got into this situation in the first place? reply radicaldreamer 21 hours agoparentIntel is notorious for having bloated R&D and keeping those projects funded despite not going anywhere, while missing mobile completely, perf/watt and now missing AI/ML as well. reply ravenstine 19 hours agorootparentCouldn't existing R&D employees be better utilized instead of being laid off? reply s1artibartfast 19 hours agorootparentThey obviously think the answer is no. There is this interesting phenomenon where people outside an organization view R&D potential as elastic. That is to say, there is always a positive return on investment for the marginal R&D dollar. It is clearly not in the case or every company would have exponential growth simply by reinvesting in R&D. In reality, it is difficult to create growth from R&D at all, let alone the marginal dollar. reply shiroiushi 18 hours agorootparent>There is this interesting phenomenon where people outside an organization view R&D potential as elastic. That is to say, there is always a positive return on investment for the marginal R&D dollar. I don't think that's the view here; instead, I think the idea is that R&D personnel could be reassigned to work on something more profitable, rather than simply laying them off. Assigning R&D people to work on something unprofitable or a dead-end is the fault of management and their poor vision, not the people assigned to research that stuff. reply wavemode 18 hours agorootparentThat implies that there are job openings in those \"more profitable\" areas. Indeed, wouldn't every company love to just reallocate all of its employees to the areas that are most profitable. But alas, adding eight more women to the project of birthing a baby does not reduce pregnancy time to one month. reply johnnyanmac 13 hours agorootparent>That implies that there are job openings in those \"more profitable\" areas. if they are more profitable, they probably have more space and budget by defauly. Outside of these strange times, it's not like Tech has historically been oversaturated and companies shy away from hiring new talent. reply wavemode 5 hours agorootparent> if they are more profitable, they probably have more space and budget by defauly Not sure what you're basing this assertion on. I've never been at any tech company where the fact that a project is profitable somehow inherently means that we can just keep adding engineers to it and those additional engineers will magically increase the revenue the project generates. In fact there's almost no industry where such an assumption would be logical. Even if your work has a very straightforward financial model, like manufacturing where you simply make Y dollars for every X parts you produce, that still does not imply you can just keep adding assembly line workers. At a certain point you have to consider whether there are even enough purchase orders to cover the volume of goods you're creating, or if they are just going to become wasted surplus sitting in a warehouse. reply jodleif 11 hours agorootparentprevNo but you could get 1 baby / month on average reply wavemode 5 hours agorootparentWhat you're suggesting is the equivalent of the eight other mothers not working on the same most profitable project, but instead on other projects of their own. So you're agreeing with my point. reply s1artibartfast 4 hours agorootparentAnd then you have 9 mouths to feed when you really wanted one very healthy baby. The corporate analog would be sustaining dozens of projects, partnerships, and business areas that never really took off and had the results you hoped for. reply s1artibartfast 16 hours agorootparentprevWhy does every organization always have something profitable they could be working on? In the case of firing, either way, companies are not staffed by omniscient leaders. The are staffed by humans, which don't know where to put R&D today to guarantee profitable inventions tomorrow. Human uncertainty and imperfection underlies all business risk. reply shiroiushi 15 hours agorootparentIt seems that the visionary management at Intel has been consistently failing at focusing R&D efforts in a productive and profitable way, so why are they still employed there? They should fire the management and hire some new management that can make better decisions. This is nothing new: even when I worked there decades ago, they were always making stupid decisions, such as the whole Itanic idea, the dumb idea of making their P4 processors dependent on expensive RAMBUS memory, refusing to make a serious 64-bit version of x86 until AMD did it first, etc. It seems they still haven't learned (or hired some better executives). reply s1artibartfast 14 hours agorootparentThey say the fish rots from the head. This is a common problem with mature companies with clueless owners and nobody competent enough to right the ship. If the money printing machine works to well, everybody forgets how to repair it by the time it breaks down. reply rowanG077 16 hours agorootparentprevIt's more like R&D is the lifeblood of a company like Intel. Intel is basically purely an R&D company, their entire future hinges on R&D. This is not typical of other companies who can usually coast for years or even decades on existing product or may not even require R&D for new products. R&D should really be Intels major spend. reply s1artibartfast 14 hours agorootparentThey have been putting record funding into R&D for years, but it seems that simply throwing money at the problem isn't helping, so it makes sense that they would try something different. Their press statement essentially R&D is too bloated, dysfunctional, and disorganized in the current state to produce. reply rowanG077 14 hours agorootparentThrowing money at any problem is ineffective by itself. Still throwing money at a problem is a prerequisite to get stuff solved. It may very well be true that Intel R&D teams are too bloated, dysfunctional and disorganized. But that is not solved with throwing less money at it. If anything doing that and nothing else just leaves with less teams that are too bloated, dysfunctional and disorganized. reply s1artibartfast 14 hours agorootparentTheir R&D spend is 4x that of TSMC and 2X that of Nvidia. If they cut 20%, they will still have an obscene budget. If you read the press release the idea is to focus on their core competencies, like making good processors. That means laying off people that can't help with that goal. reply johnnyanmac 13 hours agorootparent>If you read the press release the idea is to focus on their core competencies sure, the standard press response to layoffs. They'll be back to chasing AI in a year, despite more or less having already lost the race. reply s1artibartfast 13 hours agorootparentAi is closer to their core competencies than half the shit they get up to. That said, if they keep failing to turn a profit, it wont matter. reply Conan_Kudo 15 hours agorootparentprevBut... Intel does coast on plenty of things and seems to remain market leader anyway? reply sidewndr46 19 hours agorootparentprevI mean it isn't like they developed a graphics cards line nobody wants to use recently or anything like that reply duskwuff 15 hours agorootparentI've heard a rumor that's where a lot of the cuts are focused, actually. reply timschmidt 10 hours agorootparentThat would be unfortunate. Without a competent GPU it will be increasingly difficult to compete against AMD and Nvidia who have all the pieces necessary to produce high end gaming PCs / workstations / datacenter GPU compute. Developing a competent GPU solution isn't really optional if one wants to compete in those spaces, despite the large up-front cost, which Intel seems to have mostly already paid. Intel similarly cut their project Larrabee / Knights Landing / Knights Mill product line, which could have thrust x86 into the AI space in a way no other platform does offers today. They just quit too soon. Which suggests lack of vision or inability to properly communicate that vision to the management / board / investors. reply msie 33 minutes agorootparentSeems obvious so I suspect the cuts are going to boost some executive's compensation. Short-term gain over long-term gain. reply high_na_euv 21 hours agoparentprevThere are probably hundreds or thousands of projects, so who knows what they are going to kill reply nine_zeros 21 hours agoparentprevNot if the priority is shareholder value as opposed to innovation reply ChrisArchitect 21 hours agoprev[dupe] More discussion on official release: https://news.ycombinator.com/item?id=41133084 reply layer8 20 hours agoprevPat Gelsinger’s memo is worth reading. reply mandeepj 17 hours agoprev [–] Techcrunch reporting 15k reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Intel is laying off over 15,000 employees and halting non-essential work to cut $10 billion in costs by 2025.",
      "The company will reduce R&D and marketing spend, cut capital expenditures by over 20%, and review all active projects, following a $1.6 billion loss in Q2 2024.",
      "Despite stable sales in its PC and server businesses, Intel's stock has underperformed, prompting CEO Pat Gelsinger to emphasize the need for a leaner, more efficient operation."
    ],
    "commentSummary": [
      "Intel is laying off over 10,000 employees to reduce billions in annual R&D and marketing expenses.",
      "Critics argue that Intel's failure to capitalize on key trends like mobile and AI/ML has led to this situation, suggesting mismanagement of R&D.",
      "The layoffs aim to refocus on core competencies, but there are concerns that this may hinder long-term innovation."
    ],
    "points": 125,
    "commentCount": 30,
    "retryCount": 0,
    "time": 1722544350
  },
  {
    "id": 41138085,
    "title": "Ell – A command-line interface for LLMs written in Bash",
    "originLink": "https://github.com/simonmysun/ell",
    "originBody": "Hi HN!I&#x27;ve created a CLI tool called \"ell\" that allows you to interact with LLMs directly from your terminal. Designed with the Unix philosophy in mind, ell is simple, modular, and extensible. You can easily pipe input and output to integrate with other tools. Its templates and hook-based plugins enable you to customize and extend its functionality to suit any needs. Check out the README for usage instructions and examples.I developed this tool because existing solutions often felt too heavy, with many dependencies, or they weren&#x27;t friendly to piping and customization. I, on the contrary, wrote in almost pure Bash with least dependencies. Additionally, I found a lack of tools that could read past terminal output as context. Imagine encountering an issue in your terminal and being able to directly ask an LLM for help with a simple command—this is now possible with ell (see the demo video).Known limitations:- To maintain simplicity and efficiency, jq is used for JSON parsing.- Cannot avoid curl to sending HTTPS requests. If only there were SSL &#x2F; TLS support in `&#x2F;dev&#x2F;tcp&#x2F;`!- Perl is used to handle terminal escape sequences because regex in Bash does not support looking around.- Markdown syntax highlighting is not perfect due to the need for streaming output. It relies on a simple state machine instead of a full parser, which may produce falsy results.- Other known issues are listed in Github Issues. Please help add more!I welcome any criticism and suggestions, whether it&#x27;s about the idea or code!",
    "commentLink": "https://news.ycombinator.com/item?id=41138085",
    "commentBody": "Ell – A command-line interface for LLMs written in Bash (github.com/simonmysun)119 points by simonmysun 7 hours agohidepastfavorite41 comments Hi HN! I've created a CLI tool called \"ell\" that allows you to interact with LLMs directly from your terminal. Designed with the Unix philosophy in mind, ell is simple, modular, and extensible. You can easily pipe input and output to integrate with other tools. Its templates and hook-based plugins enable you to customize and extend its functionality to suit any needs. Check out the README for usage instructions and examples. I developed this tool because existing solutions often felt too heavy, with many dependencies, or they weren't friendly to piping and customization. I, on the contrary, wrote in almost pure Bash with least dependencies. Additionally, I found a lack of tools that could read past terminal output as context. Imagine encountering an issue in your terminal and being able to directly ask an LLM for help with a simple command—this is now possible with ell (see the demo video). Known limitations: - To maintain simplicity and efficiency, jq is used for JSON parsing. - Cannot avoid curl to sending HTTPS requests. If only there were SSL / TLS support in `/dev/tcp/`! - Perl is used to handle terminal escape sequences because regex in Bash does not support looking around. - Markdown syntax highlighting is not perfect due to the need for streaming output. It relies on a simple state machine instead of a full parser, which may produce falsy results. - Other known issues are listed in Github Issues. Please help add more! I welcome any criticism and suggestions, whether it's about the idea or code! llimllib 5 hours agoI wrote a similar tool I'm no longer maintaining: https://github.com/llimllib/gpt-bash-cli/ . Here are my suggestions: - save the conversations in a sqlite db. ~everyone has sqlite available and it allows the user to do things with the data more easily than a text file - use XDG directories instead of suggesting ~/.ellrcd (https://wiki.archlinux.org/title/XDG_Base_Directory) - I prefer using system secret stores to environment variables; I don't want to give every program I run access to my API keys. You can see how I did that in my program reply simonmysun 5 hours agoparentThanks for the suggestions! I read your code and the support of images is awesome. I would not assume everyone has sqlite but this can be done optionally with a plugin. Will consider writing a demo for this. Using XDG directories and system secrets sounds a lot better than what I did. I will learn how to use them and try to integrate them with my code! reply ducktective 4 hours agoparentprev>I prefer using system secret stores to environment variables What is the recommended way to store secrets in a Linux dev machine? The requirement is random scripts and programs should be able to load their secrets like API keys at runtime with minimum hassle. And the secrets shouldn't be stored on disk in plain-text. I see you recommended keyring [1]. Is this \"the GNU/linux way\"? I see another possibility being storing them in an encrypted filesystem (whether FUSE-based or not) [1]: https://github.com/llimllib/gpt-bash-cli/blob/841682affe2d0e... reply llimllib 1 hour agorootparentI did a fair amount of looking to try and support a Linux secret store! My conclusion was that I was too confused and so I punted to keyring which seemed to paper over a few different stores. It seems like a classic story of unfortunate Linux fragmentation reply skruzel 4 hours agoprevI also have a similar tool called https://autocomplete.sh https://github.com/closedloop-technologies/autocomplete-sh I really just wanted the feeling of tab-based auto-complete to just work in the terminal. It turns out that getting the LLM responses to 'play nice' with the expected format for bash_completion was a bit of a challenge, but once that worked, I could wrap all the LLMS (OpenAI, grok, Claude, local ones like Ollama) I also put some additional info in the context window to make it smarter: a password-sanitized recent history, which environmental variables are set, and data from `--help` of relevant commands. I've just started to promote it around the Boston area and people seem to enjoy it. reply simonmysun 2 hours agoparentWow that's very useful! I have also thought of completion but my idea was more like copilot. The user experience of your script should be better. I'm glad I didn't start to write that. Regarding history in context, I suggest adding a record mode like ell. This really helps. Password sanitizer is great. I will also add it as a plugin. Thank you for the idea! reply skruzel 1 hour agorootparentThanks for checking it out and the record mode is a great idea. I've been playing around with ways to get the terminal outputs but so far I haven't loved the UX of my solutions. Your co-pilot approach that can explain the commands and iterate is really valuable. If you're open to joining, I have a small AI engineer/ open source dev Slack community in Boston. Id love to have you (https://smaht.ai) reply simonmysun 38 minutes agorootparentI am open to join any community. As long as you don't mind the fact that I'm not in Bosten, why not? I have just submitted on your google form. Thanks for inviting! reply rancar2 1 hour agoparentprevThe demo video is epic. Nicely done! https://youtu.be/IAgkjerCvz8 reply skruzel 1 hour agorootparentThank you! It was so much fun to make. And for once my son waking me up at 2am had a positive result! reply stared 3 hours agoparentprevLooks interesting! Does it work with the Fish shell? And, in case, how do I update or uninstall it? reply skruzel 1 hour agorootparent`autocomplete remove` will delete it. I haven't tested it in fish / zsh shells. Now that I have some Mac iOS dev work to do I'll probably build and test it reply raajg 22 minutes agoprevBeen using the LLM cli by simonw and love it. https://github.com/simonw/llm https://llm.datasette.io/en/stable/ Pro tip: Use $pbpaste to inject clipboard contents in a prompt reply joshi4 32 minutes agoprevEll is really cool! I'm building a similar product called Savvy(https://github.com/getsavvyinc/savvy-cli) and considered an approach similar to yours (writing in pure bash) but ultimately decided to use Go for a few reasons: - charmbracelet makes it super easy to build rich TUI - Go produces a single binary that's compatible across many platforms and keeps installation simple - It's simpler to support multiple shells. reply alkh 2 hours agoprevLooks great! I work on a number of different machines, so having something lightweight(like written in shell) is always desired. Out of curiosity, can someone explain to me why certain commands start with a colon? Like : \"${ELL_LOG_LEVEL:=2}\";[1] I thought it was useful only as a no-op? [1]: https://github.com/simonmysun/ell/blob/main/ell.sh#L19C1-L19... reply simonmysun 2 hours agoparentThanks! The colon is here to make sure the result is not executed. I learned that from here: https://stackoverflow.com/a/28085062/2485717 reply pseufaux 2 hours agoparentprevThe : basically just tells bash to do nothing with the result of the line. So `: \"${ELL_LOG_LEVEL:=2}\";` would initialize `ELL_LOG_LEVEL` to 2 if it's not already set without producing any output. reply danenania 4 hours agoprevThis is cool! Using pure bash and unix tools is an interesting approach. I built Plandex[1] which has some similar goals (no dependencies, terminal-based, supports piping into context) but it takes quite a different route to get there—I’m using Go and compiling static binaries. It’s also ‘higher level’ and specifically focused on coding, whereas ell seems like a very lightweight and general purpose LLM tool. It reminds me a lot of Simon Willinson’s `llm` tool[2]. Are you familiar with it? The recording feature also reminds me of savvy[3]. 1 - https://github.com/plandex-ai/plandex 2 - https://github.com/simonw/llm 3 - https://github.com/getsavvyinc/savvy-cli reply simonmysun 1 hour agoparentThanks! Plandex is also nice! I never thought of such workflow. Unfortunately, I did not know Simon Willinson’s `llm` tool. I would imagine he must have written such softwares. It has support for more in-depth manipulating of LLMs. ell lacks these functionalities and only make use of the most commonly-used and also most basic interfaces but has more user experience improvements like pagination or syntax highlighting while keeping as lightweight as possible. I should mention `simonw/llm` in README and channel the user with demand of more LLM manipulations there. reply hacker-l 6 hours agoprevHi, they're also trying to do something similar with shell. I'm not sure who's better. [demo](https://x-cmd.com/mod/gemini) [source code](https://github.com/x-cmd/x-cmd/blob/main/mod/gemini/lib/main) reply simonmysun 6 hours agoparentCool! This is looks a lot fancier. EDIT: I was wrong. Ignore the next paragraph. ~~I haven't looked into details but it looks reading from somewhere like `.bash_history`. That's a good idea to get user input from. But as far as I learned, it cannot use the terminal ouput as context. I might be wrong. I should read more about its implementation.~~ It turns out it cannot make use of terminal output. But I like it that it use awk to process the response. I might also be able to use awk to get rid of the dependencies of jq and perl. Thank you for letting me know this. I will add it in the related projects chapter in README reply curry798 5 hours agoparentprevIt looks beautiful and has many features, why are there so few star? reply simonmysun 5 hours agorootparentI also wonder. It didn't appear in my search because, I guess, it has too many features and the feature I want to search has a relatively low weight. I also searched x-cmd on HN but there aren't many positive comments... I would expect it's more popular on HN because it's written in POSIX shell and awk. reply teamspirit 2 hours agoprevWill check it out. Personally been using aichat[0] for this. It's interesting you say there's no need for a more complex language than bash something like this. Doesn't the need for jq/curl/perl argue the opposite? [0] https://github.com/sigoden/aichat reply simonmysun 1 hour agoparentIndeed. That's why I list them as limitations. My original idea was to get everything done with Bash. This is however not feasible as the reasons listed. Maybe I can get rid of jq and perl using awk, but that would sacrifice a lot of simplicity and readablity of the code. I think implementing the syntax highlighter is the bottom line of my insist. I would prefer not to write anything more complex than that with Bash. They will be either not supported, or supported via external plugins. reply mherrmann 6 hours agoprevCool. The link to \"Risks\" in the README is broken. What I would love: `ell -r` automatically, and an alias `fix` that proposes a fix, including making changes to a file. For example, say I have a typo in main.cc and do `gcc main.cc`. When I run `fix`, I want ell to propose a fix in the file with a diff. If I accept, it should make that change. Then it should propose running `gcc` again - and run it for me if I accept. reply simonmysun 6 hours agoparent> The link to \"Risks\" in the README is broken. Fixed. Thanks for pointing out! > `ell -r` automatically, and an alias `fix` that proposes a fix, including making changes to a file. Good idea! `ell -r` can be added to `.bashrc`, but I'm not sure if it will conflict users' original configurations or there will be other issues. Except confirming a patch, I think it is feasible with template and plugins, but making actuall changes is challenging for me, both techinology wise and user interface design wise. I will try to figure out what can be possible reply Zambyte 6 hours agoparentprevRegarding running ell -r automatically, you can just add it to your .bashrc reply mherrmann 6 hours agorootparentYup. But the rest of the functionality is missing, I think. reply trescenzi 5 hours agoprevHuge fan of Charmbracelet's mods. I've been using it for months now and it works great. Very customizable and the output is clean. https://github.com/charmbracelet/mods reply simonmysun 5 hours agoparentThank you for letting me know! It does well with conversation but on the contrary, ell itself is stateless (on the aspect of user input and generate contents). Conversational use of ell depends on `script` to record the terminal output. Though, I can support managing historical dialogs via a plugin with side effects. I need to consider whether this suits the idea and philosophy of ell. Well, either I'm not good at googling ro google is not good at searching.. I did searched similar projects and never find these powerful tools in practice posted by HN users reply yanis_t 5 hours agoprevVery cool! I wrote a similar tool (in Node.js, though), but was trying to make it extensible with plugins. https://github.com/hiquest/nicechat reply simonmysun 4 hours agoparent(Reading your comment and code reminds me that I might have confused user with the terms of the plugin I proposed and the plugin in popular LLM backends. I will make it clear in ell documents) What kind of plugins are you going to integrate? I implemented the hook system but actually don't have many ideas to add. Currently I only added paginator and syntax highlight plugins and both of them are applied after getting response from LLM backends. reply mvavassori 6 hours agoprevI don't know why i keep getting the error: \"FATAL Template not found: ~/.ellrc.d/templates/default-openai.json\" after having cloned the repo in my home directory and created the configuration file in .ellrc in my home directory. Don't know, probably i'm doing something wrong... I'm new to bash projects, why does it search for the templates in .ellrc.d? what's the .d part? I don't understand. reply simonmysun 5 hours agoparentOh sorry that's my bad. The target clone path did not match the default value of template path. Please make sure you either clone the repo to `~/.ellrc.d` or set ELL_TEMPLATE_PATH to where you store your templates (with `/` at the end) . reply mvavassori 5 hours agorootparentThank you, i always assume there's some magic part that goes on behind the scenes which i don't understand, especially in things i'm not familiar with... In fact it was just a path mismatch as the error suggested. reply simonmysun 5 hours agorootparentYou are welcome. Please feel free to fire any issues you may encounter. reply mFixman 5 hours agoprevThe program seems to assume you'll clone it in your home directory, and has paths hardcoded to `~/.ellrc.d/`. This is just bad. reply SoftTalker 53 minutes agoparentConvention over configuration isn't bad per se, as the alternatives tend to devolve to bikeshedding. reply simonmysun 5 hours agoparentprevI wouldn't say these paths are hardcoded. They are just default values. You can set the variables manually. What is hard coded is that it indeed looks for configurations from `$HOME/.ellrc` and `$PWD/.ellrc`, with lowest precedence. Environment variables and command line arguments will overwrite them. reply piyushtechsavy 4 hours agoprev [–] Sounds cool. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A new CLI tool named \"ell\" has been created for interacting with Large Language Models (LLMs) directly from the terminal, adhering to the Unix philosophy of simplicity and modularity.",
      "\"Ell\" allows easy integration with other tools through piping, and supports customization via templates and hook-based plugins, making it highly adaptable.",
      "Developed in almost pure Bash with minimal dependencies, it can read past terminal output as context, enabling direct assistance from an LLM; however, it has some limitations like reliance on jq, curl, and Perl, and imperfect Markdown syntax highlighting."
    ],
    "commentSummary": [
      "Ell is a Bash-based CLI tool for interacting with Large Language Models (LLMs) directly from the terminal, designed to be simple, modular, and extensible.",
      "It addresses complexity and dependency issues of existing solutions, supporting customization through templates and hook-based plugins, and can read past terminal output as context.",
      "Known limitations include reliance on jq for JSON parsing, curl for HTTPS requests, and Perl for handling terminal escape sequences, but it focuses on user experience improvements like pagination and syntax highlighting."
    ],
    "points": 119,
    "commentCount": 41,
    "retryCount": 0,
    "time": 1722599759
  },
  {
    "id": 41133876,
    "title": "xdg-override: change default application temporarily on Linux",
    "originLink": "https://github.com/koiuo/xdg-override",
    "originBody": "xdg-override Override xdg-open behavior. Because the way it already works is not confusing enough. How do you change browser in Slack anyway? What is xdg-open and what xdg-override does? xdg-open is a GNU/Linux application that \"opens\" files and URLs in user's preferred application: For example, open avatar.png in the default image viewer ~ ❯ xdg-open avatar.png Or open https://freedesktop.org URL in the default browser ~ ❯ xdg-open \"https://freedesktop.org\" Most application on GNU/Linux by convention delegate to xdg-open when they need to open a file or a URL. This ensures consistent behavior between applications and desktop environments: URLs are always opened in our preferred browser, images are always opened in the same preferred viewer. However, there are situations when this consistent behavior is not desired: for example, if we need to override default browser just for one application and only temporarily. This is where xdg-override helps: it replaces xdg-open with itself to alter the behavior without changing system settings. For example, if our default browser is Firefox, and we want Chromium to be our default browser in Slack messanger, we can launch Slack like this: ~ ❯ xdg-override --match \"^https?://\" chromium slack How does it work? Two words: PATH manipulation. You can read the explanation of how xdg-override works and about my motivation in my blog post How do you change browser in Slack anyway? Installation and running If you use Nix, you can install xdg-override from the flake, or you can try it without installation like this ~ ❯ nix run github:koiuo/xdg-override -- --match \"^https://\" chromium slack For everyone else, place the script anywhere you wish and execute it from there. It does not require any configs, and it only creates some temporary files under /tmp. Usage ~ ❯ xdg-override --help xdg-override [options...]-h, --help Show command synopsis. -m, --match Override handling of specific mimetype Examples xdg-override -m \"^https?://.*\\.youtube.com/\" mpv -m \"^https?://\" firefox thunderbird Launches thunderbird and - forces all youtube.com URLs to open in mpv - forces all other URLs to opened in firefox On top of the script, the flake offers a few library functions to be used in NixOS or home-manager config proxyPkg generates a package which can be installed to the profile to globally override xdg-open behavior: customXdgOpen = xdg-override.lib.proxyPkg { inherit pkgs; nameMatch = [ { case = \"^https?://.*\\.youtube.com/\"; command = \"mpv\"; } { case = \"^https?://open.spotify.com/\"; command = \"spotify-open\"; } ]; }; home.packages = [ ... customXdgOpen ... ] wrapPackage wraps a single package and alters xdg-open behavior just for that single application: customSlack = (xdg-override.lib.wrapPackage { nameMatch = [ { case = \"^https?://open.spotify.com/\"; command = \"spotify-open\"; } { case = \"^https?://\"; command = \"firefox\"; } ]; } pkgs.slack); home.packages = [ ... customSlack ... ] Further development The script is more than sufficient for my needs and I don't plan to add new features to it. Nix library might see some improvements, and as an excercise I might do some polishing and automated testing. That said, don't hesitate to open an issue if you miss something or have a cool idea.",
    "commentLink": "https://news.ycombinator.com/item?id=41133876",
    "commentBody": "xdg-override: change default application temporarily on Linux (github.com/koiuo)114 points by koiueo 21 hours agohidepastfavorite28 comments nrabulinski 1 hour agoI don’t understand those comments. I’ve been using sway for years, i3 before that and I’ve been using xdg-open since forever to open any file in the default application and I never felt it was confusing or I that I needed to replace it with something else. What am I missing? reply arp242 18 hours agoprevI just have a small shell script as \"xdg-open\". Writing this was easier than figuring out the magic xdg-* tools use the figure out the default application for something, and then not having that work on random days for reasons of planetary alignments. This is not that different from \"xdg-override\"; you can add global overrides for specific URLs with a simple match, and matches from a specific application by checking the parent process (e.g. $(readlink /proc/$PPID/exe) = /usr/bin/slack, or some such). It seems easier to me to have everything in one place. I also considered popping up dmenu for unknown filetypes, but I don't use it that much and don't really need it. At any rate, \"to whom it might be useful\": #!/bin/zsh # # xdg-open, without suckage. [ \"${ZSH_VERSION:-}\" = \"\" ] && echo >&2 \"Only works with zsh\" && exit 1 setopt err_exit no_unset pipefail (( $+1 )) || { print >&2 'need a parameter'; exit 1 } # Open URL. if [[ -z \"${1:#*://*}\" ]]; then proto=${(L)1%%://*} case $proto in (http|https) exec firefox $1 ;; (file) 1=${1##$proto://} # Remove protocol 1=/${1#*/} # Remove hostname ;; (*) print >&2 \"xdg-open: no URL handler for protocol '$proto://' (for: $1)\" exit 1 esac fi # Open file. ext=${(L)1:e} case $ext in (html|htm|pdf)exec firefox $1 ;; (png|webp|jpg|jpeg|heic) exec firefox $1 ;; (mp?|ogg|flac|m4v|mkv|avi|mov|wav) exec mpv $1 ;; (md|markdown|txt|sh|zsh|go|py|rb|js|c|json|xml) exec st -e vim $1 ;; (*) mime=$(file -b --mime $1 2>&/dev/null ||:) t=${mime%/*} case $t in (text) exec st -e vim $1 ;; (image) exec firefox $1 ;; (audio|video) exec mpv $1 ;; esac print >&2 \"xdg-open: don't know how to open '.$ext' files (mime: '$mime') (for: $1)\" exit 1 esac reply koiueo 12 hours agoparentIn a sense, xdg-open does exactly what your script does. Only it reads associations from mimeapps.list. The complexity comes from the integration with various desktop environments. And this I understand. Ideally, everyone would use xdg-utils, but there's legacy, backward compatibility, what not. What I don't understand is why those DE-specific openers do not always respect xdg settings. For instance, kde-open would respect mineapps.list for almost everything except default browser. For me this is the main source of confusion and I would guess, this is the main driver behind numerous xdg-open alternatives out there. reply kmarc 3 hours agorootparent> The complexity comes from the integration with various desktop environments Usually I'm the first one who defends open source solutions and blames complexity and compatibility... But xdg-open is just an awful interface to interactive with, probably my most hated Linux desktop cli tool. reply koiueo 3 hours agorootparentI'd love to understand this better. My first reaction was too, that it's much more complex than it probably should be. OTOH, as I said, after reading through its code, it doesn't seem to do much more than many of its alternatives 1. it can be called with just a single argument 2. if it's running under a DE, it delegates to the ${de}-open. In the same fashion, it handles some esoteric cases, like flatpak and WSL2... 3. if it's not running under a DE or it's one of the esoteric cases, it parses $1 and reads associations from an INI file 4. finally if the executable is supplied in a form of desktop file, it resolves it to a command Most of its alternatives do steps 1 and 3, and do not do steps 2 and 4. And it doesn't seem like too much incidental complexity tbh. Step 4 seems totally legit. Step 2 — controversial, but I can rationalize this with legacy and backward compatibility. And even when we start thinking about all those ${de}-open... Probably those are needed for some eye candy, like jumping icons in the dock when an app is launching... IDK, I'm just speculating. reply kzrdude 9 hours agorootparentprevxdg-open has the nice benefit that I can just right click a file in the file manager and select \"Set default opener for file type\". And then it's saved. reply koiueo 4 hours agorootparentThis is why I wanted to override xdg-open temporarily, instead of writing yet another complete replacement. Plus, XDG is the de facto standard. Its implementation so far is not perfect, but I feel like aligning with the standard is better than diverging from it. reply arp242 6 hours agorootparentprev> In a sense, xdg-open does exactly what your script does. Pretty much, yeah. It's just a simple mapping, right? I don't recall what problems I had exactly, but it was just a pain and stopped working at various points, or just didn't do what I wanted and couldn't get to behave as I wanted. So I spent half an hour six or seven years ago and that fixed it (I added the MIME support last year or so, another 15 minutes). At some point of knowledge it's easier and less time-consuming to just script these things rather than relying on some generic system. It is for me anyway. reply sureglymop 20 hours agoprevOn gnome there is a GTK4 app called \"Junction\". It pops up a dialog that let's you choose what application to open the given content in. I highly recommend just aliasing 'open' to use that. https://apps.gnome.org/Junction/ reply vbernat 13 hours agoparentI have something similar with this short Python script: https://github.com/vincentbernat/i3wm-configuration/blob/mas... reply koiueo 20 hours agoparentprevThanks for sharing this. I'm not on Gnome and don't need the option to choose an application every time I click on a link or a file. Nevertheless, seeing how other people approach a similar problem is interesting. Looking through the source code briefly, it seems like it's almost a full re-implementation of `xdg-open`. My solution is in a different league. I didn't mean to replace `xdg-open` and aimed to augment `xdg-open` while being as simple as possible. reply sureglymop 12 hours agorootparentYours is really cool too! I'll definitely try it out :). reply LorenDB 7 hours agoparentprevThat's just the GNOME xdg portal app, right? Other DEs like Plasma have their own versions of that as well. reply M95D 8 hours agoprev> Override xdg-open behavior. Because the way it already works is not confusing enough. Oh! YESSSSS!!! FINALLY!!! I've been removing x permissions for xdg-open for YEARS!!! I hope this works. reply koiueo 3 hours agoparentI hope you are not disappointed , but I suspect xdg-override might not be what you expected. xdg-override is not a replacement for xdg-open. It's a script, that selectively replaces xdg-open in narrow explicitly defined cases. But some xdg-open alternatives have been mentioned in the comments. reply Kudos 10 hours agoprevMy work VPN client doesn't work in Firefox, so I hacked something much more specific together to deal with that problem #!/bin/sh if [ \"$@\" = \"/tmp/gpauth.html\" ] then flatpak run --filesystem=/tmp/gpauth.html org.chromium.Chromium /tmp/gpauth.html else /usr/bin/xdg-open \"$@\" fi reply tjoff 6 hours agoparentI'm more worried why a VPN-client has anything to do with a browser? reply chuckadams 4 hours agorootparentWeb login portal is my guess. reply fossdd 18 hours agoprevThat reminds my of a own xdg-open I wrote that sits in /usr/local/bin/xdg-open. It's a simple python script that checks by looking at the protocol, mime type or extension which URL it is and also asks if there are multiple applications https://paste.sr.ht/~fossdd/7fa65e10998ebcc03a2bbcc8488f94e9... (CC0) reply JNRowe 10 hours agoparent[In the spirit of elucidation, and not general meanness…] Like jojo14 points out Python has the shlex module, and it is definitely useful in these situations even if just for quote(). And, os.system() is basically never safe with external input. Without proper escaping you're one click from code execution, for example with the input \"file:///etc/issue%3Becho%20whoops\" or \"http://example.com/';echo whoops'\". It doesn't appear to matter in this instance, but you can feed check_output() with the stdin argument, which removes the need for using shell=True. shell=True in other paths could easily lead to unwanted code execution without thorough escaping. reply jojo14 14 hours agoparentprevThank you for sharing :-) Your script is simple, yet effective. If you plan to modify it you might want to check shlex : https://docs.python.org/3/library/shlex.html#module-shlex reply koiueo 12 hours agoparentprevI like the in_term trick reply TZubiri 5 hours agoprevWho would win customxdgoverridebinary application .ext or just application file.ext Some people just really take any excuse to write a program. reply koiueo 4 hours agoparentI'm not sure I understand you... I can't change Slack source code to invoke `firefox $url` for me instead of xdg-open it currently invokes. If you know a way, please share. reply TZubiri 22 minutes agorootparentHow about just: 'firefox url' directly on the terminal? reply rustyminnow 10 minutes agorootparentyes, lol, just copy the url, find/open a terminal window, type out `firefox `, paste the url, and press enter. So much easier. To be clear, the override script is closer to going ... mkdir ~/custombin/ ln $(which firefox) ~/custombin/ PATH=~/custombin:$PATH slack ... than going `firefox url` reply ThrowawayTestr 7 hours agoprev [–] Is this like the \"open with\" option in Windows? reply koiueo 3 hours agoparent [–] I don't know how \"open with\" option on Windows works, but if it works like in other OSes (https://imgur.com/c26RLRv), then xdg-override is not about that. xdg-override temporarily and selectively replaces the application opened by default (without the \"open with\" menu and in places where this menu isn't even available) reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "xdg-open is a GNU/Linux tool that opens files and URLs in the user's preferred applications, ensuring consistent behavior across different environments.",
      "xdg-override allows users to temporarily change the default application for specific tasks without altering system settings, useful for scenarios like using a different browser for certain applications.",
      "Installation can be done via Nix or by placing the script manually, and it offers options to override specific mimetypes, enhancing flexibility in application handling."
    ],
    "commentSummary": [
      "`xdg-override` is a script designed to selectively replace `xdg-open` for handling default applications on Linux, addressing specific issues users face.",
      "Users discuss various custom scripts and methods to manage file and URL opening, reflecting the complexity and need for customization in different desktop environments.",
      "The conversation highlights both the benefits and criticisms of `xdg-open`, with some users preferring alternative solutions like GNOME's \"Junction\" or custom scripts."
    ],
    "points": 115,
    "commentCount": 28,
    "retryCount": 0,
    "time": 1722547976
  },
  {
    "id": 41133084,
    "title": "Intel Reports Second Quarter 2024 Financial Results",
    "originLink": "https://www.intc.com/news-events/press-releases/detail/1704/intel-reports-second-quarter-2024-financial-results",
    "originBody": "Intel Reports Second-Quarter 2024 Financial Results; Announces $10 Billion Cost Reduction Plan to Increase Efficiency and Market Competitiveness Download as PDF Aug 1, 2024 • 4:01 PM EDT Related Documents Audio Earnings Webcast Earnings Presentation PDF Infographic PDF Prepared Remarks PDF 10-Q Filing PDF HTML XBRL ZIP XLS HTML NEWS SUMMARY Second-quarter revenue of $12.8 billion, down 1% year over year (YoY). Second-quarter GAAP earnings (loss) per share (EPS) attributable to Intel was $(0.38); non-GAAP EPS attributable to Intel was $0.02. Forecasting third-quarter 2024 revenue of $12.5 billion to $13.5 billion; expecting third-quarter GAAP EPS attributable to Intel of $(0.24); non-GAAP EPS attributable to Intel of $(0.03). Implementing comprehensive reduction in spending, including a more than 15% headcount reduction, to resize and refocus. Suspending dividend starting in the fourth quarter of 2024. The company reiterates its long-term commitment to a competitive dividend as cash flows improve to sustainably higher levels. Achieved key milestones on Intel 18A with the 1.0 Process Design Kit (PDK) released and key power-on of first client and server products on Intel 18A, Panther Lake and Clearwater Forest. SANTA CLARA, Calif.--(BUSINESS WIRE)-- Intel Corporation today reported second-quarter 2024 financial results. “Our Q2 financial performance was disappointing, even as we hit key product and process technology milestones. Second-half trends are more challenging than we previously expected, and we are leveraging our new operating model to take decisive actions that will improve operating and capital efficiencies while accelerating our IDM 2.0 transformation,” said Pat Gelsinger, Intel CEO. “These actions, combined with the launch of Intel 18A next year to regain process technology leadership, will strengthen our position in the market, improve our profitability and create shareholder value.” “Second-quarter results were impacted by gross margin headwinds from the accelerated ramp of our AI PC product, higher than typical charges related to non-core businesses and the impact from unused capacity,” said David Zinsner, Intel CFO. “By implementing our spending reductions, we are taking proactive steps to improve our profits and strengthen our balance sheet. We expect these actions to meaningfully improve liquidity and reduce our debt balance while enabling us to make the right investments to drive long-term value for shareholders.” Cost-Reduction Plan As Intel nears the completion of rebuilding a sustainable engine of process technology leadership, it announced a series of initiatives to create a sustainable financial engine that accelerates profitable growth, enables further operational efficiency and agility, and creates capacity for ongoing strategic investment in technology and manufacturing leadership. These initiatives follow the establishment of separate financial reporting for Intel Products and Intel Foundry, which provides a \"clean sheet\" view of the business and has uncovered significant opportunities to drive meaningful operational and cost efficiencies. The actions include structural and operating realignment across the company, headcount reductions, and operating expense and capital expenditure reductions of more than $10 billion in 2025 compared to previous estimates. As a result of these actions, Intel aims to achieve clear line of sight toward a sustainable business model with the ongoing financial resources and liquidity needed to support the company’s long-term strategy. The plan will enable the next phase of the company’s multiyear transformation strategy, and is focused on four key priorities: Reducing Operating Expenses: The company will streamline its operations and meaningfully cut spending and headcount, reducing non-GAAP R&D and marketing, general and administrative (MG&A) to approximately $20 billion in 2024 and approximately $17.5 billion in 2025, with further reductions expected in 2026. Intel expects to reduce headcount by greater than 15% with the majority completed by the end of 2024. Reducing Capital Expenditures: With the end of its historic five-nodes-in-four-years journey firmly in sight, Intel is now shifting its focus toward capital efficiency and investment levels aligned to market requirements. This will reduce gross capital expenditures* in 2024 by more than 20% from prior projections, bringing gross capital expenditures in 2024 to between $25 billion and $27 billion. Intel expects net capital spending* in 2024 of between $11 billion and $13 billion. In 2025, the company is targeting gross capital expenditures between $20 billion and $23 billion and net capital spending between $12 billion and $14 billion. Reducing Cost of Sales: The company expects to generate $1 billion in savings in non-variable cost of sales in 2025. Product mix will continue to be a headwind next year, contributing to modest YoY improvements to 2025's gross margin. Maintaining Core Investments to Execute Strategy: The company continues to advance its long-term innovation and path to leadership across process technology and products, and the increased efficiency from its actions is expected to further support its execution. In addition, Intel continues to sustain investments to build a resilient and sustainable semiconductor supply chain in the United States and around the world. Intel is taking the added step of suspending the dividend starting in the fourth quarter, recognizing the importance of prioritizing liquidity to support the investments needed to execute its strategy. The company reiterates its long-term commitment to a competitive dividend as cash flows improve to sustainably higher levels. Q2 2024 Financial HighlightsGAAPNon-GAAPQ2 2024Q2 2023vs. Q2 2023Q2 2024Q2 2023vs. Q2 2023 Revenue ($B)$12.8$12.9down 1%Gross Margin35.4%35.8%down 0.4 ppt38.7%39.8%down 1.1 ppts R&D and MG&A ($B)$5.6$5.5up 2%$4.9$4.7up 5% Operating Margin(15.3)%(7.8)%down 7.5 ppts0.2%3.5%down 3.3 ppts Tax Rate17.5%280.5%n/m**13.0%13.0%— Net Income (loss) Attributable to Intel ($B)$(1.6)$1.5n/m**$0.1$0.5down 85% Earnings (loss) Per Share Attributable to Intel$(0.38)$0.35n/m**$0.02$0.13down 85% In the second quarter, the company generated $2.3 billion in cash from operations and paid dividends of $0.5 billion. *Gross capital expenditures refers to GAAP additions to property, plant, and equipment. Net capital spending, a non-GAAP financial measure, is defined as additions to property, plant, and equipment, net of proceeds from capital-related government incentives and partner contributions. See below for more information on and reconciliations of Intel's non-GAAP financial measures. **Not meaningful Business Unit Summary Intel previously announced the implementation of an internal foundry operating model, which took effect in the first quarter of 2024 and created a foundry relationship between its Intel Products business (collectively CCG, DCAI and NEX) and its Intel Foundry business (including Foundry Technology Development, Foundry Manufacturing and Supply Chain, and Foundry Services (formerly IFS)). The foundry operating model is a key component of the company's strategy and is designed to reshape operational dynamics and drive greater transparency, accountability, and focus on costs and efficiency. The company also previously announced its intent to operate Altera® as a standalone business beginning in the first quarter of 2024. Altera was previously included in DCAI's segment results. As a result of these changes, the company modified its segment reporting in the first quarter of 2024 to align to this new operating model. All prior-period segment data has been retrospectively adjusted to reflect the way the company internally receives information and manages and monitors its operating segment performance starting in fiscal year 2024. There are no changes to Intel’s consolidated financial statements for any prior periods. Business Unit Revenue and TrendsQ2 2024vs. Q2 2023 Intel Products: Client Computing Group (CCG)$7.4 billionup 9% Data Center and AI (DCAI)$3.0 billiondown 3% Network and Edge (NEX)$1.3 billiondown 1% Total Intel Products revenue$11.8 billionup 4% Intel Foundry$4.3 billionup 4% All other: Altera$361 milliondown 57% Mobileye$440 milliondown 3% Other$167 millionup 43% Total all other revenue$968 milliondown 32% Intersegment eliminations$(4.3) billionTotal net revenue$12.8 billiondown 1% Intel Products Highlights CCG: Intel continues to define and drive the AI PC category, shipping more than 15 million AI PCs since December 2023, far more than all of Intel's competitors combined, and on track to ship more than 40 million AI PCs by year-end. Lunar Lake, the company’s next-generation AI CPU, achieved production release in July 2024, ahead of schedule, with shipments starting in the third quarter. Lunar Lake will power over 80 new Copilot+ PCs across more than 20 OEMs. DCAI: More than 130 million Intel® Xeon® processors power data centers around the world today, and at Computex Intel introduced its next-generation Intel® Xeon® 6 processor with Efficient-cores (E-cores), code-named Sierra Forest, marking the company’s first Intel 3 server product architected for high-density, scale-out workloads. Intel expects Intel® Xeon® 6 processors with Performance-cores (P-cores), code-named Granite Rapids, to begin shipping in the third quarter of 2024. The Intel® Gaudi® 3 AI accelerator is also on track to launch in the third quarter and is expected to deliver roughly two-times the performance per dollar on both inference and training versus the leading competitor. NEX: Intel announced an array of AI-optimized scale-out Ethernet solutions, including the Intel AI network interface card and foundry chiplets that will launch next year. New infrastructure processing unit (IPU) adaptors for the enterprise are now broadly available and supported by Dell Technologies, Red Hat and others. IPUs will play an increasingly important role in Intel’s accelerator portfolio, which the company expects will help drive AI data center growth and profitability in 2025 and beyond. Additionally, Intel and others announced the creation of the Ultra Accelerator Link, a new industry standard dedicated to advancing high-speed, low-latency communication for scale-up AI systems communication in data centers. Intel Foundry Highlights Intel is nearing the completion of its promised five-nodes-in-four-years strategy, with Intel 18A on track to be manufacturing-ready by the end of this year and production wafer start volumes in the first half of 2025. In July 2024, Intel released to foundry customers the 1.0 PDK for Intel 18A. The company’s first two Intel 18A products, Panther Lake for client — the first microprocessor to use RibbonFet, PowerVia and advanced packaging — and Clearwater Forest for servers, are on track to launch in 2025. Ansys, Cadence, Siemens, and Synopsys announced the availability of reference flows for Intel’s embedded multi-die interconnect bridge (EMIB) advanced packaging technology, which simplifies the design process and offers design flexibility. The companies also declared readiness for Intel 18A designs. During the quarter, Intel named industry veteran Kevin O'Buckley to lead Foundry Services. The company also recently appointed Dr. Naga Chandrasekaran to lead Intel Foundry Manufacturing and Supply Chain. Their leadership will support Intel’s continued development of the first systems foundry for the AI era. Other Highlights Intel announced its second Semiconductor Co-Investment Program (SCIP) agreement, the formation of a joint venture with Apollo related to Intel’s Fab 34 in Ireland. SCIP is an element of Intel’s Smart Capital strategy, a funding approach designed to create financial flexibility to accelerate the company’s strategy, including investing in its global manufacturing operations, while maintaining a strong balance sheet. Q3 2024 Dividend The company announced that its board of directors has declared a quarterly dividend of $0.125 per share on the company’s common stock, which will be payable Sept. 1, 2024, to shareholders of record as of Aug. 7, 2024. As noted earlier, Intel is suspending the dividend starting in the fourth quarter. Business Outlook Intel's guidance for the third quarter of 2024 includes both GAAP and non-GAAP estimates as follows: Q3 2024 GAAP Non-GAAP Revenue $12.5-13.5 billion Gross Margin 34.5% 38.0% Tax Rate 34% 13% Earnings (Loss) Per Share Attributable to Intel—Diluted $(0.24) $(0.03) Reconciliations between GAAP and non-GAAP financial measures are included below. Actual results may differ materially from Intel’s business outlook as a result of, among other things, the factors described under “Forward-Looking Statements” below. The gross margin and EPS outlook are based on the mid-point of the revenue range. Earnings Webcast Intel will hold a public webcast at 2 p.m. PDT today to discuss the results for its second quarter of 2024. The live public webcast can be accessed on Intel's Investor Relations website at www.intc.com. The corresponding earnings presentation and webcast replay will also be available on the site. Forward-Looking Statements This release contains forward-looking statements that involve a number of risks and uncertainties. Words such as \"accelerate\", \"achieve\", \"aim\", \"ambitions\", \"anticipate\", \"believe\", \"committed\", \"continue\", \"could\", \"designed\", \"estimate\", \"expect\", \"forecast\", \"future\", \"goals\", \"grow\", \"guidance\", \"intend\", \"likely\", \"may\", \"might\", \"milestones\", \"next generation\", \"objective\", \"on track\", \"opportunity\", \"outlook\", \"pending\", \"plan\", \"position\", \"possible\", \"potential\", \"predict\", \"progress\", \"ramp\", \"roadmap\", \"seek\", \"should\", \"strive\", \"targets\", \"to be\", \"upcoming\", \"will\", \"would\", and variations of such words and similar expressions are intended to identify such forward-looking statements, which may include statements regarding: our business plans and strategy and anticipated benefits therefrom, including with respect to our IDM 2.0 strategy, Smart Capital strategy, partnerships with Apollo and Brookfield, internal foundry model, updated reporting structure, and AI strategy; projections of our future financial performance, including future revenue, gross margins, capital expenditures, and cash flows; projected costs and yield trends; future cash requirements, the availability, uses, sufficiency, and cost of capital resources, and sources of funding, including for future capital and R&D investments and for returns to stockholders, such as stock repurchases and dividends, and credit ratings expectations; future products, services, and technologies, and the expected goals, timeline, ramps, progress, availability, production, regulation, and benefits of such products, services, and technologies, including future process nodes and packaging technology, product roadmaps, schedules, future product architectures, expectations regarding process performance, per-watt parity, and metrics, and expectations regarding product and process leadership; investment plans and impacts of investment plans, including in the US and abroad; internal and external manufacturing plans, including future internal manufacturing volumes, manufacturing expansion plans and the financing therefor, and external foundry usage; future production capacity and product supply; supply expectations, including regarding constraints, limitations, pricing, and industry shortages; plans and goals related to Intel's foundry business, including with respect to anticipated customers, future manufacturing capacity and service, technology, and IP offerings; expected timing and impact of acquisitions, divestitures, and other significant transactions, including the sale of our NAND memory business; expected completion and impacts of restructuring activities and cost-saving or efficiency initiatives; future social and environmental performance goals, measures, strategies, and results; our anticipated growth, future market share, and trends in our businesses and operations; projected growth and trends in markets relevant to our businesses; anticipated trends and impacts related to industry component, substrate, and foundry capacity utilization, shortages, and constraints; expectations regarding government incentives; future technology trends and developments, such as AI; future macro environmental and economic conditions; geopolitical tensions and conflicts and their potential impact on our business; tax- and accounting-related expectations; expectations regarding our relationships with certain sanctioned parties; and other characterizations of future events or circumstances. Such statements involve many risks and uncertainties that could cause our actual results to differ materially from those expressed or implied, including those associated with: the high level of competition and rapid technological change in our industry; the significant long-term and inherently risky investments we are making in R&D and manufacturing facilities that may not realize a favorable return; the complexities and uncertainties in developing and implementing new semiconductor products and manufacturing process technologies; our ability to time and scale our capital investments appropriately and successfully secure favorable alternative financing arrangements and government grants; implementing new business strategies and investing in new businesses and technologies; changes in demand for our products; macroeconomic conditions and geopolitical tensions and conflicts, including geopolitical and trade tensions between the US and China, the impacts of Russia's war on Ukraine, tensions and conflict affecting Israel and the Middle East, and rising tensions between mainland China and Taiwan; the evolving market for products with AI capabilities; our complex global supply chain, including from disruptions, delays, trade tensions and conflicts, or shortages; product defects, errata and other product issues, particularly as we develop next-generation products and implement next-generation manufacturing process technologies; potential security vulnerabilities in our products; increasing and evolving cybersecurity threats and privacy risks; IP risks including related litigation and regulatory proceedings; the need to attract, retain, and motivate key talent; strategic transactions and investments; sales-related risks, including customer concentration and the use of distributors and other third parties; our significantly reduced return of capital in recent years; our debt obligations and our ability to access sources of capital; complex and evolving laws and regulations across many jurisdictions; fluctuations in currency exchange rates; changes in our effective tax rate; catastrophic events; environmental, health, safety, and product regulations; our initiatives and new legal requirements with respect to corporate responsibility matters; and other risks and uncertainties described in this release, our 2023 Form 10-K, and our other filings with the SEC. Given these risks and uncertainties, readers are cautioned not to place undue reliance on such forward-looking statements. Readers are urged to carefully review and consider the various disclosures made in this release and in other documents we file from time to time with the SEC that disclose risks and uncertainties that may affect our business. Unless specifically indicated otherwise, the forward-looking statements in this release do not reflect the potential impact of any divestitures, mergers, acquisitions, or other business combinations that have not been completed as of the date of this filing. In addition, the forward-looking statements in this release are based on management's expectations as of the date of this release, unless an earlier date is specified, including expectations based on third-party information and projections that management believes to be reputable. We do not undertake, and expressly disclaim any duty, to update such statements, whether as a result of new information, new developments, or otherwise, except to the extent that disclosure may be required by law. About Intel Intel (Nasdaq: INTC) is an industry leader, creating world-changing technology that enables global progress and enriches lives. Inspired by Moore’s Law, we continuously work to advance the design and manufacturing of semiconductors to help address our customers’ greatest challenges. By embedding intelligence in the cloud, network, edge and every kind of computing device, we unleash the potential of data to transform business and society for the better. To learn more about Intel’s innovations, go to newsroom.intel.com and intel.com. © Intel Corporation. Intel, the Intel logo, and other Intel marks are trademarks of Intel Corporation or its subsidiaries. Other names and brands may be claimed as the property of others. Intel Corporation Consolidated Condensed Statements of Income and Other Information Three Months Ended (In Millions, Except Per Share Amounts; Unaudited) Jun 29, 2024 Jul 1, 2023 Net revenue $ 12,833 $ 12,949 Cost of sales 8,286 8,311 Gross margin 4,547 4,638 Research and development 4,239 4,080 Marketing, general, and administrative 1,329 1,374 Restructuring and other charges 943 200 Operating expenses 6,511 5,654 Operating income (loss) (1,964 ) (1,016 ) Gains (losses) on equity investments, net (120 ) (24 ) Interest and other, net 80 224 Income (loss) before taxes (2,004 ) (816 ) Provision for (benefit from) taxes (350 ) (2,289 ) Net income (loss) (1,654 ) 1,473 Less: Net income (loss) attributable to non-controlling interests (44 ) (8 ) Net income (loss) attributable to Intel $ (1,610 ) $ 1,481 Earnings (loss) per share attributable to Intel—basic $ (0.38 ) $ 0.35 Earnings (loss) per share attributable to Intel—diluted $ (0.38 ) $ 0.35 Weighted average shares of common stock outstanding: Basic 4,267 4,182 Diluted 4,267 4,196 Three Months Ended (In Millions; Unaudited) Jun 29, 2024 Jul 1, 2023 Earnings per share of common stock information: Weighted average shares of common stock outstanding—basic 4,267 4,182 Dilutive effect of employee equity incentive plans — 14 Weighted average shares of common stock outstanding—diluted 4,267 4,196 Other information:(In Thousands; Unaudited)Jun 29, 2024Mar 30, 2024Jul 1, 2023 EmployeesIntel116.5116.4118.1 Mobileye and other subsidiaries5.35.24.7 NAND13.53.64.0 Total Intel125.3125.2126.8 1 Employees of the NAND memory business, which we divested to SK hynix on completion of the first closing on December 29, 2021 and fully deconsolidated in Q1 2022. Upon completion of the second closing of the divestiture, which remains pending and subject to closing conditions, the NAND employees will be excluded from the total Intel employee number. Intel Corporation Consolidated Condensed Balance Sheets(In Millions; Unaudited) Jun 29, 2024 Dec 30, 2023 Assets Current assets: Cash and cash equivalents $ 11,287 $ 7,079 Short-term investments 17,986 17,955 Accounts receivable, net 3,131 3,402 Inventories Raw materials 1,284 1,166 Work in process 6,294 6,203 Finished goods 3,666 3,758 11,244 11,127 Other current assets 7,181 3,706 Total current assets 50,829 43,269 Property, plant, and equipment, net 103,398 96,647 Equity investments 5,824 5,829 Goodwill 27,442 27,591 Identified intangible assets, net 4,383 4,589 Other long-term assets 14,329 13,647 Total assets $ 206,205 $ 191,572 Liabilities and stockholders’ equity Current liabilities: Short-term debt $ 4,695 $ 2,288 Accounts payable 9,618 8,578 Accrued compensation and benefits 2,651 3,655 Income taxes payable 1,856 1,107 Other accrued liabilities 13,207 12,425 Total current liabilities 32,027 28,053 Debt 48,334 46,978 Other long-term liabilities 5,410 6,576 Stockholders’ equity: Common stock and capital in excess of par value, 4,276 issued and outstanding (4,228 issued and outstanding as of December 30, 2023) 49,763 36,649 Accumulated other comprehensive income (loss) (696 ) (215 ) Retained earnings 66,162 69,156 Total Intel stockholders' equity 115,229 105,590 Non-controlling interests 5,205 4,375 Total stockholders' equity 120,434 109,965 Total liabilities and stockholders’ equity $ 206,205 $ 191,572Intel Corporation Consolidated Condensed Statements of Cash FlowsSix Months Ended (In Millions; Unaudited) Jun 29, 2024 Jul 1, 2023 Cash and cash equivalents, beginning of period $ 7,079 $ 11,144 Cash flows provided by (used for) operating activities: Net income (loss) (2,091 ) (1,295 ) Adjustments to reconcile net income (loss) to net cash provided by operating activities: Depreciation 4,403 3,733 Share-based compensation 1,959 1,661 Restructuring and other charges 1,291 255 Amortization of intangibles 717 909 (Gains) losses on equity investments, net (84 ) (146 ) Changes in assets and liabilities: Accounts receivable 272 1,137 Inventories (116 ) 1,240 Accounts payable 184 (1,102 ) Accrued compensation and benefits (1,309 ) (1,340 ) Income taxes (2,174 ) (2,186 ) Other assets and liabilities (1,983 ) (1,843 ) Total adjustments 3,160 2,318 Net cash provided by (used for) operating activities 1,069 1,023 Cash flows provided by (used for) investing activities: Additions to property, plant, and equipment (11,652 ) (13,301 ) Proceeds from capital-related government incentives 699 49 Purchases of short-term investments (17,634 ) (25,696 ) Maturities and sales of short-term investments 17,214 26,957 Other investing (355 ) 662 Net cash provided by (used for) investing activities (11,728 ) (11,329 ) Cash flows provided by (used for) financing activities: Issuance of commercial paper, net of issuance costs 5,804 — Repayment of commercial paper (2,609 ) (3,944 ) Payments on finance leases — (96 ) Partner contributions 11,861 834 Proceeds from sales of subsidiary shares — 1,573 Issuance of long-term debt, net of issuance costs 2,975 10,968 Repayment of debt (2,288 ) — Proceeds from sales of common stock through employee equity incentive plans 631 665 Payment of dividends to stockholders (1,063 ) (2,036 ) Other financing (444 ) (453 ) Net cash provided by (used for) financing activities 14,867 7,511 Net increase (decrease) in cash and cash equivalents 4,208 (2,795 ) Cash and cash equivalents, end of period $ 11,287 $ 8,349Intel Corporation Supplemental Operating Segment ResultsThree Months Ended (In Millions) Jun 29, 2024 Jul 1, 2023 Operating segment revenue: Intel Products: Client Computing Group Desktop $ 2,527 $ 2,370 Notebook 4,480 3,896 Other 403 514 7,410 6,780 Data Center and AI 3,045 3,155 Network and Edge 1,344 1,364 Total Intel Products revenue $ 11,799 $ 11,299 Intel Foundry $ 4,320 $ 4,172 All other Altera 361 848 Mobileye 440 454 Other 167 117 Total all other revenue 968 1,419 Total operating segment revenue $ 17,087 $ 16,890 Intersegment eliminations (4,254 ) (3,941 ) Total net revenue $ 12,833 $ 12,949 Segment operating income (loss): Intel Products: Client Computing Group $ 2,497 $ 1,986 Data Center and AI 276 469 Network and Edge 139 64 Total Intel Products operating income (loss) $ 2,912 $ 2,519 Intel Foundry $ (2,830 ) $ (1,869 ) All Other Altera (25 ) 346 Mobileye 72 129 Other (82 ) (120 ) Total all other operating income (loss) (35 ) 355 Total segment operating income (loss) $ 47 $ 1,005 Intersegment eliminations (291 ) (413 ) Corporate unallocated expenses (1,720 ) (1,608 ) Total operating income (loss) $ (1,964 ) $ (1,016 ) For information about our operating segments, including the nature of segment revenues and expenses, and a reconciliation of our operating segment revenue and operating income (loss) to our consolidated results, refer to our Form 10-K filed on January 26, 2024, Form 8-K furnished on April 2, 2024 and 10-Q filed on August 1, 2024. Intel Corporation Explanation of Non-GAAP Measures In addition to disclosing financial results in accordance with US GAAP, this document contains references to the non-GAAP financial measures below. We believe these non-GAAP financial measures provide investors with useful supplemental information about our operating performance, enable comparison of financial trends and results between periods where certain items may vary independent of business performance, and allow for greater transparency with respect to key metrics used by management in operating our business and measuring our performance. Some of these non-GAAP financial measures are used in our performance-based RSUs and our cash bonus plans. Our non-GAAP financial measures reflect adjustments based on one or more of the following items, as well as the related income tax effects. Income tax effects are calculated using a fixed long-term projected tax rate of 13% across all adjustments. We project this long-term non-GAAP tax rate on at least an annual basis using a five-year non-GAAP financial projection that excludes the income tax effects of each adjustment. The projected non-GAAP tax rate also considers factors such as our tax structure, our tax positions in various jurisdictions, and key legislation in significant jurisdictions where we operate. This long-term non-GAAP tax rate may be subject to change for a variety of reasons, including the rapidly evolving global tax environment, significant changes in our geographic earnings mix, or changes to our strategy or business operations. Management uses this non-GAAP tax rate in managing internal short- and long-term operating plans and in evaluating our performance; we believe this approach facilitates comparison of our operating results and provides useful evaluation of our current operating performance. Our non-GAAP financial measures should not be considered a substitute for, or superior to, financial measures calculated in accordance with US GAAP, and the financial results calculated in accordance with US GAAP and reconciliations from these results should be carefully evaluated. Non-GAAP adjustment or measure Definition Usefulness to management and investors Acquisition-related adjustments Amortization of acquisition-related intangible assets consists of amortization of intangible assets such as developed technology, brands, and customer relationships acquired in connection with business combinations. Charges related to the amortization of these intangibles are recorded within both cost of sales and MG&A in our US GAAP financial statements. Amortization charges are recorded over the estimated useful life of the related acquired intangible asset, and thus are generally recorded over multiple years. We exclude amortization charges for our acquisition-related intangible assets for purposes of calculating certain non-GAAP measures because these charges are inconsistent in size and are significantly impacted by the timing and valuation of our acquisitions. These adjustments facilitate a useful evaluation of our current operating performance and comparison to our past operating performance and provide investors with additional means to evaluate cost and expense trends. Share-based compensation Share-based compensation consists of charges related to our employee equity incentive plans. We exclude charges related to share-based compensation for purposes of calculating certain non-GAAP measures because we believe these adjustments provide comparability to peer company results and because these charges are not viewed by management as part of our core operating performance. We believe these adjustments provide investors with a useful view, through the eyes of management, of our core business model, how management currently evaluates core operational performance, and additional means to evaluate expense trends, including in comparison to other peer companies. Restructuring and other charges Restructuring charges are costs associated with a restructuring plan and are primarily related to employee severance and benefit arrangements. Other charges include periodic goodwill and asset impairments, and costs associated with restructuring activity. Q2 2024 includes a charge arising out of the R2 litigation. We exclude restructuring and other charges, including any adjustments to charges recorded in prior periods, for purposes of calculating certain non-GAAP measures because these costs do not reflect our core operating performance. These adjustments facilitate a useful evaluation of our core operating performance and comparisons to past operating results and provide investors with additional means to evaluate expense trends. (Gains) losses on equity investments, net (Gains) losses on equity investments, net consists of ongoing mark-to-market adjustments on marketable equity securities, observable price adjustments on non-marketable equity securities, related impairment charges, and the sale of equity investments and other. We exclude these non-operating gains and losses for purposes of calculating certain non-GAAP measures because it provides comparability between periods. The exclusion reflects how management evaluates the core operations of the business. (Gains) losses from divestiture (Gains) losses are recognized at the close of a divestiture, or over a specified deferral period when deferred consideration is received at the time of closing. Based on our ongoing obligation under the NAND wafer manufacturing and sale agreement entered into in connection with the first closing of the sale of our NAND memory business on December 29, 2021, a portion of the initial closing consideration was deferred and will be recognized between first and second closing. We exclude gains or losses resulting from divestitures for purposes of calculating certain non-GAAP measures because they do not reflect our current operating performance. These adjustments facilitate a useful evaluation of our current operating performance and comparisons to past operating results. Adjusted free cash flow We reference a non-GAAP financial measure of adjusted free cash flow, which is used by management when assessing our sources of liquidity, capital resources, and quality of earnings. Adjusted free cash flow is operating cash flow adjusted for (1) additions to property, plant, and equipment, net of proceeds from capital-related government incentives and partner contributions, and (2) payments on finance leases. This non-GAAP financial measure is helpful in understanding our capital requirements and sources of liquidity by providing an additional means to evaluate the cash flow trends of our business. Net capital spending We reference a non-GAAP financial measure of net capital spending, which is additions to property, plant, and equipment, net of proceeds from capital-related government incentives and partner contributions. We believe this measure provides investors with useful supplemental information about our capital investment activities and capital offsets, and allows for greater transparency with respect to a key metric used by management in operating our business and measuring our performance. Intel Corporation Supplemental Reconciliations of GAAP Actuals to Non-GAAP Actuals Set forth below are reconciliations of the non-GAAP financial measure to the most directly comparable US GAAP financial measure. These non-GAAP financial measures should not be considered a substitute for, or superior to, financial measures calculated in accordance with US GAAP, and the reconciliations from US GAAP to Non-GAAP actuals should be carefully evaluated. Please refer to \"Explanation of Non-GAAP Measures\" in this document for a detailed explanation of the adjustments made to the comparable US GAAP measures, the ways management uses the non-GAAP measures, and the reasons why management believes the non-GAAP measures provide useful information for investors.Three Months Ended (In Millions, Except Per Share Amounts)Jun 29, 2024Jul 1, 2023 GAAP gross margin$ 4,547$ 4,638 Acquisition-related adjustments224306 Share-based compensation195210 Non-GAAP gross margin$ 4,966$ 5,154 GAAP gross margin percentage35.4 %35.8 % Acquisition-related adjustments1.7 %2.4 % Share-based compensation1.5 %1.6 % Non-GAAP gross margin percentage38.7 %39.8 % GAAP R&D and MG&A$ 5,568$ 5,454 Acquisition-related adjustments(41 )(44 ) Share-based compensation(585 )(712 ) Non-GAAP R&D and MG&A$ 4,942$ 4,698 GAAP operating income (loss)$ (1,964 )$ (1,016 ) Acquisition-related adjustments265350 Share-based compensation780922 Restructuring and other charges943200 Non-GAAP operating income$ 24$ 456 GAAP operating margin (loss)(15.3 )%(7.8 )% Acquisition-related adjustments2.1 %2.7 % Share-based compensation6.1 %7.1 % Restructuring and other charges7.3 %1.5 % Non-GAAP operating margin0.2 %3.5 % GAAP tax rate17.5 %280.5 % Income tax effects(4.5 )%(267.5 )% Non-GAAP tax rate13.0 %13.0 % GAAP net income (loss) attributable to Intel$ (1,610 )$ 1,481 Acquisition-related adjustments265350 Share-based compensation780922 Restructuring and other charges943200 (Gains) losses on equity investments, net12024 (Gains) losses from divestiture(39 )(39 ) Adjustments attributable to non-controlling interest(18 )(18 ) Income tax effects(358 )(2,373 ) Non-GAAP net income attributable to Intel$ 83$ 547 (In Millions, Except Per Share Amounts)Jun 29, 2024 Jul 1, 2023 GAAP earnings (loss) per share attributable to Intel—diluted$ (0.38 )$ 0.35 Acquisition-related adjustments0.060.08 Share-based compensation0.180.22 Restructuring and other charges0.220.05 (Gains) losses on equity investments, net0.030.01 (Gains) losses from divestiture(0.01 )(0.01 ) Adjustments attributable to non-controlling interest—— Income tax effects(0.08 )(0.57 ) Non-GAAP earnings per share attributable to Intel—diluted$ 0.02$ 0.13 GAAP net cash provided by (used for) operating activities$ 2,292$ 2,808 Net partner contributions and incentives received (cash expended) for property plant and equipment5,863(5,454 ) Payments on finance leases—(81 ) Adjusted free cash flow$ 8,155$ (2,727 ) GAAP net cash provided by (used for) investing activities$ (9,165 )$ (2,808 ) GAAP net cash provided by (used for) financing activities$ 11,237$ 117Intel Corporation Supplemental Reconciliations of GAAP Outlook to Non-GAAP Outlook Set forth below are reconciliations of the non-GAAP financial measure to the most directly comparable US GAAP financial measure. These non-GAAP financial measures should not be considered a substitute for, or superior to, financial measures calculated in accordance with US GAAP, and the financial outlook prepared in accordance with US GAAP and the reconciliations from this Business Outlook should be carefully evaluated. Please refer to \"Explanation of Non-GAAP Measures\" in this document for a detailed explanation of the adjustments made to the comparable US GAAP measures, the ways management uses the non-GAAP measures, and the reasons why management believes the non-GAAP measures provide useful information for investors.Q3 2024 Outlook1Approximately GAAP gross margin percentage34.5 % Acquisition-related adjustments1.7 % Share-based compensation1.8 % Non-GAAP gross margin percentage38.0 %GAAP tax rate34 % Income tax effects(21 )% Non-GAAP tax rate13 %GAAP earnings (loss) per share attributable to Intel—diluted$ (0.24 ) Acquisition-related adjustments0.06 Share-based compensation0.23 Restructuring and other charges0.06 (Gains) losses from divestiture(0.01 ) Adjustments attributable to non-controlling interest— Income tax effects(0.13 ) Non-GAAP earnings (loss) per share attributable to Intel—diluted$ (0.03 ) 1 Non-GAAP gross margin percentage and non-GAAP EPS outlook based on the mid-point of the revenue range. Intel Corporation Supplemental Reconciliations of Other GAAP to Non-GAAP Forward-Looking Estimates Set forth below are reconciliations of the non-GAAP financial measure to the most directly comparable US GAAP financial measure. These non-GAAP financial measures should not be considered a substitute for, or superior to, financial measures calculated in accordance with US GAAP, and the reconciliations should be carefully evaluated. Please refer to \"Explanation of Non-GAAP Measures\" in this document for a detailed explanation of the adjustments made to the comparable US GAAP measures, the ways management uses the non-GAAP measures, and the reasons why management believes the non-GAAP measures provide useful information for investors. (In Billions) Full-Year 2024 Full-Year 2025 Approximately Approximately GAAP R&D and MG&A $ 22.9 $ 20.1 Acquisition-related adjustments (0.2) (0.1) Share-based compensation (2.7) (2.5) Non-GAAP R&D and MG&A $ 20.0 $ 17.5 GAAP additions to property, plant and equipment (gross capital expenditures) $25.0 - $27.0 $20.0 - $23.0 Proceeds from capital-related government incentives (1.5 - 3.5) (4.0 - 6.0) Partner contributions (12.5) (4.0 - 5.0) Non-GAAP net capital spending $11.0 - 13.0 $12.0 - $14.0 View source version on businesswire.com: https://www.businesswire.com/news/home/20240801042170/en/ Kylie Altman Investor Relations 1-916-356-0320 kylie.altman@intel.com Penny Bruce Media Relations 1-408-893-0601 penelope.bruce@intel.com Source: Intel Corporation Released Aug 1, 2024 • 4:01 PM EDT",
    "commentLink": "https://news.ycombinator.com/item?id=41133084",
    "commentBody": "Intel Reports Second Quarter 2024 Financial Results (intc.com)113 points by mfiguiere 22 hours agohidepastfavorite106 comments softfalcon 22 hours agoThis sounds worryingly like “sales are down, cut costs to maintain profitability to spike our stock numbers” and not enough focus on what I believe is actually wrong, which is that they can’t seem to reliably make competitive processors in a stiff market. Anyone else feel like this is bean counters at Intel playing the wrong game? I personally feel like leadership at Intel lost the plot almost a decade ago. reply crowcroft 2 hours agoparentI'm not saying you're wrong, although even after reducing headcount by 15k they still have about as many employees as TSMC, NVIDIA and AMD combined. reply 0xB31B1B 2 hours agorootparentthey design and produce chips, TSMC produces but does not design, NVIDIA and AMD design but do not produce reply phonon 2 hours agorootparentThat's the point. They have more employees than the #1 silicon fabricator, the number #1 GPU designer, and the #2 CPU and GPU designer, COMBINED. reply NoPicklez 18 hours agoparentprevWe have very little understanding of the bloat that Intel might be carrying, or the projects they have underway that were not making progress or perhaps not the innovation expected. Financial reports are going to be exactly that, focused on the numbers and appearing to investors to be maximising their value. You want to carry a perception that you are focusing on the positives and the innovations being carries forward, as opposed to mulling over what \"might be wrong\". All companies go through ups and downs, but you do not want your financial report to have a theme of these are the things that are wrong. reply johnnyanmac 13 hours agorootparent>You want to carry a perception that you are focusing on the positives and the innovations being carries forward, as opposed to mulling over what \"might be wrong\". so, empty platitudes that turn into none or negative change. Gotta love the modern day business. reply NoPicklez 11 hours agorootparentStipulating in your financial report where your R&D is focusing and what those outcomes are hopefully going to be are not empty platitudes that turn into none or negative change. I doubt that Nvidia putting in their financial reports last year they were focusing their R&D on AI hardware turned into none or negative change reply johnnyanmac 11 hours agorootparentLots of hope in your comment. Not much hope in my mind. It's just been too shitty a year for me to trust these reports. The worst parts are that the shareholders barely care if they lie. They want to be lied to. They aren't investing because of product confidence after all. Pessimism aside: they did this exact song and dance some 7 years ago. So I'm not entirely operating off bad vibes but on history and current trends. Like I said, they already basicslly lost the AI race. If they want to compete for scraps, power to them. I just hope employees jump ship before the next layoff wave. reply layer8 21 hours agoparentprevLeadership changed back to an engineer with the return of Pat Gelsinger in 2021. I’d give him a couple more years. It takes time to turn around a big ship like Intel. reply lmaoguy 17 hours agorootparentMy favorite Pat moment was watching the video of him, published by VMWare, apologizing for how shitty their products were and how they were gunna do so much better. Then they got worse. reply TimeBearingDown 2 hours agorootparentGot a link? My search just turned up this comment. reply ladyanita22 20 hours agorootparentprevEveryone around here keeps talking about how the problem of Intel is that it was a Business guy running the company and not an engineer, and it feels so similar to when people claimed Phil Spencer was going to save Xbox. Truth is, Pat is doing nothing despite the generous government subsidies reply mey 20 hours agorootparentNot everyone is cut from the same cloth. Look at AMD, their CEO history has been staffed exclusively by people with engineering backgrounds, but their performance has had more than a few rocky points. reply LarsDu88 15 hours agorootparentprevThis is simply not true. They are building giant fabs in Arizona and Ohio from those subsidies. It takes YEARS to realize the benefits of these changes. The problem is, to stopgap TSMCs growing lead, Intel resorted to cranking up voltage on the last two generations of chips leading to what will be an imminent gigantic ass lawsuit. reply yndoendo 3 hours agorootparentThis is where I see that Intel Processor are pushing the cart for Intel Fabs by small iterations to sell new processors and mother boards. Intel Fabs needs to push it's own cart like TSMC and actually focus on long term quality and gains. reply toxic72 2 hours agorootparentIt takes a long time to stand up new fabs... reply epolanski 19 hours agorootparentprevI think that in a business like hardware and foundries you can really judge the CEO in no less than 4/5 years. reply johnnyanmac 13 hours agorootparentprev>it feels so similar to when people claimed Phil Spencer was going to save Xbox. Well, he did. He bought up a ton of studios and focused on games again. in 2014 they were completely tonedeaf to the state of not just games, but media as a whole. Cable box subscriptions even in 2014 for their 8th generation console was just horrible optics. Now, is it his fault directly that the game development per studio is slow, or the releases uneven? He's probably not blameless, but MS isn't really known to intervene nor micromanage their studios. IMO that's a much bigger issue than any single MS studio. reply blinded 19 hours agorootparentprevhe also dismissed arm. https://www.pcmag.com/news/intel-ceo-dismisses-threat-of-arm... my gut reaction is that he wont be their ceo for long. reply layer8 19 hours agorootparentIt’s still far from clear that ARM for Windows will be going anywhere. And Intel is trying to increase ISA diversification with their foundry business. reply epolanski 19 hours agorootparentI've seen reviews of the latest 13 inch Dell XPS and it's both more powerful and less energy hungry than the M3 in a MacBook air. It uses the Snapdragon Elite X ARM cpu. It also blows the latest mobile i7 ultra 155H on the same XPS 13 in performance while lasting almost 20 hours (compared to Intel's 6). The comparisons are made on software that runs on both (Geekbench, handbrake) but it's clear that there is a huge momentum building for windows on arm. reply LarsDu88 14 hours agorootparentThere's way more to ARM adoption than simply power consumption. When apple went to the M1, they got their entire software ecosystem to go along with the migration. That's the fundamental strength of Apple. They can do things like kill standards at will. Microsoft can't necessarily do the same thing for the vast library and catalog of x86 software. reply epolanski 7 hours agorootparentSure, but at the end of the day, the bulk of enterprise users need little more than Office + Teams + a browser. reply steve1977 10 hours agorootparentprevI guess the Lunar Lake mobile CPUs will be more interesting than the Meteor Lake ones (e.g. 155H). But we'll see if they can keep the promises in regards to power consumption. reply paulmd 15 hours agorootparentprevMT is one thing but in ST it’s still simply not even close. Even the Qualcomm SDXE pulls fully 15w less than AMD, and apple pulls 10w less than Qualcomm. 60w peak power consumption for a literal single thread. 35w average. https://old.reddit.com/r/hardware/comments/1efcst2/ai_370_vs... https://www.notebookcheck.net/AMD-Zen-5-Strix-Point-CPU-anal... We simply aren’t going to see x86 get to the subjective “apple experience” of a laptop that runs equally well on or off battery, with day-long life during interactive low-intensity usage, until x86 vendors can get their single-thread power consumption under control. Platform power is part of it (although external-monitor tests minimize most of the usual factors) but x86 simply isn’t competitive in performance terms unless it’s boosting excessively high in power terms. At least not right now. I know Keller said it only matters 20% or so, but… right now we are objectively in a world where x86 is using ~triple the power in 1T workloads. The x86 is fine when it can exploit SMT and the workloads are heavily numeric/vector oriented, they simply aren’t very good at single-threaded workloads where there is no SMT to fill their pipeline bubbles. And yes, race to sleep is all well and good. But apple can race to sleep on 1/3 the power. Apple can also have an icache and all that other crap too (m1 has an icache six times as big as its x86 competitors). At the end of the day the x86 results are still objectively poorer by literally several powers of 2. But Keller said everything is equally good therefore the evidence can be casually dismissed. Even the much happier computerbase numbers only put this at 20w core power (and they’re using sensors, not actual measurements of course). And that still is power you have to pay on those laptops, even if it’s “platform power” - like, ok, so the defense of x86 here is that x86’s finest champion is spending more on platform power than the apple laptop uses at the wall for the whole laptop… by a factor of 50%. It then uses another 2x multiple of the apple laptop to do just the computation work. That’s the bright side argument about x86. reply Decabytes 7 hours agorootparent> We simply aren’t going to see x86 get to the subjective “apple experience” of a laptop that runs equally well on or off battery, with day-long life during interactive low-intensity usage I disagree. Apple themselves showed what you could do with an x86 processor in terms of battery life long before they went to ARM, and most manufacturers still aren’t even close. People have been talking about the amazing life in their products for ages before arm. Meanwhile I can’t get my windows laptop to not burn itself up in my bag with an update, which also coincidentally uses a ton of battery power as the fans cool itself on full tilt reply paulmd 7 hours agorootparentAs an owner of an ice lake macbook I can tell you definitively that it’s still utter shit compared to the apple silicon ones. Best case scenario it idles at 14w system power, while my 2020 m1 mba idled atAs an owner of an ice lake macbook I can tell you definitively that it’s still utter shit compared to the apple silicon ones. Best case scenario it idles at 14w system power That really surprising since my 8th gen intel laptop (2 generations older than ice lake) idled at under 5W in Linux. So does my newer 12th gen intel laptop. reply paulmd 29 minutes agorootparentI would assume that’s packagd power and I mean total system power, using the “stats” cask with the average system power sensor. I will play with it and see if I can get package power. reply linotype 19 hours agorootparentprev> It also blows the latest mobile i7 ultra 155H on the same XPS 13 Oh my. reply bluedino 22 hours agoparentprev10 years from now, when the downfall of Intel is being taught at business schools, what are going to be the big takeways and now-obvious mistakes? reply softfalcon 22 hours agorootparentIn my opinion, one the most reliable signs is when companies stop repeatedly investing into their product innovation. The moment they start behaving like an established behemoth (monopoly/oligopoly) and you see repeated stock buybacks and frequent layoffs, the end is coming. This applies to most large, inefficient corporations that get too comfy with success and forget how to pivot fast, take risks, and fiercely fight for their place in the market. Eventually, any organization that falls into this state, slowly stagnates into oblivion. reply missedthecue 19 hours agorootparentIntel has put literally hundreds of billions of dollars into R&D annually in the past decade. Last year alone it was more than $16 billion. That's one of the highest annual R&D spends of any company in the entire US. Nvidia for comparison is less than half that per year. reply s1artibartfast 18 hours agorootparentThere is this interesting phenomenon where people outside an organization view R&D potential as elastic. That is to say, there is always a positive return on investment for the marginal R&D dollar. It is clearly not in the case or every company would have exponential growth simply by reinvesting in R&D. In reality, it is extremely difficult to create growth from R&D at all. reply 8note 12 hours agorootparentprevHow much of that end goes into their core product though? Vs trying to expand to different markets reply phkahler 22 hours agorootparentprev>> The moment they start behaving like an established behemoth (monopoly/oligopoly) and you see repeated stock buybacks and frequent layoffs, the end is coming. Add to that the suspension of the dividend, and the packaging of the FPGA business (getting ready to sell it?) and the reference to idle capacity - guess they can't even fill that with their foundry business. One thing I've noticed is that predicting timing is impossible. You can see a company showing signs of impending failure and somehow stock price still increases for a while, or the company decays slowly over a very long time. This might be a good thing since a company may save itself in some instances. reply epolanski 19 hours agorootparentThe writing was on the wall for Intel more than 7 years ago. By then: - Intel's 10 nm node was known to be two years late and known to be plagued for many others while TSMC had already taken the crown for most advanced foundry on the planet - Apple announced their work on phasing out Intel hardware completely for their own ARM SOCs - AMD had launched Ryzen, back then a bit slower in single thread but already much more competitive in MT - Supercomputers and crypto showed the ever increasing possibilities of GPUs for heavily parallelizable calculations and Intel had nothing to offer there - Cloud providers building their own hardware on ARM reply softfalcon 21 hours agorootparentprevI am convinced that the decay is often very slow. There are signs of impending failure and it frequently drags out for many, many years. Then, eventually, you'll see a \"straw that breaks the camel's back\" and the hollow shell of the company will finally, fully implode. reply UncleOxidant 19 hours agorootparent> I am convinced that the decay is often very slow. There are signs of impending failure and it frequently drags out for many, many years. When Jobs contacted Otellini about having Intel fab an ARM chip for them and Otellini said no... That's probably about the time their fate was sealed. And that would've been around 2006. Yes, there were plenty of signs prior to that. For example: AMD needed a lot less engineers to spin a new processor rev than Intel did and AFAIK that's still the case. reply UncleOxidant 19 hours agorootparentprev> You can see a company showing signs of impending failure and somehow stock price still increases for a while, or the company decays slowly over a very long time But Intel's stock has been stagnant for years. reply snotrockets 20 hours agorootparentprevIntel put money into R&D, but they kept betting on the wrong horses. reply jandrese 22 hours agorootparentprevProbably not offering fab time to other companies when they were process leaders. TSMC ate their lunch and managed to leapfrog Intel due to their massive R&D efforts fueled by cell phone chips. reply threatripper 20 hours agorootparentThis one is an interesting take. In hindsight it's pretty obvious but if you are in that situation at that time it seems like you would be selling your crown jewels for pennies. reply computerdork 19 hours agorootparentprevagreed. Stalling and then falling behind in fab to TSMC and Samsung is where they really lost the company. Still, Gelsinger sees this and they have bet the company on their 18A process. Will be interesting to see if they pull it off. reply MaxPock 19 hours agorootparentprevAgain ,the billions of mobile phones in the world would be running on Intel processors if they played their card well . reply danielmarkbruce 13 hours agorootparentprevThinking they were in a stable situation and going into max cashflow mode when there were in a death match. If you look at stock standard competitive theory (like, without any nuance) like Porter, you can see their situation getting really hairy starting 15 years ago. Customer concentration (public clouds), substitute products (arm in servers for standard workflows, various others in AI workloads etc), competition in their main product line couldn't go anywhere but worse (they were practically all by themselves). They had to fight like crazy but they thought they should print money. reply openrisk 13 hours agorootparent> Customer concentration Interesting that oligopsony beats oligopoly :-) reply tedunangst 22 hours agorootparentprevGo back and read the answers to when somebody asked the same question ten years ago? reply nateglims 19 hours agorootparent10 years ago the supposed lesson was probably don't operate in the US. reply epolanski 19 hours agorootparentprevBig takeaways: in consumer tech you live and die by the performance of your latest product. That applies to both CPUs and foundry. Now-obvious mistakes: I'm not including the obvious mobile argument as it belongs to the previous point, but they slept too long on GPUs. Even though the biggest supercomputers in the planet started doing computations on GPUs a decade ago they missed the ultimate parallelization-hardware train. reply paulmd 8 hours agorootparentthey have been cooking on it for decades too - larrabee was 2009 after all. Xeon phi survived that collapse and continued for another decade. Honestly the problem is the same then as it was today - having good hardware isn’t enough. You need software penetration and organic usage/ecosystem. And the world can support maybe 2-3 of those right now - nvidia, apple, maybe one other. Everyone else gets the bullshit “we are the ones you need a cross-platform “adapter” ecosystems with effectively no real corporate moat etc. (amd, intel, the door to this room is locked… one of you will get an ecosystem and the other goes home in a box… the game begins now.) Like even just in gaming, AMD’s continued refusal to do the devrel has hurt them, it’s cost them revenue. It’s not even just “the drivers” or the constant deficit in features and functionality, but getting the people out into the studios to assist in development and tuning is how it has to be, nobody is going to tune for your hardware if you don’t do it yourself. reply nateglims 19 hours agorootparentprevThis move is what business school would suggest. Revenue is declining in their near monopoly position in the market. What's the obvious mistake that fixes that? reply 2OEH8eoCRo0 22 hours agorootparentprevDon't run your own fab? It makes business sense but I don't know if I like that answer. What if everyone did that? Should everyone just use TSMC? That's stupid IMO. reply frognumber 22 hours agorootparentDon't screw up running your own fab is the better lesson. * Intel foundry services were perhaps a decade or two too late. Running a fab needs scale. That had to come before they lost the technology edge. * Intel treatment and mismanagement of engineers was well-known in 2000, and you need the best and brightest. * Leadership needs to understand core business / technology. Bob Swan. Arguably Brian Krzanich. Paul Otellini. Just a lot of clueless at the top. Etc. The point is Intel wasn't \"everyone.\" Intel was at the very top of the game a quarter-century ago. That was their position to lose, which they did in a spectacular fashion. I continue to hope for a Microsoft-style comeback, but it's becoming increasingly unlikely. reply 2OEH8eoCRo0 22 hours agorootparentDon't screw up? Sage advice! I agree they are mismanaged but it also takes luck to stay in the lead. I hope for a comeback too. My amateur worthless opinion is that Intel is struggling now but at least they have fabs. The fabless companies are going to be fucked in the long term- the fabs they contract to are all on shifting geopolitical sands! reply hylaride 22 hours agorootparent\"but it also takes luck to stay in the lead.\" It's not luck if they were riding momentum that slowed because they shifted away from proper R&D. The fabless companies had nothing but R&D to live on and the costs of outsourcing the fab means the capital costs could be amortized over more customers (meaning intel should have probably split in two). Intel's fabs are a generation behind and now they're capital constrained. How do you get back ahead outside of China invading Taiwan? reply WheatMillington 15 hours agorootparent>they shifted away from proper R&D. Can you elaborate on this? reply hylaride 5 hours agorootparentI should elaborate on the word \"proper\" in this context. Intel rarely had the best technology, but it was often \"good enough, cheap enough, and available enough\" to succeed in the marketplace - this is a lesson SO MANY people forget. Sun, DEC, etc arguably had better hardware, but it was expensive. What Intel was very good at was iterating on the technology it had and making it faster within a reasonable budget. Microsoft is another good example of where \"good enough, cheap enough, and available enough\" is what usually matters in the market. Where they started to stumble is when they got greedy. The whole RAMBUS debacle back in the day is a good example of where they took more expensive and worse RAM and tried to make it mandatory. Then there was the whole Itanium debacle, where politics succeeded over engineering and they ended up with a worse, more expensive product that failed in the market. AMD, which had recently acquired a lot of talent from DEC's alpha chip design, then went on and made 64-bit extensions to x86 that Intel had to play catch up to. Intel (for the most part) ignored the performance per watt aspect of CPU design, which mattered in embedded, mobile, and dense datacentre environments. The result is that ARM came from the bottom up and is now eating Intel's lunch from all angles. Intel's fabs couldn't compete with TSMC and to a lesser extent Samsung, both of whom could focus on the intense CAPEX (which due to cultural reasons people in Asian countries are willing to take longer term outlooks). CAPEX looks bad on an american GAAP spreadsheet. TSMC literally could take upfront money from apple to build new state of the art fabs and guarantee them a certain number of chips (and keep the money if the iphone had failed in the market). Intel couldn't do that. Intel spent most of the 2000s era doing $130B in stock buybacks and even if it was run by engineers, they lost sight of the market. Stock buybacks and dividends are fine if you have surplus cash, but chip design is a high CAPEX business. reply AnimalMuppet 3 hours agorootparent> Then there was the whole Itanium debacle, where politics succeeded over engineering and they ended up with a worse, more expensive product that failed in the market. Why do you say Itanium was politics over engineering? It turned out to be a not-really-workable idea, sure. But if you looked at it, not knowing how it was going to work out, it was not an obviously bad idea. It was probably worth trying. (Or are you saying that politics succeeded over engineering in the process of implementation of Itanium? I have no view on that.) reply UncleOxidant 19 hours agorootparentprevSomebody's gotta run fabs. And hopefully some US company can run fabs successfully, otherwise we seem to be kind of screwed. reply mbajkowski 4 hours agorootparentTo get high yields and a reliable process at these process nodes you need high throughout in the fabs, even with sophisticated models and simulations is my guess. At one point in time Intel had high throughput compared to the world via internal demand, which then translated into an advantage for their designs. Internal tools were build around this feedback loop, until that loop was no longer true. The throughput at external fabs far exceeded the throughput at Intel. While external fabs were designed to be used by all, Intel flows and fabs were not. Rather than adjusting to new reality quickly, and competing on design while exposing the fabs to customers, it seems Intel is now struggling mightely on both fronts. reply softfalcon 22 hours agorootparentprevThis is what Boeing did for their manufacturing... look how it's playing out for them now. reply honkycat 17 hours agorootparentprevWe never should have allowed the fabs to leave in the first place. Clearly it is both a security AND economic liability. The US leadership fucked the dog and decided cheap labor was more important than national security or a functioning economy. Everything is gone, it has been shipped overseas. reply electriclove 20 hours agoparentprevBean counters were not the cause of this titanic fail. And at this point, they need to shed their excess weight and find a way to stay relevant. reply Detrytus 22 hours agoparentprevI believe the ambitious plan by Gelsinger to release \"5 nodes in 4 years\", as well as building couple of new factories necessarily resulted in a lot of redundancy and hiring people who were needed for the transition period, but not necessarily long term. Now that they are nearing the completion of Intel 20A and 18A R&D cycle it seems logical point to start cost-cutting. reply softfalcon 22 hours agorootparentOne can only hope. Goodness knows it would be better if Intel were more competitive in this market. Let's cross our fingers that you're right and we see a resurgence after the new fabs come online. reply llmblockchain 15 hours agoprevI live near Intel HQ and I know many Intel employees. Everyone I know has been interviewing at other companies for the last 8-12 months. I haven't met a single person that had a positive thing to say about Intel and its future. reply DaoVeles 13 hours agoparentThey should have never sold the Xscale division. reply urmish 1 hour agorootparentPaul Otellini and Brian Krzanich (both from sales background) have made such strategic mistakes its hard to overstate, combined with the govt office work culture makes it not a great place to work reply hylaride 22 hours agoprevSuspending the dividend is poetic in a sense. They'd been taken over by bean counters decades ago and slowly pissed away their privileged position at the top of computing. They essentially ended up where Boeing did, but at least didn't kill anybody. reply DaoVeles 13 hours agoparentA lesson that has to be taught again and again. You can run a business into the ground but look great for years on inertia alone. Intel has been crumbling for a long while but the inertia of previous decades meant it wasn't apparent. reply danielmarkbruce 13 hours agorootparentThat financials are a very laggy indicator of reality is the lesson that doesn't actually seem to be properly taught. It's even worse in software. The stickiness can make companies look great when they are actually a mess. The cost of acquiring companies can make companies look like money losers when they are actually doing well. Intel has been a mess for a decade at least, an obviously going to zero. But the numbers only started going badly a few years back. reply danielmarkbruce 13 minutes agorootparent*cost of acquiring customers reply kranke155 5 hours agorootparentprevIts incredible how quickly it can happen as well. reply hylaride 4 hours agorootparentIt's exactly the same as the Ernest Hemingway quote about how bankruptcy happens: Slowly, then suddenly. reply Vecr 20 hours agoparentprevMaybe. On Intel's scale almost everything you do wrong kills people, at least statistically. Though, so does everything you do right, but probably less. How many human lifetimes were spent cleaning up and mitigating the microarchitecture vulnerabilities? reply dredmorbius 21 hours agoprevAdditional coverage from: The Register: \"Intel to dump 15 percent of staff to save costs\"CNBC: \"Intel to cut 15% of headcount, reports quarterly guidance miss\"reply StringyBob 22 hours agoprevIntel had over 130,000 employees as of a couple of months ago. 15% layoffs is nearly 20,000 people. reply electriclove 20 hours agoparentThe ‘flagged dead’ comment is right on. Intel has been a bloated bureaucracy for a long time now and things need to get tightened up for it to continue. reply ProllyInfamous 16 hours agorootparentI agree, so I am quoting it, below: >Fire 80% of them. Twitter had probably more talent per capita than Intel. If they can fire 80% most companies should. reply wwtrv 15 hours agorootparent> If they can fire 80% most companies should What's special about \"them\"? Twitter was technically never a particularly complex product that required some kind of exceptional talent. Not even remotely in the same ballpark compared to what Intel is doing (or trying to do anyway...) reply JeremyNT 6 hours agorootparentIndeed there are highly valuable experts at Intel - there have to be, for them to function at all. They're an engineering company making incredibly complex products, unlike Twitter which just sold ads. But there are also likely to be countless \"twitter-like\" employees too, paid to sit on their hands or faff about with branding or tinker with devops parlor tricks or gate access to resources that engineers need. So the current level of cuts passes the \"gut\" check for me. They surely have less \"chaff\" than Twitter, and it's crucial not to accidentally cut too many key personnel in the process. reply AnimalMuppet 3 hours agorootparentThe big difference is that Intel is a manufacturer, not just a web site. They need people on the ground, many of them, in anticontamination suits, 24/7. That changes the \"can we just fire 80% of them\" question by quite a bit. reply michaelmrose 13 hours agorootparentprevTwitter has dropped in value almost 80% since Musk bought it. Twitter is this weird zombie unicorn which keeps attracting money while mostly losing money on net. I don't think its useful to use it as an example. reply johnnyanmac 13 hours agorootparentI'm very surprised people are really taking advice from freaking Twitter for how to handle a silicon hardware company. Also the lack of empathy for fellow developers, but that's a sadly rising sentiment. Crabs in a bucket. The only reason Twitter isn't a dead husk is because network effects are really damn strong. That's it. The attrition to Bluesky or Mastodon or whatever won't be as drastic as the Myspace days when single percentages of the current internet populace were connected. You don't get network effects with hardware, especially since most people these days buy laptops and won't bother to specify an intel chip (if available at all). reply gosub100 2 hours agorootparentprevDropped in value, as in stock price? Sure. Was it ever with that much to begin with? Likely not. reply michaelmrose 2 hours agorootparentDropped in projected value as a company irrespective of the stock which you can't buy now because its private per individuals with large stakes. Their financials tanked as advertisers fled the platform or reduced spend drastically. It's now basically a money pit that at present trajectory will continue to burn money until Elon's other ventures can't afford it. Given his wealth he can keep losing a billion or two a year forever even if people stop buying his overpriced poorly built cars. I predict however that eventually it looks less interesting and they try a rebrand as twitter with 90% less Elon for 2x the advertising dollars (for real this time) and borrow as much money and assets as possible and eventually exit. reply IamLoading 21 hours agoparentprevI am surprised, the stock didnt improve. Typically, markets like layoffs. reply NoPicklez 18 hours agorootparentIt could be because in conjunction with the layoffs Intel are battling with a potential class action against their two latest series of desktop CPU's being faulty reply HDThoreaun 17 hours agorootparentprevIntel had a really crappy quarter, layoffs can’t save that. The market likes when companies that had an ok quarter with revenue growth do layoffs. reply s1artibartfast 14 hours agorootparentIntel has had a bad couple years, posting as many quarterly losses as profits, barely breaking even on net. reply bluedino 22 hours agoprevReducing Operating Expenses: The company will streamline its operations and meaningfully cut spending and headcount, reducing non-GAAP R&D and marketing, general and administrative (MG&A) to approximately $20 billion in 2024 and approximately $17.5 billion in 2025, with further reductions expected in 2026. Intel expects to reduce headcount by greater than 15% with the majority completed by the end of 2024. reply fire-them-all 20 hours agoparentINTC should fire the right people! reply honkycat 17 hours agoprev$152 billion in stock buybacks. We don't have an economy anymore, we are just handing money to the ultra-wealthy. US. Total economic collapse. Hard landing. This is the beginning of the end. We really had the chance to make something beautiful with this country, but the 1% bought and sold it into the ground. Half our politicians aren't even trying to keep it running anymore. reply wwtrv 15 hours agoparentStock buybacks are basically just more flexible dividends. Companies used to payout way more in dividends in the past now they do buybacks instead. reply s1artibartfast 14 hours agoparentprevThey should have done more buybacks so it could be used for something productive. All of the money left in the company is going to be wasted as it rots from the inside. The company didn't die of starvation, it died of obesity. reply ProllyInfamous 16 hours agoparentprevHeck, our politicians are at the point where they're taking their bribes in pure gold (see NJ's recent senatorial shame). A good friend of mine is the son of a former hedgefund manager... who told me in 2018 \"owning real gold is foolish;\" in 2024, he's recently told me about his expanding gold collection. I have made even more returns on silver/BTC, but anything \"real\" is probably durable enough to last for (hopefully at least) another decade of keep kicking the can down the road... Quoting my favorite family member of The Silent Generation (pre WW2 birth), \"Nobody wants to be the last one at the party, because then you have to help clean up all the mess!\" reply johnnyanmac 12 hours agorootparentto make sure I understand this: is this the rich getting ready for the collapse of the USD? reply ProllyInfamous 5 hours agorootparent>getting ready for the collapse of the USD? It's happening, real-time. Yes. All \"trickling up,\" exactly as-designed: into more-durable asset classes, largely unaffordable to Joe American. Just for reference, a troy pound of gold currently trades for around $30,000; whereas in 1970 the same mass was, officially, $420. e.g. Multiple OPEC countries trading oil in non-USD transactions (against policies to only do so, set since early 1970s). e.g. 2020, largest publicly-traded company was a state-run oil extractor (Aramco), worth barely only $2 trillion [two million million dollars]; 2024 (so far) there were THREE $3T+ marketcaps, each a massively-inflated evaluation; bitcoin is more-stable & more-valuable than most tech stocks e.g. #100 publicly-traded asset (by market cap), in 2020, was worth approximately $110B; #100, in 2024, is worth approximately $155B Never forget that Nixon prosmised, just as countless other politicians are trained to do: that this suffering is only TEMPORARY. They're technically not incorrect, when temporal definitions are left undefined. reply shlant 10 hours agoparentprevI hate that I can't tell if this is satire reply toomuchtodo 2 hours agorootparentIf you believe it to be satire, you haven’t been paying attention to the data. reply jaredklewis 13 hours agoparentprevWhy would anyone buy stocks if companies didn't do buybacks or issue dividends? The whole purpose of stocks is to be financially rewarded for investing capital. Like if you just don't like stock markets or capitalism in general, that's fine, but that doesn't have anything to do with stock buybacks. reply honkycat 2 hours agorootparentmy issue with stock buybacks is that clearly corners were cut elsewhere while the company was hollowed out. And they get away with it because Uncle Sam is just going to show up with a new check next year. Same with Boeing. Miserable failure of a company, somehow found room to hand the owners massive amounts of money, meanwhile they have massive quality issues. reply myth_drannon 6 hours agoprevIntel stock is down -24% in pre-market trading. That's going to be a \"fun\" Friday for sure. reply fire-them-all 21 hours agoprev [–] INTC and its subsidiaries should consider a comprehensive reorganization. The company is struggling, and it seems they're making poor decisions regarding staffing and leadership. Mediocre and ineffective leadership persists at all levels, and the business and sales departments are likely contributing to the issues as much as HR. If you want to help turn things around, contact the board members and CEOs directly. Make it clear that they should not receive any compensation until they have successfully revitalized INTC, MBLY, and other related companies. For reference, these are the KPIs for them: INTC's market cap should be currently around $250 billion and MBLY's is about $35 billion. ====================================================== Jensen Huang, please buy INTC!!!! PLEASE BUY IT AND MAKE IT GREAT AGAIN! PLEASE PLEASE PLEASE! reply LarsDu88 14 hours agoparent [–] Nvidia could probably buy a fab off of Intel. As a famous chip exec once said \"Real men build fabs\" However, the secret sauce of Nvidia is simply using TSMC anyways so... reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Intel reported Q2 2024 revenue of $12.8 billion, a 1% decrease year-over-year, with GAAP EPS at $(0.38) and non-GAAP EPS at $0.02.",
      "The company announced a $10 billion cost reduction plan, including a 15% headcount reduction and suspension of dividends starting Q4 2024.",
      "Key milestones include the release of the Intel 18A Process Design Kit and the power-on of new products, with leadership emphasizing actions to improve efficiency and profitability."
    ],
    "commentSummary": [
      "Intel's recent financial report has raised concerns about the company's strategy, particularly its focus on cost-cutting over addressing core issues like processor competitiveness.",
      "Despite a 15% reduction in headcount, Intel still has a larger workforce compared to its competitors, and critics argue that the leadership has been misaligned for years.",
      "New CEO Pat Gelsinger is implementing changes, but the company faces challenges with its latest CPU series and potential class action lawsuits, leading to internal dissatisfaction and employees seeking opportunities elsewhere."
    ],
    "points": 113,
    "commentCount": 106,
    "retryCount": 0,
    "time": 1722543139
  }
]
