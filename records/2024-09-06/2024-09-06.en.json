[
  {
    "id": 41461499,
    "title": "Burnout is bad to your brain, take care",
    "originLink": "https://news.ycombinator.com/item?id=41461499",
    "originBody": "I am depressed and burned out for quite some time already, unfortunately my brain still couldn&#x27;t recover from it.If I summarize the impact of burnout to my brain:- Before: I could learn things pretty quickly, come up with solutions to the problems, even be able to see common patterns and see bigger underlying problems- After: can&#x27;t learn, can&#x27;t work, can&#x27;t remember, can&#x27;t see solutions for trivial problems (e.g. if your shirt is wet, you can change it, but I stare at it thinking when it is going to get dried up)Take care of your mental health",
    "commentLink": "https://news.ycombinator.com/item?id=41461499",
    "commentBody": "Burnout is bad to your brain, take care612 points by tuyguntn 19 hours agohidepastfavorite260 comments I am depressed and burned out for quite some time already, unfortunately my brain still couldn't recover from it. If I summarize the impact of burnout to my brain: - Before: I could learn things pretty quickly, come up with solutions to the problems, even be able to see common patterns and see bigger underlying problems - After: can't learn, can't work, can't remember, can't see solutions for trivial problems (e.g. if your shirt is wet, you can change it, but I stare at it thinking when it is going to get dried up) Take care of your mental health burningChrome 18 hours agoEarly on in my career (I was a late bloomer and already in early 30's) as a developer, I got burnt out pretty bad twice. After the second time and teetering on a third, I knew I had to do something to change what I was doing and how I managed my work load. I just focused on getting MY stuff done and that was it. I stopped taking on other's people work. I stopped taking on more work once I got my stuff done. I would do exactly what a Sprint called for. Nothing more, nothing less. If I finished early with my tasks, I would stretch out the time and just tell the scrum master I was close, but not done yet, but always finished on time. I basically just did what was required of me. I wasn't out to impress anybody, I just became \"Mr. Dependable\" on any of the teams I worked on. This was the approach that changed everything. Now, some ten years later? I'm never too high or too low. I still do the same thing, I still just do what is asked of me and that's it. 5pm every night? Laptop gets turned off. Friday at 6pm? Laptop is off for the entire weekend. I turn it back on right before my meetings on Monday. Separating my personal life from my work life with a hard delimiter was paramount. I found out that if you don't protect your sanity and your own well being, people will take advantage of you and your time and it will never end. Once you break the cycle and get that time back for yourself? You'll make sure you never willingly give it to someone else ever again. Protect yourself. Protect your sanity. Once you lose it, like OP said, it's very, very hard to get back. I hope this helps someone else struggling to break this cycle. reply kody 17 hours agoparentI'm really curious, how do you factor in time to learn (\"up skill\")? I'm a self taught dev with 2 young kids. I've always had a healthy approach to work, but now I'm feeling quite a lot of pressure to learn new things on my own time, whether to make sure I'm prepared for the interview circuit if I get laid off, or to patch my skills that are needed at work. I'm starting to feel burnout creep in, getting an hour of study in the morning, taking care of family, and then working 8 hours. I appreciate your insight. reply Baeocystin 17 hours agorootparentYou do it during work hours. Period. Your brain only has so many truly 'on' hours in a day, and it's already less than 8. Trying to burn even more in the pursuit of complex knowledge isn't just robbing Peter to pay Paul, it's eating the seed corn and wondering why your harvest failed. It's a scary thing to realize, and can be hard to stick with. But limits are real, and respecting them gets more work done in the long run than not. reply livearchivist 16 hours agorootparent100% This is so important. I have a 3yo and wife, I currently work for a series-A startup - It's incredibly easy to do things out of hours, answer messages, train, lab things up, etc... But at the end of the day that is a part of my career. So except for when I'm traveling for work, I don't do a GD thing past 5pm, unless i choose to. When I choose to, it's likely because a lot of my team is in IST time zone rather than EST. When you're a family person, your job is to be there for yourself first, your family second, your other commitments after that. I have a weekly 4:30p friday call. Would i rather have that at 1:30p? Yes. But i've chosen to work remotely in Ohio instead of move to Cali like the last four companies have asked. So I take that friday 4:30p call. But you better believe that i check out until monday after that. During the week I'll take odd hour calls for my counter-parts in IST, but that's nearly entirely out of courtesy than necessity. Take care of things in the following order: 1. You, as a human, holistically 2. Your family, spouse first, kids second 3. Your work 4. Everything else It's reduced a huge portion of stress from my life by doing this. reply jaredhallen 15 hours agorootparentYou've said it twice, and I'll reiterate it a third time. Your own well being has to come first. You can't deliver on the rest of your commitments if you neglect your own needs. Being a martyr does not serve those who depend on you. reply antimemetics 12 hours agorootparentIf you can’t love yourself how are you going to love someone else? reply sandeep1998 14 hours agorootparentprevI am trying to move to a country where this is a reality... I just need a life outside of work (and some quiet and peace and fewer people around me all the time) I want to be able to sit down in the park, stroll around the neighbourhood, ride cycle, swim, cook, etc without the worry of job looming over my head all the time. I want to live for myself. reply pnut 9 hours agorootparentI say this as a person who emigrated away from the US in my late 30's... The hedonic treadmill exists in all countries, stepping off it is a personal priority and discipline regardless of where you live. reply ddingus 14 hours agorootparentprevVery high value, lucid advice. My experiences were similar, however I must add when your day job is not related to skill building activities, you may find your \"on\" time to be greater. Still, be careful. In my case, my day job was manufacturing and I was an effective prototype mechanic. Loved the work, hated the pay, so... I used a percentage of my free time learning more computer related things. When the time was right, I was ready to take the jump. Landed nicely, and have no regrets. Now, later in life I find the dynamics above are in play and we all ignore them at our peril. reply beaglesss 16 hours agorootparentprevAll hours spent with kids under 5 is basically 'on'. Which would leave most mothers I've met at zero 'on hours' left for work. A reason for the 'gender pay gap'? reply BobaFloutist 2 hours agorootparentChildcare is skilled, necessary labor, and should be subsidized by the government at the level that food production is. Maternity leave and paternity leave in the United States are also woefully insufficient. reply nunez 16 hours agorootparentprevnext [17 more] [flagged] JamesBarney 11 hours agorootparentMost of the research actually supports what op says. When you adjust for industry and such the vast majority of the remaining gap is due to motherhood. So much so that many researchers in the field call it the motherhood pay gap as opposed to the gender pay gap. Childless women make about the same as men (within 2-3%, some show higher, some lower). Now is the fact women take over the majority of the childcare and are more likely to take off to raise their children misogyny? Depends on your definition and perspective. reply nunez 5 hours agorootparent> Now is the fact women take over the majority of the childcare and are more likely to take off to raise their children misogyny? Depends on your definition and perspective Yes, given that: - In conservative circles, there is a strong expectation that a woman's chief job is to be a mom, - Many businesses are lead by conservatives, and - Many states (at present) are run by conservatives and enact policy to make this so (anti-abortion laws being the biggest example) Regardless, whether women want to enter motherhood or not should be irrelevant when determining employee compensation. Many of us developers justify our sky-high compensation packages in today's remote-first working culture by the \"value\" that we provide relative to the profit margins produced by our work. If this is true, then this should apply equally apply to working moms since them being moms doesn't take away from the value they bring to the table. Moms don't stop being great programmers once they bring children into this world! However, if we're going to use _availability_ as a compensation-affecting performance metric, then dads should also be paid less since, in an ideal world, they are just as involved in parenting as moms are. Given that being paid less due to being a parent is de facto illegal in the US, then I think that any argument for suppressing women's wages is either uninformed or in bad faith. (As an aside, we don't and won't have kids, but I am a huge advocate for equal-length parental leave; nobody is at their best when they're working on two hours of sleep because the baby's always crying through the night.) reply room4 1 hour agorootparentprevFrom the HN guidelines: Eschew flamebait. Avoid generic tangents. Omit internet tropes. Please don't use Hacker News for political or ideological battle. That tramples curiosity. reply hunterrrrrr 15 hours agorootparentprevCompletely agree. And it’s just one more creepy weird thing that companies allow to be normalized. If you refuse to work in these conditions, you’re “burnt out” or you’re “a bad fit” or whatever other bizarre messaging folks want to astroturf on social media hangouts. reply huijzer 14 hours agorootparentprevYes! And Christianity to this day is still very and subtly misogynistic. For example, why does a woman need to give up her last name when marrying? reply zxexz 13 hours agorootparentNot arguing that Christianity and other religions aren't misogynistic - I mean, seriously, there is a borderline unfathomable amount of serious misogynistic baggage there. However, on the point of last names, I feel the urge to point out that I personally know several, very devout and traditional, catholic couples who kept their last names in wedlock. reply rpastuszak 9 hours agorootparentWe have records of patronymics as old as the writing itself. It's hard / impossible / pointless to decouple religion from culture though. On a slightly different note: Hammurabi's name means literally \"his uncle is a healer\" (related to Arabic عم (ʕamm) meaning paternal uncle, and the latter part to rabbi). I my mind there's a mildly funny* movie where Hammurabi, the person who created/codified the foundations of our law, someone remembered for 1000s of years... was an insecure overachiever. \"You conquered the Elamites? And Larsa? Oh, that's cute my boy. Now get a real job like your uncle who is a doctor!\" * (for me, my bar is low) reply Earw0rm 12 hours agorootparentprevYep, look at the Spanish naming system for example. It doesn't get much more Catholic than that, but they combine both partners' family names. reply chopsuey5540 11 hours agorootparentSure, but traditionally only the man’s name gets passed down to children reply mejutoco 6 hours agorootparentprevThere are places with a Christian tradition where that is not the case. For instance, Spain. reply badpun 10 hours agorootparentprevHow’s that related to Christianity? reply acdha 6 hours agorootparentIt’s not a strict requirement but it was part of the culture when the Bible was written, and fits with the general hierarchy which is specified in various scriptures – the most common justification cited is in Ephesians where there’s an injunction for wives to be submissive to their husbands. Coupled with the way the Bible assumes the traditions of the time (e.g. sons taking their father’s name, the patriarchal line of inheritance, etc.) it’s common to many Christian cultural traditions even though there are exceptions. reply badpun 5 hours agorootparentIt was part of our culture before Christianity emerged, it remained part of the culture afterwards. Seems like Christianity didn’t have much to do with it. reply acdha 3 hours agorootparentIt wasn’t “our” culture unless you still live in the Bronze Age but I’d think of it more as a historical artifact which was preserved in part due to reinforcement based on that religious text. If Christianity did not give that text special significance you wouldn’t have millions of people saying they _must_ continue the practice. reply badpun 2 hours agorootparentCulture is a continuity that builds upon the past - in that sense it's our culture. Also, I've never ever heard anyone say that wives need to take names of their husbands, because the Bible says so. Is that an American thing? reply acdha 53 minutes agorootparent> Culture is a continuity that builds upon the past - in that sense it's our culture Cultures share history but the whole point is that they’re not continuous. You specified the pre-Christian era, and there have been many significant changes since then which any common definition of the term would consider discrete boundaries. > Also, I've never ever heard anyone say that wives need to take names of their husbands, because the Bible says so. Is that an American thing? It’s not specific to the US but there are certainly American churches which have strong opinions on this point. One thing to remember is that these things aren’t just the literal text of the scriptures in whatever version of the Bible they use but also the collection of interpretation and custom around it, and people have a history of interpreting scriptural text differently based on a position which they want to support. reply brailsafe 2 hours agorootparentprevI'd agree with what others have answered (do it on company time if it's company related), but although I don't have kids, I've burnt out quite badly 2 or 3 times. Apathy is the scar tissue you get from burnout, it's helpful in avoiding it after recovery, but it's best if you don't include your family in that. If possible (probably if you try hard enough) I'd suggest separating the things you want or feel you should learn into the things you're learning for yourself and things you're learning for your job, and then allocate a deliberate day or significant block to just that. Ask for help from your family if possible in letting you occasionally just isolate and immerse. Jon Carmack does this, and although I'm just an average guy or w/e, I've found it to be the only way to give hard subjects the attention they actually require. For example, the Nand2Tetris project, Swift programming, Postgres, they really take some tinkering time and deliberate practice. Nothing super valuable comes from passively digesting podcasts while driving imo either, or walking down the street, or buying groceries, so take those airpods out if you're doing it, and let your brain take a break in those moments. reply parpfish 17 hours agorootparentprevIf you’re learning a thing that you actually do for your job (eg, new language or tech), do the studying and training during work hours reply Bayko 17 hours agorootparentprevUnfortunately when it comes to preparing for interview leetcode is pretty much required at all stages. For that the way that works for me is to never let go of it. I will solve 2 3 problems over a week even when I have a job. That downtime at work when you are at home or waiting for the next meeting...just leetcode. I absolutely hate LC and hate the fact that it is omnipresent but now no longer fear it. Except Dynamic programming. That thing can go f*ck itself. But ya now when it comes to LC I am \"always\" or rather one week away from interview ready. reply kody 16 hours agorootparentFunny enough I had an interview today with a dynamic programming whiteboard problem. I feel like if I hadn't been putting in my leetcode hours I would have totally bombed reply AnimalMuppet 17 hours agorootparentprev> Unfortunately when it comes to preparing for interview leetcode is pretty much required at all stages. I have never had a leetcode-style interview in 40 years. (I may have had one such question, maybe - hard to remember for sure.) So, no, it is not required at all stages. Disclaimer: I'm in embedded systems, which is very different from FAANG. reply giantg2 17 hours agorootparentFunny enough, I just had my first LeetCode question ever... for an internal job posting. Wtf reply toomuchtodo 15 hours agorootparentThat is dystopian level hilarious. reply giantg2 14 hours agorootparentWe normally do minor fizz buzz code screens internally. But that's just a small test to see how much of the tech you know, like if you were switching from say Python Lambdas to Angular front-end. And it's mostly to see about how you approach the problem. But some of the internal postions do it differently. My favorite was a mock code review on a PR that had intentional flaws. Then you'd call put what was wrong and how to fix it - not just pure code but also requirements, tests, commit messages, etc. LeetCode is different though. The rating and stuff. Even the interface... I still don't know what it's doing behind the scenes to run the code and feed inputs and what those inputs are. Believe it or not, this LeetCode interview wasn't my worst internal code screen. I once had one that HR said to bring my laptop and use any language I wanted. When I got there, the manager handed me a Mac (which I've never used), told me to use Angular to create a page with a table (hadn't used Angular at that point), and told me to do it in Webstorm (most teams were still using Eclipse at that time, so no experience here either). I managed to Google my way to a working table, but cut the interview short when he wanted me to style it. It's and internal posting. I clearly know the basics and got something working, even in the worst possible interview scenario where I didn't know the tools at all. Surely I can learn the rest (this was a midlevel posting, not even senior). reply charles_f 4 hours agorootparentprevInteresting, I had the same thing a few years ago while interviewing internally for a manager position, and from a VP reply dheera 14 hours agorootparentprevCan't they just look at your code commit history ... reply hirvi74 13 minutes agorootparentBut then where is the opportunity for ego stroking? reply giantg2 6 hours agorootparentprevThey absolutely could. On the opposite side, I usually skip teams for their repo so I can review them. Are there test cases built out? Do they have east to follow code design, or descriptive comments? Do they have a normal level of abstraction, or are there multiple layers of interfaces for not real reason? I recently declined a position because the team was building a UI, didn't have a CMS, didn't have any real rests, and the code looked like a bit of a mess. It didn't help that the languages (Go, React) were completely new to me, so I wouldn't be able to make an impact on improving these issues. reply parpfish 17 hours agorootparentprevI’ve run into a leetcode once over the course of five job hunts. There’s always some sort of screener that may use a leetcode style interface, but the problem is something like fizzbuzz/write a function to say if a number is prime/etc. The interview is about finding the obvious resume frauds and seeing if they can communicate their problem solving process, not finding a genius that’ll invent new algorithms reply SoftTalker 17 hours agorootparentprevAlso never interviewed at FAANG and never been asked to write code in an interview reply swatcoder 17 hours agorootparentI'm with you and the GP, but I suspect all three of us have pursued a balanced and satisfying career instead of the one with top of market compensation. Some of the folks here don't see alternative options when FAANG compensation is some integer multiple of what the rest of the industry has been supporting for the last 40+ years, and I don't entirely blame them for that. I'm not surprised when some later find themselves miserable and feel like they're trapped by golden handcuffs and insufferable bureaucracy, but I understand how they got there. reply SoftTalker 16 hours agorootparentYes, I’ve been in tech for 30+ years and just recently broke 6 figures in salary. But I live where a nice house is under $300K and I take satisfaction in living frugally. reply copperx 16 hours agorootparentThat's interesting. What's your line of work? reply SoftTalker 1 hour agorootparentWebdev in various stacks, database design, programming and administration, linux administration. Mostly in higher ed with a few forays into short-lived startups. reply batshit_beaver 16 hours agorootparentprevAs someone currently in the process of trying to move from a cushy, interesting startup job to a soulless FAANG for that compensation multiple, the ONLY reason I'm doing it is because I have a young kid now. I wish there was another way, but it is genuinely impossible to provide a comfortable level of family life on a startup salary, unless your partner is also in tech and is ok with not being a stay at home parent. reply sadcherry 14 hours agorootparent> I wish there was another way, but it is genuinely impossible to provide a comfortable level of family life It's all a matter of perspective, isn't it? It's basically the top 1% speaking. And you can't tell me that the other 99% have miserable lives. > unless your partner is also in tech and is ok with not being a stay at home parent. Stay at home parent is a choice, and a pretty expensive one. One does not have to choose that and can still live a comfortable life. Many women (and let's face it, we're unlikely discussing the man staying at home for the next 7-15 years, eh?) even prefer not to interrupt and/or basically end their careers because of parenthood. Americans often look to Europe, claiming that these things are so much easier there, which might be true, but at least as much is it a matter of personal choice as well. reply eropple 16 hours agorootparentprevThere are other companies, too. I work at, statistically speaking, Your Phone Company, and they don't pay FAANG money but they certainly pay a lot better than I was doing at startups. Caveat: I don't live in the Bay Area, though the Boston area isn't exactly cheap. reply toomuchtodo 15 hours agorootparentI hope it’s a great experience there, have friends in the risk/cyber areas and have heard nothing but good things. reply eropple 18 minutes agorootparentThanks! It's an interesting place, and I think the technical quality depends pretty heavily on what org you're in. But the quality-of-life is very high and I'm mostly enjoying myself. quern 14 hours agorootparentprevI did the same for the same reason , but I moved from a soulless FAANG to a high frequency trading company. This is another integer multiple. To my pleasant surprise, the HFT is more rewarding (not just in comp) than the FAANG was. At least for now, or that's what I keep telling myself. reply dheera 14 hours agorootparentprevThe weird thing is I've gotten everything from no code to entry level to ultra-hard coding questions in FAANG-level interviews. I also have a hunch I've gotten easier coding questions when an existing team member referred me to hiring for their own team. reply rramadass 12 hours agorootparentprevAdvice from another thread : https://news.ycombinator.com/item?id=41462980 reply croshan 17 hours agoparentprevThis sounds depressing. I’m sorry that you had that experience. It’s a frustrating position to be in, and you can feel quite helpless. In my experience, it’s less about “do only what’s asked”, and rather “say no”. I.e. explain “I can do X, but if I do that then Y will suffer, and Y is a priority”. (Y being another company priority, or even your own mental health). Stated in these terms, it’s easier to negotiate your time with your coworkers. reply pjerem 16 hours agorootparentThing is that may not depend on you. I did this but I was surrounded by coworkers who were stupidly running straight into burnout themselves and said yes to anything. Well, upper management felt I wasn’t doing enough in comparison and pressured/harassed me. Ultimately, I were the first to burn out. Of course, in hindsight, I should have left way before it happened, but when you are in, you have no hindsight. Sometimes you can’t grab the surrounding toxicity before being hurt. reply culi 17 hours agoparentprevThis feels impossible for someone who is early career. How could you balance growth with this? You could say \"if your job isn't providing you with opportunities to grow, look for a new job or talk to your manager\". But that takes extra time as well. You need to work on portfolio/side projects with in-demand skills you don't currently use, talk to managers, apply to jobs, network, read, etc. reply mrmetanoia 3 hours agoparentprevYou really do have to protect yourself. I think at some point I felt like if I set boundaries I'd get fired, then I realized if I didn't set boundaries I'd go insane which seemed worse than fired so I started telling people \"no,\" and logging off on time. It's been an improvement. \"Will the fight for our sanity, be the fight of our lives?\" - flaming lips reply paulcole 1 hour agorootparent> You really do have to protect yourself I don’t know why this is a revelation to so many people. Who cares about you more than you do? Nobody — especially not anybody at work. reply crossroadsguy 4 hours agoparentprevI have a slightly different aspect (as I was the complete opposite of that) of this from my life - but it's not a disagreement. So I have always had such a nice (some would say epic) work-life balance as far as \"hours\" and \"availability\" go. After a (forced) break from work, and exploring health related help professionally, I came to know I was clearly burnt out. I was told high number of \"hours\" working or \"visible or quantifiable work load\" don't necessarily have to be present for a burn out. There are other factors at work which cause stress/etc and they are often more insidious than the typical \"load\" (not to reduce the ill effect of the typical load^). And were those signs abundant in my life and work! It was quite shocking. I always used to think that with my kind of work-life balance at least burn out was never going to be a problem. ^ It was added by them - those typical load/etc almost always cause mental health damage so I should not consider them okay all. reply ahaferburg 1 hour agorootparentYour comment is very vague to the point of not containing any information. I would sum it up as \"there are factors other than hours spent when it comes to burnout\". What are those factors? reply setopt 12 hours agoparentprev> Laptop is off for the entire weekend. I turn it back on right before my meetings on Monday. Separating my personal life from my work life with a hard delimiter was paramount. That sounds like a good philosophy for work-life balance. I sometimes work evenings or weekends, but it might be a bit different since I don’t work at a company but at a university, so my work hours are a bit flexible. I have had burnout before, especially during Covid home office. A big improvement for me was: - Regardless what’s going on, have at least one day per week when I don’t work at all (usually Saturday) and never pull all-nighters (no work after midnight); - Stop syncing work email to any mobile devices, and close the mail app on my laptop outside standard working hours. (This does wonders for destressing.) - Track the amount of time you “try to work” (e.g. how long you have your work laptop open). Note that this is not the same as tracking e.g. “focus hours”. Keep an eye on it and don’t let it accumulate too much per week. reply BossingAround 11 hours agorootparent> Regardless what’s going on, have at least one day per week when I don’t work at all (usually Saturday) and never pull all-nighters (no work after midnight); Why are you working during the weekend and after work hours? reply rawbot 11 hours agoparentprev> I just focused on getting MY stuff done and that was it. I stopped taking on other's people work... I would do exactly what a Sprint called for... This is my reason for burnout, opposite of your example. There's a thin balance doing more work because you enjoy, and doing it because managers are pushing you to do it. And now that I JUST do my job and what I'm asked to do, I have lost a lot of the drive that I loved about being a developer and engineer, making life kind of dull. Weird thing is that it is the job description that put me into this place, with no room for growth, and the search for new jobs has been dry, year after year of searching. I traded my sanity for a big chunk of my life's enjoyment. That ain't great either. reply BigJono 10 hours agorootparentMy theory is burnout comes from a lack of autonomy. If your \"do the minimum\" is having complete control over a module and implementing features as slow as you can without pissing anyone off too much, you're going to have a great time. If your \"do the minimum\" is picking up the bare minimum number of Jira cards in a sunshine and roses \"teamwork makes the dream work\" team where everyone is responsible for every line of code but nobody knows more than 5% of the codebase, your mental health is going to go straight down the toilet, because nothing is more stressful than working with over-complicated code you didn't write, and the less cards you pick up, the less code you're going to understand. reply gwathk 16 hours agoparentprevThanks for sharing and really appreciate the \"break the cycle\" mindset. A lot of people feeling stuck is holding on \"strong work-ethics\" as their identity, but it is an endless cycle and you are going to lose as you age. And your sanity is only yours to keep, protect it at all cost. reply parpfish 18 hours agoparentprevIt’s worth pointing out that the people you need to protect yourself from aren’t necessarily doing anything malicious — they just don’t know your limits and will keep feeding you work as long as you keep saying yes. It was a revelation for me when I realized I could tell people “no, I’m swamped right now” and they’d be “ok, no problem” reply shortrounddev2 1 hour agoparentprev> I stopped taking on more work once I got my stuff done. I would do exactly what a Sprint called for. Nothing more, nothing less. If I finished early with my tasks, I would stretch out the time and just tell the scrum master I was close, but not done yet, but always finished on time. A PM at my company told me a few weeks ago \"if you finish your work early, we can always find other things for you to work on\" and I told him \"you understand that my incentive is not to do that, right? If working faster only gives me more work to do, then why would I work faster?\" He told me that fast workers are repaid with bonuses, promotions, etc., but I don't think most people believe in that kind of upward mobility anymore. I certainly don't reply mverv 15 hours agoparentprevAny words of encouragement to a 32 year old considering a career switch to software development? I have a CS undegrad and have been working in the industry, although in strategy roles and never as a developer. reply manuel_w 11 hours agorootparentWhere do you live? I transitioned to software development in the age of ~30 and am based in Austria, Europe. The way I did is was to work on a project in my free time, and use that to a) LEARN, b) demonstrate that I can aquire skills myself and c) can stay motivated and push through. I wanted to show that I'm worth being given a chance. It worked flawlessly, I got hired on the first try. Just try it, what's the worst that can happen? :) I've got the feeling good software engineers are a bit more rare here, though, and Whiteboard interviews are not a common thing either. reply dclowd9901 14 hours agoparentprevYou might as well be narrating my own experience. This is the definition of work life balance. reply brainless 13 hours agoprevGiving you a big hug. I have been through really rough periods and as my health took a big toll, the only means I had to recovery was to move away from crazy startup life. Gradually I understood that, maybe, there is a better balance. I still want to learn, grow, solve problems, dream big. Instead of making 3 year plans, I started making 10 year plans. I started taking care of my health, like it is the most important thing. I unplugged for a couple years, lived in cheap places to lower my financial burden. Now I live in a small village, have built a work routine that has no deadlines and I am happy, very happy. I have a hostel I run here, I write software I love, I am planning a product. I just setup a camping spot, it is lush green around here, a slow and simple life (all shops close at 20:00 for example). I sacrificed those magazine cover dreams but in return I got a wonderful life and I am building again, just at 0.5x speed. I hesitate to think about accelerators like YC. I know I will panic so much when it comes to all those metrics, money and everything else I cannot process anymore. But that is OK. reply anonzzzies 9 hours agoparentI did roughly the same thing; I live in a small village in protected nature. I still run startups, but I sit at my stream in my forest working for them. Life is cheap here so I was able to buy a house and the land; when I feel overwhelmed, I can just throw my laptop and phone out and live out my life tinkering in the house, the land and on hardware. But since I moved (long ago) I haven't had that feeling again. reply vinc 7 hours agorootparentSame thing here. I bought a little piece of land with an old farm to renovate 7 years ago. The house is right next to a large forest, it was built 175 years ago when this area was cleared, and now I'm letting the forest come back to the parts I'm not using. I watch the small trees grow up, it's peaceful. I charge my laptop with a solar panel and got just enough mobile connectivity to be able to work efficiently. I still got burn out at my last job because I let the pressure got me. Now I'm recovering while coding small projects and I hope that I'll find a better balance in the next job, or maybe one of my projects will take off. reply yukimura 12 hours agoparentprevyour life is pretty good. reply IamTC 17 hours agoprevFrom my own experience of burning out and getting out of it: Mechanics: it seems easier to get in to burn out but far far longer to get out of. I know what I wanted to do but could not bring myself to do it. Though not always, gut health (or the lack of it. My burn out coincided with my IBD episode) could be an early symptom to back off the throttle a bit. Subjective: I've learnt to remember that look on someone face who's heading down burn out wall. In long distance cycling, in order to not 'bonk', you must fuel and hydrate sufficiently and consistently over time. With burn out, I feel the same dynamics apply, but with different 'fuel' and 'hydration'. And every person is so different that the rate of replenishment needed should and have a wide variance. What really helped me get out was, ironically COVID, when I couldn't do anything about my startup and I had to stop it and rest. The bleeding with my IBD just went away during the peak of lockdowns. Started to build and buy stuff, for leisure, that I enjoyed and had postponed away in my hustling years. On hope: The human body and brain has a remarkable capability to recover and heal itself. But one does need to give it the right input: hanging out with wholesome or wise people, exercise, eating well, getting medical intervention when needed etc. reply xupybd 17 hours agoparentI have a similar story. Burnt out and thought my brain was cooked. Then I got my sleep apnea sorted. Then found out I had celiac (the apnea might be related). Getting that all sorted is like an insane nootropic. I'm smart again and can work real fast. reply gk1 18 hours agoprevFor me the critical moment was recognizing I had burnout. It happened when I saw this post on HN, whose list of symptoms almost perfectly matched what I was feeling: https://yaledailynews.com/blog/2022/03/29/how-people-fall-ap... I’ve obviously heard of burnout and experienced it before, yet somehow I failed to recognize what was happening until then. So thank you for posting this. Hopefully it’ll help someone out there realize they’re burned out and start addressing it. reply LeftHandPath 18 hours agoparent> Rego emphasized the need to lean into life “with your hands, senses and via others.” To allow the prefrontal cortex to rest, he suggested doing hands-on activities, such as arts and cooking, and indulging the senses — especially in nature — and talking to people often. In my hardest semester at college, I wound up spending a somewhat unreasonable amount of time in nature. I would walk 3-5 miles a day and up to 20 miles on the weekend. I had a wetlands preserve across the street (well, highway) from my apartment, and a great state park about 10 minutes away. My workouts got more intense as I was more stressed as well. It all seemed to balance out and I've been trying to get back to that sort of balance of activities since I graduated. reply cpeterso 12 hours agorootparentStudies of ecotherapy support your experience: https://www.healthline.com/health/mental-health/ecotherapy reply Carrok 15 hours agoparentprevThis article really hit home for me as well. But this sentence leaves me in possibly more distress than before reading the article. > The Cornell study found that after a month of reduced stress, these effects disappeared. I do not believe I will ever be able to experience “a month of reduced stress” until the day I die. But maybe that’s just the burnout talking. reply olyjohn 2 hours agorootparentI am burnt out from work currently and am in the recovery process now. I told my work I was taking a leave of absence, and used my short term disability insurance to be able to afford the time off. If your company or state offers it, please take it. I am protected by FMLA laws so they can't lay me off while I'm gone. My therapist recommends that I stay out of work up to 3 months. I'm on week 2 and it's already taken a huge weight off of me. reply mizzao 17 hours agoprevI experienced several episodes of what I thought was burnout (from all the symptoms often described), but in retrospect were periodic recurring depressions from type 2 bipolar disorder, triggered by stress. PSA for anyone who might have the same situation — if you've experienced anything that resembles hypomania this may be worth investigating. The average time from first bipolar depression to diagnosis is 10 years, and I mistook several depressions for burnout while doing plenty of damage to my career and personal life during that time. This is one of the best books on the topic: https://www.amazon.com/Depressed-Recognizing-Managing-Bipola... reply sneed_chucker 15 hours agoparentDid reading the book help you? Did you seek treatment? reply mizzao 15 hours agorootparentI read many many books, re-read my personal journals, and basically had self-diagnosed by the time I spoke with a psychiatrist, who agreed with my assessment upon presenting the evidence. The huge challenge with diagnosing type 2 BPD is that it basically needs a historical time series of data to be detected properly, so either you or someone close to you needs that data. It's believed to be a lot more prevalent in the population than officially diagnosed, which sucks because it results in consistent, increasing depressions that don't respond to treatments for \"unipolar\" depression (major depressive disorder), which are actually dangerous as they can trigger mania. I was lucky that the first medication I found worked really well with no side effects, and I basically went from \"random 3-6 month depressions every 1-2 years\" to \"normal person\", which removed a huge debuff, in video game terms. reply RomanPushkin 13 hours agoprevI've been dealing with burnout multiplied by cancer in the family. My spouse was diagnosed back in 2020. It was tough and unmanageable until I got back to P.Cubensis and started microdosing it just to stay alive. I didn't go to stratosphere, and not a fan of a mAcrodose. But mIcrodose helped me to rewire my brain. Can't recommend it enough. Don't do P.Cubensis though, since P.Natalensis is the better, easier choice in all aspects. Also, dried Amanita Muscaria does a great thing - you're probably just one dried (!) 10cm cap away from getting back on rails. And no, you won't have a \"trip\" from it. I'm not talking about \"trips\", euphoria, etc. I'm talking about saving your life instead of wasting one. I've learnt the hard way that there are protocols from getting back on your feet from the shittiest shit in your life. There are communities of people with MUCH SEVERE problems. It's also in books, read \"PSYCHEDELIC OUTLAWS: The Movement Revolutionizing Modern Medicine\" by Joanna Kempner. (there is also audiobook). There are communities, really really good communities that will help you to get back on your feet again, quickly, no b/s (I'm a bit hesitant to share the links, but you can always reach out). This really works, verified. If you're suicidal, call 988. Also, I can send you a link to a protocol that helped many people with a very good reviews. I discovered it by accident, and there is a community of people who implemented that. Once you have all the things, the help is so quick, in a week you gonna enjoy life again. reply concerndc1tizen 9 hours agoparentI've met several Americans who are into self-medicating like this. One guy was talking about his 500k USD salary at Facebook, so clearly successful, while obsessing about where to source drugs, so clearly struggling. Have you considered that there may be permanent changes to your brain, that you're not able to perceive, similar to the radical shift in personality we've observed in Elon Musk? reply pcthrowaway 9 hours agorootparent> Have you considered that there may be permanent changes to your brain, that you're not able to perceive, similar to the radical shift in personality we've observed in Elon Musk? I think people undergo permanent changes to their brain that they can't perceive, all the time. Hacker News and other social media definitely change your brain. So does having more wealth than you can conceivably spend in lifetime. I suspect the latter is more directly responsible for Elon Musk's trash personality than microdosing. While I am a strong advocate for legalizing hallucinogens and empathogens, and am certain there are clinical uses for at least some of them which we are in the early days of understanding, I'm not as convinced by the science on microdosing (which specifically refers to sub-perceptual doses). But with so many people who seem to benefit from it, I support people who find it helpful doing so, even if it's just placebo effect. reply arnejenssen 12 hours agoprevA recent study from Sweden: https://uu.diva-portal.org/smash/record.jsf?pid=diva2%3A1851... The traditional approach of treating burnout primarily through rest and recovery is overly simplistic and may not address the root causes of burnout. Newer models, such as Acceptance Commitment Therapy (ACT), suggest that addressing psychological and existential needs, rather than just biological ones, can lead to more effective recovery. Burnout treatment should not only focus on rest but also on helping individuals reconnect with what gives their life meaning, addressing feelings of fear, shame, and high self-demands, to achieve a more comprehensive and lasting recovery. reply ethanol-brain 3 hours agoprevI have burned out at least 10 times in my career. The last time, it was like I lost half a decade, even though it didn't last quite that long. It was as if I had amnesia. I fell into a deep depression. I considered killing myself just because everything seemed so difficult and pointless. Give yourself some more time. You might not emerge exactly as who you remember, but its possible to mostly recover from the pretty extreme cognitive impairment that you are likely struggling through. reply mrmetanoia 3 hours agoparentIt really is a difficult thing to heal and a difficult thing to know when you've healed. Same with grief. And you're right it takes - relative to our lifespan - a rather long time to start to see yourself again. reply paxys 17 hours agoprevAlso important to note – a lot of people correlate burnout strictly with overwork. You could be burned out due to overwork, sure, but you could also be burned out due to not having enough work. Or doing an average amount of work but not finding real meaning in it. Or another reason not directly related to work at all. If you aren't 100% happy with your situation, and not getting out of bed every morning with a smile on your face, do your best to address it before things get really bad. reply rakejake 14 hours agoparentYes, this is called \"boreout\". https://en.wikipedia.org/wiki/Boreout reply okwhateverdude 2 hours agorootparentTIL. Like, this is the majority of the jobs I've had in the last 20 years. A bit mind blowing that this concept has been written about and studied. reply cm2012 15 hours agoparentprevDo people really go to work with a smile on their face? reply wadadadad 3 hours agorootparentI think there's a difference between being 'content' and being 'happy', where happy would lead to a smile, and content is more of a general satisfaction that may not lead to a smile. I would argue that being content is the minimum here rather than necessarily having the smile (but certainly a smile is much stronger and more noticeable of a sign); and that there are many more people who are content going to work than those who go with a smile. reply kmarc 11 hours agorootparentprevYes I did it on my last job for a year at least. Good project, learning, good direction for the team, etc. (and of course \"more important\" things like a salary, friends, family, etc was all in balance). It was not an easy job though, sometimes I was tired, exhausted by the end of the workday. But it felt like being tired after a good exercise session: feeling of accomplishment. I left the job when the smile disappeared (non-technical reasons). Then I realized that the smile in question was a really important thing to me :-) reply ddingus 14 hours agorootparentprevYes! I did for may years after my career change into the high end CAD world. And more recently I am doing it again working with people I love on a startup (manufacturing related) I believe in. reply VonGuard 18 hours agoprevThe number one trait I have seen in people who are burned out is that they utterly and completely deny they are burned out. They often furiously push back on the idea. \"I cannot possibly be burned out, because I have way too much to do,\" or something less articulate. Admitting you're burned out is the fist step on the path back. It can take years to get back to normal and have passion again. But it will return if you take care of yourself and avoid the kind of things that send you spiraling into stress. reply ajkjk 41 minutes agoparentI think the basic mechanism is: You have an identity that says you're good at something, responsible, motivated, etc. that identity is the one that talks in meetings, promises to do stuff, signs up for things, etc. This is the part that would push back on the idea of being burned out as well, because it identifies with not being that way. Part of your brain is dedicated to projecting this identity out into the world. Meanwhile you have another part of your brain which is your actual executive function, which responds to your needs and makes you want to do things. It will try to do what the first identity says, to a point, but if it starts wear down, be bored, be frustrated, etc, it will start to fail. What's supposed to happen is that your first identity, or rather your whole coherent self with all of its parts, recognizes that something is not working and does something: takes a break, quits, stops working so hard, changes something, adjusts the identity to be healthier, whatever. What happens instead is that those small failures are ignored and start accumulate into a larger and larger debt, of being behind, not getting what you need, and draining yourself of executive function to keep up with it. Eventually this becomes untenable and your brain just starts to shut down. The way out is somehow reconciling the two. I expect that it looks like: first, realizing that you're drained and properly recuperating, then second, realizing that you're not getting what you need to stay driven and doing something about it. Just recuperating on its own isn't enough. reply parpfish 18 hours agoparentprevA related trait is people who tie their self identify up with their job. When your identity is “person who does this job”, it’s hard to see that you’re doing the job too much. And even if you do have that realization, it opens up a new struggle to figure out what you’re supposed to do if you’re not doing the job. reply al_borland 17 hours agorootparentThis was (and still is) one of my issues. I had the realization that I need a life, so I stopped working 60-80 hour weeks, but didn’t have anything to fill the time with… and even if I did, I’m too burned out to do anything. reply parpfish 17 hours agorootparentCongrats and welcome to living your life! I know it’s overwhelming to find a new hobby or interest, just throw yourself into something and realize that you’re not going to be good at it reply gnulinux 15 hours agoparentprevThis is a very naive take. There are people who live paycheck to paycheck with the threat of homelessness. They can't just \"accept\" they have burnout, they have to work as if they don't just like any other person. I myself had a brutal burnout recently (hopefully recovering now slowly) but it was very difficult because I work on a visa and I can't afford to take a break or PTO etc. Yes I \"accepted\" that I'm burned out in an academic manner but almost everything my therapist offered was out of question. In that sense of course \"I can't be burned out because I have too much to do.\" I still have to work every day, churn the churn, hustle the hustle, write the performance review forms, avoid PIPs, otherwise I'm deported in a matter of months. Managers expect exponential return every quarter! reply changexd 13 hours agorootparentWell in this case my friend, perhaps sometimes it's okay to go back home? I have lots of friends doing this to them, they are burned out both physically and mentally, people usually have options if they can step back a bit, do you really want to sacrifice your happiness for working abroad and become \"successful\"? Only you can drag yourself out as you've mentioned your therapist's solutions do not work for you, it's okay to take a break, giving it up is not giving up, but a reason to look different path, you can be truly be free only if you let yourself free. reply gnulinux 5 hours agorootparentIt's not possible to do so due to having my entire life here and nothing \"back home\" where I haven't even visited last 15 years. I have my fiancée, my cat, my house, my career here and there I have nothing. Would you leave your future wife, mom of your future kids, and go to the other end of the world to a country you last visited when you were a kid? reply gosub100 3 hours agorootparentprevIts not \"naive\" to limit the scope or infer what the limited scope is, in this case it's tech workers. We aren't under contract to account for everyone else who is on a visa (that they chose to undertake) or works a low wage job. The comment is correct for an implied subset of the population. reply gnulinux 2 hours agorootparent\"Mental health problems and life struggle doesn't matter unless you're privileged like me.\" reply gosub100 1 hour agorootparentthat's not what \"privilege\" means either. reply swatcoder 18 hours agoprevMany of us have experienced what you describe and it sucks. I hope you're able to sort it out and feel better about things sooner than later. That's generally the case. But you and others should keep on mind that \"burnout\" is not a very precise or actionable word and thinking of your current challenges as being products of burnout doesn't give you much traction on what you can do about not feeling well or what external circumstances might help you recover. Reading between the lines, and trying to be more precise, it sounds like you may have pushed yourself too hard for too long while neglecting essential self-care pracfices. * You probably weren't resting very well (sleep; low-stimulation idle time). * You probably weren't eating very well (fresh, nutritious food) and may not have even been preparing food for yourself (cooking). * You may not have been physically tending to your self (being active, cleaning, dressing) and your space (cleaning, decorating). * You may not have been keeping up with your relationships (friends, family) and your community (hobby groups, church/etc, light acquaintances). For most people (and animals) -- when you don't do those things for long enough, it eventually just catches up with you. You're wired to do those things almost every day and the wires short out and things get funky when you ignore them for weeks or months or years as many fall into the habit of doing. \"Burnout\" often suggests that the malaise is a product of what you were doing instead when that often isn't even relevant. Presumably, if you're here, the thing you were doing was something you were passionate about (impressing someone, acheiving something) and probably isn't suited for villification anyway. Rather than just casting everything that feels wrong into the big vague lot of \"burnout\", try to take a minute to figure out what you were specifically neglecting and then try to get your hands dirty doing those neglected things (even if it's clumsy or slow or whatever in your fog and fatigue). reply strken 17 hours agoparentYou can get burnt out while not neglecting any of those things. Going to bed at 10pm with fresh sheets after a nice healthy dinner with friends is not able to offset an unlimited amount of workplace stress, although it's surprisingly effective. Once you're in a slump you'll probably start neglecting things, but that's getting the causation the wrong way around. reply StapleHorse 8 hours agorootparentYou are maybe right at the begining, but then I think it's both. It becomes a negative feedback loop. reply meztez 15 hours agoparentprevSeems complicated, although this is the best description of depression I've ever read, go outside and start walking. reply senectus1 17 hours agoparentprevYou missed one of the most important things they may not be doing, excersize. This has an incredible \"freeing\" effect on the mind and \"soul\". You dont need to be a HIT or cross fit fanatic. just get out and active reguarly. This will also help with sleep and eating better. Get into regular tiring excersize. It will help with so much. reply swatcoder 17 hours agorootparentIndeed! I had it there, then revised as \"being active\" as I think a lot of people get distracted and discouraged by the the contrived, abstract thing that is modern \"exercise\". I personally enjoy exercise as a hobby, but doing some productive labor, commuting or running errands by foot/bicycle, engaging with active kids, etc, can all hit the same mark in terms of ongoing wellness. reply kd5bjo 13 hours agorootparentWhen I was a kid, I developed a strong aversion to anything described with the terms “healthy” or “exercise” because anytime they were used, it inevitably meant that the activity had nothing else to recommend it and would be unpleasant. I think I’m finally over that particular hang-up, but it took decades. reply parpfish 17 hours agorootparentprevPeople on HN either hate exercise because they associate it with the old nerd vs jock battles OR they are absolutely obsessed because it’s just hacking on a big blob of meat reply Earw0rm 12 hours agorootparentIt's funny because it's true. Front-enders get surface body modifications. Ink and piercings. True engineers know that the worthwhile body modifications are a resting heart rate sub 45, or being able to bench double their body weight. reply Clubber 17 hours agorootparentprevWalking for 30 minutes 3 times a day helps me a lot. I need to start doing it again. It's so easy to ass out on the couch after a grueling day, and when you're burned out, every day is a grueling day. reply 8Z7FpV6eDp 15 hours agoprevWFH and the general state of tech burned me (and continues to burn me) out big time. I am extremely over Zoom meetings multiple times per day, every day, and what-feels-like-constant Slack interruptions. I usually love meetings, too! Tech consulting is what I love doing, but all of the small consultancies are getting hoovered up by the big 4 or WITCH firms, and all of the big firms make you wear business casual and have strong money/sports/golf cultures, which sucks ass. Going back to engineering and spending all day pairing on Zoom and dealing with petty politics isn't the way either. Work just isn't exciting anymore; the last four years have felt like different takes of the same job (despite me changing jobs a few times! ). But going back to the office in a world where half of the folks there don't want to be there isn't fun either. Also, all of the energy in tech is going towards AI, which I couldn't give less of a shit about. Startups are hella exploitative, but big companies prevent you from getting anything done. I don't know. reply rlabrecque 14 hours agoparentYeahhh; I feel this. I'm in the office 4-5 days a week again; and the rare days where most of my day ends up being in-office only interactions are great. The quick catchups in the hallway; not either forced catchups that always happen at the wrong time for someone, or never catching up. Socializing while going out for lunch; not doing lunch alone, and then having to make time for socializing when I need to be working. Those days are waay better than zoom meeting hell days OR WFH on no-meeting days. Commuting is new to me since Covid and that sucks but those days remind me what work could be like so I put up with it. :/ reply sfmz 2 hours agoprevI was doing a startup with a high achiever, I estimate ~160 IQ or higher; he worked 7 days a week, at least 12 hours a day, but often 16 for at least 20 years. He was a step-change smarter than me; PhD in Chem E. from top school, brilliant computer scientist... the only time I saw him relax is once he played Sonic the Hedgehog for like 10 hours straight. He fried his motherboard... his wife texted me one day... he's in a coma... 12 days later he emerges from the hospital with amenesia... that was years ago, still has amensia, can't create new long-term memories, can't work, etc. One thing that helped me during burnout is reading biographies, idk why it helped, but I'm passing it forward. reply ChiperSoft 16 hours agoprevI recognized I was burned out three months ago, but wasn’t in a situation to do anything about it. Then work got even harder, and I tried to push through it. My brain broke last Friday, I couldn’t think about even the most basic programming concepts without a lot of struggle and developing a nasty headache. I’m now in the exact same place as OP, and just told HR today that I need to file for temporary disability. I’m scared, I fear my career may have just come to a screeching halt. I regret not listening to myself months ago. reply ein0p 12 hours agoparentIf you’re worried about the “gap”, don’t be. In my experience it doesn’t matter nearly as much as people believe. And don’t worry about your “career”. It’s basically all bullshit anyway. reply astura 5 hours agorootparentThis comment makes no sense. Your ability to provide for yourself and your family isn't \"basically bullshit,\" and filing for short term disability doesn't leave a gap on your resume. reply ein0p 1 hour agorootparentIn the grand scheme of things arbitrary and artificial “career ladders” don’t matter. Your best strategy is to ignore all that and move around every 2-3 years looking solely at the dollar figures and ignoring the titles. If you do not move, you’re going to end up underpaid, even if you do get to a fancy title or “more responsibility”. reply madmask 3 hours agorootparentprevCareer as playing the game and climbing the ladder is bullshit. One can provide without a “career”. reply blueyes 18 hours agoprevI got super burned out working in startups for about 8 years. didn't realize it on the inside. now that i'm out, i look back and realize i was in a constant state of stress and anxiety. i got my sleep back, started exercising, started doing ice plunge/sauna, cut stress, limited exposure to stupid messaging streams like slack. it's a new world. i had to remake myself chemically in tiny steps and it took about two solid years to do it. reply siamese_puff 17 hours agoparentWhile working? reply blueyes 2 hours agorootparentYes, while working and raising a young boy. I just needed to escape the hellish pressure of having raised millions to build a business that didn't work, and worrying about my obligations to investors and the team members I hired. It was a bunch of tiny steps that I had to slot into the constraints of a working life. I recommend \"Tiny Habits\": https://tinyhabits.com Fogg has good ideas about how to redesign behavior under constraints. reply ddingus 14 hours agorootparentprevMy guess is nope. That is very difficult to do, unless one works with people willing to make an investment to heal one of their own. That is out there. But it is rare. reply xyst 17 hours agoprevThis is too real. This weekend is when I finally start looking for a new job. Corporate life just fucking sucks. Work is \"easy\" but it's just not rewarding. The before/after OP described is kind of on point. But add in the fact that I just don't give a fuck about this company anymore. There's nothing I work on that contributes to the betterment of society. Equivalent of pushing paper at this point. Going to get a good fucking rest (10 hours of full sleep). Run in the morning. Then grind out applications and hitting up connections. reply famahar 15 hours agoparentI'd argue that most dev jobs contribute nothing to society. The ones that do unfortunately don't pay well. I went into teaching for now and while it pays less, it's also tremendously fulfilling and the most human I've felt at a job. Tech work is soulless to me. Corporate environments are sterile fake bubbles of ego, profit and exploitation. It's not the real world but it pays well. If money weren't an issue I'd be a teacher for the rest of my life. reply pvsk10 1 hour agorootparentDid you have to take any certifications to get into teaching? What subject do you teach? reply noobermin 18 hours agoprevI've been burned out for two years after moving to a new country to work in one of the worst post-docs of my life. But, I've found I have no one to rely on but myself because employers don't care that you're burned out, they want to keep up their kpis. Sometimes you have to work even if you're already unhealthy. By the way, this isn't a \"when the going gets tough\" sort-of post, I'm just stating the reality of life. reply al_borland 17 hours agoparentMy company sends out blasts to everyone that tells us to take care of our mental health and stuff like that, but it’s all a show. Our actually managers drive us into the ground and any sign of weakness are met with a kick while the person is down. Everyone I work with is burned out and miserable, but too scared to say anything about it or take the time they need. Hearing grown men break down and cry on calls isn’t fun. I’ve heard it several times now. At this point, quitting seems like the only option. However, I’m in what should be the best earning years of my life, and it seems like any new job would mean a pay cut. I don’t want to cut my legs out from under myself… especially when a new job is an unknown, it could be even worse. I also have this idea in my head that I would be able to be mentally strong enough to find happiness in any situation, and if I run away from something bad, rather than being pulled toward something better, than I won’t grow as a person. reply okwhateverdude 1 hour agorootparent> At this point, quitting seems like the only option. Man, given this story, I think you have way more options. Like burning the place down, Milton-with-the-red-stapler style. Jokes aside, GTFO that place, bro. Leave a harsh glassdoor review for the cathartic release (even if it won't get posted). The grass is definitely greener somewhere else even if it might be a gamble to find it. Just note down everything you don't like about your current shithead employer and ask yourself, \"what questions can I ask in an interview that will reveal these shithead employer tendencies?\" Then go interview and remember that you are interviewing THEM. Don't worry about actually getting the job, interviews are a coin flip anyhow, just worry about how much shithead signal you're getting from them. If you end up jumping out of the frying pan and into the fire, just update your list of shithead employer questions and do it again. Life is way, way too short to deal with shitheads. Love yourself more than that. reply bityard 14 hours agorootparentprev> Hearing grown men break down and cry on calls isn’t fun. I’ve heard it several times now. Okay. Let me stop you right there. If that is something that happened once, I could believe you ran across someone who wasn't very emotionally balanced at the time. Twice could be a coincidence. Three times or more means you work in one of the most toxic workplaces I have ever heard of. I want to be a crystal clear as I can on this point, so I'm going to raise my voice a bit to be heard: THIS IS NOT NORMAL. > I don’t want to cut my legs out from under myself… especially when a new job is an unknown, it could be even worse. Yes, a new job is an unknown. But that's life, change is a constant and you have to embrace and embody that in order to truly thrive. Based on the fact that very few companies are staffed entirely of psychopaths, outside of fintech anyway, let me ask you this: do you really think throwing a dart at a random list of companies is likely to hit one that's materially worse? Either way, if you're not happy where you're at, wouldn't it make sense to throw the dart anyway, just to see where it hits? > and it seems like any new job would mean a pay cut. 1. You are already halfway to the mental ward if you think a little extra money is worth all your sanity. 2. You are probably wrong anyway. If one company is willing to pay you X dollars for your skills and experience, others will too. In fact, and I speak from recent experience here, many are willing to pay a great deal more. > I also have this idea in my head that I would be able to be mentally strong enough to find happiness in any situation, and if I run away from something bad, rather than being pulled toward something better, than I won’t grow as a person. No offense, but that is extremely backwards thinking. Would you continue to live with a physically abusive partner until a better mate showed up on your doorstep? No? Why would you continue to live with an emotionally abusive one? It sounds like you are waiting to be rescued from this situation by something or someone. Let me assure you: no one is coming to save you. You are the one in charge of your physical and mental well being. That isn't to say you shouldn't ask for help, but you need to be the one to stand up to whatever fears are holding you back and say, enough with this bullshit, enough working for fuckwits, I deserve respectful coworkers, competent managers, and rewarding work. You may not find complete happiness, but you don't have to stand for constant misery. reply al_borland 1 hour agorootparent> outside of fintech anyway Funny you say that. We seem to use various fintech companies as our feeder for senior management positions, who then bring in all their people. I usually try to wait them out, as they typically only last a few years. The idea being that it can't get worse, so the next person will be better, but they just keep getting worse somehow. We just got a new guy recently, so the impacts from that remain to be seen. > do you really think throwing a dart at a random list of companies is likely to hit one that's materially worse? When I look at job postings online, without relocating, it seems I'd likely take a 25-50% pay cut. I also have some golden handcuffs on me, so I'd have to forfeit a bunch of stock. While money isn't everything, and I keep my cost of living pretty low, it is a concern when I think about retirement. I've shared some of my frustrations with my dad, who spent his whole career in corporate IT and worked at several different places. I don't know that I brought up the crying, but I've told him quite a bit. His general replies are that he can relate, and will often point to Dilbert to show that it's the same everywhere... if it wasn't, that comic wouldn't have been popular. I've also seen people leave and beg to come back. These things together make me think the grass isn't always greener. On the flip side, I've also seen a lot of people leave who end up with a permanent smile on their face after leaving. Several have also lost significant amounts of weight, as they stop needing various coping mechanisms or find healthier outlets. I suppose this means the fear of regret is stronger than the hope that something new will be better. My old boss seems to have a standing offer if I want to go work for him. However, a former co-worker did, and he texted me about a month ago saying how bad it was. And the boss is saying he makes less than me now, so the pay cut comes up again. While he liked me and gave me a lot of autonomy, he also lied to me for several years, manipulating me to sell my house and move several states away from home. When I was finally fed up and decided to move back near family/friends in my home state, he tried to keep the lie going. I called him on it, and found out it was all BS. So I'm not excited to jump into that again. > No offense, but that is extremely backwards thinking. Would you continue to live with a physically abusive partner until a better mate showed up on your doorstep? No? Why would you continue to live with an emotionally abusive one? I think what screws with me is that I will occasionally see someone who seems happy in spite of it all. It's rare sight, but there are a couple. I wonder what their secret is and how I can get to that place, where I can be happy in spite of my circumstances. Maybe it's all an act. > I deserve respectful coworkers, competent managers, and rewarding work. My coworkers, the ones I've been working with for 10-15 years, I like. I feel some loyalty to them. Maybe I shouldn't, but we've been in the trenches together for a long time. They've had my back and I've had theirs. When it comes to management competence and rewarding work, that's currently at an all time low. I used to take on a lot of these shortcomings myself, to fill the gaps in leadership, but with 4 re-orgs leading to 4 new bosses, in 4 years... I'm sick of starting over and sick of doing other people's job, so I stopped. So far it's not gone well and everything is worse as a result, which has me questioning if I should go back to working 60-80 hour weeks to try and get the house in order as I've done in the past, but these people don't deserve that. I don't deserve that. And if I do all that work, they're just going to re-org in 6 months, so it will all be for nothing. I once told my old boss I thought about quitting every day for 15 years. Though the reasons why changed over time. At first it was impostor syndrome (which also gets in the way when I look for new jobs), then it seemed like I had nothing more to learn and hit a dead end, and now it's the overwhelming toxicity of the culture. Thanks for the tough love. You've given me a lot to consider. It's a difficult decision for me. It's been one of the few constant things in my life, and as a result I don't have much of a life outside of work. Quitting is an event that would shake loose my identity. Oh god... is this why people stay in abusive relationships for so long? reply whoknw 17 hours agoparentprevIt depends on where you work, but some employers extend mental health benefits to post-docs as well. Depending on the country, therapists have sliding scales too. The irony of looking for a therapist while you are burned out is that it can be a long process, but there is the chance of it being worth it and to see more options afterwards. reply wruza 2 hours agoprevBurnt out badly in 2022, empty tank, few “can’t get up” episodes. It took six months and one trouble only to find a stable point in my mind, but recovering didn’t even start then. I’m almost two years floating free (thank myself being smart with money) and am even trying a couple activities this year, but it takes time to replace the broken parts. All, ymmw, but take note you may not recover from it by simply taking a vacation. Btw, distancing didn’t work for me. It was the opposite, I couldn’t work in an env that couldn’t care less as a whole. Another note is that eat, shit and sleep system is in a strong feedback loop with all that. Also, I was alone most of my life and fine with it, but living with a relative suddenly changed a few things that I can’t explain. Simple human presence shifts something, although I’m not craving for it and find it burdensome in general. reply morkalork 17 hours agoprevEver since I snapped at a C-level exec and more or less told them to fuck off and stop asking me for shit, in more polite words, when they are categorically _not_ in the chain above me, I've been feeling a lot better. I may have completely burnt any and all bridges I have though, I don't know yet. reply famahar 15 hours agoparentI'm glad you're feeling better. Sometimes burning bridges is the fuel you need to build better ones. reply parpfish 18 hours agoprevYou should also know that it can take a LONG time to fully recover. I got burnt out 3-4 years ago and am only now feeling like I’m coming back to normal. Maybe if I took a more intentional path to recovery I’d be back earlier, but it’s not like the kind of thing where you can take a couple weeks PTO and expect it to clear up reply CooCooCaCha 18 hours agoparentDid you take a break from working or did you find a way to recover and work? reply parpfish 18 hours agorootparentMonth off and then to a new job that was arguably even worse. Only stayed there a year, but my new gig is good reply jpm_sd 18 hours agorootparentprevGetting a new job at a big, slow moving company can be a good way to recover while not becoming destitute reply parpfish 18 hours agorootparentFor me, the big slow moving org CAUSED the burnout Burnout isn’t always about overwork. There are several different typologies and mine was more related to a lack of control/pointlessness that led to a very extreme form of ennui. The end result was the same with depression, anhedonia, and cynicism. reply primitivesuave 18 hours agoprevI burned out around 3 years ago and couldn't fix it with a year of traveling the world and working on side projects - thankfully I discovered Vipassana meditation which helped me bounce back stronger than ever. Hopefully someone else in a similar situation might find this potential solution useful. reply andrei_says_ 18 hours agoparentWhat in Vipassana helped the most? Refocusing on the body? Focusing on equinimity? Recalibrating the mind once or twice a day? Something else? reply whoknw 17 hours agorootparentSecond that question - did you do one of the ten day retreats? reply floating-io 16 hours agoprevI wonder how much burnout is exacerbated by the fact that projects never actually end in this business? You never truly finish something. If you think you did, you are quickly disabused of that notion. You are lucky to ever feel that sense of pride in completion, and if you do, it is brief. Pride in a job well done is fleeting, if you are ever allowed to feel it at all. Yes, I'm a recovering victim of burnout, and no, this was not the only cause, but sometimes I wonder... reply yarg 16 hours agoparentWhat did it for me wasn't the fact that the project had no end in sight, It was the fact that every time I made an effort to move towards that point, the boss would pull in a dickhead architect (let's call him Huy) who would then veto my entire roadmap. This happened many times, each time I felt more and more worthless; by the time I eventually left Bravura I was suicidal. reply jdthedisciple 11 hours agorootparentToo relatable, few things worse than a half-committed architect constantly tripping you over... reply yarg 9 hours agorootparentSomeone else shat the bed on the first project I worked on for the company. He blamed me, so for the next four years took every opportunity to had to fuck me over regardless of what I was trying to get done. I once had to get through six weeks of work in a month (what need for testing?), because he told me last minute about major vital changes that were needed in the next release with zero advanced warning. This was in addition to my standard workload. After I somehow managed to pull it off, he then informed me that the changes weren't that important and weren't required for the release. Yeah, fuck that guy. reply patrickhogan1 18 hours agoprevInterestingly, while chronic sleep deprivation is harmful, studies show that a single night of sleep deprivation can have a rapid, temporary antidepressant effect in 40-60% of people with depression. I tried this after burning out on my third startup, and it helped me short-term when I needed it most. You can read more about the research Penn Medicine (https://www.pennmedicine.org/news/news-releases/2017/septemb...). reply Aeolun 18 hours agoparentSo people that keep going to bed too late are self medicating? reply thinkingemote 10 hours agorootparentThere was a recent post that implied that in cases of acute trauma, staying awake might lead to better outcomes through less long term memory formation. Sleep deprivation disrupts memory https://www.nature.com/articles/d41586-024-01732-y (3 months ago, 103 Comments, https://news.ycombinator.com/item?id=40681345 ) Its probably not the same as chronic burnout or depression but in a way staying awake after a stressful day could be self medication. reply patrickhogan1 18 hours agorootparentprevDan Gross, in his “How to Win” talk, discusses the Software Engineer’s (SWE) 25-hour cycle and emphasizes the importance of sleep for overall performance and well-being. I completely agree with his focus on sleep. The strategy mentioned above is meant as a temporary fix when healthier alternatives—like restful sleep, regular exercise, a balanced diet, or sauna use—aren’t effective. It also has an immediate effect, unlike many medications, making it a useful, isolated experiment. https://youtube.com/clip/Ugkxy4qdJ_dSU4Thv0MpGzqxJ8OYPfSvPW3... reply MathMonkeyMan 17 hours agoparentprevA psychiatrist told me that sleep deprivation does have a proven anti-depressant effect, but that the side effects are very severe. Makes sense. He preferred the SSRIs. There is a moment, when I've been up all night and am engaging with the world, that I feel a lack of anxiety and a mental clarity. It's like I've finally \"sobered up.\" I think it's my body telling me \"we need to sleep, none of this shit matters.\" Sleep deprivation is very bad for you, though, so try something else instead. reply TillE 15 hours agorootparentSleep deprivation is one of those last resort options that psychiatrists will consider if the normal treatments persistently fail. But yeah, do the normal stuff like SSRIs first. reply siamese_puff 18 hours agoprevWhat to do? My company dropped support for therapy, I pay $4k a month in rent and feel I probably just won’t wake up some days. I wouldn’t mind taking a break, but the nonstop posts about not being able to get a job don’t help. Have never felt more trapped. reply haswell 17 hours agoparentWhen you say your company dropped support, do you mean they were providing it directly and now aren’t, or it’s no longer part of your health insurance? I’ve worked at places that did both. Check your health plan. Most decent ones have mental health coverage. Don’t let coverage stop you from getting help. From experience, there comes a point when staying just won’t be an option. Your body will make the decision for you. I started a sabbatical right before all of the layoffs started. It was a little spooky at first but it was also the best decision I’ve ever made. Also worth looking into taking medical leave. Easier if you’ve been speaking with a therapist and/or doctor who can help justify the leave. I almost did this but didn’t want any pressure to return. reply chrnola 17 hours agoparentprevSame. I would rather put up with being burnt out than subject myself to interviewing. Ridiculous. reply haswell 17 hours agorootparentThat’s the burnout talking. Took me a number of months on sabbatical before I realized that the idea of interviews no longer made me want to crawl into a hole. reply cleandreams 17 hours agoprevI got burned out with the combination of a high intensity job, care taking a dying spouse, and managing the decline and dementia of a parent. Both deaths occurred near each other. I had always been highly productive and successful but at a certain point I couldn't really focus anymore. My brain felt empty. I had trouble learning things. Luckily I had had one of those golden jobs in which I made a small fortune. I retired early. Now I feel fresh again and I want to get back into the mix. It took a couple of years though. What did I do? Grief workshops, therapy, gym, meditation, grief groups, community service, deeper friendships. It works. It just takes time. reply dogbait 16 hours agoparentSo sorry to hear you went through that heartache. I'm glad life (and of course your efforts) gave you some fortune. For me - going through burnout and depression, my brain felt almost like it would hit a wall any time I wanted to learn something new. At the time it felt like it was energy or sugar deprived. Took a month of no work and just relaxing, playing video games (I joke sometimes that Witcher 3 healed me) and doing the core things, exercise, talking, spending time with my family and friends and sleeping/eating right slowly pulled me away from that raw feeling of apathy. Everything else followed once I started basic self care, but boy did it take time to feel somewhat 'normal' though I still feel 'different' following the experience. reply cleandreams 13 hours agorootparentThanks. It's hard to connect to self-care when you are in a tech grind. You are expected to grind it out and I enjoyed that but at some point in my life that didn't work anymore. Taking even a month off can help. By the way I went back to work about 3 weeks after my spouse died. It wasn't the wrong thing to do. But a couple years after that I needed a real break. reply gfody 17 hours agoprev\"burnout\" can be anything from mental exhaustion to stress induced psychosis, and should be treated like any bodily injury - like you're not going to be playing tennis soon after a severe ankle sprain, and possibly never again at the same level after a nasty wrist break. mental injuries are real and take time to heal but when you don't realize this you just keep playing tennis on your sprained ankle and turn a small injury into a big one. it feels like you can't learn, can't work, can't remember - this is just your body protecting itself, your ankle is wrapped. you have to listen to your body and give your mind a break before it takes one. reply dgllghr 18 hours agoprevThis is a psychological issue, but everything psychological is also physical. It’s all one interconnected system. So please see a doctor and have your bloodwork done. Doing that was the first step to escaping my burnout. I wish I had done it sooner. reply XorNot 18 hours agoparentI would somewhat caution against this: you're much more likely to get told everything is fine, then be told it's not. And even if you're told it's not, it may not solve any problems: I lost a bunch of weight, got fitter, and deflected myself (so far) off a path to adult-onset diabetes...hasn't helped the burn out at all. These are all good things to have done, but the secret hope of everyone once they walk into the doctor's office is to get told \"take this drug and you'll be back to feeling like you're 24 and just graduated college\". reply dgllghr 18 hours agorootparentMy goal isn’t to get anyone’s hopes up about a drug fixing all issues. It’s more to encourage to cover the basics in case it helps. Because it did for me and it’s something I could have done sooner reply jaggederest 15 hours agorootparentAnother anecdote here. My endocrine system was messed up in a multitude of ways. Getting it back closer to ideal has meant that, in general I can handle stress, and if I can't, taking time off is actually restorative, not just \"not getting worse\". You really have to insist, in the US anyway, that there is really something wrong. I was told for ~6 years \"idk you're depressed bro\", when in fact there were material physiological things that could have been addressed right away. reply al_borland 17 hours agorootparentprev> the secret hope of everyone once they walk into the doctor's office is to get told \"take this drug and you'll be back to feeling like you're 24 and just graduated college\". The fear of this attitude, which is all too common, is what keeps me away from doctors. I had a doctor several years ago who was amazing. She actually focused on lifestyle and would even host classes for her patients at night. Best doctor I ever had. Sadly I moved away, and I don’t know how to find another doctor like that. She was like a unicorn. reply owenpalmer 13 hours agoprevI started doing dev work at 17. Initially, it was the most fun and productive stage of growth in my life. After switching companies, I started taking on a lot of responsibility and stress. I didn't know how to communicate when it was too much. I was very ambitious and studied programming for hours outside of work every day. The projects assigned to me began to feel meaningless. At this time, I was also in a long distance relationship. By age 19 my mental health was absolutely destroyed. After quitting my job, I couldn't even open an editor for months. It took a lot of healing before I could even think about writing another line of code. Although I've somewhat recovered from burnout and depression, I still have lasting symptoms that haven't gone away. My memory in particular has not recovered. I used to memorize hundreds of digits on pi-day just for fun. My mental energy is not the same, and everything (things what were previously easy) continue to be challenging. I'm giving it time. I'm pretty happy now, but I miss the raw intellectual abilities. reply py_or_dy 17 hours agoprevSame, I noticed my decline about two years before I got covid (2019). Getting covid def didn't help. I've managed to work a pretty simple software dev job mostly fixing bugs and not under any time constraints. I think that helped, but then I just now got laid off because the company realized that they could outsource most of the software work to china and/or Philippines. That and the notion that along with AI, I don't think the American based software developer will ever be a thing again. Which that is making me depressed again... reply herbst 11 hours agoprevI was only a few years in IT until I burned out and never really found back into a 'normal' life a bit more than 8 years ago. I haven't had a normal job since. I still can't imagine working a daily job. I highly doubt I will ever be able to do that. At least not in a stressful matter as development jobs turned out to be. HOWEVER, it never stopped me from trying. And today maybe I need 3 or 5 weeks at a time of doing nothing or just joyful things but when I head back into a Project I can do it with full enthusiasm, enough energy and most importantly fun. Fun doing what I am able to, fun learning new things on the way. My guess is the only reason this actually works for me is because nobody ever tells me what I have to do and when I have to do it. It just takes a few days of stress I can't control and I am back into a vulnerable potato. reply happyrock 1 hour agoprevExercise, sleep, nutrition, and screen time. Getting these right is life-changing. reply ornornor 4 hours agoprevWent through a similar thing, two years on I’m still not recovered. Just to say that even though it might not feel like it right now, it eventually gets better. You have to give it time. Sometimes a long time. And seek support from friends and family but also from a professional. And once you’ve recovered, learn the signs so you can see it coming and prevent it. Leaving a shitty job or even a profession that doesn’t work for you anymore is always preferable than getting burnt out. Good luck, friend! reply jraph 13 hours agoprevBurnout can also be bad to your relationships. It can break stuff because of your lack of energy and positivity. It's not only caused by overwork and it's often a combination of things: overwork, lack of meaning, lack of recognition, misalignment with your values... If you feel like you are slowing down and it starts being difficult to get started working for more than a few days, it is critically important to do something. Burnout sets up slowly and strongly and it's hard to notice. A friend who has burned out and has been seeing a therapist who told him burnout is the brain breaking like an overused muscle. Burnout might be a defense from the brain against what harmed it. I don't know if it's true but I believe it's a better perspective than \"I'm too strong for burnout\" or \"it's purely psychological\" or \"it's in your head\". Take care. reply notepad0x90 18 hours agoprevOP, I don't know a solution to this, but I'm curious if you've tried intensive exercise routines, low calorie diets, time in nature, cold showers, socializing and, working on your non-work life as a whole? I've seen this help me out in similar battles and I have also seen them recommended to others. I also have a more general question to everyone on this thread, what is the difference between burnout and demotivation? How can one tell the difference? reply AH4oFVbPT4f8 7 hours agoparentI've felt burnout and feel that I'm dealing with it now. I know doing exercise, a better diet, nature, will all help, but it's the motivation to start doing it. You wake up not wanting to go to work. You're at work, not wanting to go home. You're at home and don't want to go to sleep since it means you're just going to start the cycle again tomorrow. My issue is finding the motivation to start improving. reply tptacek 18 hours agoprevLearning quickly and easily intuiting solutions for problems is something that will ebb and flow throughout your career. Totally normal. One symptom of burnout is getting anxious and hypervigilant about your effectiveness! reply ants_everywhere 17 hours agoprevIn my opinion, everyone should try therapy at least once. Just like you have a primary care physician for your general health, a dentist for your teeth, it makes sense to have a medical professional to help you with your brain. I think of it as a best practice. Can you get by with out it? Sure. Will you be doing things optimally? Definitely not. reply deepfriedchokes 12 hours agoprevI have struggled with burnout, and I believe it’s a capacity thing, related to continuous trauma, and I’ve had success getting it treated the same way. Sometimes this trauma can be something as simple as a toxic workplace, or choosing work over taking care of your own needs. It’s something I’ve struggled with throughout my life, and I’ve found talk therapy helps a lot, along with self care, and life changes. Psilocybin helps as well, to see things from different perspectives, like therapy does, and to mechanically loosen up those neural connections that are keeping us stuck. Most people bounce back if removed from their source of trauma, but if it persists, or if you’ve become the source of your own trauma, consider therapy. Burnout and depression and these things are your body trying to tell you something, that whatever you are doing isn’t working for you. Don’t fight it, listen to your body, reconnect with how you’re feeling and why in therapy, and make changes in your life. Feelings are the feedback on our actions. If you touch a hot stove and it hurts, that’s your body telling you to make a change. If living your life in a certain way, or working at a certain place, or having a certain person in your life is making you not feel good, that’s your body telling you to make a change. reply novia 17 hours agoprevIs there any job out there where you can go without lying? Lying leads to burnout for me. Stretching tasks out makes me feel bad and maybe also leads to burnout. I just want to do an honest day's work without someone pressuring me to be insincere. reply thih9 10 hours agoprevWhat's the difference between a light bulb and a programmer? A light bulb stops working when it burns out. --- Source: https://mas.to/@yogthos/111573984275836954 I like it; it's funny, it shows the industry has a problem, it also makes me stop working so hard. reply purple-leafy 18 hours agoprevHow are you doing now? I too suffered pretty severe burnout. I’m a programmer. I realised my burnout came from working (5 days a week), feels like an unending marathon What worked for me was dropping one full day of work each week. Now work 32 hours a week, really happy reply shahzaibmushtaq 12 hours agoprevI could be wrong, but burnout happens for any/all of 4 reasons: 1. Lack of complete focus and not prioritizing daily jobs 2. Multitasking 3. Trying to do almost everything by yourself instead of delegating 4. Not asking for help I would also like to point out that self-doubt in your abilities, questioning your confidence and \"I can't do this\" mentality are detrimental to your mental health. reply anonymous_goat 11 hours agoprevDespite a lot of the other comments suggesting \"easy\" fixes, untreated and long-lasting depression (in general) and burnout (specifically) can have these lasting effects. These do NOT seem to be treatable without psychiatric and medical intervention - the brain has spend too much time in a depressive state, and it can't get out of it by itself. Psycho therapy alone and other usual interventions (sleep, proper nutrition, positive stimulation) simply won't help anymore. So, advise for everyone: real (in terms of \"professionally diagnosed\") depression and burnout for too long (over months and years) can break you in ways you can't imagine. Treat it early. reply itsjustjordan 13 hours agoprevI have this pinned and read it like once a month just as a refresher to not let it get that far https://robinrendle.com/notes/take-a-break-you-idiot/ reply tiznow 10 hours agoprevI'm dealing with burnout and unemployment, and it's legitimately the hardest time in my life to self-start and do anything other than basic life functions. Some days I have a wellspring of energy, but most days I'm just existing. I realized I don't even have the luxury of forgoing my mental health, if I don't work on it now things won't ever get better. And my programming skills aren't stagnating, but MAN I feel like I'm not getting better. reply bamboozled 18 hours agoprevI've been through this quite a few times in my life, get outside some more, do some exercise (light), take it easy, you'll bounce back. reply gwathk 16 hours agoprevThanks for sharing and I have been in the similar situation before twice. The never-ending feeling of uselessness, stagnation and helplessness sucks real bad. and after a while I (re-)discovered the power of charity and routine. You don't need something grandeur. Sometimes a routine of 5 minutes in the morning works. Write down the one thing you can do for others of the day that you can definitely get it done, and before you sleep you cross it out or not, and write down 1 small thing to be grateful to. For example: In the morning I wrote: I will say thank you with a smile to a random cashier in the supermarket when I do grocery. At night I should be able to cross it out. Even if I cannot it is nothing to beat myself with. I will add 1 little thing to be grateful to, as small as able to post on HN works too!=) Hope you can recover soon and regain your sense of self-worthiness soon. After all your are not (only) a learner and problem solvers. You are more than that =) reply markatkinson 10 hours agoprevI burned out in 2021 quite badly. Moved to Zambia (from UK) and switched from primarily software engineering to wild mushrooms. Still coded as a hobby and explored the parts of it I enjoyed. Now in 2024 I'm back in the game and loving it! Glad I had the privilege to take such a long break and try something else. The key take away here is it took me years to properly recover (and therapy). Go easy on yourself, don't get swept up in the frenzy of work. Work to live not the other way around. reply tonymet 15 hours agoprevBurnout isn’t working too hard, it’s not working on the right thing. You have to have a purpose . I don’t mean “doing what you love “ – that’s futile. I mean finding a purpose for doing what you are doing It should always be conquering the world . Not changing it . Changing it is a half measure reply rramadass 13 hours agoprevYou might find some advice listed here useful : https://news.ycombinator.com/item?id=40978488 reply armini 12 hours agoprevI can't tell you how many developers feel this way, there is no reason for this to be the norm. Be sure to seek professional help but if you'd like someone to talk to someone who can relate feel free to book a time https://calendly.com/thanks_dev/30min reply Summerbud 17 hours agoprevI got burned out recently too, and it is such a frustrated feeling. And made me begin to think what it comes from and what is the root cause of it I think in my experience, lack by appreciation is one of the reason After thinking about it several month I wrote an article to help others cope with the situation of lacking appreciation https://open.substack.com/pub/connectingdotsessay/p/apprecia... Hope it can help others whom is entering the same situation reply nullderef 6 hours agoprevI quit my job this month to pursue things that make me happier. Very hard decision but at least I'm happy to be trying! Best of luck, OP. reply JasserInicide 17 hours agoprevI feel like I have the opposite problem. I started my new job at the tail end of the pandemic in mid-2021. It's been fully remote and I have never worked more than 20 hours in a week. Most weeks I can get everything I need to do in an average week in 2 days tops. Co-workers are great and the company's doing great but I have such little to do that it's kind of ruined my work ethic. I'm partially scared of leaving/going to a new job because I don't know if I can handle doing 40 hours again. reply azemetre 17 hours agoparentHow do you feel about up skilling, contribute to open source, or even launch your own side projects? Or do you use your free time to enjoy life more? I’d like to think I’d use the time to write a book but I’d probably just to chores around my home instead. reply SoftTalker 17 hours agoprevJoin a gym, one with real barbells, do Starting Strength for six months, getting physically exhausted 3 or 4 times a week does wonders for your mental health. I didn’t believe it until I did it. reply nunez 15 hours agoparentEveryone should do this program. Rip has issues, but he did the world a HUGE service by writing this and Practical Progr",
    "originSummary": [
      "The author shares their experience of depression and burnout, highlighting a significant decline in cognitive abilities such as learning, problem-solving, and memory.",
      "They emphasize the importance of taking care of one's mental health to prevent similar issues."
    ],
    "commentSummary": [
      "Burnout significantly impairs cognitive functions, making everyday tasks challenging and affecting learning and problem-solving abilities.",
      "Establishing a clear work-life balance and incorporating learning into work hours are essential strategies to mitigate burnout.",
      "Recovery from burnout involves professional help, physical health maintenance, and engaging with supportive communities, emphasizing the importance of patience and self-care."
    ],
    "points": 612,
    "commentCount": 260,
    "retryCount": 0,
    "time": 1725580742
  },
  {
    "id": 41463809,
    "title": "Did Sandia use a thermonuclear secondary in a product logo?",
    "originLink": "https://blog.nuclearsecrecy.com/2024/09/04/did-sandia-use-a-thermonuclear-secondary-in-a-product-logo/",
    "originBody": "Restricted Data A Nuclear History Blog by Alex Wellerstein Redactions Did Sandia use a thermonuclear secondary in a product logo? by Alex Wellerstein, published September 4th, 2024 I happened to look at a slide deck from Sandia National Laboratories from 2007 that someone had posted on Reddit late last night (you know, as one does, instead of sleeping), and one particular slide jumped out at me: It’s a little graphic advertising the different kinds of modeling software that are part of something called the SIERRA framework, as part of a pretty standard “overview” presentation on computer modeling at Sandia that was given at a meeting in Luxembourg.1 Did you catch the part that made me stop and audibly say, “uhhhhh“? Look at the lower right: So, that looks an awful lot like the cutaway of a compact thermonuclear weapon design. I immediately wondered if I couldn’t find a better resolution version of the same graphic, so I went onto OSTI.gov and starting plugging in terms that seemed relevant. Searching for “Sierra” and “Salinas” and restricting to “Conference presentations” turned up a bunch of other instances of it from the 2007-2011 or so timeframe. The one with the highest resolution came from another presentation, from 2008:2 So this is awfully strange. We’ve got something here that looks like a plausible reentry vehicle for a nuclear warhead. The bits in red, yellow, perhaps fuscia at the “tip” are in the position (and about the right size) to be the arming, fuzing, and firing system. The bits below that — the green, the blue, etc. — look like a thermonuclear warhead. The green part looks like it is meant to represent the location of the “primary,” while the the cylinders-within-cylinders are a classic representation of a thermonuclear “secondary.” One could debate about the exact identity of each color, but it looks a lot like it is meant to represent a radiation case, an interstage medium, a tamper, fusion fuel, and a “sparkplug.” You’ve even got an interesting little “dip” into the central cylinder which looks like a channel to get neutrons into the “sparkplug.” By comparison, this image from later in the presentation looks a lot more like what one would expect them to release about a reentry vehicle in a public document — just the arming, fuzing, and firing system (the top part, with the detail at right), and then the “warhead” section depicted as a featureless blank: Even that is a little more revealing than usual, as it gives pretty precise dimensions. So seeing something that looks like it is meant to represent the warhead itself is… pretty surprising!3 This isn’t some one-off slip up kind of thing. This particular graphic is present in at least half-a-dozen conference presentations on OSTI.gov, and even some on a few other government websites (like this presentation given to NASA). It’s literally the logo they use for this particular software package. And it’s not some kind of redaction error, like the ones I wrote about previously, in which things not dissimilar from the above were very clearly intended to be redacted, but were done so poorly that you could in fact see some aspects of them. This is literally the logo for this particular software framework, and it has been used in lots of presentations (including those done overseas), and is posted all over unclassified, public-facing databases hosted by the federal government. It took me a little more searching, but I eventually tracked down an isolated version of the image from yet another Sandia presentation: The slide doesn’t give any clarification as to what we’re looking at, here, other than indicating that it part of modeling work for the purposes of structural dynamics, and is clearly part of a nuclear weapons context.4 The SIERRA software framework, I gather, is a simulation/modeling toolkit that allowed scientists to basically simulate a relatively “full spectrum” of weapons safety issues. This is Sandia’s bread and butter: making sure that your weapon won’t go off if, say, you drop it, or set it on fire, or let it get hit by lightning. Things which have happened a number of times over the years.5 The “Salinas” package in particular seems to be about modeling mechanical aspects of materials. Which is to say, this demonstration of its “capabilities” is not about showing you that it is modeling how a nuclear weapon would detonate. It is showing you, “look, we can model a lot of different materials — steel, uranium, lithium, etc. — and could probably tell you whether they would crack or strain or shatter or whatever if you, say, dropped this weapon.” That’s my quick gloss on the various presentations, anyway. To give a sense of how strange this is, here is the only “officially sanctioned” way to represent a multistage thermonuclear weapon, according to US Department of Energy guidance since the 1990s: Figure 13.9, “Unclassified Illustration of a Staged Weapon (Source: TCG-NAS-2, March 1997),” from the Nuclear Matters Handbook 2020 (Revised), published by Deputy Assistant Secretary of Defense for Nuclear Matters. Two circles in a box, maybe inside of a reentry vehicle. That’s it. Nothing that gives any actual sense of size, location, materials, physicality. One can compare this with the images of more speculative thermonuclear weapon designs in the public domain for a sense of how limited the official release is compared with what is “believed to be known” about such things: Somewhat speculative diagram of a W88 nuclear weapon, from Dan Stober and Ian Hoffman, A Convenient Spy: Wen Ho Lee and the Politics of Nuclear Espionage (Simon & Schuster, 2001), via Howard Morland. Incidentally, I submitted a FOIA request on that particular guidance document (TCG-NAS-2) some time back, and the document that I got back was hilariously redacted to the point that even terms like “gun-type” and “implosion” were redacted, much less any and all images, despite that document apparently containing examples of what actually could be said publicly about these things.6 Which is just to emphasize, it’s not like the DOE is particularly loose about even as vaguely representational an image as is that one — if anything, the err in the other direction. Why are they so uptight about thermonuclear weapon design “shapes”? The official reason, of course, is because of proliferation concerns. But there’s another reason: even the appearance of giving away “secrets” can generate unwanted publicity and political scandal. In 1999, the Cox Committee’s report on Chinese nuclear espionage made some hay out of publicly-available depictions of H-bombs, and featured an entire spread dedicated to the fact that “visitors to Los Alamos National Laboratory are provided a 72-page publication that provides, among other things, a primer on the design of thermonuclear weapons.” It sensationalized that very two-circles-in-a-box image that I showed above, and weaponized it. How dare Los Alamos give that away! Despite it being unclassified. But that’s what I mean by unwanted political scandal — lots of scandals about the release of “secrets” involve non-secrets. (There’s a lot on this sort of thing in my book, of course.) Which leads us to an interesting puzzle: why would the censors repeatedly allow Sandia to use what appears to be a thermonuclear weapon cutaway as part of a promotional diagram for a software package? There are a few possibilities that come to my mind. I gave a talk at Sandia this summer, and they made me wear this badge (and another one with my face on it, which I wasn’t allowed to photograph or keep) everywhere I went. Presumably so nobody would tell me secrets, but also, perhaps, to indicate my willingness to play Checkers. One is the idea that this is an accident, a leak, an oopsie. I find this unlikely to the point of near impossibility. Not because the classification officers are perfect. But this is so obviously not something you would authorize for release if you thought it was representing something classified. To have approved many presentations with this graphic in it to go out into the world, to be posted on the websites of multiple government agencies… they’re not perfect, but they’re not fools. Again, if anything, they tend to err on the side not releasing enough. So I find it hard to believe that they’d have messed this up, again and again, when it is the most blatant thing in the world. This isn’t some subtle technical thing. Anyone who thinks about weapons information and secrecy is going to know what a cylindrical secondary looks like. I mean, this thing jumps off the page if you are that kind of person. Which I am, of course, but so are redactors. If this were the case, it would be an incredible and repeat failure of the classification system at many points, in the same way, over several years. One can’t say such a thing is impossible but I find that extremely unlikely. Another easily dismissible possibility is that this is some kind of deliberate release of classified information. Again, there is an entire infrastructure devoted to not letting this happen. With peoples’ jobs, security clearances, and personal freedoms on the line. Plus the fact that the people who tend to work in these jobs take for granted that secrecy translates to security. Even actual spies wouldn’t do it this way — they’re not about releasing secrets to the public, they’re about channeling them to the people they are spying to, quiet-like. So we’re left with much more plausible conclusion that they consider this to be unclassifiable and benign. But why would they think that, given what we know about how sensitive they are to anything that comes even remotely close to representing internal weapon components? This “multipurpose test object” (taken from the aforementioned TGC-NAS-2 report from 1997) is an example of what I mean by a deliberately “unclassified shape”: something specified by the DOE as being evocative of the kinds of physical shapes and materials that are involved in nuclear weapons designs, but are explicitly indicated as being not actually relevant to weapons design. So this kind of “shape” is something you could use to validate simulation codes on which would probably work with actual weapons materials/designs, but would not actually reveal any weapons materials/designs information other than what has already been declassified. The “obvious” answer, if my above assertions are true, is that it must not actually represent a thermonuclear secondary. What else could it be? It could be some kind of pre-approved “unclassified shape” which is used for diagnostics and model verification, for example. There are other examples of this kind of thing that the labs have used over time. That is entirely a possibility. What would be bizarre about this being the answer is that a) “unclassified shapes” generally don’t look like actual, plausible weapon designs, and this thing looks “close-enough”; b) it still gives off the appearance of a classified shape, which as noted, is dangerous in and of itself from a political standpoint; and c) if the goal is just to show off modeling capabilities in a very superficial way (this is essentially an advertising logo) they surely could have picked a million less provocative (from a classification standpoint) examples. It’s also possible that it isn’t even meant to be a nuclear weapon at all. Sure, it looks like a reentry vehicle. Yeah… it seems awfully nuke-shaped. But there are other things that can look like nukes but at really meant to be something else. Maybe I’m seeing a “secondary” because I’m primed to see one, by the context? It’s… possible. Neither spheres-within-sphere nor cylinders-within-cylinders are inherently related to nuclear weapons components. But when you place them like that, in a reentry vehicle, in that order… it looks very much like a fusing system, a primary, a secondary… It would be quite surprising to me if it was not meant to be representative of those things, but something totally different. And, again, the original context of that model appears to be very firmly rooted in nuclear weapons development.7 Another possibility is that it is some kind of “deliberate disinformation” or “misinformation.” This is the kind of thing that I think people assume the government labs might do, but in my experience, is pretty unusual and pretty unlikely. In general, you have to remember that the national laboratories are pretty, well, boring, when it comes to classified information. They want to be boring in this respect. They are not doing cloak-and-dagger stuff on the regular. They’re scientists and engineers for the most part. These are not James Bond-wannabes. They don’t parachute behind enemy lines to set up palace coups. They are extremely rule-abiding for the most part. There are lots of social and historical reasons for this (again, my book goes into the historical ones — the anxiety about “nuclear secrets” always made the Atomic Energy Commission and its successor organizations very anxious about being accused of being lax about them). And beyond the institutional culture aspects, the idea that a bunch of engineers at Sandia are going to be using a software package logo to deliberate leak out misinformation, just waiting for someone to notice it, seems a little unlikely to me on the face of it. I mean, really. What is the “operation” here? Who is meant to be “fooled”? Me? You? The North Koreans? It doesn’t feel very realistic.8 And one can add to the above the fact that, at least historically, the Atomic Energy Commission and its successor organizations have frowned on disinformation and misinformation for other very practical reasons. If you release a lie, you run the risk of someone noticing it is a lie, which can draw more attention to the reality. And even misinformation/inaccuracy can put “brackets” around the possibilities of truth. The goal of these organizations is to leave a total blank in the areas that they don’t want people to know about, and misinformation/disinformation/inaccuracy is something other than a total blank. That’s where I’ve ended up, in thinking about what this “means” and what possibly accounts for it. But it’s still bizarre that anyone would allow something that looks so suggestive, even if it is not accurate, to be released as an official product of a national laboratory. It seems like a bad idea, anyway. And yet — I can’t come up with an explanation for this that isn’t one kind of bad idea or another. But I think this is the “most plausible bad idea” of the set. One last thing. In more recent presentations on the SIERRA Mechanics framework, they changed the diagram somewhat:9 The resolution isn’t great, but you can see that the potentially problematic part is much more obscured. But it’s still there, so I don’t think that is really an attempt to draw attention from it, so much as it is an artifact of somewhat careless graphic design. In general, it’s not a great logo by any means — too busy, too complicated, too much information, does not reproduce well at small sizes or low resolutions, etc. — but, as discussed, that is not even close to the most potentially problematic aspect of it! I saw this and couldn’t resist quickly writing something up about it. That’s all I’ve got. If you’ve got thoughts on it, let me know. And if you haven’t already signed up for it, I am much more active on my other blog, Doomsday Machines, as of late! I’ve updated this post a few times since I first put it up this afternoon, but just stumbled across something even more helpful. Here’s an image from a 2014 article about computational science at Sandia that looks awfully similar to the one above:10 Unlike the others, it comes with a caption: “The multiple components of a nuclear weapon body are highlighted in this intentionally simplified mesh. Each part is comprised of numerous subcomponents, fastened together with screws, nuts, bolts, jar-lid-like fittings and more.” Which is just to say, it is pretty clearly saying that this “thing” is meant to be some kind of representation of a nuclear weapon, albeit “intentionally simplified.” Which doesn’t really solve the mystery — if anything, it just highlights why I still find it so odd that this thing got approved for released at all! Not in the sense that it contains “secrets” — but in the sense that it is just not the kind of image the national labs tend to release. Someone reminded me of something I had seen years ago: the British nuclear program at Aldermaston, when it has published on its own computer modeling in the past, used a sort of “bomb mockup” that looks far more deliberately “fake” than this Sandia one. I offer this up as what I would think is a more “safe” approach than something that looks, even superficially, like a “real” secondary design: This is called the MACE (Modal Analysis Correlation Exercise) assembly, and was created by the UK Atomic Weapons Research Establishment in the 1990s to serve as a sort of a Utah Teapot of weapons structural modeling: a benign shape that could be used to test aspects of the code that would nonetheless tell you if the code would work for real weapons assemblies.11 Anyway, I’m just surprised the DOE would release any image that gave really any implied graphical structure of a thermonuclear secondary, even if it is clearly schematic and meant to be only somewhat representative. It’s more than they usually allow! Harold Morgan, “Sandia National Laboratories and Engineering Sciences Overview,” SAND2007-6636P, Presentation to Goodyear/Sandia CRADA Meeting Colmar-Berg, Luxembourg (22 October 2007). [↩] Heidi Ammerlahn, Richard Griffith, and Paul Nielan, “Modeling and Simulation at Sandia: An Overview,” SAND2008-3315P (23 April 2008). [↩] And, just to be very clear about it, that complicated set of machinery in the render is the arming, fuzing, and firing (AFF) system. The basic shapes of such systems have been declassified for a long time. It is the system that causes the warhead firing signal to be sent if the right conditions are met. It is not the warhead itself and is a separate component. [↩] Thomas M. Baca, “1523 General Capability Overview,” SAND2007-6128P (1 September 2007). [↩] Sandia made (and has since put online) a very informative, well-produced, three-part documentary about their work on the technical side of “command and control” of nuclear weapons, titled Always/Never: The Quest for Safety, Control, and Survivability. It’s worth a watch if you haven’t seen it. Separately, one of my favorite bits of weapons jargon is the term “mechanical insult,” which means denting your warhead in some way. [↩] U.S. Department of Energy, “Joint DOE/DoD Topical Classification Guide for Nuclear Assembly Systems,” TCG-NAS-2 (March 1997), received in 2021 in response to FOIA request HQ-2020-00067-F. [↩] For example, I don’t know exactly what this is meant to be — an example used in a Los Alamos presentation on computer modeling — but it’s not a nuclear weapon. [↩] And nor does taking it one level “deeper”: the idea that they’d put out real information to make us think it must be fake information, because why else would they put it out? This is an amusing idea but, I assure you, is not how bureaucrats think, and we are talking, for better or worse, about bureaucrats here. [↩] E.g., Timothy Walsh, Greg Bunting, Andrew Kurzawski, Ellen Le, and Kevin Dowding, “Large-Scale Inverse Capabilities in Sierra Mechanics,” SAND2019-6059C (May 29, 2019). [↩] Monte Basgall, “Joint venture,” DEIXIS Magazine (September 2014). [↩] Some more info on the MACE assembly can be found in this PhD thesis from 2004: Philip Ind, “The Non-Intrusive Model Testing of Delicate and Critical Structures” (Imperial College of Science, Technology, and Medicine, University of London, 2004). The screen cap image comes from an in-house AWRE publication (Discovery) from 2000. [↩] Tweet Tags: 2000s, 2010s, Bad ideas, Bomb design, Graphic design, Hydrogen bomb, Sandia National Laboratories This entry was posted on Wednesday, September 4th, 2024 at 1:21 pm and is filed under Redactions. You can follow any responses to this entry through the RSS 2.0 feed. You can leave a response, or trackback from your own site. Citation: Alex Wellerstein, \"Did Sandia use a thermonuclear secondary in a product logo?,\" Restricted Data: A Nuclear History Blog, September 4, 2024, accessed September 6, 2024, https://blog.nuclearsecrecy.com/2024/09/04/did-sandia-use-a-thermonuclear-secondary-in-a-product-logo/. PREVIOUS POST « Announcing DOOMSDAY MACHINES 11 Responses to “Did Sandia use a thermonuclear secondary in a product logo?” isaacblue72 says: September 4, 2024 at 2:14 pm I know you say that it’s unlikely that the same thing, was missed in the same way, that many times, but is it possible that no one was really paying attention to the logos on a the title page? Obviously, the sounds sloppy to me. However, I could also see people being like “ok, we have a title page with the logo. Moving on.” Reply Alex Wellerstein says: September 4, 2024 at 3:04 pm If it was a one-time thing? Maybe, sure — people make mistakes. The wrong document gets uploaded or put on the shelves, the redaction is sloppy-enough that you can see underneath it, classifier A thinks X is secret and Y is not and classifier B thinks the opposite, something gets left out where someone uncleared could look at it — these are all real things that have happened, all the kinds of things that frankly must sometimes happen, mathematically, when you scale a classification system to such a size. But to just allow such a thing to be displayed in such a banal way on dozens of presentations, over the course of years, including those given outside of the United States (which would be subject to a lot more scrutiny by default)? I just can’t see it as being a mistake. I am 99.99% confident that cannot be the answer, even as someone who is very aware of the kinds of mistakes that redactors make, very aware of the human factors involved, etc. Redactors make mistakes all the time, that’s for sure. But oops I left in a TN weapon design on a dozen presentations is not really within the realm of “mistake,” and would have to require many people to somehow not notice this. One would have to believe they were literally blind for that to happen. So that leaves us with the only other real option, which is that they consider this to be unclassified — but that, as I outline, is strange in any of itself! But not as strange as them including high-level design information in a dozen banal presentations as kind of a dorky little promotional logo. Reply Pavel Podvig says: September 5, 2024 at 4:06 am What if it was a mistake first time and then everybody assumed that it’s unclassified? It’s just a logo, after all. I guess it’s not how the bureaucracy works, but stranger things have probably happened. Reply Alex Wellerstein says: September 5, 2024 at 5:03 pm I just don’t see them continuing it — even if it somehow was a mistake, surely at the very least they would change the logo. It’s not like it’s even that good of a logo…! Reply Cheryl Rofer says: September 4, 2024 at 2:50 pm Hi Alex – On Bluesky, you asked me to comment, and it’s more convenient to comment at length here. It’s always been my policy not to comment on nuclear weapon design, so I won’t. I will comment on that graphic and your speculations, though. The short answer is that your guess is as good as mine. The figure you are looking at is very schematic, but, as you note, the DOE keeps schematics classified as well as more detailed figures. What it looks like to me is the designs that Martin Pfeiffer embroiders, which, I believe, are based on Howard Morland’s schematics. But why would Sandia use Morland’s schematics? Are they now well enough known that classifiers would think them innocuous? And even so, for Sandia to use them could give them a stamp of approval in some people’s minds. All that touches on what you’ve said above about deceptive or erroneous figures giving some information. I think you’ve covered all the possibilities for this graphic’s having been declassified above. My most intense experience with declassification came when I was responsible for the unclassified product of a pit-to-puck process. That was always tricky, but quite different from your questions here. Reply Alex Wellerstein says: September 4, 2024 at 3:13 pm Thanks, Cheryl! And yeah, I not only can’t see why Sandia would use Morland’s 1979 bomb design, but I can’t see how they’d be allowed to use it. I cannot believe (without further evidence, I guess) that the classification guidelines on TN weapon depictions in 2008 (or even today) would allow something like that. Much less that a (relatively mundane) software package logo would be the only way that one would see a reflection of such a massive change in policy! 🙂 Reply Cheryl Rofer says: September 5, 2024 at 9:04 am I see that Martin Pfeiffer says that his design comes from DOE sources, not from Morland. Reply Arine Starchan says: September 4, 2024 at 8:06 pm Reality is these shapes are usable because they represent a very loose approximation of very old technology, and no way represent modern designs. Early on some graphic representations that came from heat modelling became over time, in the public domain, a representative example of a weapon design, which was far from reality, since the colors originally used were time-specific snapshots of heat/density indexes. Reply Alex Wellerstein says: September 5, 2024 at 5:05 pm That’s not how the DOE goes about thinking about these things. Any tech that works, even if it is out of date, is still something that they generally want to keep under wraps if possible. They’re still concerned about releasing information about the Little Boy and Fat Man bombs — not because they’re what any other state would build, but because they worry about non-state actors and other low-tech possibilities. Reply Thomas says: September 5, 2024 at 5:39 am I think you’ve covered all possibilities and either it is gross negligence or misdirection, but like you said a blank space would be better than what ever this is… Did you try and contact kfalvin@sandia.gov at all about this? Not sure in what relation they are to the topic but the contact’s right next to the graphic so maybe they know something about this… ? Reply Alex Wellerstein says: September 5, 2024 at 5:06 pm I haven’t — I wouldn’t really expect a reply, to be honest. They don’t like to answer that kind of question — “no comment” is usually the policy on such things. I suspect they would say that it is not classified but not elaborate much beyond that. Reply Leave a Reply Name (required) Mail (will not be published) (required) Website XHTML: You can use these tags: Alex Wellerstein is a historian of science and nuclear weapons and a professor at the Stevens Institute of Technology. He is also the creator of the NUKEMAP. This blog began in 2011. For more, follow @wellerstein. Want more nuclear secrecy content? Check out my book: Restricted Data: The History of Nuclear Secrecy in the United States (University of Chicago Press, 2021). I also have a new blog/newsletter which updates much more regularly: Doomsday Machines Post-Apocalyptic Road Trips, End of the World-Building, and Interesting Times. A blog about how we think and have thought about end of the world, in both fact and fiction. Search Search for: Pages About me About the blog Post archives Articles and appearances Visualizations Document list Resources for Teachers, Students, and Researchers Projects Doomsday Machines NUKEMAP Oregon Road '83 Restricted Data: The History of Nuclear Secrecy in the United States (2021) Recent posts Did Sandia use a thermonuclear secondary in a product logo? Announcing DOOMSDAY MACHINES Henry Stimson didn’t go to Kyoto on his honeymoon Deconstructing “The Doomsday Machine” – Part 1: The Question of Memory Oppenheimer: Vacated but not Vindicated Did the Japanese offer to surrender before Hiroshima? (Part 2) Did the Japanese offer to surrender before Hiroshima? (Part 1) NUKEMAP and the Ukraine–Russia war (so far) 10 years of NUKEMAP Surely You’re Joking, Comrade Beria! Post categories ► Post tags ► E-mail subscription Enter your email address to subscribe to this blog and receive notifications of new posts by email. You can unsubscribe anytime. Email Address Subscribe Recent posts from DOOMSDAY MACHINES Cinéma verité, cinéma mort September 3, 2024 Famished barbarians August 27, 2024 How much time will our civilization survive? August 23, 2024 The perfect horror of Chesley Bonestell's nuked New York August 21, 2024 Pantex employee photos, 1980s August 13, 2024 Why Oregon? Why 1983? Why a game? Why anything? August 9, 2024 Strange games August 6, 2024 Survival of the Relocated Population of the U.S. after a Nuclear Attack, 1976 August 1, 2024 Lord Byron's \"Darkness\" July 31, 2024 The Big Board July 25, 2024 All text copyright (©) 2011-2024 by Alex Wellerstein, unless otherwise specified.",
    "commentLink": "https://news.ycombinator.com/item?id=41463809",
    "commentBody": "Did Sandia use a thermonuclear secondary in a product logo? (nuclearsecrecy.com)482 points by terryf 11 hours agohidepastfavorite159 comments gnfargbl 8 hours agoWhat is it that the author thinks is particularly unusual about this image? Pretty much every schematic of a Teller-Ulam type weapon -- a schematic which you will find in every introductory Nuclear Physics textbook -- shows a large cylinder with a spherical fission device at the top and a cylindrical fusion device at the bottom, plus some FOGBANK-type material of unconfirmed purpose. This image looks exactly like those schematics except that someone has imagined some little channels which look like they're intended to move energy from the primary to the secondary. Without detailed simulation and testing, a prospective weapons designer has no way of knowing whether those channels are representative of a real weapon, or just a superficially plausible hallucination. Overall this looks like someone asked a physics undergraduate to spend an hour imagining roughly how the well-known schematic might be fitted inside a real warhead case. It probably is exactly that. I can't imagine that showing it to the North Koreans advanced their nuclear programme by any more than fifteen minutes. reply defrost 8 hours agoparent> What is it that the author thinks is particularly unusual about this image? In two decades of crawling through most of the declassified public nuclear material from the US nuclear weapons program, some exposure to classified material, and numerous hours of interviews with working and retired nuclear scientists he believes it's the single most detailed schematic of an actual specific type of warhead he's seen so far. https://blog.nuclearsecrecy.com/about-me/ https://en.wikipedia.org/wiki/Alex_Wellerstein As he's blogging about this it's almost certain he has had real current working nuclear weapons experts from his contact list read the advances and not disagree. Correct or not, it's not a casual random thought from someone with no exposure to such diagrams. reply gnfargbl 8 hours agorootparentOK, but my question remains: what is it that the author thinks is particularly unusual about this image? I'm not a nuclear scientist, but I did study nuclear physics to master's level. To my eye, there's nothing at all interesting about this image. It looks like informed speculation. Without any confirmation that this is a real weapons design (and I see no reason at all to believe it is) then it tells us absolutely nothing which hasn't been in the public domains for decades. > As he's blogging about this it's almost certain he has had real current working nuclear weapons experts from his contact list read the advances and not disagree. That seems extremely unlikely to me. People who have held the appropriate clearance to verify whether this is or is not representative of a real weapon, do not tend to casually liaise with someone who has spent their career attempting to prise open that veil of secrecy. In fact, their own careers and liberty depend on not making such personal connections. reply next_xibalba 3 hours agorootparent> what is it that the author thinks is particularly unusual about this image? The level of detail, particularly the articulation of components/subsystems (primary, secondary, radiation case, interstage medium, tamper, fusion fuel, and a \"sparkplug\"). All according to the article. Per author, DoE has very strict guidelines on the depiction of nukes, and this image appears to violate those guidelines. The official depictions are often just simple shapes, like \"two circles in a box,\" that do not convey any meaningful information about weapon design. I am speculating here, but it seems like DoE must believe that anything beyond simple shapes may provide bad actors (i.e. anyone but US Govt and allies) clues as to how to build a thermo-nuke. reply gnfargbl 2 hours agorootparent> I am speculating here, but it seems like DoE must believe that anything beyond simple shapes may provide bad actors (i.e. anyone but US Govt and allies) clues as to how to build a thermo-nuke. And with good reason: https://www.theguardian.com/world/2003/jun/24/usa.science It's a bit like the Egg of Columbus. Doing it the first time needs a team of visionary geniuses, but once the trick is known to work then even us pedestrians could manage it given enough time and resources. reply bobthepanda 26 minutes agorootparentthe problem is usually getting the fissile material. as far as non-state actors go though, other types of WMD are probably more attainable. Aum Shinrikyo is probably the most infamous example where a cult manufactured multiple chemical weapons. https://en.wikipedia.org/wiki/Aum_Shinrikyo#Tokyo_subway_sar... reply kstrauser 2 hours agorootparentprevConclusion: that's a diagram of the obvious approach to building a thermonuclear device, which happens to be completely wrong for classified reasons, and if you pursue this design you're going to waste a decade before you figure out why. reply pests 56 minutes agorootparentThe blog goes into detail about how releasing any wrong information or misinformation about a secret, still defines the bounds and brackets the real information, and allows eliminating possible options (as no agency would reveal the truth.) If that was the case, an actor could go \"this is obviously not the way to build this, lets move on\" so in a way, you have sped up the development. Just like saying, \"We have 100,000 nukes\" (a lie), everyone knows its a lie, which means we DO NOT have 100,000 nukes, as we wouldn't reveal the truth. Enough of these little \"misinformations\" get released, the closer to the truth someone can get. reply tsss 1 hour agorootparentprevMore likely is that the obvious approach is also totally the right approach and anyone with the relevant education could easily come up with it themselves, but the US government still censors it out of security theatre. reply Titan2189 1 hour agorootparentprevI would ask you to elaborate, but I guess that'd be pointless reply kstrauser 36 minutes agorootparentI don't work in or around this field and never have. You have as much knowledge about it as I do. That was just my interpretation of the situation, based on watching too many movies. reply forgot-im-old 2 hours agorootparentprevThe author should look into https://www.castelion.com/ a company started by SpaceX employees and with deep connections to Elon's Starlink and Strategic Defense Initiative. They have some interesting images. reply next_xibalba 2 hours agorootparentLink? I can't find any images that articulate a nuclear warhead like the one in OP's link. reply tgsovlerkhgsel 4 hours agorootparentprev> OK, but my question remains: what is it that the author thinks is particularly unusual about this image? This is explained in the blog post: Publications generally avoid going anywhere near that level of detail, even if not representing actual/accurate data (to avoid the appearance of leaking anything sensitive even if it actually isn't - as the post explains). reply ethbr1 2 hours agorootparentAka most of Congress doesn't have a background in nuclear physics but does want airtime. And everyone reacts when someone yells \"Nuclear secrets!\" reply defrost 7 hours agorootparentprevAs nmadden noted there's a lot of detail in the article . > That seems extremely unlikely to me. None the less his nuclearsecrecy blog has been about for many many years and he's had a great deal of contact with people who have walked up to the line. It's not that uncommon for historians to have neither confirm nor deny but we can understand various silences relations with experts - even the OG Manhatten Project had embedded historians and archivists who toed the line on handling and preserving materials and held long meetings on what to releasenot release and when. There are even a few DoE employed HN users here who know their areas of expertise and comment right up to the point where they shut up (an often shut downchange accounts) - they don't say what they shouldn't but they have chatted until they don't anymore .. which is interesting in itself. reply gnfargbl 7 hours agorootparentThere's a lot of detail about why the author thinks it is notable that Sandia released this image. There's very little about what it is in this image itself that the author finds interesting, save for some comment about a dip which could be intended to focus neutron flux from the primary to the secondary. I feel that's the kind of thing an appropriate undergraduate would imagine in a short amount of time. reply rsfern 5 hours agorootparentI think you’re just looking for the surprise factor in the wrong place. The notability is all about Sandia’s public release criteria, which are pretty much orthogonal to whether or not the information is publicly known. I don’t think the author finds any particular detail interesting or new in and of itself, they even compare to other public illustrations that have the kind of detail you are talking about. reply renhanxue 3 hours agorootparentprevThe author is a historian whose main published work is the book Restricted Data: The History of Nuclear Secrecy in the United States. He isn't very interested in the information itself; he's interested in where it comes from and in the process that led to its release. It's notable not because it contains interesting information, it's notable because it seems like it might represent a radical break with established patterns in US government procedures with regards to restricted data (which is a special and very weird kind of classification that only applies to nuclear secrets). In other words: the author is interested in the institutions and policies that manage nuclear secrets, not so much in the secrets themselves. In a different post[0] regarding a fumbled redaction that released similar information about what a warhead looks like, he had this to say: > It’s also just not clear that these kinds of [declassification] mistakes “matter,” in the sense of actually increasing the danger in the world, or to the United States. I’ve never come across a case where some kind of slip-up like this actually helped an aspiring nuclear weapons state, or helped our already-advanced adversaries. That’s just not how it works: there’s a lot more work that has to be done to make a working nuke than you can get out of a slip-up like this, and when it comes to getting secret information, the Russians and Chinese have already shown that even the “best” systems can be penetrated by various kinds of espionage. It’s not that secrets aren’t important — they can be — but they aren’t usually what makes the real-world differences, in the end. And these kinds of slip-ups are, perhaps fortunately, not releasing “secrets” that seem to matter that much. > If anything, that’s the real critique of it: not that these mistakes happen. Mistakes will always happen in any sufficiently large system like this. It’s that there isn’t any evidence these mistakes have caused real harm. And if that’s the case… what’s the point of all of this secrecy, then? > The most likely danger from this kind of screw up is not that enemy powers will learn new ways to make H-bombs. Rather, it’s that Congressmen looking to score political points can point to this sort of thing as an evidence of lax security. The consequences of such accusations can be much more damaging and long-lasting, creating a conservatism towards secrecy that restricts access to knowledge that might actually be important or useful to know. [0]: https://blog.nuclearsecrecy.com/2021/05/17/how-not-to-redact... reply scubbo 2 hours agorootparentprev> walked up to the line I'm not familiar with that idiom, and searching for it only gives me \"Walk the line\" - what does it mean? reply MereInterest 1 hour agorootparentI read it as being related to the \"line in the sand\" idiom. There exists some set of rules, the \"line\". Exactly what is and isn't allowed under those rules is a bit arbitrary, like the exact location where you would draw a line in the sand with your finger. What matters is that the line has been drawn, and everybody knows that the line may not be crossed. Under that metaphor, a person may stay very far from the line, to avoid accidentally stepping over it, or they may walk right up to the line. Metaphorically, the former would be a person who refuses to answer any questions about nuclear secrets, regardless of whether the question can be legally answered. The latter would be a person who knows exactly what can be legally answered, and will give as full of an answer as is allowed. They know where the line in the sand is, and have walked up to the line. reply Merad 1 hour agorootparentprevTo \"cross the line\" means that you went too far, in this context meaning that someone revealed secrets or otherwise talked about things that they shouldn't reveal. So to walk up to the line means that the person was willing to talk about the topic or share their knowledge, but did so without \"crossing the line.\" reply MadnessASAP 1 hour agorootparentprevIt means going to the limit of what is allowed, the line represents some limit/law/threshold that cannot be crossed. In this case the veil of secrecy that separates what is/is not public about nuclear weapons. Normally you would stay well away from said \"line\". Occasionally though someone may \"walk\" right up to the \"line\" but no further. You can take it to mean that someone knows something secret but is carefully only talking about what isn't secret. The risk is that they might inadvertently reveal some information of what is beyond the line. reply fragmede 1 hour agorootparentprevChatGPT's really good for that kind of a thing, but in this case it's a saying popularized by a Johnny Cash song about staying loyal and committed to his wife while being on the road and facing temptation. reply morpheuskafka 3 hours agorootparentprev> There are even a few DoE employed HN users here who know their areas of expertise and comment right up to the point where they shut up (an often shut downchange accounts) It seems like one could pretty easily build a database and track online commenters that are government affiliated. I've seen several on reddit from various three letter agencies (see r/TSA, r/1811, r/securityclearance, r/cbpoapplicant/). They usually try to self-limit what they share, but inevitably say things that aren't approved to be public. If you gathered a database of posts across these forums, it would be easier to reconstruct info across different sources. Regularly scraping the site and flagging whatever gets deleted by the mods to read is also a good strategy, as they do often remove posts for being too sensitive. You could also identify patterns of content they engaged with that resulted in information disclosure. For example, there used to be a CBP officer on Reddit that had offered on at least one occasion to look up someone's PASSID in their internal systems because their GE application had gotten stuck in processing. Someone could make a similar post to solicit them to \"help\" them with a similar situation as a means of info gathering. As you said, what they don't share is often informative as well. For example, someone asked that account what it meant when the officer said they \"had three BTPs\" and sent them to secondary; his response was that it was too sensitive to disclose. I can't find the term in any public docs, so the existence of this procedure itself is info that could be valuable to a threat actor. They could also just try posting about the same thing until someone different reveals slightly more info. These internal acronyms can also be used as a shibboleth when posting to subconsciously make people more comfortable sharing info in response. If the term is internal, and you ask a question to a \"fellow employee\" online, they may disclose things that they think you already know. You can find a lot of info about the systems they use in public PIA/SORN notices. Unclassified codenames can also be used as a Google search tactic to uncover content posted by insiders and filtering out news articles and other public results. For example, this Quizlet user is easily searchable given the plethora of military acronyms, and contains information about the location of wiring inside a naval facility and the structure of classified satellite networks: https://quizlet.com/578117055/tcf-specific-flash-cards/ , https://quizlet.com/414907821/eiws-study-guide-here-it-is-bo..., https://quizlet.com/463959814/scif-flash-cards/. Now Google some of those terms and find more Quizlets: https://quizlet.com/593984066/osi-308-odin-sphere-enclaves-f..., https://quizlet.com/595864454/transport-layers-flash-cards/. This one has info about hidden security features on a USAF ID badge authorizing access to parked aircraft (logo mistakes and base name spelled with 1 for L): https://quizlet.com/763351519/response-force-member-knowledg.... Even detailed descriptions of agency procedures by the public is valuable, if summarized and put into a database. Inevitably, things are overheard or observed each time one interacts with security forces. Everything from their facial expression, how much they are typing, etc. can reveal how you are perceived. On Chinese social media, for example, there is a lot of discussion of US immigration procedures and which ports/offices are perceived as most strict. One could run statistics based on others posts about visa and entry denials to identify weaknesses and reconstruct non-public procedures. For example, this thread discusses a TSA procedure I saw myself: https://old.reddit.com/r/tsa/comments/14l1ca1/what_is_the_bo.... One respondent says it is sensitive, and another tries to deflect the question by saying it is to \"weight down light things\" while also admitting it \"distinguishes the bag for the X-ray operator.\" It's pretty obvious that the \"paper weight\" (the code name which someone helpfully shared) contains the image of a prohibited item (or a known pattern) to test that the X-ray operator is paying attention; the tray was sent to secondary but not actually searched beyond removing the object. This comment (https://www.reddit.com/r/tsa/comments/1clxfn8/comment/l2wox2...) indirectly confirms that TSA does collaborate with law enforcement to help forfeit cash which was the subject of a recent lawsuit by the Institute for Justice, by saying \"there was no need to notify anyone because they traveling domestically,\" implying that they do notify LE if international. reply nmadden 7 hours agorootparentprevThe article goes into a lot of detail about why the author thinks its unusual. reply jonstewart 6 hours agorootparentprevRead the article? reply DoneWithAllThat 6 hours agorootparentprevI’m sorry but all I can think of reading your comment is “but why male models?”. reply keepamovin 5 hours agorootparentprevnext [4 more] [flagged] mindcrime 3 hours agorootparent> Struggle to get a nat labs job despite your MPhys was it? There is absolutely no need for that kind of thing here on HN. From the guidelines[1] \"Be kind. Don't be snarky. Converse curiously; don't cross-examine. Edit out swipes.\" [1]: https://news.ycombinator.com/newsguidelines.html reply gnfargbl 4 hours agorootparentprevI'm not contemptuous or mocking, and I'm sorry it came across that way. I am annoyed at having my time wasted by what I feel is a clickbait article. Given the article title, the accusation of straw-manning is really unfair. Your comment would also have been better without the jab; if you're familiar with the field then we both know why I left science for software, and it isn't because of a lack of jobs. reply Cushman 2 hours agorootparentGently: The snark you’re getting is undeserved, but you are doing the “but why male models?” thing. You gotta make a left turn here :) Let’s reset: Hey, did Sandia use a thermonuclear secondary in a product logo? Did they actually? Despite all the reasons they wouldn’t? If they did, why? Was it a mistake or on purpose? Neither one quite makes sense. Those are interesting questions! But there’s no alleged secrets leak, and there’s nothing else that’s interesting about that specific picture. You could say it’s implied somehow, but in that case you really got got by anti-clickbait. “Did Sandia use a thermonuclear secondary in a product logo?” is the whole riddle, and the answer is the whole blog post. reply matthewmcg 7 hours agoparentprevHe says it a few paragraphs in: “To give a sense of how strange this is, here is the only “officially sanctioned” way to represent a multistage thermonuclear weapon, according to US Department of Energy guidance since the 1990s: Figure 13.9, “Unclassified Illustration of a Staged Weapon (Source: TCG-NAS-2, March 1997),” from the Nuclear Matters Handbook 2020 (Revised), published by Deputy Assistant Secretary of Defense for Nuclear Matters. Two circles in a box, maybe inside of a reentry vehicle. That’s it. Nothing that gives any actual sense of size, location, materials, physicality.” reply gnfargbl 7 hours agorootparentIf the story here is that the US DoE is now implicitly confirming common public-domain knowledge that can be found immediately on Wikipedia then sure, that's a story of minor interest. That story is nothing like the title of the blog, though! reply bathtub365 3 hours agorootparentOne thing to keep in mind is that the author’s interest lies in the nature of nuclear secrecy, and not necessarily the secrets themselves. It’s a subtle distinction but I think explains why the author finds the fact that this type of diagram was officially released by a national lab interesting, even if the information has previously made its way to the public domain in other unofficial ways. reply lazide 4 hours agorootparentprevspeculation can be found on Wikipedia, perhaps accurate speculation, perhaps not. DoE contractors leaking details that confirm that speculation would indeed be a big deal, and might well save adversaries some real time and mistakes they’d otherwise make. reply fragmede 1 hour agorootparentOr it's a psyop designed to make adversaries waste their time on a design that couldn't work. reply lazide 1 hour agorootparentSpooks man, goddamn spooks! reply snowwrestler 3 hours agorootparentprevUnless he is actually employed in the classification process inside these agencies, he does not know everything that is officially sanctioned. It’s all guesswork, from the outside. reply SiempreViernes 8 hours agoparentprevThe unusual thing, as stated repeatedly throughout the article, is that this is published by people who are under one of the strictest censorship systems in the world, a system that explicitly exist to prevent the publication exactly this sort of thing. reply gnfargbl 7 hours agorootparentYes. And as you'll know, since we both read the article, the author mentions what I believe to be the correct conclusion: > The “obvious” answer, if my above assertions are true, is that it must not actually represent a thermonuclear secondary. [...] It could be some kind of pre-approved “unclassified shape” which is used for diagnostics and model verification, for example. There are other examples of this kind of thing that the labs have used over time. That is entirely a possibility. However, he then goes on to immediately reject this \"obvious\" answer, because he thinks the well-known schematics of fission-fusion bombs give the appearance of a classified shape, and because he feels it is \"provocative\" for a government weapons lab to show a mock up of a well-known schematic in one of their publications. Those positions seem very weak to me. reply proto-n 5 hours agorootparentHe later finds basically the same object with the caption \"The multiple components of a nuclear weapon body are highlighted in this intentionally simplified mesh\" from another publication of Sandia, making that theory kind of unlikely reply krisoft 3 hours agorootparentI don't understand that conclusion. That sentence, in my mind, makes that conclusion more likely. They say it is an intentionally simplified mesh. Which to me means it is not the real deal. So why does this sentence makes you think the theory is unlikely? (Or what is the specific part of the theory you think it makes it unlikely?) Genuinely curious. reply proto-n 2 hours agorootparentI took the quote [1] to basically mean \"we might think this is a nuclear warhead, but in fact it is not, rather it is some kind of random test object used to demonstrate the software\". Obscure part of a washing mashine, random geometric shape, etc. [1] \"The “obvious” answer, if my above assertions are true, is that it must not actually represent a thermonuclear secondary. [...] It could be some kind of pre-approved “unclassified shape” which is used for diagnostics and model verification, for example.\" reply krisoft 2 hours agorootparent> Obscure part of a washing mashine, random geometric shape, etc. Oh i see what you mean. I took the theory to be that it is looking like a nuclear warhead but it doesn't have the right dimensions, or even the right arrangement of the components. Kind of like the difference between the real blueprints of a submarine (very much classified) or the drawing evoking the same feel but drawn by someone who has never seen the inside of a submarine nor does really know any details (not classified). reply mhh__ 7 hours agoparentprevPhotos of even a hint of the inside are rare enough that he has another article show (in effect) a hint of an imprint from an old photocopying mistake. I also doubt it's useful, but Ted Taylor could supposedly walk around a room full of nukes and guess based on the shape of the casing what was unique about a design reply bryant 6 hours agoparentprevFind the paragraph that says \"so this is awfully strange\" and start there. It's a detailed analysis of the graphic in question, and what's \"unusual\" about it is that this graphic, with the detail identified by the author, has been published at all. The next paragraph details what the author would have expected to be published by comparison. And then figure 13.9 is what the DoD expects to see published at all. reply evo 1 hour agoparentprevI feel like the most novel aspect of this image is an implication of the shape of the reflective casing at the far rear of the device--it seems to suggest a parabolic \"shaped charge\" sort of focusing element that likely helps to boost the neutron flux and initiate the \"spark plug\" from the rear at the same time as from the front. reply tivert 4 hours agoparentprev> What is it that the author thinks is particularly unusual about this image? Read the article and look at the \"officially sanctioned\" diagram. This looks like the tl;dr of what he things about this: > Anyway, I’m just surprised the DOE would release any image that gave really any implied graphical structure of a thermonuclear secondary, even if it is clearly schematic and meant to be only somewhat representative. It’s more than they usually allow! This linked post of his about an earlier redaction mistake also makes it clear (https://blog.nuclearsecrecy.com/2021/05/17/how-not-to-redact...): > ...but we’re given a rare glimpse inside of modern thermonuclear warheads. Now, there isn’t a whole lot of information that one can make out from these images. The main bit of “data” are the roughly “peanut-shaped” warheads, which goes along with what has been discussed in the open literature for decades about how these sorts of highly-efficient warheads are designed. But the Department of Energy doesn’t like to confirm such accounts, and certainly has never before let us glimpse anything quite as provocative about these warheads. The traditional bomb silhouettes for these warheads are just the dunce-cap re-entry vehicles, not the warheads inside of them. reply ianburrell 3 hours agoparentprevLow radiation steel is less needed because new steel is lower radiation. The atmospheric radiation level has dropped and steel making uses oxygen instead of air. Presumably there are uses that need old steel but they are probably smaller amounts. reply scottlamb 3 hours agorootparent> Low radiation steel is less needed because new steel is lower radiation. The atmospheric radiation level has dropped and steel making uses oxygen instead of air. > Presumably there are uses that need old steel but they are probably smaller amounts. This comment seems out of place? It would have made sense as a reply to a different comment thread in a different article a couple weeks ago: https://news.ycombinator.com/item?id=41323780 but I don't get how/why it ended up here. No one was talking about steel at all, as far as I can see? edit: oh, there's another article today where folks are talking about low-background steel. I assume this comment was just supposed to go there. https://news.ycombinator.com/item?id=41436009 reply ianburrell 1 hour agorootparentI meant the other post about wrecks. reply mannyv 1 hour agoparentprevThe best guess about fogbank is that it’s plutonium suspended in aerogel. reply thadt 4 hours agoparentprevNot that the image itself is particularly useful or descriptive (it's not), but because the review office is rather quite conservative when deciding what to release, and anything suggestive of a real device is usually right out. In this case, the initial approval was probably an anomaly. I suspect that the reviewers looked at it that day and thought \"eh, this is so far from reality that it's just not a big deal\", and let it go. Any other day or set of reviewers and it probably would have been kicked back. It would be interesting to know the story around that approval, and what the fallout was, if any. Any further use isn't very surprising. Once it is approved and in the wild, re-using it is not really a problem (especially if being run through the same office for approval again). reply taneliv 7 hours agoparentprevEven so, it would be very unusual if I understand the author correctly: > ... at least historically, the Atomic Energy Commission and its successor organizations have frowned on disinformation and misinformation for other very practical reasons. If you release a lie, you run the risk of someone noticing it is a lie, which can draw more attention to the reality. And even misinformation/inaccuracy can put “brackets” around the possibilities of truth. The goal of these organizations is to leave a total blank in the areas that they don’t want people to know about, and misinformation/disinformation/inaccuracy is something other than a total blank. In other words, the author expected to see a previously familiar schematic or nothing. This is clearly not nothing, and also not a familiar schematic, hence the surprise. reply snowwrestler 3 hours agoparentprevThe article is not about warhead technology, it is actually about the internal culture of how the military and nuclear-adjacent agencies classify and communicate about nuclear technology. But here’s the thing: that internal culture is just as opaque to outsiders as the technology itself! No outsider actually knows how the internal folks think, feel, and decide about little graphics or schematics or whatever. They’ve just inferred some heuristics from incomplete data. And this is basically just saying “this little graphic seems to violate my heuristics.” Which makes for interesting reading, but there is no real actual objectively verifiable content in this article. Betteridge’s Law tells us the answer to the headline question is always “no.” And in this case I think common sense agrees: Sandia Lab probably did not give the entire thermonuclear ballgame away with a logo graphic. reply freestyle24147 1 hour agoparentprevPlease provide even one link to an image or book or anything that proves what you're saying is true. The fact that this is the top comment is troubling, since your question is answered throughout the article. The thing you're claiming (basically that imagery like this can be found all over the place) is so easy to prove, one wonders why you haven't done it here or in any of your other comments. reply splonk 6 minutes agoprevThe author is u/restricteddata on Reddit. This appears to be the thread that inspired this post: https://www.reddit.com/r/nuclearweapons/comments/1f85zpi/mk4... reply simplicio 36 minutes agoprevI've worked on (unrelated to nuclear stuff) computer simulation projects for the Navy where they had standard, notional models of the battleship which had the same sort of general properties you'd expect a battleship to have, but wasn't based on the design of any real battleship, so they could share them with researchers to develop their codes on without having to worry about revealing classified details. Wonder if this isn't something similar, if the DoE has some sort of \"standardized notional warhead\" design they can use to give to outside researchers without having to give every post-doc and grad-student a security clearance. reply walrus01 33 minutes agoparentDo you actually mean battleship, or frigate, corvette, aircraft carrier, etc? Battleships in the sense of the Iowa class and similar haven't been a thing in the US Navy for a very long time, unless you were working on blast damage/effect simulations in the 1980s when Reagan reactivated them for a short time. reply Joking_Phantom 5 minutes agorootparentIt seems likely that theoretical work would still be done on battleships, after we stopped using them in the real world. reply bee_rider 5 hours agoprev> This is the kind of thing that I think people assume the government labs might do, but in my experience, is pretty unusual and pretty unlikely. In general, you have to remember that the national laboratories are pretty, well, boring, when it comes to classified information. They want to be boring in this respect. They are not doing cloak-and-dagger stuff on the regular. They’re scientists and engineers for the most part. These are not James Bond-wannabes. The Sandia folks may be extra special, it is a pretty famous place. But engineers are people first of course, so lots of variation. And also, some are super serious of course, but there are hacker tendencies, playful tendencies. I bet if some intelligence agency folks wanted to, they could find some engineers out there who’d be receptive to this sort of thing. If it is a fake, known-stupid design, including it would be a funny prank that wastes the time of people that might want to nuke us, right? reply csours 1 hour agoparentI visited Los Alamos earlier this year and talked to a retired materials scientist at the visitor center. He said that we have lots of books about the science and scientists that worked on the bomb during WWII, but very little mention of the engineering or engineers - and that's largely because it's extremely classified. The scientists can talk about most of their work because it's too broad to give any real aid to the enemy, but the engineers can't because they could REALLY speed up someone else's weapons program. reply writeslowly 4 hours agoparentprevSomebody (probably a programmer or engineer) took the time to create all of that rad 3D word art, multicolored pie-chart, and the mountain logo, it's not hard to imagine they'd also throw in an eye-catching fake nuclear warhead for fun. reply zubiaur 5 hours agoparentprevExtremely boring, bureaucratic and inefficient. With a few exceptions, I guess they are a way to have Phds on retainer. reply mjevans 10 hours agoprevThat thing is supposed to be a logo? I'm reminded of CGP Gray's videos about flags. https://www.youtube.com/user/cgpgrey/videos Like this one https://www.youtube.com/watch?v=l4w6808wJcU About US state flags reply chefandy 4 hours agoparentI've done branding and identity design in the past, and got university training to do it. I've also worked as a developer and contributed a ton to FOSS projects. That an engineering organization thinks this is a product logo is entirely unsurprising. I'll bet their interfaces are really something. The most frustrating thing about being a designer in those environments is the dunning-krueger cockiness many technical people have in their understanding of design, which they usually believe is purely an aesthetic consideration.* It's not even like a junior developer trying to 'correct' a senior developer about coding practices in a dev meeting— the better analog is a designer that watched a half hour Coding for Designers talk at a conference trying to correct a senior developer about coding practices in a stand-up, because they'd never have been invited to the dev meeting to begin with. If there were only designers in that meeting— and they likely find the other designer more credible because they jibe with their perspective, don't realize how important the developers input is, and might have watched that same conference talk— that could damage a project. In my experience, designers are way more likely to be solo in meetings with developers and the echo chamber of developer 'expertise' on design drowns out actual professional design expertise. In most FOSS projects, is bleaker than that because designers don't even bother trying. * though completely out-of-context \"rules\" born from Tufte quotes aren't uncommon. In art school, we were told that we need to understand the rules in order to know when to break them. Imagine someone who'd never driven before that memorized a few pages of the driving manual calling you an unqualified driver because your actions didn't comply with the letter of one page they memorized even if it was qualified by another, or required for safety. reply permo-w 9 hours agoparentpreva product logo, according to the title, although that may be a hint of editorialising from the author. reply PaulHoule 7 hours agorootparentIt really is, it’s just much more graphically detailed than the usual product logo, probably because it was designed by nuclear weapon designers and not by professional graphic designers. reply hbossy 8 hours agoprevI bet it's an inside joke, like Lenna.jpeg. Some outdated / test / dead-end, or otherwise harmless project put there as a wink to everyone involved in the industry. Maybe it's something an intern ruined on his first day and made entire lab work on for three weeks without realizing? reply taneq 6 hours agoparentThat was my first guess, that this picture is in the first page of image search results for \"nuclear detonator\" or whatever. reply BWStearns 2 hours agoprevTangentially: I wonder if the checker badge is a visual pun on the Arms and Influence cover. https://www.amazon.com/Arms-Influence-Preface-Afterword-Lect... reply _n_b_ 1 hour agoparentI would bet a few dollars that no Facility Security Officer (the name for people who manage security programs for defense contractor, despite sounding like a Sunday name for ‘guards’) in the entire NNSA complex has ever read Arms and Influence. That’s not quite their demographic profile. reply BWStearns 18 minutes agorootparentI'd take the other side of that bet. I've met some with pretty surprising backgrounds. reply karaterobot 57 minutes agoprevOne thing he doesn't consider: Perhaps if they do not call it a nuclear warhead, or place it in the context of a larger drawing that tells you it's a warhead, having a sort of blobby, colorful model shape is considered plausibly nonsensical enough that it doesn't matter to the censors. reply kingkongjaffa 9 hours agoprevBasically 0 CAD models you see with color coding and a mesh are actually accurate. In order to mesh the geometry for finite element analysis, the geometry virtually always needs to be defeatured. So the cross sectional CAD model here is a nice curiosity but basically useless for any reverse engineering purposes which is the key reason this stuff is kept secret. reply thrwooshfem 3 hours agoparentSandia FEM is using the different blocks (colors) to represent different materials. This is pretty common in a multi physics finite element program. This story is probably nothing interesting because this went through all the public use approvals needed for public presentations and being available on osti.gov. It is probably just a toy test problem used on a capabilities logo for Sierra. Maybe it comes from some sort of integration test that is easier to run than the actual problem. reply weinzierl 9 hours agoparentprevIn Germany we say \"The DIN knows non color\". DIN is our standardization organization and informally also how their documents are called. I did finite element model preparation for a living many year ago and it did not only involve heavy defeaturing but interestingly also remeshing with quads. Renderers love triangles, FE solvers love boring quads. reply krisoft 8 hours agorootparent> Renderers love triangles, FE solvers love boring quads. Btw even in Blender (which is pure visual rendering) people prefer quads. The common wisdom is that you should keep your topology quads with nice rectangle-ish aspect ratios if you can at all. It is not that triangles don't work, but they have a tendency to do visually unpleasant silly things when animated or sculpted or subdivided. reply USiBqidmOOkAqRb 6 hours agorootparentThe \"quads only\" rationalizations come off as quite cargo-culty. Sure, edge rings won't have dead ends, and that's useful when adding edge loops to increase detail, but doesn't necessarily mean the topology is of high quality. Using only quads some cursed helix type topology can be constructed. First thing subdivision will do on non-quads is ortho(1) operator, so a nice averaged vertex in the middle will be added. High side count cylinders will have weird saddles around caps, but that's due to subdivision being wrong tool for the task. Quads can be abused to look bad too. If a mesh looks bad, it's a bad mesh. If animated mesh looks bad, it's bad rigging and skinning. Knowing \"this one industry secret\" won't fix those. 1: https://en.wikipedia.org/wiki/Conway_polyhedron_notation#Ori... reply cherryteastain 9 hours agorootparentprevMost 3D meshes will have a combination of hexahedral and tetrahedral elements anyway so the surface will be a combination of trangular and quadrilateral elements. Accuracy and convergence wise, it doesn't matter as much as polynomial order/time step size/element size. reply albrewer 2 hours agorootparentprev> FE solvers love boring quads That's because, in a mathematical sense, triangular and tetrahedral meshes aren't able to be as accurate as quickly. reply kingkongjaffa 9 hours agorootparentprevyeah there are several adaptive meshing techniques that use a mixture nowadays, imagine a bar with a hole bored through it, you might use quad meshes for the majority of the bar and then switch to tetrahedral meshes close to the bore hole to better model the curved geometry of the hole, and increase the node density in high stress concentration regions for a more accurate simulation. reply buran77 9 hours agoprevI see a few commenters think the big chart/diagram in the first picture is the one being discussed. It is not, it's the rightmost slice (\"Salinas\") of that infographic which shows something like a warhead. It's shown blown up (pun intended) in the second picture of the article. reply smiley1437 5 hours agoprevAny chance it's a legitimate screw up but they don't want to cause any Streisand effect? reply aidenn0 2 hours agoparentThat was my first thought too. If you screw up once, and then redact it in the future it's screaming \"Hey everybody look here, there's classified information\" reply QuadmasterXLII 8 hours agoprevSome people are confused why this could be a big deal. An analogy: on GitHub, if you echo a GitHub access token in an action’s log, it will be automatically censored. This post would be like noticing that someone’s action step is just named ghp_1ae27h… and that the name isn’t censored, and speculating on what that says about the token-censorship algorithm reply ajsnigrutin 7 hours agoparentSame on hackernews, if you type your password here, it is printed like this: **** instead of clear text (\"h u n t e r 2\" spaces added for it to not be censored). reply eszed 6 hours agorootparentKey point: if you try it yourself, it will be in clear-text for you (you already know your password, so there's no issue), but everyone else will only see \"***\". reply Reubachi 5 hours agorootparenthunter2 mods, please allow this chain to remain as original runescape \"hacks\" are about as hckrnws as any other content. reply Izkata 1 hour agorootparentIt's from IRC, here's the original: https://bash-org-archive.com/?244321 reply shahzaibmushtaq 6 hours agoprevIn the era of CDs/DVDs and according to year 2007 perspective, these types of infographic logos were quite common. Other than that, I'm not so sure about the particular design pointed out by the author. reply closewith 9 hours agoprevFor everyone complaining that it's an infographic, not a logo, that's addressed in the article: > It’s literally the logo they use for this particular software package. Which seems to refer to the image of the re-entry vehicle in isolation from the infographic where the author originally found it. reply lupire 5 hours agoparentI don't see that claim supported in the article. reply HelloNurse 9 hours agoprevThis thing could be a test object that doesn't work as an actual nuclear warhead but is similar enough to validate the discussed software: real-world crash tests match software simulations, and being accurate at simulating the dummy is a guarantee of being accurate at simulating classified weapon designs. reply cm2187 8 hours agoparentNo this is an espresso machine! reply schmidtleonard 5 hours agorootparentThat radiation case couldn't focus water through coffee beans let alone X-rays onto a pusher. reply mindcrime 3 hours agorootparentprev> No this is an espresso machine! I don't know... hit it with an HTCPCP request and see if you get back 418 - I'm a Teapot, or not. reply aeonik 7 hours agorootparentprevA snow cone maker! reply eesmith 9 hours agoparentprevExcept as the author commented: > Someone reminded me of something I had seen years ago: the British nuclear program at Aldermaston, when it has published on its own computer modeling in the past, used a sort of “bomb mockup” that looks far more deliberately “fake” than this Sandia one. I offer this up as what I would think is a more “safe” approach than something that looks, even superficially, like a “real” secondary design: > This is called the MACE (Modal Analysis Correlation Exercise) assembly, and was created by the UK Atomic Weapons Research Establishment in the 1990s to serve as a sort of a Utah Teapot of weapons structural modeling: a benign shape that could be used to test aspects of the code that would nonetheless tell you if the code would work for real weapons assemblies. reply lupusreal 8 hours agorootparentThe author doesn't convincingly rule out the possibility that this is what it is. The other possible answers seem less plausible than it being a fake shape for software testing that happens to look fancier than past test shapes. reply eesmith 7 hours agorootparentThe author wasn't trying to be convincing. \"I’m just surprised the DOE would release any image that gave really any implied graphical structure of a thermonuclear secondary, even if it is clearly schematic and meant to be only somewhat representative. It’s more than they usually allow!\" My reply was to point out that the author discussed issues related to HelloNurse's suggestion. reply HelloNurse 7 hours agorootparentThe tone of this kind of article has to be nice and diplomatic, and mistakes need to remain hypothetical and attributed to the largest possible organizational unit (DARPA having surprising policies, not the mechanical finite element simulation software team spreading data they consider harmless). The second object that appears near the end of the article looks like a simplified version of the first with more basic shapes, as if someone was asked by someone else to draw a less suggestive replacement of the original (possibly with the sole purpose of appearing in slides); in a natural design process the cruder design would have appeared first. reply avar 6 hours agoprevLet's assume the schematic depicts a genuine weapon, and that this was a massive redaction screw-up. I think the author is omitting the most likely explanation for why it wasn't redacted in future publications. It took from 2007 to 2024 for someone (him) to publicly notice this. If your job was to censor documents coming out of Sandia National Laboratories, and you screwed up this massively, what's your incentive to call attention to your screw-up? Better to just coast along, by the time you retire or move on to another job your ass is off the firing line. Ditto (but less so) if this was your co-worker or team mate, after all North Korea, Iran etc. already have access to the published document. What could anyone in your organization possibly gain from the ensuing shitstorm of admitting something like that? Has this person worked, well, pretty much anywhere, where people have a stronger incentive to cover their own ass and keep out of trouble than not? Or, that internal report and subsequent shitstorm did happen, but what do you do at that point? Make a big public fuss about it, and confirm to state actors that you accidentally published a genuine weapons design? No, you just keep cropping that picture a bit more, eventually phase it out, and hope it's forgotten. Maybe they'll just think it's a detailed mockup of a test article. If it wasn't for that meddling blogger... Edit: Also, I bet there's nobody involved in the day-to-day of redacting documents that's aware of what an actual weapons design looks like. That probably happens at another level of redaction. So once something like this slips by it's just glazed over as \"ah, that's a bit detailed? But I guess it was approved already, as it's already published? Moving on.\". Whereas a censor would have to know what an actual thermonuclear device looks like to think \"Holy crap! Who the hell approved this?!\". And even then they and the organization still need the incentive to raise a fuss about it. reply kridsdale3 37 minutes agoparentMy experience working for huge orgs where success and failure is many nodes removed from individual actions makes me vote for this as the most likely scenario. reply ggm 10 hours agoprevThe entire half round with an inner core is surely half an explosively compressed primary. And, it's not a \"logo\" it's an infographic. reply dredmorbius 7 hours agoparentnext [–]reply niemandhier 7 hours agoprevPutting a weapon of mass destruction in a logo is tasteless. It’s like advertising with cans of mustard gas. reply ceejayoz 7 hours agoparentYou’ll love the NRO’s mission patches. https://www.theverge.com/2016/6/9/11895496/nro-spy-weird-mis... reply krisoft 3 hours agoparentprevThey build/test/design weapons of mass destruction. What would you advertise a can of mustard gas if not with a can of mustard gas? reply jiggawatts 7 hours agoprevReminds me of another design secret that leaked out because someone published a paper titled something like \"X-ray crystallography of Lithium Deuteride under high pressure.\" People very quickly figured out that this was the source of the D-T fuel in fusion part of the bomb instead of cryogenic D-T liquid. Lithium Deuteride is nasty stuff, but it's a storable solid. When bombarded with neutrons from the fission primary, the Lithium splits and forms tritium, which then combines with the deuterium that was the other half of the crystal. The reason the usage was obvious (from the title alone!) is that very few chemists would care about any property of Lithium Hydride, which is dangerous to handle and has few practical uses. Lithium Deuteride is unheard of in analytical chemistry, and its crystallography under high pressure is totally uninteresting to anyone... except physicists working on atomic weapons. reply sandworm101 7 hours agoprevNo. That is not a nuke. It is a mass simulator, specifically the electronic model of a mass simulator for a warhead. The various colors represent density of material. This would be used during aerodynamic simulations. That is why it is behind the graph about processors. This also explains the simple geometry as keeping things simple reduces the number of calculations. (Note that nuke warheads fall nose-first, the opposite of space capsules. So the dense material is packed in the nose, with the lighter stuff at the back.) The nearby disk looks like a represention of airflow around a falling warhead. They, like apollo, likely had an offset center of gravity that allowed them to stear by rotation, creating the asymetrical airflow shown on the disk. Falling in a spiral also probably frustrates interception. So that whole corner of the image is advertising Sandia's ability to do aerodynamic simulations. reply thedrbrian 58 minutes agoparentNice try Sandia guy who forgot to redact this original picture. reply joegibbs 8 hours agoprevSay if an adversary with a small nuclear program that hasn’t yet achieved a weapon got a hold of this, what kind of impact would that make? reply PaulHoule 6 hours agoparentThere is the fission stage and the fusion stage. The fission stage in this image is not well represented. It is generally known how to make a fission stage similar to the “Fat Man” device but the “Fat Man” device is larger than the whole warhead with both a fission and fusion stage that fits on a Minuteman 3. The fission stage in that warhead has numerous refinements that help miniaturize it, for instance the implosion is probably not spherical so it can fit in the pointy end of the warhead. A really refined modern weapon is packed with details like that. reply schmidtleonard 5 hours agorootparentThe secondary isn't well represented either: that radiation case isn't focusing any X-Rays and the stairstep in the tamper would tear it in two when ablation started. Plus, as you note, the primary is impossibly screwed up as well, with what looks like a single point of initiation and zero details on the boosting. It doesn't just look simplified, it looks like every part has been corrupted with a feature that makes it impossible to mistake for real while being slightly less crude than the \"Mastercard\" or British designs. Besides, real engineering doesn't just need a schematics, it needs details, and some of the missing ones are notorious (FOGBANK) and inherently difficult to figure out with any confidence in the absence of weapons tests (or even more expensive giant buildings crammed to the gills with lasers). So yeah, not very useful to an aspiring designer. I understand the author's surprise but I suspect they really did just become a few notches less crazy about the redundant protection on information that has been public for 30 years. reply PaulHoule 4 hours agorootparentAlso the mental models of proliferation are warped by secrecy. For instance, Iraqis got caught building Calutrons when the official line was to watch out for plutonium reprocessing and centrifuges... Despite the fact that the enriched uranium used for the first nuclear weapon used in war was produced with a Calutron! Anyone responsible who thinks about this stuff, even if they don't have a security clearance, will look into the question of what the ethics are and what the legal consequences of secrecy laws are if you talk about certain things you think about. I had dinner with a nuclear scientist at a conference, for instance, who told me that he hadn't told anyone else about his concern that Np237 was the material that terrorists would most want to steal from a commercial reprocessing facility (if they knew what we knew) and I told him it was no problem because people from Los Alamos had published a paper with specifics on that a few years earlier. I will leave it at that. reply krisoft 8 hours agoparentprevThey would be in possession of an image. It is hard to understand what the author is hand-wringing about. It is not that nobody knows how these weapons are supposed to work. The real barrier is that to obtain the materials necessary you need a big-ish industrial base and if you do that that leaves signatures the relevant agencies can detect. It is not even clear if when he speaks about \"safe\" is he talking about being safe from nuclear proliferation, or safe from clueless bureaucrats causing you legal trouble. reply renhanxue 4 hours agorootparentThe author is a historian who has published a book that is specifically about the history of nuclear secrecy in the United States. Not about the history of nuclear tech or nuclear weapons, about the history of restricted data, the special classification grade for the information. How the classification works and what is considered safe to release and what isn't is in itself one of his main research interests. My impression from his book is that his position on nuclear secrecy is that a lot of it is pointless or outright contra-productive, but that isn't really the point of the blog post. The point of the blog post is that if something has changed about what information is considered safe to release, that is interesting to him. He is more interested in the humans and institutions than in the technology, I'd say. reply implements 5 hours agorootparentprev> It is hard to understand what the author is hand-wringing about. The issue seems to be “Organisations party to classified information have to keep it secret regardless of whether it’s in the public domain”. As an academic historian the author is intrigued by the diagram - was it a mistake or was it authorised as a declassified representation? Either way, the consequences would be of interest. > It is not that nobody knows how these weapons are supposed to work. Optimally small, lightweight, robust, safe, reliable - all sorts of engineering short-cuts or novel techniques … you don’t want to give way accidental insights about the “hows” an enemy hasn’t thought of. reply avar 6 hours agorootparentprevThe \"large industrial base\" is required primarily to highly enrich uranium (or plutonium). A modern fusion bomb requires much less of that than the initial fission bombs. So I don't know how much a state actor could infer from an image like that, if we assume it's a schematic of an actual bomb. But it's just not true that someone in possession of detailed plans for how to construct a bomb isn't put into a much better position. They'll need a much smaller amount of fissionable material than they otherwise would with a cruder design. reply sandos 10 hours agoprevMost likely is that it was deemed simplified enough not be an issue? reply ceejayoz 8 hours agoparentThe article addresses this by giving past examples of what “simplified enough” usually means. They’re much simpler. reply lupusreal 8 hours agoprevProbably the guy who produced that part of the graphic was not told what a thermonuclear warhead actually looks like, because he didn't need to know, so he just whipped up his own idea of it from speculative public images. Knowing that the graphic came from somebody who didn't actually know anything, the censors didn't see the need to worry about it. reply renhanxue 3 hours agoparent> Knowing that the graphic came from somebody who didn't actually know anything, the censors didn't see the need to worry about it. That is not how nuclear secrets work. The US Department of Energy holds that restricted data (a special kind of classification that only applies to nuclear secrets) is \"born secret\". That means, even if you come up with a concept for a nuclear weapon completely independently without ever talking to anyone, it is considered classified information that you are not allowed to redistribute. This doctrine is highly controversial and the one time it has been tried in court the verdict was inconclusive, but to this day it is how the DoE interprets the Atomic Energy Act of 1954. In general this is very precarious to attempt to enforce, of course. If the DoE sues someone because they published their nuclear weapon designs, that'd be seen as a tacit admission that the design could potentially work. Nevertheless they actually did do this at one point (United States v. Progressive, Inc., 1979). reply relaxing 6 hours agoparentprev> Knowing that the graphic came from somebody who didn't actually know anything, the censors didn't see the need to worry about it. That’s not really true. If you manage to independently come up with classified info and release it to the public, you will get a visit from an agency. Overall I think you’re correct. reply AnimalMuppet 6 hours agoprevHeh. Ask my mother about the time that Sandia dropped an atomic bomb casing in the streets of Albuquerque. IIRC the story, this was still during WWII. They were testing the flight characteristics of the bomb casing. It did not contain a core. But it was still extremely classified. They had the test casing in the back of a truck, taking it from Sandia to Kirtland AFB. The truck got in an accident, the tailgate fell open, and the bomb casing fell out and went rolling around in the street. reply dwighttk 7 hours agoprev>That’s where I’ve ended up… Where did he end up? Intentional misinformation? It was definitely not clear but that was the last one he listed… reply virgulino 10 hours agoprevFor anyone interested in the basics of nuclear weapons, I highly recommend the \"Nuclear 101: How Nuclear Bombs Work\" lectures by Matthew Bunn, a man heavily involved in nuclear arms control. His lectures are always highly entertaining, a real pleasure to watch. This is a clip from his lecture explaining the basics of thermonuclear warheads: https://youtu.be/YMuRpx4T2Rw And the full “Nuclear 101” lecture, in two parts: https://youtu.be/zVhQOhxb1Mc https://youtu.be/MnW7DxsJth0 reply nirav72 5 hours agoparentAnother one - fascinating video on how nuclear weapons locking systems work - https://www.youtube.com/watch?v=F1LPmAF2eNA reply sidewndr46 7 hours agoparentprevGiven the nature of nuclear weapons work, isn't anything presented by someone basically speculation? If he actually had the information he wouldn't be able to talk about it. He seems to have been involved at the government level in the storage and handling of weapons, not production of them. reply bitexploder 7 hours agorootparentFun idea, there basically are no nuclear secrets. If you look long enough you can pretty much learn everything except some in the weeds details of the most modern nuclear warheads. My basic premise is all our “enemies” have this info by now and the complexity is actually in building them, not how they work or how to build them. reply jerf 5 hours agorootparentThe hard part has never been the design: 1964, Physics PhD who knew nothing about nuclear physics designs a bomb: https://www.theguardian.com/world/2003/jun/24/usa.science Physics junior in the mid-1970s designs a device good enough to impress Freeman Dyson: https://en.wikipedia.org/wiki/John_Aristotle_Phillips#%22A-B... As search engines continue their trend of considering your search term just a suggestion, I can't pull it up, but there's also a case where a high school physics class decided to try to design one and also came adequately close. The hard thing that is actually the stopper is the enrichment of the relevant materials. The other hard part is getting the best possible yield; there's huge variances in what you get from the same amount of fuel depending on how well you can put it together before it blows itself apart, but that's not a stopper for a terrorist group. Getting to Hiroshima levels is apparently not that difficult, as evidence by the fact it was done so many decades ago. Delivery is another major challenge, but I'll consider that separate from the task of creating one at all. reply qchris 5 hours agorootparentprevThis is concept is a neat one that I think differentiates the real world from many fantasy worlds. In the latter, many of the core problems are built around somebody having \"forbidden\" or \"dark\" knowledge, or the heroes needing to find just the right rare answer to some kind of fundamental problem that somebody wrote down but that was suppressed. Think Horcruxes in Harry Potter sort of a deal. In the real world, we have classification, but by-and-large those are about very specific elements of very specific things (i.e. the exact shape/location of that secondary, not that the secondary exists or that Sandia does modeling of that sort of thing). No one's really the gatekeeper of knowledge of things like nuclear engineering or biological gain-of-function. There's not really a litmus test for someone to attend to a microbiology graduate program or take a chemistry class that would enable them to develop synthetic drugs. Same thing with martial arts; no one's hiding some secret martial technique. A BJJ purple belt will, in a fistfight, toy with just about anyone else on the planet not trained in jiujitsu like they're a toddler. And you can just, like, walk into many strip malls across the North America, pay your $200/mo, and a few years later of consistently showing up, you're there. No secret death touch or spiritual clarity needed. reply meindnoch 4 hours agorootparentprevUsing publicly available knowledge won't get you a working nuke, even if you have the necessary fissile material. A lot of finicky details have to be just right in order to get a nuclear explosion instead of a fizzle. C.f. https://en.wikipedia.org/wiki/Fogbank More often than not, comparatively simple chemical reactions are hard to reproduce reliably just by reading the research papers. reply gorjusborg 7 hours agorootparentprevWhich is probably why the U.S. looks out for uranium enrichment. reply Cthulhu_ 7 hours agorootparentprevThere was once an article in a pop sci magazine 25 odd years ago about how to build a nuke in a house; basically a pipe / barrel from the attic to the basement, a concave bit of plutonium or the right kind of uranium in the basement encased in a good carrier like concrete, and a convex matching part at the top of the barrel. Explosives behind the top one, launch the one towards the other, ????, nuke. In theory. That said, if it was that easy, I'm sure we would've had terrorist attacks with nukes already. Or if terrorism was that big an issue. I don't know if it hasn't happened yet because technology and three-lettered agencies are doing their job right though. reply cannonpr 7 hours agorootparentCasting, machining or welding plutonium into the right shapes and purities without killing your self, or some of the other exotic metals, without killing your self or making your neighbours sick in a sub 1-3 week horizon is incredibly challenging. The exact geometries you need to achieve aren’t easily available either neither is measuring is you achieved them without again killing your self. Getting a dirty fizzle is a lot easier which is why people are afraid of dirty weapons by terrorists. reply lumost 5 hours agorootparentMaking the entire thing efficient enough to actually be delivered to a target is also another matter. This requires precise calculation of the geometries and very precise grades of plutonium, barrel pipe, and explosives. How do you even keep the gun type shapes from deforming in the barrel? reply lazide 5 hours agorootparentprevGetting the right type of plutonium in sufficient quantity is an order of magnitude harder than either of them - there is essentially no naturally occurring plutonium, it only comes as a side effect of neutron bombardment of specific isotopes of Uranium, which are already hard to seperate, and only under specific conditions are the right types of plutonium isotopes to be useful produced. And even then, it’s non trivial to seperate them. The whole thing is a giant, high profile, and dirty mess. reply AnimalMuppet 6 hours agorootparentprevGetting the plutonium, in sufficient quantities, is also non-trivial. reply lupusreal 5 hours agorootparentprevPlutonium won't work in a gun-type device like described in that magazine, the Pu-240 contamination makes it far too sensitive. reply thesuitonym 5 hours agorootparentprevI'm sure in 1985 plutonium was available in every corner drugstore, but in 2024 it's a little hard to come by. reply oneshtein 4 hours agorootparentprevChemical attacks, like one sarin attack in Tokyo by Aum Shinrikyo, are few orders of magnitude cheaper than any nuclear attack. reply RA2lover 4 hours agorootparentThat's not to say they didn't try. https://en.wikipedia.org/wiki/Banjawarn_Station reply nikcub 5 hours agorootparentprevThis is the same method published in the BBS/FTP distributed Jolly Rodger's Cookbook in the early 90s. reply taneq 6 hours agorootparentprev[Cut to me in 1999 driving my old station wagon down to the local hardware store to pick up a few kilos of highly purified enriched uranium and some C4] reply ClumsyPilot 6 hours agorootparentprev>> ,I'm sure we would've had terrorist attacks with nukes already. Or if terrorism was that big an issue There are two problems with that statement. Let’s examine them Firstly, does majority of terrorists want to nuke NewYork? If you gave 9/11 bombers a 5 megaton warhead, would they use it? You have to remember that many of them imagine they have a just cause. Second, imagine you are could make a nuke at home and were completely immoral, who would you sell it to? There are many evil governments and organisations that could pay more and be better clients than terrorists. reply chasil 7 hours agorootparentprevI remember rumors of the theft of the W88 (mentioned in the parent article) during the Clinton presidency. https://en.m.wikipedia.org/wiki/Cox_Report reply xattt 7 hours agorootparentprevYou might have the theory, you might have an understanding of the materials involved, but you’re missing the way they fit together. Assembly of the actual warhead could be aided by the OP diagram. reply Ginden 6 hours agorootparentThis is merely an engineering problem. The hardest part of building nukes is acquiring weapon-grade enriched uranium, because it's controlled as hell and you will get bombed if you try to make your own. If you spend hundreds of millions of dollars on enriched uranium, paying salaries for team of engineers is the easy part. reply sidewndr46 46 minutes agorootparentNorth Korea, Pakistan, India, South Africa & likely Israel didn't get bombed due to their enrichment programs. There is a rumor that the USSR flirted with the idea of a pre-emptive strike on Mainland China to decapitate their nuclear program after the Sino-Soviet split. This did not happen obviously. Iran didn't get bombed, although that may just be because other forms of sabotage were available. Syria & Iraq on the other hand, yeah those got bombed. But it's not 100% a guarantee. reply JohnMakin 6 hours agorootparentprevThe fact nukes are hard to make aren't because of lack of knowledge, everyone knows how to make nuclear weapons - the issue is materials. Control of them is closely guarded and you tend to get disappeared or bombed if you make them yourself. reply mxfh 10 hours agoprevWhy someone is calling a chart/diagram a logo is the bigger mystery here. Mockups of things exist. reply ibeff 9 hours agoparentIt's not a diagram or mock-up, it's a direct representation of the real thing for computer simulations, similar to CAD. The dimensions and shape of the components are accurate. And the author is calling it a logo because the picture is used to represent and advertise the software. reply mxfh 9 hours agorootparentIt's a product diagram on a presentation slide. Hopefully meant to be read on handouts or proceedings. A logo is the Sierra stylized text in the lower center. And the two others in the slide's footer. That Sandia might use, what was obviously intended as a diagram as a logo is a whole other thing but doesn't make it one. As long as all representation of that thing are that big and readable one can assume they were not used as logos. reply InsideOutSanta 8 hours agorootparentThe author of the post claims that the warhead-like design \"is literally the logo for this particular software framework.\" I can't verify this claim, but other Sandia frameworks (e.g. Sierra) use similar, equally overdesigned logos, so it's plausible. reply dredmorbius 7 hours agoparentprevnext [–]reply pantulis 10 hours agoprev [–] And why wouldn't they? As wikipedia states, SNL's mission includes \"roughly 70 areas of activity, including nuclear deterrence, arms control, nonproliferation, hazardous waste disposal, and climate change.\" reply KeplerBoy 9 hours agoparent [–] Because such details are usually classified. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A 2007 Sandia National Laboratories slide deck featured a graphic resembling a thermonuclear weapon cutaway as the logo for the SIERRA software framework, raising questions about its origin.",
      "The graphic, appearing in multiple presentations, depicts a reentry vehicle with components similar to a thermonuclear warhead, yet Sandia deemed it unclassified.",
      "Theories suggest it could be a deliberate unclassified shape or a mistake, with the Department of Energy (DOE) typically avoiding detailed weapon designs to prevent proliferation and political scandal."
    ],
    "commentSummary": [
      "Sandia National Laboratories released an image that appears to be a detailed schematic of a thermonuclear weapon, sparking debate about its accuracy and implications.",
      "The image's level of detail, including components like the primary, secondary, and radiation case, is unusual and may violate Department of Energy (DoE) guidelines, which typically restrict such depictions to simple shapes.",
      "The release is notable not for the technical information it provides but for potentially representing a significant shift in US government procedures regarding the handling and release of restricted nuclear data."
    ],
    "points": 482,
    "commentCount": 159,
    "retryCount": 0,
    "time": 1725607626
  },
  {
    "id": 41465735,
    "title": "Wealthfolio: Private, open-source investment tracker",
    "originLink": "https://wealthfolio.app",
    "originBody": "Beautiful, and Boring Investment Tracker, with Local Data Storage. No Subscriptions, No Cloud. Wealthfolio is a simple, desktop-based investment tracker. Your financial data is stored safely on your own computer Ditch the spreadsheets, forget about those pesky subscription fees, and no more worries about SaaS services playing around with your data. Download The Essentials You Need to Track Your Wealth Forget juggling spreadsheets or compromising privacy with online apps. Choose Wealthfolio's simple, secure approach to manage your finances. Accounts Aggregation Gather all your investment and savings accounts in one place. See everything at a glance, from stocks to savings! Import your statements from your broker or bank. Accounts Performance Track your accounts' holdings and performance over time. See how a particular account is performing, and how it's changing over time. Holdings Overview Get a clear picture of what's in your portfolio. Stocks, bonds, or mutual funds - know what you have and how it's performing. Income Tracking Monitor dividends and interest income across your entire portfolio. Get a clear view of your passive income streams, helping you make informed decisions about your investments. Goals Tracking Set your savings targets clearly. Distribute your funds across these objectives, assigning a specific percentage to each. Keep an eye on your progress.",
    "commentLink": "https://news.ycombinator.com/item?id=41465735",
    "commentBody": "Wealthfolio: Private, open-source investment tracker (wealthfolio.app)391 points by a-fadil 6 hours agohidepastfavorite137 comments kmfrk 4 minutes agoWould love an example dataset to import just to get a sense of what it looks like with data. Maybe in an example/ folder or directly in the app as a placeholder set. :) reply diggan 5 hours agoprevFirst question from reading through the landing page is about this part: > Import your statements from your broker or bank. Exactly what brokers/banks that are supported should be listed somewhere and linked here, as that's a \"make or break\" feature for a lot of people I bet. Not much point in replacing my homegrown \"Banks CSV export -> Data processing > Import into spreadsheet\" workflow unless I just replace that last step but the previous ones remain the same. reply ryandrake 51 minutes agoparentAs an avid, daily Quicken user, yes, seamless integration with financial institutions is my #1 requirement. I am not willing to manually navigate a dozen banks' broken UIs to find their \"download CSV\" option, hope it works, download a bunch of files to my computer, and then hope that they can be imported into my application--and then repeat every day when I update. I have in the past switched physical banks purely because their integration was either terrible or not working and I refused to go the \"download CSV\" route. Unfortunately some banks are starting to drop support for applications directly connecting to them, and moving to an unacceptable model where intermediaries like Intuit's servers have to do the communication and store your credentials. This has been getting noticeably shittier in the last couple of years. My #2 requirement (a close second) is that the application must be running on my local PC. I will never accept a cloud-based web-app or something I have to host on a VPS and access through some dinky HTML/JS UI. reply ghosty141 2 minutes agorootparent> I am not willing to manually navigate a dozen banks' broken UIs to find their \"download CSV\" > My #2 requirement (a close second) is that the application must be running on my local PC. I will never accept a cloud-based web-app You're lucky you don't live in the EU since well then you are straight out of luck since the bank APIs are only available to commercial entities thus the software generally is in the cloud and costs money. reply brutal_boi 3 hours agoparentprevFor that very reason I tried selfhosting Actual Finance[1] but it is more of a budgeting app than a networth tracking app. I ended up coding a small exporter[2] since I already had some stack in place that queries SimpleFI[3], which essentially allows querying balance and transaction information for most US-based banks (read only); most similar to plaid but a lot more developer-friendly afaik. [1] https://actualbudget.com/ [2] https://github.com/eduser25/simplefin-bridge-exporter [3] https://beta-bridge.simplefin.org/ reply a-fadil 2 hours agoparentprevFor now only a standard csv file is supported with these columns: Date, Symbol, Quantity, Activity Type, Unit Price, Currency, and Fee. Supported activity types: BUY SELL DIVIDEND INTEREST DEPOSIT WITHDRAWAL TRANSFER_IN TRANSFER_OUT CONVERSION_IN CONVERSION_OUT FEE TAX Example CSV format: date,symbol,quantity,activityType,unitPrice,currency,fee 2024-01-01T15:02:36.329Z,MSFT,1,DIVIDEND,57.5,USD,0 2023-12-15T15:02:36.329Z,MSFT,30,BUY,368.6046511627907,USD,0 2023-08-11T14:55:30.863Z,$CASH-USD,600.03,DEPOSIT,1,USD,0 reply cvoss 1 hour agorootparentSeems like this arrangement of columns can't properly support dividends, as 1) there is no change to the held quantity when a dividend is issued, 2) the unit price of the symbol is irrelevant, and 3) there is no column to record the actual amount received. My bank records a quantity of 0 and a dummy unit price of $1. It would be incorrect for the bank to record a non-zero quantity. reply rexreed 48 minutes agoparentprevThe Spreadsheet-based workflow works very well for me as well. I have a feeling a very large % of people manage their personal finances on a spreadsheet. And it's private, not cloud based, backupable, and password protected. reply dv_dt 2 hours agoparentprevAn tool (maybe AI) that processes PDF statements and outputs the structured importable positions & transactions would be appealing to me. No live online link to be compromised, or at lease a simpler fetch statement PDF scrape (vs maintain scrape of broker sites). reply jonromero 1 hour agorootparentWe try doing that with HeyFire.co - import from a screenshot that is processed on your browser! But with a high rate of hit or miss right now. reply neilv 4 hours agoparentprevI don't know about Wealthfolio, but the import QFX/OFX/CSV/etc. into GnuCash has ways to reconcile that with transactions you've manually recorded/edited, which can be much richer than the bank or CC knows. (GnuCash also has a way to import via network access, but I haven't tried it.) (Example of richness: splitting am Amazon CC charge into the multiple expense accounts for the items that went into the order, and also accounting for the CC rewards and the Gift Card balance that contributed.) I tried taking a break from GnuCash for maybe year, and going to a spreadsheet, and found: (1) it was still substantial work to maintain an accurate view of balances, and (2) I was missing a lot of information I found I needed in practice. reply figmert 3 hours agoparentprevI really feel like there should be a tool that wraps Woob[0] finance and provides something similar to Plaid, but self-hosted. There are some great finance apps that could then potentially integrate it to improve automation. Woob does a great job of providing a good API for automating the web, and sure, not everything works, but it's a good start. Unfortunately, it seems it's not very well known still. [0] https://woob.tech/ reply aketchum 2 hours agorootparentthis sounds incredibly hard to do - plaid's moat is that it is a bunch of work to keep up to date with all these different bank UI's, plus many banks have moved to OAuth which they only provide to trusted partners - like plaid. You cant get an oauth token to your BofA account just because you have an account there reply progforlyfe 4 hours agoparentprevThat's what I was wondering. It's a ton of work, but would love the auto importing / screen scraping features that Mint.com had. For a local desktop tool it even has the potential to support every possible service because they can't do IP blocking on end-users (versus the server-to-server model that Mint.com had, caused many services to IP block Mint's servers). Unfortunately, depending on an open-source tool to do this is a double edged sword if it had these features, because we would be opening the risk of supply-chain attacks -- malicious actors getting commits into the repository code which cause the program to send your data elsewhere -- or worse, deplete accounts' funds. reply diggan 4 hours agorootparent> but would love the auto importing / screen scraping features that Mint.com had I never used it, but didn't that ask you for the username/password in order to do its job? If so, I wouldn't touch it with a ten-foot pole. > cause the program to send your data elsewhere -- or worse, deplete accounts' funds. Again, seemingly because their shitty architecture would that even be possible. There are modern (possibly only European?) standards nowadays that forces the banks to expose proper APIs for doing things like that. Would require a business entity to deploy to production (I think that's one of the requirements?) but otherwise wouldn't be a huge task compared to manually scraping stuff. reply j-a-a-p 2 hours agorootparentI suppose you mean PSD2. That is mandatory for EU banks that do payments. I don't think your stock and crypto trading services need to comply. reply nightski 4 hours agorootparentprevSome banks allow you to create separate limited read only credentials at least that can be revoked at any time. But not all of them allow this. reply al_borland 4 hours agorootparentI used Every Dollar for budgeting for a while. It seemed mixed. Some banks used auth through the bank that would create a token for the site/app, which could be revoked through my account when the bank. Others used a 3rd party service which required the user enter their bank creds, and seemingly trust them. I was in the market for a new bank, so I ended up coming up with my short list of banks I’d look at moving to, then went to Every Dollar to try adding accounts to see what kind of prompt I was met with. Anything that required the 3rd party to store my creds was out of the running. I ended up ending a 20+ year relationship with a bank of this. There were other things too, but this was the straw that got me to actually cut ties. I assume Mint was similar. I used it a long time ago, probably when I was more trusting in my youth. reply jfdjkfdhjds 1 hour agorootparentprevonly if there were regulations for consumer banking having the bare minimum for application security as is for everything else banks themselves depend on. reply groby_b 50 minutes agoparentprevThat's the core question. This is 99% of the value that any such tool provides. An open source project that had import flows for all the major banks & brokers into a well-defined unified format? Tremendous impact. A graphing tool that only imports a standardized CSV? I can do that in my spreadsheet in minutes. reply klinquist 3 hours agoparentprevI just assumed it uses Plaid. reply diggan 3 hours agorootparentI assume it uses no external services at all as it's supposed to be local first and \"No Cloud\" is basically the first thing you see when opening up the landing page. Not to mention the second paragraph is \"no more worries about SaaS services playing around with your data\" reply aketchum 2 hours agorootparentprevunlikely, who would pay the plaid bill here? they dont really have ala cart pricing - you have to create an account with them etc reply Onavo 1 hour agoparentprevI have found https://teller.io to be really good for this. They are more affordable than Plaid too at the lower end of scale. I have also seen some apps use https://www.simplefin.org/ reply jfdjkfdhjds 1 hour agoparentprevit's open source... so all of them? reply groby_b 49 minutes agorootparentThat's a somewhat useless statement. \"I have a hello world on github. It's Open Source, so it can solve all your problems\" is both true and not helpful at all. reply cube2222 4 minutes agoprevLooks cool! How does it compare with Portfolio Performance[0], which is arguably the most popular open-source tool for portfolio tracking? [0]: https://www.portfolio-performance.info/en/ reply a-fadil 3 hours agoprevThank you for your comments, just some context: - The app is a simple desktop application that works on macOS, Windows, and Ubuntu. - I developed this app for my own needs. Getting tired of SaaS app subscriptions and privacy concerns. - For now, the activities are logged manually or imported from a CSV file. No integration with Plaid or other platforms. - No monetization is planned for now (only a \"buy me a coffee\" if you use and appreciate the app). reply theogravity 1 hour agoparentGreat work on the app. As another comment stated, having to import CSVs and spending most of your time editing transactions is a huge barrier to adoption. I know most commercial solutions offer something like Plaid to interface and import with financial institutions, and I have no idea what you can do / use as an equiv for a local solution like this. I personally pay for Rocket Money (they let you decide how much you want to pay per month with a min of around $4 / month) and as someone who came from Mint, it does an amazing job overall - I rarely have to do manual edits (other than assigning appropriate categories for certain transactions) and the one thing it lacks is Apple Card API import (have to do CSV, but once a month isn't bad). reply j-a-a-p 2 hours agoparentprevI always wondered what staring at the historic values of your portfolio will actually help to improve performance. If you can define some sort of investment strategy, then the tool can make you follow it perhaps. reply rufus_foreman 1 hour agorootparentI have similar information in a spreadsheet (that I am also turning into an app), and what it can help with long term is to put downturns in the market in perspective and keep you from overreacting to them. When you look at a log chart of your net worth over several decades, things like the dot-com bubble and the Great Recession look like blips. It makes it easier to look at a bear market and think, \"this too shall pass\". Of course it also helps you see your progress towards a goal and give you information on how long it will likely take to get there. reply rs999gti 1 hour agoparentprev> No monetization is planned for now (only a \"buy me a coffee\" if you use and appreciate the app). A few ideas: Anonymize and aggregate the data, then sell it off to financial and marketing firms. Add ads to the site. Charge a subscription fee. Partner with banks as a white label financial planning tool. reply xyst 1 hour agorootparent> Anonymize and aggregate the data, then sell it off to financial and marketing firms. Horrible. Goes against the privacy oriented aspect of this app. > Add ads to the site. Oh great, more useless ads I have to block. Nothing like getting a crypto scam ad while viewing your portfolio performance. Horrible UX idea. > Charge a subscription fee. Yet another SaaS, centralization of data, and betrays the privacy oriented aspect > Partner with banks as a white label financial planning tool. Likely won’t work. Maybe small advisors would buy into it but at that level there are a plethora of tools available to them with real time aggregation available via Plaid or even old school scraping (doubtful in 2024 though). How about this? Just charge one time fee for major versions of the app. Minor and patch versions are free. Keep the privacy oriented aspect and local to users machine. Why must you always use the worst ways to monetize? Treat users with respect and you will have life long customers. Not everything needs to be a billion dollar unicorn pumped with VC funds. reply rs999gti 57 minutes agorootparent> Why must you always use the worst ways to monetize? Treat users with respect and you will have life long customers. Not everything needs to be a billion dollar unicorn pumped with VC funds. They aren't the worst ways to monetize, they are just the ones that work. > How about this? Just charge one time fee for major versions of the app. Minor and patch versions are free. Keep the privacy oriented aspect and local to users machine. Unless he is charging a substantial and/or recurring amount, there is no way he will put up with angry customers and enjoy maintaining the software in the long term. Plus, if this is hosted, hosting is a variable cost that always goes up, so his prices for updates will always be increasing. reply DoingIsLearning 1 hour agorootparentprevDid you read OP's words? > I developed this app for my own needs. Getting tired of SaaS app subscriptions and privacy concerns. reply jfdjkfdhjds 1 hour agorootparentwell, it won't concern HIS privacy :) reply prashp 1 minute agoprevWhat framework/language did you use? reply amadeusw 0 minutes agoparentGitHub page has a robust writeup of all technologies used [0] [0] https://github.com/afadil/wealthfolio?tab=readme-ov-file#tec... reply insane_dreamer 2 hours agoprevIt's a beautiful design, and I like the idea of OSS and self-hosted instead of a SaaS, but since it doesn't support direct connections to banks/brokerages (i.e., through Plaid), then it's not really an option for me. I'm not going to go through the trouble of downloading/importing CSVs etc. (too many different accounts). (I currently use Wealthfront for net worth aggregation and Copilot for tracking spending.) reply yellowapple 51 minutes agoprevIt looks nice, but unfortunately Fidelity's CSV exports don't seem to be particularly cooperative AFAICT, which limits how much I'd be able to use this. Haven't tried my other accounts yet. It'd be nice if there was an actual standard for this sort of thing (incl. an API for automatically retrieving new transactions), and if banks and brokerages and such could be depended upon to actually use it. reply TuringNYC 29 minutes agoparent>> Fidelity's CSV exports don't seem to be particularly cooperative AFAICT Not to mention, Fidelity's site seems broken over half the typical days, especially with products like Basket Trades. Baskets broken. No cost basis. No quotes...not even during market hours. Insane. reply ryandrake 47 minutes agoparentprevThere is a standard, called OFX[1], but support among financial institution is spotty, unfortunately. 1: https://en.wikipedia.org/wiki/Open_Financial_Exchange reply lbrito 1 hour agoprevLooks exactly like Wealthsimple; did you use the same graph framework or something? reply smsm42 57 minutes agoprevOn one hand, this looks like awesome work. On the other hand, personally for me I am not sure how it could ever work for me. Right now, I have 20+ money/investment accounts from ~10 different providers and I am tracking it through a provider that uses Yodelee (and maybe other methods too?). Importing all the statements (which every provider stores in different ways in different places) manually would be a pretty big chore. But keeping it up-to-date - without which the whole exercise is kinda useless - is completely infeasible. That even not getting into the question of every provider exporting data in a different format... reply steviedotboston 5 hours agoprevLooks nice. One reason why I use a spreadsheet for stuff like this is I can share it with my wife through Google Sheets, so we can periodically update with our separate accounts. reply snide 3 hours agoprevReally happy with Projection Lab in this space. Although it's not open source, it is self-hostable if you pay for their lifetime access. The developer continues to update it, and has pretty much all the features I want for managing retirement projections. reply wingin 3 minutes agoparentanother lifetime subscriber here, highly recommend! reply vectoral 2 hours agoparentprevProjectionLab is great, it's been fun to watch it grow over the last few years! reply scubakid 2 hours agoparentprevOh hey, thanks! Working hard to make PL a little better every day :) reply tantalor 1 minute agoprev> Ditch the spreadsheets ... and use this spreadsheet instead? reply admn2 2 hours agoprevis Plaid inherently bad? Is having an automated way of pulling in real time data worth the security risk of authing into all your bank accounts? Genuinely asking as this seems great in theory, but I'm a bit confused what it looks like to manually keep it updated. reply aketchum 1 hour agoparentMy company is an online lender - we use plaid so that users may instantly link their bank account. They have an alternative of verifying with micro-deposits, but that does take 2 days and the company gets less information on the user, so there are more manual verifications the user must do (provide paystub and id etc). Plaid Cons: - The end user must type their bank account credentials into a third party platform that uses their banks logo. It is terrible for general population cyber security because this is the exact type of you thing you should never do in general. However I do not know of any data leaks or info sec issues from Plaid specifically. As far as I know Plaid is totally safe with this information. Im sure they will be hacked eventually though - everyone is. - Plaid shows the permission you are granting but the user can not make it more restrictive. For example the company with the plaid integration can choose from 1 to all off these functionalities (they all increase api cost though): KYC Verification, PII from the account, one time current balance, ongoing current balance check, all transactions for previous 2-24 months. The vendor chooses what they want to get and the end user can take it or leave it, they cant pick and choose. Plaid Pros: - instantly verify bank account instead of waiting 1-2 days for Micro Deposits to hit account then come back to the app to verify. This is just better flow for the user, who often wants the loan asap. It is better for company too, because there is more conversion. - balance checks, transaction history - these are useful for us to not overdraw accounts when pulling a payment, and verify income. Budgeting apps use these to auto import values of course. - many banks have been forced to move to OAuth because of plaid. Having worked at a Top 10 US bank, I do not believe that any other than maybe Capital One would have OAuth today if it were not for Plaid pushing them - There is really no other feasible option to get this data (other than competitors with same exact strategy so no difference). This is the customer's data that is valuable to them! They should be able to share it with trusted partners if it gives them value. reply jjice 1 hour agorootparentI was pleasantly surprised to see a few of the large banks having added OAuth in my recent use of a product that uses Plaid. That said, my local bank is far from it and even a large bank like Discover doesn't offer OAuth yet. I've just decided that I have to enter that data manually for those accounts because I can't give out a password to my bank accounts - it's just absurd to me. Here's to a continued migration to OAuth by banks, but I'm not holding my breath for it. reply xyst 1 hour agorootparentprev> The end user must type their bank account credentials into a third party platform Huh? I have seen plaid redirect to my banks login and then authentication and subsequent authorization (read access to accounts) in other flow. Then plaid uses provided token to retrieve data. I don’t recall having to pass login credentials to plaid. Maybe that’s a limitation of _your_ bank? reply smsm42 51 minutes agorootparentYes, for banks that have this workflow enabled. In know WF does something like that. But many banks don't, and for these there's not much alternative except getting username/password and scraping. Terrible security, but dragging the banks into 21th century will take a lot of time. Some providers are annoying enough to ban external aggregation completely, seemingly just out of spite. Normally I wouldn't even work with such bank but unfortunately sometimes (like HSA account from work) you don't have a choice. reply breadwinner 1 hour agoparentprevIf you call Fidelity with a security issue the first question they ask you is, did you share your password with anyone (and if you did, you're to blame). reply fsckboy 1 hour agorootparentthat's line of reasoning applies to all banks etc., though they might not ask it as first question reply andrewmcwatters 1 hour agoparentprevYes, but the fault lies with the banks who do not allow their own customers access to their data. Plaid, Intuit, and other private companies scrape financial institutions unless they provide more secure methods to obtain customer data, and most of them do not do this. So the state of the art to connect to banks... is Selenium with stealth modifications. I own a business which does the same work as Plaid, Intuit, et al. reply conradev 35 minutes agoprevHow does it store data? If it was “file format first” and used something like Beancount or Ledger, I’d absolutely use this. Partly because I already have data in Beancount format. reply HackBlade 1 hour agoprevLove the design! If this had automatic importing I would probably drop Copilot for this. reply Glyptodon 1 hour agoprevBesides the ability to easily connect with arbitrary bank and brokerage accounts to maintain data, another thing somewhat lacking in this (general) area is a relatively comprehensive open source market data dataset. You can somewhat pull for individual stocks, but if you want to do analysis or back test a strategy against real data, comprehensive data on even just the S&P 500 is lacking. reply alex_suzuki 4 hours agoprevWhile you’re at it, have a look at Ghostfolio too: https://ghostfol.io/en/start Open Source and self-hostable. reply hammock 3 hours agoparentHow does this compare to Simplifi, Empower, etc? reply dmackerman 1 hour agoprevThe tickers from my 401k at Vangaurd aren't supported. VFIAX, VTIAX. Oh well. reply a-fadil 57 minutes agoparentWorks for me. If the tickers is in Yahoo Finance, it should be supported. reply skim 2 hours agoprevThis looks great. Is there more information on the external connections the app makes? So far I see: wealthfolio.app yahoo.com I'm assuming latter is to fetch ticker symbols, but ideally would like to use this app completely local. reply a-fadil 1 hour agoparentwealthfolio.app to check for new app versions. yahoo.com to fetch ticker symbols and quotes reply Ninjinka 1 hour agoprevI tried importing activity from a Charles Schwab account, and it did not work, since they capitalize their field titles. Then after fixing that I got \"CSV deserialize error: record 1 (line: 2, byte: 81): field 4: cannot parse float from empty string\" and gave up. Not sure what accounts this is meant to work for. reply Ninjinka 1 hour agoparentDropped my CSV into ChatGPT with the following prompt and the output file worked: ``` Modify this csv to match this format: Follow these steps to import your account activities from a CSV file: Ensure your CSV file is in the correct format. Columns should include Date, Symbol, Quantity, Activity Type, Unit Price, Currency, and Fee. Click the 'Import' button and select your CSV file. Review the imported activities before confirming. Supported Activity Types: BUY SELL DIVIDEND INTEREST DEPOSIT WITHDRAWAL TRANSFER_IN TRANSFER_OUT CONVERSION_IN CONVERSION_OUT FEE TAX Example CSV format: date,symbol,quantity,activityType,unitPrice,currency,fee 2024-01-01T15:02:36.329Z,MSFT,1,DIVIDEND,57.5,USD,0 2023-12-15T15:02:36.329Z,MSFT,30,BUY,368.6046511627907,USD,0 2023-08-11T14:55:30.863Z,$CASH-USD,600.03,DEPOSIT,1,USD,0 ``` Except it couldn't find the symbol `BRK/B`, `BRK.B` or `BRKB`. reply xyst 1 hour agoparentprevI would just switch brokerages. Not just for the csv issue, but their platform has taken a shitter since acquiring TDA. reply FractalHQ 1 hour agorootparentAre there any you can recommend? reply xyst 1 hour agorootparenthave had no issues with IBKR since switching last year. There was a recent “crash” (the Japanese stock sell off?) that caused a massive influx of retail trading and dark pool trading. At market open on Monday, SCHW account with 401K was not accessible. But IBKR was up and running. reply Oras 5 hours agoprevLooking good, I've worked in a startup doing this using an app (with more things). Adding accounts manually is painful. We used to do it with Open Banking, but since this is open-source, I appreciate that it cannot be done with Open Banking. However, an option to upload a statement (CSV) will simplify the process. The same goes for adding securities. I believe you can get an eToro statement that shows you everything, and then you can parse it to populate the information. Good luck! reply AndroTux 4 hours agoparentActivity > Upload-Icon (top right) > Drop CSV reply Oras 4 hours agorootparentThanks! I didn't see it. The add activity button is prominent! reply oezi 5 hours agoprevI have been very happy with https://www.portfolio-performance.info/en/ which is also Open Source, local/desktop and quite advanced. reply Circlecrypto2 4 hours agoprevMan... The loss of Mint has really left a gap in this market. reply r3trohack3r 4 hours agoparentI have been using Empower (previously Personal Capital) for almost 10 years now and have been happy enough reply mindwork 4 hours agoparentprevOnce Mint.com has closed I started to dig for alternatives and found Monarch Money. Couldn't be happier to pay for the service. New features come out pretty often, and I believe they work on the better support for tracking investments. reply impostervt 3 hours agorootparentSeconded. I used Personal Capital for a while but the links to my accounts broke frequently. Moved to Monarch and paid for it and its way less of a hassle. reply the__alchemist 3 hours agoparentprevNot really: Ever since Mint's shut down, there have been replacements pouring out of the woodwork. It's a low-hanging-fruit (Due to aggregators like Plaid), saturated marked. Note that the OP's program is a bit different in that it's local, and seems to focus on individual investments vice online account aggregation. reply constantinum 14 minutes agoprevManually adding/importing has always been a hassle for me to get into these apps. For the hassle one has to go through to get the data in, I would just settle for an excel sheet. Let me how you folks are integrating various banks/cards/stock brokers with investment apps? reply constantinum 7 minutes agoparentImporting CSV might look easy, but banks, at least in the country that I live in does not have a standard. One might end up spending more time cleaning up the data. reply LifeUtilityApps 3 hours agoprevThis looks really nice, and I love that it's open source and all the data is saved locally. I will give it a try this weekend! reply yesimahuman 4 hours agoprevLooks very cool. I started working on my own version of this to self host in my LAN. First issue I ran into was the lack of understanding certain CSV formats. For example, Vanguard is so common that I support their export format exactly. Might be worth thinking about focusing on a few common brokerages (vanguard, fidelity, schwab) and making the experience for those really good. Otherwise it's all too manual and most people won't bother going through the hassle of it all. reply dewey 5 hours agoprevIt feels like one of these things where a commercial version has a lot of benefits as most of the interesting APIs in this field are paid, or for banks require a B2B agreement for automatic imports. reply figmert 4 hours agoprevNote that this is a desktop app developed via Tauri. It would be great to turn this into a hosted service that I can deploy onto a homelab and access everywhere? reply lucasfdacunha 4 hours agoprevThis looks nice. Does this work for the international market, like Brazil for example? Does it track fixed-income types of investments like government bonds, etc? reply user_agent 3 hours agoprevI've put 15 minutes of my work into configuring the app. Even on that surface level I can conclude that the application is full of bugs that impact accounts and savings. It looks good, but it's unusable for any serius purpose. Have a nice day. reply ejp 3 hours agoprevAny recommendations for a privacy-focused app that can handle transaction splitting in ways other than 50/50? Or tracking accounts from multiple people in a household? Every app I've tried this is painful or unsupported. reply sushiburps 3 hours agoparenthttps://www.splitwise.com/ reply mNovak 1 hour agorootparentI used to really like Splitwise for group expenses, but they at some point throttled the free accounts to 4 transactions/day, which is painful. Paying a monthly subscription isn't worthwhile if I only use it in bursts a couple times a year, so its back to spreadsheets. reply aaronax 3 hours agoparentprevAny personal accounting software? Quicken, GNUCash, any Plain Text Accounting, etc. I must be missing something in your requirements. reply ejp 2 hours agorootparentIn my experience, gnucash qualified easily as painful. :) Here's an example of what I'm talking about: suppose you and a housemate decide that an equitable split for the electric bill is 65/35 based on usage habits. One person pays the electric bill every month. All of these finance apps will download the transaction, categorize the electric bill for me, and maybe apply a custom tag. But I have to manually calculate the amount owed to me, and manually reconcile that with the fact that the other person pays the water bill. I'd love to find an accounting app for shared arrangements, but it seems like most are targeted to solo or completely joint finances. Monarch listed elsewhere in these comments is the closest I've seen, but it also doesn't support reconciling split transactions. reply aaronax 21 minutes agorootparentI see. I split my monthly cell phone bill among 8 family members. This is a manual process, but not too bad since I do it on average twice a year (faster to sign in and download 6 PDFs once than to sign in 6 times to download 1 PDF each time, etc.). So a few minutes to download 6 statement PDFs, 10 minutes to key numbers from those PDFs into my spreadsheet, and then 15 minutes to go through and manually split the transactions based on totals from the spreadsheet. I'm pretty sure I could write a custom importer for Beancount but the breakeven point on time would be years. I think modifying the CSV importer for Beancount to split certain transactions to certain percentages would be fairly easy--switching to Beancount itself (or other Plain Text Accounting software) would of course be monumental. But it is the ultimate in flexibility. reply diegoholiveira 3 hours agoparentprevGnuCash may be a good option reply jeffchien 1 hour agoprevI wish this and Ghostfolio supported stock splits. reply palk 3 hours agoprevUI looks way more polished than the competition — without having fully set it up, the app sounds very promising as an alternative to SaaS tools. Any plans to monetise? reply oulipo 4 hours agoprevquite nice! It would be great to have a bit more infos about how to get setup, how to input existing values from accounts, etc I think I got it right after doing a \"deposit\" of the exact value of my account, then try to work out what was the correct \"buy\" price for each stock without the P/L, it roughly works but the numbers don't exactly match those that I have in my account, perhaps because you're not using the same data source as my account reply scosman 4 hours agoprevRRSP and CAD on the homepage . So few financial apps work for Canadians. reply ape4 3 hours agoparentIts common for Canadians to have USD and CAD investments so that means the app will have to handle multiple currencies which is a useful feature for any investment app. reply GoRudy 3 hours agoprevLooks like it only takes CSVs, how would we upload documents from brokerage accounts? reply thinkloop 52 minutes agoprevHow do things remain private if the prices of assets, like stocks, have to be updated? reply herodotus 4 hours agoprevLooks interesting. I have tried it out. Cannot see how to do this step: > Import your statements from your broker or bank. reply AndroTux 4 hours agoparentActivity > Upload-Icon (top right) > Drop CSV reply herodotus 4 hours agorootparentThanks! reply Batman1337 59 minutes agoprevCan you add Linqto support? reply gniting 2 hours agoprevLooks great, nice job! Crypto asset tracking on the roadmap? reply a-fadil 2 hours agoparentSupports Crypto Assets as well. reply tinyhouse 5 hours agoprevThis looks like a great idea. Are there similar OS alternative apps for YNAB / RocketMoney type functionality? reply freddie_mercury 4 hours agoparentActual Budget is basically an open source clone of YNAB. The UI isn't quite as polished IMHO. reply tsycho 5 hours agoprevDoes it support options, or only stocks? How do you get current market prices for investments? reply jimmyswimmy 5 hours agoparentLooks like it uses yahoo_finance_api in rust. In theory that supports options, but no idea whether this tool handles that data properly, I didn't feel like searching that hard. It's gonna take a lot to pry me away from my spreadsheets. They are simple and just work. Ages and ages ago I used MS Money but once they shut down I never migrated to the 'sunset edition,' just switched to excel. I keep trying things, but without local, automatic sync to my accounts, nothing is as simple and effective as a simple spreadsheet, for me. reply Dalewyn 4 hours agoprevSpeaking practically, I don't see a need or reason for this. I can just login to my bank and brokerage accounts and check live data on the spot. Speaking as a Boglehead, checking on your investments frequently is usually a bad thing. reply diggan 4 hours agoparent> Speaking practically, I don't see a need or reason for this. I can just login to my bank and brokerage accounts and check live data on the spot. First mentioned and most prominent feature is \"Accounts Aggregation\" on the landing page. If you don't have multiple accounts, it makes sense you don't see any need for this. But you should also realize that it's fairly common to have multiple accounts, for various of reasons. reply mNovak 1 hour agorootparentMy main brokerage (Schwab, and I assume most others) have account aggregation built in, so that's become my de facto 'wealth manager' dashboard. Now, those external accounts are second-class citizens and don't get portfolio analysis and stuff like that, so there is room for improvement, but the ease of use and cost (free) is hard to beat. reply downut 2 hours agorootparentprevI have multiple accounts and I use the friction of logging in manually to each as an incentive not to check them. About every 6 months or more I get a beer, login to each, and check for surprises. Ever since decades ago I gave up my personal autonomy (I will not pick stocks, GE, really?) and channeled my inner boglehead there has not been any surprises. reply Dalewyn 4 hours agorootparentprevI haven't used it myself (yet?), but both my bank and my brokerage purport to let me link external accounts for easier aggregated viewing. reply goodpoint 20 minutes agoprev\"\"\" Prerequisites Ensure you have the following installed on your machine: Node.js pnpm Rust Tauri \"\"\" Sorry but all these languages and tooling just for a simple desktop application is a pass. reply TexanFeller 5 hours agoprev\"Local Data Storage. No Subscriptions, No Cloud\" This is what we need more often from our software, especially from software that works with sensitive data. I do typically want sync options though since I tend to use several different devices and it sucks not being able to reference information on the go from my phone. Sync options can include locally/self hosted options or use something like iCloud that don't depend on a software vendor's running a service though. reply mr_mitm 4 hours agoparentIf I can specify the data location, I could just use syncthing or dropbox or whatever. Syncing directories is mostly a solved problem. reply LifeUtilityApps 3 hours agoparentprevI built a similar tool to what OP shared, mainly for debts instead of investments, and I completely agree with you. My app only uses iCloud to sync and it keeps all sensitive data on the user's phone. Another benefit I want to share about this approach is it means that apps built local-only will never have the risk of one day going offline and being inaccessible due to the company closing down or turning off the server. reply picardo 4 hours agoparentprev> This is what we need more often from our software, especially from software that works with sensitive data. Storing sensitive data in local storage makes you vulnerable to XSS attacks and Man-in-the-Browser attacks. You're exposing your sensitive data to an attacker that injects a script to the website and to malicious browser extensions. All sensitive data stored in local storage must be encrypted using a key stored in the server or somewhere on your hard disk. Otherwise, you're not reducing your risk, but substituting one type of information disclosure vulnerability with another. reply diggan 4 hours agorootparent> Storing sensitive data in local storage makes you vulnerable to XSS attacks and Man-in-the-Browser attacks. You're exposing your sensitive data to an attacker that injects a script to the website and to malicious browser extensions The app in question runs locally and only with trusted code. How is the attacker supposed to get in there to place the XSS or even do a MITM attack when there is no exposed website at all? Neither are there browser extensions involved here. > All sensitive data stored in local storage must be encrypted using a key stored in the server Huh? Please don't do this, especially not for \"local first\" applications, would defeat the entire purpose. reply picardo 4 hours agorootparent> only with trusted code That's a big assumption. Have you read all the code, and the dependencies of the dependencies of your code? If you haven't, how do you know it can be trusted? What if there is a backdoor in an obscure dependency that can inject a script into your website to steal your sensitive data? Don't laugh it off. When there is money on the line, someone is going to try it. > Neither are there browser extensions involved here. What about the extensions you installed in your browser? What about the user scripts (if you use them)? > Huh? Please don't do this, especially not for \"local first\" applications, would defeat the entire purpose. Why not? Why do you want a local first app in the first place? What's the purpose of a local first app, if not security? reply diggan 4 hours agorootparentI think you're misunderstanding what kind of application this is. It's not a website, it doesn't run in your normal browser. It runs as a standalone application. > Why not? Why do you want a local first app in the first place? What's the purpose of a local first app, if not security? Because as soon as those keys aren't available (either because the endpoint no longer exists, or you cannot connect to the endpoint for whatever reason (like being offline)), you can no longer access your data. That isn't \"local first\" at all, it's something else entirely. reply picardo 3 hours agorootparent> Because as soon as those keys aren't available (either because the endpoint no longer exists, or you cannot connect to the endpoint for whatever reason (like being offline)), you can no longer access your data. The encryption key doesn't have to be stored in the cloud. It just has to be stored somewhere else -- it could be in the file system. > It's not a website, it doesn't run in your normal browser. It runs as a standalone application. Even if it's a standalone application, it doesn't mean the code can be entirely trusted. I wouldn't take that risk. reply diggan 3 hours agorootparent> The encryption key doesn't have to be stored in the cloud. It just has to be stored somewhere else -- it could be in the file system. Right, makes sense. I was saying to not store it in the cloud, specifically. Encrypt local data at rest, makes sense. Storing encryption keys for said content somewhere where you need internet access to get, doesn't make much sense. > Even if it's a standalone application, it doesn't mean the code can be entirely trusted. I wouldn't take that risk. \"Trusted\" here refers to \"not user provided inputs\" that SaaS/website usually does somewhere. Obviously, there is code somewhere that you haven't read and verified, that's true for literally everyone using a computer today, no one has read and verified all the code they've run, we'd get nothing done if that was common practice. Just for curiosities sake, what OS you use and how much of your software you use daily have you read through the source code of? reply picardo 2 hours agorootparent> what OS you use and how much of your software you use daily have you read through the source code of? Very few. It depends on the data I need to store in the program. I don't store sensitive data in Figma or VSCode, so I don't really care if they don't encrypt my data in local storage. But if I'm in the market for something that offers to manage my sensitive financial data, then yes, I want to dig into its dependencies and security strategy first. reply jxf 5 hours agoparentprev> Sync options can include locally/self hosted options or use something like iCloud that don't depend on a software vendor's running a service though. Don't most sync options depend on a software vendor running a service? (Your VPS hosting company, your SaaS handling cross-device syncing, your cloud provider, et cetera.) reply kyrofa 4 hours agoprevv1.0 before 100 commits, wow. reply the__alchemist 3 hours agoparentIt appears that it does not use 0ver: https://0ver.org/ reply kyrofa 2 hours agorootparentHaha, you just made my day. How have I not seen this?! Thank you. reply a-fadil 2 hours agoparentprevI developed, the app as a side project for my needs. Made the decision to move to another public repository to open sourced and not to keep the git history. App code is simple to read if you want to check security and privacy concerns. reply Ringz 4 hours agoparentprevOnly if you assume that it is their first repository and that they performed the first commit after the first line of code. reply tomlue 4 hours agoprev [–] just want to mention that it's like a few hours to set up some google sheets scripts to set up 90% of this yourself. reply constantinum 11 minutes agoparent [–] Not sure why this is downvoted. I settled with spreadsheets after trying out lots of such trackers. The frustration in your comment, I can feel. A lots of similar comments also reflecting the same about spreadsheets. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Wealthfolio is a desktop-based investment tracker that stores financial data locally, removing the need for spreadsheets, subscriptions, and cloud services.",
      "It aggregates investment and savings accounts, allowing users to import statements from brokers or banks, track account performance, and monitor dividends and interest income.",
      "Users can set savings goals with clear progress tracking, providing a secure and straightforward way to manage finances."
    ],
    "commentSummary": [
      "Wealthfolio is a private, open-source investment tracker designed to avoid SaaS subscriptions and privacy issues, with no plans for monetization.",
      "Users highlight the need for seamless integration with financial institutions to replace cumbersome manual CSV imports and suggest adding example datasets and listing supported brokers/banks.",
      "There is a preference for local data storage over cloud-based solutions, and concerns about the lack of automatic importing and the challenges of maintaining accurate data manually."
    ],
    "points": 392,
    "commentCount": 137,
    "retryCount": 0,
    "time": 1725627375
  },
  {
    "id": 41460037,
    "title": "Clojure 1.12.0 is now available",
    "originLink": "https://clojure.org/news/2024/09/05/clojure-1-12-0",
    "originBody": "Clojure OverviewReferenceAPIReleasesGuidesCommunityDevNews clojure.org ask.clojure.org Clojure 1.12.0 Clojure Deref (Aug 30, 2024) Clojure 1.12.0-rc2 Clojure Deref (Aug 23, 2024) Clojure Deref (Aug 16, 2024) Clojure Deref (Aug 9, 2024) Clojure 1.11.4 Clojure Deref (Aug 3, 2024) Clojure 1.12.0-rc1 Clojure Deref (July 27, 2024) Clojure Deref (July 17, 2024) Clojure Deref (July 5, 2024) Clojure Deref (June 28, 2024) Clojure 1.12.0-beta1 Clojure Deref (June 13, 2024) Clojure Deref (June 8, 2024) Clojure/conj 2024 CFP Clojure Deref (June 1, 2024) Clojure/conj 2024 Registration Clojure Deref (May 24, 2024) Clojure 1.12.0-alpha12 Clojure Deref (May 17, 2024) Clojure Deref (May 10, 2024) Clojure Deref (May 3, 2024) Clojure 1.12.0-alpha11 Clojure 1.12.0-alpha10 Clojure Deref (Apr 26, 2024) Clojure 1.11.3 Clojure Deref (Apr 19, 2024) Clojure Deref (Apr 12, 2024) Clojure Deref (Apr 5, 2024) Clojure Deref (Mar 29, 2024) Clojure Deref (Mar 22, 2024) Clojure Deref (Mar 15, 2024) Clojure Deref (Mar 8, 2024) Clojure 1.11.2 Clojure Deref (Mar 1, 2024) Clojure Deref (Feb 26, 2024) Clojure 1.12.0-alpha8 Clojure Deref (Feb 15, 2024) Clojure Deref (Feb 9, 2024) Clojure Conj 2024 Clojure 1.12.0-alpha6 Clojure 1.12.0-alpha7 Clojure Deref (Feb 2, 2024) Clojure Deref (Jan 26, 2024) Clojure Deref (Jan 19, 2024) Clojure Deref (Jan 12, 2024) Clojure Deref (Jan 7, 2024) Clojure Deref (Dec 22, 2023) Clojure Deref (Dec 15, 2023) Clojure Deref (Dec 8, 2023) Clojure Deref (Dec 1, 2023) Clojure Deref (Nov 24, 2023) Clojure Deref (Nov 17, 2023) Clojure Deref (Nov 10, 2023) Clojure Deref (Nov 3, 2023) Clojure Deref (Oct 27, 2023) Clojure Deref (Oct 23, 2023) Clojure 1.12.0-alpha5 Clojure Deref (Oct 16, 2023) Clojure Deref (Oct 6, 2023) Clojure Deref (Sept 29, 2023) Clojure Deref (Sept 22, 2023) Clojure Deref (Sept 15, 2023) Clojure Deref (Sept 8, 2023) Clojure Deref (Sept 1, 2023) Clojure Deref (Aug 25, 2023) Clojure Deref (Aug 18, 2023) Clojure Deref (Aug 11, 2023) Clojure Deref (Aug 6, 2023) (next Rich) Clojure Deref (July 28, 2023) Clojure Deref (July 20, 2023) Clojure Deref (July 7, 2023) Clojure Deref (June 30, 2023) State of Clojure 2023 Results Clojure Deref (June 23, 2023) Clojure Deref (June 16, 2023) Clojure Deref (June 9, 2023) Clojure Deref (June 2, 2023) Clojure Deref (May 26, 2023) Clojure Deref (May 19, 2023) Clojure Deref (May 12, 2023) Clojure Deref (May 5, 2023) Clojure Deref (May 1, 2023) Introducing Morse Clojure Deref (Apr 21, 2023) Clojure Deref (Apr 14, 2023) Clojure 1.12.0-alpha2 Clojure Deref (Apr 10, 2023) Clojure Deref (Mar 31, 2023) Clojure Deref (Mar 27, 2023) Clojure Deref (Mar 18, 2023) Clojure Deref (Mar 10, 2023) Clojure Deref (Mar 3, 2023) State of Clojure 2023 Survey Clojure Deref (Feb 26, 2023) Clojure Deref (Feb 17, 2023) Clojure Deref (Feb 10, 2023) Clojure Deref (Feb 3, 2023) Clojure Deref (Jan 30, 2023) Clojure Deref (Jan 20, 2023) Clojure Deref (Jan 13, 2023) Clojure Deref (Jan 6, 2023) Clojure Deref (Dec 22, 2022) Clojure Deref (Dec 16, 2022) Clojure Deref (Dec 8, 2022) Clojure Deref (Dec 2, 2022) Clojure Deref (Nov 23, 2022) Clojure Deref (Nov 18, 2022) Clojure Deref (Nov 11, 2022) Clojure Deref (Nov 4, 2022) Clojure Deref (Oct 28, 2022) Clojure Deref (Oct 21, 2022) Clojure Deref (Oct 14, 2022) Clojure Deref (Oct 10, 2022) Clojure Deref (Oct 3, 2022) Clojure Deref (Sep 26, 2022) Clojure Deref (Sep 16, 2022) Clojure Deref (Sep 9, 2022) Clojure Deref (Sep 2, 2022) Clojure Deref (Aug 26, 2022) Clojure Deref (Aug 19, 2022) Clojure Deref (Aug 12, 2022) Clojure Deref (Aug 5, 2022) Clojure Deref (July 30, 2022) Clojure Deref (July 15, 2022) Clojure Deref (July 8, 2022) Clojure Deref (July 1, 2022) Clojure 1.12.0-alpha1 Clojure Deref (June 24, 2022) Clojure Deref (June 17, 2022) Clojure Deref (June 10, 2022) State of Clojure 2022 Results Clojure Deref (June 2, 2022) Clojure Deref (May 27, 2022) Clojure Deref (May 20, 2022) Clojure Deref (May 13, 2022) Clojure Deref (May 6, 2022) Clojure Deref (Apr 29, 2022) Clojure Deref (Apr 22, 2022) Clojure Deref (Apr 14, 2022) Clojure Deref (Apr 8, 2022) Clojure 1.11.1 release Clojure Deref (Apr 1, 2022) Clojure Deref (Mar 25, 2022) Clojure 1.11.0 release Clojure Deref (Mar 20, 2022) Clojure Deref (Mar 11, 2022) Clojure Deref (Mar 4, 2022) Clojure Deref (Feb 28, 2022) State of Clojure 2022 Survey Clojure Deref (Feb 18, 2022) Clojure Deref (Feb 14, 2022) Clojure Deref (Feb 4, 2022) Clojure Deref (Jan 28, 2022) Clojure Deref (Jan 21, 2022) Clojure Deref (Jan 14, 2022) Clojure Deref (Jan 7, 2022) Clojure Deref (Dec 23, 2021) Clojure Deref (Dec 17, 2021) Clojure Deref (Dec 10, 2021) Clojure Deref (Dec 2, 2021) Clojure Deref (Nov 24, 2021) Clojure Deref (Nov 19, 2021) Clojure Deref (Nov 12, 2021) Clojure Deref (Nov 5, 2021) Clojure Deref (Oct 29, 2021) Clojure Deref (Oct 22, 2021) Clojure Deref (Oct 14, 2021) Clojure Deref (Oct 8, 2021) Clojure Deref (Sept 24, 2021) Clojure Deref (Sept 17, 2021) Clojure Deref (Sept 10, 2021) Clojure Deref (Sept 3, 2021) Clojure Deref (Aug 27, 2021) Clojure Deref (Aug 20, 2021) Clojure Deref (Aug 13, 2021) Clojure Deref (July 30, 2021) Clojure Deref (July 23, 2021) Clojure Deref (July 16, 2021) Source Libs and Builds Clojure Deref (July 9, 2021) Clojure Deref (July 2, 2021) Clojure Deref (June 25, 2021) Clojure Deref (June 18, 2021) Clojure Deref (June 11, 2021) Clojure Deref (June 4, 2021) State of Clojure 2021 Results Keyword argument functions now also accept maps Clojure 1.10.3 release Clojure 1.10.2 release State of Clojure 2021 Survey Cognitect Joins Nubank! Clojure Homebrew Tap State of Clojure 2020 Results State of Clojure 2020 Survey Clojure Forum Clojure 1.10.1 release JIRA Migration State of Clojure 2019 Results State of Clojure 2019 Survey Clojure 1.10 release State of Clojure 2018 Results Git Deps for Clojure Clojure 1.9 is now available State of Clojure 2016 Results Introducing clojure.spec State of Clojure 2015 survey results Clojure 1.8 is now available Welcome to the new clojure.org! Clojure 1.7 is now available Transducers are Coming Clojure core.async Channels Anatomy of a Reducer Reducers - A Library and Model for Collection Processing Clojure Governance and How It Got That Way Introducing ClojureScript Clojure 1.12.0  Clojure 1.12.0 05 September 2024 Alex Miller Clojure 1.12.0 is now available! Find download and usage information on the Downloads page. 1 Compatibility 1.1 Java 8 - Compatiblity EOL notice Clojure 1.12 produces Java 8 bytecode (same as Clojure 1.10 and 1.11), but this is expected to be the last release using a Java 8 baseline. Future releases will move the bytecode and minimum Java compatibility to a newer Java LTS release. 1.2 Java 21 - Virtual thread pinning from user code under synchronized Clojure users want to use virtual threads on JDK 21. Prior to 1.12, Clojure lazy-seqs and delays, in order to enforce run-once behavior, ran user code under synchronized blocks, which as of JDK 21 don’t yet participate in cooperative blocking. Thus if that code did e.g. blocking I/O it would pin a real thread. JDK 21 may emit warnings for this when using -Djdk.tracePinnedThreads=full. To avoid this pinning, in 1.12 lazy-seq and delay use locks instead of synchronized blocks. 1.3 Security Fix CVE-2024-22871 detailed in GHSA-vr64-r9qj-h27f: 1.4 Serialization CLJ-1327 explicitly sets the Java serialization identifier for the classes in Clojure that implement Java serialization. In Clojure 1.11.0 this changed for two classes unnecessarily and we reverted those changes in Clojure 1.11.1 - this completes that work for the rest of the classes. Clojure data types have implemented the Java serialization interfaces since Clojure 1.0. Java serialization is designed to save graphs of Java instances into a byte stream. Every class has an identifier (the serialVersionUID) that is automatically generated based on the class name, it’s type hierarchy, and the serialized fields. At deserialization time, deserialization can only occur when the available class has an identifier that matches the class id recorded in the serialized bytes. Clojure has never provided a guarantee of serialization consistency across Clojure versions, but we do not wish to break compatibility any more than necessary and these changes will give us more control over that in the future. 1.5 Dependencies Updated dependencies: spec.alpha dependency to 0.5.238 - changes core.specs.alpha dependency to 0.4.74 - changes 2 Features 2.1 Add libraries for interactive use There are many development-time cases where it would be useful to add a library interactively without restarting the JVM - speculative evaluation, adding a known dependency to your project, or adding a library to accomplish a specific task. Clojure now provides new functions to add libraries interactively, without restarting the JVM or losing the state of your work: add-lib takes a lib that is not available on the classpath, and makes it available by downloading (if necessary) and adding to the classloader. Libs already on the classpath are not updated. If the coordinate is not provided, the newest Maven or git (if the library has an inferred git repo name) version or tag are used. add-libs is like add-lib, but resolves a set of new libraries and versions together. sync-deps calls add-libs with any libs present in deps.edn, but not yet present on the classpath. These new functions are intended only for development-time interactive use at the repl - using a deps.edn is still the proper way to build and maintain production code. To this end, these functions all check that *repl* is bound to true (that flag is bound automatically by clojure.main/repl). In a clojure.main REPL, these new functions are automatically referred in the user namespace. In other repls, you may need to (require '[clojure.repl.deps :refer :all]) before use. Library resolution and download are provided by tools.deps. However, you do not want to add tools.deps and its many dependencies to your project classpath during development, and thus we have also added a new api for invoking functions out of process via the Clojure CLI. 2.2 Invoke tool functions out of process There are many useful tools you can use at development time, but which are not part of your project’s actual dependencies. The Clojure CLI provides explicit support for tools with their own classpath, but there was not previously a way to invoke these interactively. Clojure now includes clojure.tools.deps.interop/invoke-tool to invoke a tool function out of process. The classpath for the tool is defined in deps.edn and you do not need to add the tool’s dependencies to your project classpath. add-lib functionality is built using invoke-tool but you can also use it to build or invoke your own tools for interactive use. Find more about the function execution protocol on the CLI reference. 2.3 Start and control external processes For a long time, we’ve had the clojure.java.shell namespace, but over time Java has provided new APIs for process info, process control, and I/O redirection. This release adds a new namespace clojure.java.process that takes advantage of these APIs and is easier to use. See: start - full control over streams with access to the underlying Java objects for advanced usage exec - covers the common case of executing an external process and returning its stdout on completion 2.4 Method values Clojure programmers often want to use Java methods in higher-order functions (e.g. passing a Java method to map). Until now, programmers have had to manually wrap methods in functions. This is verbose, and might require manual hinting for overload disambiguation, or incur incidental reflection or boxing. Programmers can now use qualified methods as ordinary functions in value contexts - the compiler will automatically generate the wrapping function. The compiler will generate a reflective call when a qualified method does not resolve due to overloading. Developers can supply :param-tags metadata on qualified methods to specify the signature of a single desired method, 'resolving' it. 2.5 Qualified methods - Class/method, Class/.method, and Class/new Java members inherently exist in a class. For method values we need a way to explicitly specify the class of an instance method because there is no possibility for inference. Qualified methods have value semantics when used in non-invocation positions: Classname/method - value is a Clojure function that invokes a static method Classname/.method - value is a Clojure function that invokes an instance method Classname/new - value is a Clojure function that invokes a constructor Note: developers must use Classname/method and Classname/.method syntax to differentiate between static and instance methods. Qualified method invocations with :param-tags use only the tags to resolve the method. Without param-tags they behave like the equivalent dot syntax, except the qualifying class takes precedence over hints of the target object, and over its runtime type when invoked via reflection. Note: Static fields are values and should be referenced without parens unless they are intended as function calls, e.g (System/out) should be System/out. Future Clojure releases will treat the field’s value as something invokable and invoke it. 2.6 :param-tags metadata When used as values, qualified methods supply only the class and method name, and thus cannot resolve overloaded methods. Developers can supply :param-tags metadata on qualified methods to specify the signature of a single desired method, 'resolving' it. The :param-tags metadata is a vector of zero or more tags: [tag …]. A tag is any existing valid :tag metadata value. Each tag corresponds to a parameter in the desired signature (arity should match the number of tags). Parameters with non-overloaded types can use the placeholder _ in lieu of the tag. When you supply :param-tags metadata on a qualified method, the metadata must allow the compiler to resolve it to a single method at compile time. A new metadata reader syntax ^[tag …] attaches :param-tags metadata to member symbols, just as ^tag attaches :tag metadata to a symbol. 2.7 Array class syntax Clojure supports symbols naming classes both as a value (for class object) and as a type hint, but has not provided syntax for array classes other than strings. Developers can now refer to an array class using a symbol of the form ComponentClass/#dimensions, eg String/2 refers to the class of a 2 dimensional array of Strings. Component classes can be fully-qualified classes, imported classes, or primitives. Array class syntax can be used as both type hints and values. Examples: String/1, java.lang.String/1, long/2. 2.8 Functional interfaces Java programs emulate functions with Java functional interfaces (marked with the @FunctionalInterface annotation), which have a single method. Clojure developers can now invoke Java methods taking functional interfaces by passing functions with matching arity. The Clojure compiler implicitly converts Clojure functions to the required functional interface by constructing a lambda adapter. You can explicitly coerce a Clojure function to a functional interface by hinting the binding name in a let binding, e.g. to avoid repeated adapter construction in a loop, e.g. (let [^java.util.function.Predicate p even?] …). 2.9 Java Supplier interop Calling methods that take a Supplier (a method that supplies a value) had required writing an adapter with reify. Clojure has a \"value supplier\" interface with semantic support already - IDeref. All IDeref impls (delay, future, atom, etc) now implement the Supplier interface directly. 2.10 Streams with seq, into, reduce, and transduce support Java APIs increasingly return Streams and are hard to consume because they do not implement interfaces that Clojure already supports, and hard to interop with because Clojure doesn’t directly implement Java functional interfaces. In addition to functional interface support, Clojure now provides these functions to interoperate with streams in an idiomatic manner, all functions behave analogously to their Clojure counterparts: (stream-seq! stream) ⇒ seq (stream-reduce! f [init-val] stream) ⇒ val (stream-transduce! xf f [init-val] stream) ⇒ val (stream-into! to-coll [xf] stream) ⇒ to-coll All of these operations are terminal stream operations (they consume the stream). 2.11 PersistentVector implements Spliterable Java collections implement streams via \"spliterators\", iterators that can be split for faster parallel traversal. PersistentVector now provides a custom spliterator that supports parallelism, with greatly improved performance. 2.12 Efficient drop and partition for persistent or algorithmic collections Partitioning of a collection uses a series of takes (to build a partition) and drops (to skip past that partition). CLJ-2713 adds a new internal interface (IDrop) indicating that a collection can drop more efficiently than sequential traversal, and implements that for persistent collections and algorithmic collections like range and repeat. These optimizations are used in drop, nthrest, and nthnext. Additionally, there are new functions partitionv, partitionv-all, and splitv-at that are more efficient than their existing counterparts and produce vector partitions instead of realized seq partitions. 2.13 Var interning policy Interning a var in a namespace (vs aliasing) must create a stable reference that is never displaced, so that all references to an interned var get the same object. There were some cases where interned vars could get displaced and those have been tightened up in 1.12.0-alpha1. If you encounter this situation, you’ll see a warning like \"REJECTED: attempt to replace interned var #'some-ns/foo with #'other-ns/foo in some-ns, you must ns-unmap first\". This addresses the root cause of an issue encountered with Clojure 1.11.0, which added new functions to clojure.core (particularly abs). Compiled code from an earlier version of Clojure with var names that matched the newly added functions in clojure.core would be unbound when loaded in a 1.11.0 runtime. In addition to CLJ-2711, we rolled back a previous fix in this area (CLJ-1604). Detailed changelog See the official changelog for a complete list of all changes in 1.12.0. Contributors Thanks to all the community members who contributed patches to Clojure 1.12: Ambrose Bonnaire-Sergeant Christophe Grand Frank Yin Nicola Mometto Ray McDermott Steve Miner Community Resources Contributing Companies Site Legal License Privacy Policy Documentation Overview Reference API Guides Libraries & Tools Updates News Events ETC ClojureTV Books Swag Code Releases Source ClojureScript ClojureCLR Copyright 2008-2022 Rich HickeyPrivacy Policy Logo & site design by Tom Hickey Published 2024-09-06 Update this page",
    "commentLink": "https://news.ycombinator.com/item?id=41460037",
    "commentBody": "Clojure 1.12.0 is now available (clojure.org)351 points by msolli 22 hours agohidepastfavorite94 comments contrarian1234 16 hours agoThis is really a massive release with many cool new features My personal favorite is add-libs You can now write single file demos or minimal examples for issues. Really lowers the friction to share small runnable snippets with people You can also actually use it to demo Java libraries as well without all the Java boilerplate. Just poke around in the REPL and paste code into a comment on HN or wherever and anyone can replicate your \"setup\" and get it running exactly the same. No need to clone a repo or anything reply didymospl 4 hours agoparentDoes anyone remember Groovy? It has @Grab annotation which does essentially the same as add-libs you described. Very conventient for writing scripts. reply vips7L 2 hours agorootparentJbang has a similar feature: https://www.jbang.dev/documentation/guide/latest/dependencie... reply kagevf 3 hours agorootparentprev> Does anyone remember Groovy? I recall that Atlassian had some kind of scripting console where you could run Groovy and interact with its API / objects. It was useful for exploring when writing plugins for bamboo or Jira ... reply kaba0 4 hours agorootparentprevYes! Groovy does have quite a few under appreciated cool gems, and it’s a shame that is barely getting any attention nowadays.. reply fire_lake 12 hours agoparentprevCool! You should post an example :) reply geokon 10 hours agorootparentJust tested it: You run `clj` to get a Clojure REPL Then you can for instance paste the following into the REPL (add-libs {'thi.ng/geom {:mvn/version \"1.0.0-RC4\"}}) (use 'thi.ng.geom.viz.core) (use 'thi.ng.geom.svg.core) (->> {:x-axis (linear-axis {:domain [-10 310] :range [50 550] :major 100 :minor 50 :pos 150}) :y-axis (linear-axis {:domain [0 4] :range [50 150] :visible false}) :data [{:values [[0 100] [10 90] [80 200] [250 300] [150 170] [110 120] [210 280] [180 280] [160 240] [160 170]] :attribs {:stroke-width \"10px\" :stroke-linecap \"round\" :stroke \"#0af\"} :layout svg-stacked-interval-plot}]} (svg-plot2d-cartesian) (svg {:width 600 :height 200}) (serialize) symbol) - the first line downloads a library and adds it to the running session - the second and third line add the library to the REPL's default namespace - the rest of the code makes an axis and plots some random values - the output is then serialized and send out the REPL output You should get a little SVG plot on the output PS: Make sure you have version `1.12` by running with `clj --version`. If not, then (re)run the instructions here to get the latest version: https://clojure.org/guides/install_clojure reply puredanger 5 hours agorootparentUsing (add-lib 'thi.ng/geom) is sufficient here - it uses the newest version by default. reply diggan 3 hours agorootparentParent specified a RC version, does it automatically use the latest RC versions as well? AFAIK, it only uses the latest stable version, but I could be wrong, it happened before. reply geokon 10 hours agorootparentprevHere is an example playing with BooFCV's Java API It'll pop up a little window displaying an image (add-libs {'org.boofcv/boofcv-all {:mvn/version \"0.35\"}}) (import 'boofcv.alg.color.ColorRgb 'boofcv.core.image.ConvertImage 'boofcv.gui.ListDisplayPanel 'boofcv.gui.image.ShowImages 'boofcv.io.UtilIO 'boofcv.io.image.ConvertBufferedImage 'boofcv.io.image.UtilImageIO 'boofcv.struct.image.GrayU8 'boofcv.struct.image.ImageType 'boofcv.struct.image.Planar 'java.awt.image.BufferedImage) (let [image-url \"https://kxygk.github.io/web/chengdu.jpg\" color (ConvertBufferedImage/convertFrom (UtilImageIO/loadImage image-url)true,(ImageType/pl 3 GrayU8)) weighted (GrayU8. (.width color) (.height color)) gui (ListDisplayPanel.)] (ColorRgb/rgbToGray_Weighted color weighted) (.addImage gui weighted (str (.width color) \" \" (.height color))) (ShowImages/showWindow gui \"RGB222\" true)) reply pjmlp 4 hours agoparentprevNote that Java has a REPL now and scripting support, although something like add-libs is still missing from available meta commands. reply vips7L 2 hours agorootparentJBang can grab dependencies for you. reply medo-bear 3 hours agorootparentprevJava's REPL is like a kick in the nuts compared to using one in Common Lisp. How does Clojure's REPL feel like in comparison? reply diggan 3 hours agorootparentHaven't used neither Java's repl nor Common Lisp (just read about both of them) but at a glance Clojure's repl is much closer to CLs repl than Java's. In fact, I think it's confusing to call the repls of language like Ruby, Java, JavaScript et al \"REPL\" at all, compared to what lisps offer, as the experience is so different. They're more like \"Code evaluators\" than anything else. Typically when using repls outside of lisps, you'd type your code into the actual repl window, while in lisp-land you typically connect your editor to the repl and program like usual, selecting stuff to evaluate and so on. reply filoeleven 2 hours agorootparent> In fact, I think it's confusing to call the repls of language like Ruby, Java, JavaScript et al \"REPL\" at all Agreed. I always call them “consoles,” since I work largely in JS and that’s what the browser calls it. There’s no way in a console to jump into a module and modify a single function without resetting any state that the module was tracking. reply ajanuary 2 hours agorootparentprevrepl as a name kind of describes the requirements for something to be a repl - it has a read-evaluate-print loop. It would be more confusing to say that something with a read-evaluate-print loop isn't a repl. reply jdminhbg 1 hour agorootparentYeah, the problem with \"REPL\" is that it underdescribes what Clojure, Common Lisp, etc. can do, not that it overdescribes Ruby, Python, etc. reply pjmlp 3 hours agorootparentprevMany tools are like that, unfortunately Common Lisp didn't took off, and we are still catching up, see Python and Machine Learning, instead of using a powerful dynamic language with native compilers. However that doesn't mean Java REPL is useless. reply puredanger 1 hour agoprevIf you're interested in learning more about Clojure, check out the Clojure/conj conference Oct 23-25 in Alexandria, VA. https://2024.clojure-conj.org :) reply koito17 15 hours agoprevI thought they were going to hold this until Clojure/conj 2024. No particular reason to believe so (besides Clojure 1.10 being released around the same time as Clojure/conj 2021 and the Datomic-becoming-free announcement being done at the very start of Clojure/conj 2023). Still waiting on spec2, though... for now I am working around rigidity of specs by using Malli but it really isn't a first-class citizen in Clojure (mostly due to inability to check macros, and this is by design of the Clojure compiler). But you can emulate the ideas of schema/select by manipulating malli schemas as data. The changes for functional interfaces also means we no longer have to maintain utility macros like (defmacro ->Consumer [f] `(reify java.util.function.Consumer (accept [this arg#] (~f arg#)))) and instead just pass functions directly. reply doubleg 11 hours agoparentI really wanted schema/select after watching “maybe not”, so wrote a library for malli: https://github.com/eval/malli-select reply eduction 14 hours agoparentprevWhat do you mean by “inability to check macros”? You can s/fdef macros with spec and it checks the calls at compile time. In fact Clojure core uses spec to check macro calls as you can see in the stack trace sometimes when you call one wrong. Do you mean something else? reply koito17 13 hours agorootparentHere's what I mean by Malli's inability to check macros. https://github.com/clojure/clojure/blob/ad54fec/src/jvm/cloj... The Clojure compiler directly calls into clojure.spec and does not expose any sort of hook for validating macros. No library can validate macros except clojure.spec. In this sense, Malli feels like a second-class citizen in Clojure compared to the built-in clojure.spec. reply eduction 12 hours agorootparentAh thanks for explaining! I did not know they special cased spec. I hope that changes. reply jdminhbg 20 hours agoprevSuch a pleasure to get a boatload of new features and all my code just runs on it because of the hard work dedicated to avoid breaking changes. reply diggan 20 hours agoprevLovely to see add-libs and sync-deps, aren't many (any?) reasons to close down a session at all now. This release feels like it had a very different scope from previous releases, contains a lot of stuff, which is exciting to see! But I hope it doesn't end up like a hairball a few releases down from increase of pace or something. reply port19 12 hours agoparent> But I hope it doesn't end up like a hairball a few releases down from increase of pace or something. Rich Hickey and the rest of the Clojure Team are very careful designers. I wouldn't worry too much reply diggan 8 hours agorootparent> Rich Hickey and the rest of the Clojure Team are very careful designers. I wouldn't worry too much I am aware of this, which is why I suppose previous releases haven't included as many features at once as this one. It's this possible change of pace that raised the question in me :) reply tvaughan 3 hours agorootparentAdd to which, a lot of \"new, big features\" come in libraries, not the core language itself. reply diggan 3 hours agorootparentBut my point is specifically about the features mentioned in this very release, which are all in the built-in clojure namespaces. Or did I miss something from the release notes? In fact, the separate libraries have their own release process and isn't part of this release at all, as things should be. So not sure what you're referring to here exactly? reply tvaughan 2 hours agorootparent> So not sure what you're referring to here exactly? That the size or pace of this release alone should cause worry about future hairballs. reply eduction 13 hours agoparentprevPure speculation but I believe this is the first release since Rich Hickey left nubank so could be more attention from him. reply simongray 11 hours agorootparentThey've also hired Michael Fogus to work on Clojure, so more resources are definitely being put into developing the language. reply charlotte-fyi 19 hours agoprevThe functional interface changes are huge. Clojure is always at its best when staying close to Java via judicious use of interop and this solves one of the major missing links. reply ledgerdev 18 hours agoprevWhat had become of spec? Abandoned? Any news on hopes for it? reply puredanger 16 hours agoparentIt continues to exist and is in use. Lots of work has been done on a successor, but that is stalled while we consider what we want to do on various things. reply wiz21c 4 hours agoprevDumb question: what is clojure usually used for ? (in my view, Java is for \"enterprise\" stuff, python for AI/data sciences, C for performance, etc.) reply uludag 4 hours agoparent\"Enterprise\" stuff in a much less \"enterprise\" way is one usage, hence being based off the JVM. Rich Hickey has also mentioned the concept of \"situational programs\"[1] which Clojure is used in a lot. Clojure is also used in a wide variety of other areas like data science[2] or desktop applications[3] much like other general purpose programming languages. [1] https://youtu.be/2V1FtfBDsLU?feature=shared&t=639 [2] https://scicloj.github.io/ [3] https://github.com/HumbleUI/HumbleUI reply rockyj 4 hours agoparentprevIt is a general programming language (with great interop with Java). You can pretty much build anything with it - web apps (backend + frontend), APIs, Scripts, etc. Anything you can do in Python / Java you can do it in Cloujure. It even has libraries for data crunching (or can use Java libs). reply ebiester 4 hours agoparentprevThe same advantages of java in a lisp-like shell. NuBank, OneStudyTeam, CircleCI, and Guaranteed Rate are some of the larger companies I know about personally that have significant investments in Clojure. reply sir_eliah 3 hours agoparentprevA lot of banking/finance use cases. reply xxmarkuski 9 hours agoprevClojure is great. Brining together Lisp with the Java ecosystem makeand its concurrency model makes it great for building backend system, while still enabling quick changes. One thing that I found noteworthy is that Clujure did not pickup some innovations happening at Java since like version 8, such as Invoke Dynamic in the JVM or streams. reply puredanger 5 hours agoparentGenerally for streams, the equivalent in Clojure with sequences or transducers is much cleaner and simpler so there was not a lot of reason to want them from Clojure. However, it is important to provide interop paths to work with Java libs that make use of them. The functional interface coercion is implemented with invokedynamic. reply pjmlp 10 hours agoprevLots of cool improvements. The main Lisp like language I usually reach for. reply tgerdin 20 hours agoprevLooks like a pretty solid release, very happy that Clojure is still going strong! reply haolez 20 hours agoparentIs it going strong? I'm evaluating it for a new project. I'm considering it together with Clara[0]. However, it does give a vibe that it's not as mainstream as it was before and that the ecosystem is more sparse than what is once was. I'm not trying to troll. I want to choose it. It seems like a good engineering decision to me, but if it's nosediving in popularity and contributors, this might bite me back in the near future. [0] https://www.clara-rules.org/ reply hlship 20 hours agorootparentClojure's slow, deliberate development pace confuses people. The core team takes backwards compatibility very seriously. What you see with each new Clojure release is generally improved performance, better Java interop, and a smattering of new features. This is doubly true for 1.12 which is doing quite a bit of invisible work to make interop considerably better. So what you don't see is a constant flux of \"innovation\" followed by a community having to adapt to those innovations. People pull Clojure examples out of books that are 12 or more years old and they still run. I think there's some very exciting things in the Clojure space, such as Clerk (https://github.com/nextjournal/clerk) for live notebooks, and Babashka (https://github.com/borkdude/babashka) for amazing (and amazingly fast) scripting. reply ReleaseCandidat 13 hours agorootparentI guess that the GP didn't talk about the language itself, but the users. For me it looks like Scala and Clojure had lost many of its users because of Kotlin and newer Java versions. Generally I see a decline in the usage of functional languages since their heyday in the 2010s. I guess that's because imperative languages either get \"functional features\" or are \"functional enough\" - new ones like Rust or Swift. reply ndr 1 hour agorootparentClojure is more lindy than Scala. If someone tells you their project is written in Scala, Golang, Groovy, Coffeescript it almost dates the project doesn't it? Not so much in Clojure. It's niche but I can bet it's still going to be there 10 years from now, going at least as strongly as now. reply uDontKnowMe 25 minutes agorootparentI'm not so sure. I wish it were as you say but there are currently 5600 job postings mentioning Scala on LinkedIn in the USA, vs 82 that mention Clojure. 82! In the entire USA. So even in its state of relative decline, Scala might be about 70 times as used in industry as Clojure is. Even as I flip through the 7 postings mentioning Clojure in all of Canada, only 4 of them seem to indicate the job itself makes use of the language (rather than mentioning it just as an example language as in \"* Fluency in one or more languages like Ruby, Clojure, Scala, ReactJS, JavaScript, TypeScript, Java, Python - Deep understanding of internet protocols and standards.\") reply thom 19 hours agorootparentprevWhat you’re seeing sounds familiar but definitely not new. I’ve used Clojure professionally for 15 years and at no point in that time have you been guaranteed critical mass around any library or framework. Clojure has always been a small ecosystem of high variance people and projects. You get things like Rama and Electric which are bold reimaginings of what systems could look like, but you also get a lot of short lived, burnt out efforts that fizzled. The good news is nothing really _breaks_ ever, and you have access to the entire JVM ecosystem if you want it (many Clojure people find Java interop icky which I personally find moronic). reply pjmlp 4 hours agorootparentIronically, Clojure seems to be the only guest language on the JVM where the community is welcoming of the platform that makes their existence possible in first place. Similarly to how Groovy used to be, but I am not counting it as it seems only to be around to power Gradle and little else. Scala and Kotlin folks speak too much about replacing Java, yet I am yet to see their native variants match JVM in any form or fashion. Even if we take Android into consideration, Google was forced to update their Java support, as means to keep Java libraries ecosystem available for Android developers and their beloved Kotlin. reply asa400 16 hours agorootparentprevI don’t do much Clojure anymore (I wish I did!) but agreed on all points. The JVM interop is such a huge, huge advantage that it’s hard to express to people who aren’t used it. reply eduction 4 hours agorootparentprevElectric looks outstanding. It seems like the sort of thing that would take some time to spread but once it does and people take the time to learn it it could be huge. reply jakebasile 19 hours agorootparentprevI'd categorize Clojure as stable but niche. It's not nosediving in popularity, but I don't think it's growing by leaps and bounds either. Many libraries are also stable, in the sense that they are finished - sometimes people will see no activity on a GitHub project and assume it is dead when in reality it's just done. Clojure libraries tend to be very small and focused, and often no Clojure wrapper is needed at all due to the ease of Java interop. I love Clojure, and it's been great for me and all the professional teams I've worked on that use it. reply geokon 15 hours agorootparentprevI'd also look at https://github.com/oakes/odoyle-rules/ I think the userbase is slowly shrinking, but I'd personally use Clojure even if all Clojure developers disappeared tomorrow. It's not built on shifting sand as the JVM is stable. If you need really niche/cutting edge stuff you're probably going to need to dip into Java or JS interop anyway reply filoeleven 2 hours agorootparentThanks for the link! I’m not the parent poster, but I was thinking of using Clara Rules for prototyping a game idea and to get some experience with rule engines. I don’t think that truth maintenance (which is handled by Clara and not O’Doyle) is important for my use case, and O’Doyle looks simpler to pick up. reply souenzzo 17 hours agorootparentprevReagent is the clojurescript wrapper to react Reagent has the same API and the same best practices since 2014 Meanwhile, react changed from creactClass to extend Class. From classes to function components. Many clojure libraries are simply done. There is no reason to commit everyday to a project. reply jmcgough 20 hours agorootparentprevI found myself frustrated a lot when I used it two years ago. A lot of abandoned libraries. There's not a huge ecosystem around it compared to golang and other popular languages, but there's probably enough that it's a viable option if you really want to work with the language. reply dotemacs 13 hours agorootparent> I found myself frustrated a lot when I used it two years ago. Sad to hear about your experience. > A lot of abandoned libraries. There's not a huge ecosystem around it compared to golang I found it to be the opposite. In Clojure you have Clojurists Together: https://www.clojuriststogether.org which funds people to work on Open Source libraries. And more importantly there is Clojure Commons: https://github.com/clj-commons which takes popular Clojure libraries, that are no longer being supported and carries on looking after them. When I found popular Go libraries that have been abandoned, I asked in the Go community, if there are such initiatives, especially seeing how Google is behind Go. When people didn't understand what I meant, I pointed them at the examples above, from Clojure. To which their response was \"TIL, Clojure, never heard of it before! No, we don't have such initiatives in Go.\" Maybe the initiatives from Clojure Commons & Clojurists Together need more visibility for the newcomers to Clojure? reply gleenn 19 hours agorootparentprevI think there is this misconception that lack of activity on libraries indicates they aren't worth using. But I strongly believe a lot of libraries are just feature complete and bug-free enough to leave them be. The syntax of the language changes so minimally that libraries don't have to change at all after updates. This isn't Javascript where everyone keeps tweaking things over and over again. reply regularfry 9 hours agorootparentThe problem this creates is that as a potential consumer I can't tell the difference between \"effectively done\" and \"abandoned, half-done, and about to waste a lot of my time\". I don't see an easy answer to this because having \"done\" be an available state is extremely attractive, and forcing extra work on the author would be the wrong thing to do. reply gleenn 2 hours agorootparentWell, picking libraries shouldn't be done willy nilly by looking at the stars in a github repo or that they contributed 5 minutes ago. There are many curated resources that help pick libraries. Here is a great one: https://www.clojure-toolbox.com/ reply jacobobryant 18 hours agorootparentprevAlso the whole/part of the point of being hosted on the JVM is if there isn't a clojure lib for something you can just use a Java lib. reply mark_l_watson 19 hours agorootparentprevI agree, solid working libraries often don’t need frequent updates. Sort of Common Lisp: a lot of old very stable code that just works fine. reply Zak 19 hours agorootparentprevSomething I've found to be more true of Clojure libraries than those in most languages is that they can be finished. Once the code does the thing it set out to do, there's often no need to do anything else. The language is unlikely to break compatibility, and idiomatic code tends to be mostly functional with very clean interfaces. The one example I can think of where that's emphatically not true is clojure-android, which was tightly coupled to the Android SDK and did not remain usable after the main developer moved on. The Android SDK does not share the aforementioned traits. reply hatefulmoron 19 hours agorootparentI find this to be the case in Lispy languages in general (CL, Scheme, Clojure..); I go looking for a library that does X, only to find that someone wrote one more than a decade ago. It looks weird coming from more fast paced languages, but Lisp maintainers tend to their libraries carefully and might tweak them over the years but they're mostly complete already. reply sokoloff 18 hours agorootparentprevExactly. Find a random node package that was last changed 4 years ago and it might as well be toxic waste. Find a clj lib with the same stats and it's probably going to work smoothly. reply thom 10 hours agorootparentprevI know a lot of people are making the case libraries are just finished not abandoned, but your feelings are valid. It’s like investing in a really low yield but dependable bond, when everyone around you is making huge gains on tech stocks. I like libraries that get more featureful over time, but sometimes you watch your friends go broke. There are opportunity costs too, maybe you can say Spec is perfectly fine but you’d be forgiven for having mixed feelings with a massive codebase built on that in a world where many have moved to Malli or elsewhere. But let’s also be honest, loads of promising Clojure libraries do get abandoned, not finished. ClojureQL was a brilliant, composable approach to writing SQL queries but never reached its potential and was left in a fairly buggy state. I’m probably four or five Clojure data access libraries on from that in my career now. Om was highly influential but good luck if you made an investment in that. Incanter could have been enormous but failed to reach critical mass and you’d be crazy to pick it up now. There’s ‘core’ stuff like core.logic that feels like a decade old unoptimised proof of concept that didn’t follow up any of the interesting paths it laid down. Heck, I’ve even got code that relies on libraries from Chris Zheng, who quit the scene after getting a deserved dressing down from Rich Hickey after complaining about the Clojure development process. None of this is a moral failing on the Clojure community, and there’s no reason to be defensive about it. It’s a small ecosystem and it’s very hard to build critical mass. Clojure people often have magpie brains that pull them to work on new things. You’ve got to judge it for yourself. reply danieroux 9 hours agorootparentprevThis is my favourite example of a not-abandoned library: https://github.com/candera/causatum?tab=readme-ov-file#liven... \"As of this writing (25-Sep-2014) I consider this library alive and well\" ... \"Update 2017-Oct-16: Still true. :)\" This library has been done-done for a decade now. I used it last week. reply aeonik 18 hours agorootparentprevThe really nice thing about Clojure is it runs on the JVM. The entire ecosystem could die tomorrow, and you can still compile new Clojure code for any system that supports Java in the future. reply mvc 2 hours agorootparentprevThere's another Clojure rules library worth considering. It has a section in the README about why you might prefer it to Clara. https://github.com/oakes/odoyle-rules reply jiehong 11 hours agorootparentprevNuBank[0] mainly use clojure for most of their software, and NuBank is a big yet quickly growing company. [0]: https://en.wikipedia.org/wiki/Nubank reply Barrin92 20 hours agorootparentprevFrom the last view developer surveys I've paid attention to it didn't seem like Clojure was growing much but it's definitely still large enough of an ecosystem to be a valid choice. So, depends on your definition of 'going strong'. On its merits it's definitely still a great choice, I never really thought of it as particularly mainstream. reply rr808 16 hours agorootparentprevIts dead in the water. Sure, some people like it for their private projects and I'm sure there are some commercial products but I wouldn't touch it. I dont particularly like Scala either but at least it has Spark which means it'll be around for decades. reply fire_lake 12 hours agorootparentScala for spark is in decline too - people prefer the Python bindings for some reason. reply kunley 8 hours agoprevsync-deps and add-lib seems very cool reply MarkMarine 15 hours agoprevThis is a wonderful language I've only just started paying attention to, watching the talks from Rich on YouTube have ruined things I loved (like Either types.) I'm struggling with how to introduce it into my company without recommending my colleagues follow my path of working through 3 books and then watching most of the conj talks from the last 12 years on 1.75x speed, while building a personal project and re-implementing a couple of services I work with every day in it... but the lessons around simplicity I think are so critical, I'm going to find a way. reply lebski88 8 hours agoparentI've been at an organization that went from Java to Clojure about 12 years ago. I think there were two main things that allowed us to make the move: * No one was in love with Java. It was fine but we were doing the whole spring style super verbose Java and it felt like a lot of ceremony to get anything done. There had been an experiment with Scala previously but that hadn't taken off. * We had a service-oriented architecture which meant we could try Clojure out on a few new services and see how it felt. We ended up going from 2 services to moving the whole org over really quickly. A lot of excitement built up and people didn't want to be left out. At the end of things only 2 people decided they didn't want to learn Clojure. A few other things we did: * Bought loads of books and left them lying around * Started a Clojure club where we booked an hour a week and did some exercises in Clojure * Had a big meeting where we convinced everyone that Clojure was worth an experiment * Brought in 3 consultants to do some Clojure training for everyone * Probably strong armed everyone into watching simple made easy - it helped that lots of people had already seen it live that year There are a few talks about it floating around although they are very very old now and I'm not sure they're worth the time! https://whostolebenfrog.github.io/clojure,/deployments,/clou... reply bschwindHN 9 hours agoparentprevIt's funny because I went the opposite direction - from clojure to Rust, and I feel my programs are more maintainable, easier to re-read code written by myself and others, and runs without needing to bring along a virtual machine. I do like Rich's talks and agree that static typing can be taken a bit too far though. ClojureScript in particular is much nicer to work with compared to JavaScript reply chii 14 hours agoparentprevFind the least important project that one person can take on, and have that be the prototype for the clojure stack. Ideally, use someone well versed in the tech stack - otherwise, you're taking on double risk of a new tech stack plus unfamiliarity. This prototype needs to demonstrate the value of the clojure stack - which has to have a business value (aka, speed/ease of maintenance etc). Convince the decision makers to use clojure after the above prototype showed value, and use it to extrapolate value for other projects. This will then require a transition from doing the project, to teaching others (who might not know clojure at all). You cannot rely on just telling people to watch videos or read books - they won't do it, and it will cause failure in subsequent projects. You will have to hand hold, until the newbie \"clicks\". Unfortuantely, this is an uphill battle, because management will always want to hire for the \"regular/normal\" tech stack, and will have trouble finding clojure-ready people. So the company will continue to have to invest in teaching it to new hires, which is a drain that could tank the clojure move. reply nbardy 1 hour agoparentprevThe way is to drop Clojure and adopt it's principles. Teach your colleagues the functional engineering principles. You can write code that looks a lot like Clojure in any modern language now, a lot of the functional primitives have been adopted in mainstream. e.g. Async/await => channels. I started my career as a Clojure/Clojurescript developer 12 years ago. And now I do python for ML research and Typescript for prototyping all day. Clojure honestly help me back a lot of the time because the tooling is so far behind the large programming communities. Functional programming has a lot of good ideas, but none good enough to leave behind all the packages on pip/npm. I would only ever advise niche programming languages for small sub-teams that are highly technical were it makes a lot of sense. Something like compiler teams, webgl/triton for GPU programming, etc... reply lelag 12 hours agoparentprevHonestly, maybe don’t. You love Clojure, that’s awesome. But introducing it at your company if it does not have a lisp culture already might not go so well. You say so yourself: lisp dialects like Clojure come with a steep learning curve, and not everyone will appreciate the shift, especially if they're comfortable with the current stack. Forcing it on your team could create frustration, confusion, and a lot of resentment, not just toward the language, but possibly toward you. Sure, you might convert a person or two, but most will likely see it as unnecessary complexity. If you really want to write Clojure every day, you might be better off finding a company that already embraces it instead of trying to turn your current team into Clojurists. Sometimes it’s better to enjoy something for yourself than to make it everyone else’s problem. reply port19 12 hours agorootparentI'll second this. Many people are happily complacent with mainstream languages. A minority ventures out in $lang of the day for the fun of it, with functional languages being an even smaller minority. At a minimum, build some strong clojure skills first, such that when you introduce it to anyone else, you can do so with confidence reply defyonce 9 hours agorootparentprevit is better to have +1 company with Clojure (potentially hiring), than +1 Clojure dev looking for work reply chr15m 12 hours agoparentprevEvery company likes to hear about increased productivity and less bugs, and that's what Clojure/Script gives you. The trade-off is you get less resumes when hiring. The plot twist is the resumes are much higher quality. reply wokwokwok 8 hours agorootparentHa. I personally have sat in a meeting where a clojure enthusiast was explaining how he had quickly built a system. He could not explain the code he had written only three weeks before. Clojure suffers heavily from a “less code is good code, write clever code not verbose code” culture. For newcomers this creates dumpster fires that are quick to create and impossible to maintain. Anywaaay, long story short: no. It doesn’t. Specifically, I’ve seen it be a dumpster fire three times. Perhaps your experience has been different; but you are flat out wrong in your generalisation; and that arrogant attitude has been the root cause of all three failures I have personally had to clean up after. reply elric 8 hours agorootparentPeople who complain about verbosity and boilerplate in Java generally fall in 1 of 2 categories: people who haven't used Java for anything non-trivial in a very long time, or people who are bad at designing abstractions. Less code can be good code, but they largely are orthogonal axes. Without good abstractions, it doesn't matter whether code is dense or verbose, it will be bad and difficult to grok. reply puredanger 5 hours agorootparentHaving done substantial work in both Java and Clojure, my experience with abstraction in both is that in Java, making things more abstract almost always involves making the code larger (adding more interfaces, extending existing types to those interfaces, etc) whereas in Clojure making things more abstract typically means they get smaller. Over time and at scale, this matters quite a lot. Java code grows and grows at a super linear rate as it handles new and changing requirements. This is ultimately not sustainable. Clojure code typically grows at a more linear rate (accretion of attributes in data or operations on data), but has more tools to create abstraction that can actually (if wielded well), be sub linear instead. This kind of change is not free or easy in any language, but in Clojure it is at least possible. reply port19 12 hours agoparentprevleft-right-thingy makes me chuckle every time I watch \"Maybe Not\" reply FranzFerdiNaN 10 hours agoparentprevDont. It wont be appreciated because nobody but you can work on it, and one day you wont work there anymore and the company is stuck with a few projects in Clojure while the rest is on their regular tech stack. You are creating a major company risk just for your own personal benefit. reply minikomi 5 hours agoprevFantastic. Sure would love to get a clojure job one day. reply anothername12 3 hours agoprev [–] We had to dump a Clojure code base for Golang because it was too slow for lambda usage. Does any of this release help with startup time? reply diggan 2 hours agoparent [–] > Does any of this release help with startup time? Clojure (and indirectly Java) was never created with \"fast startup speed\" in mind. This is why things like `add-lib` (that was added in this release) is so useful, because you start your developing session once, and it stays open until you either have to restart your computer or done developing the project. Then the typical deployment target is either \"Push this .jar to a server somehow, start the process and let it run\" or \"User double-clicks executable, waits for application to be ready\". If you really need fast startup, you can go through something like https://github.com/ionutbalosin/faster-jvm-start-up-techniqu... Or if you're fine with slightly worse runtime performance, give https://github.com/babashka/babashka a try Finally, if you're OK with JavaScript you could give ClojureScript a try, has fast startup (as fast as NodeJS I suppose) but yeah, it's JavaScript. But overall, Clojure/Java isn't optimized for the use-case of \"Start process for each request, stop process once processed\" so I'm guessing you'll face an uphill battle there. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Clojure 1.12.0 introduces several new features and updates, including ending Java 8 compatibility and adding support for Java 21.",
      "Key updates include a fix for CVE-2024-22871, improved control over Java serialization identifiers, and updated dependencies for spec.alpha and core.specs.alpha.",
      "New features include interactive library addition, out-of-process tool function invocation, better process management, and enhanced Java interop capabilities such as using Java methods as functions and improved support for Java Streams."
    ],
    "commentSummary": [
      "Clojure 1.12.0 has been released, featuring add-libs, which simplifies sharing runnable code snippets and demoing Java libraries without boilerplate.",
      "The release includes functional interface changes, reducing the need for utility macros, and is compared to Groovy's @Grab annotation and Jbang's dependency feature.",
      "Despite concerns about the ecosystem's size, Clojure remains stable, reliable, and backward-compatible, with a community that values simplicity and deliberate development."
    ],
    "points": 351,
    "commentCount": 94,
    "retryCount": 0,
    "time": 1725567172
  },
  {
    "id": 41459865,
    "title": "Common food dye found to make skin and muscle temporarily transparent",
    "originLink": "https://www.theguardian.com/science/article/2024/sep/05/common-food-dye-found-to-make-skin-and-muscle-temporarily-transparent",
    "originBody": "0:58 Scientists use common food dye to make skin transparent – video Medical research Common food dye found to make skin and muscle temporarily transparent Researchers say procedure not yet tested on people could eventually be used to help locate injuries or tumours Ian Sample Science editor Thu 5 Sep 2024 14.00 EDT Share Researchers have peered into the brains and bodies of living animals after discovering that a common food dye can make skin, muscle and connective tissues temporarily transparent. Applying the dye to the belly of a mouse made its liver, intestines and bladder clearly visible through the abdominal skin, while smearing it on the rodent’s scalp allowed scientists to see blood vessels in the animal’s brain. Treated skin regained its normal colour when the dye was washed off, according to researchers at Stanford University, who believe the procedure opens up a host of applications in humans, from locating injuries and finding veins for drawing blood to monitoring digestive disorders and spotting tumours. “Instead of relying on invasive biopsies, doctors might be able to diagnose deep-seated tumours by simply examining a person’s tissue without the need for invasive surgical removal,” said Dr Guosong Hong, a senior researcher on the project. “This technique could potentially make blood draws less painful by helping phlebotomists easily locate veins under the skin.” The trick has echoes of the approach taken by Griffin in HG Wells’s 1897 novel, The Invisible Man, in which the brilliant but doomed scientist discovers that the secret to invisibility lies in matching an object’s refractive index, or ability to bend light, to that of the surrounding air. When light penetrates biological tissue, much of it is scattered because the structures inside, such as fatty membranes and cell nuclei, have different refractive indices. As light moves from one refractive index to another, it bends, making tissue opaque. The same effect makes a pencil look bent when dropped in a glass of water. Dr Zihao Ou and his colleagues at Stanford theorised, counterintuitively, that particular dyes could make certain wavelengths of light pass more easily through skin and other tissues. Strongly absorbing dyes alter the refractive index of tissues that absorb them, allowing scientists to match the refractive indices of different tissues and suppress any scattering. View image in fullscreen Before and after images of the use of the dye on a rodent. Photograph: handout In a series of experiments described in Science, the researchers show how a fresh chicken breast became transparent to red light minutes after being immersed in tartrazine solution, a yellow food dye used in US Doritos, SunnyD drink and other products. The dye reduced light scattering inside the tissue, allowing the rays to penetrate more deeply. The team then smeared the yellow dye on a mouse’s underbelly, making the abdominal skin see-through and revealing the rodent’s intestines and organs. In another experiment, they applied dye to a mouse’s shaved head and, with a technique called laser speckle contrast imaging, saw blood vessels in the animal’s brain. “The most surprising part of this study is that we usually expect dye molecules to make things less transparent. For example, if you mix blue pen ink in water, the more ink you add, the less light can pass through the water,” Hong said. “In our experiment, when we dissolve tartrazine in an opaque material like muscle or skin, which normally scatters light, the more tartrazine we add, the clearer the material becomes. But only in the red part of the light spectrum. This goes against what we typically expect with dyes.” The researchers describe the process as “reversible and repeatable”, with skin reverting to its natural colour once the dye is washed away. At the moment, transparency is limited to the depth the dye penetrates, but Hong said microneedle patches or injections could deliver the dye more deeply. The procedure has not yet been tested on humans and researchers will need to show it is safe to use, particularly if the dye is injected beneath the skin. Others stand to benefit from the breakthrough. Many scientists study naturally transparent animals, such as zebrafish, to see how organs and features of disease, such as cancer, develop in living creatures. With transparency dyes, a much wider range of animals could be studied in this way. In an accompanying article, Christopher Rowlands and Jon Gorecki, of Imperial College London, say there will be “extremely broad interest” in the procedure, which, when combined with modern imaging techniques, could allow scientists to image an entire mouse brain or spot tumours beneath centimetre-thick tissues. “HG Wells, who studied biology under TH Huxley, as a student would surely approve,” they write. Explore more on these topics Medical research news Share Reuse this content",
    "commentLink": "https://news.ycombinator.com/item?id=41459865",
    "commentBody": "Common food dye found to make skin and muscle temporarily transparent (theguardian.com)335 points by _Microft 23 hours agohidepastfavorite138 comments andai 3 hours agoI read a short story in my youth -- it must have been by Paul Jennings -- about a boy who got bit by a weird bug. His skin turned transparent and he had to go live in a cave. Many years go by and he gets bit again and his skin goes back to normal. He finally returns to society, only to find that everyone has gone transparent, and he is once again an outcast... reply Intralexical 7 hours agoprev> The team then smeared the yellow dye on a mouse’s underbelly, making the abdominal skin see-through and revealing the rodent’s intestines and organs. > The procedure has not yet been tested on humans and researchers will need to show it is safe to use, particularly if the dye is injected beneath the skin. How did they resist the urge to sneak a peak at their own arm or one of their fingers? reply TomMasz 6 hours agoparentIt's a food dye, if you can eat it you certainly can put it on your skin. And they probably did but don't want to announce that they experimented on themselves. reply derefr 1 hour agorootparent> if you can eat it you certainly can put it on your skin That doesn’t always follow. There are (organic, large-molecule) substances that your mucus membranes will protect you from, and which you’ll then digest (denature) and greatly metabolize (non-leaky intestinal absorption routes through the liver) and so render harmless; but which would greatly harm you if left on your skin, as the substance can potentially absorb from there all the way to your bloodstream, without any digestion or a chance at first-pass metabolism. Think, for example: testosterone gel. Eating it wouldn’t result in much if any testosterone entering your bloodstream — but rubbing it on yourself sure does. reply delecti 4 hours agorootparentprevThe dose makes the poison though. Tartrazine is already in cosmetics, but that doesn't mean a ton of it is still safe. reply cpncrunch 2 hours agorootparentAnother reason to avoid tartrazine. Who knows what its doing to our insides. reply delecti 1 hour agorootparentThat isn't remotely what I was saying. You can die from drinking too much water, that doesn't mean you should avoid drinking water for fear of what it's doing to your insides. reply cpncrunch 26 minutes agorootparentOf course. My comment was based more on this study. It’s concerning that it has this effect. reply TheRealPomax 2 hours agorootparentprevblue #1 would like a word. Also basic human biology: just because something's safe to consume (which keeps it isolated from the rest of your body until it's been through the digestive tract) in extremely low doses doesn't mean it's safe to expose yourself to a highly concentrated dose via external exposure. reply Mistletoe 2 hours agorootparentprev$25 and an Amazon order and posterity awaits. https://a.co/d/gJ1MQG3 Did the article imply you need red light to see the effect though? reply Mattwmaster58 1 hour agorootparentLooks like someone took you up on it, instead of a showing a price the Amazon link shows out of stock. reply speleding 5 hours agoparentprevThis is going to be a Halloween sensation if it ever becomes available to the general public! reply ethanol-brain 4 hours agorootparentIt looks like you need special sensors and a lot of light in certain wavelengths. Would like to read the paper. reply Palomides 4 hours agoparentprevyou'd probably get fired immediately for doing human experiments without IRB approval reply ithkuil 1 hour agorootparent\"it was an accident!\" reply siva7 6 hours agoparentprevYou don't play with chemicals reply lm28469 3 hours agorootparentThat's kind of how we got LSD, saccharin and microwave ovens. (not really \"playing with\" but not being super careful about safety) reply diggan 4 hours agorootparentprevEven when the play is \"touching\" and the chemicals are \"food dyes\"? I wouldn't say I'm a risk taker, but even I would probably try that out for giggles. reply perlgeek 3 hours agorootparentprevEven if not intentional, such things happen by accident. Have you ever read up on how the psychedelic properties of LSD were discovered? > While re-synthesizing LSD, he accidentally absorbed a small amount of the drug and discovered its powerful effects From https://en.wikipedia.org/wiki/History_of_LSD#Discovery reply lazide 6 hours agorootparentprevClearly you don’t know many chemists? You might as well tell EOD to not play with explosives! reply DocFeind 4 hours agorootparentconfirmed as correct reply smeej 7 hours agoprevI know they say \"not tested in humans,\" but I don't think anybody's going to convince me nobody in the lab tried it out when they thought nobody was looking, unless there's some really obvious (to experts) reason to assume this won't work in humans. reply alentred 8 hours agoprevIt is fun to imagine how my intestines become transparent every time I drink Fanta and there is no one to see it but the microbes living there. Who probably \"freak out\" in their own way. reply alwa 22 hours agoprevI’m surprised that this characteristic of an extremely common dye—being used in its main application, as a dye—hasn’t been described before. Surely there’s some limitation that’s obvious to those skilled in the chemical and biological arts? Or is it really just a matter of serendipity waiting til now to lead anybody down the path of trying it this way? reply qnleigh 11 hours agoparentMaybe the concentration has to be high enough that this wouldn't happen often in practice? The point made below about mice having thinner skin makes sense too, though there are parts of the body where skin is quite thin, like ears and wrists. I have a feeling that this will get tested by some intrepid YouTuber before the authors of the paper get approval from an ethics review board. I'll try to remember to Google this in a month or two. reply gadders 4 hours agorootparent>>The point made below about mice having thinner skin makes sense too, though there are parts of the body where skin is quite thin, like ears and wrists. Let's hope no-one gets it on their eyelids. reply RobotToaster 20 hours agoparentprevGiven how common it is, it does seem weird that nobody has spilled it on themselves and noticed this effect. reply rincebrain 20 hours agorootparentThe article says it's only to the depth it penetrates, so given that you have a lot of skin, comparatively, I'd guess it'd be hard to distinguish from the dye staining you weirdly for a bit. reply amy-petrik-214 14 hours agorootparenton this point curcumin aka tumeric has a quite a similar though not perfectly the same wavelength-adsorption profile (i.e. anything with a strong yellow color) tumeric / curcumin is often used a magic skin treatment type dealie. question is why are not all these wanting-to-have-youthful-skin type people discovering transparency! answer is below but TLDR human skin is thicker and doses are still low. some main points from the paper( damned paywell, see supplement) > the dye only goes about 1mm deep, so maybe that works magic in a mice but not so good in humans nor noticable. > the dye comes it at arnd 0.5-1 molar solution. gmw is 500 g/mol ish. so 1M solution is 500g in 1L or 0.5g in 1 mL aka 500 mg in 1 mL. Okay, fine, you prepare this and rub 500 mg on your big toe from a little 1 mL aliquot. the daily limit or whatever for the food dye is around 4 mg! Soooo... >on the latter point, safety, the supplement had a bunch of stuff where they were like \"we did all the normal blood tests on the mice, and looked at the tissue, and looked to see if they died later, and it all looks good\" reply rsynnott 9 hours agorootparentprevAlso, only specific wavelengths; from the article I don't think this is visible to the naked eye. reply ckemere 20 hours agorootparentprevMakes me want to rub on some Doritos just to see… reply ashton314 16 hours agorootparentSorry lemon juice guy, you really should have rubbed Doritos on your face before robbing all those banks. reply _Microft 23 hours agoprevPaper: „Achieving optical transparency in live animals with absorbing molecules“, https://www.science.org/doi/10.1126/science.adm6869 reply JumpCrisscross 21 hours agoparentAh, it \"reduce[s] the [refractive index] contrast between water and lipids, leading to optical transparency of live biological tissues.\" Craziest part being it was predicted using a classical optical model [1]! [1] https://en.wikipedia.org/wiki/Lorentz_oscillator_model reply sans_souse 10 hours agoprevI just got my Doritos dry rub on, followed by a Sunny D Shower, and now nobody can see me. reply RandomCitizen12 3 hours agoparentDon't forget to go to Canada and get some Cheezies reply arcticbull 22 hours agoprevFrom the article, the dye is tartrazine -- FD&C Yellow 5 or E102. reply excalibur 21 hours agoparentOkay well getting yellow #5 on your skin definitely doesn't make you invisible. Source: Doritos reply SketchySeaBeast 3 hours agorootparentWell, there may be something to it - get enough Dorito dust on you and you'll be invisible to the opposite sex. reply bdcravens 52 minutes agoprevStrange dating moment: \"I really do have a good heart!\" (takes off shirt, take out a bottle of dye, and smear it on torso) \"See, just look at it!\" reply pvaldes 22 hours agoprevNever tested on humans Some tropical American frogs evolved to do it naturally (fam Centrolenidae). Some fishes also can do it also in a few different orders (Siluriformes and Perciformes at least), so in lower vertebrates it is possible and evolved several times. But they have a different metabolism than ours and a mouse skin is much more thin than our own skin. I assume that this effect will work only on very small animals and the optical effect will hit some thickness limit somewhere. Could work on fingers but not in heart. At this moment my hype level is a 4 over 10. reply jldugger 21 hours agoparent> Never tested on humans But a few billion have ingested it in the past year, sometimes even in medical pill form to make yellow pills. Could be worse at higher doses but seems plausibly safe and worth further testing. reply karmajunkie 20 hours agorootparentThe poison, as they say, is in the dose... just speculating but the quantity of dye ingested versus that used to render skin transparent may be such that the former is relatively innocuous while the latter would be very harmful. In particular it seems to be genotoxic at relatively low levels so that would be concerning for use in humans. reply pvaldes 9 hours agorootparentI don't recall the case of anybody grabbing a doritos bag and seeing trough their fingers, but a lamp behind your hand definitely can turn your fingers translucent. Maybe with both effects combined? The more valuable contribution here is probably the idea IMHO. To know that the optical effects of the light can be manipulated with the correct stuff and we could search for it. An ointment seems of to be useful to a restricted volume, to maybe the first millimeters of the skin. We evolved totally transparent proteins that are hard, resilient and harmless. We have them in the eyes so we know how to do it. If we could only suggest the body to temporarily accumulate those proteins in the upper layers of the skin, or we could inject temporarily the proteins in local areas of interest that would be awesome (and maybe safe as long as is our own human protein)... On the skin the continuous shedding of the upper layers would probably self-fix the stuff. reply billfor 3 hours agoprevSome countries have banned it in humans, due to health concerns. https://www.verywellhealth.com/tartrazine-free-diet-83227 reply sschueller 21 hours agoprev> while smearing it on the rodent’s scalp allowed scientists to see blood vessels in the animal’s brain. Since when do mice not have skulls? reply mattkrause 20 hours agoparentMouse skulls are very thin and you can sometimes image directly through them! reply griffzhowl 21 hours agoparentprevMy thought too but later in the article it says that was by using the dye in combination with laser speckle imaging (whatever that is) reply Intralexical 7 hours agoparentprevThe article says they used laser speckle imaging for the brain test. reply dylan604 21 hours agoparentprevEveryone knows skulls are transparent in everything except x-rays. It is known reply janalsncm 20 hours agorootparentSkulls aren’t transparent in visible light either. reply ptsneves 10 hours agorootparentI guess not only are skulls transparent to light but jokes as well. Went right through chuckle reply lupire 17 hours agorootparentprevDead skulls, sure. For live skulls, it's considered white rude to check. reply jjkaczor 5 hours agoprevHalloween is about to become even more weird... reply kevindamm 5 hours agoparentHow long before someone tries to make a tattoo using this as ink? reply amelius 5 hours agoparentprev\"I need to go to the bathroom.\" \"Yes, I can see it.\" reply justinclift 10 hours agoprevWonder if this has potential for internal imaging too? For example, with an endoscope or other thing that checks internal passageways. Applying this stuff (or whatever is appropriate to the given organ) could potentially allow the optical visibility of more stuff. reply ardrak 21 hours agoprev> At the moment, transparency is limited to the depth the dye penetrates, but Hong said microneedle patches or injections could deliver the dye more deeply. Reverse tattoos incoming. reply HPsquared 18 hours agoparent\"Alpha channel\" dye. reply FjordWarden 20 hours agoparentprevSorry for being nerd, but your internal organs are going to get UV damage. reply murphyslab 20 hours agorootparentUV damage to internal tissues seems unlikely given that the tartrazine dye they used absorbs strongly in the UV region of the spectrum. You can see this in Figure S1 A & B: https://www.science.org/doi/suppl/10.1126/science.adm6869/su... Also the abstract of the article notes that strong UV absorption is likely a prerequisite for this effect: > We hypothesized that strongly absorbing molecules can achieve optical transparency in live biological tissues. By applying the Lorentz oscillator model for the dielectric properties of tissue components and absorbing molecules, we predicted that dye molecules with sharp absorption resonances in the near-ultraviolet spectrum (300 to 400 nm) and blue region of the visible spectrum (400 to 500 nm) are effective in raising the real part of the refractive index of the aqueous medium at longer wavelengths when dissolved in water, which is in agreement with the Kramers-Kronig relations. As a result, water-soluble dyes can effectively reduce the RI contrast between water and lipids, leading to optical transparency of live biological tissues. https://www.science.org/doi/10.1126/science.adm6869 However this kind of research into the effects of absorption bands on the transmission properties at interfaces might ultimately bring about more effective sunscreen formulations. reply JumpCrisscross 19 hours agorootparent> UV damage to internal tissues seems unlikely given that the tartrazine dye they used absorbs strongly in the UV region of the spectrum To expand: \"the most hazardous UV radiation has wavelengths between 240 nm and 300 nm\" [2]. While tartrazine has a lambda max at 425 nm in water [2], it has a second ridiculously-convenient peak around 260 nm [3]. TL; DR It should be mildly UV protective ceteris paribus. [1] https://ehs.umass.edu/sites/default/files/UV%20Fact%20Sheet.... [2] https://pubchem.ncbi.nlm.nih.gov/compound/Tartrazine#section... [3] https://www.aatbio.com/absorbance-uv-visible-spectrum-graph-... reply permo-w 19 hours agorootparentaccording to this study, tartrazine can cause kidney and liver damage in rats https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5326541/ like an x-ray, I'd risk that for a one-off doctors appointment, but I'd probably not risk it on my body at all times. maybe there are safer dyes that have the same effect reply JumpCrisscross 18 hours agorootparent> maybe there are safer dyes that have the same effect Given the effect is optical, perhaps encapsulation in benign, transparent beads? (Could be particularly effective is the goal is a tattoo.) reply EvanAnderson 18 hours agorootparentprevSo that whole \"get UV light inside the body to fight COVID\" trope could come true? >smileHey Tiktokers, who needs a stupid dye? Show your inner light. Swallow our new gastrosubmarine led pill and shit bright like a diamond. reply adamredwoods 20 hours agoprevI wonder if this would improve Digital Optical Spectroscopy for cancer detection and monitoring? Also related: https://www.ycombinator.com/companies/eden-2 reply azinman2 22 hours agoprevTruly wild. This could be an amazing advancement if true and safe! reply Reason077 22 hours agoparentI imagine it could eventually lead to a full invisibility serum, as documented in the classic Kevin Bacon film Hollow Man. Of course, we need to be aware of the side effects (mostly murderous rampaging). reply spuriouserror31 21 hours agorootparent> Of course, we need to be aware of the side effects (mostly murderous rampaging). Common side effects include rash, constipation, nausea, diarrhea, dizziness, homicidal urges, drowsiness, insomnia, headache, and dry mouth. reply Unai 17 hours agorootparentYou forgot blindness. If you're transparent, your eyes won't be able to refract light. Which is good if you also have homicidal urges, but awful if you get diarrhea. reply yencabulator 4 hours agorootparentAnd would you get invisible diarrhea? (This might be the more desirable of the two outcomes. Otherwise you the man may be invisible, but everyone sees your intestinal contents floating in mid-air.) reply lazyasciiart 11 hours agorootparentprevHow would it get into bones? Wouldn’t the likelier outcome be visible animated skeletons, rather than full invisibility? reply starkparker 16 hours agoprevSome practical VFX artists are gonna go wild with this reply wordsinaline 2 hours agoprevAnyone want to sell me some tartrazine? reply D-Coder 15 hours agoprevThe Washington Post's headline for this article is: Scientists use food dye found in Doritos to make see-through mice My first reaction was, what the heck have I been smoking? reply rbanffy 15 hours agoprevThis solves my Halloween costume for this year. reply kragen 12 hours agoprevspecifically tartrazine in only the red part of the spectrum. can this be real? reply aster0id 20 hours agoprevNew kink incoming reply roshankhan28 11 hours agoprevwhat are we trying to achieve with making skin transparent? I dont see a use case. anyone want to help me with it? please tell me more about it. reply Lio 7 hours agoparentI can think of a use case. The same one we have for modified transparent Zebra Fish in medical research. That is so that you can observe features such as the circulatory system. https://en.wikipedia.org/wiki/Zebrafish#Transparent_adult_bo... reply dpassens 4 hours agoparentprevIn addition to the medical usecases listed in the other comments, it's also just pretty cool. reply in_a_hole 9 hours agoparentprevKnee hurts, doctor can have a look and literally see what's wrong. reply BoatyPrint 11 hours agoparentprevDiagnosing some internal illnesses without xray or MRI. reply diogolsq 9 hours agoparentprevxray can only pick up information up to a level. an extra tool(window to our inner bits) without the necessity of making a biopsy is always welcome. reply tiahura 18 hours agoprevDon’t mice have skulls? reply swayvil 20 hours agoprevHalloween costume! reply freen 21 hours agoprevAwesomest Halloween ever. reply amelius 20 hours agoparent\"I can tell what you had for dinner\" reply moralestapia 22 hours agoprevIt says it's never been tested on humans and the proper diligence should follow, But given that we already eat large amounts of it with no harmful side effects, the expectations are good. reply gus_massa 22 hours agoparentThe dose makes the poison. Considering that food usually don't make your tongue transparent [1], probably you need to use more than the usual amount to get the effect. [1] Note that they get skin that is transparent only to one shade of red, it's not transparent to all the visible spectrum. reply moralestapia 21 hours agorootparentThe absorbed dose makes the poison. The effect of a substance is usually three orders of magnitude lower when you rub it on your skin vs. when you swallow it. reply JumpCrisscross 21 hours agorootparent> effect of a substance is usually three orders of magnitude lower when you rub it on your skin vs. when you swallow it Going out on a limb and guessing you're at an effective dose for something when it's making your skin transparent. reply fasa99 15 hours agorootparent(1) \"All things are poison, and nothing is without poison; the dosage alone makes it so a thing is not a poison.\" (2) assume it isn't absorbed into the larger body. Still the tissue absorbing it got a YUUUUGEEE dose. Then presumably most of it is washed out minutes later. So under that assumption we worry about localized tissue damage ---- --- which, if we're talking about things like cancer patients here who commonly get zapped with X-rays and gamma rays and antimatter and such, is perhaps not out of the ordinary. If there's no systematic damage the main concern would be cancer. If the skin dies, it can be fixed. And heck, a lot of cancer treatments also cause cancer i.e. many children with blood cancers go onto later get other cancers due to the medicinal cure of their blood cancer side effect. reply ryanwhitney 22 hours agoparentpreveh i just put some on the top of my hand and i didn't see any bones reply pfdietz 21 hours agorootparentTim: Look at the bones! reply DFHippie 22 hours agorootparentprevMaybe you should get that hand x-rayed. Is it particularly bendy? reply seydor 20 hours agoprevintrospective people eat doritos reply m3kw9 19 hours agoprevCan’t wait till it becomes a trend on instagram reply ImHereToVote 12 hours agoprevImagine this as face cream at a rave. reply evan_ 20 hours agoprevWhen my little brother was 3 or 4 he stepped on a nail in our yard, probably dropped during some recent construction. It went all the way through his poor little foot, straight through, out the top. I can see it, vividly, in my mind's eye. Mom scooped us up and rushed us, still barefoot, to the ER. I remember him being almost calm- not the way I would have reacted. They x-rayed his foot and soaked it in a tub of what I now know to be iodine to kill bacteria. I remember this clearly: it was the first time I'd ever seen an x-ray in real life, rather than just in alphabet books. Fortunately the nail totally missed anything important, so they just pulled it out and bandaged him up- no worse for the wear. He went on to be an honest-to-God track star so it obviously didn't have any lasting effect. Decades later we were talking about something and he said to me, \"Why don't they use that x-ray water anymore?\". I had no idea what he was talking about so I asked him to elaborate. The way he remembers the incident is that they put his foot into a bucket of amber liquid and, once submerged, his skin became transparent. He looked in and saw his own bones, blood vessels, and- in the middle of it all- the nail that was causing such a fuss. He described wiggling his toes, flexing his ankle, and seeing the bones and tendons move, directly, with his own eyes. His toddler brain, probably in shock, had combined the x-ray film and iodine bath. Over the years it had grown more detailed and reinforced. He described it with such clarity that I almost wondered if I hadn't been mistaken. He didn't believe me when I told him how I remember it. We called our mom who confirmed my version of events, plus did some googling, which finally convinced him. Anyway I just sent him this article. It's interesting that not only is the x-ray water he remembers theoretically possible, it would actually be amber. reply ajb 19 hours agoparentThat is a fascinating story. Historically there were actually \"live\" x-ray machines, where you could have seen yourself wiggling your toes. They aren't used now due to the horrific exposure to x-rays, but before that was understood to be bad they were used in shoe shops (!). I don't know that they were ever used in hospitals though https://en.m.wikipedia.org/wiki/Shoe-fitting_fluoroscope reply smeej 7 hours agorootparentI had a motion x-ray as recently as 2020. I don't know enough about the technology to know why this was different, but I have a copy of the video. Edit: This is the type of machine it was: https://www.dmxworks.com/ reply ajb 6 hours agorootparentThat's cool. I wonder how they reduce the dose enough that it's safe. Presumably they were quite careful about how long the exposure was? reply toast0 3 hours agorootparentDigital x-ray sensors require a much smaller exposure than film, and I'd guess a lot smaller exposure than a shoe sizer machine, too. For multiple exposures in motion, it will add up, but assuming there's a reasonable diagnostic benefit and the total exposure isn't too long, and the staff is well protected, it's a reasonable risk. reply smeej 3 hours agorootparentprevIt took several minutes and a couple tries to get the exposure right on certain shots. They didn't seem overly concerned about the exposure. The person operating the machine didn't seem at all worried about it, so I didn't worry either. Can't rule out that I should have! reply ajb 1 hour agorootparentThese days the machine itself should also warn if it's on too long, so perhaps the operator was relying on that. These days even UV treatment gets added to your record so that further treatments don't accumulate too much. Well, it does in the UK at least. reply eternauta3k 3 hours agorootparentprevAlso used for medical research (e.g. back injury research) reply dredmorbius 18 hours agorootparentprevAnd of course the most harmed by fluoroscopes weren't the customers (bad enough) but the sales staff, who had multiple daily exposures day after week after month after year. Checking your Wikipedia link: Yikes! These were used into the 1970s. And of course industry denialism of any possible harm the devices might cause.... SMFH reply mh- 3 hours agorootparent1981 in West Virginia according to some sources. https://www.museumofquackery.com/devices/shoexray.htm reply dredmorbius 23 minutes agorootparentMy head can only shake so much.... At least they had the good sense to give it up when notified. reply zackmorris 5 hours agoparentprevI don't know why I'm replying to this other than to add another anecdote about the fungibility of memory. I first saw a Macintosh computer around 1984/85 when I was 7 or 8 years old, and I vividly remember the color screen. They were demoing MacPaint or possibly a SuperPaint beta and I recall the palettes being in color. Except Macs at that time were black and white! Now I realize that it was probably synesthesia where some of the gray patterns looked blue, yellow, brown or even pink. So basically it was like dreaming and seeing colors which don't exist. Although nearly all of my dreams are in black and white, and I only remember a handful of dreams that had color, like a recent one that had a fruit bowl with all of the colors. https://en.wikipedia.org/wiki/SuperPaint_(Macintosh) https://en.wikipedia.org/wiki/Macintosh_Color_Classic (hadn't been created yet) https://www.youtube.com/watch?v=UVcv8ORSZEQ Color Macintosh Plus (mod) https://www.youtube.com/watch?v=slY_F1MxGlk The Mac Plus had modern multi monitor support in 1986 and I got it working! (not me!) I'm especially curious about the last link, because there's a remote chance that someone had a Mac Plus with a color video card that I was lucky enough to witness in a rare demo. But the odds of that are pretty slim. Maybe some old graybeard knows of such a thing. reply FiatLuxDave 2 hours agorootparentAre you sure it was a Mac and not an Apple ][ ? I believe those had support for color at the time. reply knodi123 20 hours agoparentprevThat's fascinating! I also have a vivid childhood memory that I can see, clear as day, despite knowing as an adult that it's impossible. It's really uncomfortable to combine the facts that a.) memory is unreliable, and b.) memory is what gives me my sense of self. (if you don't accept that second fact, that's fine, I'm not here to convince anyone or debate) reply nullorempty 19 hours agoparentprevWell, he actually might have been perceiving what otherwise we don't perceive. reply tampontim 2 hours agoprevnext [2 more] [flagged] ToucanLoucan 2 hours agoparent\"Endure\" holy shit. Imagine having this much to say about what other people do to their own bodies and being subjected to like... seeing it. For a few seconds. Sometimes. My sincerest condolences sir, it's a wonder you've survived such trials. reply ranger_danger 17 hours agoprev [–] Absorbing anything that ends in -zine into the body does not sound safe. reply dagurp 11 hours agoparentfrom Wikipedia: > Tartrazine is among six artificial colors for which the European Union requires products that contain them to be marked with the statement May have an adverse effect on activity and attention in children. > The FDA requires that the Precautions section of prescription drug labels include the warning statement, \"This product contains FD&C Yellow No. 5 (tartrazine) which may cause allergic-type reactions (including bronchial asthma) in certain susceptible persons. reply r2_pilot 14 hours agoparentprev [–] I hope you don't have allergies then as you might otherwise be taking cetirizine already. reply ranger_danger 4 hours agorootparent [–] no it gives me headaches anyway reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Stanford University researchers have developed a technique using a common food dye, tartrazine, to make skin, muscle, and connective tissues temporarily transparent in living animals.",
      "This method could revolutionize medical applications by allowing non-invasive visualization of internal organs, blood vessels, injuries, veins, and tumors.",
      "The process is reversible, with tissues regaining their normal appearance after the dye is washed off, although it has not yet been tested on humans."
    ],
    "commentSummary": [
      "Researchers discovered that the food dye tartrazine can make skin and muscle temporarily transparent in mice, revealing internal organs.",
      "The procedure has not been tested on humans, raising safety concerns, particularly regarding injection.",
      "The discovery has initiated discussions about potential applications and safety, with comparisons to fictional invisibility serums, but further research is necessary to understand its full potential and safety in humans."
    ],
    "points": 335,
    "commentCount": 138,
    "retryCount": 0,
    "time": 1725565702
  },
  {
    "id": 41462574,
    "title": "What happens when you touch a pickle to an AM radio tower",
    "originLink": "https://www.jeffgeerling.com/blog/2024/what-happens-when-you-touch-pickle-am-radio-tower",
    "originBody": "September 3, 2024 A few months ago, our AM radio hot dog experiment went mildly viral. That was a result of me asking my Dad 'what would happen if you ground a hot dog to one of your AM radio towers?' He didn't know, so one night on the way to my son's volleyball practice, we tested it. And it was awesome. There's a video and some pictures in my hot dog radio blog post from back in March. Fast forward a few months and one Open Sauce later, and Jay from Plasma Channel visited us in St. Charles, MO, for round two—where my Dad and I were prepared to measure (almost) everything: SWR, RF forward power, SDR on site, AM field intensity 25km (16mi) away, meat thermals, and—courtesy of Jay—some taste testing! Our full experience is documented in today's Geerling Engineering video: But I'll also summarize all our test results in this blog post, for easier reference: Test Setup and Safety Precautions DO NOT ATTEMPT. Don't mess with towers, especially AM broadcast towers. We consulted with an experienced broadcast antenna designer before any testing. Using conservative FCC guidelines (also see Supplement A), we determined a safe exposure distance for the tower and transmitter at this single tower site. Every tower, station, and frequency will be different, so again, do not attempt what we did. It was for educational purposes only. And science. Experiment 1 - Hot Dog Hypothesis: Well, we already knew the hot dog would make some noise. This time, we brought all our instrumentation, and measured how it affected the signal. Observations: The hot dog did, indeed, produce copious noise through plasma-air interaction. It did an excellent job demodulating the AM signal into audible sound, and the entire hot dog was heated to around 80°C—which is luckily a safe internal temperature for eating. What may be less safe is eating whatever charred remains were left on the end of the hot dog. The transmitter RF output (as measured on the control panel) rose to 14 kW (from a nominal 12) briefly, before the internal foldback protection cut power to around 6 kW (until we stopped shorting the hot dog to ground, after which the Nautel XR12 raised power back to 12 kW). Experiment 2 - Pickle (Gherkin) Hypothesis: Some commenters believed the salt content of a fresh gherkin would cause the arc to change from orange-ish (hot dog) to green-ish (pickle). We speculated it may turn more reddish... Observations: The gherkin was quite a pickle. While testing, there was a loud spark, then the transmitter quickly got very quiet. We originally thought it cauterized itself and caused less conduction, but were very wrong. As it turns out, the pickle was an excellent conductor, with much lower internal resistance than any of the meats we tested. The salt-saturated watery interior provided an excellent path from tower to ground! This was the only object we tested which caused the transmitter to completely disable its RF output, if only momentarily. The end of the pickle glowed orange, and we also observed a plasma shockwave (pictured above) in a few frames. Would love to see this with a high-speed camera! In the category of 'what-were-you-thinking' comes Jay from the Plasma Channel. He decided to taste-test the pickle, and immediately spat it out as he said it tasted strongly of copper. He speculates the taste may have resulted from the electrolysis of the copper we used to ground the pickle. We speculate he may be a little crazy—our kind of crazy. Jay has his own video on the experience here: Creating A Plasma Shockwave Using Wireless Energy. Experiment 3 - Bratwurst Hypothesis: Many commenters speculated a bratwurst would translate the normally-English radio signal into German. We had our doubts. Observations: The bratwurst did indeed translate the signal into German! Or, well... it broadcast the german phrases the on-air talent spoke during his morning show. The bratwurst was the floppiest of the tested meats, and had a rather phallic look as it was hanging off the end of our probe. The 'droop' resulted in a large contact patch, which produced more smoke than the hot dog, but not any perceptible difference in sound. The transmitter reacted about the same as it did with the hot dog. Experiment 4 - Vegan Hot Dog Hypothesis: We expected the vegan hot dog to perform similarly to the all-beef hot dog, though were wondering if it could surprise us. Soybeans and sugar may react differently than beef or turkey! Observations: The sound was a bit louder, the vegan hot dog was a bit cooler, and the end burned off a bit more quickly. The more disgusting bit was the end near the copper insertion point—some white substance oozed out the backside and did not look very appetizing (see photo above). Jay taste-tested the cooked vegan hot dog (this time biting off a section from the middle, not a part that came in contact with the copper) and described the taste as 'pretty good'. Experiment 5 - Corn Dog Hypothesis: We speculated the corn layer surrounding the hot dog may provide enough insulation to prevent a serious reaction with the tower. This item also was a physical manifestation of our sometimes 'corny' dad jokes. Observations: Copious amounts of smoke, followed by large bursts of flame. Honestly, this was the most surprising of the bunch. The smoke seemed to follow the leg of the tower at a fairly large distance from the point of contact! Unlike the other meats, the smell of the burnt corn dog was pleasant–almost sugary. The sound was not that loud, and apparently the corn layer provided enough resistance the transmitter's foldback protection circuit never activated; the transmitter continued at 12 kW power throughout our corn dog test. Nobody was brave enough to taste-test the corn dog. Experiment 6 - Breakfast Sausage Hypothesis: Will a meat meant for the 'a.m.' perform any better on an AM radio tower? Observations: Yes, in fact—this smaller bit of meat was louder than the rest, and seemed to burn very evenly. The breakfast sausage stayed under 70°C, and it quickly kicked the transmitter back to 6 kW (half) output, but was stable at that power output. The end was quite crispy. Experiment 7 - Hot Dog Warmer We also tested holding a hot dog on the stick within about 1\" of the base of the tower for approximately 60 seconds, but found there to be no significant heating at that distance. Part of the hot dog had to be touching the tower, creating the plasma arcs, to heat the hot dog at the 1460 kHz frequency of this broadcast station. At least at the 7 kW or so this tower was putting out. Conclusion If we ran the tests again, I would very much like to bring a sound pressure level meter. It would be interesting to more quantitatively measure the sound of each object. Some have also suggested using a better insulating rod—something like this $300 fiberglass rod. It would be an improvement over our wooden stick, though with the power at this antenna, the risk is extremely small that RF would arc through the stick, into a human holding it (especially with our thick rubber gloves), versus through the copper in the end. The bigger risk is heating and near-field RF exposure, which follows the inverse-square law. Distance is safety. I would love to get a high speed camera (capable of at least 10,000 fps) to capture the plasma interaction between the tower and the meat to see if we could visualize the amplitude modulation in plasma. Maybe also repeating the experiment at dusk, so the plasma is brighter. As it is, there are just lots of bright bursts of plasma that look interesting but mask the hidden modulation causing them! (If you're a Slow Mo Guy and you're reading this... DMs are open, lol.) Further reading Talking Hot Dog gives new meaning to 'Ham radio' The Mighty 'MOX: 50kW AM Tower site tour 1 Million Watts of RF - how the FM Supertower works radio rf am video youtube geerling engineering science plasma Add new comment Comments Steve Coffman – 1 day ago Hey, this reminds me of when my dad and I made an electric pickle! If you split a A/C cord into positive and negative and poke either end into a pickle, then plug that into a surge power strip, flip it on, and the pickle will incandesce (light up) until it burns out (60 seconds). Reply Anonymous – 6 hours ago In reply to Hey, this reminds me of when… by Steve Coffman Ummm, don't try this at home. First, AC doesn't have positive and negative. Second, if you touch one of those wires (or the pickle) accidentally you could die. Reply Rick – 3 hours ago In reply to Hey, this reminds me of when… by Steve Coffman You should patent your idea and create vegan light bulbs. Reply Jake – 3 hours ago Here's a video of some Russian youths having fun close up with an AM radio antenna, and they can hear the audio component resonant in the vaporization of the grass: https://yewtu.be/watch?v=b9UO9tn4MpI RF Burns are painful! Reply",
    "commentLink": "https://news.ycombinator.com/item?id=41462574",
    "commentBody": "What happens when you touch a pickle to an AM radio tower (jeffgeerling.com)302 points by _Microft 15 hours agohidepastfavorite98 comments JCM9 4 hours agoFor folks wondering why these sort of videos (there are lots on YouTube) always focus on AM towers: 1. On AM the radio energy literally pulses (the amplitude modulation) and thus the arcs of plasma will pulse too thus creating the audio noise. AM has a carrier wave that’s constant but the two sidebands of signal pulse from zero energy at silence to more power the louder the sound being transmitted. FM signals broadcast essentially the same power all the time since it’s the frequency and not the amplitude that’s changing. 2. Because the signal frequency is much lower on the AM broadcast bands the wavelength is much larger and thus the antennas are much bigger. On AM the tower itself is typically the antenna vs FM radio where the antenna is typically only a meter or two long at the top of a very tall tower. That’s what makes AM towers more dangerous as the tower can be carrying many kW of energy and if you touch it you’ll go zap zap. The towers typically sit on top of a ceramic insulator to insulate them from the ground whereas FM towers typically just are attached right to the ground (although with grounding straps for lightning protection). Finally (some folks don’t always know this) you can operate AM on the frequencies typically used for FM… it’s just a mode and works on any frequency. Aviation radios operate on AM but in the VHF band near FM broadcast frequencies. reply timr 3 hours agoparentAnother thing to note, since people seem to be focusing on the RF aspect of this: there's 20-30 Amps running to the tower in this video. If your body is the connection to ground for a 20 Amp current, from any source, you're going to have a lot more to worry about than a burnt pickle (I guess it's cool that you'd make radio sounds while you died?) When they put the pickle/hotdog/whatever an inch away from the tower without actually touching it, it doesn't even get warm. This isn't RF, it's just standard-issue AC electrocution. Maybe the one \"radio\" thing here is that the ground underneath a tower like this is essentially a big metal mesh, but even that isn't a factor -- they're literally hooking a jumper cable from the pickle to ground. reply geerlingguy 2 hours agorootparentRF burns are a lot different than electrocution-style burns, though. But I'm not an expert on either topic, I'd defer to some people who know more about it. reply runjake 59 minutes agorootparentAnecdotal: I was cooked by some pretty powerful ECM [electronics countermeasures] gear, because an ECM officer was dumb and had his equipment turned on while on the tarmac. My abdomen was up against the area where the antenna was, about 6 inches away. No outward signs of injury, I just felt an internal burning sensation and severe nausea pretty quickly. I was feeling okay after about a day or two. I never did get checked out by medical, so no clue of what permanent damage was done. reply timr 2 hours agorootparentprevDefinitely, but this video is not that. reply geerlingguy 50 minutes agorootparentSame disclaimer: I'm not an expert on this... but I have been talking a lot about RF burns and arcing with RF engineers, and I think there's more nuance to this. It would be interesting to see the difference grounding a hot dog through 7 kW AC (60 Hz) and seeing any difference in internal heating and arcing. Maybe a topic to explore in another video—especially if I can get access to a transmitter manufacturer's testing lab... reply MisterTea 2 hours agorootparentprev> electrocution-style burns Do you mean burning via resistive heat dissipation from current flow through flesh? There are also burns from plasma in arc discharge events. An arc discharge to the body can produce both. reply CobrastanJorji 1 hour agoparentprevWhy would we want aviation radios to operate in AM? Is it just that we standardized on AM before the 60s, it works well enough, and migrating would require a worldwide effort? Or is there some interesting advantage to AM for planes? Maybe superior range? reply K7PJP 1 hour agorootparentAM doesn’t exhibit the capture effect, so you can hear multiple transmissions at once. https://en.m.wikipedia.org/wiki/Capture_effect reply retrac 4 minutes agorootparentIt's also possible to detect the presence of an AM transmission (if not necessarily decode) at a much lower received power than with FM. With FM there's little in the way of graceful degradation. As signal strength falls it can go from full fidelity to silence with very little transition. reply gwbas1c 1 hour agorootparentprev> The ability to receive multiple signals simultaneously is in some cases considered beneficial and is one reason that the aviation industry, and others, have chosen to use AM rather than FM for communications. reply nsxwolf 26 minutes agorootparentprevOne reason is that AM signals blend together whereas with FM the stronger signal will tend to \"capture\" the others and be the only one heard. This matters a lot in busy airspace where multiple people may be talking simultaneously. reply ck2 3 hours agoparentprevThe history of AM radio and the invention of the mechanical sparkgap transmitters by Reginald Fessenden is absolutely fascinating. Imagine only having telegraphs and morse code and amateurs listening every night to the spark noises in morse then suddenly in 1906 (first done in 1900 !) you hear voices and music! https://en.m.wikipedia.org/wiki/Reginald_Fessenden can't seem to direct link the photos but scroll down to see what you are talking about with the base of the tower being a massive insulator scroll to: Brant Rock, Massachusetts, facility https://en.m.wikipedia.org/wiki/Reginald_Fessenden#Rotary-sp... reply jhallenworld 35 minutes agorootparentYou can still see operating Alexanderson Alternators running at SAQ (Grimeton Radio Station). Not AM, but the same equipment was used for AM by Fessenden. https://en.wikipedia.org/wiki/Alexanderson_alternator https://www.youtube.com/watch?v=yYZjz745yGA reply BoxOfRain 9 hours agoprevA soapbox of mine here in the UK is that since BBC and commercial AM radio is more or less dead with the remaining stations set to close over the next few years, Ofcom should open up the band to low-power broadcasting hobbyists. These already exist illegitimately and have done for decades, you can pick up plenty from the Netherlands and a few domestic ones as well on a sporadic schedule. It would be a nice thing to do from several angles I think and would help drive interest in radio as a technology in general; as well as building transmitters and aerial systems, there's things like setting up an audio processing chain to get the best possible modulation and being a disc jockey which will always have a bit of a buzz from being on the 'real' radio. If valves and vintage equipment are involved it would be an interesting form of technology history preservation and 'living history', and there's also an environmental angle where old analogue radio receivers could be prevented from becoming e-waste. There could be a minimal licencing regime to demonstrate the individual is not a complete numpty and a fee to PRS for music rights along the lines of how streaming works. Maximum power could be kept low especially at night to avoid interfering with countries in Europe where AM radio is still an active platform, and I don't think there'd need to be a lot of enforcement with respect to content since you'd only realistically be broadcasting to other anoraks. Additionally there's already precedent for non-profit stations where the medium of AM itself plays a role, for example former pirate Radio Caroline which uses it to keep its historic radio ship in operation. reply neilv 5 hours agoparentJust yesterday, I was talking with a colleague in the UK, who's selling a serious-sounding amateur radio tower. Whilst waiting for regulatory change, besides amateur radio station, are there other fun RF things one could do with such a tower's height? reply geerlingguy 5 hours agorootparentStick a meshtastic node at the top of the tower and be the envy of every meshtastic user! reply discretion22 6 hours agoparentprevI think you are looking for a Restricted Service License : https://www.ofcom.org.uk/tv-radio-and-on-demand/restricted-r... reply bArray 7 hours agoparentprevI think lots of communities running localised AM stations could be super cool. > There could be a minimal licencing regime to demonstrate the individual is not a complete numpty [..] I wouldn't bother and it just adds more resistance. > [..] and a fee to PRS for music rights along the lines of how streaming works. I think the quality is so low and the audience so few that it wouldn't matter. > Maximum power could be kept low especially at night to avoid interfering with countries in Europe where AM radio is still an active platform, [..] Yeah, not sure where the sweet zone would be though. > [..] and I don't think there'd need to be a lot of enforcement with respect to content since you'd only realistically be broadcasting to other anoraks. That would be the point, just low-power decentralised communities. Only real reason to get involved is if the power goes too high or band use is not respectful to other users. reply BoxOfRain 7 hours agorootparentThat's a good point about the regulation given the low quality, I suppose if it was a problem they'd already have gone after public SDRs capturing the broadcast bands. It doesn't sound like the sort of thing Ofcom would go for as I suspect it'd be seen as making unnecessary work for them, but you never know. Someone there clearly likes Radio Caroline (despite Ofcom's predecessors having fought to close it for decades in its pirate days) because they got awarded a 1 kW and later 4 kW power limit when AM community stations are usually much lower, so there might be sympathy towards the idea of more community AM generally. It would be a difficult thing to lobby for politically I think because it's such a niche interest, but it'd be an easy thing for them to do and there's not much else that part of the spectrum can be used for easily. reply dgacmu 6 hours agorootparentprevThe reason for licensing is similar to the reason for licensing ham radio: you get a slightly higher level of clue about not creating huge amounts of accidental interference, and a point of contact to yell at if they do. and a little safety education.... The ham radio licensing process is not onerous. reply bArray 3 hours agorootparentI went through it (admittedly many years ago), but ham licensing wouldn't really do anything for safe radio operation. I learned the real stuff from two very experienced operators. It would probably be easiest to regulate the transmitters than the people using them. reply dgacmu 2 hours agorootparentMe too, but at least there's some stuff in there (for extra) about RF safety. Not a lot, but enough that someone with an extra class license should know that they need to go do some calculations about the safe distance from their antenna based upon radiated power, etc., and hopefully that's enough to get them to actually do it. IIRC there was a question or two in the pool about RF burns. Not much in there that would stop you from electrocuting yourself, though, I agree. Licensing the transmitters is the FCC's other standard approach and would probably work except for radiated power safety and antenna issues -- which can be pretty big. You could easily create significant interference or hazard from a botched antenna or connection. (But also which you don't learn enough from just passing the exam.) reply WarOnPrivacy 5 hours agorootparentprev> I think lots of communities running localised AM stations could be super cool. I agree. My US thoughts on the likelihood of (and potential outcome of) opening AM to the public - they all focus on content. US AM content is mostly religious, conservative, sportsball and ethnic-usually-Latino. Those are the opposing interests to opening AM. To counter opposition, I'd open the upper half of the AM band to the public. To ease friction, I'd lift any regulatory fees and offer subsidies to offset costs. As for content on the newly open bands, I could see at least 2 of the current AM interests firehosing cash to saturate the newly open bands and markets (which might unwind over the long term). reply the_arun 4 hours agorootparentWhere is the energy coming from? The power source towers are connected? Already our electric bills are super expensive. How can we run localized AM Stations with high cost of maintenance? reply bArray 3 hours agorootparentIt depends how powerful, but running a 1kW station could be feasible for a home owner. Also I imagine they would generally have operating times which would greatly reduce operational overheads. reply WarOnPrivacy 2 hours agorootparentTrue and a community station might have community content and funding. Buying airtime is as old as broadcasting. It could also power down for a bit. I'm old enough to remember commercial TV going off-air overnight. reply justanother 7 hours agoprevI understand he got permission and everything was checked out by actual RF eggheads, but damn. I won't even change a HV run capacitor unless i'm wearing crocs, standing on cement, and wearing the rubber oven mitts. And even then, I keep one hand behind my back. Because there have been accidents, and they hurt (the pool pump run cap fails approximately annually in this climate and if I paid someone to change it every time, I'd be a lot poorer). That said, the food demodulating the signal into audible noise is badass. reply SoftTalker 3 hours agoparentJust short the terminals with a screwdriver before you touch anything else? (Look away in case there's an brief arc flash) reply FiatLuxDave 1 hour agorootparentOh man, that reminds me of a mistake I made a few years back. I had opened up a motor controller to fix it, and I knew to discharge the cap before messing around inside. I applied a screwdriver across the terminals to short it out, and was rewarded with a beautiful long and skinny arc as the screwdriver came into contact. I said out loud, \"That was cool\", and my coworker sitting behind me said, \"What was cool\"? I told him that I had just shorted out the cap and the arc looked really cool. So he said, \"Can you show me?\" I said sure, and plugged the controller in for a few seconds to recharge it, then unplugged it and proceeded to repeat what I had just done. What I had forgotten was that previously the motor controller had been unplugged overnight. When I touched the screwdriver to the freshly charged capacitor, there was a boom, a three inch fireball, and the end of the screwdriver was completely gone. As I sat there thunderstruck, my coworker said, \"You're right. That was pretty cool\". reply jdironman 13 minutes agorootparentWell, your comment was my deep laugh for the day. excellent story. When I was younger, I saw my father working on a ceiling fan...while it was on. I asked him why he did not flip the breaker first and he said \"well, as long as you don't touch both wires at the same time, you'll be fine \" Fast forward a few days later I am at school, and I see in one of the outlets one of the prongs for a power cable had broken off in it. I remembered his advice about not touching both sides and proceeded to try and pull it out using my fingers...you can probably imagine what happened. It grabbed hold of me for a few seconds and a lesson was learned. reply justanother 1 hour agorootparentprevYeah, I try to bleed it with a long-handle screwdriver for 30 seconds. In fact, the couple times I've managed to zap myself was with residual current even after that, so I can't imagine what the full potential is. It's just a no-fun job. reply shepherdjerred 3 hours agoparentprevWhy standing on cement? Wouldn't cement be considered a ground? reply alexjplant 3 hours agorootparentIndeed it is. Anybody who's spent time jamming in old basements with bad ground or two-prong plugs has learned this the hard way via a microphone or guitar (myself included). Shoes are essential - not even flip-flops are good enough because even something as simple as walking across a wet lawn will leave enough residual moisture to zap you. reply ljf 12 hours agoprevI mentioned over dinner at my parents house (about 20 years ago) that I'd read that running 240v through a gherkin would cause it to glow - and pretty much as soon as dinner was over, my father and I had the experiment set up. Gherkins and even pickled onions glowed brilliantly. I set up a basic site to share the video we'd taken and details of the experiment, and shared it to B3ta. Sadly all lost to time. reply xattt 9 hours agoparentI see a similar comment at the end of the original article that mentions that pickles incandesce. Is it true incandescence or is it just internal arcing? reply ljf 4 hours agorootparentI wish I had the video still - maybe I need to run the experiment again, this time with my kids? Tangent: I look back sometimes and realise how stupidly lucky I was to have a father who not only humoured my crazy ideas, but actively encouraged them - I only hope I am doing the same for my kids. reply bsder 12 hours agoparentprev\"WRL Technical Note TN-13 Characterization of Organic Illumination Systems\" https://simh.trailing-edge.com/semi/docs/WRL-TN-13.pdf reply dekhn 2 hours agorootparentOne of the authors, Alan Eustace, was an exec at Google (in the days when execs at Google had a clue) and also holds the record for highest jump (135K feet). reply edm0nd 40 minutes agorootparentBill Gates can actually jump over a chair. og Tech execs are awesome at jumping it seems! reply vatys 11 hours agorootparentprevFurther testing indicated that the taste was neither enhanced nor diminished, but remained ‘‘very much like a pickle.’’ Our conclusion is that the culinary potential of electrical stimulation is limited. reply voidUpdate 6 hours agorootparentI think bigclive would disagree about that, he is known for electrocuting his sausage and sometimes enjoying the taste after reply smolder 11 hours agorootparentprevThis is gold and I will be keeping this .PDF in my rather limited data hoard. reply hinkley 12 hours agoparentprevPretty sure my high school physics teacher did this one. reply jhallenworld 55 minutes agoprevA thing that just happened in Boston is that Bloomberg swapped their relatively low power transmitters with iHeart's Alternative Rock 92.9. This is awesome for Bloomberg's reach, but it means that we now have an AM rock station, probably for the first time since the 1960s: 1330 AM. We'll see how long this lasts.. Red Hot Chili Peppers on AM right now.. reply tokai 9 hours agoprevReminded me of this old classic video of some intrepid guys getting tufts of grass to play music with the help of a radio tower. https://www.youtube.com/watch?v=b9UO9tn4MpI reply bjornsing 11 hours agoprevA grounded pickle. The word grounded is very important here, and missing from the question in the title. reply geerlingguy 6 hours agoparentWe also tested a floating hot dog (we detached the leads from the ground wire, so it was basically the hot dog and about 3' of unattached copper wire), and it still made little sounds as it was touched to the tower. We didn't have a way to safely touch the hot dog with no extra wire attached, unfortunately. reply eternauta3k 5 hours agoparentprevI wonder if a floating human would still get zapped, due to its non-trivial capacitance to ground. reply bityard 2 hours agorootparentNot to do with RF, but there are old YT videos of HV linemen who literally hop out a helicopter onto an HV transmission line to manually inspect it. As the helicopter approaches, they hold out a long pole which is bonded to the aircraft's frame to bring it to the same potential as the line. It starts arcing quite a few feet out until the potential is neutralized and the lineman can \"safely\" step out onto the line and start working. I imagine this inspection work is done with camera-equipped quadcopters nowadays. reply geerlingguy 4 hours agorootparentprevMany tower climbers historically jumped onto AM towers (usually at lower power levels), and they still felt little shocks climbing the tower. Even if the tower is off, if it's near any other sites, they can draw a significant amount of RF (as a good AM tower is a good AM antenna) and if it's not grounded, that RF will go through a person too! This specific tower site doesn't require lights on the shorter towers, so it's not an issue here, but for sites with lights needing replacement, most nowadays turn off power to the tower and ground it before anyone climbs the tower. reply pacaro 3 hours agoprevThe tech trivia related to this that springs to mind is that the DEC Alpha processor was known internally by the code name EV, which stood for \"Electric Vlasic\" — although the suits backfit this in to \"Extended VAX\". (Vlasic is an American pickle brand.) reply dekhn 2 hours agoparentwell, alan eustace who's on the DEC electropickle paper also worked on the alpha, I bet he suggestedit. reply kazinator 12 hours agoprevIf it's forty below, your pickle freezes to the tower and you have to call 911. reply saagarjha 11 hours agoparentBonk reply unkeen 13 hours agoprevHow is it possible that these towers have not been made more difficult to access? Is it usual for them to be secured only by a low fence?! reply pewu 12 hours agoparentThere's a broader area protected by a high fence with barbed wire. They had access there, cause the father is a radio engineer and have friends on various sites. reply geerlingguy 6 hours agorootparentIt's also in bordered by two farms, with a flood plain across the street, in a rural part of St. Charles County, in MO. Granted, home builders keep building subdivisions closer and closer, but just 10-15 years ago the closest residence was a mile or so away (outside the couple farm houses). There's also danger/warning signage around the entire property, on all fences (including those around the towers). reply linuxguy2 1 hour agorootparentIs that the KH0J transmitter? I've driven past that countless times and it seems so run-down I've often wondered if it was still transmitting. So many times I've wanted to park in the lot and take a gander... Probably for the better that I haven't! reply geerlingguy 44 minutes agorootparentYep! Honestly this site is about average in terms of local tower site upkeep. Many station owners let their sites run a bit wild, unfortunately. reply razakel 11 hours agoparentprevThere'll be a higher external fence for access by vehicles and people who need to go near the tower (someone is mowing that grass), the short fence is just a reminder to go no further unless authorised. reply TeMPOraL 12 hours agoparentprevThe tech is so old-school that it predates the fear culture. reply mcpherrinm 12 hours agoparentprevThe AM radio tower that I know is near me has a short wooden fence close to the tower, and then a larger area surrounded by a high fence with barbed wire tops and warning signs. reply _joel 11 hours agoparentprevJeff's dad works there :) reply qwertox 12 hours agoparentprevAs soon as some kids jump over the fence and at least one of them ends up in a hospital with a severe condition, those fences will get replaced. reply hinkley 12 hours agorootparentTechnically the morgue is in the hospital… reply ablation 12 hours agorootparentDeath is a pretty severe condition, too. reply xattt 9 hours agorootparentHighly incompatible with life. reply pantulis 6 hours agorootparentSounds bad, is it reversible? reply lesuorac 5 hours agorootparentYes but it takes 3 days. reply function_seven 4 hours agorootparentThey tried to confirm this anecdote with a proper blind study, but the study kept proclaiming, \"I can see now!\" reply JohnMakin 7 hours agoprevI always wonder if there would be any pain in the death that results from touching one of these. I’d assume it’d be instant from the electricity traveling through your heart - or would you just burn up more slowly? reply alnwlsn 2 hours agoparentI've been gently bit by a small Tesla coil before (100s of kHz but lower frequency than AM). There is absolutely no 'electrical' pain to speak of - it is nothing like getting a static shock or touching line voltage. However, it still hurts because it burns you, like touching a tiny flame, which is the only way I could tell anything was happening. It also vaporizes your skin, which smells terrible. reply tigerlily 6 hours agoparentprevMight end up in hospital for three days, and then die. reply gosub100 2 hours agoparentprevit may not kill you. the ways that electricity harms the body is unpredictable. Depends on things like bare skin vs gloves, humidity, sweat, what phase your heart is in at that exact moment, and probably many more factors. since the voltage is oscillating very quickly, it _may_ not cause your muscles to lock up, so you _may_ just get the zap of your life and bounce off. Whereas other types (non-RF) electrocution cause the muscles to lockup and for them to remain in contact with the voltage, which increases the chances of death. reply grugagag 46 minutes agoprevIs pickle a new term for hot dogs? Probably similar conductors are congruent in this case, the heating/buring makes a lot of sense but what I wonder though is how it produces sound. reply awful 3 hours agoprevside comment; Cub Scout project books of the 1960s, as I recall, had you make a hot dog cooker by connecting line voltage to two nails through a board... reply SoftTalker 3 hours agoparentThere was actually a kitchen appliance that did this, we had one when I was a kid: https://www.youtube.com/watch?v=029jcmv4tIU reply awful 2 hours agorootparentHaha; Thank You for sharing that. reply chilling 11 hours agoprevSometimes I feel sorry for myself when I read articles like this. At the end of the page, I usually start asking myself, \"Why was I even curious about this?\" Anyway, I will probably use this knowledge in 10 years. Hopefully (so far, that’s how things have been going for me). reply thepuppet33r 9 hours agoparentI mean, sometimes it's edifying to just find out cool stuff about the world and the ways it feels a little magical. We have a local power company here that has a trailer with a set of power wires and a transformer on it, and at their events, a TRAINED linesman will do tricks with it. They spend the first half of the presentation doing safety instructions (\"don't touch the wire because you'll get fried\", \"here's how squirrels can cause shorts\") and the other half doing magic tricks like making pinwheels spin, metal film levitate, etc. Fun stuff to see. reply JosephRedfern 4 hours agoprevI'm curious as to how much paperwork was involved here. Was the pickle grounding out the transmitter and (presumably) interrupting the broadcast not an issue? reply amelius 5 hours agoprevWhy isn't there a bigger fence around it? reply Supernaut 11 hours agoprevWhat I didn't see explained in these videos, and which I'm now curious about, is the mechanism by which the hot dogs convert the radio signal into sound? I understand how a loudspeaker works, but since food products typically don't contain coils and magnets, how was the AM signal being demodulated and converted into sound waves? reply boneitis 15 minutes agoparentI haven't watched it yet, but they state in the beginning of Geerling's vid that Plasma Channel (run by the third guy in the video) should be covering this in their own simul-published video. https://www.youtube.com/watch?v=NowhPAMDOTo reply fuzzfactor 5 hours agoparentprevThe closer you are to the source of the radio waves, the less sensitivity will be needed in the receiver, and less audio gain you will need in your reproduction device. And the less efficiency you will need in your speaker, aka transducer. At these conditions there is also no more need for user-supplied power for the audio output to become audible, so no electronic amplification is needed. As you get closer to the source the need for a carefully crafted, somewhat complex, receiver circuit will diminish, and when there is only one audio program being broadcast on a single radio frequency, no need to discriminate between different frequencies. In an electronic radio, after the single radio frequency channel has been selected, then the radio frequencies are filtered out before electronic gain is applied to the audio alone. Otherwise audio power would be wasted amplifying radio frequencies that are not audible. The hot dog emulates all of these requirements, except for the receiver sensitivity that would be needed to respond very strongly from a distance. No noticeable demodulation until it touches the source directly. Then as a single-component device, a low-efficiency transducer, it conducts the full undemodulated RF power. Its frequency response as a transducer is probably not even as high as human hearing can go, and people can not hear any RF being reproduced anyway, so all you hear is the audio. Plus when it comes to hot dog conductivity, who could forget this futuristic home appliance from the 1960's: Amy demonstrates the Presto Hot Dogger https://www.youtube.com/watch?v=LMbQmp7yC-Y reply ryukoposting 5 hours agoparentprevI'm not an RF engineer, but I'll take a stab at it: With any modulation scheme, you have the \"carrier signal\" and the \"message signal.\" The carrier is the frequency you dial into your radio. The message is the thing you listen to - voice, music, whatever. Those two get \"modulated\" together and blasted out over an antenna, and ta-daa, radio! Amplitude Modulation is really, really simple. It's literally just the product of the carrier signal by the message signal. The carrier signal is a really high frequency relative to the message, which is where I'm guessing the \"resolution\" of the signal comes from. Now, hot dogs. Hot dogs probably don't resonate very well. Or, maybe they do, but just a little bit at low-ish frequencies - up to a couple thousand Hertz, but no higher. If that's the case, then a hot dog would act like a low pass filter! Since AM is just the product of a high-frequency carrier and a low-frequency message, a low-pass filter could ostensibly leave behind something that resembles the message signal. Proper AM demodulation involves diodes and whatnot, but I can't imagine a hot dog has semiconductive properties. Now, if it's an electrical signal, why can we hear it through the hot dog? A hot dog is not a good antenna. It's bad at inducing an electromagnetic field around itself. Instead, it converts the energy from the radio tower into mechanical force - motion, like the way a speaker moves. All of this could be wrong. Maybe the hot dog isn't serving as a filter, and it is indeed reproducing the AM carrier signal - it's just too high of a frequency for us to hear it. I don't remember my signal processing classes well enough to say for sure. Maybe my whole \"hot dog is a speaker\" explanation is bunk. Maybe hot dogs really are semiconductors. Not sure. reply winrid 10 hours agoparentprevJust the sparks themselves can produce audio! [0]. [0] https://youtu.be/lbubH1FovFc?si=T7Q7CqDNz3NtbLFl reply eternauta3k 5 hours agoparentprevPutting an AM signal through any non linear process will give you (shitty) demodulation. reply _joel 9 hours agoprevDon't tell Rick Sanchez reply chadcmulligan 6 hours agoprevyou can light up fluorescent tubes as well https://youtu.be/SDL9O2Fwb64 reply geerlingguy 4 hours agoparentWe actually tried that experiment; the tubes we had were a little older, so not sure how much that affected it vs the power at this site (the middle tower is 7 kW, which is a lot less than the 50 kW towers at more mid/high power AM sites). But it didn't light up near the tower. It did near the RF circuits above the phasor, though! reply kylehotchkiss 13 hours agoprevBeing curious is a virtue. Now I know how to avoid having to deal with a copper flavored pickle if I get too close to my nearest AM transmitter. reply thelastparadise 7 hours agoprevI'll be keeping my pickle far away from any radio towers. reply pjerem 13 hours agoprevOK that was pretty unexpected :) reply surfingdino 12 hours agoprevThat tower is TikToker magnet. reply greesil 13 hours agoprev [–] Not to state the obvious, but isn't there a damned good reason the tower is fenced off? You can see the fence in several of the pictures. reply stavros 12 hours agoparent [–] You can also see the reason in several of the pictures. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The experiment involved grounding various food items to an AM radio tower and measuring parameters like SWR (Standing Wave Ratio), RF (Radio Frequency) power, and meat thermals.",
      "Key findings included the hot dog producing noise and heating to 80°C, the pickle causing a plasma shockwave, and the bratwurst translating signals into German phrases.",
      "Future tests are suggested to include a sound pressure level meter, better insulating rods, and a high-speed camera to capture plasma interactions."
    ],
    "commentSummary": [
      "Touching a pickle to an AM radio tower can create audio noise due to the AM signal causing plasma arcs.",
      "AM towers are more dangerous than FM towers because they carry more energy and are larger.",
      "The experiment demonstrates the unique properties of AM signals and the potential hazards of high-power radio towers."
    ],
    "points": 302,
    "commentCount": 98,
    "retryCount": 0,
    "time": 1725592580
  },
  {
    "id": 41463734,
    "title": "2M users but no money in the bank",
    "originLink": "https://exercism.org/blog/september-2024-restructure",
    "originBody": "Find this post useful? Share it around! Find the post interesting or useful? Share it around and have others benefit too! Hi everyone! Last week we hit the huge milestone of two million users. Within a few hours, we also hit 45 million exercise submissions. A day later, I paid the final payroll for me, Erik and Aron, and our bank account reduced down to the point we can't afford to pay another. I think this sums up Exercism's story pretty well. Over 1,200 people per day sign up to Exercism. Tens of thousands solve exercises each day. But we don't have enough money to continue to work on the platform. We've tried a lot of things to change that. We've spoken to hundreds of funders and companies, but Exercism isn't the right fit for their support. It doesn't fit a niche that makes sense for them. By serving people everywhere, it seems we don't serve a narrow enough demographic that we align to funders' often narrow missions! The one area we have had some promising success is in advertising on the site. But the effort it takes to find advertisers and manage them, and my general desire not to flood Exercism with adverts, has meant that I feel this isn't a very sustainable strategy. I think it's fair to say that at this stage I've lost faith in the nonprofit business model working in a way that allows Exercism to reach any of its potential. Keeping something free for everyone relies on either the user being the product, or on significant donations, and without either, it's very hard to grow. Erik + OSS Restructure Probably the hardest thing about the situation right now, is that we can no longer afford to pay Erik, so he's leaving as an employee at the end of this week. Erik has been an absolute critical part of Exercism's growth and success over the last few years. He's also been a wonderful colleague and friend, and I'll really miss working alongside him. It goes without saying that I'm incredibly grateful to Erik for all his hard work and support. And I know many of you will feel the same (if so, please reach out and tell him!) Erik's a die-hard Exercism fan, and he's going to continue as a senior maintainer of a few tracks, and he'll hold onto his super-admin privileges, but the plethora of hidden (and often a bit boring) things that he does day-to-day need to get spread across the organisation. The one key thing we're enforcing is that every PR in a live Exercism repository should get a review before it can be merged (with only one exception outlined below). This has generally been the case anyway for a long time, but there are places where it's fallen through the cracks, so we've now scripted things to ensure this is always the case. To do this, we've come up with a new classification system for repos, and specific rules for each type: maintained: A repo that has multiple maintainers. All PRs require reviews from a track maintainer. maintained-solitary: A repo that has one maintainer. A new cross-track-maintainers team will get pinged to review all PRs. unmaintained: A repo that has no maintainers. The cross-track-maintainers team will get pinged here too. maintained-autonomous: A repo where all maintainers are also in the cross-track-maintainer team. This is the exception, where they can merge their own PRs. wip-track: An unlaunched track. As it's not \"live\" yet, it doesn't have restrictions. We've created two new GitHub teams that enforce this. @exercism/guardians: A team to check the safety of PRs to tooling repositories (test runners, analyzers, etc). Made up of a few longstanding polyglots. @exercism/cross-track-maintainers: A new team made up of longstanding polyglots who are active on the site on a day-to-day basis, and who have the same level of reviewing-pedanticism that I do (ie they're not more strict or more flexible than me). This is important, as I want a consistent, responsive experience from this team. Both teams are invite-only. I'll review them sporadically. We've also invited new maintainers and \"pruned\" a lot of inactive maintainers as part of this. To those people who have been removed - thank you for all you've done, and please know you're very welcome back if you find the time/desire to contribute in earnest to Exercism again! So what's next? So this has all been a bit gloom and doom so far. Things don't always go as you hope in life, but you have to make lemonade from the lemons! Right now, we have about 800 monthly donors and about $7,500 in monthly donations. That covers our server costs pretty much exactly. So if you're donating right now, thank you. You are literally keeping our servers on. Our donor base is generally quite stable, so I'm not too worried about Exercism's existential prospects. (It would be really good to build a bit of a financial buffer, so if you can afford it, please consider making a recurring or one-off donation 💙) We also have an amazing community, maintainer team, and group of mentors who keep adding new exercises (and tracks!), helping students, and numerous other things. Exercism has probably never been healthier as an organisation. It's growing faster than ever, more people are using it than ever, and I think the product and educational experience is better than ever. So I'm still deeply dedicated to growing and nurturing Exercism. For the last few months, I've been working on a new educational product teaching coding fundamentals that I'm going to launch in 2025. 96% of people who try to learn coding give up - which I find unacceptable, so I'm aiming to change that. My plan is to give beginners a rock-solid base, then funnel them into Exercism. I'm creating a new for-profit company for the new company, and going to use proceeds from that to keep Exercism growing. I've raised a little investment for this, which means I can continue to pay Aron's salary, so he'll be staying around, working on that with me, and tweaking Exercism as needed. I'm also planning (probably 90% certain) of running a dedicated learn-to-code course from Jan-March 2025, where I can test out some of what we've been building, and I can get my hands dirty working with the students who existing platforms don't serve. So keep out for an announcement about this soon. I'm exploring launching a basic version of Exercism Teams, as a way of making some extra revenue. There's a forum post here where you can leave thoughts. I'd really appreciate any you have! But first, I need a breather! I'll be taking the next two weeks off, unplugging and recovering a little. Thanks for all your support - emotional and financial. Exercism's community is phenomenal and I'm deeply grateful to everyone involved in the project. 5th Sep 2024 · Found it useful? Published by @iHiD 57.3k Jeremy Walker",
    "commentLink": "https://news.ycombinator.com/item?id=41463734",
    "commentBody": "2M users but no money in the bank (exercism.org)219 points by leandot 11 hours agohidepastfavorite156 comments insane_dreamer 59 minutes agoCongratulations on a very successful platform! (Success should be measured in usage/reach, not $). You've probably thought of this, but it might be easier to charge a very small amount -- say $1/month, which most people even students, could afford, rather than rely on donations. If you get 1% of users paying that, it's still $20K month which is more than you're getting now. (Of course managing the payments themselves costs money). It can still be non-profit (which is a great thing), so no one is getting rich off of it, and it doesn't poison the mission. But it could pay the bills. Update: Processing fees are a problem as posters have pointed out, so you'd probably want to make it $10/year, or $5/six months. It's still an easily decision for a very large number of people. Patreon has $1/month options, not sure how they do it though. reply charlie0 36 minutes agoparentWould $1/month even be worth it? It seems payment processors would take a big chunk out of that $1, which is why I very rarely see monthly subs of that amount. reply insane_dreamer 24 minutes agorootparentYou'd probably want to charge $10/year (once) rather than $1/month. It's still an easy choice for many people (of course still inaccessible for students in some countries). reply gradyfps 22 minutes agorootparentprevSome payment processors have \"micropayment\" fee structures, where they take a higher % (5% in PayPal's case) for a lower fixed fee per transaction. PayPal's traditional fee (for USD)[1] = 3.49% + $.3, for $1 = $0.3349 PayPal's micropayment fee (for USD)[2] = 4.99% + $.09, for $1 = $0.1349 Using that model would make sense in OP's case. [1]: https://www.paypal.com/us/webapps/mpp/merchant-fees#statemen... [2]: https://www.paypal.com/us/webapps/mpp/merchant-fees#micropay... reply whatevaa 33 minutes agorootparentprevYeah, if you want that little, do Bitwardens $10 a year. $1 transactions are ripe for abuse, checking if cards are active. reply datavirtue 22 minutes agorootparentprevWell, it's $12 a year. I always pay a sub for a year or two if it's that low. reply chris_pie 33 minutes agoparentprevDon't most payment platforms have a constant minimum fee per transaction? That would hurt you at a $1 price. reply wslh 22 minutes agoparentprev> Congratulations on a very successful platform! (Success should be measured in usage/reach, not $). Most organizations aim to survive as long as possible, so financial sustainability ($) is crucial. reply dartharva 27 minutes agoparentprevThere will still be plenty of students (mainly from outside of the West) who will immediately lose access if anything gets paywalled by even a cent because of various reasons. reply insane_dreamer 25 minutes agorootparentYes, for sure. You could make it free for users in X countries, based on IP. Yes, people elsewhere could use a VPN to get around it and use it for free but you're charging so little that anyone who can afford or has a mechanism to pay won't go through the trouble. reply BlackjackCF 45 minutes agoparentprevI think this makes a lot of sense. Same model as TryHackMe. reply giancarlostoro 31 minutes agoparentprevYeah their minimum is $10, which for me, I can only justify if I daily your project, or use it frequently. I love the site, but I don't use it nearly enough to justify this cost. $5 I might forget about. There's a site I rarely use that I pay $3.99 for, because itsI've lost faith in the nonprofit business model Great! You will find a way to generate revenue streams. This is a good pivot! I would recommend going fully open source and public domain as you add a profit model. IMO public domain for-profit companies are superior to (C) non-profit companies. Profits don't make you evil, closed source and copyright does. > every PR in a live Exercism repository should get a review before it can be merged Why? I recommend just merging in. Quickly fixing/undoing problematic commits. > $7,500 in monthly donations. That covers our server cost OMG!!! Stop! This money should go to you 3, not cloud providers. Server costs should be $0. This should be a local first, entirely client side site. Maybe 1 $50 a month droplet if you need some read/write user stuff. With less than 100K active users in a day, 1 server should be more than enough. Finally, ditch the (c) symbol at bottom. Go public domain! Here's my user test and authoring of this comment: https://www.loom.com/share/763e480438c4481ba0aa056c6ef0cbbb?... reply napoleoncomplex 9 hours agoprevMaybe this will be helpful to the author (partially already mentioned): - Nonprofit business model does not equal \"everything is free for the user forever\", I'm guessing you already know that, but the wording on why you don't believe in nonprofit business models explicitly mentioned keeping everything free as the reason. You can earn revenue from users in a nonprofit business. - You have a big audience with good engagement for the segment, there are multiple ways to make money without abandoning the core mission (job boards, screencast upsells for advanced courses, premium content, whatever else, look at how Remoteok.com makes money, copy-paste as the founder is super open on his process) - Being a for-profit business and fundraising, will temporarily solve your issue of having funds to run a business. It will not solve the issue of not knowing how to/being afraid to charge users or other parties for the value they get out of your product. You could already be solving this problem today, and you have a 2million audience pipeline built in to solve that issue. I'm not dismissing the challenge of some business segments being extremely difficult to make money in despite the value being meaningful, I work in healthcare, so I know, but since your new business will effectively be in the same segment, do focus on the revenue aspect much sooner and much than you think you'll need to, because you already know what happens if you don't. And big respect for what you've built in a super crowded space, you obviously have the product and user empathy chops needed, wishing you the best of luck on nailing the business chops! reply mef 9 hours agoprevout of money, final payroll, no alternative but to go into zombie mode, yet for the last few months the co-founder has been working on his next product which will launch in 2025. maybe everything that could have been tried was tried but this comes off like some of the effort spent working on the next company could have been spent keeping this one alive reply vidyesh 8 hours agoparentThey said they will be using the proceeds from that for-profile company to pay for a team member's salary and keep Exercism running as much as they can. So this next company could be considered to be an effort to keep this old one alive! reply p3rls 7 hours agorootparentIt sucks being out of money and then you have to fend off the \"why aren't you more dedicated\" line of questioning when you had to find an alternative to keep the company alive reply yieldcrv 3 hours agorootparentprevOooh contingent on the next unproven idea being economically viable. Amusing. I walk away from all business partners that think this way They hand waive away “who will pay what” reply dheera 53 minutes agoparentprev> but this comes off like ... You don't know more about the company than them. Most likely they saw this coming months ahead of time, and needed to figure out how to pay their own rents after actual doomsday and needed to pre-emptively start figuring out what's next. Founders who don't start with a pre-existing financial cushion have very, very little job security if they underpay themselves and their businesses shut down without an exit. Also, founders tend to be generalists, and most big companies don't need more generalists, so it's not easy to get hired, doubly so if you have wasted a lot of your brain pitching to investors and having coffee chats with clients. The harsh reality is, the more you are forced to chat with investors and customers instead of working heads-down, the more you lose your hard technical abilities that other people would hire you for. As a founder of a shutting down company, if you want to pay your rent on time, you need to do one of 3 things: (a) pay higher salaries prior to shutdown to give you some time to figure yourself out (controversial), (b) start studying to be a specialist well ahead of shutdown and get on the interview treadmill, (c) start working on your next thing well ahead of shutdown. If you do none of those things, things can get really dangerous to your personal finances. reply philipwhiuk 9 hours agoprev> For the last few months, I've been working on a new educational product teaching coding fundamentals that I'm going to launch in 2025. 96% of people who try to learn coding give up - which I find unacceptable, so I'm aiming to change that. Feels like you've been kickstarting a competitor/pivot on the side. reply sealeck 9 hours agoparentI think the tone of this comment is unnecessarily condemning (apologies if I am reading it incorrectly) – I can totally understand why someone who has worked for years on a non-profit business which has created a lot of value for people (I think exercism is pretty good software) might want to be able to at least pay themself. reply kelnos 8 hours agorootparentNon-profit doesn't mean you didn't get to pay yourself. It just means that any revenue that exceeds expenses must be reinvested into the business. reply slkjdlskjdklsd 8 hours agorootparentThat sounds like Amazon to me. reply JCharante 4 hours agorootparentExcept amazon shares would be worth much less if there was a promise of no dividends ever reply elAhmo 9 hours agoparentprevWith those stats, even with just 4% of people wanting to learn, and just a fraction of them actually paying, that would be dozens of thousands of paying customers. Even at 1USD per month, it seems a relatively sustainable business. reply FollowingTheDao 8 hours agorootparentYeah, I think he is confusing \"non-profit\" with \"non-payment\". You can have a non-profit company with paying customers. I think he need to take a basic economics class. reply JCharante 4 hours agoparentprevCharging people $1 on sign-up would probably lower that 96% metric reply Laaas 9 hours agoprevHow are they managing to spend 7.5k a month in server expenses? Are they using AWS? reply ihid 7 hours agoparentWe're paying ~$1k/month for all our webservers (which is a dozen ECS instances). They're handling about 3,000 requests per second (but that does sometimes massively spike to tens of thousands if not more). We're paying ~$1k/month for all our tooling servers (so the 150 different test runners, representers, analyzers that are used to check peoples code. There's >=1 of those running every second). Bare in mind, we're running student's code in over 70 languages here. Each is a docker container (often many gb large) - so we pay for HDD too. The biggest actual cost is the database at $2k/month. We have about 600 queries per second, and around 10MB per second (spiking to 47MB per second) of read throughput. It's an autoscaling database, but AWS determines that it's at the level it needs to be, and if I turn that down, performance suffers (I've tried). Beyond that, all the other individual services are ~$300/m, so quite small amounts, but for things we rely on (e.g. caching servers, a shared filesystem amongst all those servers, and other things). $1.2k on tax is also fun. reply ahofmann 3 hours agorootparentThank you so much for sharing your costs! I was very curious to see what the real expenses for AWS services look like, as I've always assumed AWS is massively overpriced. From the numbers you've provided, it seems like your total cost is around $5.5k, so I assume the remaining $2k is attributed to traffic. Everything looks quite reasonable, except for the database and traffic costs. I've run MySQL servers handling 150k reads/sec and 50k updates/sec with no issues, even on very cheap machines (around €30 per month). Years ago, we were serving over 100 million pages (of heavy content) per month, and we didn’t even bother looking at traffic statistics because, here in Germany, it’s hard to hit the traffic limits that most hosting providers impose. That being said, AWS is less expensive than I initially thought. At the same time, I’m confident you could reduce your hosting bill by up to $2k without even leaving AWS by setting up your own database server. Moving away from AWS entirely might be challenging, as managing a fleet of about 30 servers would likely take one or two days of work per week (I'm managing a dozen mostly idling servers and I work one day per month on them). When your hosting bill reaches $30k, I'm very sure it would be cheaper to hire someone (hint, hint ;-)), that moves everything to dedicated servers and manages them. reply stavros 51 minutes agorootparentprevI don't want to armchair ops your decisions, but maybe do consider moving to some dedicated Hetzner servers, at least for the runners. You can probably reduce that cost tenfold relatively simply. reply whatevaa 29 minutes agorootparentAWS will charge for network traffic, both in and out. Would need to calculate what is cheaper. reply stavros 24 minutes agorootparentThe runners take some code and return text, right? That shouldn't be too much traffic, hopefully. reply RobRivera 2 hours agorootparentprevA part of me is tempted to say 'maybe some cost reduction in cloud bill is possible' but for the scale you operate at and cost you already have, I feel like refactoring the revenue model is the greater strategic 'bang for your buck' reply AndroTux 1 hour agorootparentprevNot to be that guy, but I'm pretty sure that these volumes (talking about ECS and database here) could be handled quite well by a few dedicated $100/mo servers, provided the code isn't hugely unoptimized. So I'm sure you could save (very conservatively) half your budget when going on-prem. That said, it probably won't help you much overall, I would imagine. reply genewitch 48 minutes agorootparentprevI've mentioned this before on HN, but we had a single postgres machine primary read/write server that did 4k QPS 24/7. It had DDR ram as storage on a PCIe card, of course, but this was before \"SSD\" was a thing. It was for a site that hosted portfolios of images, for both people in the images and people who took the images, and such. The front end data (the images and text) was, iirc, 3TB. Sometimes we'd need a server in a new location, so a locked metal briefcase was carried from the DC where the front-end data lived, to our offices, where one of our \"IT\" people would then carry it on to the new location and offload it to those servers in that location. Anyhow that database server was probably ~$35,000 all in. That's 5 months of your current AWS spend. One of the things i did during that time was take a 2 generation newer server, a $35,000 1u Dell with 512GB of ram, and mirrored the postgres database into tmpfs and enabled replication, then we set that machine as primary. The new machine didn't break a sweat. So much so that one of the things me and the (really very awesome and nice; Hi, Chuck, if you're out there!) DBA did was set postgres to use no more than 640KB of memory, then ran the entire site, with 4k QPS, on that postgres instance with 640KB of memory (not counting the 280GB of tmpfs storage, of course!), just to prove it would work. It did - although some of the bookeeping queries (not sure what they're called) were taking a very long time, and would have had to be refactored to use less temporary memory, and such. anyhow my point is, there are people out there that can do things cheaper, or faster, or more efficiently than whatever you got goin on right now. Your statistics on \"per second\" usage and the like don't sound too demanding. If you could squirrel away $500/month for a few months, and you ask around for someone that can rack metal and has peering, there are people (including me) who could get you co-lo in > which doesn't actually buy one a whole lot of servers/databases/bandwidth/monitoring/logs/etc. It buys you 150 machines for a month 12 core 24GB VPS with unlimited traffic on a 1Gbps link See my comment below. reply swiftcoder 7 hours agorootparentAnd then you get to stand up your own databases, load balancers, monitoring, logging, etc. For which you need a development team with significant operations experience to do correctly - who will surely cost you more than $90k/year I get it, AWS looks expensive, but a bunch of their foundational services are real force-multipliers if you don't have the cash to build out entire operational teams. reply re-thc 7 hours agorootparent> And then you get to stand up your own databases, load balancers, monitoring, logging, etc. You get all if not most of this on DigitalOcean, Linode, Upcloud, Scaleway, etc all of a LOT cheaper. > but a bunch of their foundational services are real force-multipliers if you don't have the cash to build out entire operational teams. No, it's not. As above and for a lot of things AWS' complexity and silly factor can make it even worse. In GCP I can setup a dual region bucket. As simple as that. In AWS I need to setup 2 buckets, a replication role, bucket policies, lifecycle policies and a lot more just to get the same. Force multiplier? As in make it slower? EKS takes longer than the default Terraform timeout to provision. The list goes on... reply swiftcoder 2 hours agorootparentI think a lot of folks make their lives unnecessarily complicated by trying to do things on AWS in an explicilty non-AWS way (I inherited a startup codebase last year that did this to themselves in spades). Why go to the trouble of running Kubernetes on top of AWS, when ECS does roughly the same job at a fraction of the complexity? Why use Terraform when CloudFormation maps better to the underlying primitives? reply andrewstuart 7 hours agorootparentprev>> if you don't have the cash to build out entire operational teams Its just not true that AWS doesn't need expensive experts to get stuff done - it really does. Anyone who is half decent on the command line in Linux can get all those servers installed and running without the spaghetti complexity of AWS. The cloud as a magical place of simplicity and ease of use and infinite scalability in every direction - I think its the opposite of that - AWS is a nightmarish tangle of complexity and hard to configure, understand, relate and maintain systems. Its MUCH easier just to load up a single powerful machine with everything you need. I'm not saying that works for all workloads but a single machine or a few machines can take you an awful long way. reply swiftcoder 2 hours agorootparent> Its MUCH easier just to load up a single powerful machine with everything you need. I'm not saying that works for all workloads but a single machine or a few machines can take you an awful long way. For the core service I tend to favour monoliths too, but I would say you are vastly underestimating the halo of other crap needed to operationalise a real website/SaaS. Where is your load balancer? Your database redundancy? Where are backups stored? Where are you streaming your logs for long-term retention? Where are you handling metrics/alarming? Bare metal is great, but you have to build a ton of shit to actually ship product. reply fragmede 1 hour agorootparent> Where is your load balancer? Your database redundancy? Where are backups stored? Where are you streaming your logs for long-term retention? Where are you handling metrics/alarming? What we lose sight of, is that those things aren't as important as we, as SREs would like to think. When you're a corporation of one person, trying to stay afloat, you can just rely on a single big box and spend your time dealing with all the other problems first. Make sure you have an escape hatch so you can scale up if need be, but don't overengineer for a problem you won't run in to. reply re-thc 9 hours agoparentprev> Are they using AWS? Yes! reply Laaas 9 hours agorootparentYou’d think they’d use a cheaper hosting service if that’s literally the only thing preventing them from having positive gross profit. reply fendy3002 9 hours agorootparenthonest questions, is there any ECS-like hosting that's much cheaper? reply jfdjkfdhjds 55 minutes agorootparentfor compute of containerized payloads, in house servers is a no brainer for cost. almos zero sysadmin troubles. might even reduce the troubles of working with eks/ecs. now for storage and db, that's a different story. reply re-thc 8 hours agorootparentprev> is there any ECS-like hosting that's much cheaper? Most have adopted EKS-like services i.e. kubernetes. There is fly.io that's closer. Hope they improve on the reliability aspect. reply andrewstuart 9 hours agorootparentprev$50/month gets you a 12 core 24GB VPS with unlimited traffic on a 1Gbps link on Ionos. https://www.ionos.com/servers/vps $7500/month would get them 150 such servers. Maybe they should cut the AWS costs and hire their developer back. Id be really interested to hear the breakdown of their AWS bill. It would be a crime if they were blowing what money they have giving Amazon 9 cents per gigabyte egress. reply tptacek 1 hour agorootparent$7500/mo is less than half of one headcount --- if you could get all hosting for free. This is a sideshow. With these numbers, their viability is not determined by hosting costs. The problem here is that we all have opinions about hosting, but not so many useful opinions about business models, so hosting feedback is what this person is going to get. reply dspillett 8 hours agorootparentprevIf they are self-managing all the extras you get with a decent cloud setup (backups, node failover, load distribution and auto-scaling, multi-region or at least multi-DC for availability beyond single node failures, …), they are going to need an infrastructure person as well as that developer. Preferably two so the one isn't effectively on-call 24/7. And for that multi-DC for availability thing: you might need someone (or assign time from existing people) to manage the accounts with your various providers, you won't want tens+ of VPSs from just one provider like that. Of and on backups & failover, you need person-time (and other resources, but the people are probably the expensive part from the business PoV) to regularly test and adjust all of that, so you can be reasonably sure it all works when actually needed. And you need to manage replacing those people when/if they decide to move on to something new, etc… Also note that a lot of the things you are paying for (CPU cores, traffic, network throughput) in those nodes are shared resources (that Gbit link especially) and/or have “fair use” policies attached to them, and while the same might be true of cloud providers those policies are often either more generous or (perhaps more important from the business stability PoV) at least better defined. “Cloud” is still expensive compared to buying and managing individual nodes, even if you add in all the above and the things I no doubt forgot to mention, but it does give a lot more than the same cost in individual nodes than this sort of comparison suggests. And sometimes just not having to deal with all that, keeping the business more focused on its core competencies, is worth the extra expense. In DayJob we use Azure a lot, and sometimes I see the costs of certain things¹² and balk, and we do still have infrastructure people to manage the platform, but overall it works better for us than managing our own resources more directly. We have an extra complication due to our client base (regulated companies like banks and insurers, who are storing PII of both their own people and their customers with us) in that we have to give a lot of assurances on security and such which would be more work (it is already a _lot_ of work as anyone else in that sort of B2B arena can attest) if we self-managed everything. ---- [1] $2,400/yr for SFTP access to a storage account if you need it available 24/7?! Especially given we have at least one such account per client as their requirements understandably require that level of separation. I think we'll keep using the relay & management dashboard I setup in a few cheap VMs, thanks… [2] and the performance given the costs: AzureSQL³ I'm looking at you! [3] though again, some of that cost is in things like the scaling flexibility and other infrastructure convenience, which the business finds worth paying for reply re-thc 7 hours agorootparent> If they are self-managing all the extras you get with a decent cloud setup (node failover, load distribution and auto-scaling, multi-region or at least multi-DC for availability beyond single node failures, …) History has proven that most of the time these reduce availability than increase them. Any sort of failover and the complicated setups to get it going introduces bugs and issues more than the redundancy it provides. Have we forgotten the number of large single server applications running on single linux machines that never needed an unplanned restart or had a crash for years? And you can't beat AWS us-east-1 or Azure or GCP in outages lately. And I doubt any service like this needs auto-scaling. Most services barely will use up a proper single server i.e. something with >96 cores >1TB of RAM. > “Cloud” is still expensive compared to buying and managing individual nodes > And sometimes just not having to deal with all that, keeping the business more focused on its core competencies, is worth the extra expense. There are ways to not manage all that and still be in the cloud. It's called don't use AWS or Azure. reply nh2 7 hours agorootparentprev> they are going to need an infrastructure person No. I run multi-site Ceph+Nomad clusters with NixOS on Hetzner for our startup and maintaining those takes less than 5% of my time. By using great tools and understanding them well you can do it with little manpower. I learned all those tools in around 3 months total -- so around as much as getting a basic understanding of AWS IAM ;-) The only thing you don't get with that from your list is auto-scaling. But the with Hetzner the price difference vs AWS is 10x for storage, 20x for compute, and 10000x for traffic, so we just over-provision a little. And my 5% time /includes/ manual upscaling. Yes, I am oncall 24/7 to manage that infra, but I'd be as well when using hosted cloud services. Yes, fixing a Ceph issue, or handling Hashicorp Consul not handling an out-of-disk situation correctly is more complicated than waiting for S3 go come back from its outage, but the savings are massive. Testing whether your backup restore works is something you need to do equally with hosted services. So it is definitely possible to self-manage everything, for 5% of one engineer. reply dspillett 6 hours agorootparent> By using great tools and understanding them well you can do it with little manpower. “and understanding them well” is doing a lot of legwork there. From a standing start how does a startup that has the skills & experience to make the product but not necessarily manage the infrastructure get to the point of understanding the tools well, or even knowing which tools are best to learn to the point of understanding well? > So it is definitely possible to self-manage everything, for 5% of one engineer. I can accept that as true, if you have the right person/people, and they are willing (particularly the on-call part). reply bloopernova 37 minutes agoprev:( exercism has been great. I've been subscribed to the insiders program for more than a year now, I wish I could help more. reply heeton 9 hours agoprevI don’t know if Jeremy will see this, but: At my org it’s hard to get justification for donations. However if this was something like ~100$ a year or whatever per dev, I’d be paying it today for my team. reply ihid 8 hours agoparentHello :) Appreciate the comment. If you have thoughts on that, I'd love to hear them here: https://forum.exercism.org/t/exercism-teams-coming-soon/1266... reply throwaway2225 8 hours agoparentprevI remember reading an article about a non-profit discovering a work around for this problem. They created a subscription plan that had no real value except maybe adding some trivial \"feature\" like a gold star next to their name (I don't remember the details). This made it possible for the companies to receive a standard invoice that had a greater chance of approval. reply whatevaa 18 minutes agorootparentYeah, can't justify donation to corporate, need some reason to pay for stuff. reply benreesman 9 hours agoprevWhere the fuck are the VCs looking at serious hackers with millions of users who haven’t gotten the business model dialed in yet? Y-Combinator says “build something people want”. Two million sounds like a lot of people. I’ve only glanced over this so I could be missing some critical fact, but superficially it sounds like pmarca or pg should write a check before the rest of us stop believing in the startup lottery. reply ahstilde 27 minutes agoparentWell, the standard quote leaves out \"and will pay for\" reply ozim 9 hours agoparentprevOnly real metric I see is 800 monthly donors and $7500 from them ($10 per person) - that's what that business is worth, those are really people that want (they pay so that's what matters). Having 1600 people sign in daily and never logging back again - creating 2M zombie accounts is I suppose critical fact that you are missing. reply benreesman 9 hours agorootparentIf it’s two million churned out dead accounts, non-replaced, and 800 actual people who care then the author of the post was posting in bad faith and I’d retract my remark. To get from 800 real people to two million user id rows one would be running some kind of spam scam, and if that’s the case I apologize. reply ozim 8 hours agorootparentI don't think it is case of spam scam. I do think they really can have legit sign ups, but people \"wanting to learn code\" usually fizzle out quick. I have my experience as a dev when friends/family/colleagues ask for guidance, I provide them with links resources and some mentoring and after 2-3 days they don't follow up ever again. But not using metric like daily active users, returning users, might indicate that they want to inflate their worth or they convinced themselves to believe in the wrong metric. reply benreesman 8 hours agorootparentOh I don’t doubt for a minute that there’s some gap here. But the key people are serious enough to list rigorous code review as a core value in the next breath after “I just stopped paying everyone including myself.” If the millions of users thing is even a little real, that’s a galactically less risky play than friggin LangChain for Pets or whatever. I hope I’m being paranoid but I get the sense that someone pissed off someone important. reply EduardoBautista 9 hours agoparentprevWell, exercism is a \"not-for-profit organisation registered in the UK\" according to the footer of their website. Edit: It appears that their \"not-for-profit\" message in their footer is a bit misleading, as explained by those who replied to my comment. reply benreesman 9 hours agorootparentOpenAI is a 501c nonprofit. Doesn’t stop Sam taking big time meetings more often than he checks his email. reply LunaSea 9 hours agorootparentPart of OpenAI is a nonprofit, not in its entirety. reply benreesman 8 hours agorootparentMatt Levine uses a diagram to allude to the complexity. And that was before Larry Summers and the National Security Administration got involved. A better term for OpenAI would be “rogue state”. https://www.bloomberg.com/opinion/articles/2023-11-20/who-co... reply choult 9 hours agorootparentprevThey're not officially a non-profit, they're a limited company. Obviously they can still operate as such - that's down to the board how they distribute profits via dividends, so they might choose to do so. A true non-profit company in the UK would be a registered Community Interest Company, or a registered Charity. reply ihid 8 hours agorootparentHello. This isn't actually correct. Exercism is a Company Limited by Guarantee. It has no shareholders. It can't pay dividends. Community Interest Companies do have sharedholders and can pay dividends. CIC's are definitely not charities in the scope of the word that you're using it. reply physicsguy 8 hours agorootparentprevThey've not set up the structures for it to be not-for-profit here, they're just an ordinary registered company. Typically you'd form a Charitable Trust or Charitable Incorporated Organisation, and Exercism isn't listed as either on the Charity Comission website. reply renewiltord 9 hours agoparentprevThere's nothing special about a VC. It's just someone with money to allocate. Go ask them to give you a big chunk of the company for $25k if you think this is just a few steps from being a blow-up success. Being able to differentially detect when a company is successful is a pretty good skill. If you think you've found a diamond in the rough, you should go in. reply benreesman 9 hours agorootparentThis absurd hagiography about efficient markets allocating capital will be viewed by future historians like some kind of flat earth theory. Eugene Fama himself is walking back the idea and he won a Nobel Prize for asserting it. Markets are what people do when they’re not having sex. No sense in fighting markets. Cartels and market failures are what happens when the holders of capital aren’t terrified of Lina Khan or Maximilian Robespierre for longer than 12 seconds. The Battery Club is for kingmakers who decide things together for their mutual benefit behind closed doors. They learned their lesson after Don’t Poach Gate: it’s not in writing anymore. reply surfingdino 9 hours agoparentprev> Where the fuck are the VCs looking at serious hackers with millions of users who haven’t gotten the business model dialed in yet? Busy investing in AI? reply blitzar 7 hours agorootparentThese guys should \"pivot to AI\". Should be able to get a full B for an Ai company with 2 million users. reply benreesman 7 hours agorootparentFuck I’ll train a LLaMA tune for them on Saturday(s) gratis. reply re-thc 7 hours agorootparentprevSo Exercism AI? reply huijzer 27 minutes agoprev> We've tried a lot of things to change that. We've spoken to hundreds of funders and companies, The goal isn’t to get investors! It is to get money from customers. A lot of startups seem to get this wrong. reply lolinder 19 minutes agoparentThis is apparently a nonprofit, not a startup. They weren't looking for investors, they were looking for donors. reply rurban 9 hours agoprevThis are the LinkedIn comments on this post: https://www.linkedin.com/posts/exercism_activity-72374803032... reply physicsguy 9 hours agoprevThis is the problem with ed-techs. Nobody wants to pay. Those that do (Universities, schools) are also competing with the platforms to some degree. reply fredgrott 42 minutes agoprevI wonder why this would not be a fit for GitHub and Microsoft...seems like it could complement GitHub... reply leetsbehonest 9 hours agoprevI just don't agree with this leetcode industry. That, recruiters and the whole tech hiring industry that has spun off from a process originally intended to get to know and gain confidence in a potential employee. It is just I have doubts in the educational help these platforms really deliver given that there are already so many resources to learn these days say compared to 20y ago. reply ihid 8 hours agoparentWe're not really part of the \"leetcode industry\". People have used Exercism to learn new programming languages for a decade. We've deliberately not wanted to become a place of competition or a recruitment space. We've always focused on helping people learn based on their intrinsic motivations. reply leetsbehonest 7 hours agorootparentSorry you are right, what I posted isn't fair. I should have read more into it. reply ihid 7 hours agorootparentNo problem. Thanks for acknowledging that! :) reply h1fra 9 hours agoprevKudos for being passionate and providing stuff for free. A lot of people will probably tell you to add a paywall, not sure it's breaking the \"non-profit business model\" if you keep the price really low. But at the same time, even a low price would deter some users (myself included) and it would also devalue your content :/ reply ihid 8 hours agoparentThanks :) reply Fokamul 10 hours agoprevAlso internet is flooded with similar learning websites. First time I've heard about exercism though. Looks cool. reply ainiriand 9 hours agoparentCompleted the whole c++ and PHP paths there. It is by no means a way to learn those languages in my opinion. reply tr33house 9 hours agoprevFirst time I've heard about them. I hope this helps them get a bigger donation pool and support from similarly minded organizations reply NoblePublius 3 hours agoprevCrazy idea: charge $1 reply sneak 9 hours agoprevWhy not charge 5000 users money instead of servicing 2M users for free? It seems to me if you can’t get 1 in 500 of your users to give you $10 per year then maybe your product isn’t actually valuable or useful and should just shut down. I say this without knowing anything whatsoever about this product or its utility; it just seems like a general thing. If you have this many signups and you can’t charge even a tiny tiny fraction of them, it means the signup number is irrelevant. reply galactus 9 hours agoparentThey say in the article they tried to force 1000 random users to convert to paying account and none of them did reply grardb 9 hours agorootparentCan you point out where they said this? reply philipwhiuk 9 hours agoparentprevThey're charging 4000 users. The paywall is ethical. reply yieldcrv 3 hours agoprevSo you need to charge, but don’t want to lie about the 100% free part even though you can change that So you need to upcharge. It is 100% free… to start and then there is a subscription that is paid to finish the language course, shown in monthly cost but charged annually by default more languages? charge more You can sell the account data to recruitment firms. Everyone hates this but you know that your users are the product, your users know that they are supposed to be the product. Keep a cut with the recruiters so they have to pay you a little commission when candidates land a job reply acureau 43 minutes agoparentI'm not sure whether to be appalled by your suggestions or impressed by your blatancy reply KoftaBob 8 hours agoprev> I think it's fair to say that at this stage I've lost faith in the nonprofit business model working in a way that allows Exercism to reach any of its potential. Keeping something free for everyone relies on either the user being the product, or on significant donations, and without either, it's very hard to grow. Non-profit =/= the product is free. The vast majority of hospitals and universities are non-profit, and their product/service sure as hell isn't free. Nonprofits operate under a non-distribution constraint, meaning any surplus revenues must be reinvested into the organization's mission rather than distributed to private ownership. What they've lost faith in is running a business with a free product. reply andrewstuart 9 hours agoprevHow can there be NO money in 2 million users? reply aswerty 9 hours agoparentI would be more interested in active users. I have had personal projects with 100s of registered users yet I was the only one who actually used it. So 2M users might translate to somewhere between 1000 and 10000 unique users per month. Considering the niche; many of them young people with very little discretionary spending money. reply ihid 8 hours agorootparentWe have about 70,000 MAU. People tend to spend an intense few weeks learning a language, then disappear for a year. Then come back and learn another language. A large part of the 2M is still \"alive\" (I don't know exactly what number that would be, but I'd think around 600k) but Exercism isn't the sort of product you use day-in-day-out. reply thinkingemote 9 hours agoparentprevThey have 800 monthly donors totalling $7,500 per month. That is some long tail but I doubt the 2 million are active users. reply Joel_Mckay 9 hours agoprevShould offer some paid structured courses for $200, and offer a 90% discount for existing users. Without revenue any company will fail regardless of popularity. A firm may acquire the company for the customer/lead list, but I wouldn't count on that kind of valuation matching the work your team put into the projects. =3 reply echelon 10 hours agoprevWhy is this free? That's the problem here. They'll easily get 10-100x their donation amount if they make this freemium. They don't even have to degrade the core experience. Life takes energy. You need to make some of it back to survive. Asking for money isn't a dirty thing. reply pjc50 9 hours agoparentIt's free because all the competition is free and switching costs are zero. They claim that trying to upsell people causes them to quit. reply ZephyrBlu 10 hours agoparentprev$7500/mo in donations is also already really, really good. It seems like they could easily turn this into a viable business with some small changes. reply OccamsMirror 10 hours agoparentprevit's that any profit made must be reinvested into the organization to further its mission, rather than being distributed to shareholders or owners. Non-profit organizations can and often do generate revenue that exceeds their expenses, in other words... profit. The key distinction is how that surplus is used. In a non-profit: - Profits are reinvested to support the organization's goals and activities. - There are no owners or shareholders who receive dividend payments. - Any surplus funds are typically used to expand services, improve operations, or build financial reserves for future needs. Non-profits still need to be financially secure. reply FollowingTheDao 9 hours agoprevThe biggest issue I had with the tech boom and the current tech culture is when they replaced \"profit\" with \"people\" as a metric of success. To me they took the phrase \"people over profit\" and turned it into \"people are profit\". It is time investors businesses and started looking at the bottom line again, even non-profits. I mean can you imagine if we based the success of a store with how many people walked in even if they did not buy anything? Even non-profits need to make money, so their business model was either wrong or they do not have a product worth paying for. On top of that we are probably in economic stagflation so we will be seeing more stories like this as the months go on. reply tpoacher 7 hours agoprevJust donated a small amount. I think this is a nice service, and can think of a couple of friends who struggle with programming (professionally!) but are too embarrassed to ask and progress, and could make use of this service. I hear the pain-points about the donation-driven model not rising to the task, but I do wonder how prominent that particular call to action is on the site. On one hand you don't want to bombard your users with annoying jimmy-wales-style boo-hoo donation banners. On the other hand you don't want your users to be completely oblivious to the fact that their favourite service is about to be shut down if everybody thinks that \"it's ok, they probably have enough money / I wouldn't make a difference anyway\". Have you considered having a discreet yet prominent progress bar on the website, showing your monthly donation needs/goals? This could act as a good prompt for users to consider donating. One suggestion would be to accompany this by an information button, which when clicked takes you to a page explaining the different costs that need to be covered, where your money goes when you donate, and a detailed breakdown of what is currently still required / missing. Optics-wise, I would also try to find a way to differentiate between \"large\" donors and donation \"trickles\". E.g. you could color code on that progress bar different \"tiers\" of donation (or perhaps display this separately as a pie-chart in the breakdown information page). The point of this is to show to people who might be tempted to donate \"small\" amounts but are sitting on the fence because they don't think it'll make a difference, that it \"can\" actually make a cumulative difference, and push that kind of user past that threshold and donate \"something\". Alternatively / additionally (you may do this already), if and when you see that a user has already extracted value from your service, such as, e.g., when they have submitted their 100th exercise, you could show a \"congratulations\" banner that says that you hope they're finding the service useful, and politely asks them if they could consider donating (oftentimes worded as \"buy us a beer or two\"). If they decide to donate, then after their donation, you could also have a tickbox at the bottom of this banner to ask in a respectful manner (i.e. not a dark-pattern-worded / confirmshaming one) if they would like to be reminded again after some time / number of exercises, or if they simply prefer to make a one-off donation and that's fine. Finally, depending on your resources, if people \"do\" buy you a \"beer\", it would also be a nice touch to thank them for it, in an as personalised a manner as possible. Better yet, you could give them some sort of 'reward' / 'recognition' on the site; e.g. I think something silly such as revealing a hidden feature that allows a user to then tick a box to add a silly 'holding a beer' overlay to their avatar icon (in a similar way to how stackoverflow gives 'hats' close to christmas time), would actually go a long way to motivate people, after seeing these beer mugs on other people's avatars. And it's \"silly\" enough that people might donate to get this just for the fun and silliness of it. The donation model is an odd one. Obviously, not everyone donates, but I think given some prompting and lack of friction in doing so, there's a significant number of people who would be inclined to donate out of a sense of gratitude, but who don't do so if they haven't been given a reasonable opportunity / visibility to do so, or some sort of confirmation that their donation doesn't just go to greedy shareholders on top of some sort of pre-existing dodgy revenue stream, but makes an actual difference to real people running the service. reply thunderbong 9 hours agoprevThe title has a typo - it's Exercism, not Exercise. reply dang 1 hour agoparentThanks! Fixed now. Submitted title was \"Exercise has 2M users but no money in the bank\". Solution is not to fix the typo but to follow the site guidelines: \"Please use the original title, unless it is misleading or linkbait\". It's not necessary to add the company name since the domain is displayed next to the title. reply zelphirkalt 8 hours agoprevAt some point they messed up their login with google captcha stuff. From the moment I discovered this new state of affairs, I have avoided exercism. A shame, that they ruined it. reply dlahoda 53 minutes agoprevTried to donate in crypto, failed. Bad UX. May I have just address and chain to send to? reply efitz 1 hour agoprev [–] From the article: > “I've lost faith in the nonprofit business model”. There’s your problem right there. Investors want profit. If you want investors then you have to convince them you’ll deliver ROI. Altruism is not a business model. There is nothing wrong with altruism but it is not compatible (except in short term or insignificant ways) with most of the business world, which is profit driven. reply darth_avocado 1 hour agoparentNon profit doesn't mean you survive on donations. Non profit can still charge money to keep the lights on. If you have 2M users, charging $0.50/year for use can still get you $1M to run your business. Edit: I think the comment was taken quite literally. The point I was trying to make was that the user base exists, monetization for profit is definitely hard, but monetization for keeping the lights on can work. You could try a flat fee for all users, you could do seasonal exclusive contents to support the platform, you could try selling merch, you could literally put a banner annually like Wikipedia does etc. The point being, if you have 2M users and you provide enough value, there are ways to make it work. Donations unfortunately don’t work, because it’s not top of mind for people and people need a little pushing. reply mrmuagi 1 hour agorootparentAs a side point I was curious how low you can charge given processing fees, and you'll have to charge $1 to get $0.50 cents roughly (checked Stripe/Paypal for my currency CAD). reply darth_avocado 19 minutes agorootparentUpdated the comment with clarification reply chaos_emergent 1 hour agorootparentprevthis isn't at all realistic; a tiny fraction of free users are going to be willing to pay for your product. reply darth_avocado 19 minutes agorootparentUpdated the comment with clarifications. reply bee_rider 1 hour agoparentprevHe wrote: “I think it's fair to say that at this stage I've lost faith in the nonprofit business model working in a way that allows Exercism to reach any of its potential.” Removing the context that makes it clear that a quote is only applying to a very limited situation is a bit dishonest. reply mdgrech23 1 hour agoparentprev [–] I think it's fair to say we need a new model, just saying but all of that is way bigger than me or you or Exercism. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Despite reaching two million users and 45 million exercise submissions, the platform is facing financial challenges and cannot afford to pay its team.",
      "Erik, a key team member, is leaving due to financial constraints but will continue as a senior maintainer; repository management has been restructured with new GitHub teams for quality control.",
      "The platform has 800 monthly donors covering server costs, and the founder is launching a new educational product in 2025 to teach coding fundamentals and support the platform's growth."
    ],
    "commentSummary": [
      "Exercism.org, with 2 million users, faces financial challenges despite its popularity, having no money in the bank.",
      "Suggestions to cover costs include charging a small fee ($1/month or $10/year), though concerns exist about deterring students, especially in non-Western countries.",
      "The platform currently relies on $7,500 in monthly donations for server costs, prompting discussions on shifting to a for-profit model or finding new revenue streams for sustainability."
    ],
    "points": 221,
    "commentCount": 156,
    "retryCount": 0,
    "time": 1725606998
  },
  {
    "id": 41464371,
    "title": "Swift is a more convenient Rust",
    "originLink": "http://blog.namangoel.com/swift-is-the-more-convenient-rust",
    "originBody": "October 2, 2023 Swift is a more convenient Rust I’ve been learning Rust lately. Rust is one of the most loved languages out there, is fast, and has an amazing community. Rust invented the concept of ownership as a solution memory management issues without resorting to something slower like Garbage Collection or Reference Counting. But, when you don’t need to be quite as low level, it gives you utilities such as Rc, Arc and Cow to do reference counting and “clone-on-right” in your code. And, when you need to go lower-level still, you can use the unsafe system and access raw C pointers. Rust also has a bunch of awesome features from functional languages like tagged enums, match expressions, first class functions and a powerful type system with generics. Rust has an LLVM-based compiler which lets it compile to native code and WASM. I’ve also been doing a bit of Swift programming for a couple of years now. And the more I learn Rust, the more I see a reflection of Swift. (I know that Swift stole a lot of ideas from Rust, I’m talking about my own perspective here). Swift, too, has awesome features from functional languages like tagged enums, match expressions and first-class functions. It too has a very powerful type system with generics. Swift too gives you complete type-safety without a garbage collector. By default, everything is a value type with “copy-on-write” semantics. But when you need extra speed you can opt into an ownership system and “move” values to avoid copying. And if you need to go even lower level, you can use the unsafe system and access raw C pointers. Swift has an LLVM-based compiler which lets it compile to native code and WASM. Deja Vu? # You’re probably feeling like you just read the same paragraphs twice. This is no accident. Swift is extremely similar to Rust and has most of the same feature-set. But there is a very big difference is perspective. If you consider the default memory model, this will start to make a lot of sense. Rust is bottom-up, Swift is top-down. # Rust is a low-level systems language at heart, but it gives you the tools to go higher level. Swift starts at a high level and gives you the ability to go low-level. The most obvious example of this is the memory management model. Swift use value-types by default with copy-on-write semantics. This is the equivalent of using Cow for all your values in Rust. But defaults matter. Rust makes it easy to use “moved” and “borrowed” values but requires extra ceremony to use Cow values as you need to “unwrap” them .as_mutable() to actually use the value within. Swift makes these Copy-on-Write values easy to use and instead requires extra ceremony to use borrowing and moving instead. Rust is faster by default, Swift is simpler and easier by default. Swift takes Rust’s ideas and hides them in C-like syntax. # Swift’s syntax is a masterclass in taking awesome functional language concepts and hiding them in C-like syntax to trick the developers into accepting them. Consider match statements. This is what a match statement looks like in Rust: enum Coin { Penny, Nickel, Dime, Quarter, } fn value_in_cents(coin: Coin) -> u8 { match coin { Coin::Penny => 1, Coin::Nickel => 5, Coin::Dime => 10, Coin::Quarter => 25, } } Here’s how that same code would be written in Swift: enum Coin { case penny case nickel case dime case quarter } func valueInCents(coin: Coin) -> Int { switch coin { case .penny: 1 case .nickel: 5 case .dime: 10 case .quarter: 25 } } Swift doesn’t have a match statement or expression. It has a switch statement that developers are already familiar with. Except this switch statement is actually not a switch statement at all. It’s an expression. It doesn’t “fallthrough”. It does pattern matching. It’s just a match expression with a different name and syntax. In fact, Swift treats enums as more than just types and lets you put methods directly on it: enum Coin { case penny case nickel case dime case quarter func valueInCents() -> Int { switch self { case .penny: 1 case .nickel: 5 case .dime: 10 case .quarter: 25 } } } Optional Types # Rust doesn’t have null, but it does have None. Swift has a nil, but it’s really just a None in hiding. Instead of an Option, Swift let’s you use T?, but the compiler still forces you to check that the value is not nil before you can use it. You get the same safety with more convenience since you can do this in Swift with an optional type: let val: T? if let val { // val is now of type `T`. } Also, you’re not forced to wrap every value with a Some(val) before returning it. The Swift compiler takes care of that for you. A T will transparently be converted into a T? when needed. Error Handling # Rust doesn’t have try-catch. Instead it has a Result type which contains the success and error types. Swift doesn’t have a try-catch either, but it does have do-catch and you have to use try before calling a function that could throw. Again, this is just deception for those developers coming from C-like languages. Swift’s error handling works exactly like Rust’s behind the scenes, but it is hidden in a clever, familiar syntax. func usesErrorThrowingFunction() throws { let x = try thisFnCanThrow() } func handlesErrors() { do { let x = try thisFnCanThrow() } catch err { // handle the `err` here. } } This is very similar to how Rust let’s you use ? at the end of statements to automatically forward errors, but you don’t have to wrap your success values in Ok(). Rust’s compiler catches problems. Swift’s compiler solves some of them # There are many common problems that Rust’s compiler will catch at compile time and even suggest solutions for you. The example that portrays this well is self-referencing enums. Consider an enum that represents a tree. Since, it is a recursive type, Rust will force you to use something like Box for referencing a type within itself. enum TreeNode { Leaf(T), Branch(Vec>>), } (You could also us Box>> instead) This makes the problem explicit and forces you to deal with it directly. Swift is a little more, automatic. indirect enum TreeNode { case leaf(T) case branch([TreeNode]) } Note: that you still have to annotate this enum with the indirect keyword to indicate that it is recursive. But once you’ve done that, Swift’s compiler takes care of the rest. You don’t have to think about Box or Rc. The values just work normally. Swift is less “pure” # Swift was designed to replace Objective-C and needed to be able to interface with existing code. So, it has made a lot of pragmatic choices that makes it a much less “pure” and “minimalist” language. Swift is a pretty big language compared to Rust and has many more features built-in. However, Swift is designed with “progressive disclosure” in mind which means that just as soon as you think you’ve learned the language a little more of the iceberg pops out of the water. Here are just some of the language features: Classes / Inhertence async-await async-sequences actors getters and setters lazy properties property wrappers Result Builders (for building tree-like structures. e.g. HTML / SwiftUI) Convenience has its costs # Swift is a far easier language to get started and productive with. The syntax is more familiar and a lot more is done for you automatically. But this really just makes Swift a higher-level language and it comes with the same tradeoffs. By default, a Rust program is much faster than a Swift program. This is because Rust is fast by default, and lets you be slow, while Swift is easy by default and lets you be fast. Based on this, I would say both languages have their uses. Rust is better for systems and embedded programming. It’s better for writing compilers and browser engines (Servo) and it’s better for writing entire operating systems. Swift is better for writing UI and servers and some parts of compilers and operating systems. Over time I expect to see the overlap get bigger. 350 Kudos 350 Kudos",
    "commentLink": "https://news.ycombinator.com/item?id=41464371",
    "commentBody": "Swift is a more convenient Rust (namangoel.com)219 points by mpweiher 9 hours agohidepastfavorite242 comments noelwelsh 8 hours agoHmmm...I disagree with a number of statements in the post but I think the following two hypotheses will make for more interesting discussion than some nitpicks: 1. A large part of why many people love Rust is that it's the first time they've used an ML family language. One of the innovations of Rust was to create a community that felt like home to Unix hackers who weren't programming language nerds. 2. Rust is the first language to bring non-GC automatic memory management to the mainstream. It won't be the last and it might well be the worst. Other languages in this space include Swift (as in OP's post), OCaml[1], and Scala[2]. These alternatives take the approach that tracking ownership is not the default, which is fine for the majority of programs and far more ergonomic. There's also a corollary 3. The age of Smalltalk is over. It's now the age of ML. (Amusingly, going backwards in time, from 1983 to 1975). The languages that dominated the 2000s (Ruby, Python, Javscript, PHP) were all more or less derived from Smalltalk (everything is an object! dynamic types! runtime metaprogramming!) The new languages (Rust, Scala, Swift, Kotlin, etc.) are ML family languages. Similarly, back in the day you could learn, say, Ruby, and still be reasonably proficient in Python or JS. Now you can learn, say, Scala, and pick up Rust or Swift reasonably easily. [1]: https://blog.janestreet.com/oxidizing-ocaml-locality/ [2]: https://dl.acm.org/doi/full/10.1145/3618003 reply Loic 7 hours agoparentIn this context, ML is Meta Language: https://en.wikipedia.org/wiki/ML_(programming_language) reply kingofthehill98 6 hours agorootparentThank you! The whole time I was like \"what in the absolute hell is a ML language\". reply noobr 4 hours agorootparentprevthanks, i'm bad at abbreviations and don't like when people just throw them like this without first using the whole term at least once reply thiht 25 minutes agorootparentThis is indeed an abbreviation, but it doesn’t convey meaning. At this point ML is just the name of the thing, it could not expand to anything and still convey the same meaning. If you don’t know ML, knowing what it stands for won’t help you. It’s like JS, either you know what JS is or you don’t. It’s not about what it means, it’s about what it is. reply plorkyeran 3 hours agorootparentprevExpanding this abbreviation conveys zero information. It’s a programming language named ML, and if you haven’t heard of it then giving the etymology of the name isn’t going to help. reply arghwhat 8 hours agoparentprev> Rust is the first language to bring non-GC automatic memory management to the mainstream To nitpick, the first language to bring non-GC automatic memory management to the mainstream would be either Forth or C through stack memory. For heaps, we have reference counting, often handled automatically through the stack (e.g., C++ smart pointers). The thing Rust brought to mainstream is not automatic memory management - they're a dime a dozen with and without GC. It's an ownership model that is strict about whether you have read or write access within the type system. At the same time, this is also where most developer friction stems from, as it's quite unique, and you're often faced with a trade-off between explaining exactly what you want at compile-time at higher design cost, or bailing out more to runtime checks with e.g. RefCell while getting fewer guarantees about code correctness from the compiler. reply pjmlp 8 hours agorootparentNot at all, considering the decade of high level systems programming languages that predated the very thought of C coming into life. All with stack allocation. reply arghwhat 3 hours agorootparentKeyword is mainstream, so it’s not when the idea was invented - I think Forth popularized it? I can’t really comment on what counted as mainstream before C though. Not old enough for that. reply pjmlp 3 hours agorootparentMainstream is whatever people could use between 1958 and 1969, as high level programming language, in whatever computers, universities and companies could afford. Goggle, Bing, DuckDuckGo, ChatGPT,... will gladly provide a list. reply arghwhat 2 hours agorootparentWhat people could use is not at all what mainstream is. You can use D, OCaml, F# and brainfuck, but they are not mainstream. To define what was mainstream we'd need to talk to people coding at the time and ask them about popularity, adoption, tooling availability, etc. and what languages people were likely to use rather than what was available. And no, I have no need for researching that as I have no use of the information - the point is to say that automatic memory management in mainstream languages predate rust by decades and is present in most languages, not \"this specific language should get credit\". reply shakow 7 hours agorootparentprev> C through stack memory. Stack memory is decades older than C. reply Ygg2 6 hours agorootparentprev> non-GC *automatic memory* management to the mainstream would be either Forth or C Emphasis mine. It's not C. You do manual memory management there. You have to call malloc/free. Didn't use Forth, so I can't say anything about it. reply xolox 6 hours agorootparentmalloc/free are for heap based allocations. The grand parent explicitly mentioned he was referring to stack based allocations, which are kind of automatic (implicit). reply Ygg2 4 hours agorootparentSure, however you still have to do them manually. That's what manual in manual memory management stands for. Stack based allocation are essentially registers, right? reply eska 59 minutes agorootparent{ int8_t x = 1; } allocates a byte on the stack, binds it to a variable named x, sets it to 1, then deallocates it from the stack. There is no explicit allocation or deallocation. As an optimization it can be put into a register instead of the stack, again without explicit allocation and deallocation (this is done by the compiler playing musical chairs with registers). I would not consider this manual. Manual would instead be something like in embedded programming int8_t* y = (int8_t*)0xB4DC0FF3; *y = 1; because one needs to keep track of used memory locations (do allocation management) reply arghwhat 3 hours agorootparentprevThe stack is fully automatic arbitrary memory and has nothing to do with registers. You can allocate as much as you want (including e.g. bytearrays), until you run into the allocated stack limit. That limit can be arbitrary, and some languages even dynamically scale the stack. That you also have access to manual memory on the heap doesn’t matter. You can also do manual memory management in Rust if you want, as one has to do at times. reply bad_user 7 hours agoparentprev> first language to bring non-GC automatic memory management to the mainstream ... Other languages in this space include Swift Ugh, “Arc”, aka (automatic) reference counting, is an implementation of GC as well. It may have certain characteristics, like having worse throughput, corner cases, and better predictability/latency characteristics, but it's GC nonetheless. That's not manual memory management. Swift is not a non-GC language. And that's the big issue that people are missing — Rust tackles some hard problems regarding memory management, and a friendlier alternative exists: garbage collection. reply rcruzeiro 7 hours agorootparentBoth ARC and garbage collection are memory management techniques. ARC does not equal garbage collection though. Garbage collection runs at intervals and is triggered by certain signals (memory pressure, etc), pauses all threads and scans for objects that can be deallocated. It is a very different concept than ARC. reply twoodfin 6 hours agorootparenthttps://courses.cs.washington.edu/courses/cse590p/05au/p50-b... This paper makes a strong argument that “pure” tracing garbage collection and “rote” reference counting are effectively duals at the opposite ends of a spectrum of implementation choices. For example, GC’s often optimize differently for young vs. old objects. How do they distinguish these? By “counting” (one bit) their references across one or more traces in a series of sweeps. reply 01HNNWZ0MV43FF 3 hours agorootparentAnd a hot wheels car is a car, but I would be perplexed to see one offered to me at a car dealership reply Tuna-Fish 6 hours agorootparentprevARC is a method of implementing garbage collection, and is discussed as such in academic literature. What you are equating with \"garbage collection\" is Mark-Sweep, which is an another way to implement GC, with a very different set of tradeoffs. (Broadly, better throughput at the expense of higher latency.) reply 112233 6 hours agorootparentprevDeleting large hierarchy of objects when the last reference gets decremented also is triggered by a certain signal (reference decrement) and pauses all threads while it collects garbage. There are even tunable GC that become ARC if you set particular parameter to \"N=1\" reply zozbot234 5 hours agorootparentI'm not sure that collecting a large hierarchy of objects requires pausing all threads. What can definitely require pausing threads (other than in specialized concurrent collectors) is the tracing step, which relies on some invariants that in simple GC implementations (not the more specialized concurrent ones mentioned earlier) are only ensured at very specific points in the program (known as GC \"safepoints\"). reply 112233 3 hours agorootparentMy bad, thanks for correcting! Of course single thread freeing a lot of heap allocations will not pause other threads by itsel. What I had to write was: calling destructor of an object that in turn calls destructors of other objects (because a large tree of reference counted objects loses last reference to it's root) stops that thread, until all deallocation is done. reply pessimizer 5 hours agorootparentprev> There are even tunable GC that become ARC if you set particular parameter to \"N=1\" You can call a pointer to a value a \"one-element static array.\" reply pessimizer 5 hours agorootparentprevIt's not \"automatic\" reference counting, it's \"atomic\" reference counting. And it's not automatic, it's entirely manual and implemented with traits as a fat pointer. Reference counting types in Rust are just defaults that give certain guarantees. This feels like people arguing that atheism is a kind of religion. Borrow checking and a library of safe default primitives make it so you don't really have to think about memory management; except to the extent that you generally stick to those primitives, and that you have to install the borrow checker into your own head to write Rust comfortably (although the compiler will help.) Rust doesn't have any garbage collection, but it can just assume how you would want to deal with memory by forcing you to be very specific about when values should be created or destroyed. reply Ontonator 5 hours agorootparentIn the context of Swift, ARC is automatic reference counting: https://docs.swift.org/swift-book/documentation/the-swift-pr... reply est31 8 hours agoparentprev> Rust is the first language to bring non-GC automatic memory management to the mainstream. It won't be the last and it might well be the worst. Other languages in this space include Swift Rust's memory management is not automatic, you have to explicitly manage memory. It's just made extremely easy for you by the language thanks to stuff like RAII, and there is checks that prevent memory safety violations like double free. But those checks won't prevent leaks, although the many lints do make it harder to forget about a value. Also, Swift's refcounting can be seen as a form of gc. reply lolinder 7 hours agorootparent> Rust's memory management is not automatic, you have to explicitly manage memory. It's just made extremely easy for you by the language thanks to stuff like RAII, and there is checks that prevent memory safety violations like double free. But those checks won't prevent leaks, although the many lints do make it harder to forget about a value. By this logic no language on earth has automatic memory management. I've spent time troubleshooting a memory leak in JavaScript in the past month, caused by someone keeping a pointer around longer than necessary. Rust's memory management is automatic in that you can write entire Rust programs without once calling `free` manually. I'm not sure what definition of automatic you're working off of, but if it excludes JavaScript it doesn't seem especially useful. reply Measter 6 hours agorootparentI've found it's kinda helpful to think of Rust/modern C++ style management as semi-automatic memory management. You control when things are allocated and freed, but you don't bother with the minutia of it unless you're writing a low-level container type. This is contrast to something like C/Zig, where things are fully manual, or something like Python or Javascript where things are fully handled for you. reply est31 3 hours agorootparentprev> Rust's memory management is automatic in that you can write entire Rust programs without once calling `free` manually. Personally I'd put the bar around not requiring people to distinguish different pointer types (owned vs shared). Languages like Java, JS, Python, Swift, Go, etc all have this \"everything is a smart pointer\" paradigm, (or at least the strong and widely used default). I'd say Rust is manually managed because you need to think about which pointer type to use and using gc'd pointer types like Arc has a syntax overhead (like say when a pointer is cloned). reply consteval 2 hours agorootparentMost GC langs have these features too they're just not in your face. Technically C# has true value types like C++. Rust makes the distinction between stack and heap references, like C++. Other, more high-level languages don't - there's only one kind of reference, you can't take a reference to a stack object. Maybe you implement that by making all objects heap allocating (Java) or you just say they have to be copied every time (C# struct). That's really where the difference is. There's a lot of juicy, juicy performance there. The problem is taking references to stack variables is problematic. Tracking heap objects with a GC or a ref counter is really trivial in comparison IMO, at least when you try to combine the systems. reply neonsunset 46 minutes agorootparentThe assessment on C# does not match language spec at all. Not only instance methods on C# structs are implicitly byref, you can easily pass structs by reference via ref, out and in keywords. On top of that, ref structs can hold `byref` pointers aka 'ref' keyword which can point to arbitrary memory, or have references to other structs/variables/anything. There is also regular C syntax with &T and T* for unmanaged references/pointers. On top of that, .NET's compiler has gotten very good at struct optimizations and pretty much ensures they stay in registers all the time unless address-taken, including SIMD registers for Vector and Vector128/256/512 even their \"deconstructed\" form when specified width is not supported so they get handled as e.g. 256x2. There was a big jump in codegen quality in .NET 8 which can now sometimes trade blows with GCC and Clang around struct optimizations. All these features are first-class and are heavily used by all kinds of performance-sensitive code. Also, structs can implement interfaces and can be generic arguments that satisfy interface constraints, which works exactly like generics with trait bounds in Rust - you get a generic instantiation aka monomorphized function body, making the abstraction zero-cost. reply iknowstuff 3 hours agorootparentprevSwift has „weak” references for when you don’t want to bump the reference count. Does that make it manual? reply bryancoxwell 6 hours agorootparentprevPointers in JavaScript? I’m far from a JS expert, but didn’t think the language had pointers. Could you explain what you mean here? reply lolinder 6 hours agorootparentI'm not aware of any mainstream language that doesn't have pointers, the question is whether they expose pointers as a first-class language construct (i.e. you can choose to not dereference them or to do pointer arithmetic) or use them as an implementation detail. In JavaScript's case it's an implementation detail, but one that is extremely relevant when maintaining something in production. reply bobajeff 6 hours agorootparentCorrection about JavaScript: All non-primitive data types are pass by reference. So not just implementation detail as no valid js interpreter will pass those by value. reply lolinder 6 hours agorootparentIt's not up to the implementation to decide whether to pass by reference or not, but it is up to the implementation whether to use pointers under the hood to model passing by reference. Since there's no pointer arithmetic, other models could theoretically be used to accomplish the same semantics [0], it just happens to be that pointers are by far the most logical choice. [0] As a silly example: a JavaScript implementation could technically store object references as a URL of an API that allows interacting with the object, as long as this is transparent to the user and the program behaves the same as a pointer implementation (minus non-functional characteristics like performance). reply bryancoxwell 6 hours agorootparentprevMakes sense, thanks! reply mind-blight 6 hours agorootparentprevMost variables on JavaScript are (essentially) pointers. A common mistake people make in the language is keeping references to objects in a global map, which prevents them from being garbage collected (often a bad caching implementation). You can use things like WeakMap or WeakRef as one solution, but there are usually better options reply pessimizer 5 hours agorootparentprev> you can write entire Rust programs without once calling `free` manually. If you mean \"drop,\" it's just syntactic sugar for calling a trait that manually deallocates the memory and that you're free to reimplement. It feels like people are equating \"manual memory management\" with \"onerous memory management.\" People are usually going to want to do the boring thing with memory, and everything in the standard library by default does the boring thing with memory. If you write boring structs and enums, you'll derive boring memory management. But it's not part of the language, it's part of the library. reply lolinder 5 hours agorootparent> If you mean \"drop,\" it's just syntactic sugar for calling a trait that manually deallocates the memory and that you're free to reimplement. I meant `free` because I'm contrasting with C. > It feels like people are equating \"manual memory management\" with \"onerous memory management.\" Manual memory management is onerous, but I'm very specifically talking about manual. If I can write a whole program without thinking about memory, the language does not require manual memory management. It may support it, but it doesn't require it the way that C or Zig do. You do not \"have to explicitly manage memory\" as OP claimed. reply tialaramex 4 hours agorootparentprevYou can't call Drop::drop for type T at all. Try it if you don't believe me. It would be unacceptable to allow this because Drop::drop says it only takes a mutable reference &mut T (and indeed it does) but now the thing is destroyed, so, that wasn't just a mutable reference at all! You can call core::mem::drop but well, look at it, here's the code: pub fn drop(_x: T) {} Like, duh, we give it a T and then it doesn't give anything, the T is gone. That's not magic library code by the way, if we make our own: pub fn vanish(_x: T) {} Now we can call our vanish function and the same happens. So yeah, automatic memory management. reply consteval 2 hours agorootparentTo be fair I don't think this is enough to say automatic memory management, otherwise C++ would be automatic memory management too (and maybe it is, just poorly implemented?) reply tialaramex 1 hour agorootparentYes, C++ has automatic memory management. As with the rest of the language, the automatic memory mangement requires that your program has no mistakes - which requires inhuman amounts of care during implementation and testing. So, that's obviously a spectacularly bad idea, but it's still automatic memory management. reply kaba0 7 hours agorootparentprevYeah, the correct statement would be ‘Rust is the first mainstream language without GC, that guarantees memory safety’ (with obviously the caveat of unsafe blocks, but than you can also sun.misc.unsafe yourself into segfault in java). reply lucideer 6 hours agoparentprev> The age of Smalltalk is over. It's now the age of ML [...] The languages that dominated the 2000s (Ruby, Python, Javscript, PHP) were all more or less derived from Smalltalk [...] The new languages (Rust, Scala, Swift, Kotlin, etc.) are ML family languages. What drew people to a lot of your examples (Javascript, PHP especially) was the runtimes rather than the language features. Your example sets aren't just demarcated by Smalltalk-ishness/ML-ness but more by runtime type (Scala & Kotlin are odd examples given the VM but for the most part your latter examples have build-time compilation while the former have plaintext interpreters). We're definitely in a tools-heavy era of programming where, unless you're writing bash scripts, even very basic applications in interpreted languages are layered with a slew of transpilation/compilation/etc., but generally speaking I still don't see the majority of people moving wholesale away from plaintext runtime interpreters. Where are the ML-ish competitors in that space? reply noelwelsh 5 hours agorootparentGood point. The nitpicky take: a lot of these languages come with a repl / console. E.g. the most recent version of Scala builds Scala CLI[1] into the language. You can run `scala repl` and just type code into it, or run `scala SomeFile.scala` and it will compile and run `SomeFile.scala`. There is special syntax for writing dependencies so that a single file can pull in the libraries it needs. The 5head thought leader take: the traditional model for typed languages has two phases: compile time and run time. Types exist at compile time. This is inadequate for many applications, particularly interactive ones. E.g. a data scientist doesn't know the shape (type) of the data until it is loaded. It should be possible to infer the type from the data once it is loaded and make that type available to the rest of the program. We know how to do this (it's called staging) but it's just not available in the vast majority of languages. Staging, and metaprogramming in general, is perhaps the next great innovation in programming languages (which will take us from ML to Lisp). In general, the challenge for these new languages is to reach \"down\" into the simpler scriptier applications, instead of the \"serious\" programming they are usually built for. [1]: https://scala-cli.virtuslab.org/ reply tgv 8 hours agoparentprevRust is not really an ML language, is it? &mut is a very noticeable difference. Calling Rust, Scala, Swift and Kotlin ML seems to be taking it too far. Scala and Kotlin even have all the traditional OOP features. You might just as well put C++ in the ML list. reply tialaramex 7 hours agorootparentIt's not the Standard ML of New Jersey of course, like I was taught last century, but it looks like an ML to me. Rust has a sound type system, whereas a language like C++ inherits C's YOLO approach to typing. In Rust Vec> is just a counter. Really, that's not theory that'll just happen by default because of how type arithmetic works. In C++ you can't even write down an equivalent type, let alone say how it would be represented, the type system blows up long before we get there. reply wsabihi 3 hours agorootparentI've looked for this optimisation, and while it makes sense to me (Infallible is unhabitable ==> s: Option can only exist if s = None ==> all values in vector must be of the same value None that is known ahead of time ==> store a counter of how many Nones are in the vector instead of each None as an entry into a traditional vec), I cannot find any trace of such optimisation, whether by reading into the bytes backing the vector (with rustc -O / -C opt-level=3 to ensure this opt is triggered), or by calling `mem::size_of::>>()`. reply koverstreet 5 hours agorootparentprevCould you elaborate? I would think Vec> would have to be a bit vector. reply zozbot234 5 hours agorootparentInfallible is a clunky name for the Never type in Rust, i.e. a type that has no values and cannot be instantiated. Thus, Option only has a single value, viz. None. Then Vec> is isomorphic to Vec which reduces to a length field - there's no other data associated with it. reply pornel 7 hours agorootparentprevRust is its own thing, but use of algebraic data types + pattern matching and type inference makes it feel closer to OCaml than C++. The original Rust compiler has been written in OCaml, so that's definitely an influence. reply lolinder 7 hours agorootparentprevIf &mut makes Rust not in the ML family then none of the languages they list are in the Smalltalk family either—there's no concept of an image, everything is in files! It's pretty clear that we're talking about very broad families, which is okay—Rust has more in common with ML than it does with Smalltalk or ALGOL (though the ALGOL heritage is definitely present). reply foldr 7 hours agorootparentprevML has mutable references: https://saityi.github.io/sml-tour/tour/02-09-mutable-refs.ht... (OCaml has something similar too.) reply the_duke 8 hours agoparentprevAd 3) Scala is quite a bit older than the others, I'd put it in a previous generation. I always saw Kotlin as a more convenient Java, without Scalas heavy tilt towards FP. Java also added the equivalent of sum types with sealed interfaces and exhaustive pattern matching, does that make Java an ML language? Many older languages by now have incorporated valuable parts of FP/ML (including Javascript, Java, C++, ...) Borrowing some concepts from ML doesn't put these languages in the ML family. reply valenterry 8 hours agorootparentOCaml is older than Scala though. > Java also added the equivalent of sum types with sealed interfaces and exhaustive pattern matching, does that make Java an ML language? I don't think so. Java heavily relies on mutation and you can see this throughout the whole ecosystem and even the JVM whereas OCaml doesn't. Kotlin also relies on mutation (it relies on Java's stdlib after all) whereas Scala has its own stdlib with both mutable and immutable classes but defaulting to immutability almost everywhere. So if anything, Scala can be called an ML language imho. reply SSLy 8 hours agorootparentprev> does that make Java an ML language? not really, the type-system-sublanguage is still modelled like classy OOP, not more like MLy modules. reply nextaccountic 8 hours agorootparentBut Kotlin is like this too. reply SSLy 8 hours agorootparentIndeed, and Scala (at least the version I've tried 10 years ago) tries to do both, somewhat poorly. shrug reply valenterry 8 hours agorootparentPersonally I found Scala's module/import system to be really really good. There are some annoying things with it, but they mostly come from JVM/Java compatibility. reply SSLy 7 hours agorootparentYeah, it's the compat that I vaguely recall being kludgy. reply hyperbrainer 4 hours agoparentprevAbout the time travel to past aspect, I wonder if we will have an age of lisp now? I know Lisp is very popular in some niches(zB Emacs), but I really want to see innovations in syntax from the current standard of too many brackets. (M-expressions?) reply hollerith 3 hours agoparentprevYou seem to assert that OCaml doesn't use a run-time garbage collector: >Rust is the first language to bring non-GC automatic memory management to the mainstream. . . . Other languages in this space include . . . OCaml[1] But your own link[1] says, >The OCaml compiler does not statically track lifetimes. Instead, it relies on a garbage collector to figure out a suitable lifespan for each value at runtime. Values are collected only after they become unreferenced, so OCaml programs are memory-safe. To a first approximation, this model requires allocating all values on the heap. Fortunately, OCaml’s generational GC can efficiently handle . . . Scala does run-time garbage collecting, too (or rather the JVM does, which Scala depends on at run-time) unless I'm very much mistaken. reply dgellow 8 hours agoparentprevSwift does have garbage collection via reference counting reply zerr 5 hours agorootparentYes, usually GC vs non-GC discussion is actually about deterministic vs non-deterministic memory management. Swift's ref-counting is deterministic. reply benreesman 8 hours agoparentprevI think if Linear/Affine typing was a default anyone wanted, Haskell hackers (who are usually pretty concerned with performance) would regard it as more than a research oddity. When people bitch about the borrow checker, what they usually mean is “std::move is a great wristwatch but god damn does it chafe as a chastity belt”. reply zozbot234 8 hours agorootparentThe whole point of Haskell as a programming language is to have lazy evaluation be the default. This comes with boxing data objects everywhere, which is the opposite of a focus on low-level performance. Haskell does support using strict, unboxed data but it's clunky and not the default. (Also, recent versions of Rust have now added support for \"plug-in\" laziness via the type constructors LazyCell and LazyLock.) reply benreesman 8 hours agorootparentI’m aware of how boxing works in GHC, I learned it from Simon Marlowe. I don’t mean to be obtuse but I don’t see what that has to do with linear typing as a fucking weird mandatory default? reply the_duke 7 hours agorootparentWhy should every language occupy the same design space? Rust was shaped by Mozilla wanting a language to replace parts of Firefox with. A language that is low-level enough to give very high performance, enforces correctness through the type system, and yet has many abstractions so it feels modern and convenient to use. Rust doesn't have any automatic allocations. You can wrap every type in `Arc>` and treat it like a very verbose Python, but that's the programmers choice. The design decisions have been validated by the success of Rust in certain domains. There is a reason why more than one programming language exists... reply benreesman 7 hours agorootparentI think Rust is cool! If it wasn’t actively seeking world domination I’d be like, cool let’s use that sometimes. Rust is so hell bent on a Rust monoculture ranging from stuff like TRACTOR to actively opposing interop that a few of us who know our shit have to be like “easy now” once in a while. I’m trying to decide between tiktoken and sentencepiece for a new vocabulary at the moment, and it would be easier in some ways to go with tiktoken. But I want it to run faster than a fart at inference time, which means I’m linking libtorch, which means I’m writing C++. And fuck, link to Rust from C++? Let’s take another look at the Google stuff. reply tialaramex 6 hours agorootparent> If it wasn’t actively seeking world domination I’d be like, cool let’s use that sometimes. Hylo specifically says it intends \"world domination\" (next year in fact, having apparently completed all the delayed 2023 goals and also all its 2024 goals this year, I guess maybe they're going to do it all in December?) But I don't really see this from Rust. I'm sure Hylo's \"world domination\" is a joke, but, so is the \"Rust Evangelism Strike Force\". Rust people I've interacted with strike me as very much more accepting of the \"better tool\" theory than of some weird cult or panacea. When somebody in a Rust forum says (e.g. about JPEG XL) \"Ooh we should use Rust\" and I say \"No, WUFFS. This problem is what WUFFS is for\" the responses tend to be a mix of \"Yeah, I guess\" and \"I didn't know that existed. Thanks for the link\" rather than cultist denial. reply benreesman 6 hours agorootparentHaha we’ve tangled before and in my experience when the Rust evangelism strike force is on the case discretion is the better part of valor. I admire both the technical sophistication and passion you folks bring to the table, the one true language thing just isn’t my bag. I pine for the Halcyon days when HN was run by the Rust people rather than the LLM idiots. Keep doing what you’re doing, one hacker to another. reply zozbot234 7 hours agorootparentprev> to actively opposing interop Rust just uses the C ABI for interop (including interop with Rust code that might not be part of the same build, such as dynamically-linked program objects). So you just have to come up with a plain C API for the interface and write wrappers on both sides of the divide that reference the C API. There are crates that will help with this, even achieving something like a \"stable ABI\" for Rust interop. (And we'll probably see some work into interop with Swift itself (which has a stable ABI of its own) once there's enough interest in that as a memory safe language.) reply benreesman 7 hours agorootparentIt’s doable! But bindgen/cbindgen/cxx/etc exist for a reason: it hurts like a root canal. In my particular case, tiktoken is substantially like 600 lines of Rust. If I have a deadline do I fuck with the linker or just write it again? I’m marshaling std::string here, fuck let’s just write it. What I’m not going to re-write because I’m not a magnificent maniac like geohotz? I’m not going to rewrite libtorch. Which is written in C++ like all the software you can’t really live without. reply zozbot234 8 hours agorootparentprevI'm not sure what's supposed to be especially weird about linear typing (or rather, uniqueness typing which is what Rust ultimately relies on). If you want to see the use of such types in a language that's clearly even less \"convenient\" and more principled than Rust, you can look at Austral https://austral-lang.org/ reply benreesman 7 hours agorootparentI think I’m going to be a hard pass on a language more militant about BDSM type system level memory management than Rust. reply farmeroy 4 minutes agorootparentIs their code linter called whippy? bananapub 8 hours agorootparentprevperhaps a dumb question, but why does laziness imply boxing? or does 'boxing' in haskell mean something other than 'embed a simple bit of data in a fancy thing on the heap'? reply throwaway17_17 5 hours agorootparentI seem to be missing the implication as well. I am under the impression that Haskell relies on boxed values primarily due to its parametric polymorphism. There is a Simon Peyton Jones talk somewhere discussing the acrobatic GHC requires for the type theory to deal with unboxed types and their implicit requirement for an alternative Kind at the type level. The laziness as a default just makes boxing closure values a sensible default, when the type system requires the boxing of everything in general. reply benreesman 4 hours agorootparentOn everything from the JVM to GHC to v8 there is a critical distinction between the semantics of a boxed type and the practical outcome on the gear. Every managed language runtime done by pros (and those all are, I should have said the CLR too) will quietly unbox in all the easy cases and some of the hard ones. Parametric polymorphism is kind of orthogonal to that. It’s related I guess. It can involve some kind of runtime dispatch, but usually that gets JITed or inlined or whatever unless you really insult the compiler. And even full frontal invokedynamic it’s still like, is it in the BTB and the I-cache? Ok well we’re still doing business. reply benreesman 8 hours agorootparentprevA dramatic over-simplification is that a lazy value referenced by some continuation/thunk is hard to stack allocate in-situ. Now GHC does stack allocate, but it’s hard to count on without really aggressive hinting. reply the_duke 7 hours agorootparentFunnily enough Rust supports exactly that pretty well with async. An `async {}` block is not evaluated, but converted into a generator/state machine that lives on the stack, and that has to be advanced by calling a poll method. You can move it to the heap , but that does not happen automatically. Sharing of values is obviously much more awkward due to mutability and no automatic cloning though. reply benreesman 7 hours agorootparentI know how it works though I remain unconvinced that rustc is dealing with the same scope of problem as GHC in the general case. But to be clear, anyone with the username the_duke is probably really cool, and you clearly know your stuff as well as having style, so count me as a fan. reply bananapub 7 hours agorootparentprevah, right, laziness can cause the control flow to become extremely complicated - makes sense, thanks! reply benreesman 7 hours agorootparentAlso true! And in very real sense literally what I meant. But not so much in the conditional branch sense of the phrase “control flow”. More like, I’ve got a bunch of references and one of them is a reference to a function I might evaluate, damn, I need that reference and the transitive closure of everything it knows about, all of which are probably on the heap. reply zozbot234 7 hours agorootparentThe proper name for this is a \"space leak\". Also known as: \"you wanted a banana, but what you got was a gorilla holding the banana and the entire jungle\". This is of course pretty much the opposite of low-level \"performance\" - and it's also the kind of problem that tracing garbage collection was actually designed to address when first developed. reply benreesman 6 hours agorootparentFake news and FUD and other balderdash. A space leak, much like any memory leak is when you or the compiler or the runtime or whoever misplaces such reference. GHC having a closure in scope in no way immediately means there is a space leak. Plenty of Haskell code that compiles to thunks will run all day in an amortized fixed-size heap. Much like Erlang, which is what Joe Armstrong had designed before he said the thing about jungles you’ve quoted. And it is in no way difficult or even really rare to drop an Arc in a table and leak all over the place. Rust has all the same computer science problems as anything else. Full stop. reply mananaysiempre 8 hours agorootparentprevGHC Haskell is a fairly large language with a considerable legacy already, so integrating linear or affine types into it may well be a very different question from making a language centered around them. That language exists in the form of Clean[1,2]. Admittedly it’s not really well-known. [1] https://clean.cs.ru.nl/ [2] https://clean-lang.org/ reply benreesman 8 hours agorootparentThank you for making me aware of Clean, on quick glance it looks cool. I like a lot of things about Rust: it’s got compiler checked exhaustive pattern match and a good initialization syntax and Either baked in and fucking correct package management and a ton of other things. I’ll look at Clean to see if linear-only memory management can be done gracefully. Rust is a lot of cool things but not the language that demonstrated that. reply MarcusE1W 5 hours agorootparentThere is also Austral, which has linear types as a main capability: https://austral-lang.org/ reply IsTom 7 hours agoparentprev> (Ruby, Python, Javscript, PHP) were all more or less derived from Smalltalk I'd argue that Erlang (with gen_servers being \"objects\") has more in common with Smalltalk than these. reply alex_smart 7 hours agoparentprev> The languages that dominated the 2000s (Ruby, Python, Javscript, PHP) were all more or less derived from Smalltalk One of these is not like the others. Javascript derives from Lisp (first-class functions, lambdas, closures), not Smalltalk. reply robertkrahn01 7 hours agorootparentBrendan Eich used both Scheme and Self as inspirations. Self is a dialect of Smalltalk. https://en.wikipedia.org/wiki/Brendan_Eich reply pessimizer 5 hours agorootparentDid you link his biography? The claim is that he used Self as an inspiration, not that there was once a man named Brendan Eich. reply astrobe_ 7 hours agorootparentprevMore than features, JS derives from Lisp because its author was a Scheme implementor. Otherwise function pointers are trivially done even in assembly language, and Smalltalk does have closures. Or maybe you think of the fact that JS uses prototype-based OOP, which makes it closer to what one would do with Scheme (something inspired from CLOS I guess) than Smalltalk ? reply panzi 7 hours agorootparentprevPython has those too, although with less convenient syntax (multiline functions (closures) can only be at statement locations). reply timeon 8 hours agoparentprev> These alternatives take the approach that tracking ownership is not the default, which is fine for the majority of programs and far more ergonomic. If you want non-default safety you do not need to leave C++. That is why unlike all these new languages, Rust makes difference. reply zozbot234 7 hours agorootparentSwift 6 is expected to be memory safe, including for concurrent programs. That's a lot more than you can say about C/C++. (This is achieved by tracking ownership at runtime when required. Rust allows for this via library types such as Rc and RefCell, which is more principled but obviously adds some boilerplate compared to Swift.) reply nicce 9 hours agoprev> Rust invented the concept of ownership as a solution memory management issues without resorting to something slower like Garbage Collection or Reference Counting. They did it well, but not invented? There very many kinds of influeces: https://www.reddit.com/r/rust/comments/le7m54/is_it_fair_to_... Especially Cyclone, I think: https://en.m.wikipedia.org/wiki/Cyclone_(programming_languag... reply mananaysiempre 8 hours agoparentThe best review of the relevant research that I know is Pottier’s presentation[1]. It’s from 2007, but then again as far as fundamental concepts it doesn’t seem to me that Rust is state-of-the-art even as of then. (To be fair, that’s not due to ignorance, Rust’s type system is deliberately conservative.) [1] https://pauillac.inria.fr/~fpottier/slides/fpottier-2007-05-... reply afavour 7 hours agoprevAs someone that’s recently been working on integrating Rust into an iOS Swift app I do agree with a lot of this. I love Rust but the more I’ve used Swift the more I find myself wishing I was just using Swift all the time. That said, the difference between the two has a lot less to do with the language itself than the world surrounding it. You can use Swift cross platform but it’s very obvious that Apple platforms are the primary target. Rust has a rich and varied package system, about the only assumption most packages make is that you’re using the Rust standard library. By comparison lot of Swift packages (which is a much smaller ecosystem anyway that’s slowly transitioning away from Cocapods, Carthage etc) will lean on OS APIs that won’t work if you compile for Linux or WASM[1]. I want Swift to be a more convenient Rust but it just isn’t there. e.g look at IBM abandoning Swift on the server not that long ago. [1] for example, this blog post: https://swiftrocks.com/weak-dictionary-values-in-swift Discusses making a dictionary with weak values in Swift. It has a homegrown Swift version then discusses using NSMapTable… which isn’t available on Linux. But you wouldn’t know that reading the article because the assumption is that you’re running on an Apple platform. reply 369548684892826 7 hours agoparentSwift is in its .NET Framework stage. I’m looking forward to Swift Core! reply lolinder 6 hours agorootparentThe difference is that Microsoft very intentionally decided it was going to make .NET cross-platform as a strategic play. Apple has recently shown a willingness to get out of the way of cross-platform Swift, but I haven't yet seen evidence that they're throwing any significant weight behind it. They have an even worse track record than Microsoft did of investing heavily in locking developers into their ecosystem, so I'll have to see quite a bit of evidence to believe they're actually serious about cross-platform Swift. reply afavour 7 hours agorootparentprevI like that comparison! But it might require Apple’s perspective as a company to shift in the same way Microsoft’s did. We’ll see, I guess… reply pzo 6 hours agorootparentprevIt might be too late. IMHO Microsoft also did transition too late and these days .NET is less relevant today than it used to be - even many microsoft apps are build using React Native or Electron. reply nicce 6 hours agorootparent> even many microsoft apps are build using React Native or Electron. I doubt that .NET has much to do with it. There are just many more JavaScript developers who know how to make UIs. reply consteval 1 hour agorootparentThat's because the web is cross platform, truly. It's not a separate issue - the prevalence of the web is exactly due to platforms like .NET being limited. If .NET (and others) were cross platform much earlier, I think many applications would be true apps instead of web apps right now. reply lukeh 7 hours agoparentprevWell, that article also presents a pure Swift (non-Foundation) solution, WeakRef. reply afavour 7 hours agorootparentYes, I mentioned that. There’s probably a better example but this is off the top of my head as something I experienced myself. My point is that the blog post suggests the Swift native version then discusses NSMapTable without ever calling out the fact that you can’t use the latter cross-platform. I find that endemic in the Swift community, there’s a base assumption you’re coding on an Apple platform (and often specifically on iOS!), it adds an additional barrier to getting things done. reply K0nserv 8 hours agoprevI love both Rust and Swift, they have their respective strengths. I would say Swift has a less noisy surface syntax, but instead uses more dedicated keywords and compiler magic. This is nicer, but means some areas are \"compiler only territory\". In many cases Swift would be a better choice than Rust, when the convenience and developer experience is worth trading for some performance. However, Swift's biggest problem is that any usage outside of the Apple ecosystem is a second(or third) class citizen. Until this is solved, Swift will remain mostly an Apple only language, regardless of how nice it is. reply galangalalgol 7 hours agoparentIn my toy usage of swift I found it to run dramatically slower than rust. To even get something close to go or java speeds I had to compile with unchecked losing a lot of safety. Other than developing for an apple product, I don't know why I would ever pick swift and I wouldn't ever find myself deciding between rust and swift. It would be swift vs go. When considering rust it would be vs c++ or zig. reply attractivechaos 6 hours agorootparentIn my limited experiences in both languages, it is easier to write inefficient programs in swift. With rust, follow your instinct. As long as it compiles, the performance is usually close to your expectation. With swift, the result may surprise you more often. reply K0nserv 7 hours agorootparentprevIt depends on the axis you are considering. Swift might be slower than Rust, but it has an equally powerful type system. Swift and Go are much less similar than Swift and Rust in this regard. reply galangalalgol 7 hours agorootparentI compare tools based on what they do not how I use them. I use mig and hot glue guns similarly, but I'd compare mig to stick or tig and a glue gun to tubes or gluesticks. reply zer0zzz 8 hours agoparentprev> However, Swift's biggest problem is that any usage outside of the Apple ecosystem is a second(or third) class citizen. Until this is solved, Swift will remain mostly an Apple only language, regardless of how nice it is. I think a time goes on this is more and more only a perception and not a reality. However perception is really important because it’ll mean even if it’s a great language with a great set of tools and libraries for all platforms it will not have a community of developers outside of the Apple ecosystem. reply knighthack 7 hours agorootparentThe issue is not \"as time goes on\". The issue is now - the use of Swift outside of the Apple ecosystem is remarkably stifled, given the lack of Apple support. A language truly acquires mainstream mindshare and community, only if it can extend its use beyond Apple's OSes. reply zer0zzz 3 hours agorootparent> given the lack of Apple support. It’s an open source project that’s more and more detached from Apple itself every release, with lots of contributors making it better and better on Android and windows all the time. It is possible to get a vscode ide environment working for cross platform development and debugging today, which was not that easy or possible even a few years ago. There is at least one pretty sizable software project that has shipped a product on Android and windows using swift. I think swift 6 is going to be great for cross platform uses, but convincing folks to try it still won’t be easy. reply robjwells 8 hours agoprevOne way that Swift is certainly not more convenient than Rust is the tooling. I use a 2018 MacBook Air, using macOS 12, which is now unsupported by Xcode. Meanwhile SourceKit-LSP is treated as very much a second-class citizen. But Rust 1.81 and rust-analyzer build and run just fine. reply arghwhat 8 hours agoparentNot to praise Swift, but Swift and Xcode are unrelated projects. Saying that Swift is inconvenient because of Xcode issues is like saying C++/C# is inconvenient because of Visual Studio. You can install Swift on Linux if you want and code away, just like with Rust - but as it hasn't really caught on for anything other than building apps for the Apple ecosystem, it's not a particularly normal thing to do. reply x3ro 8 hours agorootparentThe defacto standard matters. The vast majority of Swift programmers will be using Xcode, and I definitely immediately think of the pains I've had with Xcode when I hear Swift. For example, I don't know of any other good IDE environment for Swift, though maybe there is one. You could also argue that e.g. Rust is not cargo, but almost every Rust programmer will be using cargo. Sure I could use something else, but why would I? Of course the analogy is not perfect, because the \"why would I?\" is clear for Xcode: it's bad and macOS only :D All I'm trying to say is: defaults matter. Most people will not be writing Swift in VS Code (on macOS). reply nelup20 7 hours agorootparentYep, I've only started using Swift a couple of months ago, but Xcode just isn't pleasant to use imo (though I'm probably spoiled by Jetbrains' IDEs), and the Swift extension for VS Code is clunky. I'm still really sad Jetbrains decided to sunset AppCode :( So the quality of tooling/IDEs is definitely a factor, I just don't see myself using Swift outside of the Apple ecosystem when there are so many other alternatives. reply arghwhat 7 hours agorootparentprevYou don't use Xcode to write Swift, you use Xcode to write Apple apps which you happen to do in Swift. No matter the language, you need Xcode to write those apps. Equalling Xcode and Cargo makes no sense. A similar situation to Xcode and Swift would be like Visual Studio and C# on Windows. Many developers use these tools, but they are not the language ecosystem, and the Cargo equivalents are entirely separate (Nuget, Cocoapods). reply yunohn 8 hours agorootparentprevI’m pretty sure you need Xcode to compile Swift on macOS. reply robjwells 8 hours agorootparentYou can install a Swift toolchain on macOS without Xcode, but Xcode is the “blessed” route and listed first on the swift.org getting started instructions. https://www.swift.org/install/macos However, it can be a bumpy ride. For example: “swift test” (via the CLI) doesn’t work if Xcode is not installed. https://github.com/swiftlang/swift-package-manager/issues/43... I would just emphasise that the OP was about _convenience_ and Swift-without-Xcode on macOS is not smooth sailing. reply latexr 7 hours agorootparentprevEveryone who has installed Homebrew has the official CLI Developer Tools (Homebrew installs them for you), and everyone who has those has a way to compile Swift. Even if you don’t have Homebrew, the first time you try to run `swift` in a Terminal you’ll get a GUI prompt which lets you install the Developer Tools in two clicks. Or you can run `xcode-select --install` (comes preinstalled, no Xcode needed). reply acar_rag 8 hours agorootparentprevAbsolutely not, you just need to use swiftc: https://theswiftdev.com/the-swift-compiler-for-beginners/ reply dlachausse 7 hours agoparentprevIt looks like MacOS Sonoma (and the latest Xcode) should work on your Mac. https://support.apple.com/en-us/105113 reply mrtksn 8 hours agoparentprevJust get something with Apple Silicon, even the 4 years old M1 Air with 16GB of ram would be huge upgrade. The tooling is fine, it's just that you are using the really old tools. reply homebrewer 8 hours agorootparentIs upgrading every 5-6 years to be able to write code considered normal in the Apple world? I'd been comfortably writing code in several languages using latest toolchains on a decade-old Intel machine just a few months ago, and was forced to upgrade because one of the components died. Otherwise I'd be using it for at least five more years. reply jdmoreira 8 hours agorootparent> Is upgrading every 5-6 years to be able to write code considered normal in the Apple world? Yes, pretty much reply zer0zzz 8 hours agorootparentprevI thought this was pretty normal for anyone writing code in larger code bases in these slow to compile languages in the first place… reply SSLy 8 hours agorootparentprevfrankly, late intel macs just sucked with their power-to-capability ratios. progress since M1 haven't been that incredible. reply sgt 8 hours agorootparentprevI mean.. upgrading every 5-6 years is pretty normal outside the Apple world too, if you are a professional programmer. I don't expect my mom to upgrade her computer that much (she's happy with her 2011 (!) model iMac). But for those of us who use a computer every day, surely it makes sense to stay a bit cutting edge and it won't break the bank either since it is literally our income. reply timeon 8 hours agorootparentIs it sustainable? reply kaba0 7 hours agorootparentThe curve has flattened a lot - on mobile phones it is extremely noticeable, but I would say that apple’s M series is also the last significant jump in the laptop world (because laptops weren’t really ‘mobile’ before with such a bad battery life). So, yeah, I would say it can be reasonably sustainable. reply mrtksn 8 hours agorootparentprevI don't see why would anybody complain that the tools they bought 10 years ago don't magically do the things that the new tools are doing. It's not like the old tools stopped doing the things they do, right? Anyway, you sel the old machine and get the new one is pretty normal as the Apple devices tend to hold value. reply tcfhgj 6 hours agorootparentWe are talking about Software though. It's not really sustainable to throw buy new stuff all the time when there's not a technical reason for it reply mrtksn 6 hours agorootparentThat still doesn't mean that the tooling is bad reply gr__or 7 hours agorootparentprevlet the record show that we're talking about 6 years reply mrtksn 7 hours agorootparentWhich is about the same time it takes a high school student to get his masters degree in computer science, get into a FAANG and get promoted. 6 years is a lot. It runs about 14$ a month if you throw away you tool at the end. It's probably more like 10$ since you are likely to be able to sell that tool at reasonable price since its Apple. reply dannersy 8 hours agorootparentprevBuying a computer is not a reasonable response to a comment about bad tooling. reply mrtksn 8 hours agorootparentThe comment says that the old tool doesn't do this new thing. The new tools do the new things. How is it that buying the new tool to do the new thing is unreasonable and expecting the old tool to do the new thing is reasonable? IMHO if the new tools are good and the tool you have is not good it doesn't mean that the tooling is bad, it means that the tool you have is bad and the solution for this is to obtain a new tool. reply dgellow 8 hours agorootparentprevI can write rust on a decade old machine without issues reply pjmlp 8 hours agorootparentDepends on how much time you have to wait for clean builds, recompiling the same crates from scratch. reply tcfhgj 8 hours agorootparentOn my 15 years old machine I learned to do clean builds only when necessary reply pjmlp 8 hours agorootparentBasically working around the problem. reply tcfhgj 8 hours agorootparentWithout any effort, because great tooling reply pjmlp 8 hours agorootparentGreat tooling is able to depend on binary libraries without requiring to build the world. reply timeon 8 hours agorootparentprevConstantly making clean builds is made-up problem. reply pjmlp 8 hours agorootparentBetter yet is not doing any at all, binary libraries are a thing in some systems programming languages. reply bhaney 8 hours agorootparentprevThe modern tooling not being available for common hardware that's only a few years old is a problem with the tooling reply mrtksn 8 hours agorootparentIt can be a bad value depending on what do you do with your tools but I wouldn't say that this is bad tooling. The new tooling is amazing, its fast its snappy it runs the code you write for you mobile device directly on your tool. If that brings you value less that is less than 200$ a year, then it can be a bad deal but its not bad tooling. reply seanalltogether 8 hours agoprevI keep trying to get into rust but I always hit a brick wall when looking at examples and the code looks so complicated. Examples like this straight from the rust website just make my eyes glaze over struct Task { future: Mutex>>, task_sender: SyncSender>, } reply MSFT_Edging 6 hours agoparentSomething I like about Rust is that it gets very specific and explicit. On first glance you're like wtf is going on, but you can derive backwards what is happening without having to look for a discussion on language behavior under the hood. Automagic is nice sometimes but I'm the kind of person that needs to say the each word of an acronym to process it. Rust is like that in a way. You have a mutex on an option type, the option has a heap allocated future that contains data that can live for the lifetime of the program. This is clear to me because I don't need to fill in blanks. My memory is terrible, I've forgotten so many things I've learned in the past. I could pick them back up quite quickly but I don't have the little facts ready to go. If i wanted to use that future, I know I need to check the mutex lock, check if the option contains a Some(), etc. Sure this isn't for everyone, but I'm glad we have a tool like this gaining popularity. I have little interest in studying the arcane knowledge of C++ and sorting out what is current and what is obsolete, then arguing with a 30 year veteran that their technique is 20 years stale. reply swiftcoder 8 hours agoparentprevI'll grant you that is probably too complicated an example to appear early in the docs, but how often are you actually building multithreaded job dispatch systems from scratch (which appears to be what this example is doing), and how simple would it be in other languages? reply sorentwo 7 hours agorootparentTransparently parallel, lightweight tasks are part of the language in Elixir. Fully multithreaded and able to utilize all cores out of the box. reply foldr 7 hours agorootparentYes, but the Rust code is the kind of thing you'd write if you wanted to build that kind of thing yourself. I do think normal Rust can get too typey, but this is probably not the best example of that. reply diggan 8 hours agorootparentprevThis is how simple it would be in Clojure, for comparison: (defrecord Task [future task-sender]) Probably used something like this: (defn create-task [] (let [future (atom nil) task-sender (async/chan)] (->Task future task-sender))) Not sure it makes sense but a pretty much direct translation as far as it goes. reply galangalalgol 8 hours agorootparentHaving never used a lisp outside an AI class a quarter century ago, that isn't comprehensible to me, and I don't think it is just my lack of caffeine. The rust example makes more sense, but I've used rust for almost a decade at this point and c++ for over three. Familiarity matters. reply Sharlin 7 hours agorootparentBut honestly only for a very short time. It took me two weeks of learning for Clojure to start looking completely natural to me. Surface syntax is such a trivially minor thing, which is why it seems ridiculous to me that the OP author even mentions things like \"Swift uses switch rather than match, such familiarity\" among other much more solid points. reply diggan 8 hours agorootparentprevYeah, of course. If you show me Brainfuck or APL code I won't be able to make head or tails of it either. But familiarity should never stop one from learning new things, otherwise we miss out on a lot of simple, interesting and useful stuff :) reply speed_spread 6 hours agorootparentprevSo it's the same but without type annotations? Meaning that the clojure IDE has a much harder time providing completion and that you need to write all sorts of tests to get the same guarantees as the rust compiler provides for free. Type systems aren't just about memory representation, they also tell the next programmer about the intent and performance characteristics of the code at hand. reply tmtvl 5 hours agorootparentThat's why I moved from Scheme to Common Lisp, it's nice being able to do... (defstruct Task (future :type Future) (task-sender :type Sender)) And have SBCL warn me when I try to jam the wrong type in. reply diggan 6 hours agorootparentprevIf you really badly want types, you'd slap something like this below it: (s/def ::future atom?)) (s/def ::task-sender async/chan?) (s/def ::task (s/keys :req-un [::future ::task-sender])) (s/fdef create-task :ret ::task) (stest/instrument `create-task) But then I don't think you'd reach for something like Clojure if static typing is something that you require. reply jppittma 5 hours agorootparentprevIn golang I think just type Task struct { Sender chan Task } no? reply nurettin 8 hours agorootparentprevIt would be ridiculously simple in go with channels. reply kenmacd 7 hours agorootparentWould it though? Just running things 'async' is simple, but it's also simple in Rust. I wouldn't figure writing an Executor would be any easier in Go than the Rust example at https://rust-lang.github.io/async-book/02_execution/04_execu... reply nurettin 6 hours agorootparentAs I understand, the idea an executor is to emulate an event queue using threadsafe (hopefully lock-free) queues. Since the language already has goroutines, channels and group waits, I don't think this is something that needs to be built in Go. I mean you can do your rate limiting and retry handling logic outside the language primitives. If you do have to make a task spawning executor, you can do that with channels as well. But it would just be a very thin wrapper. reply bitexploder 8 hours agoparentprevThe only tricky thing there is the BoxFuture and ‘static lifetime. Arc is pretty simple. Option is simple. Rust is just forcing you to acknowledge certain things and understand lifetimes explicitly before you can move data around. And static is close to a “plz make this lifetime error go away” thing cause it means it can live forever. But they are also fine, and often the right choice. This may seem contradictory but it will make sense if the Rust compiler hurts you enough times :) reply smodo 8 hours agoparentprevThis may demonstrate the intricacy of the type system but isn’t a very intuitive example… I feel like the Rust Book does a good job of explaining the different types in std. For one thing it shows these types in their most idiomatic use cases. Rust is my first real low level language and I learned a lot by reading the book. And by reading it I mean I actually read the thing front to back before touching a keyboard. Then I started to experiment with some simple code and after a couple of months I had some actually programs that I use often. Obviously I rewrote them after a year but hey ho, it’s all a learning experience. reply hu3 6 hours agoparentprevIt's not just you, I watched yesterday [1] that Bun's author initially tried to use Rust but wasn't as productive. Then he switched to Zig and here they are, innovating JS/TS landscape. [1] https://www.youtube.com/watch?v=eF48Ar-JjT8&t=670s reply junon 8 hours agoparentprevYeah this is a bad example for introductions for rust - namely that async rust is something I'd consider advanced. However the type explicitness is, IMO, one of its strengths. It lets you build up types that e.g. in C++ we're not a given, had properties about the behavior buried in docs, etc. reply pjmlp 7 hours agorootparentIt would be, if there wasn't a trend to expose async all over the place on the Rust ecosystem. Thus even newbies get to bump into it quite fast. reply kenmacd 6 hours agorootparentThey run in to async, but do they run in to the internals of how that code is executed? The chapter that example is from includes the disclaimer: > In this section, we'll cover the underlying structure of how Futures and asynchronous tasks are scheduled. If you're only interested in learning how to write higher-level code that uses existing Future types and aren't interested in the details of how Future types work, you can skip ahead to the async/await chapter. reply pjmlp 6 hours agorootparentNaturally, as soon as they get some kind of async related compilation error. reply XorNot 8 hours agoparentprevHonestly that one I can read (I am just now in earnest trying to learn Rust). What I've been banging my head into is trying to get a suite of boilerplate libraries together to make basic things happen. Got directed from slog to tokio-tracing for logging, so dove into setting up my basic \"--log-level\", \"--log-format\" CLI options I add to every non-trivial program in Rust and ran into...whatever is going on with configuring it (namely, tokio-subscriber seems to encode all the configuration information into types, so you can't just return a Subscriber or Subscriber builder from a function and then add it as a logger...the documentation gives no hint on what trait or type I'm meant to return here). reply guitarbill 6 hours agorootparentNot just you. Best case the tracing ecosystem is weird and the documentation is lacking, but all of the weirdness makes it very performant. Worst case it is weird and badly documented and over-engineered. Since rustc uses tracing I really hope it's the first... reply agubelu 8 hours agoprev> In fact, Swift treats enums as more than just types and lets you put methods directly on it You can do the exact same thing in Rust: impl Coin { fn valueInCents(&self) -> u8 { match self { Self::Penny => 1, Self::Nickel => 5, Self::Dime => 10, Self::Quarter => 25, } } } reply tialaramex 7 hours agoparentAlso they probably have their understanding upside down. What's going on here isn't that either Swift or Rust treats the enum types as \"more than just types\" but that they are indeed first class types, whereas in C and C++ what you get isn't a type at all, it's just a strange way to spell an integer. I don't think Swift has union types, but Rust does and so does C++ and in both languages the unions, just like their main product type (C++ class, Rust struct) can have methods defined on them. The enumeration \"types\" in the C-like languages are special and it's because they really aren't proper types at all, they're just integers wearing a funny hat. One of Rust's most important post 1.0 types MaybeUninit is actually a union, lots of Rust's important types, in 1.0 and since, are enums. reply secondcoming 7 hours agorootparentC++'s scoped enums are strict types. reply tialaramex 5 hours agorootparentScoped enums (\"enum class\") are a very small improvement on the previous enum, the main thing they deliver is that they don't pollute your namespace as badly thanks to the scoping. Their notional status as \"strict types\" means nothing in a language which doesn't really care anyway, that's why memory_order::relaxedmemory_order::relaxedSwift use value-types by default with copy-on-write semantics. This isn't true. Copy-on-write semantics are implemented only for arrays, dictionaries, and strings. Swift value-types are copied immediately. https://docs.swift.org/swift-book/documentation/the-swift-pr... reply mogoh 6 hours agoprevAlways, when I read those postings that praise Swift, I wonder how good is the developer experience is if you don't use any of the Apple/MacOS ecosystem (except Swift, of course). I have not met any Swift developer who is not developing on macOS, usually for macOS. That makes me very skeptical that non-Mac devs are treated as second-class citizens. I am not only talking about the standard library, but also about the tooling, LSP, libraries, tutorials and so on. I totally believe that Swift is a good language, but I guess it is only good if you are on macOS. If you are developing with Swift but not using a Mac at all, I would love to hear how your experience has been. reply pzo 6 hours agoparentAnd even on MacOS you are limited - you cannot avoid not using Xcode pretty much. So in practice you cannot just only use VSCode or Jetbrains IDEs. There is been a talk in WWDC 2024 that apple invest with Swift for embedding systems and some language servers but not sure how mature it is. Apple doesn't have crossplatform in their DNA. reply bryancoxwell 6 hours agoparentprevI recently went through the Swift tutorial for building a REST API using Vapor[0]. I used VSCode, compiled and run on Ubuntu. It’s the only Swift I’ve ever written, and obviously far from a production app, but I did enjoy it enough that it made me want to continue playing with Swift outside of the XCode/Mac ecosystem. [0]: https://www.swift.org/getting-started/vapor-web-server/ reply mogoh 5 hours agorootparentIt's not much, but it's something. Thanks reply hardwaresofton 8 hours agoprevAm I the only one that dislikes the dot syntax for variants? Zig and Swift do it and I feel like it makes things harder to read, not easier. `.variant` vs `Type::Variant` IIRC the syntax is optional (you can include the type name) but it seems obvious that in any sufficiently long or complex code, not having the type name close would be annoying, especially if you didn’t have IDE like capabilities in your editor. reply Klonoar 7 hours agoparentI've said it in other comments on HN over the years, but yes - I agree. That `.variant` syntax is annoying as hell to dig through when you don't have an IDE to rely on for jumping around. Rust (or your choice of other more explicit language) is just generally way more clear about what's being used. The way I usually settle on describing it is that this feature solved for people writing code, but code is read more than it's written, and thus I don't believe this tradeoff was worthwhile. reply robjwells 7 hours agoparentprevFortunately in Rust you can have it both ways, as in `Type::Variant` most of the time and `use Type::Variant; … Variant …` in cases where the type name just causes noise. Example in the playground: https://play.rust-lang.org/?version=stable&mode=debug&editio... reply hardwaresofton 5 hours agorootparentI’ve never done this but this is a great point. I think I’d avoid doing this though because variants often have really short, reusable/general names (leaning into the overall type name being close) reply GrantMoyer 4 hours agorootparentYou can put the use statement in the function with the match, or even limit the scope further: { use MyEnum::*; match my_enum {…} } reply lukeh 9 hours agoprevI don’t know Rust, but I’m loving Swift for systems programming. Most recent project was an 802.1Q SRP implementation and I couldn’t imagine going back to C. Higher up the stack, I’ve also used it with a custom runner to build the business logic for an embedded Flutter app. My only beef is that the binaries are quite large. I’m hoping the new Foundation will improve things, in the interim I’m trying to eliminate my Foundation dependencies. reply ahlCVA 1 hour agoparentFascinating that somebody is using Swift \"in production\" for that! I work on small-ish embedded Linux systems and I've been looking for an alternative to C for a long time. Rust does not fit the bill, both because I don't enjoy the ergonomics of it (but I could get over that were it not for the other issues) and because the binaries are huge, so unless you go for a busybox-style multicall binary (and even then) you'll be wasting a lot of space. Both the standard size reduction techniques and splitting out things into shared objects (the ABI instability is not an issue on an embedded system which always gets compiled as a whole anyway) don't really move the needle compared to what you can achieve using plain C. I've been meaning to give Swift a shot for applications like this. From what I've seen I had assumed that it would have less of a tendency to monomorphize everything (like Rust and C++ like to do when you use them idiomatically), leading to less binary size bloat. You also mention binary size, but in relation to a library - is it that the absolute cost of including the library in the image is too high or is there a per-binary effect here as well? Could you maybe share some of your experiences with Swift on embedded Linux in the context of that project? What is working well, what are the warts? What kind of distribution (like buildroot, Yocto, ...) are you using? Sorry for the ton of questions, it's just something that has been on my bucket list for quite a while and it very exciting to hear that somebody is already doing this. reply neonsunset 8 hours agoparentprevYou can get much smaller native binaries with .NET's NativeAOT nowadays: https://github.com/MichalStrehovsky/sizegame Funnily enough, I'm using C# to solve quite a similar type of tasks. It's a really pleasant experience. reply pjmlp 8 hours agorootparentNative AOT needs to get better tooling ergonomics though, the whole publish process is a bit convoluted versus toolchains that have AOT compilation as their default. Not counting having to learn about IL trimming, and the whole AOT compatible libraries. reply neonsunset 8 hours agorootparentWhat kind of issues did you have with the build process? (as in, if you had a specific case, it might be worth submitting an issue or updating documentation) It's a very straightforward process - you pass a single flag, maybe specify optimization preference and instruction set target, and it gives you the binary upon 'dotnet publish'ing the project. The process of static linking (if you care about this scenario), with other static dependencies written in C/C++/Rust is not too different from other toolchains - you specify `DirectPInvoke` and `NativeLibrary` properties in .csproj, and they are linked into the final product as a part of the build process. You may need to forward linker arguments[0] for the imports referenced by those however, but this is expected regardless of .NET. I think it's fair to criticize the additional compatibility effort required for high-level user libraries that rely on un-analyzable reflection, reflection emit or assembly loading, but none of these features usually have any relevance in the domain of systems programming. When you write a project from scratch, you never have to think about whether it's native compilation or \"JIT+CIL assemblies sandwich\" executable, or anything else. It just works. For example https://github.com/codr7/sharpl - the author was pretty much learning C# on the go and it needed exactly 0 changes besides adding `PublishAot` property to make it output a native executable. [0]: https://github.com/U8String/U8String/blob/main/Examples/Inte... reply pjmlp 7 hours agorootparentAs you are well aware, I know .NET since it was \"partners only beta software\", so dealing with \"dotnet publish\" plus csproj configuration, is still way easier than something like NGEN. However this is somehow cumbersome versus doing a plain \"aot-lang-compiler source -o binary\". Which is the experience I think the team should strive on as goal, especially for newcomers. More so when comparing IDE experience of something like Delphi or Swift to keep it in context (press build), versus Visual Studio (besides csproj, create publish properties file, followed by a solution publish, which is hardly documented still). reply neonsunset 7 hours agorootparent> However this is somehow cumbersome versus doing a plain \"aot-lang-compiler source -o binary\". But...it works in this exact way? dotnet publish -o folder -p:PublishAot=true Does not need -p argument either, as noted in the previous comment, if `PublishAot` is specified in .csproj, like with any AOT template (e.g. dotnet new console --aot or dotnet new webapiaot). On Visual Studio, I have started to recommend to newcomers to avoid its publishing UI which is convoluted and is easy to get side-tracked with. CLI offers much cleaner UX. Not that it matters outside of Windows. But you don't need to create publish file either, just tick the boxes you care about in the modal window. Edit: you can't be serious, no one in their sane mind would consider a single extra keyword to get the final product once you're done writing code a learning curve too steep, unless you're in a bad mood and want to make a bad faith argument. Consider what you make the comparison against - C and C++ with their CMake, Ninja, or even raw MSBuild, Swift is barely better too. Rust with Cargo is about the same amount of effort as .NET CLI. Cmon, Pjmlp. reply pjmlp 7 hours agorootparentPublish versus build, yet another step, another concept to learn. CLI only isn't the answer, if you want better adoption. reply Measter 5 hours agorootparentprevHow are build times for AOT these days? Last time I tried it (~2019) it was slower than Rust at building the same project. reply neonsunset 4 hours agorootparentIf you refer to R2R, then it's more like pre-JIT - it embeds pre-JITed code into the executable that still very much uses JIT. It will also re-JIT R2Rd code if it's deemed hot enough and in need for further optimization. This is an older mechanism that works differently to NativeAOT, it's also used by host-installed runtime to improve startup latency, and you can do your own R2R, either full or granular, to further improve this: https://learn.microsoft.com/en-us/dotnet/core/deploying/read... It can slow down the build quite a bit from what I've seen. NativeAOT is different - when you use it, ILLink (which previously was the Mono Linker and now has evolved) trims all unreachable and links together all of the remaining CIL bytecode and metadata from the CIL assemblies that the application/library consists of. After that, ILC (IL AOT Compiler) compiles everything (and performs AOT-specific optimizations) into a single static bundle emitted as COFF or PE (or Mach-O?) file containing machine code. Then the toolchain invokes a host-provided linker which produces the final native executable or library, much like it happens with C, C++ or Rust. It even has the OS-specific symbol format, so you can feed it to the same tools that work with native code. Technically speaking, .NET's compiler still retains the name \"RyuJIT\", but in practice it's not JIT-specific and ILC drives the same back-end as JIT compilation at runtime, but with different optimizations and options. This is a new feature that was introduced in .NET 7, and has substantially improved further in 8 and upcoming 9. Completely different output aside, NAOT builds take less time than the ones that have R2R from my experience. Your mileage may vary depending on how big the application is, how complex linking it requires and how much the native code to compile there is. The main difference with Rust is that compilation time whether it's good or bad has much less relevance because for development you can use JIT (both debug and release, i.e. plain 'dotnet run') or even hot-reload which can recompile actively running code without restarting the application with 'dotnet watch' which works surprisingly well. reply pjmlp 4 hours agorootparentThe last point is exactly the value of having compiler toolchains with JIT/AOT in the box, as standard toolchain, which only a few are around. We get to enjoy both worlds, and picking the best deployment options as per scenario. Rust development experience would be much better if they adopted a similar approach, which by the way, is common on other ML inspired languages. reply pjmlp 8 hours agoprevWhat Rust did great was bringing affine type systems into mainstream culture. However outside very specific use cases, where no kind of automatic resource management is allowed, no matter what, like in high integrity computing, or critical kernel code, approaches that mix and match both solutions are much more ergonomic. Swift isn't the only one going down this route, we see it as well in D, Chapel, Linear Haskell, OCamml Effects, Mojo, Hylo, Koka, Veronica, and probably many other research languages being born during the last 5 years. Because in the end, programming language ergonomics and expressiveness really matters for wide scale adoption. reply DasIch 7 hours agoparentRust is more popular than all of these languages except swift combined. So it seems empirically that ergonomics and expressiveness don't matter that much or these languages don't manage to do significantly better than rust. reply pjmlp 7 hours agorootparentIt appears more popular, which isn't the same thing. reply rich_sasha 7 hours agoprevMy interest in Rust stems from a very good Python interop. There's a very small handful of compiled languages with that property: Rust, C++, Nim (which is itself quite niche)... That's basically it as far as I know. Swift doesn't seem to tick that box. I would happily have something 50-100% slower than C++/Rust with good interop, alas there seems to be very little / nothing. Cython for various reasons isn't ideal. reply pzo 6 hours agoparentThere used to be Swift for Tensorflow but google killed it and then Chris Lattner created Mojo. AFAIR the punchline was that Swift was either too complicated for data scientists or they just preferred to use python that already knew. reply prmoustache 7 hours agoprevUnrelated to the blogpost in question but I don't understand why the author is not using its own certificate if he is using his own domain. Using an browser set to autodirect to https by default, all I get is some huge warning because the host use a certificate for svbtle, the service used to host this blog. I know some people think that because some blogpost is public it can be served without ssl, but I think it is still nice to leave the choice of the reader to disclose or not to his provider and everyone in between what he is reading or not without seeing horrible warnings. reply alabhyajindal 3 hours agoparentExactly. Very annoying! reply tromp 8 hours agoprev> it gives you utilities such as Rc, Arc and Cow to do reference counting and “clone-on-right” Not quite right: [1] https://en.wikipedia.org/wiki/Copy-on-write reply steveklabnik 6 hours agoparentCow in Rust does mean “Clone on write,” because Copy is a term of art in Rust (as is Clone). reply __jonas 6 hours agoprevDoes Swift make it as easy as Go or Rust to produce a single binary for any target platform? Would it be a good choice for a CLI application? It sounds kind of intriguing but I know very little about the language. reply StewardMcOy 3 hours agoprevAs someone who has worked on large projects in both Swift and Rust, I have to disagree with the author about error handling. It's not perfect, but Rust's use of Result and syntactic sugar is probably the best solution to error handling I've ever used. try/catch (or in Swift's case do/catch) is more disruptive to the program flow. And prior to Swift 6, throws in Swift were untyped. (Yes, there's arguments that untyped throws are better for library code because it leaves you more room to add more errors as you become aware of the need for them without breaking the contract with your users, but really, client code is going to be written to the errors you're throwing anyway (i.e. Hyrum's Law). I much prefer my errors to be typed so that if an error is added, the library version has to be bumped to indicate the new incompatibility with old code. And for my own, non-library code, typed errors make sure I'm handling all the error cases.) reply lame-lexem 5 hours agoprevRust's `Vec` already allocate values on the heap, so there is no need for another inderection with `Box`. this works: enum TreeNode { Leaf(T), Branch(Vec>), } https://play.rust-lang.org/?version=stable&mode=debug&editio... otherwise if it was just tuple of `TreeNode` there would be E0072 https://doc.rust-lang.org/stable/error_codes/E0072.html reply nicce 5 hours agoparentBox takes less space in stack, and you can use Box to move pointer to Vec contents easier, without mem::take. So if you want to min-max things, you could still use Box. reply BiteCode_dev 8 hours agoprevSwift won't be able to compete with rust until it has a great scripting story. Rust is currently the defactor choice if you want to make something with js/python bindings, of id you want to speed up a dynamic bottleneck because it makes it super easy. Swift doesn't even have a good ffi. reply lukeh 7 hours agoparentSwift can import C (and C++) modules directly, and it's fairly straightforward to wrap existing C APIs with callbacks to be usable from structured concurrency. Here's an example I just worked on. [1] [1] https://github.com/PADL/NetLinkSwift reply BiteCode_dev 6 hours agorootparentThis is not what holding swift. What's holding swift is not having a good story to call a swift compiled extension from Python/JS/Ruby/PHP. Python's community is huge, very active, Python is everywhere, and it needs compiled extensions. And tooling to make them BFF, like pyo3 and maturin, is great And that's how we got cryptography, pydantic core, polar... Which motives even tooling to be written in rust as a side effect, and how we have uv and ruff. The scripting community is the most active, if you got them on your side, you get access to a huge pool of devs. reply pjmlp 8 hours agoparentprevTry to make Rust interop with C++, C and Objective-C as easy as Swift does it. reply sgt 8 hours agorootparentThis is a big deal. In reality, most of the code that powers your systems (phones, tablets, any computers) is built using C and C++, regardless what OS you use. reply galangalalgol 8 hours agorootparentAgreed, and rust-c interop is as good as any other I've used. The c++ interop was clunky but getting much better with crates like zngur. That is what was holding back its use on chrome for a while. Oddly its python interop is way better with pyo3 and maturin making it super easy. reply Klonoar 7 hours agorootparentprevC++ is (IME) an order of magnitude more annoying from Rust than C or Objective-C. I've dealt with interop of the latter two on a number of projects and frankly found them to be fine. (Though I wouldn't fault anyone for making an argument that Swift is still more ergonomic here) reply dist1ll 8 hours agoprevThe tree example is quite contrived. Most Rust programmers would use indices for indirection, pointing into flat buffers. reply MereInterest 8 hours agoparentIt’s also incorrect. There’s no need to use both Vec and Box, as either is sufficient to provide indirection. reply singularity2001 6 hours agoprev'Swift is the better rust' inspired by the why-ruby-is-an-acceptable-lisp debate: http://www.randomhacks.net/2005/12/03/why-ruby-is-an-accepta... reply high_priest 9 hours agoprevYes! And C# is just more convenient C. reply dbfa 8 hours agoparentJavaScript is just a more convenient x86-assembly. :P reply neonsunset 8 hours agoparentprevCloser to convenient C++ probably :) reply pjmlp 8 hours agorootparentDefinitely, Windows development would be so much more fun, had Native AOT been there since day one, and WinDev wasn't so much siloed into their C++ toys. reply jb1991 6 hours agoprev> But when you need extra speed you can opt into an ownership system and “move” values to avoid copying. I've been using Swift a long time and don't quite get what this is referring to. Also: > Swift too gives you complete type-safety without a garbage collector. Type-safety and memory-safety are two entirely different things; this is an odd sentence. reply nicce 4 hours agoparent> I've been using Swift a long time and don't quite get what this is referring to. Latest Swift release (June 11th) added ownership system. reply iknowstuff 1 hour agorootparentSeems odd for an article which is comparing rust and Swift not to delve into the new Swift ownership system... reply andrewstuart 7 hours agoprevIf only it wasn't so heavily tied to Apple. reply tkz1312 6 hours agoprevI mean basically everything is a more convenient rust... reply dangoodmanUT 6 hours agoprevClone-on-write... reply neonsunset 7 hours agoprev [–] And C# is a cross-platform and faster Swift :) reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Rust and Swift share many features, including functional elements, a strong type system, and LLVM-based compilation, but differ in their default levels of abstraction.",
      "Swift's syntax and error handling are more familiar and convenient for developers used to C-like languages, while Rust offers more control and speed for systems programming.",
      "Rust is ideal for low-level systems and embedded programming, whereas Swift is better suited for UI and server applications, with potential for increased overlap in the future."
    ],
    "commentSummary": [
      "The post discusses the comparison between Swift and Rust, highlighting Swift as a more convenient alternative to Rust.",
      "It emphasizes that Rust is notable for bringing non-Garbage Collected (GC) automatic memory management to the mainstream, a feature that has sparked significant interest and debate among developers.",
      "The discussion also touches on the evolution of programming languages, noting a shift from Smalltalk-derived languages (e.g., Ruby, Python) to ML family languages (e.g., Rust, Scala, Swift)."
    ],
    "points": 219,
    "commentCount": 242,
    "retryCount": 0,
    "time": 1725613849
  },
  {
    "id": 41460276,
    "title": "The Early Days of Valve from a Woman Inside",
    "originLink": "https://medium.com/@monicah428/the-early-days-of-valve-from-a-woman-inside-bf80c6b47961",
    "originBody": "Valve’s Half-Life on CD-ROM, still available on Amazon 26 years after its original release. The author worked side-by-side with Gabe Newell and Mike Harrington to launch Valve’s debut product and establish Valve as a major player in the game industry. The Early Days of Valve from a Woman Inside Monica Harrington · Follow 27 min read · Aug 20, 2024 -- 59 Almost 30 years ago, Monica Harrington guided the marketing and business development efforts for Valve, which has become the biggest player in the PC game industry. This is her story. Almost 30 years ago, a small company was founded near Seattle WA. Gabe Newell and my now ex Mike Harrington were the official cofounders. I was on a two-month leave from my job at Microsoft, where I was a group marketing manager in the Consumer Division, overseeing a product portfolio that included Microsoft Games. The Microsoft Market Maker Award, chipped but still standing I’d worked for Microsoft for nine years by then. My career was in high gear. A year earlier I’d been honored with the Market Maker award as the marketer who “added the most to the (1600+-person) Consumer Division’s bottom line.” I loved my job but I was also tired, so when Microsoft announced a leave program in the Spring of 1996, I was all in, hoping that a couple of months of paid leave would be invigorating, ideally with some travel and a break from the remodeling project that had left our new home a mess. My husband Mike had other plans. He’d worked in the game industry before joining Microsoft the same year I did, and he had a dream of starting a game company. Mike decided to use his break to figure out if he wanted to stay at Microsoft or embark on a huge new adventure doing something else. During the break he started to solidify plans with Gabe Newell to really make it happen. Our travel plans quickly disappeared. Gabe and Mike had met when Mike was working on printer drivers for the OS/2 operating system and the three of us had hung around together beginning a few years earlier, including a weekend in Eastern WA with Gabe’s then girlfriend. Mike was also friends with Mike Abrash, an industry luminary who was then working at id Software, the independent studio behind the hugely popular Doom franchise. Because of his relationship with Abrash, Mike was able to quickly secure agreement to build Valve’s first product using id’s game engine. That was a huge deal and essentially catapulted Valve and Gabe and Mike into serious company and game development. When I returned to Microsoft, Mike and Gabe and the small team they quickly assembled were well on their way to planning their first product. The original idea Mike had was that Valve would create a product that would be launched by Microsoft. It turned out that Microsoft had little appetite for doing a deal with its own former employees, which meant that Valve would need to sign a publishing agreement with one of Microsoft’s competitors. Because of my role overseeing Games Marketing for Microsoft, the interplay with Valve was complicated. The investment Mike and I were making in Valve was substantial so I knew I couldn’t not be involved, but I also needed boundaries. When I returned to Microsoft, I went directly to the head of games and to the VP of our division to say that my husband and Gabe Newell were starting a games business, and that I would be helping them, and that I’d be open to any changes Microsoft might want to make in terms of my role as a result. Both Ed Fries and my managers were friendly and reassuring. At the time, there were literally hundreds of games published each year that vanished into the ether. Valve was a tiny player, and I’m sure from Ed’s and everyone else’s perspective, likely to remain so. I was traveling for Microsoft on a cold wintry day in Seattle when Mike called to tell me that he and the team had just finished meeting with the head of Sierra Online, which was a major force in PC Games and one of our biggest competitors. Their office was in Bellevue WA, just twenty-five minutes or so from our home. Because of the icy conditions, Ken Williams, their CEO, was the only one from Sierra who made it into the office. By the end of the meeting Ken was essentially saying to the team, “I want to work with you…let’s make it happen.” Because of my role at Microsoft, I decided not to get involved in the contract negotiations. It was up to Mike and Gabe to figure that out with Sierra. At the time, standard industry practice for an unproven game company was for an upfront advance against royalties, with additional royalties due only if the game were successful. The Sierra advance was for approximately a million dollars, which along with the hundreds of thousands Mike and I and Gabe had already invested, meant that Valve had enough to fund the company through the launch of the first product. The first product was going to be a first-person shooter, in the same category as id’s category-defining game Doom. Gabe and Mike and I were meeting regularly and one of the things I told them was that the Games business was a hit-based business, where only the top 10 games made any real money. At a time when thousands of games were being introduced each year, it meant that Valve’s first game was going to be a hit or it wasn’t, and given the dynamics of the games industry, if the first game wasn’t a hit, there likely wouldn’t be a second Valve game. Gabe and Mike had been talking about trying to launch a B product, something that wasn’t a hit, but that would be successful enough to support the company as it established itself, and I knew and made clear that simply wouldn’t work. For the next ten months or so, the activity at Valve was all about hiring and onboarding people, building out appropriate office space, and fleshing out the game concept that had hooked Sierra’s Ken Williams. While I continued to consult with Valve, my day job at Microsoft was invigorating. One of the projects we had underway was the first global launch of a new game, which meant a simultaneous launch in all of the markets where Microsoft had a consumer presence. My team and I had been working for months to make sure we had the launch and marketing strategies ready to go to support Microsoft’s next big hit game in markets around the world. At the time, the game group’s biggest hits to date were the strategy game Age of Empires and Flight Simulator, a product that mostly appealed to pilots and flying enthusiasts. In the background, I was still working with Valve, something I reminded Microsoft folks about frequently. No one seemed worried. My general rule was that I wouldn’t tell Microsoft anything about Valve, and I would tell Valve nothing about what was happening at Microsoft. However, all of the learning I was doing about the games industry in my work and personal time was definitely put to work for both Microsoft and Valve. Mike and I were each working 10 to 12-hour days or more. At one time, I was in a meeting with some well-known game developers who had signed a long-term, multi-game development deal with Microsoft and the subject of Valve’s new deal, using the id engine came up. The leads of that company, not having any idea about my ties to Valve said something like, “what a joke — a couple of Microsoft developers license the id engine and think they can build a game.” Inside, I thought, “Oh man…this is going to be tough.” One of the roles I played with Mike and Gabe in those days was to help them understand what it would take to be successful from a marketing and business standpoint. At the time, the key marketing strategies for games involved PR and outreach to influentials, advertising in game-specific publications, and working with the retail channel on strategies to get prominent display space so a consumer walking in would feel compelled to pick up and purchase your game. Once a game shipped, you had to feed and nurture the early adopters, supporting them so they could tell their friends about your game. The broad strategy I’d learned and fine-tuned over a period of years was essentially “Arm and Activate (early adopters).” From a PR perspective, Microsoft was a phenomenon within the industry. By the time I worked on the games business, I’d spent years working directly with consumer and technical press for products ranging from Microsoft Word and Office to Expedia and Encarta. I’d also managed large product marketing and communication teams, and had been on press tours meeting reviewers around the country, from New York to New Hampshire to Austin, Texas, and Eugene, Oregon. The games business shared a lot in common with some of the other businesses I worked on, but there was also a key difference. In a business like Word or Office, you basically run your marketing with a winner-take-all perspective, and that’s because in those businesses, there’s likely to be one market leader, and as that leader gains more market share, its advantages continue to grow and become self-reinforcing as companies and the broader industry standardize around one product. At the time, my experience in fighting market battles with Lotus and WordPerfect was that a given software category will only support one market leader. The PC games business in the late 90s was much more like the music business, where there were lots of independent studios, and where the developers treated each other much as musicians do. There’s mutual respect, there’s competition in a given category, but also the understanding that gamers are going to buy multiple games. If they love your game, they also have room to love your competitor’s game and in fact someone who likes action games is likely to be a connoisseur of the category, with multiple favorites. The most influential people in the games market were not press, but game developers themselves. For the publishers and major players, it was a different story. Microsoft was competing against Sierra and Electronic Arts to attract game developers, much like music labels at the time competed to sign top musical talent. The typical 15 percent royalty margins for new games developers mimicked other content deals in music and book publishing. Of course, the huge difference between the games business and the book or music industry was that the costs of producing a game were much higher and starting to climb exponentially. At Valve, costs were growing rapidly as the team was being built out. Soon it became clear that the initial investment Gabe and Mike and I had made plus the advance Sierra had made were not going to cover the actual cost of producing Valve’s first game. One evening Mike and I hosted a potential new Valve hire, Yahn Bernier, and his fiancé at our newly remodeled home. I remember thinking that “if we hire you, Mike and I and Gabe are going to be paying your salary from our own pockets.” We pitched Yahn and his fiancé Beth hard. I remember that it was only a few days earlier that Beth had learned Yahn even did software development, as his day job was as a patent attorney in Atlanta. Valve’s strength in those days was finding talent around the world who had done amazing things — the type of things that might not show up on a typical resume but could be discovered on the Internet, which in many ways was still in its infancy. At one point Gabe tracked down and recruited two creators of game-related software that was becoming popular on the Internet only to discover that they delivered pizza for a living and they thought Gabe’s phone call was part of some elaborate prank. Fortunately, while the Valve development team was working to build Half-Life, my Microsoft options were continuing to vest, which meant that Mike’s and my net worth continued to climb. It was stressful, but in the overall context, the stress was manageable. Somewhere in the first year of Half-Life’s development, I officially wrote up the marketing plan for launching Half-Life. Key to our strategy was positioning Half-Life as a game that was worthy of Game of the Year honors. We wanted to earn the respect of the industry influentials, which included the gaming press and other game developers. As part of the strategy, Valve’s developers went to industry conferences to talk about some of the work they were doing in key technical areas including AI, skeletal animation, and physics. In support of the effort, I wrote up backgrounders on each of these topics for the press based on interviews with developers Ken Birdwell, Jay Stelly, Yahn Bernier and others. In the Spring of 1997, I was in a meeting at Microsoft about the upcoming E3 show, which was the biggest and most important industry tradeshow for electronic entertainment companies. One of my team members made the recommendation for Microsoft not to attend the show, and during her pitch to me and others, part of her recommendation was clearly based on the idea that our competitors weren’t likely to have a major presence there. I knew Sierra was going to be there and Valve would have a big presence. Meanwhile, the game I’d been focused on for Microsoft, which would have been at the show, had faced a huge setback. A month or two earlier, I had initiated a meeting with Ed Fries where I told him point blank, “I’m not hearing great things about our game and am losing confidence. Are you sure?” My conversation was based on hallway talks with various gamers within the division, who had had exposure to the game and weren’t excited. Basically, I couldn’t find anyone who really believed in the game. I also knew from the work I was doing for Valve what it felt like when developers who are also gamers are hugely excited about a new project By that time, Microsoft’s Consumer Division had already laid a huge egg with Microsoft Bob, and I knew that if we launched another consumer product that didn’t live up to the expectations we’d raised, the broader consumer effort would be hugely damaged. After some soul searching, Ed decided to cancel the launch, and the huge plans we’d made were quietly set aside. By that time, I knew that Sierra was going to be teasing Half-Life and that it would be the star of their booth at E3. I remembered thinking, “Damn, I know too much. Something has to change.” I had another conversation with Microsoft execs about my role and the conflict with Valve, and again I was essentially told, “it’s fine, we’re OK, we like where you’re at, don’t worry.” A couple of months later, Valve’s Half-Life premiered publicly in the Sierra booth at E3 in Las Vegas. The demos Valve showed were so well received that Valve earned Best Action Game honors at the show. When the Valve team returned from Las Vegas, and I got the full update, I asked for a meeting with the division’s senior exec, and said, “this may not be a conflict for you, but it is for me. I need a new assignment.” Shortly thereafter, I started a new role within the company, completely unrelated to the games business. As the months went on and Valve’s costs continued to escalate, it became clear that Mike and I were maxing out on our financial commitment. Rather than renegotiate the contract with Sierra, Gabe, who had started at Microsoft much earlier than Mike and me, began funding the ongoing development costs, set up as a loan against future company profits. Over that summer and in the months to follow, the “game” that Valve had shown, which wasn’t actually a game, but instead was some elaborate demos, went into early playtesting, which involved bringing gamers into Valve, having them play with the game elements and giving us their feedback. The feedback was OK. Just OK. Which for a company that needed a hit was devastating. Gabe and Mike and I all knew that we couldn’t stay the course. If Valve shipped the game we had, it would launch and quietly disappear, and all of the work we’d all done would account for nothing. All of the people we’d hired would lose their jobs, we’d lose the money we’d invested. It was a disaster. There was no choice. Ultimately the decision was made to essentially toss out what we had, and use everything the team had learned to that point to start fresh. Unfortunately, Sierra was not on board with the plan. They wouldn’t invest any more to make Valve’s first game a hit. We were on our own. Gabe’s deep pockets became more important. It would take more than a year for Valve to rebuild Half-Life in a way that put us back into the position which everyone assumed was already the case– with a game that could be launched in just a few months. The new target become launching for the Christmas season of 1998. In the Spring of 1998, Gabe was essentially saying, “When can you be here full-time? We need you now.” I’d already written the marketing and launch plan for Half-Life, I’d written all of the press materials and copy for the web site, I’d written the backgrounders we shared with key press, but I was not focused on some of the larger business fundamentals. As a huge example, I still had not read the publishing agreement Gabe and Mike signed with Sierra. I went to my bosses at Microsoft and essentially said, “I’m ready to leave.” In my closing interview with Pete Higgins, then the VP of Microsoft’s Consumer Division, he started by saying, “Is there anything that would get you to stay?” and I knew the answer was No. I needed to move on. Valve needed me. We had had too much invested. It was time. For the next few months, I worked furiously laying the groundwork for Half-Life’s launch. Among the projects I worked on was seeding a story with the Wall St. Journal. Basically, my idea was to build retailer buzz so that the retailers who were going to be putting in orders for the Christmas season would order more Half-Life and feature it prominently. For several weeks, I sent the reporter emails with updates about all of the great Half-Life news, from developer comments to industry buzz that was appearing in the gaming press. By that time, most of my Valve work was with Gabe or the other developers or with Sierra’s own marketing team. Mike was furiously heads-down on the final work needed to finish Half-Life so we could send it off for duplication. One of the key issues we worried about was piracy. One of my nephews had recently bought a CD duplicator with a monetary gift I’d sent him, and I was horrified to realize that he was copying games and giving them to his friends. To him, it wasn’t stealing; it was sharing. A generational shift in culture and technology meant that the game we’d poured our blood and treasure in would likely be pirated from its first days not just by the professional thieves, but also by everyday end users. At the time, no publisher was doing effective checking to ensure ownership of a PC game was legitimate. Valve would need to implement an authentication scheme. At around this time, we caught a lucky break. For about a year, we’d been pushing Sierra on plans for seeding Half-Life with OEMs, the computer manufacturers who produced the hardware on which Half-Life could be played. For a time, we were even talking seriously with Intel about a version of the game that would highlight the features in a new chip they had under development. All of this came from the collective Microsoft experience about working with OEMs and seeding product in mass quantities to spur user adoption. Ultimately, the Intel play didn’t happen but one of the programs that Sierra led involved providing a small portion of the game that they shipped as a trial disk called “Day One.” When we first realized what had happened, that Sierra had shipped some of the Half-Life code as Day One, Mike and I were furious. We quickly realized that we were at the mercy of whatever happened next. Fortunately, Day One became a phenomenon. Game developers LOVED it and began buzzing. Half-Life was going viral. The product was still a month or two from completion and no one had played the final game, but the early buzz for the first portion of the game was hugely promising. I continued to feed the Wall St. Journal reporter news about Half-Life, about its early reception, about what we were hearing from Day One users. It was all hugely positive. Mike was still coding and he was exhausted. I was exhausted, and the team was antsy as we really didn’t know how Half-Life would do in the marketplace. Finally, in late 1998, a few weeks before Christmas, we were ready to ship. Valve had a party where Mike broke open a pinata filled with candies and small toys. While the game was in manufacturing, final disks went to the gaming press. We waited. At some point, when Mike was in the shower, I felt overwhelmed by anxiety and asked with a worried tone to my voice, “Is it really a good game?” and his honest response, “I don’t know.” Gabe and Mike and I had all been through the shipping process at Microsoft, but being part of a large team where the company backed everything was completely different from being the funders of a company where we knew it was a one-shot deal. The game would either be a hit or it wouldn’t, and for a short while, when the disks were being duplicated and the packaging printed and shipped, we simply wouldn’t know. The first disks went straight to the key gaming press. About a year earlier, I had worked with Gabe to set the audacious goal of Half-Life winning at least three of the top industry Game of the Year awards. We very consciously thought through what it would take, including breakthrough technology, a compelling new angle, and broad industry support. It was going to be especially tough for a game that some insiders initially dismissed as “Microsoft developers building on id’s technology.” Within a few weeks, Half-Life won the first of more than 50 Game of the Year awards. It had never happened before. Shortly before Christmas, the Wall St. Journal article came out with the headline, “Valve’s Storytelling Game is a Hit.” In the article, Sierra as our publisher was never mentioned. That was an explicit strategy of ours — since we were funding the development, we wanted Half-Life to be known as a Valve game, not a Sierra Studios game. A few weeks before Christmas, we were all exhausted. Some members of the team took vacation, but most continued showing up, almost in a daze, as we moved from tight pre-production intensity to the purgatory of Wait and See. We hadn’t seen any sales figures. At one point, just after the game had shipped and we started seeing feedback online about how awful the authentication system was, Mike was yelling. It turned out that when someone complained about the authentication, Mike called the person back directly, challenging them and asking for sales verification. None of the people Mike contacted who complained early on had paid for the product. Mike was mad and tired but also vindicated. The Game of the Year honors kept coming in, and we were optimistic that the great reception we were getting from industry influentials would ultimately translate into financial success for the company. I started working feverishly on post-launch marketing strategies, which mostly involved amplifying Half-Life’s success and making sure retailers were armed with sales data and point of sale materials so customers could find it. I had purchased the web site GameoftheYear.com and we launched it with all of the material about the Game of the Year honors Half-Life was winning, including from PC Gamer and Computer Gaming World, which then were the heavyweights in our industry. In the meantime, Gabe and Mike’s relationship had deteriorated. A huge part of this was the stress and the financial imbalance. Gabe had become the major funder, and Mike had essentially burned himself out doing the final critical coding work before Half-Life shipped. Where before we’d tried to shield the team from our collective anxiety, Mike’s yelling at customers had unnerved some people. I found myself in a situation where the two founders were essentially not talking to each other and people were tiptoeing around wondering what was going on. Then, in January at a time when I was getting ready to focus on Next Steps, Sierra asked for a meeting. Essentially their message to us was “thank you, the game’s done great, we’re moving on.” They were pulling all marketing from Valve to focus on one of their next titles. Basically, their marketing at the time amounted to Launch and Leave, whereas we were trying to market a franchise-worthy game that we could build on for years to come. Gabe and I were stunned; I was also furious. I knew that the marketing of Half-Life was only getting started. We’d done all of this hard work to earn Game of the Year honors with the idea that that would help us break out from the pack and it was time to capitalize on that effort with sustained marketing. At Microsoft, winning awards was always the start of a much larger process where we leveraged positive reviews to win customers over time. With steel in my voice, I told the Sierra team that they were not pulling marketing dollars from Half-Life. They were going to re-release it in a Game of the Year Box, and they were going to support it with huge marketing spend or we were going to walk away from our agreement and tell the industry that had fallen in love with Valve how screwed up Sierra really was. At the end of the meeting, I was shaking. We were vulnerable, the partners were barely speaking, and life at home and in the office was tense. Sierra relented and started working on the packaging for a new Game of the Year box. The icon on the front looked similar to an Academy Award. The basic idea was that for anyone walking cold into a game retailer, they would quickly see that Half-Life was the Game of the Year they couldn’t ignore. By early March, things at Valve were still very strained. In addition to ongoing communications and marketing work for Half-Life, I was working on developer strategies closely with Gabe and some of the other developers and Mike was spending less and less time at the office. At some point in the early Spring, Mike said to me, “I want to leave Valve.” I was in a panic. We hadn’t made back the money we’d invested. The buzz was continuing to build, but we had a long way to go. I told Mike that we needed time to figure out a pathway out, as at that time, the value of our ownership stake was highly questionable. At the same time, I was also panicked because I’d read, for the first time, the contractual agreement between Sierra and Valve, and while I thought I’d understood the key terms Gabe and Mike had agreed to, there were several points I hadn’t been aware of. Chief among them was that Sierra owned all of the intellectual property for Half-Life and held the exclusive option to publish Valve’s next two games, all at a royalty rate for Valve of 15 percent. We would do all of the development work with an upfront royalty advance of $1 million for each of those games, and Sierra would get 85% of the revenue and all of the intellectual property. At the time, I knew development costs were approaching $5 million or more per game Given the licensing deal we had with id for the game engine license, the lack of any ownership of our own IP, and the exclusive commitment for future game publishing rights, all I could see was Valve swimming in red ink for years to come. We needed a different path forward. Fortunately, one of the consequences of Valve’s work on an authentication system was that our customers were registering with Valve directly, Early on, we started to understand the benefit of what we’d inadvertently done. Instead of a situation where we had no idea who our customers were, we actually knew exactly who our customers were. It was unprecedented. Every Half-Life registration meant a customer contact directly in Valve’s database. Added to this, the previous year, Gabe had had the brilliant idea of recruiting a development team that had written one of the leading mods for id’s huge hit Quake and now they were part of Valve’s team. John Cook and Robin Walker were delightful Aussie additions to Valve. The game mod they’d written to run on top of id’s Doom was quickly adapted to run on top of Half-Life. Essentially the game mod enabled a player to play a completely different game on top of the technology of Half-Life. In the case of Team Fortress, it was a multiplayer game where you could team up with your friends over the Internet in a team-based game where each of you played a unique and fun character. While the Half-Life buzz was continuing to build through word-of-mouth and the new marketing push, the additional buzz and enthusiasm that came as a result of Team Fortress was layered on top of everything else. Soon there were hundreds of thousands of people playing Team Fortress on top of Half-Life and Valve knew who each and every one of them were. We had a direct pipeline, bypassing Sierra, to our own customers. In late Spring, Team Fortress, the Cook/Walker mod for the Half-Life engine was presented at E3, where it won Best Action Game and Best Online Game on behalf of Valve. Through all of this, I continued to noodle about the best ways I could position Valve for long-term success. With the bad publishing deal in hand, I knew I had to work on multiple fronts. If Mike and I were to leave, we needed to demonstrate value for Valve that wasn’t tied directly to the Half-Life IP. We needed to renegotiate our deal with Sierra. And we needed to figure out a way to cap our royalties to id, so that Valve wouldn’t be paying them a fee each time someone bought one of our future games. Valve had already done a lot of work to customize the id engine code for our purposes, and we’d reached the point where for any next game, we’d either continue using and adapting that code base or we’d take the time to write new engine code ourselves from scratch. With Gabe’s OK, I reached out to the team at id, and we came to quick agreement on a capped deal. The second step was to kick off steps to renegotiate our agreement with Sierra. I met with Valve’s attorney, and the basic approach we took was to make clear that if Sierra was going to insist on keeping the original deal, then the Valve team would pivot to a completely different category and never publish a second game. Since Gabe and Mike had a ton of experience in other facets of software development, the threat was not idle. The bottom line was we weren’t going to create games and take on all of the risk only to make other people rich. One of my responsibilities in the mid-90s at Microsoft was overseeing the initial marketing for Expedia. I’d spent a lot of time with Josh, the person on my team who was tasked with laying out the market case. From that and other experience over the years, I knew a lot about how to scope and size the online opportunity for a completely new category. I got to work trying to figure out an online business opportunity that wasn’t dependent on the Half-Life IP. Internally, we had rich experience to draw from. Gabe and Mike had a lot of experience with developers and with the developer marketplace, and at one time, I’d overseen Microsoft’s PR outreach related to software tools for the developer community. In addition, I knew the games business inside and out, and I’d been part of teams within Microsoft that were completely focused on the emerging online opportunity made possible by the Internet. By the summer of 1999, Mike was researching trawler yachts, I was immersed in figuring out Valve’s potential business opportunities, and Gabe was doing deep thinking, leading the team and communicating with customers. In the meantime, because of the way Gabe and Mike had structured the ownership, where employees could earn equity over time, Mike’s and my ownership stake was effectively shrinking. Finally, at some point, I realized that the only way to prove the worth of some of the ideas I was focused on was to write them up and get an offer. Without that, I could make the case that Valve was worth a lot of money or nothing. And I knew Gabe could make that same case. With Gabe’s buy-in, I decided to pitch Amazon on a new business opportunity. I’d known about Amazon for a long time as one of my dear friends from Microsoft had been hired on as its original marketing lead. She had since left, but I’d followed the company closely. At the time, it was headquartered in South Seattle in an imposing building just South of the i-90 freeway exchange. In a nine-page document, I proposed that Valve and Amazon team up to create a new online entertainment platform. I scaled the business opportunity within four years at $500 million dollars. The gist of the idea was to create a made-for-the-medium platform that would bring users together in a sticky, compelling entertainment experience, with digital and offline content sales. I wanted Amazon’s financial backing as a way to gain first mover advantage against Microsoft and Electronic Arts, then the major PC games players. I didn’t see a role for Sierra. If pushed, we wouldn’t create any new games ourselves, and instead would team with outside developers so that they could distribute content not subject to an 85% publishing fee. At the time, I considered it an act of rebellion against the traditional publishing dynamic where independent developers took on huge risk, and the big publishing houses reaped the rewards. With Gabe’s OK, I sent the document over to Amazon. Within a short period of time I had a response. “Let’s meet.” When I arrived, the Amazon Vice President I met with was super friendly. He was familiar but I couldn’t place him. Then he said, “You don’t remember me, but you interviewed me at Microsoft.” I realized I must not have hired him, and for the first time, started getting uneasy about how things would go. He reminded me gently that when Amazon was pretty much in its infancy and a company I knew of mostly because of my friend, I had interviewed him for a position at Microsoft. He was interviewing at Microsoft because the company he worked for had just done a major layoff. Our division was pretty much in a temporary hiring freeze and he had a background in retail, so I suggested he look into a tiny company named Amazon. By the time we met again, he’d been there several years. We had a great discussion, and a couple of weeks later, a champagne bottle appeared at Valve’s door. It was exhilarating and scary at the same time. We had an offer from Amazon for a minority stake, but the dynamics within the company were tricky. Amazon could help propel Valve to the next level, but the partnership would not be without costs. Valve’s culture was still evolving. A partnership with a major outside player could help but it could also hurt what we’d all built. It was after the Amazon offer that Mike revealed to Gabe that he wanted to leave. With an offer in-hand, it didn’t take long for us to figure out the outline of a deal. Ultimately, Mike and I gave up ownership to start the next chapter of our lives. The structure of the deal meant that we would be vested in Valve’s success over the next five years. I knew the opportunity that lay ahead. I also saw huge risks. The Sierra deal might collapse publicly, employees might get spooked, we might not be able to actually get the IP back, and with any online endeavor, there would be huge new risks. Within several months, Mike and I left Seattle for a new adventure on San Juan Island and Whistler B.C. I continued to make myself available to Valve. But for the most part, I shed my work identity and started on new projects, including a passion for protecting Washington’s resident orca whales. It was up to Gabe and the Valve team to move the business forward. Several years after Valve, I went to work for the Bill & Melinda Gates Foundation, and from there, took on another CMO role when Mike started a new partnership and business focused on photo editing. That company, Picnik, sold to Google in 2010. I continued to see the Valve team intermittently through the years, and even worked with the team on a story that appeared in the New York Times in 2012 about Valve’s highly unusual flat culture. When the Half-Life IP was secured and owned by Valve, the team sent us a small trophy with the etching “Welcome back Gordon.” Gordon was the key protagonist in the Half-Life adventure. In 2016, Mike and I separated and then divorced. In 2018, I joined Gabe and some friends from Valve on a cruise on Gabe’s yacht around the islands of Japan. Some ten years after Half-Life’s release, PC Gamer named it the Best PC Game Ever. In a separate story, PC Gamer also named Half-life the Best Marketed Game Ever, with special credit to whoever came up with the Game of the Year box and retail push. Valve’s online platform Steam is now an industry phenomenon, with annual sales in the billions of dollars. As I look back on the huge success Valve has become, I’m proud of what the team accomplished. I’m also proud of the work I did while recognizing that my biggest contributions to Valve’s business went largely unnoticed and unrecognized within the industry. Part of that was due to the bro culture of the software business, part of it was that I receded to support my husband in a partnership where he was effectively the lesser partner, and part of it was that women, especially in tech, often seem to disappear when the story gets told. I was hugely disappointed when Valve released a video in 2023 about the creation of Half-Life where one of the people interviewed, Karen Laur, a wonderfully talented texture artist, talked about the isolating experience of being a woman at Valve and essentially said that the only other woman during her tenure there was an office manager. I understood why she felt as she did, but the senior Valve team knows better. Watching the video, I felt like my place in Valve’s history had been completely erased. I know that Valve wouldn’t have been successful without Mike. It wouldn’t have been successful without Gabe. And it wouldn’t have been successful without me. A friend of mine who knows the full story once said to me, “you were a founding partner” and in hindsight, I agree. From the beginning, I invested time, treasure and industry expertise to make the company a huge success. And it is. The author celebrating the holidays along Route 66 with Scott. Monica Harrington lives in Bend, Oregon, with Scott Walker and their spaniel Johnnie Walker Black and White. Editorial note 8/21: The author updated the details regarding the authentication scheme and the name of the mod created by Robin Walker and John Cook, which ultimately shipped as Team Fortress Classic.",
    "commentLink": "https://news.ycombinator.com/item?id=41460276",
    "commentBody": "The Early Days of Valve from a Woman Inside (medium.com/monicah428)209 points by krajzeg 22 hours agohidepastfavorite39 comments ryandrake 20 hours agoWhat really struck me was how OK Microsoft seemed to be with her moonlighting for Valve, basically working for a competitor (albeit a small one) directly in a role that was also her role in Microsoft. Pretty much unheard of in FAANGs today. You can't so much as breathe on an external project today without FAANG claiming IP ownership over anything and everything you breathe on. Imagine working for Apple and telling your manager, \"Hey, by the way, I'm going to be helping out a little with a small-potatoes competing mobile operating system project... You're cool with that, right?\" > I had another conversation with Microsoft execs about my role and the conflict with Valve, and again I was essentially told, “it’s fine, we’re OK, we like where you’re at, don’t worry.” WOW! reply Dwedit 18 hours agoparentGabe Newell was on the Windows 1.0 team. reply gibbetsandcrows 14 hours agorootparentAn Easter egg of his was recently found in an old Windows 1.0 file. https://www.techradar.com/news/almost-37-years-after-its-lau... reply kevingadd 15 hours agoparentprevAnyone planning to moonlight while working at a big company should consult a lawyer first, but Microsoft has very employee-friendly policies in general. reply intelVISA 20 hours agoparentprevOof. What a sly way to imply the person doesn't have any real value to the company, MS truly be ruthless. reply fn-mote 20 hours agorootparentThe way I took it was that she was producing a lot of value at Microsoft and they estimated the “threat value” was very low. In this case they were wrong, but could anyone have known? reply 0cf8612b2e1e 19 hours agorootparentThis was years before Steam. It was just a regular game studio, of which most are complete failures. reply justsomehnguy 18 hours agorootparentprevFunny, I just recently had a talk about this with a guy who is younger than Half-Life. ugh Basically, at this point MS already had an understanding what games are a great driver for selling both the OS and apps, but the game market itself was too small to bother with more than being a publisher: >> In the United States, Age of Empires debuted at #7 on PC Data's computer game sales rankings for October 1997.[36] It secured places eighth and 13th the following two months, respectively.[37][38] By the end of 1997, Age of Empires totaled sales in the country above 178,000 units, for revenues in excess of $8 million. This performance made it the United States' most successful real-time strategy game during late 1997: a writer for PC Gamer US noted that its sales surpassed the combined totals of rivals Total Annihilation and Dark Reign over the same period, and were over four times greater than those of Myth: The Fallen Lords.[39] Sure, AoE was a great success eventually ($120M revenue, by 2000) but it was a hit which surpassed many, many other games and but it took a lot of time; while this was still a summer of '97. reply smittywerben 18 hours agorootparentprevI find your speculation about Microsoft's intent to be vapid and unnecessary. Those who are easy to work with and well-liked are allowed to do more. It's that simple. This dynamic is common in workplaces. reply klyrs 20 hours agorootparentprevI read this as hubris from Microsoft -- they valued the author's work, but the expected value of a game company is negative so that's how they played their hand. reply hex4def6 19 hours agorootparentI don't know if I read that as hubris. What else could they do? If they say \"no,\" and this truly is something she's interested in, they risk losing her completely. I think it sounds like they were remarkably accommodating. I doubt you'd find many companies these days that would grant the same sort of deal. reply fragmede 19 hours agorootparentDo you know a lot of people who report to directors at many Fortune 100 corporations? I'm sure if you are high up enough, and have specialized enough skills, many companies would grant the same deal because there are only a handful of people in the world that have been proven able to do that job. How many Bob Eigers are there? reply ryandrake 18 hours agorootparent> 'm sure if you are high up enough, and have specialized enough skills, many companies would grant the same deal because there are only a handful of people in the world that are able to do that job. How many Bob Eigers are there? I think many people believe this, but how do they know? There are ~7 billion people on the planet. You mean to tell me that only a \"handful\" are capable of doing a particular job? And not even \"CEO of billion dollar company\" but \"Director of a 200 person org who attends meetings and makes decisions.\" Really? Only a \"handful\" of the 7 billion people on earth can do this? reply barrkel 18 hours agorootparentThere's the raw talent, and then there's everything else: occupying powerful positions near the top of the hierarchy, the social network, the experience, the track record, the lessons learned from mistakes made, and so on. There's only so much room at the top, and you need to spend time near the top to get everything else. Truth is, the everything else is a big part of the package. reply ryandrake 18 hours agorootparentIt's really all about the room at the top. Every company is pyramid shaped, and not all of us can physically fit at the top of the pyramid. It's not about whether you can do the job, it's just that there's only a few slots up there, and a lot of us. I truly believe I could do the job of my grand-boss 4 levels above me on the totem pole, and so could most of my peers. The reason I'm (or someone else is) not there comes down to things like timing, luck, who got where first, and just the reality that one person already being in that SVP position simply blocks everyone else from being there. I really think that a large number of leaf-node employees are massively under-employed compared to what they are capable of. I guess it's kind of a reverse-impostor syndrome. reply fragmede 18 hours agorootparentprevalright. I edited my comment to say \"proven able to do the job\" instead. reply wk_end 19 hours agorootparentprevThat interpretation seems to contradict Microsoft's general attitude towards her: > I’d worked for Microsoft for nine years by then. My career was in high gear. A year earlier I’d been honored with the Market Maker award as the marketer who “added the most to the (1600+-person) Consumer Division’s bottom line.” reply rPlayer6554 15 hours agoprevThe author has the conclusion that she was wiped from the history books because she's a woman. But her husband worked almost the exact same amount (if not more - because he was always a full time employee.) and he got equally erased from the history books. Competitive environments can be cutthroat and she and her husband let Gabe become the face of the company because they left. reply chis 2 hours agoparentThis article contains 7000 words and exactly one paragraph is about being a woman at Valve, mostly it's just a depiction of the early days there and how Gabe ended up as the sole remaining founder. I truly doubt you read the article. reply gyropants 14 hours agoparentprevAdditionally, she had to be less visible because her primary contribution was marketing. She describes in detail how much time and effort was necessary to create advance buzz around the game (seeding stories to the press, the \"game of the year\" posturing before they actually had a game). Her contributions were major to be sure, and I don't mean to downplay her efforts towards Valve's success. But by necessity, the machinery of marketing needs to be mostly invisible, because the manipulation doesn't work when people are conscious that they're being manipulated. reply nox101 14 hours agorootparentAgreed, how many marketing people can you name from Hollywood? Me, zero. But you can probably name some of the people who created the movie (actors, directors, producers, musicians, etc....) reply ofrzeta 13 hours agorootparentI don't know many producers, maybe with the exception of the Broccoli family who are producing James Bond :) I know some directors of photography, though, because their work is defines an aesthetic characteristic of movies. However I was/am a film buzz for a long time and don't think the layman will know any directors of photography. Related it's also interesting that in German the directory of photography is only called a \"Kameramann\" (camera guy) while the English term emphasizes their \"directing\". And it's true. They are typically not the ones operating the camera but have operators for that like \"focus pullers\". Sorry, I got carried a away with the topic a little bit :) reply quadyeast 3 hours agorootparentThe (film) camera dept, led by the cinematographer, encompasses the camera operators, the electricians led by the Gaffer, the grips led by the key grip, and the camera assistants which includes loaders and focus pullers. reply zackmorris 3 hours agoparentprevYours is an off-color take that does a disservice to the HN readership. I'm saddened that it's currently the top comment. Here's what I saw: As the months went on and Valve's costs continued to escalate, it became clear that Mike and I were maxing out on our financial commitment. Rather than renegotiate the contract with Sierra, Gabe, who had started at Microsoft much earlier than Mike and me, began funding the ongoing development costs, set up as a loan against future company profits. .. By the summer of 1999, Mike was researching trawler yachts, I was immersed in figuring out Valve's potential business opportunities, and Gabe was doing deep thinking, leading the team and communicating with customers. In the meantime, because of the way Gabe and Mike had structured the ownership, where employees could earn equity over time, Mike's and my ownership stake was effectively shrinking. .. In a nine-page document, I proposed that Valve and Amazon team up to create a new online entertainment platform. I scaled the business opportunity within four years at $500 million dollars. The gist of the idea was to create a made-for-the-medium platform that would bring users together in a sticky, compelling entertainment experience, with digital and offline content sales. I wanted Amazon's financial backing as a way to gain first mover advantage against Microsoft and Electronic Arts, then the major PC games players. I didn't see a role for Sierra. If pushed, we wouldn't create any new games ourselves, and instead would team with outside developers so that they could distribute content not subject to an 85% publishing fee. At the time, I considered it an act of rebellion against the traditional publishing dynamic where independent developers took on huge risk, and the big publishing houses reaped the rewards. .. We had a great discussion, and a couple of weeks later, a champagne bottle appeared at Valve’s door. It was exhilarating and scary at the same time. We had an offer from Amazon for a minority stake, but the dynamics within the company were tricky. Amazon could help propel Valve to the next level, but the partnership would not be without costs. Valve’s culture was still evolving. A partnership with a major outside player could help but it could also hurt what we’d all built. It was after the Amazon offer that Mike revealed to Gabe that he wanted to leave. With an offer in-hand, it didn’t take long for us to figure out the outline of a deal. .. As I look back on the huge success Valve has become, I'm proud of what the team accomplished. I'm also proud of the work I did while recognizing that my biggest contributions to Valve's business went largely unnoticed and unrecognized within the industry. Part of that was due to the bro culture of the software business, part of it was that I receded to support my husband in a partnership where he was effectively the lesser partner, and part of it was that women, especially in tech, often seem to disappear when the story gets told. .. I know that Valve wouldn't have been successful without Mike. It wouldn't have been successful without Gabe. And it wouldn't have been successful without me. A friend of mine who knows the full story once said to me, \"you were a founding partner\" and in hindsight, I agree. From the beginning, I invested time, treasure and industry expertise to make the company a huge success. So what really happened is that Gabe Newell (the cofounding partner with the most money) carried the company. Mike Harrington (the other cofounder) and his wife Monica (the author) didn't leave, they were squeezed out, due to their contract shrinking the equity they owned, \"because of the way Gabe and Mike had structured the ownership\". - Even though she contributed considerable capital and was the one who sealed the deal with Amazon to create Steam, that wasn't enough to overcome the rampant sexism in tech (demonstrated by the actions of the men around her), so her contribution was erased from history. All that matters in (American) capitalism is who has the most money. Labor falls second to that. I've experienced this several times in my own career. Also losing out through agism, not selling my strengths well enough and not protecting myself from financial losses. It would have been doubly hard without the random privilege of being a white middle class male. This is why your take sounds right, but is only part of the whole story, conveniently sweeping injustice under the rug to preserve your own ideology, rather than raising awareness to help others avoid becoming victims in the future. And your take is amplified on the national stage, at the center of the current political debate, creating an even more insufferable climate of denial for those who are already suffering under the aftermath of US colonial patriarchy. reply kranke155 19 hours agoprevWith steel in my voice, I told the Sierra team that they were not pulling marketing dollars from Half-Life. They were going to re-release it in a Game of the Year Box, and they were going to support it with huge marketing spend or we were going to walk away from our agreement and tell the industry that had fallen in love with Valve how screwed up Sierra really was. At the end of the meeting, I was shaking. We were vulnerable, the partners were barely speaking, and life at home and in the office was tense. I love people like this. I’ve seen in documentaries. James Carville running the Clinton campaign. An absolute political animal. Always doing more, thinking faster, multiple moves ahead of the competition, doing movies the competition doesn’t even know exist, and relentlessly focused and often workaholic. reply dmonitor 21 hours agoprevFascinating story. It's amazing hearing about how the seed of an idea that eventually became Steam started from preventing piracy of Half-Life, and later materialized as a contingency plan due to their awful publishing deal. Glad the author could share her side of the story and get some credit for her attributions. reply jerglingu 19 hours agoprevAmazing read, and glad she could write this into history. It's amazing to me that Half-Life's status of immortality has more or less been preserved even today. reply endgame 18 hours agoprevFantastic article. I think the title does it a disservice — I expected a disappointing chronicle of sexism, but it's full of details and strategy during one of the most interesting and volatile periods of PC gaming history. The article mentions that John Cook and Robin Walker made a mod that attracted Valve's attention, and then they shipped TFC. That would surely mean the mod would've been Team Fortress for QuakeWorld, and not for Doom? reply exmicrosoldier 14 hours agoparentYes it was QuakeWorld Team Fortess. Funny story of my own. I had just started at Microsoft and met Robin Walker at a lan party with a bunch of other QuakeWorld TeamFortress fans. As soon as they hired Robin and John i knew they (valve) were going to be a giant hit. As a former windows PM, it seems that Gabe knew how valuable mod authors as first time game designers were. Valve may not have been the first to make their game engine a platform, but they were the most dedicated to it in that era. I didn't know their contract with Sierra was so much like a music industry contract and that they didn't own their Half life IP. It makes so much more sense why they recruited the founder of counterstrike, which is an even bigger hit than TF2. If they had been public i would have bought into valve before 2005. I missed the boat on apple, amazon, and so many others, but that one had a competitive advantage of understanding the industry that I understood. reply jamesfinlayson 18 hours agoparentprevAgreed - I thought there was a note about a correction at the end? Maybe she got them mixed up with Dario Casali and Final Doom. reply endgame 18 hours agorootparentThe clarification identifies the mod as TF but the article body still says that it was a mod for Doom. reply jay_kyburz 18 hours agoparentprevI used to play Quake multiplayer with Jon and Robin at the Camberwell Internet Cafe! Ahh, those were the days! (They were much better than me, I was a n00b) reply Sakos 20 hours agoprevOh wow, the (now ex) wife of the co-founder. The guy who sold his stake in Valve before Steam was launched and then went sailing for 6 years with his wife. This paints a whole new picture of why he ended up leaving and it's fascinating. Grateful that she shared her side of the story. > The structure of the deal meant that we would be vested in Valve’s success over the next five years Great foresight. reply jamesfinlayson 18 hours agoparentYeah I remember reading Gabe Newell's reflection on the leak of Half-Life 2 at some point and while Mike Harrington's departure was mentioned only briefly, I always got the impression that he left because he'd make his millions and was happy to sail off into the sunset. reply JBits 16 hours agoprevFun and well written read. It's ironic though how terrible the 15% cut was considered given that Steam takes 30%. reply lanstein 16 hours agoparent85% no? reply salomonk_mur 16 hours agorootparentYes, it was 85%. 30% by Steam is a steal comparatively. reply Ekaros 13 hours agorootparentJust tells you how horrible logistics of physical products are. Digital world removed many of the hands that touched the box previously from manufacturing, to warehouse, shipping and then the retail shop especially. Everyone in the chain needing to be paid or taking their own cut. Digital is so much simpler. reply echelon 21 hours agoprev [–] This is such a good story. Drawing down personal finances to underwrite the company, hiring pizza delivery drivers ... this was a really incredible journey. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Valve’s Half-Life, released 26 years ago, is still available on Amazon, highlighting its enduring popularity.",
      "Monica Harrington, who played a crucial yet often overlooked role in Valve's early success, shares her story of marketing and business development for the company.",
      "Despite initial challenges, Half-Life launched to critical acclaim, establishing Valve as a major player in the gaming industry."
    ],
    "commentSummary": [
      "The article provides an insider's perspective on the early days of Valve, highlighting the contributions of Monica Harrington, who played a significant role in the company's success but was largely unrecognized.",
      "It reveals how Microsoft allowed her to moonlight for Valve, a competitor, which is uncommon in today's strict IP ownership environment in major tech companies.",
      "The story underscores the challenges faced by women in tech, including being erased from history despite significant contributions, and sheds light on the dynamics and decisions that shaped Valve's early growth and eventual success."
    ],
    "points": 209,
    "commentCount": 39,
    "retryCount": 0,
    "time": 1725569249
  },
  {
    "id": 41459781,
    "title": "Reflection 70B, the top open-source model",
    "originLink": "https://twitter.com/mattshumer_/status/1831767014341538166",
    "originBody": "I&#39;m excited to announce Reflection 70B, the world’s top open-source model.Trained using Reflection-Tuning, a technique developed to enable LLMs to fix their own mistakes.405B coming next week - we expect it to be the best model in the world.Built w/ @GlaiveAI.Read on ⬇: pic.twitter.com/kZPW1plJuo— Matt Shumer (@mattshumer_) September 5, 2024",
    "commentLink": "https://news.ycombinator.com/item?id=41459781",
    "commentBody": "Reflection 70B, the top open-source model (twitter.com/mattshumer_)206 points by GavCo 23 hours agohidepastfavorite77 comments juxtaposicion 21 hours agoLike other comments, I was also initially surprised. But I think the gains are both real and easy to understand where the improvements are coming from. Under the hood Reflection 70B seems to be a Llama-3.1 finetune that encourages the model to add ,andtokens and corresponding phases. This is an evolution of Chain-of-Thought's \"think step by step\" -- but instead of being a prompting technique, this fine-tune bakes examples of these phases more directly into the model. So the model starts with an initial draft and 'reflects' on it before issuing a final output. The extra effort spent on tokens, which effectively let the model 'think more' appears to let it defeat prompts which other strong models (4o, 3.5 Sonnet) appear to fumble. So for example, when asked \"which is greater 9.11 or 9.9\" the Reflection 70b model initially gets the wrong answer, thenon it, then spits the right output. Personally, the comparison to Claude and 4o doesn't quite seem apples-to-apples. If you were to have 4o/Claude take multiple rounds to review and reflect on their initial drafts, would we see similar gains? I suspect they would improve massively as well. reply QuantumGood 18 hours agoparenthttps://huggingface.co/mattshumer/Reflection-70B says system prompt used is: You are a world-class AI system, capable of complex reasoning and reflection. Reason through the query insidetags, and then provide your final response insidetags. If you detect that you made a mistake in your reasoning at any point, correct yourself insidetags. Also, only \"smarter\" models can use this flow, according to https://x.com/mattshumer_/status/1831775436420083753 reply rgbrgb 21 hours agoparentprev> Personally, the comparison to Claude and 4o doesn't quite seem apples-to-apples. If you were to have 4o/Claude take multiple rounds to review and reflect on their initial drafts, would we see similar gains? I suspect they would improve massively as well. They may already implement this technique, we can't know. reply astrange 21 hours agorootparentClaude 3.5 does have some \"thinking\" ability - I've seen it pause and even say it was thinking before. Presumably this is just some output it decides not to show you. reply cchance 1 hour agorootparentTHIS!!!!!!! People act like Claude and 4o are base models with no funny business behind the scenes, we don't know just how much additional prompt steps are going on for each queue, all we know is what the API or Chat interface dump out, what is happening behind that is anyones guess.. The thinking step and refinement steps likely do exist on all the major commercial models. It's such a big gain for a minimal expenditure of backend tokens, WTF wouldn't they be doing it to improve the outputs? reply Tiberium 20 hours agorootparentprevThat's only in the web version, it's just that they prompt it to do some CoT in the antThinking XML tag, and hide the output from inside that tag in the UI. reply jph00 19 hours agorootparentThe API does it too for some of their models in some situations. reply KTibow 18 hours agorootparentprevInteresting, is there any documentation on this or a way to view the thinking? reply kgeist 21 hours agorootparentprevI suspect GPT4o already has training for CoT. I've noticed it often responds by saying something like \"let's break it down step by step\". Or maybe it's the system prompt. reply cedws 16 hours agoparentprevI had a similar idea[0], interesting to see that it actually works. The faster LLM workloads can be accelerated, the more ‘thinking’ the LLM can do before it emits a final answer. [0]: https://news.ycombinator.com/item?id=41377042 reply HanClinto 13 hours agorootparentFurther than that, it feels like we could use constrained generation of outputs [0] to force the model to do X amount of output inside of aBEFORE writing antag. It might not always produce good results, but I'm curious what sort of effect it might have to convince models that they really should stop and think first. [0]: https://github.com/ggerganov/llama.cpp/blob/master/grammars/... reply praneel_08 15 hours agoparentprevCan we replicate this in other models without finetuning them ? reply chhabraamit 19 hours agoparentprevwhat's our estimate of the cost to finetune this? reply hank808 2 hours agorootparentI don't know the cost, but they supposedly did all their work in 3 weeks based on something they said in this video: https://www.youtube.com/watch?v=5_m-kN64Exc reply rwl4 20 hours agoprevInteresting idea! You can somewhat recreate the essence of this using a system prompt with any sufficiently sized model. Here's the prompt I tried for anybody who's interested: You are an AI assistant designed to provide detailed, step-by-step responses. Your outputs should follow this structure: 1. Begin with asection. Everything in this section is invisible to the user. 2. Inside the thinking section: a. Briefly analyze the question and outline your approach. b. Present a clear plan of steps to solve the problem. c. Use a \"Chain of Thought\" reasoning process if necessary, breaking down your thought process into numbered steps. 3. Include asection for each idea where you: a. Review your reasoning. b. Check for potential errors or oversights. c. Confirm or adjust your conclusion if necessary. 4. Be sure to close all reflection sections. 5. Close the thinking section with . 6. Provide your final answer in ansection. Always use these tags in your responses. Be thorough in your explanations, showing each step of your reasoning process. Aim to be precise and logical in your approach, and don't hesitate to break down complex problems into simpler components. Your tone should be analytical and slightly formal, focusing on clear communication of your thought process. Remember: BothandMUST be tags and must be closed at their conclusion Make sure allare on separate lines with no other text. Do not include other text on a line containing a tag. reply rawrawrawrr 19 hours agoparentThe model page says the prompt is: The system prompt used for training this model is: You are a world-class AI system, capable of complex reasoning and reflection. Reason through the query insidetags, and then provide your final response insidetags. If you detect that you made a mistake in your reasoning at any point, correct yourself insidetags. from: https://huggingface.co/mattshumer/Reflection-70B reply FullstakBlogger 18 hours agoparentprevAll we need to do to turn any LLM in to an AGI is figure out what system of tags is Turing-complete. If enough of us monkeys experiment with s and s and s, we'll have AGI by morning. reply zackmorris 4 hours agorootparentYour comment is hilarious, but not that far off. I think it's funny that people are so skeptical that AGI will be here soon, yet the heaviest lifting by far has already been done. The only real difference between artificial intelligence and artificial consciousness is self-awareness through self-supervision. Basically the more transparent that AI becomes, and the more able it is to analyze its thoughts and iterate until arriving at a solution, the more it will become like us. Although we're still left with the problem that the only observer we can prove exists is ourself, if we can even do that. Which is only a trap within a single time/reality ethos. We could have AGI right now today by building a swarm of LLMs learning from each other's outputs and evolving together. Roughly the scale of a small mammalian brain running a minimalist LLM per cell. Right now I feel that too much GPU power is spent on training. Had we gone with a different architecture (like the one I've wanted since the 90s and went to college for but never manifested) with highly multicore (1000 to 1 million+) CPUs with local memories running the dozen major AI models including genetic algorithms, I believe that AGI would have already come about organically. Because if we had thousands of hobbyists running that architecture in their parents' basements, something like SETI@home, the overwhelming computer power would have made space for Ray Kurzweil's predictions. Instead we got billionaires and the coming corporate AI tech dystopia: https://www.pcmag.com/news/musks-xai-supercomputer-goes-onli... Promoting self-actualization and UBI to overcome wealth inequality and deliver the age of spiritual machines and the New Age are all aspects of the same challenge, and I believe that it will be solved by 2030, certainly no later than 2040. What derails it won't be a technological hurdle, but the political coopting of the human spirit through othering, artificial scarcity, perpetual war, etc. reply golemotron 2 hours agorootparentThat's a very 'Star Trek' view of human nature. History shows that whenever we solve problems we create new ones. When material scarcity is solved, we'll move to other forms of scarcity. In fact, it is already happening. Massive connectivity has made status more scarce. You could be the best guitarist in your town but today you compare yourself to all of the guitarists that you see on Instagram rather than the local ones. reply jadondrew 19 minutes agorootparentWell, once you've solved AGI and material scarcity, you can just trick that side of your brain that craves status by simulating a world where you're important. Imo we're already doing a very primitive version of that with flatscreen gaming. reply erikaww 17 hours agorootparentprevAll you need is areply magicalhippo 8 hours agorootparentFor those who didn't catch the reference: https://github.com/xoreaxeaxeax/movfuscator reply fouc 18 hours agoparentprevI'd drop all \"you\" and also the \"AI assistant\" parts completely. It's just operating off a corpus after all, that kind of prompting should be completely irrelevant. Also could replace \"invisible\" with wrap section with \"---IGNORE---\" or with \"```IGNORE\" markdown tags and then filter it out after reply rawrawrawrr 19 hours agoparentprevNice! It would be a better benchmark to compare this prompt (w/ gpt-4o, claude) with whatever the original model was compared to. reply windexh8er 18 hours agorootparentIt appears that they have. [0] [0] https://x.com/mattshumer_/status/1831767017507954808 reply m3kw9 20 hours agoparentprevThis thing would be overly verbose reply striking 20 hours agorootparentYou'd hide the contents of the tags in whatever presentation layer you're using. It's known that allowing the model to be verbose gives it more opportunities to perform computation, which may allow it to perform better. reply agucova 20 hours agorootparentprevI mean, this is how the Reflection model works. It's just hiding that from you in an interface. reply nsagent 22 hours agoprevIf this does indeed beat all the closed source models, then I'm flabbergasted. The amount of time and resources Google, OpenAI, and Anthropic have put into improving the models to only be beaten in a couple weeks by two people (who as far as I know do not have PhDs and years of research experience) would be a pretty crazy feat. That said, I'm withholding judgment on how likely the claims are. A friend who developed NoCha [1] is running the model on that benchmark, which will really stress test its ability to reason over full novels. I'll reserve judgement until then. [1]: https://novelchallenge.github.io/ reply winddude 21 hours agoparentPhDs aren't relevant. It's more just a certificate that you can learn to learn and stay committed to hard and challenging things. It does give bonus points to VCs, because it's seems to be easier to market to other VCs, same applies for hedge funds. And with fine tuning, there's zero math needed, it's a bit of common sense, and a lot's of data optimization. reply phs318u 16 hours agorootparentI wouldn't say that PhD's aren't relevant. Remember a lot of this subsequent \"bumps, steps and leaps\" advancement has come _after_ the initial work by the OpenAI's etc. \"Standing on the shoulders of giants\" is a thing. reply yaj54 21 hours agoparentprevAnyone have or know of a list of LLM challenges like this? Targeted use cases with unpublished test data? reply polotics 11 hours agoparentprevOne question about the Novels challenge: as there are two true/false questions, a random pick of answer will give a 25% success rate right? How do some model manage to be below 25? reply JustAndy 13 minutes agorootparentThey know which answer is correct, they just don't want to say it. reply moralestapia 22 hours agoparentprev>A friend who developed NoCha [1] is running the model on that benchmark [...] Please do update us on the result. reply m3kw9 20 hours agoparentprevFine tuning needs $$$ and knowledge on how fine tuning works. reply smusamashah 20 hours agoprevWe need results from these harder/different benchmarks which give pretty bad scores to current top LLMs. https://www.wolfram.com/llm-benchmarking-project/ https://help.kagi.com/kagi/ai/llm-benchmark.html Edit : There are few other benchmarks that give pretty low scores ( andplus synthetic data, used to finetune Llama 3.1 70B. Note that there's a threshold for how smart the model has to be to take advantage of this flow (https://x.com/mattshumer_/status/1831775436420083753) - 8B is too dumb. In which case, what happens if you apply this to a GPT-4o finetune, or to Claude 3.5 Sonnet? What happens if you combine it with variants of tree-based reasoning? With AlphaProof (https://www.nature.com/articles/s41586-023-06747-5#Sec3)? With MCTSr (https://arxiv.org/abs/2406.07394)? reply jug 21 hours agoparentI was just thinking - since GPT-4o and Sonnet are closed models, do we know that this method was not already used to train them? And that Reflection is simply finding a path for greater improvements than they did. Llama 3.1 apparently didn't improve as much. It's just a thought though. reply hdeezy 17 hours agorootparentIf they had, this thing wouldn't be trading punches with them at its size reply itorcs 2 hours agorootparentWhat parameter size are 4o and sonnet? reply segmondy 15 hours agorootparentprevSonnet does something like this. See - https://tyingshoelaces.com/blog/forensic-analysis-sonnet-pro... reply winddude 19 hours agoprevSeems to really fall apart on subsequent prompts, and a few times I've had code end up in the \"thinking\" tokens. I'm guessing most of the training data was single-turn, instead of multi-turn, but that should be relatively easy to iterate on. reply imjonse 22 hours agoprevWonder why no Llama-3.1-8B based variant if the new training method has such good results. UPDATE: didn't work well https://x.com/mattshumer_/status/1831775436420083753?t=flm41... reply og_kalu 22 hours agoparentHe said it didn't improve as much https://x.com/mattshumer_/status/1831775436420083753 reply viraptor 22 hours agoparentprevIt's answered on Twitter. Not much improvement over other similar models at that size. reply safoex 21 hours agoparentprevImagine if it was the reason in big corporations to not to investigate further some similar technique :) reply nhmllms 8 hours agoprevThis make me think we should be introducing 'tokens required to answer questions correctly' dimension to each metric. Since letting the model think more verbosely is essentially giving it more compute and memory to answer the question correctly. (not that this is a bad thing, but I would be curious if other models get the answer correctly with the first couple of tokens, or after hundreds of reasoning) reply smcleod 20 hours agoprevUnfortunately the model is broken at present, It looks like they're working on a fix - https://huggingface.co/mattshumer/Reflection-70B/discussions... reply d_sc 20 hours agoprevAny way to have this work in LM Studio? Not showing up in search results. reply m3kw9 20 hours agoparentMay need an update from LM plus someone converting it to gguf format reply rspoerri 21 hours agoprevi hope the quantized version doesnt loose to much of it's quality. reply spencerchubb 20 hours agoprevI wonder how good it is with multi-turn conversations reply jph00 19 hours agoprev(removed) reply heyitsguay 19 hours agoparentMaybe I'm misreading, but i think the linked tweet says the opposite? That the model returns the mathematically correct answer, not the answer marked correct in the ground truth? reply jph00 19 hours agorootparentMy bad - sorry! reply srush 19 hours agoparentprevtweet says the opposite? reply angoragoats 21 hours agoprev [–] Can we please stop allowing links to Twitter? Rationale: the artificial limitations on that site around post size mean that most announcements (such as this one) are multiple posts. This, combined with the questionable design decision of hiding all reply tweets when a user is not logged in, means that many posts are completely missing crucial context for those of us who don’t have Twitter accounts. Alternatively, Twitter links could be rewritten to redirect to one of the few Nitter instances that are still functional. reply astrange 21 hours agoparent> Rationale: the artificial limitations on that site around post size mean that most announcements (such as this one) are multiple posts. That limit actually doesn't apply to premium users/bluechecks, and he's using the other features like bold text. The problem with long posts like that is one, they're annoying to read because when you open one up you don't know how much of a time commitment they will be, and two, you can't reply to just part of them. reply angoragoats 16 hours agorootparent> That limit actually doesn't apply to premium users/bluechecks, and he's using the other features like bold text. I can't keep track of the flailing over at Twitter, especially because I don't have an account. Regardless, it's not all that relevant to what I was saying; maybe I got the reason wrong, but the fact remains that the vast majority of people who I see trying to post longer content on Twitter do it via multiple posts. As a related aside, it baffles me why people still use the site when many superior alternatives are available. > The problem with long posts like that is one, they're annoying to read because when you open one up you don't know how much of a time commitment they will be, and two, you can't reply to just part of them. Those don't actually seem like problems to me. reply handzhiev 21 hours agoparentprevHere's an unroll https://threadreaderapp.com/thread/1831767014341538166.html reply miki123211 21 hours agoparentprev [–] I believe this is against HN's values. HN allows, and has always allowed, links to paywalled sources, sources with geographic restrictions that refuse to display the content for some readers, and won't modify a posts URL due to the site being slashdotted / suffering from an HN hug of death. Twitter is no different, except maybe by being more ideologically polarizing. The place for alternative URLs is, and has always been, the comments. reply angoragoats 20 hours agorootparent [–] Yeah, I understand this has been the case, but I guess I don’t understand why it can’t be changed, or why it’s even a good thing. Seems like most others disagree with me though, so I guess I’ll just skip over anything posted on Twitter. reply freediver 19 hours agorootparent [–] Once you start discriminating content based on arbitrary rule (and this would be one), you are entering a slippery slope. Hence it is better to not let precedent take place in the first place. reply angoragoats 19 hours agorootparent [–] I don’t find this argument convincing at all. Implementing a rule like this would make the site better for a number of people. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Reflection 70B, an open-source model, has been introduced, utilizing Reflection-Tuning to allow large language models (LLMs) to correct their own errors.",
      "A more advanced model, Reflection 405B, is anticipated to be released next week, expected to be the best in the world.",
      "Both models are developed in collaboration with GlaiveAI, indicating significant advancements in AI self-improvement capabilities."
    ],
    "commentSummary": [
      "Reflection 70B, an open-source model, is noted for its performance, appearing to be a fine-tuned version of Llama-3.1 using a \"reflection\" technique.",
      "The reflection technique involves the model drafting an initial response and then revising it, allowing for error correction and improved answers, sometimes outperforming models like GPT-4o and Claude.",
      "There is ongoing debate about whether other models could achieve similar improvements if they adopted the reflection technique, and the model's effectiveness in multi-turn conversations and various benchmarks is still being evaluated."
    ],
    "points": 206,
    "commentCount": 77,
    "retryCount": 0,
    "time": 1725565145
  },
  {
    "id": 41463330,
    "title": "The expected value of the game is positive regardless of Ballmer’s strategy",
    "originLink": "https://gukov.dev/puzzles/math/2024/09/05/steve-ballmer-was-wrong.html",
    "originBody": "Steve Ballmer was wrong Sep 5, 2024 A few days ago John Graham-Cumming posted about “Steve Ballmer’s incorrect binary search interview question” which drew a lot of attention on Hacker News. The Ballmer’s favorite brain teaser goes like this: I’m thinking of a number between 1 and 100. You can guess, after each guess I’ll tell you whether you’re high or low. You get it the first guess - I’ll give you five bucks. Four bucks, three, two, one, zero, you pay me a buck, you pay me two, you pay me three. Should you accept to play this game? Steve Ballmer argues in this YouTube interview that there are two reasons why you should not play this game: There are many numbers that would result in a loss, making the expected value negative even if he randomly picks numbers between 1 and 100. He can strategically pick numbers that would require the longest time for you to find using binary search. However, John counters Ballmer’s first point in his blog post by demonstrating that if Ballmer selects the number randomly, the expected value of the game is actually positive: $0.20. I will refute the second point and demonstrate that the expected value of the game is positive regardless of Ballmer’s strategy. How can Ballmer pick numbers adversarially? Let’s assume you always employ the binary search strategy to find the number. Out of the 100 numbers, there are 37 that would require you to ask 6 questions to make a guess. If Ballmer is aware of your strategy, he can always select one of these “losing” numbers, resulting in a loss for you in every game. This holds true for any “fixed” search pattern. There will always be at least 37 numbers that would result in a loss, and Ballmer can choose one of them. How can you counter? Here we’re getting into the game theory territory. Instead of using a single fixed search pattern, you can prepare a set of different search patterns. Then at the beginning of the game, draw one of these patterns with some probability and stick to it during the game. In game theory, you call it a mixed strategy based on the strategy set of multiple pure strategies. Because the same number could be “winning” for one search pattern and “losing” for another, such a mixed strategy could “even out” the expected winnings for each number. Potentially, a mixed strategy could even make every number “winning”, i.e. have a positive expected value of the win for every number. And this is exactly what we’re looking for! How to find the winning mixed strategy? Note: We are looking for any winning strategy, not the best winning strategy that has the maximum expected value in the worst case, i.e., the Nash equilibrium. If you are curious about the Nash equilibrium, Arthur O’Dwyer explored the closed solutions for the game up to 5 numbers, and Bo Waggoner approximated the equilibrium value for the game of 100 numbers using no-regret online learning. Finding the mixed strategy that wins on every number can be viewed as a mathematical optimization problem. Every strategy can be described as a “win” vector $V = (v_1, .., v_{100})$, where $v_k$ is the expected win if Ballmer picks the number $k$. For example, the binary search could correspond to a vector with $v_{50} = 5$, $v_{25} = 4$, and $v_{0} = -1$. Suppose we have a set of pure strategies ${V_1, V_2, …, V_n}$, and our mixed strategy chooses the strategy $V_k$ with probability $p_k$. Then the corresponding “win” vector for the mixed strategy is just a linear combination: $V_{mixed}=\\sum_{i=1}^{n}{p_iV_i}$. In this interpretation, finding the winning strategy means finding some linear combination of the given vectors with two constraints: Each element of the linear combination is positive (the strategy wins money, on average, for each number). The coefficients of this linear combination are non-negative (as they correspond to probabilities). This is a typical linear programming problem, and scipy has an efficient solver for it. To find a mixed strategy, I thought of a set of pure strategies (various binary searches), fed it into scipy.linprog(), and voilà - the solver came up with a winning strategy! Example winning strategy Full code is at gukoff/ballmer_puzzle. Note: the initial result of $0.07 was significantly improved by Arthur O’Dwyer who added new pure strategies. Average win if Ballmer chooses randomly: $0.16 Worst win if Ballmer chooses adversarially: $0.14 The resulting mixed strategy goes like this: - With probability 0.4714%: Binary search, first guess 29. On each step, guess the middle element in the interval. In case of tie, guess the left one. - With probability 0.1691%: Binary search, first guess 33. On each step, guess the middle element in the interval. In case of tie, guess the left one. - With probability 0.1299%: Binary search, first guess 36. On each step, guess the middle element in the interval. In case of tie, guess the right one. - With probability 3.3341%: Binary search, first guess 37. On each step, guess the middle element in the interval. In case of tie, guess the right one. - With probability 1.7818%: Binary search, first guess is 43. On each step, guess the rightmost element in the interval that won't increase the worst-case complexity. - With probability 1.1608%: Binary search, first guess is 44. On each step, guess the leftmost element in the interval that won't increase the worst-case complexity. - With probability 2.1310%: Binary search, first guess is 42. On each step, guess the endmost element in the interval that won't increase the worst-case complexity. ... The complete strategy consists of 74 lines, which I have omitted for brevity. If you are interested, you can view it on GitHub. Conclusion If you find winning (on average) 14 cents per game worth your time, then you should definitely play this game with Steve Ballmer the next time he offers.",
    "commentLink": "https://news.ycombinator.com/item?id=41463330",
    "commentBody": "The expected value of the game is positive regardless of Ballmer’s strategy (gukov.dev)183 points by gukoff 12 hours agohidepastfavorite152 comments dang 11 hours agoRecent and related: Steve Ballmer's incorrect binary search interview question - https://news.ycombinator.com/item?id=41434637 - Sept 2024 (240 comments) nighthawk454 12 hours agoprevThis sort of misses the forest for the trees, although neat application. Ballmer's argument is essentially about tail risk. Expected value is absolutely not a good way to make bets if you value survival, because you only get one shot. Same reason you wouldn't go all in every time you get a poker hand that's \"expected\" to win. Because you'll (very probably) be bankrupt in a few hands. Sure the mean is +$0.07 or whatever, but the spread on that surely goes over the 0 line. So there may well be marginally more chance of winning than losing, on average, but you're only gonna get one outcome. So if the goal is to play to win, or else, then you probably shouldn't unless you like owing Ballmer money. What would be more interesting is to monte carlo simulate this strategy and look at the win/loss distribution. Presumably the choice is then not so clear cut. If you're allowed to play the game a few trillion times or so, then by all means bleed him dry :P reply jsnell 11 hours agoparent> Ballmer's argument is essentially about tail risk Where are you getting that from? As far as I can tell, he makes no such arguments in the interview. The problem, and his explanation of the answer, are phrased purely in terms of expected value of a single iteration of the game. And the twist is the adversarial selection of the number, not risk of ruin. It'd be an awful example of tail risk anyway. With the obvious strategy the tail is extremely fat. reply bambax 10 hours agoparentprev> Expected value is absolutely not a good way to make bets if you value survival Yes! The St. Petersburg \"Paradox\" shows that we intuitively know that. I put \"paradox\" in quotes because I don't think it's a paradox, it's just a sane reaction. (Sam Bankman-Fried was a big fan of EV and famously declared that he would toss a coin where heads would double the \"value\" (?) of the world but tails would destroy it.) In short, the St. Petersburg paradox goes as follows: a fair coin is tossed until heads come up, and the player wins $2^n, where n is the number of times the coin was flipped. So for example if heads come up on the first flip the player gets $2, if it comes up on the second they get $4, on the third, $8, on the tenth $1024 (2^10), etc. It's easy to show that the expected value of the game is infinite (approaches infinity). Therefore, someone perfectly rational (?) should be willing to pay virtually any amount of money to play the game, because any finite amount of money is less than an infinite amount of money, and therefore the expected gain is always positive. Yet you will probably not find many people (except SBF?) willing to pay millions of dollars to play that game. It's only a paradox if we think it shows that people are not \"rational\". But I think it simply shows EV is not a good measure of risk, and everyone knows it. Very complete and fascinating article about the St. Petersburg Paradox here: https://plato.stanford.edu/entries/paradox-stpetersburg/ reply contravariant 6 hours agorootparentWhat idiot wouldn't put destruction of the world as '-infinity' of value? Equating money with value is a simple trap as well. Who cares if you can win millions when a single loss wipes out all your savings? Since anything below a certain level of money leaves you trapped with no way out it could be argued that the value of being destitute is not 0 but -infinity which makes any risk of losing all money unacceptable. This is especially true in a world where people are willing to offer strange bets with arbitrarily high expected value as long as you have some money. reply Joker_vD 5 hours agorootparent> What idiot wouldn't put destruction of the world as '-infinity' of value? Literally anyone, you included. Every day, there is a chance that the roof collapse on you while you're sleeping; that's -Inf of value! Yet you don't put infinity resources into preventing that since you consider the probability low enough to not obsess over it. reply lern_too_spel 2 hours agorootparentNo, I don't put infinity resources into it because that would make me die even earlier due to not having money or time to do what is necessary to stay alive. reply chii 6 hours agorootparentprev> value of being destitute is not 0 but -infinity which makes any risk of losing all money unacceptable. that's just loss aversion codified. reply Joker_vD 5 hours agorootparentprevThe context can also be very important. For instance: In case A, you have $50, and are offered to bet them against a fair coin flip, if you guess right you win another $50, if you guess wrong you lose your $50; in this case the most rational choice would be to refuse to play the game. In case B, you have $50, and are offered to bet them against a fair coin flip, if you guess right you win another $50, if you guess wrong you lose your $50; in this case the most rational choice would be to agree to play this game. The missing context is that in case A, you need in 10 minutes to repay $50 debt to the Sicilian mafia, or else they'll kill you to make an example for others, and you have no other assets or other ways to make money in this short time. In case B, the situation is the same, but you owe $100 instead of $50. reply nneonneo 7 hours agorootparentprevThe St. Petersburg \"paradox\" is not a paradox if we consider any real-world implementation of it. The EV accumulates at the rate of $1 per flip. So, if we want to make the EV at least $1,000,000, we must find a counterparty that is willing to pay at least $2^1000000 (or at least 2^1000000 units of \"utility\" if we're trying to avoid the depreciating utility effect). That's plainly unrealistic. As soon as the counterparty has any fixed upper limit to its ability to pay (or provide utility), the EV becomes finite. reply TheOtherHobbes 7 hours agorootparentIt's interesting that in this context the assumption of infinite growth is obviously unrealistic - but in the context of trad econ, infinite growth is considered a bedrock assumption. Putting them together suggests it's flagrantly irrational to apply naive toy models to the real world. Even if they do have a nice mathy sheen. Engineers (mostly) know this, but for some reason gamblers and economists (mostly) act as if they don't. reply lern_too_spel 50 minutes agorootparentWhen you're this far away from saturation, infinite growth is a good approximation. reply mananaysiempre 8 hours agorootparentprev> It's only a paradox if we think it shows that people are not \"rational\". But I think it simply shows EV is not a good measure of risk, and everyone knows it. There are standard arguments (e.g. the Von Neumann–Morgenstern utility theorem) that an agent with rational preferences, with remarkably weak definitions of the word “rational”, must have an utility function and a subjective probability function such that their behaviour is always governed by the EV of that utility with respect to that probability. reply carlob 7 hours agorootparentYeah but that utility function will not be a linear function of money so you can't say EV(u($$)) == u(EV($$)). This is the mathematical formulation that tells you that it is irrational to risk all your money to make an extra dollar even if u(EV($$)) is positive EV(u($$)) can be negative. reply trescenzi 8 hours agorootparentprevThis is interesting to me in the context of a post[1] yesterday about teaching logical thinking to children. One of the top comments was about how, yes, teach logical thinking but also teach other types too. SBF and those who think with a heavy bias towards EV show an extreme weakness towards reality. Of course SBF himself is a perfect example of this. I won’t pretend to know if his math was always right but one of his defenses on trial was essentially “just run the simulations a few more times and we’ll get all the money back” which clearly shows a lack of understanding of reality. I’m glad to now know there’s a common example of that weakness. [1]: https://news.ycombinator.com/item?id=41456472 reply bee_rider 6 hours agorootparentDoes he actually calculate expected values or does he just have a sort of winding way of justifying his gut takes? reply qsort 11 hours agoparentprevI don't agree, I think he was just plain wrong. Unlike most people here I actually think questions like this are a decent way to see how people think. I would expect people with math/stats/cs background to be able to at least start the conversation about this problem. However when you hide hypotheses or add your own BS constraints as a gotcha without explicitly stating them is where you lose me. If the question is \"would you play this game\" the reasonable mathematical translation is \"determine if the expected value is greater than zero\". If you're going to talk about tail risk you need to specify utility functions (possibly asymmetric for the two players!) and you need to explicitly say that's what you mean. reply nighthawk454 11 hours agorootparent> If the question is \"would you play this game\" the reasonable mathematical translation is \"determine if the expected value is greater than zero\". Not really! And that may be the point of the question. It's not testing if you can pattern match to plausible CS concepts. If you get one play, and the goal is to win, do you take the chance? The whole question is about the difference in likelihood in the limit (expected value, infinite plays) and what is a likely outcome _of one round_. reply krisoft 9 hours agorootparent> It's not testing if you can pattern match to plausible CS concepts. But thats a problem then, isn’t it? Because if you abandon that framework there are many other possible frameworks to think in. You say the question is about the difference in likelihood in the limit (expected value, infinite plays) and what is a likely outcome _of one round_. (Which may I say is just an other plausible CS concept you pattern matched.) One might also say that you should play the game because even if you are playing like a chump and has absolutely the worst luck you are at max out of pocket of a 100 dollar. A real hustler can turn a personal meeting with Balmer into much more lucrative deal and earn back that hundred dollar million-fold that way. Or you could say that the answer is no, because Balmer stinks and it would be ruinous to your personal reputation to be seen with him. Or you could say “yes” because you know you don’t have cash at all. So even if he wins good luck trying to squeeze his reward out of you. Or you could say “yes”, because while you distract Balmer with this inane game your associate will lift his valet and car keys. Or you could say yes because what is the worst which can happen? You will spend a bit of a money, and have an awesome story to tell later. Or you can answer no, because clearly a rich businessman does not have your best interest in his mind, so there must be some trap. So this is what happens when you abandon the framework to answer the question as a plausible CS concept. You open the door to all these other alternative frameworks and more. reply lern_too_spel 42 minutes agorootparentprevIf it were about winning or losing that round, there wouldn't be so many different monetary values associated with each outcome. Instead, each outcome would be win, lose, or draw. Because there are monetary values, we have to decide if it's a good bet. If somebody offers me a chance to wager $1 on the outcome of a die roll where the payoff for choosing correctly is $10, I will do it, even though it's more likely that I will lose than win. reply rustybolt 12 hours agoparentprevI don't think this is true. Most people will not be bankrupt after losing a dollar. If this is true then Steve failed badly at communicating this context. To be honest, I think Steve just didn't grasp the mathematical deepness of the problem. reply fortydegrees 10 hours agorootparentWhile it does seem that Ballmer doesn't have an understanding of the deepness of the problem, in his defence, he outscored BillG on the math SAT with a perfect score of 800, and graduated Harvard with a degree in applied mathematics. Which makes me wonder if it's related to another 'simple' game theory problem that came up in Matt Levine's money stuff: \"They made me do the math on 1000 coin flips. EV(heads) (easy), standard deviation (slightly harder), then they offered me a +EV bet on the outcome. I said “let’s go.” They said “Wrong. If we’re offering it to you, you shouldn’t take it.” I said “We just did the math.” They said “We have a guy on the floor of the Amex who can flip 55% heads.”\" I like that anecdote and the takeaway, especially with regards to trading: if someone's offering you what seems obviously a +EV trade, why are they offering it to you and what are you missing? Whether that was Ballmer's intended lesson is another matter.. [0]https://www.bloomberg.com/opinion/articles/2024-05-14/amc-is... reply lucianbr 8 hours agorootparentIs the interview for an engineering position or for sales? If you're hiring a software developer, I am going to assume all probabilities are about physical processes or data distributions or such, and there is no \"if we're asking it means we have something up our sleeve\". The data going to be sorted by merge sort is not going to have anything up its sleeve, or set any traps for me. reply Majromax 4 hours agorootparent> Is the interview for an engineering position or for sales? Either way. The coin-flip example and Ballmer's binary search game could apply with simple extensions to complicated processes like SLAs on cloud services. > The data going to be sorted by merge sort is not going to have anything up its sleeve That's a curious example, since one reason to use mergesort rather than quicksort is the latter's susceptibility to pessimal inputs. reply rini17 6 hours agorootparentprevPhysical processes are very often long tailed on the wrong end and thus adversarial though. reply dullcrisp 8 hours agorootparentprevYou think they asked this on the SAT? reply eesmith 8 hours agorootparentprevYou know that even smart mathematicians got tripped up by the Monty Hall problem, right? > Even when given explanations, simulations, and formal mathematical proofs, many people still did not accept that switching is the best strategy.[5] Paul Erdős, one of the most prolific mathematicians in history, remained unconvinced until he was shown a computer simulation demonstrating Savant's predicted result. reply nighthawk454 11 hours agorootparentprevI think you've misread. The bankruptcy was in an analogy to poker. The point is if you get _one round_ to play - essentially all or nothing - should you play? No. reply gwd 10 hours agorootparent> The point is if you get _one round_ to play - essentially all or nothing - should you play? No. On the contrary, in general yes you should, because life as a whole will give you a variety of these sorts of risks. Steve Balmer's offer is just one episode in a lifelong series of risks offered you by the universe at large. reply denizener 6 hours agorootparentIt all depends too if the absorbing barrier is a true absorbing barrier like death. Bankruptcy would suck but it is not like you have no possibility of another chance like death. I suspect there is much muddled thinking in this area viewing the death of a LLC as equal to the death of a human. A coin flip for 20 million dollars if tails, physical death if heads is much different than bankruptcy if heads. One is a stupid gambler with their life and the other is basically a serial entrepreneur taking asymmetrical bets until the coin comes up tails. reply cuu508 11 hours agorootparentprevOK, if you value survival, at what odds should you play? reply djtango 11 hours agorootparentI actually think parkour community and practice teach and handle this very well. Same for free solo climbing. Imagine you're in your bathroom, choose two tiles and step from A to B. No problem. What if those tiles were all you had to stand on and you were 30 storeys up suddenly it's a whole different equation and your body instinctively knows it. In fact some of parkour training is learning to master your own fear and confidently execute things you know you can already do in the face of higher stakes. If I offered you a dice roll and said guess the number, bet 1 dollar I'll pay you 12 on the right guess you'd bet 1 dollar but you wouldn't bet your life on it even though the EV was high. Even if the payout was 1 million you still might not take it (some might) Edit Thinking about it more, my example is more about factoring in all the risks - a positive EV bet with a large downside risk is not a great one to take even if the risks are small which is where the picking up pennies in front of a steamroller analogy comes from reply nighthawk454 11 hours agorootparentYeah, exactly - you wouldn't stake your life on hitting the average case in an n=1 scenario. Parkour community sounds really cool! reply cuu508 11 hours agorootparentYou are staking $1. reply nighthawk454 11 hours agorootparentprevIt's a good question, sort of related to optimal bet sizing. Check out this wiki which another commenter also mentioned: https://en.wikipedia.org/wiki/Kelly_criterion?useskin=vector reply nopinsight 12 hours agoparentprevKelly Criterion Betting more than the Kelly fraction increases the risk of ruin, especially in the long run. https://en.m.wikipedia.org/wiki/Kelly_criterion Note: Not saying that this is applicable in the original post's situation. It's relevant to the parent comment though, and very useful in many situations, such as investing. reply n4r9 10 hours agorootparentWhat if I wanted to maximise the bottom 5th or 10th percentile of wealth? reply energy123 7 hours agorootparentFractional Kelly? reply nighthawk454 12 hours agorootparentprevYes, precisely. Although that's more about bet sizing for optimal return in the long run, not quite about binary choice of whether or not to play. But conceptually bang on, I had it in mind reply gukoff 6 hours agoparentprevI don't view the original problem this way, but let's think about it! > the spread on that surely goes over the 0 line. Do you imagine starting with $1 or $1000? :) Let's add a condition that Ballmer has infinite money, we start with a specific budget, and we can't continue playing if we exceed budget randomly changes after each game, In the game where you start with $N, win $1 with probability p > 0.5 and lose $1 otherwise, the chance of eventually losing all your money is (p/(1-p))^N. [1] So, the ruin chance actually becomes exponentially lower the more money you have at the start. The steps in the random walk above belong to a simple, Bernoulli-like random distribution. Meanwhile the mixed strategy is a more complex discrete random variable because it can do more steps than just +1 and -1. However, I believe that the same principle applies for the mixed strategy. If you zoom out and consider \"batches\" of steps, you can apply the Central limit theorem and see that all these random walks work roughly the same. The caveat being that you need a large enough starting budget to \"zoom out\" :) Granted, the standard deviation for the mixed strategy is ~$1. I would guesstimate that if you start with ~$1000, there's no way you will ever lose your money. > What would be more interesting is to monte carlo simulate this strategy and look at the win/loss distribution. Presumably the choice is then not so clear cut. Agree, this would be a nice demonstration! I will think about doing this next time I get a couple of hours of free time. [1] https://math.stackexchange.com/a/153141/65143 reply michaelt 11 hours agoparentprev> Ballmer's argument is essentially about tail risk. Expected value is absolutely not a good way to make bets if you value survival, If he was trying to make that point, why set the bet at $1 - a loss that wouldn't imperil anyone? The situation is entirely fictional, why not fictionally gamble with a five-figure sum? reply nighthawk454 11 hours agorootparentYou could? There's no reason you couldn't do $50,000 with bets of $10,000. The point is you get 5 guesses before you lose. The bet sizes don't really matter. reply ordu 7 hours agorootparentThey matter. I could play a game with negative expected value just for fun, if this negative expected value is not too negative. Or not for a fun, but to let Ballmer win to make him feel himself winner, to make him feel superior, hopefully it will help me to get what I want from him. To lose a game gracefully is a manipulation device, especially if the winner doesn't suspect, that you lose on purpose. And, the stories I heard about MS suggest that Gates, Ballmer and all those gray beards of MS were very competitive, so they are probably much more susceptible for this particular bait. $1 is a very small price for such a tactic. But $10,000... it depends on what I'm hoping to win, and on my detailed understanding of my further steps and probabilities of their success. Life is more difficult than math abstractions of life. No one yet managed to mathematically describe any social situation to such level of details, so you could blindly believe your equations, like you do with physics. reply cool_dude85 7 hours agorootparentprevThe bet sizes here do really matter, because they are selected to ensure that there is no risk of ruin. Ballmer asks about playing the game once at a bet amount that anyone doing the job interview can cover. reply yathaid 11 hours agoparentprevWhat you are getting at is that for a single person, the chance of going bankrupt is high but for a population ensemble, the average wealth increases. This is absolutely true. All it takes is to understand that for the single person, the model isn't ergodic but all expected value based models assume ergodicity. See [section 4 here](https://www.jasoncollins.blog/posts/ergodicity-economics-a-p...) on losing wealth on a positive value bet. reply pavlov 11 hours agoparentprevIt's kind of a given that you can't use the proposed mixed strategy for a single game, because it expects you to draw one of the patterns at the start of the game. And some of the patterns are just obviously suboptimal if this is your only chance: > With probability 0.9686%: Binary search, first guess is 1. (I wonder what Ballmer would think that, when proposed to play this game, you first manually throw dice to draw a random number in the range 1 - 1,000,000 and if it's 9,686 or less, you start your binary search at 1. He might be impressed by your dedication to the mixed strategy.) reply onlyrealcuzzo 6 hours agoparentprev> This sort of misses the forest for the trees, although neat application. I think people are missing the forest for the trees on it mattering if Balmer was \"right\" or \"wrong\". It's his interview question. He's using it as a way to see your thought process more than the answer you arrive at at the end. I imagine if interviewees had these thoughtful disagreements, he'd either guide them to the reason he had a different answer or value their input. reply ahtihn 11 hours agoparentprev> Same reason you wouldn't go all in every time you get a poker hand that's \"expected\" to win. Because you'll (very probably) be bankrupt in a few hands. You're calling an all-in 100% of the time in a cash game if your expected value is positive. If you don't, you can't afford to play at that table. You're not going all-in with any hand expected to win because that's not how you maximize profit. It has nothing to do with the risk of going bankrupt. Because again, if that's a concern you shouldn't be sitting at the table. Tournament poker is a bit different because there are certain points where you have positive chip EV and negative $ EV and the math changes. reply nighthawk454 11 hours agorootparentPeople are really zeroing in on the word 'bankrupt' here. The point was if you used that strategy, all in 100% of the time for positive EV, you will _probably_ go bankrupt even though the n=infinity limit of that strategy is positive. The whole poker thing was merely an analogy in the first place. reply RHSeeger 5 hours agorootparentprevCalling an all-in and going all-in are two totally different things, unless the all-in (that you'd be calling) is for an amount greater than you have. Otherwise, it's just \"bet a lot, but you can keep trying if you lose\". Going all in, on the other hand, is \"bet it all, and if you lose you're done\". The risk on the later is much greater. Any time there is no chance for recovery on failure, your risk analysis changes dramatically. reply mahoho 4 hours agorootparentBut in a cash game, if you're properly bankrolled (a common number people recommend is to have at least 40 buy-ins worth of cash set aside for the stakes you're playing), the one buy-in you lose if you lose an all-in is relatively small and you can just buy in again and keep playing. Going back to what OP said, if you shove every time you get aces you will profit over time as long as you have a properly managed bankroll, it's just not the most profitable way to play aces in most situations. It's different in tournaments because when you're late enough into a tournament, losing your stack actually does mean losing everything since you can't re-buy reply a-dub 11 hours agoparentprevagree about the EV stuff. it only makes sense over many draws and the problem states that he is thinking of \"a number\", that sounds like one game. that said, the problem screams binary search and you know your opponent is a computer person, so i guess the question is: if you make a bet that your opponent is making an adversarial choice that assumes you're going to do a vanilla binary search, can you improve your odds of coming out ahead by modifying your own binary search to always assume the target is an adversarial one? reply nighthawk454 11 hours agorootparentThat is an interesting question. I suppose it's equivalent to the 'worst case' performance for binary search, which would be a relevant topic. Finding the optimal strategy in the case where the opponent _may_ be adversarial could be interesting. I don't imagine the odds improve compared to the base situation, but not sure reply a-dub 11 hours agorootparentwhat if you, say, decided to make the bet that your opponent is adversarial and just did binary search, but restricted high, low and mid to snap to the nearest adversarial numbers when adjusting them? reply rcxdude 10 hours agoprevWhen Ballmer said 'adversarial', I considered this strategy: he's not actually required to pick a fixed number at the start at all. He can simply give the answer to each guess which leaves the largest number of possible numbers remaining, guaranteeing a loss regardless of strategy. reply iainmerrick 7 hours agoparentRight! I'm not sure if that's actually what he had in mind, but if he did, it's funny because it makes all this mathematical analysis completely pointless. The OP has a complex randomized strategy that guarantees to average at least $0.07 against any adversary; meanwhile, just by delaying his \"pick\" and stringing you along, Ballmer makes you take seven guesses and owe him a dollar each time. If you were expecting to win $0.07 on average, how many rounds would you play before you realise you're being scammed? reply akoboldfrying 4 hours agoparentprevThis should be higher. The OP's article is interesting, but it assumes a very weak notion of \"adversarial\", in which Ballmer still commits to some initial choice. Interestingly it's actually possible for a player to know this is the case if Ballmer uses a commitment scheme [1]. For example, at the start of the game Ballmer could generate 500 random bits, append his chosen number in the range 1-100 to this, hash the result and then send you that hash: At the conclusion of the game, he sends you the 500 random bits, and you can check that concatenating his chosen number (now revealed) to those bits and hashing the result produces the hash he originally sent. (If Ballmer lies and changes his number, he would need to somehow come up with 500 bits that when concatenated with this different number still produce the original hash. This is hard.) [1]: https://en.wikipedia.org/wiki/Commitment_scheme reply mrgoldenbrown 5 hours agoparentprevHis wording of the rules implies he chooses a number and sticks with it. He \"has a number in mind\". Of course some interviewers like to play mind games and twist things up to make themselves feel smart but I don't think that's his intent here. reply akoboldfrying 4 hours agorootparent>I don't think that's his intent here. Well, rereading what he (was reported to have) said, I now think that probably was his intent, and he was just sloppy. At least, he can't have it both ways: Either he genuinely commits to a number at the outset, and uses the word \"adversarial\" to mean a very weak form of adversary (one that is defeated in expectation by TFA's mixed strategy), or he is using \"adversarial\" in the standard (strong) sense, in which case he must be lying about committing to a number, which is a shifty mind game as you say. reply GuB-42 10 hours agoparentprevThat's what I thought too, kind of like Absurdle, an adversarial variant of Wordle: https://qntm.org/files/absurdle/absurdle.html It is by the author of HATERIS, a variant of Tetris that always gives you the worst piece. reply jessriedel 7 hours agoparentprevI mean, who know what he’s thinking, but based on the game description that strategy isn’t “adversarial”, it’s lying. Maybe the lesson is “don’t play games for money with people who will cheat”, but it would be a boring one. reply imtringued 8 hours agoparentprevThis is how it is done in the analysis of competitive ratios of online algorithms. The adversary can change its mind on a whim, it merely has to commit to the decisions it has already made in the past. reply TheDong 10 hours agoprevEdit: Oops, nope, this comment is wrong, ty fgna for pointing that out! I feel like there's an even simpler proof that you can beat adversarial-ballmer, with exactly the same expected positive outcome as binary search vs random ballmer. I call my algorithm \"randomly offset binary search\". It goes like this: 1. Pick a random number between 0-100, call this 'offset' 2. Perform the binary search algorithm, except at each step add 'offset' to the value and mod by 100. That's it. Now, even if Ballmer knows you're using this strategy, he can't make it perform any worse by selecting any specific number. Therefore your expected outcome is still $0.20 per game, beating the strategy proposed in this blog post. reply fgna 10 hours agoparentUnfortunately the numbers are not circular :( By offsetting the initial number, the binary search does not work optimally right? Imagine the number is below 50, and you start by guessing 60, now you have to search for 30 numbers instead of 25, and thus the binary search is not optimal. reply reply TheDong 10 hours agorootparentAh, yup, you're right. Ballmer's answer of \"high or low\" isn't in the offset number system, but the normal one, so my strategy doesn't work. That's what I get for not thinking it through properly, thank you for pointing that out! reply n4r9 10 hours agoparentprevNeat. A nice way to see this is to imagine that the numbers 1-100 are arranged around a clockface; you randomly spin the clock before doing a conventional binary search starting from the top. reply kikimora 10 hours agoparentprevThis is brilliant! reply tromp 3 hours agoprevA more extensive analysis of Nash equilibria including a numerical solution for the full game is presented in https://bowaggoner.com/blahg/2024/09-06-adversarial-binary-s... reply gukoff 2 hours agoparentThank you, this is very interesting reply zug_zug 6 hours agoprevI was looking for the comment that simply said \"This looks right, good work!\" and since I couldn't find one, let it be me: This looks right. Good work! reply cbanek 12 hours agoprevOf all the things that Ballmer was wrong about... I guess this is one of them. reply glimshe 9 hours agoparentI'd love to be wrong like Ballmer. The net balance of his decisions were billions of dollars. reply lucianbr 8 hours agorootparentThe net balance of his decisions, his circumstances, his random events and who knows what else. Please please stop with this \"if he's rich he must be smart\" argument. Please? reply glimshe 3 hours agorootparentAs long as we stop with \"if he's rich it must have been luck alone\". Even a lottery winner has to buy a lottery ticket. Ballmer was a top salesman and a notorious workaholic. Of course he needed luck, but I doubt most in his position would have netted the same billions. reply fuzzfactor 5 hours agorootparentprev>The net balance of his decisions were billions of dollars. Billions of dollars less than it could have been, not just for Microsoft, but all Windows users combined. If he's rich he must be fortunate, have to find out if he's smart some other way. reply WalterBright 11 hours agoparentprevBallmer was right about betting on Microsoft. reply fuzzfactor 5 hours agorootparentAgree, but Microsoft was wrong about betting on him. reply sph 10 hours agoparentprevShow us what you have been wrong about so we might judge you. reply jimt1234 11 hours agoparentprevMy personal fav: https://www.youtube.com/shorts/rCszxibClKE reply cbanek 11 hours agorootparentMy favorite Ballmer practice is stack ranking. It completely screwed up the entire company. I worked on Windows Mobile at the time the iPhone came out. We were all shitting ourselves. reply muststopmyths 6 hours agorootparentStack ranking existed at MSFT before Ballmer became CEO, i.e., when billg was CEO. It was a practice that Jack Welch brought into the corporate world and Microsoft was just guilty of following what were thought to be best practices at the time. Source: worked at Microsoft before Windows Mobile was a thing. As an aside, Windows Phone was my favorite phone OS and Ballmer seemed like the one who actually cared about it a lot. reply RaftPeople 2 hours agorootparent> best practices Tangent: I love that phrase. Anytime I hear someone make that statement I think about the 9,000 things that have been considered \"best practice\" until we actually understood that they weren't even \"good practice\". It gets thrown around as if it's been studied and confirmed when in reality it means \"a bunch of people are doing it\" reply Varriount 11 hours agorootparentprevOof, that does not sound like a strategy that culminates a positive work atmosphere. reply qarl 12 hours agoprevAnd this, friends, is the perfect example of why the modern tech interview process is pure insanity. reply Jalad 12 hours agoparentIs this a perfect example of broken modern tech interviews? Balmer's question seems fair for the complexity of the answer he was expecting. As the interviewee you would presumably provide the (mathematically) wrong answer, but you'd show your thinking along the way, including a small demonstration of CS principles. Keep in mind that Balmer had a long career, so if he ever asked this question, it was probably back in the 80s when no one expected you to come up with the complex solution outlined in the post. If you did outline the correct answer, that would be amazing, and you'd be an instant hire. But the question doesn't fundamentally seem broken to me because either answer (taking the bet or not) needs to be well justified. reply rustybolt 12 hours agorootparentThe question seems like a mathematical one. What you're saying sounds to me like \"your answer doesn't need to be correct, it just needs to sound reasonable\". What you're filtering on with this question is good bullshitters. To me, the only reasonable to this question is \"I don't know\". I think even a mathematical genius like Terrence Tao would not be able to give you the answer to this on the spot. (Although I can also totally believe that he would instantly see this from some obscure theorem that only like 5 people on the planet know.) reply ywvcbk 11 hours agorootparent> \"I don't know\" Which is exactly the same as “no” in this situation. If you were capable of proving the opposite I assume he would have been willing to hear you out. > not be able to give you the answer to this on the spot Realizing the most obvious strategy would be suboptimal if the game is adversarial is the first step of the correct answer though. If you didn’t know what to do next obviously the correct answer is “no, because I don’t know”. Someone who is trying to absolve himself from making any decision ls is presumably not the sort of a person they were looking for. Also would Balmer have been hiring for engineers to begin with? reply roenxi 11 hours agorootparentprevIn fairness, if someone proposes a complex and contrived game which cannot be easily analysed but is potentially adversarial... you shouldn't play them. reply randomdata 11 hours agorootparentAre you talking about Balmer's question or the aforementioned job being interviewed for? reply IanCal 11 hours agorootparentprevNo, it's about understanding what an interview is for. They're not trying to get the answer. They're trying to find out what you know, how you think and how you communicate. Do you spot that it's different with one Vs many plays? Do you spot the binary search? Do you spot that an adversarial opponent can push things? Can you clearly communicate these? If you just say \"I don't know\" and that's it you are showing you don't know how to communicate important information and miss soft skills about understanding the context of an interview. If you say \"I don't know\" and talk through your thoughts then great. The point is talking things through, even if you have gotten the wrong answer. Maybe you'd be able to say \"and here's how I'd code a simulation to check\" reply rustybolt 11 hours agorootparentThat seems reasonable, and in that context I would think it's actually a good interview question. But it seems that Steve Ballmer used this question as if it has a single right answer, and that answer is \"no\". Unless it's more about the question \"do you want to play this game, right here, right now?\", then it becomes more about heuristics and quick reasoning. It's all about context I guess. reply randomdata 12 hours agorootparentprevSeems so. The broken tech interview idea stems from the idea that interview questions that do not pertain to the job will lead to hiring the wrong people. And, indeed, what Microsoft really needed in the 80s was people who truly understood memory management in C, not gamblers left to hack their way into something that kind of worked sometimes. Microsoft's need to correct that hiring mistake later set them back significantly. Had they asked about the intricacies of C as it directly pertained to the job instead of unrelated trivia, they would be in a much stronger position now. reply ywvcbk 11 hours agorootparent> Had they asked about the intricacies of C Presumably it wasn’t Ballmer who was asking questions like that? If he was running the “business”, sales etc. part of the company. All of the things you listed would have been less than worthless if they weren’t able to convince anyone to buy their products. reply randomdata 11 hours agorootparentThanks for playing along. This is a perfect example of why pointless trivia does well in an interview. It reveals the psuedo-intellectuals who will overanalyze the situation in an effort to try and sound intelligent. Exactly who you want to steer clear of. The candidate you actually want to hire will respond with something to effect of \"That's dumb. Let's instead talk about X, which will be a far more appealing topic to both of us.\" reply qarl 6 hours agorootparentprevI think you're missing my point. The problem isn't the question - it's the fact that Balmer was objectively wrong about the answer - and he never changed that determination after having conversations about it however many times. (\"I asked this question all the time.\") It doesn't matter that it was difficult to prove he was wrong. The issue is that it was impossible to prove he was right. And if anyone ever tried to bring that up to him, he never once heard them. I believe an interviewer who is wrong and does not listen to you is a perfect example of the broken process. Especially given that he was an industry leader - in this interview he was providing a historical example of the process' merits - all while being entirely incorrect. reply lupire 4 hours agorootparentYou are claiming things that are absent from and contradicted by the interview. reply qarl 4 hours agorootparentYou need to explain what you think those things are. reply langcss 12 hours agorootparentprevYes because it is a question for a quant. reply noname120 12 hours agoparentprevWell to be fair Steve Ballmer is a terrible leader and if he had to take the tech interviews he wouldn't have passed and Microsoft wouldn't have stagnated for 10 years, before Satya Nadella took over and brought the company back on its feet. reply ywvcbk 11 hours agorootparentHe’s probably a decent leader just not a very good CEO for a company that needs to develop new products and enter new markets to continue growing rather than to try and squeeze every remaining penny from their current customers. reply smolder 11 hours agorootparentprevSatya Nadella has been good for the stock price and is probably a better leader than Ballmer, but hasn't made MS into a respectable company. reply high_na_euv 10 hours agorootparentprevMany Satyas successes started under Ballmer. reply noname120 10 hours agorootparentCould you give some examples? reply high_na_euv 9 hours agorootparentBiggest one: Azure, then Bing https://blog.jovono.com/p/ballmer-microsoft-underrated reply OmarShehata 12 hours agoparentprevis it? If I was forced to ask this question as an interviewer, and the candidate said, \"actually, you're wrong, here's why\" that's a very good signal. Do most people not do this? (typically there's discussion with all the interviewers and it isn't just \"did the candidate get the question right or not). I personally think a lot of big tech interview questions are dumb but I think the process isn't as broken as I thought, seeing it from both sides. reply carlmr 11 hours agorootparent>If I was forced to ask this question as an interviewer, and the candidate said, \"actually, you're wrong, here's why\" that's a very good signal. Do most people not do this? The question is whether Ballmers ego would allow him this flexibility if it's his own question. Some people might be very emotionally attached to the questions they created, but not so much to those they've been given as an interviewer. I've fared well pointing out issues with questions in the past and gotten the job. I'd try to be diplomatic about it though and not outright say they're wrong. Instead pointing out how with a classical binary search the expected value is negative, but there are strategies from game theory to deal with adversarial picks and here you could reach a positive expected value. Kind of a \"yes, and...\" approach. You acknowledge their view, and then you add a new perspective. But don't say they're wrong. Funny enough in situations where I suspect the interviewer was given the question it probably wouldn't have helped, not due to emotional attachment, but because the interviewer had a tenuous grasp of the topic themselves and couldn't stray from the script they were given. reply metabagel 12 hours agorootparentprevI suppose that telling the interviewer that they're wrong is a good way for the interviewee to test culture fit. reply rustybolt 11 hours agorootparentprev> Do most people not do this? I'd say it's impossible to answer this question conclusively within the time frame of an interview. That makes it, in my opinion, a bad interview question. My answer to this question would be to show that I understand what it would take to answer this question correctly (you'd have to find a mixed strategy that has a positive expected value for every choice of number), I wouldn't be able to give a confident \"yes\" or \"no\" answer on the spot. I think that's the only correct answer. In practice, I think this question is advantegeous for those who confidently blurt out an answer and then make up a heuristic argument for it. But a heuristic argument can be found for both \"yes\" and \"no\". reply qarl 7 hours agorootparentprevI think you're missing something. Presumably Balmer did ask this question. At least a few times. And yet he never heard of the correct answer, and believed the incorrect answer to be correct. That tells you that if anyone did say \"actually, you're wrong\" he never listened to them. reply TheCondor 5 hours agoparentprevI think this is a good question, there are many veins of potential discussion which is what you want. It’s not likely a binary question. Is it fair? Does he change his choice or pre-record it? Can you play multiple times? Purely random distribution, totally fair? Sure play the game every time, the math pans out. It’s not that though. It’s about showing your work reply thih9 11 hours agoparentprevAs long as it's used to figure out if the two parties would enjoy working with each other, I guess it's fine. But yes, increasingly often this turns into a quiz or worse. At least we get some quality fiction like https://aphyr.com/posts/340-reversing-the-technical-intervie... and its sequels. reply beeflet 12 hours agoparentprevI don't work in the tech industry but I always assumed these questions were designed for you to demonstrate your problem-solving skills, regardless if you get the answer correct or not. In this case, it would just be showing that you can reason about binary search and showing that the mean profit is 0.20 dollars reply weinzierl 12 hours agoparentprevIt is the perfect example, why you should pay attention in your math class too. reply corimaith 12 hours agorootparentI don't think the average CS curriculum is going to cover advanced game theory. And you certainly aren't going to doing most linear programming on the spot in a interview. reply rustybolt 11 hours agorootparentThis is actually extremely basic game theory, but I agree that most CS programs would probably not cover it. reply dooglius 7 hours agoprevNice! I tried to solve this the other day too, but came from the other angle--trying to find a probability vector for Ballmer that always won (finding the best response tree is n^3 complexity best I could find). I'm somewhat surprised since I figured for sure Ballmer had a big edge by picking numbers near the endpoints, making the player pay a large cost to check them. reply fph 12 hours agoprevSteve Ballmer's net worth is 120 billion dollars, so, assuming each game takes 30 seconds, it would take you 1.6 million years to win it all. reply koolala 12 hours agoparentWe let our computers play. My computer's AI vs Ballmer's AI. One trillion six hundred eighty-three billion thirty-six million fifty-one thousand nine hundred eighty-four computer games in 30 seconds. reply leni536 12 hours agoprevCan't wait for the paper that solves for the Nash equilibrium for this game. reply arianvanp 12 hours agoparentBallmer Peaking - an optional strategy for a number guessing game reply lazyasciiart 11 hours agoparentprevIsn’t that what the Arthur O’Dwyer link gives? reply tromp 10 hours agorootparentOnly for up to 5 numbers. Note that the Nash equilibrium for 100 numbers could require many pages to describe. reply leni536 9 hours agorootparentprevRight, I missed that one. reply WalterBright 11 hours agoprev> I’m thinking of a number between 1 and 100 People are unable to think randomly. They'll avoid the obvious \"not random\" numbers 2 and 99, for example. I read somewhere that most people, asked to pick a number between 0 and 10, will pick 7. And the next digit would probably be odd, and not 5, because 5 is not random. That leaves you with 71, 73, 77 and 79. 77 is not random, so 71, 73 or 79. I'd pick 73 as my first guess. I'd say those were good odds! (That's why when you're picking a \"random\" number, it's best to use an actual dice.) This is how you win at hammer-paper-scissors, too. Ballmer could also change the number he's thinking of as you make guesses, so part of the game would be guessing what he's thinking. reply gwd 10 hours agoparent> Ballmer could also change the number he's thinking of as you make guesses, so part of the game would be guessing what he's thinking. If I were to take the bet with him, I'd make him write down the number first hide it (turn the paper over / put it under a book, whatever). reply fnord123 11 hours agoprev> I’m thinking of a number between 1 and 100. I guess this is part of the clarifications one normally asks when in an interview setting, but he has specified numbers and not integers. One could choose (pi*2)/2 and you will owe a lot of money. reply Lockal 10 hours agoprevHere is a chart for probabilities for starting value: https://docs.google.com/spreadsheets/d/e/2PACX-1vThljkK2nUIL... I find it interesting: it is definitely symmetrical, but I did not expect that in the final result 1/98 could be more important as a starting value, while 2-17/82-97 are not used at all. reply gukoff 3 hours agoparentThis really depends on the pure strategies that you choose. The initial set of strategies wasn't very diverse and compensated for the binary search \"weaknesses\" on the ends of the spectrum by sometimes guessing 1 and 98. But after adding some more pure strategies to the set, we've got a far better mixed strategy that prefers the numbers between 28-70 as the first pick: https://github.com/gukoff/ballmer_puzzle#winning-strategy reply Lockal 35 minutes agorootparentO, wow, post got update! > Avg win if Ballmer chooses randomly: $0.16247848000093376 > Win if Ballmer chooses adversarially: $0.14657033010415976 So the goal is to find a set of strategies where adversarial avg win == random avg win? Or these numbers will never be equal? reply nojvek 1 hour agoprevIt would only make sense if Ballmer writes the number he is originally guessing on a piece of paper and fold it before game begins. And win/loss is checked with what is written on the paper. Otherwise it is a hidden mutable information game where Ballmer dynamically changes higher/lower for maximum tree depth and always make you lose. reply koolala 12 hours agoprevWhat if he flips a coin? 50% chance to optimize for Binary Search and 50% chance to optimize for Ballmer Search? reply vjo 8 hours agoprevI did a very similar exercise after reading the original post. You can get the EV a lot closer to the optimal +0.2 (Although I was unable to prove how close) by dropping the requirement \"do not increase worst-case complexity for the binary search\" as this is lost with initial guesses outside 36-64 anyway. Deviating at a higher depth makes punishing specific guesses in the tails a lot cheaper, only giving up 1-2 cents of EV. reply gukoff 6 hours agoparentInteresting! What about the worst case? And which kinds of strategies did you pick? reply thih9 12 hours agoprevI'd like an online demo where you play as Ballmer against an opponent using this strategy. reply nehalem 12 hours agoprevI wonder whether the search algorithm would need (and can?) to be adjusted to respond to the increased probability of playing numbers that are hard to find with standard binary search. reply draluy 11 hours agoprevI dont get this. If this is true, then he found a more efficient algorithm than binary search. Why are we not using it in CS? reply larsnystrom 11 hours agoparentI'm no mathematician, but I think that if you know something about the probability distribution before searching, then you can be more efficient than blindly using binary search. And if you assume Ballmer is out to get you (i.e. the distribution is not random) then you can use that information to improve the search speed. reply pnt12 11 hours agoparentprevThe point is that Ballmer is an adversary, and may choose the worst cases for binary search. As I understood, the algorithm in TFA holds against any choice. As others said, if you don't expect adversary behavior in your data, it should be good enough. reply abigail95 11 hours agoparentprevBinary search wins in the average case on random data. Ballmer is not required to choose randomly. reply veltas 11 hours agoprevHonestly I think Ballmer would have appreciated this answer in an interview. reply arduanika 11 hours agoparentOnly if he were hiring for game theorists game theorists game theorists game theorists reply gavindean90 11 hours agoprevI 100% believe Balmer had an off by one error reply quuxplusone 6 hours agoparentFrom my own blog post (linked from TFA): > If Ballmer is choosing his secret number uniformly at random, then the expected value of the game is [that you win $0.20]. But, as Ballmer points out in the linked video, if he knows you’re going to do a plain old binary search, then he certainly won’t ever choose 50 as his secret number. In fact, he has no reason to choose 25 or 75 either. Or 12, 13, 37, 38, 62, 63, 87, or 88. If Ballmer avoids those eleven numbers, and chooses uniformly at random from among the rest, that alone is enough to lower the expected value of the game from [$0.20] to about [−$0.0045]. So I think Ballmer was being perfectly honest in what he said: he does know a strategy that makes the expected value of binary search counterintuitively negative, and that strategy is (as he says explicitly) to avoid the first few numbers that you're going to guess. No further speculation about errors or deception on his part is needed. reply tromp 12 hours agoprev> Out of the 100 numbers, there are 32 that would require you to ask 6 questions to make a guess. Huh? I have 100 - (1+2+4+8+16+32) = 100 - 63 = 37, where 2^i numbers can be guessed after exactly i wrong guesses plus one correct guess. reply gukoff 11 hours agoparentThanks for spotting it! Exactly right, I fixed the text. reply thaumasiotes 11 hours agoparentprevPreliminary analysis: one in every three numbers has this undesirable property; the edges mess this up but shouldn't be able to add more than two extra undesirables; it should be impossible to have more than ceil(33.333) + 2 = 36 undesirables. (Also, since six bits will serve to identify 64 different numbers, it should be impossible to have more than 36 numbers that can't be identified that way.) I'll update with boring manual data later. ---- update ---- That was wrong; using a naive guessing method, I found 37 values that require 7 guesses. reply malthaus 11 hours agoprevmoral of the story: you might be theoretically correct, but the other dude still has a net worth of 120bn and you don't. so who's the loser now? reply randomdata 11 hours agoparentI don't know. Play his game just shy of two trillion times and it will be you with the $120bn net worth! It seems the real moral here is: The best time to plant a tree was 20 years ago. reply balazspeczeli 9 hours agoparentprevnot being a billionaire doesn't automatically make you a loser a better moral of the story would be \"a billion dollars does not guarantee that someone is right\" reply ajcp 12 hours agoprevAfter watching the interview I can't imagine why anyone would spend time trying to solve for this or entertain this as a valid test of anything. In 7 guesses he TWICE amended if she was high/low after hearing her guess. reply wed239023 10 hours agoprev [–] I watched the interview, and I see two problems: - nowhere it says he has to choose whole number, he could choose fractions (55.25) or even irrational like PI. Number of questions can be infinitive. - nowhere it says, he may not change his number while the game runs. You pay upfront for each question, and you hope game is not somehow rigged. It is not just question of algorithms. Also money you win is a taxable income, payments for hazard are not taxable expenses... reply mattmanser 9 hours agoparent [–] He also doesn't say he wants to play in this reality where the rules of maths hold. That his one and your one mean the same thing. That your accent doesn't have to match his. That you haven't got to be holding a certain pose when you say it. There are always implied rules, and Ballmer's implied rules are he'll use a whole number, not change his number and be fair. You could probably spend now until the end of time adding stipulations and he'd still be able to cheat. I'd recommend never learning about philosophy as you'll disappear into nihilsm. And lottery wins aren't taxable every where on the planet (e.g. the UK), so you made the same \"mistake\" as the author too! reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "John Graham-Cumming's post about Steve Ballmer's binary search interview question has sparked interest on Hacker News.",
      "Ballmer argues the game has a negative expected value, but John counters that with random number selection, the expected value is positive: $0.20.",
      "Using mathematical optimization and scipy’s solver, a mixed strategy can be devised to ensure a positive expected value, making the game potentially profitable."
    ],
    "commentSummary": [
      "The game has a positive expected value regardless of Ballmer's strategy, but Ballmer argues that expected value isn't a good measure if survival is a priority due to tail risk.",
      "The St. Petersburg paradox is used to illustrate that expected value isn't always a reliable measure of risk.",
      "The game involves guessing a number between 1 and 100, with the potential for adversarial behavior, and a mixed strategy can ensure a positive expected value."
    ],
    "points": 183,
    "commentCount": 152,
    "retryCount": 0,
    "time": 1725602893
  },
  {
    "id": 41461747,
    "title": "Why Don't Tech Companies Pay Their Engineers to Stay?",
    "originLink": "https://www.goethena.com/post/why-dont-tech-companies-pay-engineers-more-to-stay/",
    "originBody": "Staying in a role builds valuable, company-specific domain knowledge. Leaving often results in a payday—so, why aren’t tech companies paying more for their engineers to stay? This article was originally published to Marker. Why don’t companies pay engineers more? When news broke that breakout star Regé-Jean Page was leaving Bridgerton after only one season, my initial reaction was that of shock and heartbreak. I couldn’t fathom why Netflix and The Duke of Hastings weren’t able to come to some sort of agreement. But then it hit me: my entire career, I’ve watched talented engineers leave companies for greener pastures after painfully short tenures. I’m even guilty of this myself — I left an amazing company after less than two years to join Ethena as VP of Engineering. My example aside, I think the larger phenomena is a problem with organizations, not individuals. When hiring someone new, companies are forced to play in the open market, competing for top talent. But internally, they create opaque and informationally asymmetric compensation structures designed to minimize growth for existing employees to save the company’s bottom line. That’s not the type of company I want to be a part of, so at Ethena, I’m working to create career paths and compensation structures that encourage long and happy tenures by paying our engineers generously and in proportion to their impact. Additionally, I’ll be working with our not yet hired Head of People to publish our compensation formula publically. Let’s break down why this strategy makes sense, and why I believe it will be fundamental to Ethena Engineering’s long-term success. Tech compensation is all wrong With a market this hot, software developers are hopping between companies and raking in enormous pay raises in the process. But let’s think like economists for a second — in a perfect market, this shouldn’t be possible! If a developer of a certain caliber is able to demand a given salary on the open market, why isn’t their existing company paying them that very same amount? In our imperfect world, engineers join a company at a certain level of expertise, spend time learning and growing that expertise within that company, and then for whatever reason find that it’s much easier to get recognition for that growth outside that company. A graph or two might help illustrate the problem. First, market salary increases with years of experience, assuming an engineer is improving their skills of course! That one is a bit obvious, huh? Okay, well, let’s look at an engineer’s salary in their job at Acme Corp. Notice the slope of the line is a bit less . . . exciting? In my opinion, it’s likely the short-sighted desire to save money that defines the slope of this line at many companies. Well, if we’re talking about tech compensation over time, what about impact? Check out this steep angle! See, developers don’t just improve their transferable skills while working at their company—they gain domain knowledge that is specific to that company, and that stuff is incredibly valuable. The wild thing is that it’s only valuable to that one company! Let’s put it all together in one graph, and please don’t judge my blending of the units here . . . The hard truth that many companies struggle to wrap their heads around is that they should be paying their long-tenured engineers above market rate. This is because an engineer that’s been working at a company for a long time will be more impactful specifically at that company than at any other company. Bridgerton casting aside, a company like Netflix understands this, and will always outbid the competition for their top talent. Paying engineers more is easier said than done… It’s easy to say “pay your developers more,” but it’s never that simple. For one thing, this type of compensation structure is unrealistic for very early-stage startups where paying your first few engineers a market salary is usually impossible. Additionally, without an HR infrastructure in place, simplicity and equality can help early-stage companies thrive. This is why, so far at Ethena, the entire engineering team, including myself, has made the same salary. The other challenge with a compensation strategy like I’m proposing is measuring everyone’s unique impact accurately and without bias. What happens when the new hotshot junior engineer suddenly starts outperforming the old guard? With an impact-based compensation structure, she would deserve a sizeable raise, but is the company willing to go through with it and risk upsetting the other team members? Plus, not all engineers necessarily increase their level of impact over time. How are these engineers, who still add value every day, compensated in this type of structure? I believe the key to navigating these hard problems is organizational maturity. At Ethena, our track record of transparency, open feedback channels, and an experienced management team put us in a position to make these types of bold policies that other companies may struggle to operationalize. So, what’s the plan for compensating engineers? With the help of our soon-to-be Head of People, we intend to create a formula that takes into account title, years of tenure, and performance to create a compensation graph that scales with company impact as closely as possible. By making it predictable and public, both existing team members and potential hires can know in advance what they should expect to make at Ethena in the short- and long-term. It also means being comfortable with hard truths — not everyone’s impact grows in the same way and at the same time scale and maintaining talent density means being willing to part ways with underperformers. At the end of the day, if any engineer at Ethena demonstrates they are performing at a certain level, regardless of how many years of experience they have in or outside of the company, they should be rewarded with a title and base salary that matches their impact (in addition to their tenure and performance multipliers!). So stay tuned for more! I hope the future Head of People knows what they’ll be getting themselves into . . . Speaking of compensating engineers, we’re hiring!",
    "commentLink": "https://news.ycombinator.com/item?id=41461747",
    "commentBody": "Why Don't Tech Companies Pay Their Engineers to Stay? (goethena.com)164 points by samspenc 18 hours agohidepastfavorite267 comments BadHumans 17 hours agoThis entire piece starts from the conclusion that engineers leave because they aren't paid enough then works backwards from there. This is wrong from my experience. Anecdotally, I have never left a job because of money. Sure, I left jobs and got ones that ended up paying more money but the reason I started looking in the first place wasn't money. It was for other reasons that usually included frustrations with management. reply steelframe 16 hours agoparentYou should try leaving a company for money sometime. Financial independence really is life-changing, and you can get there surprisingly quickly in the tech industry by putting yourself on the market more often. Anecdotally, at my current company nearly everyone I know who left did so within a few months of hitting the 4-year cliff on their signing equity. I've left 3 companies in my career primarily because the next company doubled my comp. I've only left 1 company for reasons other than pay. reply BadHumans 16 hours agorootparentI make low six figures in a low to medium cost of living area. I don't think even doubling my income would change my life too much. reply sokoloff 16 hours agorootparentMoney isn’t everything, but the math behind retirement saving is compelling. https://www.mrmoneymustache.com/2012/01/13/the-shockingly-si... reply ryandrake 16 hours agorootparentYep, I look at every extra dollar I could make (that I don't technically need to survive) as some number fewer minutes until I can retire. So every extra dollar is worth it, no matter how frugal my lifestyle is. reply kulahan 15 hours agorootparentHere’s hoping you’re lucky enough to live until then. Don’t forget to live in the meantime. It’s a lot easier to hike across Europe in your 30s than in your 50s. reply DanielBryars 14 hours agorootparentThe sentiment is right, and sure, there are some differences, but please dont think your 50s is some geriatric period of your life where hiking across the alps/europe is not thoroughly enjoyable! reply ThrowawayR2 15 hours agorootparentprev\"Here’s hoping you’re lucky enough to live until then.\"? The median lifespan is over 80 and developers are paid above the median, often by quite a bit. It's far, far more likely in your 50s that you'll be staring down the barrel of a layoff + industry downturn and cursing yourself for the money spent on your trip across Europe and other frivolities in your 30s. reply shiroiushi 13 hours agorootparentIf you spent a ton of money to hike across Europe, you've done something terribly wrong. I spent a month traveling across Europe by train a few years ago, and it was fairly cheap, certainly FAR less money than I would have spent on any vacation in the US. Taking a vacation (any vacation) in the US is a frivolity, even if you live in the US. If you could theoretically rent out your home in the US while you're gone (for the same cost as your current rent+utilities, so no net profit), you'd probably end up saving money by spending a 2+ week vacation in Europe instead of just spending that time at home and going out to restaurants in your own town. reply bbarnett 11 hours agorootparentThis is only tangentially aligned, but I live in Canada and find the same equation in the winter. I travel south, to a low-cost area, and get to shut down the heat in my house for 4 months. The result is a $2000 savings over those months on heating costs. reply thot_experiment 14 hours agorootparentprevI don't think this is true for most people, when you ask older people about their regrets, it's often that they worked too much and didn't live enough. reply longdustytrail 13 hours agorootparentThere are many people who don’t get asked about their regrets when they’re older. And there are many people living lives of quiet desperation. reply thot_experiment 1 hour agorootparentYes but the set of people we're talking about in this context is software engineers often paid well above median. reply rapjr9 9 hours agorootparentprevThe median lifespan is no longer over 80, at least not for middle age males in the US, though it is for females: https://www.ssa.gov/oact/STATS/table4c6.html It also depends a lot on what your current age is. If you're 60 or older it's 80 or more. If you're younger than that and male it's under 80, going down the younger you are. Covid and other things reduced life expectancy in the US. This is the 2021 table, the most recent, life expectancy may go down further as new tables are published. However the graphs here tell a different story: https://www.ssa.gov/oact/STATS/table4c6.html Part of these graphs are future projections, so it's difficult to tell what to believe. I believe (correct me if I'm wrong) that the first table is what the insurance industry and Social Security uses. reply klooney 8 hours agorootparentThere are some uh, relevant socioeconomic correlations here. reply red-iron-pine 3 hours agorootparentto a degree, yes. but obesity -- which correlates with income level and area code -- is what's killing people early. if you're fat as hell at 19 you're probably going to be even fatter at 60, and heart disease or cancer is going to kill you. reply seanmcdirmid 12 hours agorootparentprevI couldn’t imagine living like that. Yes, it’s possible that I’ll get screwed since I started my money making career late, but I might have died of depression much younger otherwise. Everyone needs to find their own route through life and working your youth way is really really scary when you turn 59 and realize you haven’t lived yet. reply indemnity 11 hours agorootparentprevIn my 30s my single driving goal was to pay off my mortgage and be debt free (I came to home ownership late). Thanks to this industry, I got there at 42. I’m sure as shit not going back to the treadmill, for what? So I am taking my young family on trips and experiences I never had growing up (visiting other countries, camping, hiking, etc.), and working on the health I neglected in my 30s. Also being more assertive at work and not sacrificing like I used to. Because of this, I’m probably not going to have a wealthy retirement, but I have a lot of peace of mind knowing we could keep the family afloat working minimum wage jobs, with the house paid off and no debts. reply _zoltan_ 12 hours agorootparentprevA lot of my swiss neighbours are more fit than half my friends in their 30s, and they are 70+. I'm not sure what the secret is but I'm fairly sure just moving here added an extra 10 years to my life expectancy. reply chrisandchris 12 hours agorootparentThat's because we hike across our 30s, and don't stop until our 80s (at least a part of the population). Work is fine, but being outside makes you live longer and better. My grandfather was still skiing while being 80. reply Gud 9 hours agorootparentAlso I think less dependency on cars, in my experience (living in Switzerland) moving around by foot/bicycle/public transport is normal. reply kennyloginz 15 hours agorootparentprevWow. Is this really true? Do you live in a studio apt in the Midwest while working for a FAANG? reply ryandrake 15 hours agorootparentI consider myself a \"FIRE devotee without the compensation necessary to actually FIRE.\" So yea, time to retirement is definitely a variable that I actively try to minimize however I can. I don't want to be one of those guys who has to wait so long to retire that they're dead. reply chgs 10 hours agorootparentI’ve known far too many people who die within 3 years of retirement regardless of age. Quality of life now is more important to me. reply maxlamb 16 hours agorootparentprevRight but what if you enjoy your job and don’t want to retire? reply sokoloff 16 hours agorootparentKnowing that you have F-you money in investments makes it a lot more likely that you can enjoy your job and removes other stresses in life, or at least it did in my case even with only lowercase f-you money. reply _zoltan_ 12 hours agorootparentprevI love my job but having too much money would let me email someone 4 higher in the hierarchy to give them my opinion on things. :) reply sokoloff 8 hours agorootparentParadoxically, I think the willingness and ability to do that (assuming it's used at all reasonably) tends to increase your visibility and perceived value to the company when averaged over a large number of trials. \"This is stupid, but I'm going to keep my mouth shut because I like to eat and live indoors.\" vs \"This is stupid and I'm going to tell the CEO that and suggest a better alternative.\" reply 01HNNWZ0MV43FF 15 hours agorootparentprevThen take more unpaid sabbaticals, or buy a boat. \"Too much money\" is a solved problem reply nly 11 hours agorootparentprevWork is more enjoyable when you don't have to do it for money reply WrongAssumption 15 hours agorootparentprevWhat if you stop liking your job? reply desmosxxx 13 hours agorootparentThis happened to me sometime between my first and second kids (last year or so). It was some mix of changing priorities, less time, starting to feel my age, work becoming more difficult, company cultural changes, etc. I think I've stuck a decent balance of saving and living, but man does life come at you fast. Went from happily working 60-80 hours (including some side projects) to struggling to work 40 hours. Reminds me of how one day something switched and I just couldn't drink anymore. Age is probably the biggest factor, and I can't imagine what this is going to be like in my 50s (just turned 40). reply malux85 16 hours agorootparentprevHaving the option is better than not having it reply Am4TIfIsER0ppos 9 hours agorootparentprevSoon to have 25% skimmed off every year and that's assuming you get to live long enough to spend it. reply BadHumans 6 hours agorootparentI assume you're talking about the proposed tax on unrealized gains that only applies on holdings over 100 million. 100 million dollar threshold being a critical piece of information you conveniently left out. reply Am4TIfIsER0ppos 6 hours agorootparentHow many people did the original income tax apply to? reply BadHumans 6 hours agorootparentI don't think it matters. I'm in favor of the tax as proposed. If it changes I'll adjust my stance accordingly. reply BurningFrog 13 hours agorootparentprevDoubling your income would mean you can take 50% of your time off with the same income. Pretty sure that would change your life! reply consteval 1 hour agorootparent> you can take 50% of your time off The economy and society isn't structured like this. I'd happily take half the pay I have now for half the time. But the only way to get that time is to make 10 dollars an hour flipping burgers. reply YZF 13 hours agorootparentprevIt doesn't really work like that. The reality is that you can't work 50% of the time for half the salary (if that's what you mean). When you make more money you typically want a nicer place to live, maybe a nicer car, your standard of living will go up somewhat. Now to maintain that standard of living you're going to need to save more money. Maybe you have kids and you want to be able to pay for their education, or buy them a place to live... Maybe you're helping your family. Personally I could have \"retired\" a long while back if I wanted to have a lower standard of living and also take some risk. But I don't hate my work, I do things out of work as well, I prefer a nicer house and a nicer car, I'd probably be bored if I didn't work. reply BurningFrog 2 hours agorootparentI have asked to work 4 day weeks at 80% of my salary a few times, and not had a problem. When I once asked for a 3 day week that was turned down. The other way to work 50% is to take a few months or years break between jobs. I've enjoyed doing that. It's certainly not for everyone. reply yunohn 10 hours agorootparentprevIf anything, most tech company contracts are written the other way around - there is almost never overtime pay and any thinking/work done both within and outside work hours is completely owned by the company. reply brazzy 11 hours agorootparentprevDevelopers in the USA earn far beyond the level where the lifestyle creep that you describe is so compelling that it makes any sense at all to say \"you can't work 50% of the time for half the salary\". A more solid factor is that companies don't want to hire part-time developers, because coordination overhead means twice the number of developers each working half as many hours are far less effective. reply GianFabien 10 hours agorootparentprevTypically with a higher income you taxation rate increases even more. So 50% more salary might only end up being 20% more in your hand. reply throwaway2037 10 hours agorootparent> So 50% more salary might only end up being 20% more in your hand. Can you give an example of a tax regime where this would hold true? I find your example hard to believe. reply seafoam 7 hours agorootparenthttp://gregmankiw.blogspot.com/2008/10/blog-post.html reply ruszki 8 hours agorootparentprevhttps://en.m.wikipedia.org/wiki/Progressive_tax reply consteval 1 hour agorootparentEven under a progressive tax things don't work the way conservative fiscal armchair economists would like to have you believe. Poor people still, comparatively, spend more of their income to taxes. That's because poor people have to spend more of their income on direct consumption, i.e. not investment. If I'm poor I'm easily spending 90% of all my money on stuff for me, right now. If I'm rich that drops to 10%, and the rest goes towards stuff that isn't taxed. So, while income tax may favor the poor, sales tax very obviously favors the rich. The only reason a progressive tax exists is because rich people are so powerfully favored in modern tax systems, we need to try to bring them back in line to the burden poorer people face. Even still, poor people face more burden. reply simonw 16 hours agorootparentprevHave you considered worst-case scenarios? An injury that prevents you from working, or something like cancer in the family, could be a whole lot easier to deal with if you have a sizable nest egg. reply BadHumans 15 hours agorootparentI have considered it and it is a legitimate concern to think about. I'm still fairly young and healthy and I have enough money to not work for years if it came down to it so you could call it hedging my bets but it is something that does lurk in the background as time passes. On an unrelated note, big fan of your work :) reply kyawzazaw 13 hours agorootparentfor me, I like donating. So more money is great! reply bb88 16 hours agorootparentprevI've had my income more than doubled now, nearly tripled in the past decade. Just because I was willing to move where I would be paid market rate. There's a lot of companies in high cost of living areas that may be willing to split the difference in salary. reply emrah 13 hours agorootparentprevI love it when people guess how changing or trying something new will affect them without doing it and never having done it. reply abc123abc123 10 hours agorootparentprevMaybe not for you, but for your family and future children it could be a life changer. If something happens to you, having a few millions in the bank is also very nice. reply fragmede 16 hours agorootparentprevWhat's your FIRE number? When are you going to retire? Doubling your income shouldn't change your current lifestyle but it should change your trajectory towards retirement. Why retire at 65 when you could retire at 55, or even 45? reply nsxwolf 15 hours agorootparentprevI always find my salary very difficult to replace, and it's not particularly high. I'm assuming it's all pay cuts from here on out with the economy the way it is. reply BurningFrog 14 hours agorootparentThe economy has been objectively really great last few years. Many people say the economy is bad, whatever the measurable macro-economical state of the economy is. reply consteval 1 hour agorootparentThis is because the idea of economy has been highjacked by armchair capitalists. The economy has almost nothing to do with the average person's quality of life. We've completely lost the plot. That's why a country like the US can have such an insane GDP and GDP per capita and have comparatively much lower quality of life than countries with worse economies. When people say the economy is bad, they mean the things that actually matter. When economists say the economy is good, they're speaking of some theoretical economy nobody can see. They're speaking of numbers on a screen, that don't go into your pocket. That's where the discrepancy comes from. reply nsxwolf 13 hours agorootparentprevIf you find it almost impossible to get jobs I don’t know if it matters. reply BurningFrog 13 hours agorootparentYour immediate situation is equally shitty, sure. But if you realize the problem is not \"the economy\" (which you can't possibly affect), but something about you (which is the though you can affect the most), you have a chance to find a better path for yourself. reply RGamma 10 hours agorootparentprevYou see, according to that one HN commenter everything is always fine (they own capital) reply dartos 15 hours agorootparentprevFor the next few years at least, probably reply bb88 16 hours agorootparentprev> Financial independence really is life-changing. This. All companies want you to be loyal to them and them only. But they won't reciprocate it. Only the C-suite is deserving of hefty pay bumps. reply jongjong 11 hours agorootparentprevI've never been in a position where I had any kind of leverage to negotiate a serious increase. I've even been in an extreme situation in crypto sector where I was putting pressure on the company founder for a salary increase. I was earning like USD $100K per year comp total. They had over $100 million of assets. The founder, a multi-millionaire who had more money than he knew what to do with said that the pressure I was putting was like \"Holding a knife to the company's throat.\" Guess how much of a raise he offered? 2%! I quit. Within 1 month after I quit, they fired half of the company. Coincidence? They didn't even need to do layoffs, they still had over $100 million in liquid assets/runway. They were spending at a rate of like $1 million per month. WTF! Out of the 10+ tech startups and corporations I worked for over the past 20 years, that was the closest I ever came to receiving a raise and still didn't get it. The whole market feels fake. Like a kind of weird social engineering PsyOp. reply roncesvalles 11 hours agorootparentGetting more money from your current company based on market conditions almost never works. Even star performers get shafted on the regular. reply notepad0x90 16 hours agoparentprevHR has a saying \"employees don't leave jobs, they leave managers\". Pay has motivated me to look for other jobs, but only after I was already worn out and frustrated with my current job. Switching jobs isn't like getting a new car or moving to a new apartment. It's traumatic, kind of like going through a break-up. You work with the same people for years and then suddenly you will never see them again. That isn't pleasant. If the pay is bad enough, I like to think I would leave anyways. But I think most people are given better reasons to leave their jobs and onto greener pastures. I wonder if LLMs would do a better job as managers, if they can make up for cognitive biases in humans. Managers treat new employees with lesser experience, with higher regard and respect than existing employees with longer experience that remained at that company for a long time. Switching jobs is also the best way to get a raise, due to managers being heavily biased towards obtaining new hires. On one hand, they're supposed to keep good performers, but on the other hand they're supposed to keep talent flowing in. Employees should then also try to keep their jobs best they can, while also searching for better jobs and not getting more attached to their employer than their employer is to them? Humans in general are too biased and faulty in their thinking. Sure, LLMs hallucinate and propagate existing bias in society, but at least they can maybe (in the future) evaluate employees and form more objective opinions towards existing staff and new hires? sounds better than humans winging it based on \"vibes\"? reply dataflow 15 hours agorootparent> HR has a saying \"employees don't leave jobs, they leave managers\". I'd say they leave people. The people aren't necessarily managers. reply notepad0x90 15 hours agorootparentwell, the thinking there is, managers manage people, so ultimately it is their failure to manage people that causes good performers to leave. reply dataflow 14 hours agorootparentI mean, that thinking is obviously wrong. Not everything is within your manager's power to fix. And people have different tolerances with how many headaches they put up with too. The manager might need much more time to improve things than their employee might tolerate. reply notepad0x90 13 hours agorootparentThose are good points, but at the end of the day, people issues are management issues. It may not be your specific manager that is responsible but the management of the company and HR, who are responsible for the work environment that is set. I'd imagine it is a business (think money) decision on how much time and effort is put into cultivating a reasonably tolerable work environment. if employees have unreasonable demands for their work environment, I agree, it is the employee's fault. But fault aside, even for unreasonable and overly sensitive employees, they're still leaving managers who can't or won't fix people issues in their teams, more often than not, with many many exceptions of course. reply dataflow 13 hours agorootparentIf by \"people leave managers\" they mean anyone in the chain up to and including the CEO, then I guess? That's hardly a meaningful statement though, it's practically a tautology... the CEO is ultimately responsible for everything the company does, so whatever reason you have for leaving is their responsibility... by definition. I can't say I find a tautology like that to be a particularly insightful observation, but maybe I'm missing something. reply notepad0x90 3 hours agorootparentLet me put it differently and talk about immediate managers only. If the people problem is coming from other teams, the immediate manager should \"shield\" their team members from that. If it is between their team members, then they need to somehow manage the person reporting to them. They can't always, and I personally find that understandable. But still, the \"people leave managers\" expression is implying that either that manager is not capable or they are not being given enough resources, authority or training to manage people in their team and outside their team. From the CEO down to line managers, management is responsible for setting the tone and culture. Jeff Bezos and Tim Cook alike are responsible for how horrible and toxic of a work environment exists at amazon and apple. If the company is great, employees can usually switch teams when they don't like a manager. reply ImPostingOnHN 5 hours agorootparentprevYeah, the \"managers\" in the term \"people leave managers\" refers to their immediate manager in my experience, and often their immediate manager doesn't make the call on a lot of stuff. reply shiroiushi 13 hours agorootparentprev>It's traumatic, kind of like going through a break-up. You work with the same people for years and then suddenly you will never see them again. That isn't pleasant. That depends on your co-workers. It may be more like getting a divorce from an abusive spouse. reply nxpnsv 12 hours agorootparentEither way, unpleasant. reply shiroiushi 12 hours agorootparentHow so? Getting out of a bad marriage isn't unpleasant at all. A bit traumatic perhaps, but that's like going through the trauma of major surgery so you can have your badly broken leg bolted together so you don't have to get an amputation or die of infection. The feeling of freedom and peace you get after getting out is worth the trauma of divorce. Same goes for getting out of a shitty job with bad coworkers or a bad boss. reply nxpnsv 4 hours agorootparentSure, there is relief and a feeling this was necessary and for the best - but also broken dreams, failing social expectations, broken friendships. I guess I mostly agree with you, but I think such traumas make for unpleasant experiences... reply ttyprintk 10 hours agorootparentprevConsider the following: we don’t train LLM to optimize for a decision made on local context. That would cover a minimum viable manager-bot. We train on (admittedly flawed) context and offer decisions. Much closer to an executive advice bot. If given two checkpoints: your competitions manager bot, or your competitions executive advice bot, the latter is much more valuable. reply soco 10 hours agorootparentprevIf you train the LLM on today's practice, guess what, they will act exactly like today's managers, bias and faults inclusive. reply ljlolel 16 hours agorootparentprevStill traumatic with remote? reply notepad0x90 16 hours agorootparentWhen leaving jobs? For me it's even more traumatic. In-person working tends to come with a lot more drama, so leaving can be a relief in part. Remote working, at least for someone of my personality and slight obsession with technical matters, I could get more attached to like minded co-workers; with WFH I encounter minimal drama. But on this topic, pay is much less of an issue as well for WFH. I think I would put up with a lot more of undesirable work conditions remotely than in-person. reply Arisaka1 10 hours agorootparentprevYou think unprofessional workplace interactions, lack of growth (personal or/and company), and micromanagement aren't bad because it happens to you while you're at home? reply kortilla 16 hours agorootparentprevYes. You bond with people when you communicate a lot with them, regardless of the medium. reply linotype 17 hours agoparentprevThis. If you leave every 3-5 years you get to flush all that frustration down the toilet to make room for new, hopefully better frustrations. reply icedchai 16 hours agoparentprevSame. Over the past ~25 years, I've had 10 jobs, everything from junior engineer to a (failed) startup CTO. I've never left a job due to compensation. Poor morale, stubborn leadership, dysfunctional teams, uninteresting work, obviously bad business models, managerial incompetence and nepotism, have all been reasons. I even left jobs to take a pay cut to get out of these bad situations. reply goalieca 7 hours agorootparentIt’s because you’ve never stayed lo my enough for your salary to get stale. Around year 5-7 you’ll get tired of the less than inflation amounts of raise if you even get that. Every time I’ve switched jobs I get a title bump and a big raise. reply icedchai 2 hours agorootparentThat is true, to some extent. The longest I ever held a job was 6 years. Shortest, 6 months. reply YZF 13 hours agorootparentprevSame. reply somerandomqaguy 13 hours agoparentprevKind of depends. I live in Canada, most companies don't pay software related jobs like dev or SDET particularly well. When I left my QA / SDET position at 9 years of experience my salary was $52,000 Canadian a year. To give you an idea, it would've been like living in Denver, Colorado on a $35,000 USD salary in 2020-ish or so. Not every engineer is going to be making six figures. You just don't see those folks talking about it too much. reply YZF 13 hours agorootparentI would say that's a very low total comp for an SDET in Canada in any major metro area (e.g. Toronto or Vancouver). New grads with a CS degree that can code can find an entry position for double that compensation. Startups or big co. reply somerandomqaguy 11 hours agorootparentLow but it wasn't exactly unheard of either. There were full time positions publicly offering only $20,000 a year right on the listing itself. Not sure how publicly offering below minimum wage makes any sense though. Highest offer I've heard specifically for a mid level SDET position was $72,000 for 4 to 5 YOE but it was with a big company out of Vancouver. AFAIK they had no problem filling that opening within a few weeks. reply marssaxman 16 hours agoparentprevNot only have I never left a job simply to get more money, I have on more than one occasion left a job for one offering less money - and considered it an upgrade. Sometimes you have to ask: how, exactly, is the extra money I might earn here going to buy enough extra happiness to make up for the crap I'd have to put up with in the process of earning it? And sometimes there is no good answer. reply bionicthrowaway 16 hours agoparentprevI haven’t left many jobs because they paid poorly, but I’ve definitely stayed at jobs because they paid very well. For many people working in the tech industry for the past ~15 years, they could easily find a new job with comparable or better pay. That’s no longer a guarantee for most people. reply BobbyTables2 14 hours agoparentprevI find it pretty soul crushing to work hard and have a successful engineering team, only to have bonuses withheld because sales/marketing couldn’t hit lofty goals… Followed by the company spending huge amounts of cash on acquisitions in the same year… Too many companies are eager to invest in everything except their own employees. reply dataflow 15 hours agoparentprev> This is wrong from my experience. Anecdotally, I have never left a job because of money. Leaving because of money isn't the same thing as leaving because they didn't pay you enough to stay. For most frustrations people encounter at work (or elsewhere for that matter) that causes them to want to leave, there is a price at which they would put up with it and stay. The price is often much higher than management would consider paying, and higher than the income they'd have at their new job, but it does exist. So the question of why don't they pay you enough to stay isn't really based on the assumption that you were going to leave because of money. reply metabagel 10 hours agoparentprevI’ve left two jobs, because I was dissatisfied with my compensation. reply greenthrow 16 hours agoparentprevAnecdotally in multiple decades of jobs every single time I left it was for money. Sometimes as much as a 50% increase. reply yieldcrv 17 hours agoparentprev> It was for other reasons that usually included frustrations with management. and here I am thinking this was a meme by HR myself and all my competition leave jobs due to - and for - money. if you're sticking around to stay in graces of your comfortable management you are contributing to the wage gap for your respective gender in the wrong direction. reply BadHumans 17 hours agorootparent> if you're sticking around to stay in graces of your comfortable management you are contributing to the wage gap for your respective gender in the wrong direction. I have no idea why I should care about this. reply yieldcrv 16 hours agorootparentprivileged take reply david38 15 hours agorootparentNo doubt you are disadvantaging your gender by wasting time here and not working two jobs. Or did you somehow think you had the privilege of thinking your income only matters to you and your family? Amazing how people try to claim righteousness in stupidest of situations. reply ipaddr 16 hours agorootparentprevWage gap for gender? There are a lot of things in life to fight for. But to fight for a meaningless stat that doesn't take into account pregnancy is probably not the best use of my limited power. reply UniverseHacker 16 hours agorootparentprevA job with good management and a good work environment is hard to find… that is worth lower pay to a lot of people. I’m a person with tech skills in academia… myself and most of my coworkers and colleagues could make at least 2x in industry yet we’re still here because we like the job better. I have however lost a lot of colleagues. reply BirAdam 16 hours agorootparentI make “okay” pay at a non-profit, and I could make more if I left. However, I would then have more hours, more stress, and less freedom. Why do that? reply wsc981 16 hours agorootparentprevFor me it's the same. I'd be ok if management is crappy, but the pay is good. I actually left a company this year, because I was looking for (what I thought) was a very reasonable raise, but the company made negotiations very hard and annoying: - first meeting with direct manager: I was offered a very meager immediate increase and offered a \"personal improvement plan\" for proper raise end of the year (I declined - I hate this nonsense and I know I'm already a senior, no need to work towards \"senior\"). - then 2 times a meeting was planned with the CEO, but CEO wouldn't show up. He stated both times something came up, apparently more important. When I announced my decision to leave, at that point suddenly more was possible. I could get the raise I wanted, CEO excused himself for his behavior, etc... But at that point, too much harm was done, from my point of view. I would have stayed easily 1 or 2 more years if the pay was decent and I didn't have to deal with the nonsense for salary negotiations. reply alberth 16 hours agoparentprev> included frustrations with management Which I presume this is another way to say “your direct boss”. Because 99% of an employees view of a company, and opinions about their employer, is actually just a reflection of their like/dislike of their direct boss. reply kccqzy 16 hours agorootparentNot in my case. I left Google but it wasn't because of my direct manager. It was because of Google-wide issues that are outside of my or my manager's or my director's control. reply bb88 16 hours agorootparentUsually front line managers are kind of hamstrung. Yes they can fight for their people, but the reality is, that if the C-Suite only wants to give you a %2 raise because well, they have an off-site meeting in Maui -- well tough. The modern management model has been to reduce the power of the front line manager to the point he can only maybe hire and fire, but then he is the one to give the employee bad news. reply brazzy 11 hours agorootparentThere was never a management model where front line managers could freely decide on raises. There's always a budget, and you playing favourites causes drama. reply BurningFrog 13 hours agorootparentprevRed Pill: The boss/employee relationship depends equally on both people. If you always \"have a terrible boss\" that really means your relationship with your boss is bad, which depends on both people. You were warned. The Red Pill is near: To spell it out: If you consistently have a terrible relationship with your boss, with several bosses... I'm sorry, but the common factor is you. You're probably a shitty employee. reply metabagel 10 hours agorootparentWhat you wrote doesn’t seem related to the comment you are replying to. Plus, your unrelated response comes off as arrogant and judgemental. reply mistercheph 12 hours agorootparentprevThe more negative things a new hire has to say about their former employer or coworkers, the more likely that they are unbearable to work with. reply ttyprintk 10 hours agorootparentMaybe, but it’s a mistake to begin applying this without a big-enough sample. A slippery slope exists: what if they say negative things about the domain? Worry that new patterns in project management are unproven but unchallengeable? I’ve had new hires say that their old team was “hard to work with” but for a release cycle I can’t be sure if that’s a compatibility odor or simply the truth. reply red_admiral 11 hours agoprevAs a regular reader of Rachelbythebay - I agree with the sentiment of a lot of other posters here, it's not the money that makes people quit. A classic story here is the \"Sodas are no longer free\" one: https://steveblank.com/2009/12/21/the-elves-leave-middle-ear... The total cost of free sodas for engineers is probably small compared to their salaries, and for the individual engineer, the new $0.50 per soda cost is probably negligible compared to their salary. But moving from free (as in free soda) to non-free signals a culture change, and so the best engineers started updating their CVs. reply Corrado 10 hours agoparentHoly carp! When they took away the free soda at KFC I started updating my resume. I worked at the KFC headquarters for over 10 years and for most of that time they had free soda in the lobby. Then the cafeteria management got turned over to a 3rd party, I'm guessing as a way to save money. Setting aside a food company not managing their corporate cafeteria, this 3rd party wanted to sell sodas and that's really hard when the company is providing them for free. So, KFC took out the free soda machines in the lobby. I'm not joking when I say that free soda was a huge selling point to new recruits in the IT department. We even used it as a \"smoke\" break for those of us who didn't smoke. Feeling that after lunch malaise? Walk down 5 flights of stairs to get a small Pepsi. Need to talk out some tech problem with a co-worker? Grab a soda together and take a walk. It was great. When they announced they were removing the soda machines one of the KFC VPs even offered to pay for the supplies out of their own budget. Rumor has it that the total cost was in the neighborhood of $30k / year, which was nothing in the grand scheme of things. But the higher ups said no and the machines were removed. That's when I (and others) started to update our resumes. reply tasuki 7 minutes agorootparent> Feeling that after lunch malaise? Walk down 5 flights of stairs to get a small Pepsi. Need to talk out some tech problem with a co-worker? Grab a soda together and take a walk. It was great. It sounds like hell. How do you not get fat doing this? reply kcplate 6 hours agorootparentprevI was in the break room at a former company when one of the warehouse workers who had been with the company for nearly 30 years and who had been through multiple ownership changes, made this comment to me: “well, the company is for sale again, the are buying Maxwell house coffee”. Within a week I was answering due diligence type questions from “consultant” who turned out to be the CTO of the company that acquired us, and became my boss a few months later. That was 20 years ago. Ever since through the 4 companies I have been through in that time frame, I have always used the break room as the barometer for corporate change. reply alecco 8 hours agorootparentprevIf corporate starts sharpening their pencils at the small things they will sure cut on the bigger things like bonuses and raises. Time to leave if you are an over-performer looking for merit rewards. reply rightbyte 8 hours agorootparentprevOh dear. I agree with your point, but man, I do not handle free soda at work well. I do comfort drinking way too much. reply pas 3 hours agorootparentTime to do tea ceremonies at work. It's very comforting! reply lrvick 10 hours agoparentprev100% this. In every company I have been at that was going south, the first things to go after a hiring freeze were snacks and lunch. When companies walk back any benefits of the job that cause you to pay for things out of pocket, you just got a pay cut, and should GTFO. reply dagw 9 hours agorootparentI worked at a company that bought a smaller company. That smaller company had free snacks and we didn't. Somewhere in the negotiation someone from our company had promised the employees at the smaller company that they would be able to keep their free snacks. Anyway, merger happens and no free snacks. Now there were probably several reasons why the merger wasn't a success and why basically everybody from that company left as soon as they could, but the one thing every one of them would bring up when you talked to them was \"we were promised that we would get to keep our snacks and they lied to us\". reply rightbyte 8 hours agorootparentFood is holy in a primal way. It pisses people off when you mess with their food, don't invite them for it, etc. Way way way more than what is proportional to the costs. Like, 'pizza for all but the contractor' kind of social transgressions. reply doctorwho42 5 hours agorootparentAnd food can also be a great incentive for improving culture of a work place. I went from one department where the boss penny pinched all the lunches/leaving dinners/birthday budget... To a department where the boss works hard to keep a fund that allows us to go to nice restaurants, buy catered food for major meetings, and have a budget for birthday cakes. I will tell you one thing, I definitely overlook the shortcomings of the new boss and try to compensate for them without much complaint. The first boss? I did just enough ass covering to get solidly good reviews. reply bravetraveler 7 hours agorootparentprevSeriously. I have a 'thing' about eating around people... feels gross, prefer not to. You'd think I insulted someone for their choices by opting out I know they mean well with their lunch offer, but I'm barely socialized. I don't want to develop that skill, it's not personal. I'm just firmly independent reply Yizahi 5 hours agorootparentprevOne thing is certain in 2024 - ANY agreement to the low rank employees about something after merger/acquisition is a lie. Like clockwork, every single time. reply abc123abc123 10 hours agorootparentprevAmen! This has been my experience too. When the free snacks go, it is time to move to the next job. Usually the big cuts follow 6-18 months after the first snacks have gone. reply sys_64738 5 hours agorootparentprevI found it was time to go when the benefits literature in the Fall went from being glossy printouts to black and white photocopies. reply ttyprintk 10 hours agorootparentprevI’ve seen two sides of this: when the company is small and 80% of the sodas are taken by 20% of the people, it’s a quirk of personality. When the company is large, removing a building’s $750/year snack budget is a trial balloon for identifying who will tolerate the much deeper cuts. reply sys_64738 5 hours agoparentprevWhen Oracle bought Sun then the first day they installed the free soda fridges everywhere. They were replenished always. reply Joel_Mckay 10 hours agoparentprevThe other metric is it is easier to leave for a better position, than experience a layoff for redundancy. I was always happier floating between 2 different firms, as you literally don't have to engage with peoples games. You can call the bluff every time, and simply drop your hours if people get irrational. Tip: When one sees a place with perpetual Ads for fresh desperate grads, than you know it is likely a digital Gulag operating on tax subsidies. lol =3 reply gregfjohnson 15 hours agoprevA person close to me works at a law firm. She was feeling a bit stagnant, so she connected with a recruiter. She got a very solid offer with a significant pay bump. She gave her two weeks' notice to her firm, including appointments with the partners. One of the partners asked her for a half hour. They came back with a massive pay raise, and a promotion to partner if she would stay. She was in a state of shock, but then informed the other firm that she was staying at her current firm. By way of contrast, an engineering firm I am familiar with had an employee who had been there six years, and knew the company's very complex product inside and out, every nook and cranny. He was one of the only people who had such deep understanding of the system that he could fix any issues that might come up, hardware, firmware, software, everything. He gave his two weeks' notice, and then went to a different job. He's a very talented guy, who would command a very attractive offer, but his talent to the current company is vastly greater than his generic value on the market, because of his detailed knowledge of the product. Although he diligently documented his knowledge, the company was still left in a jam after his departure. It would have been great if the company had fought for him the way the law firm fought for the other individual described above. reply mbsa_cs 11 hours agoparent“but his talent to the current company is vastly greater than his generic value on the market” This has always been one of my fears. I would not want to become indispensable for a no name company while paying the price of being average to the market. reply metabagel 10 hours agorootparentThe point is that the market is willing to pay more, which seems counterintuitive since the employee should be much more valuable to their current employer. But, this does seem to happen with some frequency. reply lainga 15 hours agoparentprevWhat prevents engineering firms from acting like law firms? reply everforward 15 minutes agorootparentPeople may hate this, but people leaving is valuable to companies as a whole. Lawyers typically specialize and they work off the same body of work everywhere (the same set of laws). Having worked for 10 law firms doesn’t mean that they know something current employees don’t. Tech isn’t like that. Everywhere is different, many of us touch multiple specializations, the body of knowledge we need is always shifting. An engineer that has worked 10 places very likely does know things your current employees don’t, like different tools. Losing an engineer is bad for the individual business, but engineers moving around is good for businesses in general. reply rramadass 14 hours agorootparentprevWell... Because the Industry thinks that Management/Marketing/Sales are the important \"leaders\" and Engineering is just mere \"foot soldiers\" and hence replaceable/dispensable as needed. The above is justified as \"Business needs\", \"Investor returns\", \"Profit next quarter\" etc. reply hysan 11 hours agorootparentVery early on in my career, I had a few good mentors who all told me the same piece of advice - tech (IT, programming, QA, etc) are __cost centers__ to most businesses. No matter how valuable you are, your pay is not going to scale the same way no matter how good your performance reviews are. I’m very thankful for that advice because I was never shocked when raises were low or when finding out that new, lower leveled coworkers had higher starting salaries than me. My default mindset is that I’m fungible to the business. Work hard but also expect to fight to prove your worth. This is generally good advice in any career but I think it’s a must in tech. reply rramadass 9 hours agorootparentBut it wasn't like this in the beginning of the Industrial/Knowledge revolution. Engineers/Scientists were valued and founded companies with Engineering at its core with Management/Marketing/Sales/etc. playing their proper ancillary roles. It was much later that the system was manipulated to place Management on a pedestal (undeserved) citing market/financial reasons. And Engineers have allowed this to happen, take root and persist to this day. We need to change the above status-quo. However; the important point we need to be aware of is that in the current Economic/Financial System many events and their payoffs are no longer linear and that is what companies are trying to optimize for. The best explanation of this is Nassim Taleb's Mediocristan (non-scalable) vs Extremistan (scalable) dichotomy. This video Pareto, Power Laws, and Fat Tails—what they don’t teach you in STAT 101 is a very nice overview of the essential points : https://www.youtube.com/watch?v=Wcqt49dXtm8 reply metabagel 10 hours agorootparentprevWell, yeah, and generally you need to seek new employment regularly, because your current company is counting on you not recognizing your worth, whereas other companies will have to make competitive offers in order to win you over. reply CoastalCoder 13 hours agorootparentprev> What prevents engineering firms from acting like law firms? I wonder if it's harder to associate an employee's skill level with company profit. If most lawyer companies have established hourly billing rates for each employee, then the owners can more clearly see an employee's true value to the company? reply chii 12 hours agorootparentand yet for software consulting firms, this billing hours are also done the same. Yet, you don't see the same level of compensation raises unlike with law firms. I think it's true that Engineering is just mere \"foot soldiers\" and hence replaceable/dispensable as needed (as mentioned in another sibling comment here). reply lobsterthief 6 hours agorootparentprevAll attorneys that work for law firms have billable hours. Only agencies and consultancies have billable hours for engineers. It’s easier to say “we will lose $X if this person leaves” or “$Y will be at risk if they leave due to personal relationships” than it is to quantify an engineer’s revenue impact to the company. Hence the common cost center assumption. reply dzonga 7 hours agorootparentprevin a law firm, the lawyers are partners or very important people to the firm even if they're not partners. i.e they're not cogs in a wheel that can be replaced by 'management'. in as much engineers here, would like to believe otherwise -- most engineers at most firms are treated as replaceable / disposable resources. reply basch 12 hours agorootparentprevIn theory, this would become some type of exploitable game theory. Send out offer letters to companies most indispensable people, just to jack up your competitors labor costs. Arms race. Eventual mutually assured destruction. reply ttyprintk 8 hours agorootparentThe fraudulent offer letters notwithstanding, I think insiders would see this as an opportunity for Moneyball rather than a risk of unraveling in confusion. Moneyball as in an optimization technique when roles are static. Obviously this is generic because static data of any value inevitably ends up in a spreadsheet. Otherwise, I’m not sure game theory holds together here. reply fire_lake 11 hours agorootparentprevCompanies did engage in the reverse of this, to keep salaries down. reply imhoguy 9 hours agorootparentprevThat is capitalism. reply AnimalMuppet 1 hour agorootparentprevPartners at law firms know that the money comes from the lawyers, and they (probably) know who the rising stars are. Managers at engineering firms too often think that the money comes from the wisdom of the managers and the hustle of the marketers, not from the work of the engineers. This may be because partners at law firms are lawyers, but upper managers at engineering firms often are not engineers. reply Proziam 15 hours agorootparentprevManagement perceives people to be more replaceable than they are. Years of working in, or being the architect of, the company's core product will make you a true expert in it. But, from the company perspective, your value is based on the 'market rate' for your generically defined skills and experience. reply ttyprintk 9 hours agorootparentThis is precisely the reason for management; when priorities are internally competitive. reply 1oooqooq 15 hours agorootparentprevengineers either have patent quotas or are blue collar as far as any Enterprise is concerned. do you have patent quotas at your position? if not they are counting the days to replace you with a machine, someone overseas, a script, AI. depending on the decade. reply Ancalagon 12 hours agorootparentWhy is a lawyer position irreplaceable, but an engineering/blue collar one is not? Not trying to be spiteful or angry, just geniunely curious about the business logic and psychology behind that kind of decision making. Isn't every job replaceable? reply District5524 11 hours agorootparentI think the reason is not that lawyers are irreplaceable, to the contrary perhaps. The reason is most likely that law firms are always led by lawyers, while that's rarely true for firms where most engineers work (or for most other professions). Typcially, law firms can only be owned by lawyers due to regulatory constraints (the UK, Australia being a notable, but not particularly successful exception). While this rule restricts the possible size, scalability, efficiency and profitability of law firms compared to many other sectors, it can ensure a certain degree of independence (insulation) of the management from extra-professional influences. Like \"Das Kapital\" trying to change the way the firm works to achieve better returns in the next 5 years. That leads to law firm management and owners being composed mostly of people who have previously worked in that exact field and PROBABLY being better at judging the worker's worth in terms of potential revenue he/she may earn, the client trust they have and the chance that they may transfer that to another firm... Maybe law firms also have less of an illusion about what is valuable in their law firm as opposed to those companies relying on engineers who have or believe they have some special moat outside their people (technology, source code, inventory etc.). No professional law firm would have any illusions that their lawyers are special - perhaps outside trial lawyers and some very special field of litigation, the firm just needs burnout resistant cannon-fodder with the capacity to run for at least ten years, so they may acquire the sufficient experience, plus a number of bland human skills and patience in coping with other human beings. There never was a genuine myth of the \"10x lawyer\", that's something that only ChatGPT invents. (Sidenote: I wouldn't call an engineering job blue collar as long as you work in an office - WFH, we are all collarless workers now.) reply Ancalagon 1 hour agorootparentThat makes a lot of sense, thanks for explaining! reply rramadass 3 hours agorootparentprevTwo main reasons; 1) Power/Politics - This is basically Human Nature at work and institutionalized as Management/Leadership/etc to put themselves at the top. A lot of it is BS (see the books by https://jeffreypfeffer.com/) but unfortunately only the enlightened in the industry have woken up to this. It is also the case that in these domains many of the objectives are intangible/subjective and difficult to measure thus allowing the actors to create an illusion of \"Importance\". 2) Nature of Engineering - The output of any Engineering activity has a well-defined boundary. This makes it more tangible/manageable/measurable and reason about. All the main costs are paid upfront and once gizmo-x/software-y is done the recurring costs are generally pretty low. This gives the illusion that the Engineer is now not worth his pay compared to his current output and hence replaceable/dispensable based on bean counter calculations. It also doesn't help that Engineers do a pretty good job so that a product/software once released and accepted in the market is generally very stable and not in much need of rework. This is the reason \"Planned Obsolescence\", \"Subscription Model\" etc. were invented by the Industry. reply aorloff 13 hours agorootparentprevThe fact that (in theory) the computers are doing all the work. reply hintymad 16 hours agoprevAmazon used to have an internal Slack channel that allowed employees to share their total compensations anonymously. Thousands of people shared and the numbers were eye opening. Basically, if one was not a star and got consistently promoted every two or three years, she would not get compensated at market price. As a result, an L6 who stayed in the company for years often got lower total compensation than an L5 new hire who was actually an L4 before jumping to Amazon. Note: No L7 or above shared, or so as I knew. That said, like any large company, resources tend to concentrate to the top. L8 and plus were still compensated really well, but L7 were so so because L8 became the new L7 after waves of rapid promotions inside Amazon. reply pixelatedindex 15 hours agoparentI can relate to this. I was hired as an L4, got a promotion after 3 years to an L5. I later found out that my L5 TC was high-mid band for new L4s. To rub salt into the wound, I had to have “consistent” L5 level output (translates to about a year) before I could even apply for promotion and compensation only kicked in at the next review cycle. The ~13% salary bump was retroactively granted but RSUs were not, which was upsetting. Why try to get promoted? reply hintymad 15 hours agorootparentOn a personal level, promotion always means I have more freedom to do more interesting stuff (and lose freedom to some other stuff too, so there is a balance). Impact and validation of my ability are some other factors, though not that important. Now about the monetary side: the purpose of getting promoted is to get to a high enough level. Say L7 in Amazon. Since resources disproportionally concentrate to the top, L7+ got handsomely paid, especially when you are a top performer in that band. reply pixelatedindex 14 hours agorootparent> On a personal level, promotion always means I have more freedom to do more interesting stuff (and lose freedom to some other stuff too, so there is a balance). In my role I didn’t have the freedom and the opportunity because we were a small team as part of a sub-org - not much scope for multi-team impact. I have influenced some product roadmaps but for minor changes. Should I be hunting for chances that have more meat and convince others to see things my way? reply fire_lake 11 hours agoparentprevAny resources on these levels? Never worked for a FAANG so curious where I would sit. reply zelos 11 hours agorootparenthttps://www.levels.fyi/ . I don't know how accurate their data is, though. reply fire_lake 10 hours agorootparentI mean experience wise, not TC. Like “how do my skills compare to a Google L7?” reply VirusNewbie 1 hour agorootparentwhat do you want to know? (not L7 though). Mostly the level determines scope: L3 can work on a feature or part of a feature. L4 can own a large feature. L5 owns a project. L6 owns a large project or something that affects multiple projects. L7 is working across multiple teams to improve many teams projects. However, a project at rando big company might be very different than a project at a FAANG, so even these terms are incredibly nebulous. Generally, most FAANGs are very snobby in that even if you pass the interviews, if you don't come from another FAANG type company you get down leveled. I know multiple people this happened to( Interviewed for L7 EM, offer L6 EM. Interviewed for L6 SWE, offer at L5 SWE). Age and experience matter less though. I know L5s who are 29, and L5s who are in their late 50s. So if you interview for L6, unless you nail every part of every interview, expect L5. Same with L7, L4, etc. reply qwe----3 8 hours agorootparentprevSearch LinkedIn for senior staff engineers at google reply VirusNewbie 15 hours agoparentprevThis is true at Google too, because you get a large four year grant, while people who have been there are getting smaller refresher grants staggered. I am making more this year than managers one level higher than me because of stock increases, and the way my stock vests. reply BobbyTables2 14 hours agoparentprevExactly. I find companies celebrating 20-30 years of seniority to be very darkly humorous… reply gkoberger 17 hours agoprevThis is from 2021. Since then, they hired their Head of People a month later, and ~6 months later published a follow up: https://www.goethena.com/post/a-public-and-transparent-formu... reply yen223 16 hours agoparentMy previous company did something similar. They had employee pay structure listed in their handbook and is available to all employees. If I knew what level you were at, I knew how much you were making. I really liked it. They rarely had the problem where people felt they were under-compensated for doing the same job - a problem that I have since learnt is prevalent in other companies. reply jnwatson 16 hours agoparentprevThis is of course hogwash. \"Ethena provides generous equity in addition to cash compensation, but the details of equity are a bit trickier to make public.\" Publishing a formula for half your comp isn't useful. reply n_ary 12 hours agoprevManagement Mindset: As long as the employee is not complaining, why throw more money? Besides, they can't be \"that valuable and hard to replace\". I have even seen management who don't even bat an eye or goes extra mile to hire some 5-10x more expensive(even compared to market value) limited time contractor but zero interest or energy in putting up a fight to give a fair pay bump to one or more severely underpaid employee(s). The tainting is a mind game: an employee suddenly hears from their friend or random recruiter about some lucrative offer(usually at least 25-100% raise in pay), tries out their luck and lands an offer, but now manager(assuming a sensible person) needs to put a fight[1] with upper management to bring that same bump(or comparable). However, the relation is now tainted: employee now feels that injustice had been done and there is no guarantee that in future further raises/promotions will not come easy[2] and the manager might be looking into replacing them soon. The manager is now also sad that, they got under pressure by a leveraged employee+upper management will push to de-leverage such assets(yes a term managers use), and seek to replace such expensive assets soon. Now, both sides are running on bad trust and it gets immensely uncomfortable, hence the employee leaves anyways or get replaced by some shiny new hire who will command more than the original employee being replaced attained at their level. [1] This is often difficult, unless your manager is politically influential, because once you have neglected an employee too long, adjustment can be bit high, it is now difficult to justify, how suddenly a particular employee became so much valuable out of the blue. Human mind is wired in such a way that, slowly ascending a hill feels less tiring compared to ascending steep jumps, as the latter takes more energy(or in case of employee big pay bump). [2] Even though the adjustment being a correct valuation, any raise/bump of significance also brings expectations of more responsibilities and higher performance which is the same ol' undervaluing again in action. reply mppm 10 hours agoprevIt's always puzzled me why many tech companies seem so reluctant to give counter-offers to departing employees. Trying to pay as little as possible and not easily giving raises, even to their most productive employees, is at least somewhat understandable. But if a valuable employee is about to leave, possibly taking some critical knowledge with them, you'd think that a 50% raise should be on the table out of pure self-interest. So why doesn't this usually happen? Is it just part of keeping up the charade (a big raise is a tacit admission that they have been underpaying massively)? Is it to increase the barrier to negotiations (you have to actually leave rather than just get an offer)? Is it because HR people get more points for bringing in \"new talent\" rather than keeping the current workforce? Or is it just that neither HR nor management have any clue who their critical employees are, so they are unable to prioritize? reply michaelt 10 hours agoparentI've made some counter-offers in my time as a manager, but I've never had a counter-offer accepted. For a start: everyone resigns because of multiple factors, and money is of course one of them - but when handing in their resignation, in order to leave on a positive note they'll focus on factors outside of anyone's control. Usually people tell me they're leaving because of something like because they want to explore new challenges, or that they just feel that it's time for a change, or because a shorter commute will give them more time with their kids. Such reasons do not invite a counter-offer. You want to spend more time with your kids? Good for you! I won't try to argue you out of it. For another thing, when someone offers their resignation you only have a few hours to pull together a counter-offer - so on the occasions when I was able to make counter-offers, they were pretty meagre. I always get my team as close to the top of the salary range for their role as I can, so there's no headroom for anything big without getting a bunch approvals for a special exception. And finally, a lot of people who leave get offers that are kinda good, or at least good for their situation. If a kid's leaving my employer, who most people haven't heard of, for somewhere like OpenAI? That recognisable brand might well be great for their career. Leaving to get a PhD? Great, so long as they know what it really involves. And if I wouldn't council them to stay, I'm not going to be able to sell a counter-offer persuasively. reply ttyprintk 9 hours agorootparentGreat comment. Side note about PhDs: only some countries generously support you during it. And only some jobs are easier than it. I’ve only found people with multiple PhDs to have gained very related advanced skills. reply Arisaka1 10 hours agoparentprevI saw someone explaining how they would never accept a counteroffer because it proves how the company was fine with not giving them a raise they seemingly deserved until they finally found it somewhere else. reply Sebb767 10 hours agoparentprevI think a lot of your points play a role, but a major one is that when the employee is handing in his resignation, it's likely they have mentally already closed that chapter in their life and won't remain happy or productive. At best they leave soon anyway, at worst you're now paying a premium for worse work. reply rwmj 9 hours agorootparentFor the company that might still be a worthwhile trade-off. Gives the company time to train up replacements and avoids an immediate cliff-edge. reply lacker 3 hours agoparentprevI think counteroffers in your typical high-quality tech company are generally bad for three reasons. First, you should be giving people pretty good compensation packages. If you're underpaying massively in the first place, then you're going to consistently lose your best employees. Second, you should recognize who the best employees are, promote them, and pay them more. Third, you should be giving people at the same level very similar compensation packages. It will get a little bit off but you want to try to keep things fair. Given these rules, counteroffers lead to trouble. If you have ten equal engineers and one of them is overpaid 1.5x, do you just keep them overpaid by 1.5x the rest of their career as you promote them? Do you keep it a secret from the other ones? Etc etc. Usually when a counteroffer seems like it makes sense you are screwing up one of these principles of a well-run company. Maybe you're underpaying people but also not getting what you're paying for. You're paying 40th percentile pay and getting a 20th percentile team. You give every engineer an equal salary. Then your star engineer gets an offer from Google that doubles his pay. Yeah, then it makes sense to counteroffer. But it would be better to not be in this situation. reply rollcat 10 hours agoparentprevPerhaps it's because the ones who stay always pick up the slack, thus a single employee doesn't actually matter that much? Maybe it's because we still feel too entitled to consider collective action? reply knallfrosch 10 hours agoprevThe article ignores that \"the market\" works. Switching jobs, with new physical locations, new informal structures, new colleagues imposes a change cost on the software engineer too. That's why a lot of people stay. Additionally, paying every engineer the market rate wastes money on those that would have stayed anyway. As a similar problem, countries that pay for babies find that 98% of their money is wasted on couples that have babies anyway. The Economist says: \"schemes in Poland and France cost $1m-2m per extra birth\" https://www.economist.com/leaders/2024/05/23/why-paying-wome... Now that's a scale problem. Is one engineer staying really worth $10m? $1m? You'll pay way more than you think. reply ttyprintk 8 hours agoparentI had to think about your argument. So the underlying collapse in birth rates is actually among 19-year-old women who have chosen college and specifically because of low social mobility. Programs to help the marginal inconveniences of new parents don’t perform as well as directing that budget at social mobility. So let’s take a four-person company: marketing, HR, CEO, and engineer. Marketing, HR, and CEO share two beliefs: (1) if the engineer goes, the product will change. (2) no company has ever existed without marketing, HR and CEO. So, it’s not like they need a program parallel to these more-babies program; they just need to feel they could adapt to selling any variation of their product. Engineering has a different belief: imagine what we could do if we had another engineer slot in to tackle this backlog. That does look a little more like the more-babies program. PS> Article is https://archive.ph/nY2b1 reply codr7 16 hours agoprevFairness. I'll work hard for less money if it feels like we're in it together and the potential compensation is fairly distributed. But if someone pays me less just because they think they can get away with it, I'm out. reply atleastoptimal 16 hours agoprevHiring people is like gambling for companies, as in most tech companies hire some person on the off chance they're a 10x developer, though expect them to be a 1.5x one on average. Even if you're a 2x developer, you haven't lived up to the hypothetical 10x ideal to your employer, so they aren't willing to put in the extra money and effort to convince you to stay, there's more incentive to put that money into hiring the next potential 10x-er An analogy is, let's say you get a treasure box that can be opened for 100 dollars and may contain 1000 dollars. You open it and find 150 dollars. There is a smaller box inside which you can open for another 50 dollars which could contain at most 75 dollars but will most likely only contain 50 dollars. Do you spend those 50 dollars on opening the smaller box, or do you use the money to buy another larger chest that could contain 1000 dollars? reply ttyprintk 9 hours agoparentI don’t understand, from the beginning, why we weren’t talking about the 10x manager mathematically improving their team in aggregate? That has sports coach metaphors whereas the 10x engineer only has 19th century patent metaphors. reply rightbyte 12 hours agoparentprevThe chest need to have the risk of containing a pirate ghost that punches you in the face, for the analogy to make sense. Churn is a risk in that sense. Known average programmers have the quality of not punching you in the face. reply kaba0 12 hours agoparentprevFrankly, this 10x dev myth should just die. There are only at most 2x developers, and most ordinary people are just below the 1x factor. reply rsyring 11 hours agorootparent\"Facts and Fallacies of Software Engineering\" cited research indicating it can be as high as 28x. To get that number, you have to take into consideration terrible devs who are negative multipliers. I.e. the scale is not 1x - 10x. It's more like -10x - 10x. I've personally experienced development projects where there was easily a -5x - 5x difference between the least and most productive. I've seen productivity improve when devs have been removed from a project. reply kaba0 11 hours agorootparentMinus times plus is minus though :D reply dmichulke 10 hours agorootparentI suppose they couldn't call that new hire a -1000x developer either. reply sumedh 6 hours agorootparentprev> this 10x dev myth should just die. How would you rate someone like John Carmack? reply solardev 3 hours agorootparentHe overflows to -2147483648x. reply fragmede 12 hours agorootparentprevLike other idioms in the English language, it's not a mathematically accurate statement, but it persistents. Like a ten foot pole or a dime a dozen. reply treebeard901 15 hours agoprevMiddle and upper management never want to be put in a position to explain why they designed a team where it is not easy to just swap someone else in instead of paying more to keep someone. Usually if this happens, they will pay more to keep you until they find a way to solve this problem. reply sameermore 14 hours agoprevMy 2 cents - I think this is also a function of the domain the organisation operates in. IMHO, there are predominantly two types of companies - one where the technology creates the business vs. one where the business uses the technology as an enabler. For the former, think of companies like Boeing, nVidia or the Windows/Office divisions at Microsoft. Here, the product of technology is what brings in the money. For the latter, think of almost any \"IT company\" in the world which pieces solutions for clients in various businesses by leveraging existing technology/tooling and applying some amount of customisation. The former tend to value engineers more (exceptions are always there) as there are usually less number of competitors, but the risk of the employee switching and enriching the competitor's knowledge (and hence, business) is significant. The latter tend to look at engineers as replaceable (with little to medium effort) resources, and value their payroll expenses more than retaining top talent. reply ralferoo 13 hours agoprevI worked in the UK at a FAANG, so I was on a different bonus system, but my US colleagues had a very significant lock-in. Both your starting bonus and annual bonuses were implemented in terms of share grants that vested at 25% each year. I heard from several of these colleagues that the annual bonuses were often about the same as the base salary, so for some of these guys it was around $200k. So, at any given time they had between $150k and $200k locked up in un-vested shares that would be lost if they left the company. It's framed as a benefit rather than paying someone to stay, but ultimately it's structured this way so it serves the same purpose of providing a strong disincentive to leaving. reply pledg 6 hours agoparentWhich FAANG in the UK doesn't follow the same long term incentives with RSU as their US offices? All that I am aware of do for engineers. reply fire_lake 11 hours agoparentprevAnd this is why VCs love it when founders quit FAANG to work on their idea. It’s a strong signal. reply brianshaler 6 hours agoprev> \"With a market this hot\" Maybe the title should get a [2021] because it sounds like the market has cooled substantially in the last year or so. The article doesn't seem to take into consideration market cycles, assuming market rate always goes up at a rate that outpaces cost-of-living comp adjustments. While this may be the case more often than not, how are companies supposed to absorb market downturns? A salary reduction, if legal (?), seems almost as bad as redundancy except you risk being saddled with disgruntled workers who might decide to jump ship at the next moment that is convenient for them. reply MathMonkeyMan 16 hours agoprevI wonder if what's going on is that most of the work is done by people who joined within the last two years. Or maybe somebody leaving and having to be replaced by a new hire kind of rolls the dice on headcount, which low and mid-level managers might find interesting. The answer I like the most is that, as the article says, when you hire a new person you have to pay, on average, market rate. When you're evaluating whether to change the pay of Joe Lifer, you sometimes have to pay market rate but often you don't have to. Maybe you'd save money by giving raises to Joe Lifer, but who knows? You're hiring people anyway, so if Joe Lifer wants to leave, that's a shame, pay the new guy instead of him. reply siliconc0w 17 hours agoprevThe people running companies are mostly \"professional managers\" who see engineers as a fungible resource. If anything, tenure in the same role is mostly a negative signal. Why haven't you gamed the promotion system yet? Don't you want to grow into management or 'technical leadership' and spend your days in meetings? What is wrong with you? reply ttyprintk 9 hours agoparentI think the exceptions prove this rule. Bell Labs and Gore-Tex are broadly studied in business school as structures empowering technical staff to keep innovating. I believe your comment describes the case when the company is not expected to innovate. reply leros 16 hours agoprevI've heard the argument that an engineer who wants to go should be let go. They won't be motivated anymore even if you pay them more to stay. Not sure if that's valid. reply nly 11 hours agoparentSometimes people just need more money In the UK, having a family often results in one partner quiting work because they earn less after tax than the cost of daycare. Likewise interest rates on mortgages (which aren't fixed long term in the UK, unlike the US) have tripled and inflation has risen 20-25% over the last 3 years Adopting this policy of \"fire em if they ask for more\" is so evil. reply jillesvangurp 16 hours agoparentprevDepends. It helps to understand why they want to go to begin with. Basically, if you are having regular one on ones with your people on their ambitions, career development, etc. and they appear to be happy, them leaving would be a surprise. But the reality is that some people leave after a certain amount of frustration has been building up for a while and they aren't being listened to. That can be with a lack of promotion; or career paths that are being blocked because the company looks outside the own organization for filling roles without even thinking to promote people. Weak leadership/management can be very damaging. The whole Peter principle is a thing. If you get stuck below some incompetent burned out leadership, the best move is to just move sideways. Companies are bad at fixing themselves. The symptom is usually high staff turnover. Throwing more money at the problem doesn't necessarily fix anything if the problem is deeply entrenched management layers protecting themselves with that money instead of using it to replace themselves with better people. I used to have a great manager. We jokingly called him the cleaner because his career path was literally being parachuted into teams to fix them. All he did was listen to his team when he came in and then not shying away from doing surgical fixes. Including removing people or moving them sideways, promoting people, and just not being shy towards management about what needed fixing and why. He was a busy man. Lots of dysfunctional teams in that company and senior management had figured out he was good at this stuff. So he'd swoop in with the backing of management and then straighten things out and bruising some egos in the process. And of course the reality is that we are in a job market with record high employment. Job security has relatively low value and is mostly an illusion. Especially if you are good at what you do. People that are insecure put up with a lot of crap. But a lot of jobs in tech are the opposite. This manager ultimately moved sideways as well. Because he couldn't fix the mess above him. reply creesch 10 hours agoparentprevLike most simple arguments that make sense on the surface, reality is more complex. In some cases, this might be true, certainly if the engineer wants to go because of other reasons than pay. I feel like this argument might be used by managers or HR in companies who know that their company isn't the greatest work environment. reply bumby 16 hours agoparentprevI have a feeling it probably depends on the personality. People who are high on the conscientiousness scale will probably have a greater feeling of duty to still perform whereas people low on the agreeableness spectrum may coast out of spite. reply cryptos 8 hours agoprevI see one obstacle by this transparency approach: How to create a fair measure for \"impact\"? I would say that it is very hard to measure the actual impact of a senior developer. He gives advice here and there, he influences decisions in a good way, he asks the right questions, he recognizes risks early and so on. All that can hardly be measured. reply thot_experiment 14 hours agoprevIt's honestly wild. Just had someone leave because of an incredibly dumb money-saving corporate policy reason. The overall impact will DEFINITELY be that projects get delayed and we waste a ton of time training the new guy, it would have been much cheaper to fix by just paying him more (or fixing the actual benefits issue). It's mind boggling how short sighted some of these fucking decisions are. reply sceptical 12 hours agoprevSome companies do. At my previous company (I have since retired), I would get yearly outsized stock grants to motivate me to stay. I sincerely doubt I could have found matching compensation at another company. I never had any expectation of loyalty from the company and it didn't from me either, otherwise the stock grants would be unnecessary. I had some loyalty to my manager and had promised him to give a heads up before leaving the company. He knew I would retire once I hit my target. reply xilis 6 hours agoprevIn my experience money is absolutely part of the reason why people quit. Not everyone lives in places or is in circumstances where finances don't matter that much. reply moritz64 11 hours agoprevit's the same everywhere, not just with jobs and careers. contracts for (mobile) internet are always much cheaper for new customers than for old customers. or old customers don't automatically get the better conditions of new customers. and that although old customers are even more valuable, because they have already earned their acquisition costs. reply the_jeremy 15 hours agoprevThe issue no one here seems to be talking about is that paying people according to tenure is anticompetitive for the company on both sides. If you pay people more because they've been at your company longer (the way the follow-up post by Ethena describes[0]), you're explicitly choosing to pay them more than they can get elsewhere. You don't want to pay more than you have to for talent, so this is a hard sell to whomever manages the budget. On the flip side, if you're attempting to pay people in proportion to their worth to you as a company, you're going to be paying less than the competition, because the competition front-loads this money. A new engineer takes a few months or more to ramp up, so if you're making an attempt to pay engineers based on their impact, you will be outcompeted by companies willing to give sign-on bonuses and extra comp to convince people to switch. That's built into the plan of the four-year cliff - you pay them a lot to start with and hope you get the savings on the other side when they don't spend the effort to switch jobs later. Lastly, turnover isn't as much of a negative for the company as everyone seems to ascribe. Being forced to keep up with industry best practices and technologies to be able to recruit talent, to onboard new devs when someone leaves, and to retire unmaintainable legacy cruft when the creator leaves are not strictly negatives - they are risk reduction. That's not mentioning the benefit of fresh eyes and fresh ideas. (Honestly, I think all of this discussion on both sides ascribes too much rational decision-making to what is essentially cargo-culted hiring processes. The biggest companies copy decisions from each other to the point that it's literally collusion[1], and everyone else follows suit because they are smaller and don't have the economies of scale to make researching alternatives positive expected value. People at the top setting policies don't have lines of communication to front-line managers to be able to determine whether their particular company needs extra focus on retaining developers for business continuity reasons, so to the extent that it's a conscious decision at all, it's based on industry-wide studies or company-wide turnover statistics.) [0]: https://www.goethena.com/post/a-public-and-transparent-formu... [1]: https://www.theguardian.com/technology/2014/apr/24/apple-goo... reply colesantiago 17 hours agoprevIt is simple. Because they have no money. For startups, they want engineers to take a pay cut to work 996-like hours. Especially in the UK, where there is a running joke where companies complain about a “skills shortage” when in reality companies cannot find engineers at top universities that want to take a pay cut and work for less pay. reply yen223 16 hours agoparentThe no-money argument is less convincing to me, because I see this happen in well-financed companies. A very common scenario is that some person leaves, and is replaced by a new person who ends up getting paid more for doing the same role. The old person was on an old outdated rate and the new person is on a new corrected salary (that usually is higher) I suspect it's inertia. Companies don't make the effort to update old rates to match new market rates, because that requires active effort on part of the company. reply linotype 17 hours agoparentprevWhat do you think the UK could do to make the situation better aside from increasing pay? Or is that the only issue? reply whitehexagon 9 hours agorootparentIR35 was enough for me to leave the UK and never look back. Doesn't matter how much they pay if you have tax/legal uncertainty. reply dzonga 7 hours agorootparentwhere did you go to if you don't mind ? reply colesantiago 16 hours agorootparentprevUK companies do not respect software engineers or reward them properly (not even stock), even interns in other places get paid 5x more than a senior engineer in the UK. There is a also a huge cost of living issue in the UK which makes it dead on arrival for any software engineering job in the UK. I could say there should be more VC funding in the UK for startups but I don't think this would help either due to the above issues especially pay, as I don't see this at all. So there is nothing the UK can do to make the situation better other than talented engineers should either go into finance / hedge funds, leetcode hard and compete for FAANG jobs only or move to the US and don't look back. reply mmarq 11 hours agorootparent> UK companies do not respect software engineers or reward them properly (not even stock), even interns in other places get paid 5x more than a senior engineer in the UK. In monetary terms this is not true. A good software engineer can make 150-200K in the UK without going into finance or FAANG. In real terms you are better off making 50-80K in Germany, Spain, France, Poland, Italy, etc…, especially if you have children and don’t own property. reply philipwhiuk 11 hours agorootparentName a company paying 150-200K that’s not finance or FAANG? reply mpalfrey 9 hours agorootparentNot too many even in London really. reply mmarq 10 hours agorootparentprevAccording to levels.fyi: Personio, Deliveroo, Samsara, Atlassian, monday.com (and others, including my employer) I know many consultants that make 150K+ (which is 600£ per day) reply m_rpn 7 hours agorootparentGood for you, i work in finance in london and don't quite make that much, none of my friends in other places like JP, Goldman Sachs, Amazon, Instagram ecc does make 200k pounds/year base, maybe in tc yes. Skill issue probably. I would say 90-120k pounds/year base for a mid-senior engineer in FAANG/Finance is what most of us is being offered right now in London, based on my recent experience. What i feel is that many of us are being heavily undercut right now, me included, while consultancy keeps it's pace and everywhere outside London it's a bloodbath. reply mmarq 5 hours agorootparentRSUs and bonuses are part of compensation. reply haspok 5 hours agorootparentprevThere is no Atlassian salary data for the UK on levels.fyi. I think you are just quoting American salaries. Deliveroo L6 is 135k average, but I think it is more realistic to look at L5, which is just around 105k. Also, 600 a day as a contractor is nowhere near 150K+, it is 132K paid to your company's account (assuming 220 working days a year - but that's not a salary!), or you go via an umbrella and then it is even less. A 600 daily rate is pretty average in London, but only if you work for a bank - which classifies as \"finance\", I guess... But then you are not an employee, you are a contractor, which is very different. reply mmarq 5 hours agorootparentOn levels.fyi there is one Atlassian P60 engineer (senior? staff?) in London making 230K+. On L60-L50, I’m not saying that everybody makes 150K+; I’m saying that it’s not impossible for a good senior engineer (or staff or principal, as we call them nowadays) to make more than 150K at a non-FAANG company. Maybe I got my maths wrong with contractors. I never did it myself, but I know they do crazy things with taxes (eg hiring their wife, son, dog and plants, to reduce the tax bill) and that they don’t take holidays. So I multiplied 600 by 5 and then by 50, got 150K and I assumed they’d make more than an employee earning the same. reply haspok 5 hours agorootparentI'd left the city 5 years ago, just before IR35 hit, so my info is not quite up to date, but in general I would say that nobody can work without taking any vacations - both for health and legal reasons. Some contracts may even stipulate a maximum number of days you can work in a year (that's where my 220 number is from). And it used to be that you could do some tricks to lower your taxes, but there is a limit, and after the IR35 reforms many firms decided they don't want contractors, or they are pushing you inside IR35, which means PAYE taxes, and worse (because you still have to do the accounting for your company, pay corporation tax etc). So contractors are earning LESS than an employee with an equivalent salary, plus there are some extra burdens. It used to be that a regular engineer (without any management responsibilities) could achieve higher income in the short term being a contractor, but I'm not sure that is the case anymore. Outside London, if you can find a place willing to take you on as a contractor it may still be worth it, because your daily rate will be less, meaning you may not reach higher tax brackets, and compared to almost everyone else around you you would still be king. reply colesantiago 7 hours agorootparentprevApart for consultants which is what I recommend people get into for a high paying job, even looking at levels.fyi, the average pay is actually lower in the UK. Take Samsara, on average basis an entry level engineer in the US pays higher than a semi-senior SWE (SWE II) in the UK, taking into account the base as well for a senior also looks dismal for UK engineers. Even when these companies are public, UK salaries just don't seem to be competitive or appealing and this all just proves my point. Just go to the US, FAANG, finance or just be a consultant. reply mmarq 5 hours agorootparentSalaries in the US are much higher, but it doesn’t mean you can’t hit 150K of total compensation working for a non-FAANG company. Here’s one that advertised on this site: https://www.ycombinator.com/companies/meticulous/jobs/AkHpFa... Up to 160K plus 1% of equity. reply jnwatson 16 hours agorootparentprevSimply put, UK needs more companies run by software folks. Only software folks respect other software folks enough to pay them well. reply colesantiago 15 hours agorootparentPrecisely and this requires funding (as per my other point) but since the UK has a very very very risk averse culture to starting companies I do not see this changing unfortunately. reply port19 12 hours agoprevWhile the conclusion that engineers leave because they aren't paid enough does hold some truth, I'm much more compelled to cite the old \"People quit managers, not jobs\" saying. reply naffty_draw 10 hours agoprevHow can a company effectively measure an employee's impact? In my experience, when performance metrics are tied to salary, employees often manipulate the numbers to reflect a more favorable outcome, which may not accurately represent their true impact. reply m1keil 7 hours agoprevAll this effort, metrics, measuring impact, performance reviews, blah blah blah. You want to make sure your engineers paid top dollar? Tell them to go interview in other places. If you truely value them - beat whatever they were offered by X%. reply mtsolitary 10 hours agoprevI think this reads a bit differently today than 2021… should be in the post title reply fungiblecog 11 hours agoprevSo the new head of people will help come up with a magic remuneration formula… right… reply thedevilslawyer 8 hours agoparenthttps://www.goethena.com/post/a-public-and-transparent-formu... reply jppope 14 hours agoprevI wrote a related Article \"why aren't software developers paid more\" (https://jonpauluritis.com/articles/why-arent-developers-paid...) the reality is that we get comp way wrong... and its related to hiring, and its related to Venture Capital and related to a million other things reply holden_nelson 13 hours agoparentArticle not found reply SomewhatLikely 12 hours agorootparenthttps://jonpauluritis.com/articles/why-arent-developers-paid... reply jppope 4 hours agorootparentthank you... seems like a copy and paste error reply anothernewdude 17 hours agoprevBy the time the Engineer has gone through the effort to find some place to go to, it's well past time for the company to increase pay. They'd have to pay more than the difference, so they don't. And they'd have to be able to predict which engineers are about to leave (and churn models are terrible.) reply ryandrake 16 hours agoparentI don't know. Every job I've left, I would have stayed if they counter-offered for some X factor of my new offer. Some of those companies were terrible, but that just means the factor would have to be very large. But I have to admit, the worst job I've ever had, I'd gladly go back to for, say $1M/year. reply quantified 16 hours agoprevFrom 2021. reply graycat 17 hours agoprev\"The impact\" of an engineer? How to measure that? Hmm. Let me think .... Think of a new company the customers will \"love\". Start the company and, being a good engineer, be the CTO and CEO. \"Impact\"? The value of the new company. Pay? They OWN the new company. reply hiddencost 11 hours agoprevIt's challenging being in big tech right now. I spent a year applying for equivalent level jobs at peer institutions and startups. Finally got an offer from a startup that was heavily stock weighted. Took the offer to my boss and got a $100k raise within a week. TBH suspect I was being seriously underpaid. reply etchalon 13 hours agoprev1. Roles have budgets and companies only have so much cash to pay people. 2. Raises done arbitrarily to match market rates snowball across the organization. One 20% raise is going to turn into 2, or 3. See #1. 3. \"Losing time\" because of a junior hire is, oddly, less of a disruption than issue 2 becoming issue 1. reply VirusNewbie 14 hours agoprevI am making over 100k more this year than I expected at my current job due to stock increase, that’s pretty damn good retention. reply spl757 14 hours agoprevgreed reply dimitrios1 16 hours agoprevIn my experience, the job hopping for an increase only works up to senior / lead level (or engineering manager for manager counterpart). Anything after that requires time in role having a consistent, positive impact, and building up a portfolio that you can then use to sell yourself at the company for one of the coveted principal / staff / otherwise distinguished roles. reply ryandrake 16 hours agoparentMy first job hop was for about +33%. The next one was for +15%. The next one maybe +8%. Fast forward to today, my most recent job hop was probably even, maybe +0.5% at most. You definitely plateau at some point. reply Woshiwuja 12 hours agorootparenti think the plateau is the real market value, we were just underpaid before reply nextworddev 17 hours agoprevSupply and demand reply s-lambert 17 hours agoparentBut there's no supply for the people who know your product and codebase except for your existing employees, isn't that the whole point of paying them to stay? reply nextworddev 17 hours agorootparentThey can be onboarded and trained reply batshit_beaver 16 hours agorootparentIn my experience it's virtually impossible to reach the same level of familiarity with a codebase as the people who originally wrote it. This is not only due to years of accumulated complexity and debt, but also the fact that code simply does not capture business intent completely, let alone correctly or with full context. This is why projects tend to be put on maintenance mode or rewritten (piecemeal or from scratch) once their original owners are gone. This can be, but isn't always, expensive for the business' owners. reply PhilipRoman 9 hours agorootparentprevDepends heavily on the company and codebase. I've had situations when there is literally no way to arrive at the correct implementation unless you ask the guy who 8 years ago spent several months analyzing a particular unfixable hardware bug. The worst case is mass layoffs instead of natural gradual replacement, since entire teams leave with no time to document their area (and little motivation to do so) reply IX-103 15 hours agorootparentprevThat's right. You can just replace all that institutional knowledge and established social network infrastructure for a cost so low it's negligible. Not worth mentioning even. /s reply ath3nd 10 hours agorootparentprev> They can be onboarded and trained Over a period of 6 years, until they reach 30% of the knowledge/velocity of the people who wrote the original thing. /s Basically the company: - hires a new engineer on the new market rate so they get up spending extra money - spends extra time and resources to onboard the new engineer to a fraction of the productivity of the engineer that's had tenure Over the years, I used to think that companies are taking the hit on money and productivity in order to not have \"irreplaceable\" engineers. Better have replaceable cogs in the machine rather than important pillars of your company, right? Workers need to know their place, even if it costs you money and productivity. Nowadays, I just think it's the sheer incompetence and the stubborn insistence of managers in thinking that giving a new engineer the same title as the title of one of your tenured engineers will somehow magically mean they both can do the same things, at the same pace. I used to think that kind of company behavior was calculated malice, now I believe it's simply brutal stupidity. reply kennyloginz 14 hours agoprevSalary? reply jauntywundrkind 16 hours agoprevWith apologies, they are idiots. That they can't frelling figure out even remotely who is worthwhile to keep around or not is 300% on them, something so few orgs actually calibrate on, or do so based off awful anti-signals on, and it's embarrassing that this pathetic foolery has just gone on and on and on and on, with zero signs of improving. My boss loves me, swears I'm so full fo awesome knowledge & smarts. But every review, there's some VP pissed off I asked a question about why we were switching to OKRs or how to was going to work or how it would help or some security team pissed off because I have complained about NetSkope or their shitty undocumented USB drive blocking policies. There's always some fuck doing a shitty job offended that some engineer dare speak up, and my boss is telling me again and again it's costing me many dozens of $k in raises. It's so so so sad. Even if there aren't the dogshit losers, there's still so little discernment & taste. And there's so many people who can look busy and suck up, but actual deep knowledge is so so rarely respected. There's so many orgs that straight up deserve to fail, based on how bad they are at supporting their truest asset, their human resources. reply mixmastamyk 15 hours agoparentIntelligence is not enough, one needs people ski",
    "originSummary": [
      "Many tech companies don't pay engineers enough to retain them, leading to high turnover as developers seek better pay elsewhere.",
      "Ethena is addressing this issue by creating career paths and compensation structures that reward engineers generously based on their impact, aiming to encourage long tenures.",
      "Ethena's approach includes a compensation formula considering title, tenure, and performance, making it predictable and public to maintain talent density and reward impactful engineers."
    ],
    "commentSummary": [
      "Engineers often leave tech companies due to management frustrations rather than insufficient pay, challenging the assumption that money is the primary motivator.",
      "The debate includes views on financial independence, job satisfaction, and the impact of management, with some arguing that better management and fair compensation are key to retaining talent.",
      "Perspectives vary on whether doubling income significantly changes quality of life, highlighting the complexity of job satisfaction factors beyond just salary."
    ],
    "points": 164,
    "commentCount": 267,
    "retryCount": 0,
    "time": 1725583296
  },
  {
    "id": 41461850,
    "title": "LwIP – Lightweight IP Stack",
    "originLink": "https://www.nongnu.org/lwip/2_1_x/index.html",
    "originBody": "lwIP 2.1.0 Lightweight IP stack Main Page Related Pages Modules +Data Structures Data Structures +Data Fields +All _ a b c d e f g h i j k l m n o p q r s t u v w z +Variables _ a b c d e f g h i j k l m n o p q r s t u v w z +Files File List +Globals +All a b c d e f g h i l m n p r s t u w z +Functions a b d e h i l m n p r s t u z +Variables d h i l n r s t +Typedefs a b d e h i l m n p r s t u +Enumerations d e i l m n p r s +Enumerator e h i l m n p +Macros a b c d e f g h i l m n p r s t u w z •All Data Structures Files Functions Variables Typedefs Enumerations Enumerator Macros Modules Pages Overview INTRODUCTION lwIP is a small independent implementation of the TCP/IP protocol suite. The focus of the lwIP TCP/IP implementation is to reduce the RAM usage while still having a full scale TCP. This making lwIP suitable for use in embedded systems with tens of kilobytes of free RAM and room for around 40 kilobytes of code ROM. lwIP was originally developed by Adam Dunkels at the Computer and Networks Architectures (CNA) lab at the Swedish Institute of Computer Science (SICS) and is now developed and maintained by a worldwide network of developers. FEATURES * IP (Internet Protocol, IPv4 and IPv6) including packet forwarding over multiple network interfaces * ICMP (Internet Control Message Protocol) for network maintenance and debugging * IGMP (Internet Group Management Protocol) for multicast traffic management * MLD (Multicast listener discovery for IPv6). Aims to be compliant with RFC 2710. No support for MLDv2 * ND (Neighbor discovery and stateless address autoconfiguration for IPv6). Aims to be compliant with RFC 4861 (Neighbor discovery) and RFC 4862 (Address autoconfiguration) * DHCP, AutoIP/APIPA (Zeroconf) and (stateless) DHCPv6 * UDP (User Datagram Protocol) including experimental UDP-lite extensions * TCP (Transmission Control Protocol) with congestion control, RTT estimation fast recovery/fast retransmit and sending SACKs * raw/native API for enhanced performance * Optional Berkeley-like socket API * TLS: optional layered TCP (\"altcp\") for nearly transparent TLS for any TCP-based protocol (ported to mbedTLS) (see changelog for more info) * PPPoS and PPPoE (Point-to-point protocol over Serial/Ethernet) * DNS (Domain name resolver incl. mDNS) * 6LoWPAN (via IEEE 802.15.4, BLE or ZEP) APPLICATIONS * HTTP server with SSI and CGI (HTTPS via altcp) * SNMPv2c agent with MIB compiler (Simple Network Management Protocol), v3 via altcp * SNTP (Simple network time protocol) * NetBIOS name service responder * MDNS (Multicast DNS) responder * iPerf server implementation * MQTT client (TLS support via altcp) LICENSE lwIP is freely available under a BSD license. DEVELOPMENT lwIP has grown into an excellent TCP/IP stack for embedded devices, and developers using the stack often submit bug fixes, improvements, and additions to the stack to further increase its usefulness. Development of lwIP is hosted on Savannah, a central point for software development, maintenance and distribution. Everyone can help improve lwIP by use of Savannah's interface, Git and the mailing list. A core team of developers will commit changes to the Git source tree. The lwIP TCP/IP stack is maintained in the 'lwip' Git module and contributions (such as platform ports) are in the 'contrib' Git module. See doc/savannah.txt for details on Git server access for users and developers. The current Git trees are web-browsable: http://git.savannah.gnu.org/cgit/lwip.git http://git.savannah.gnu.org/cgit/lwip/lwip-contrib.git Submit patches and bugs via the lwIP project page: http://savannah.nongnu.org/projects/lwip/ Continuous integration builds (GCC, clang): https://travis-ci.org/yarrick/lwip-merged DOCUMENTATION Self documentation of the source code is regularly extracted from the current Git sources and is available from this web page: http://www.nongnu.org/lwip/ There is now a constantly growing wiki about lwIP at http://lwip.wikia.com/wiki/LwIP_Wiki Also, there are mailing lists you can subscribe at http://savannah.nongnu.org/mail/?group=lwip plus searchable archives: http://lists.nongnu.org/archive/html/lwip-users/ http://lists.nongnu.org/archive/html/lwip-devel/ lwIP was originally written by Adam Dunkels: http://dunkels.com/adam/ Reading Adam's papers, the files in docs/, browsing the source code documentation and browsing the mailing list archives is a good way to become familiar with the design of lwIP. Adam DunkelsLeon WoestenbergGenerated by 1.8.13",
    "commentLink": "https://news.ycombinator.com/item?id=41461850",
    "commentBody": "LwIP – Lightweight IP Stack (nongnu.org)152 points by fidotron 18 hours agohidepastfavorite49 comments bangaladore 22 minutes agoFor those looking for options like LwIP, consider NetXDuo [1] and its counterparts ThreadX, FileX, LevelX, and UsbX (I use TinyUSB instead). It has been one of the top commercial RTOS network stacks for, I think, 20 years. It moved hands a couple of times and now is supported by the Eclipse Foundation and is MIT-licensed. I'd use it over LwIP. [1] https://github.com/eclipse-threadx/netxduo reply gregfjohnson 4 hours agoprevWe used LwIP for a project some years ago, and found a very nice way to do system testing. The project involved multiple microcontrollers communicating over an internal LAN. They used a small embedded kernel named MicroCOS, with LwIP as the IP stack. We had cross-platform build tools set up, so we could build our stand-alone microprocessor applications either for native execution or with gcc, compiling to x64 code and executable on developer boxes. In the latter case, we implemented the lowest level link-layer part of LwIP using a mock, that used standard TCP/IP! We wrote a small TCP server and would spool up the micro-controller applications, which would then talk to each other on the developer machines as though they were running inside the actual system. This setup worked really well, and we used it for years during the development effort for the project. reply weinzierl 12 hours agoprevIP Stack is a bit of an understatement. It comes with enough to be a HTTP client, a HTTP server or a MQTT client - and that is the way I've seen it used in practice. It is more like the busybox of embedded networking, but with a much more convenient license. reply jacobmarble 16 hours agoprevAdam Dunkels also wrote (most of) Protothreads. https://dunkels.com/adam/pt/ reply cristoperb 15 hours agoparentHe also wrote uIP, the TCP/IP stack for the Contiki OS which is even smaller than LwIP https://en.wikipedia.org/wiki/UIP_(software) reply evanjrowley 8 hours agoprevWhat is nongnu.org and how does it relate to gnu.org? EDIT: I found an answer[0]. StevePerkins on May 22, 2016unvotehttp://savannah.gnu.org is a hosting site for \"official\" GNU software (i.e. sponsored by the Free Software Foundation). http://savannah.nongnu.org is a hosting site for \"community\" projects that are not sponsored by the FSF. [0] https://news.ycombinator.com/item?id=11747093 reply quailfarmer 13 hours agoprevI really like LWIP because it lets you use the same block of memory allocated by the Ethernet MAC DMA for the lifetime of the packet. You can really optimize the memory “pools” for your use case to reduce the number of memcpys. reply kneep 15 hours agoprevI guess it's the most used TCP/IP stack in resource constrained devices. But it seemed that for long, there's no competent alternative to it. https://github.com/FreeRTOS/FreeRTOS-Plus-TCP looks like a promising one. reply schnitzelbot 14 hours agoparentThere are high quality alternatives: - NetXDuo from ThreadX. It's Opensource for a while now. - Zephyr also brings its own stack reply bfrog 45 minutes agorootparentIt'd be interesting to see a breakdown of IP stacks for MCUs, their performance, how many security issues, etc. NetX, Zephyr, LwIP, and SmolTCP all sort of fit in this realm these days it seems like. Probably others too... but yeah hard to discern the differences at a high level without digging in. reply quailfarmer 13 hours agoparentprevLWIP integrates quite well with the FreeRTOS scheduler, I’ve used that combo before. How does the “plus-TCP” stack compare? reply schnitzelbot 13 hours agorootparentThe quality usually depends on the vendor adapting it to their silicon. If you look at ST and their STM32 the lwip integration is extremely bug ridden. Just read all the articles in their forum from \"Piranha\". I also struggled with extremely hard to debug bugs coming from their adaption layers. Lwip itself has a solid quality. reply aftbit 3 hours agorootparentThat sounds like ST. They make some really intriguing chips at good prices, but the tradeoff is that their hardware and software are full of bugs. reply high_priest 3 hours agorootparentprevCan you say, with which hardware does, the LWIP stack, work well? reply spacechild1 1 hour agoprevI first heard about LwIP when I worked with the ESP32. Espressiv seems to maintain its own fork with some ESP-specific patches: https://github.com/espressif/esp-lwip reply rramadass 5 hours agoprevFor those folks interested in implementing their own lightweight TCP/IP stack, Jeremy Bentham's book; TCP/IP Lean is a great resource. reply tony-allan 17 hours agoprevFrom the article: \"This making lwIP suitable for use in embedded systems with tens of kilobytes of free RAM and room for around 40 kilobytes of code ROM.\" reply tonyarkles 16 hours agoparentI've run it on a Cortex M4 with a built-in Ethernet MAC peripheral. It was shockingly simple to integrate... basically just needed to set up a receive ISR that handed packets to the LwIP stack and a transmit function that the LwIP stack could call to send packets. reply yuye 15 hours agorootparentThat simple? We've got an overseas software team that was tasked with doing the exact same. 6 months later and they still haven't got a working implementation. reply Thervicarl 11 hours agorootparentI have run it on a few hundred systems with Cortex R5 (used in a production context so demonstrated to be stable over tens of thousands of hours). At that time there was a reference port for the Hercules development board available on-line. It was mostly working straight out of the box. I just had to fix a few issues with the Halcogen generated files (since then, TI has fixed the bugs), configure the lwIP options (to have DHCP and only use UDP). Since then (7 years ago), I have not touched the code once. reply rramadass 13 hours agorootparentprevAre they integrating LwIP as it is or are they hacking its source to fit into your architecture? I did the latter a decade ago for a home-grown SoC and it is non-trivial. And then testing it with conformance/performance in mind takes more time. reply 1oooqooq 15 hours agorootparentprevthey are probably testing with more than the best case simple connection before declaring success, unlike everyone here. reply yuye 13 hours agorootparentI love your optimism. I've seen their implementation. It was horrible. We eventually took the project away from them and had the local team work on it. Also a fun story: they didn't use version control at all. When we eventually forced them to use git, they put the whole codebase in a .zip file and committed that. reply _joel 11 hours agorootparentI've worked with offshore companies that are similarly as bad, but then again there have been some that have been excellent. In your case, I don't know how they lasted 6 months if they're not committing to git etc, if that's the standard. They should be brought into the daily standups as 6 months to wait for some delivery seems a bit waterfally (apologies if this is a mischaracterisation). reply aleph_minus_one 9 hours agorootparent> They should be brought into the daily standups as 6 months to wait for some delivery seems a bit waterfally (apologies if this is a mischaracterisation). At least it it a clear mischaracterisation of waterfall: * https://changelog.com/posts/waterfall-doesnt-mean-what-you-t... * HN discussion: https://news.ycombinator.com/item?id=37405049 * http://bawiki.com/wiki/Waterfall.html * HN discussion: https://news.ycombinator.com/item?id=26760606 reply _joel 8 hours agorootparentThat's why I said waterfally reply pts_ 12 hours agorootparentprevYour onshore contract handlers were definitely difficult to work with. The number 1 reason for bad work are bad managers. See Boeing. reply rowanG077 8 hours agorootparentprevWell you need an Ethernet phy driver. If you have that that can work with the api of lwip it really is that easy. reply kaycebasques 17 hours agoprevPico W uses this, right? https://github.com/raspberrypi/pico-examples/blob/master/pic... reply MathMonkeyMan 16 hours agoparentYep!reply tptacek 16 hours agoprevSimilarly, for Go programmers: https://pkg.go.dev/inet.af/netstack reply Gazoche 10 hours agoparentAnd similarly, for Rust: https://github.com/smoltcp-rs/smoltcp I've been using it in a toy OS project and it works brilliantly. reply ranger_danger 16 hours agoparentprevalso gVisor has a tcp/ip stack, tun2socks uses it reply tptacek 12 hours agorootparentnetstack is the gVisor IP stack. :) reply mannyv 17 hours agoprevI love these tiny TCP stacks. I used to work with TinyTCP back when. What's interesting is if a search for tinytcp turns up a bunch of them. Awesome! Apparently there's no tiny ipv6 stack? reply convolvatron 16 hours agoparentLwip has v6 support reply RachelF 13 hours agoparentprevYes, it's impressive. I had to write one in assembly years ago. However, could only do UDP unfortunately as I didn't have enough memory for code and TCP buffers in 64kB. reply bfrog 48 minutes agoprevHow does LwIP compare to SmolTCP at this point? reply throwawayabcdef 16 hours agoprevsee also uip and contiki as well as the other creations from Mr. Dunkles: https://dunkels.com/adam/software.html reply stevefolta 17 hours agoprevWhat is nongnu.org, and what is its relationship to gnu.org? reply TheDong 17 hours agoparentnongnu.org is also run by the same people as gnu.org, but hosts software which isn't currently officially part of the gnu project. Basically, it's an area for software that is aligned with the GNU philosophy, might one day become part of the GNU project, but isn't officially currently part of the GNU project. https://savannah.nongnu.org/register/requirements.php https://savannah.nongnu.org/maintenance/GNUvsNonGNU/ reply lovidico 16 hours agoprevWhat’s the news value of this? LWIP is the most popular embedded network stack and has been around for ages. It also is awful to use and riddled with undocumented issues (in my experience, anyway) reply fargle 5 hours agoparentthe stack itself is extremely solid and works perfectly with reasonable performance. the codebase is extremely stable and has not had major changes, nor significant bugs in ages. the biggest problem with lwip is the documentation. you have doxygen API docs that tell you exactly what the interfaces are (and not much more than the reading the header filed does), you have a few pages of \"how to ...\" and higher level background. but often it's slightly bit rotted, subtly hasn't kept up with design changes. so it's difficult to learn - you effectively have to thoroughly read the code to get the big picture. and if you make a mistake in handling your application callbacks, you can easily leak buffers or create other problems. it's not \"awful to use\", it's actually very simple - once you understand it, which is seriously hampered by truly lacking documentation. the second issue is that the SoC vendors inevitably pay some overseas contractor to do the port and MAC/PHY drivers and example code, just like another [1] comment describes. that's where a lot of the instability and bugs come in. it's not lwip, it's the port that sucks. [1] https://news.ycombinator.com/item?id=41462602 reply unmole 13 hours agoparentprevIn my experience, it is a breeze to use. ~10 years ago, we managed to significantly cut down the cost of IP cameras by using lwIP with NuttX which allowed us to use a cheaper microcontroller instead of a more expensive chip that could run Linux. Plugging in a new TCP congestion control scheme was also straightforward. reply kragen 12 hours agoparentprevwhat kind of undocumented issues have you run into, and what did you have to do to deal with them? reply wmf 16 hours agoparentprevhttps://xkcd.com/1053/ (jinx) It's allowed to repost \"classic\" stuff on HN as long as it isn't too frequent. reply fragmede 16 hours agoparentprevhttps://xkcd.com/1053/ reply taspeotis 12 hours agoprev [–] Written in C you say? https://git.savannah.nongnu.org/cgit/lwip.git/log/?qt=grep&q... Then you've got stuff like this whose commit messages don't really hint at \"memory will leak to remote attackers through the network\" https://savannah.nongnu.org/bugs/?58553 reply tptacek 12 hours agoparent [–] This code is over 2 decades old. Pointing out that it's written in C is just about the least interesting thing you can say about it. https://web.archive.org/web/20160304140507/https://citeseerx... reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "lwIP 2.1.0 is a lightweight TCP/IP protocol suite designed to minimize RAM usage, making it ideal for embedded systems with limited resources.",
      "It supports a wide range of networking features, including IPv4/IPv6, DHCP, TCP/UDP, and optional TLS via mbedTLS, among others.",
      "Originally developed by Adam Dunkels, lwIP is now maintained by a global network of developers and is available under a BSD license."
    ],
    "commentSummary": [
      "LwIP (Lightweight IP) is a popular TCP/IP stack designed for embedded systems with limited resources, such as tens of kilobytes of RAM and around 40 kilobytes of code ROM.",
      "Alternatives to LwIP include NetXDuo, which is now MIT-licensed and supported by the Eclipse Foundation, and other stacks like Zephyr and SmolTCP.",
      "LwIP is widely used in resource-constrained devices and integrates well with FreeRTOS, but it has been criticized for poor documentation and issues with vendor-specific ports and drivers."
    ],
    "points": 152,
    "commentCount": 49,
    "retryCount": 0,
    "time": 1725584406
  },
  {
    "id": 41464334,
    "title": "Intent to unship: HTTP/2 Push",
    "originLink": "https://groups.google.com/a/mozilla.org/g/dev-platform/c/vU9hJg343U8/m/4cZsHz7TAQAJ",
    "originBody": "Groups Conversations All groups and messages Sign in     Intent to unship: HTTP/2 Push 13,624 views Skip to first unread message Valentin Gosu unread, Sep 4, 2024, 2:44:13 PM (2 days ago)    to dev-pl...@mozilla.org In the next few days I intend to disable HTTP/2 Push on all platforms. Status in other browsers is: Safari: although I couldn't find any resources regarding the deprecation of HTTP/2 Push in Safari, local testing with a nodejs server indicates that Safari rejects push streams in the current version. Chrome: Disabled HTTP/2 push in Chrome 106 (September 2022) Chrome Platform Status Bug to remove: 1915848 - Pref off HTTP/2 push Two years ago Chrome disabled HTTP/2 push citing low use, and recommending the rel=\"preload\" and 103 Early hints as a replacement. Firefox has continued supporting HTTP/2 push as this wasn't too large of an effort until recently. However in the past few months we've encountered some webcompat bugs only affecting Firefox through HTTP/2 push: bug 1915830. This means that if webservers and websites use push and don't test in Firefox, this feature can potentially cause websites to stop working only in Firefox (eg bug 1913100) Though we will pref it off now, the implementation will remain in the tree for a while longer. Most likely we will remove it completely before we branch for ESR 140 in the spring of next year. Please let me know if you have any concerns. Thanks!  Reply all  Reply to author  Forward",
    "commentLink": "https://news.ycombinator.com/item?id=41464334",
    "commentBody": "Intent to unship: HTTP/2 Push (groups.google.com)138 points by todsacerdoti 9 hours agohidepastfavorite78 comments saurik 4 hours agoIt is extremely annoying that all of this sudden discovery that http2 push didn't work hasn't come with some kind of apology to everyone out here who had tried to explain before why this wouldn't work and why it would be a dangerous waste of time just to be shouted down for years by the people insisting it was going to be epic as the much-smarter people at Google knew what they were doing and really needed this so we should just let them ram it into the spec. We should be extremely conservative about what we put in the spec and stop just throwing in speculative stretch goals because some people at Google thought it's a good idea. reply _heimdall 7 hours agoprevI never found the explanations given for why HTTP/2 Push failed compelling. Google usually just refers to a blog post from Jake Archibald [1], but that post seems to call out all the ways browsers poorly implemented it rather than reasons the protocol itself wouldn't work. Browsers already support preload links, which should function effectively the same as a Push header. Why couldn't that same code have been used for Push, including all the existing handling for things like caching and authorization headers that Jake called out as challenges with the 2017 implementations? [1] https://jakearchibald.com/2017/h2-push-tougher-than-i-though... reply aseipp 4 hours agoparentPreload headers DO NOT function \"effectively the same\" the same as HTTP/2 Push. Yes they have similar outcomes, no that does mean they function the same. They are related, but are not actually that similar except in the most trivial ways like using the word \"Preload\" - HTTP/2 Push: When the server thinks a client needs the resource, it pushes it into the client proactively, avoiding one round trip for the resource. The goal is to improve latency by sending the resource actively, independently of any DOM->render pipeline that would trigger the fetch. - Preload header: When the client requests a resource, the server delivers the page body, but it also tells it what it can load in parallel before parsing or JS eval. The goal is to improve latency by moving up the \"fetch\" stage, before the parse->DOM->render pipeline that would trigger the fetch. And beyond those two, over the past few years a new kid has appeared on the block: - 301 Early Hints: When the client requests a resource, the server sends a Preload hint telling it what to load before it even finishes generating the response. A 301 is delivered before the body is fully delivered, before even the first byte. The goal is to improve latency even further by moving the fetch stage up even earlier in the pipeline. Yes, they attack the same soft spot, but mechanically there is a VERY big difference between server-initialization and client-initialization, and between along-with-body and before-first-byte. (Obviously, 301s and Preloads are closer than anything.) Ignore the security stuff. The simplest reason HTTP/2 Push isn't so great is because it's not very good at accomplishing its goal. This is because browsers employ an ancient technique, originally written in hieroglyphs, called \"caching\", which means that the browser just won't request a resource if it already has it. A cache hit is the ultimate reduction in latency. But only the client browser knows what is in its cache, the server has no idea. With Push, you run a very real possibility of sending resources that aren't needed, overall losing efficiency. With 301s/preloads, you at worst receive a few wasted bytes from the useless headers. It's both much easier to get right, and much less costly if you get it wrong. It's also complicated to implement on top of all the other stuff. Preloads and 301s are vastly simpler and much more targeted additions to the HTTP stack, and HTTP is only useful insofar as implementations are compatible. So 301s/Preload are significantly easier to support and achieve much of the same purported benefits. reply CodesInChaos 2 hours agorootparent\"Early Hints\" is 103. 301 is \"moved permanently\". reply mariusor 23 minutes agorootparentI suspect parent was thinking of 304 Not Modified, which is the status header usually associated with caching. reply youngtaff 6 hours agoparentprevFor security reasons pushed resources have to be treated as a special case until they're claimed by the page, amongst other things this means they need a separate cache until they're claimed reply _heimdall 6 hours agorootparentThat's an interesting challenge. Is the Push header being included on the document request not enough to consider it a secure resource? I could see this being a concern with secondary requests that haven't been claimed by the document, say a stylesheet with Push headers to preload font files. I'm not quite sure how it would get into that state with the stylesheet being requested without the page having claimed the request, but is that the security concern? reply youngtaff 6 hours agorootparentJake mentions one of the reasons in his post (that's linked elsewhere) Push is on a connection (not request) basis so if the connection is authoritative for multiple hosts i.e. they share a cert in the way low cost Cloudflare plans used to (perhaps still do?) then you can push resources for another site Even without that issue you wouldn't want every resource that gets pushed to end up in the browser cache by default as it leaves open all sorts of malicious behavior e.g. just keep pushing until the browser cache is full of crap etc. reply paulddraper 6 hours agorootparentprevExplain why security demands a separate cache? reply bawolff 6 hours agorootparentCache poisioning attacks. reply paulddraper 5 hours agorootparentOh I see. Push was not limited to the same host. Which would have been an easy fix. reply bawolff 4 hours agorootparentConnections arent limited to the same (virtual) host. Additionally, to prevent cross page tracking, browsers use a separate cache for subresources loaded from different top level domains. Anyways, it is trickier than it sounds at first glance. reply paulddraper 1 hour agorootparent> Connections arent limited to the same (virtual) host. Huh? Doesn't HTTPS and SNI effectively require that? reply bawolff 1 hour agorootparentIts a minor point, since the rules are quite strict so its probably not a security issue, but no, due to connection coalescing, one connection can serve multiple virtual hosts. See https://daniel.haxx.se/blog/2016/08/18/http2-connection-coal... reply jauntywundrkind 2 hours agoparentprevI find the excuse for unshipping especially ridiculous because developers never had a good chance to make use of Push! We can't see Pushes coming at us, cant be responsive to them! https://github.com/whatwg/fetch/issues/51 It also feels like the use case everyone was focusing on/acknowlegding of content delivery had plenty of opportunities left. There weren't very many visible public attempts! Very few people had access to libraries or starting places to begin to jump in, figure out what to Push! reply lol768 7 hours agoprevI'm a bit sad to finally see the death of HTTP/2 Push. It was a neat idea, with poor framework uptake that never really got the attention I think it could've benefitted from. The .NET folks never bothered shipping it; there was a basic implementation in nginx. It was always hamstrung by lack of cache digests too. Chrome ultimately got rid of it with a justification partially along the lines of \"nobody would notice anyway\" and because re-architecting everything to use UDP (because that works great with NAT, doesn't it?) was apparently more important. reply kstrauser 5 hours agoparentI never had problems with UDP and NAT, but if that’s the thing that gets people annoyed enough to migrate to IPv6, I’ll shut my mouth and smile. reply LegionMammal978 2 hours agorootparentI'd imagine that an IPv6 host behind a stateful firewall would have very similar issues with UDP connection tracking. reply kstrauser 36 minutes agorootparentPerhaps the main difference is that the average IPv6-configured firewall device is newer than the average NAT device, having become common much later. reply 01HNNWZ0MV43FF 1 hour agorootparentprevIt might require a firmware update but I see a clear text connection if here in the quic example https://quic.xargs.org/ Assuming that the IP port 4-tuple is not enough I never have trouble on my networks with QUIC or other popular udp protocols like WebRTC or DNS reply LegionMammal978 1 hour agorootparentI also haven't had any issues with UDP behind an IPv4 NAT, nor behind an IPv6 firewall. I'm just suggesting that at whatever rate people do have issues with UDP behind an IPv4 NAT, people would similarly have issues behind an IPv6 firewall. reply pornel 7 hours agoprevYou can get some of this speed back with HTTP/3 0-RTT start, and use 103 Early Hints to make browsers preload assets early. This combo has an advantage of being semantically backwards-compatible with HTTP/1 (reverse proxies, load balancers). reply rrr_oh_man 8 hours agoprev> This means that if webservers and websites use push and don't test in Firefox, this feature can potentially cause websites to stop working only in Firefox That is one reading of the situation. The other would be: All other browsers reject HTTP/2 Push & gracefully ignore it, but Firefox majorly trips up in edge cases. (quote: «It seems that Firefox is resetting the connection because it encounters an uppercase character in the header names»). reply jorams 7 hours agoparentYour reading doesn't really make sense. Other browsers don't implement the specification. Firefox does. The specification is very explicit about how this violation should be treated. Those webservers and websites have a broken implementation. Had they tested with any spec compliant client they would have noticed it being broken. reply rdsubhas 3 hours agoparentprevThey make it clear in their post: > Firefox has continued supporting HTTP/2 push as this wasn't too large of an effort until recently. > However in the past few months we've encountered some webcompat bugs only affecting Firefox through HTTP/2 push They are clearly saying that recently there has been bug report, and this blog post is to do exactly what you mentioned as other browsers do: reject H2 push and gracefully ignore it. There does not appear to be any hiding here. reply chrismorgan 7 hours agoparentprevIt could just as easily have gone the other way: a new spec implemented only in one browser (typically Chrome, as it most frequently ships things first, often incomplete) and, badly implemented by a server, causing such a problem. reply swiftcoder 3 hours agorootparentI mean, that's pretty much how we got HTTP/2 Push as a standard in the first place, so it's somewhat fitting we lose it the same way. reply dang 2 hours agoprevRelated (I think). Others? Removing HTTP/2 Server Push from Chrome - https://news.ycombinator.com/item?id=32522926 - Aug 2022 (201 comments) A Study of HTTP/2’s Server Push Performance Potential - https://news.ycombinator.com/item?id=32097013 - July 2022 (2 comments) HTTP/2 Push is dead - https://news.ycombinator.com/item?id=25283971 - Dec 2020 (168 comments) Blink: Intent to Remove: HTTP/2 and gQUIC server push - https://news.ycombinator.com/item?id=25064855 - Nov 2020 (133 comments) We're considering removing HTTP/2 Server Push support - https://news.ycombinator.com/item?id=24591815 - Sept 2020 (2 comments) Performance Testing HTTP/1.1 vs. HTTP/2 vs. HTTP/2 and Server Push for REST APIs - https://news.ycombinator.com/item?id=21937799 - Jan 2020 (71 comments) How HTTP/2 Pushes the Web - https://news.ycombinator.com/item?id=18216495 - Oct 2018 (16 comments) Nginx HTTP/2 server push support - https://news.ycombinator.com/item?id=16365413 - Feb 2018 (63 comments) HTTP/2 Server Push on Netlify - https://news.ycombinator.com/item?id=14798271 - July 2017 (23 comments) The browser bugs and edge cases of HTTP/2 push - https://news.ycombinator.com/item?id=14445728 - May 2017 (20 comments) A Guide to HTTP/2 Server Push - https://news.ycombinator.com/item?id=14077955 - April 2017 (59 comments) HTTP/2 Server Push - https://news.ycombinator.com/item?id=13990074 - March 2017 (2 comments) HTTP/2 Server Push and ASP.NET MVC – Cache Digest - https://news.ycombinator.com/item?id=13659962 - Feb 2017 (9 comments) Accelerating Node.js Applications with HTTP/2 Server Push - https://news.ycombinator.com/item?id=12296922 - Aug 2016 (6 comments) Rules of Thumb for HTTP/2 Push - https://news.ycombinator.com/item?id=12224258 - Aug 2016 (25 comments) Google's Rules of Thumb for HTTP/2 Push - https://news.ycombinator.com/item?id=12223352 - Aug 2016 (2 comments) HTTP/2 Protocol for iOS Push Notifications - https://news.ycombinator.com/item?id=11175980 - Feb 2016 (13 comments) reply KaiserPro 8 hours agoprevWhy wasn't push adopted more widely? It was one of the big reasons HTTP2 was meant to be a game changer (despite the massive flaws) Was it a lack of browser support? or that it didn't really work with CDNs? reply JackSlateur 7 hours agoparentServer push was never massively deployed because they may be harmful : the server pushes assets that may be needed by the client, but also may be already cached by the client. In the later case, this is a harmful burden, especially on mobile etc. The server is never able to truly know if the asset is actually required by the client Early hint is better, probably: the server quickly tells the client it will need those assets. The client can then decide if they must be fetched, or if they are already available. reply alex_duf 7 hours agoparentprevI looked into using this, but changed my mind. Say you get a hit on Index.html. you probably want to push script.js and style.css. So now you've pushed a few hundred kbits. Now, the user comes back and asks for index.html again: do you send everything again? Surely the resources are still in the user's cache. If you don't, how do you know what to send? Only the user's browser knows what's in can't and what's not. So you face the choice: speed up first visits but waste bandwidth for subsequent visits, out slow down first visits but speed up subsequent visits. reply swiftcoder 8 hours agoparentprevYou might like the more detailed breakdown published when Chrome decided not to support push: https://developer.chrome.com/blog/removing-push/ reply Aachen 7 hours agorootparentAll that says (that is relevant to the posed question) is: > it was problematic as Jake Archibald wrote about previously, and the performance benefits were often difficult to realize Edit: Clicking through to the linked post by Jake, , problems mentioned are - browsers had buggy implementations which wouldn't (always) use the pushed data. In that case, you've (as a web server) kept the connection busy and sent bytes for nothing - browsers ignore max-age when using push cache. Given that the time between pushing and using is usuallyThere are some pretty gnarly bugs around HTTP/2 push right now, but once those are fixed I think it becomes ideal for the kinds of assets we currently inline, especially render-critical CSS. This doesn't sound like a reason to remove push altogether. Quite the opposite? reply dwaite 54 minutes agorootparentMy reasoning for never pursuing push is that a lot of semantics become implicit in the business requirements of the application itself. How does the server know it should push or not push data based on the client state, e.g. should it be pushing resources which could potentially already be in cache. That leads you to one of two paths: 1. The web content needed should be communicated to the server by the client; either requests are made with Fetch with additional parameters, or via a service worker which can then populate the cache itself. However, once you are supplying logic in the page to handle these resources, there are other approaches you can make - such as having a service worker populate the cache by downloading a single archive and unpacking it. 2. The other option would be for content which is specifically never meant to be cached, such as live updates of a sporting event. There is no API however to support this, and we already do have things like WebSocket to do this. reply pas 7 hours agorootparentprevin retrospect it seems the semantics got overcomplicated, which led to partial implementations (and of course many bugs and confusing and hard technical questions), which eventually led to implementation projects getting abandoned. and, probably in situations where the benefit of decreasing \"time to first render\" is big enough, there it makes sense to have a server that is coupled to the various low-level bits (load balancer connection tracking info, TLS session info, User Agent header, and Cookie of course) and for new sessions it can produce an optimized response payload. reply bawolff 7 hours agorootparentprevWell there is a link with more info about what Jake wrote. The tl;dr: its hard to predict ahead of time what resources browsers really need, so often you send the wrong thing or the non ideal thing. End result is the practical performance benefit was much smaller than the theoretical one. reply kijin 7 hours agorootparentThe practical benefit is virtually nil because HTTP already has a proven mechanism for caching and preloading. By the time you visit the second page on a multi-page site, you are likely to have almost all stylesheets, scripts, and common images already cached. This means you will reject almost all of the resource the server tries to push to you. Even on the first page, modern browsers are very quick to identify resources they need to load, both from headers and the early parts of the document. They load those resources concurrently while they are still parsing the document, so they are rarely blocked for a noticeable time. Meanwhile, single-page sites have evolved to a point where the entire application is contained in one or two heavily optimized, minified scripts. You just load that one script and you're done. Most small images these days are SVG embedded right in the source code, so again, there's little need to push other resources. The only time a modern website makes you to load a lot of unanticipated resources is when those resources are used for tracking and advertising. They can't be pushed because they live on different origins. reply bawolff 6 hours agorootparent> Even on the first page, modern browsers are very quick to identify resources they need to load, both from headers and the early parts of the document. The premise of http2 push is that those resources could be sent before the first round trip even occured - before any link headers or request body is available. Which is kind of two things - the round trip of network latency and also the backend latency of how long it takes to make the resource. The solution was to give up on the round trip network latency, but concentrate on backend latency. Which you can do by sending link headers before the resource is finalized, or if you cant even do that, by sending a 103 response. The new solutions are still leaving some latency on the table. Price to be paid for simplicity. The other side of that coin, is if you really care about the latency of those resources for clients who dont have them cached, you can just embed them in the html document. reply ndriscoll 5 hours agorootparentBackend latency should be negligible next to RTT latency though. If RTT is on the order of 100 ms, shaving off 5-10 ms for request processing doesn't help much. I don't know the history here, but nginx seemed to have a solution (which was removed) to be able to conditionally attach pushes to a location directive based on a cookie, and then set that cookie to know if it was a first visit. Seems simple enough? Did it actually never work or something? reply bawolff 3 hours agorootparent> Backend latency should be negligible next to RTT latency though \"Should\" is doing a lot of work there. For dynamic resources this is often very not true. On the other hand i suppose the landing page is often highly optimized. The cookie approach does seem like the most common approach to that problem. I have no idea how well it worked. reply kijin 3 hours agorootparentA modern SPA is often just a static HTML page that loads a whole bunch of minified JS. Backend latency is indeed negligible in that case, compared to the RTT for the multiple MB of scripts that you need to load, parse and execute. A more traditional multi-page website, on the other hand, can benefit a lot from putting a CDN in front of it. Once the main dynamic resource has been generated, the rest of your assets can be loaded from edge servers closer to your users. When RTT is on the order of 10ms, it doesn't really matter whether you push or pull. reply bawolff 1 hour agorootparentSure there are scenarios where it doesn't really matter, but that is not everyone. Edge caching is great if resources can be shared. Sometimes resources are per-user. SPA's that involve dynamic per user content still have to load it to show the user anything interesting. Edge caching is definitely not 10ms for everyone. Depending on who you are targeting that could be a reasonable assumption, but it is definitely not true of the world at large. reply acdha 6 hours agorootparentprev> Meanwhile, single-page sites have evolved to a point where the entire application is contained in one or two heavily optimized, minified scripts. You just load that one script and you're done. Most small images these days are SVG embedded right in the source code, so again, there's little need to push other resources. This isn’t true of most websites - look at the developer tools traces - because it’s terrible for performance to optimize for the IE6-era browser design. With those kind of bundles, you have to push a ton of content which didn’t change any time one byte of any resource changes. Since HTTP/2 substantially reduced the cost of multiple requests any site which has repeat visitors will benefit enormously from letting the bulk of the content which hadn’t changed be cached and only refetching the few responses which actually need to be updated. reply kijin 6 hours agorootparentNot saying it's good design, but a huge bundle is the default for a lot of frontend frameworks these days. :( On the other hand, sites with lots of separate static assets are often split into multiple origins. Images from a CDN, fonts and libraries from another CDN, and API endpoints on a \"serverless\" platform somewhere else. These sites won't benefit much from having Push enabled, either. Of course with HTTP/2 it's better to serve as many resources as possible from a single origin. But that doesn't sit well with the recent trend of sprinkling your stuff across buckets and lambdas, duct-taped together with CORS. Good ol' Cache-Control still does most of the heavy lifting there. reply acdha 6 hours agorootparentDid you have a particular framework in mind? None of the ones I’ve worked with do that by default and I very, very rarely see even close to a single bundle on a website any more. A decade ago it was more common since HTTP/2 hadn’t shipped and IE6 was still a concern but the cache wins are compelling and well known by now. reply kijin 5 hours agorootparentI don't have much experience fine-tuning the build options, but last time I tried a new project with default settings, React produced 2 large chunks, and Svelte gave me a single .js file. reply sigseg1v 4 hours agorootparentSame thing with Vue.js reply Aachen 7 hours agorootparentprevI was indeed reading that while taking notes. The comment is now updated with those. I didn't read in the post what you said its tldr is supposed to be; maybe I read over it reply mhitza 7 hours agoparentprev> Why wasn't push adopted more widely? It wasn't given enough time, would be my guess. First Apache release that included HTTP2 support was in late 2015, same year HTTP2 RFC finished going through the process. In 2017 there still was browser inconsistency on how server push was handled (one of the reference articles in the sibling comment link). nginx implemented support for push somewhere around 2018 (based on wikipedia information). All those changes need to trickle down. Versions available in stable distros, config defaults etc. First time I've enabled http2 on my Apache servers, was in 2020 (and there are likely application servers out there that still don't support it directly in 2024). reply WhyNotHugo 5 hours agoparentprevIt’s really hard to architect around http push. Say I have a website in Python/Django, where I know that a page uses certain images. In order to use http push, my app would need to stream those images itself, rather than let a CDN or even Nginx do it. I suppose that some solution could have been implemented so that my Python app can tell nginx to stream certain static resources over a given connection… but the tools for that never surfaced. Most HTTP frameworks don’t support push. reply znpy 7 hours agoparentprev> It was one of the big reasons HTTP2 was meant to be a game changer Probably because it's a game changer only if you're at google/amazon/meta (or slightly smaller) scale. For everybody else its largely a huge complexity addition, and it's essentially ignored. reply KaiserPro 5 hours agorootparentWe enabled HTTP2 in 2015 on the $big_financial_news_site. We had some influential JS people that were very keen to roll it out (they mostly ended up fastly after). I did warn that it would degrade all but the high bandwidth experience. It took a long time for them to \"understand\" the data, and that HTTP2 was not very useful, especially when compared the impact of changing CDN, or optimising for CDN caching. reply bawolff 6 hours agorootparentprevI suspect the issue is it wasn't really a game changer at google scale either. reply liveoneggs 7 hours agoparentprevCan you explain the problem is solved better than Link headers, websockets, or SSE? reply SahAssar 3 hours agorootparentWebsockets and SSE are completely unrelated. Link headers can be used for preload, but until 103 Early Hints it could not be sent before the body content was processed on the server (unless your body content did not affect your headers, which is quite rare). reply SSLy 9 hours agoprev… in Firefox. reply jprjr_ 8 hours agoparentIt seems to be removed everywhere else already. reply SSLy 8 hours agorootparentyeah, but the submission title could be clearer. reply youngtaff 7 hours agoprevRemember talking to Mike Belshe (SPDY, and H2 spec co-author) before H2 was standardised and even then they were trying to get it dropped from H2 as the benefits were hard to realise, there were plenty of issues and foot guns too One of the largest issues was 'over-pushing' through either sending something that was already in the browser cache, or just trying to push way too much non-critical content (I've seen some truly bad cases of push actually making the page slower to load) There were some proposals to allow the browser to communicate to the server what was already in the local cache but these ran into some issue HTTP Early Hints and Resource Hints have largely removed the need for H2 Push in a way that's much easier to implement, avoids unnecessary fetches and it's easier to reason about too reply jongjong 7 hours agoprevWell I'm not surprised. This is usually what happens when you take an existing protocol meant for a specific purpose and try to tack on additional functionality on top which has little to do with the original design goals of the protocol; you're almost always better off starting out with a low level protocol and going straight for your use case. In that respect, I think WebSockets already solved the problem of bidirectional communication elegantly. In terms of reducing latency when loading deep file/script hierarchies, thetag with rel=\"preload\" or rel=\"modulepreload\" is an excellent, simple construct. reply _heimdall 7 hours agoparentHTTP/2 Push would have fit the exact same use case as preload links with reduced latency. The whole point was for the server to send the content that should be preloaded as a header so it could be preloaded before the link tag was ever sent or parsed. This is less useful, in my opinion, for pages that support streaming but for any request that hangs until the entire HTML page has been rendered server-side could have noticeable gains. reply klabb3 6 hours agorootparent> HTTP/2 Push would have fit the exact same use case as preload links with reduced latency. I’m no expert, but it sounds like this still breaks a lot of assumptions about the 1:1 request-response based protocol that http is. If there’s no request, headers are… inferred? And the determination of what needs to be sent requires the server to model relationships between resources, as well as infer user-agent behaviors. Anyway, I never looked into it deeply. But I always felt this was a massive complexity burden spanning browsers and servers, for essentially bootstrapping cache performance only. Given that websites often don’t even cache properly, don’t bundle their bloated JS, etc, there’s so much low hanging fruit that needs addressing first anyway. So I’m happy it’s dying. Bank for the buck is crucial, and complexity creep is suffocation. reply bawolff 7 hours agoparentprevHttp/2 was a new low level protocol and http push was never really about bidirectional communication. reply paulddraper 5 hours agoparentprevIs HTTP not bidirectional communication? reply v3ss0n 8 hours agoprev [–] HTTP/2 Push was really useful when we wanted to avoid Websocket , Ajax Polling , Long Polling. The problem with not adopting is due to Websocket getting more popular and Devs stop caring about HTTP2 altogether. But there are many cases Websocket is overkill , even text chat application dosen't need websocket. Similar functionality can already be achieved by using SSE/Eventsource although HTTP/2 Push was more powerful. reply nirui 7 hours agoparentAre you talking about Server-sent Events (https://developer.mozilla.org/en-US/docs/Web/API/Server-sent...)? Which can be implemented under HTTP/1 too. HTTP/2 Server Push is another thing. It allows server to send additional related resources to a client without the client explicitly requesting. reply klabb3 7 hours agorootparentNot wrong, but for context: websocket http/1.1 only. It cannot use http/2 at all. reply nirui 6 hours agorootparentI think it's more of a problem on the implementation side. IETF RFC 8441 (https://www.rfc-editor.org/rfc/rfc8441.html) described a way to bootstrap WebSocket under HTTP/2. That said, I don't know whether or not people are actually doing it in the wild. reply realharo 6 hours agorootparentAs far as web frameworks go, WebSockets over HTTP/2 are supported in for example ASP.NET by default (https://learn.microsoft.com/en-us/aspnet/core/fundamentals/w...). There is however still a surprising amount of languages/libraries/frameworks/servers where the support is missing (e.g. go https://github.com/golang/go/issues/49918). On the client side, both Chrome (https://chromestatus.com/feature/6251293127475200) and Firefox will use it when available, but I have encountered some issues with cross-origin support (https://issues.chromium.org/issues/363015174) reply klabb3 2 hours agorootparentGP here. This was completely new to me despite working with it day to day. Thanks for sharing. This gives me some hope about having websockets be more in line with the rest of the stack. reply creesch 7 hours agoparentprevIn what practical sense are websockets overkill? As far as I know, the resource usage isn't really all that different. It also isn't as if websockets are that difficult to use these days. I am also skeptical of the \"doesn't need websocket\" statement. It is technically true that you can use other technologies. But, WebSockets provide bidirectional communication, while Ajax Polling and Long Polling are used for periodic updates. HTTP/2 Push is more suited for pushing resources or data from the server to the client. As far as my understanding goes the use case there is specifically aimed at pushing resources the server \"knows\" the client will need as well without the client requesting them. I am sure that with some creative code you can also use this to implement a chat of sorts but that is a bit besides the point. reply plopz 7 hours agorootparentIs there any reason to use websockets over webtransport now? reply creesch 7 hours agorootparentAbsolutely: https://developer.mozilla.org/en-US/docs/Web/API/WebTranspor... reply diggan 7 hours agorootparentprevProbably the most major one is if you want cross-browser support, AFAIK, WebTransport still isn't available in Safari. reply bawolff 7 hours agoparentprev [–] Perhaps i misunderstand, but i feel like http2 push was trying to achieve something very different than websicket/ajax poling/long polling/sse. They dont seem comparable to me at all. reply Lio 7 hours agorootparent [–] That's an interesting point, would you mind elaborating on how you think the goals of HTTP2 Push differed? Even is if is a misunderstanding it would still be useful to consider. reply bawolff 7 hours agorootparentHTTP2 is to hide connection latency by preloading. The other things are for bidirectional communication with a server. I would consider them very much apples and oranges. Its not just that they are designed for different purposes; i don't think it is possible to even use server push for the purpose websockets is used for in the browser. reply creesch 7 hours agorootparentprev [–] I don't know how to ask this without being quite direct. But why would you ask someone that when the differences are quite obvious? Certainly between web sockets (bidirectional, client initiated) and HTTP2 push (server initiated, one directional). Are you asking because you basically want to know more about the technologies? In that case why not frame it like that? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Valentin Gosu announced the disabling of HTTP/2 Push on all platforms due to compatibility issues with major browsers like Safari, Chrome, and Firefox.",
      "Chrome disabled HTTP/2 Push in September 2022, recommending alternatives like rel=\"preload\" and 103 Early hints, while Firefox faced web compatibility issues.",
      "The feature will be turned off soon and is expected to be removed before the Extended Support Release (ESR) 140 next spring."
    ],
    "commentSummary": [
      "HTTP/2 Push is being phased out due to its inefficacy and complexity, despite initial support from Google.",
      "The feature aimed to reduce latency by allowing servers to send resources proactively but faced challenges such as poor browser implementation and cache inefficiencies.",
      "Alternatives like preload headers and 103 Early Hints have proven to be simpler and more effective, reflecting a trend towards practical, easily implemented solutions."
    ],
    "points": 138,
    "commentCount": 78,
    "retryCount": 0,
    "time": 1725613430
  },
  {
    "id": 41464347,
    "title": "Study: Playing D&D helps autistic players in social interactions",
    "originLink": "https://arstechnica.com/science/2024/09/study-playing-dungeons-dragons-helps-autistic-players-in-social-interactions/",
    "originBody": "We can be heroes — Study: Playing Dungeons & Dragons helps autistic players in social interactions \"I can make a character quite different from how I interact with people in real life.\" Jennifer Ouellette - 9/5/2024, 9:40 PM Enlarge / Researchers say that Dungeons & Dragons can give autistic players a way to engage in low-risk social interactions. Nicole Hill/CC BY-SA 4.0 reader comments 75 Since its introduction in the 1970s, Dungeons & Dragons has become one of the most influential tabletop role-playing games (TRPGs) in popular culture, featuring heavily in Stranger Things, for example, and spawning a blockbuster movie released last year. Over the last decade or so, researchers have turned their focus more heavily to the ways in which D&D and other TRPGs can help people with autism form healthy social connections, in part because the gaming environment offers clear rules around social interactions. According to the authors of a new paper published in the journal Autism, D&D helped boost players' confidence with autism, giving them a strong sense of kinship or belonging, among other benefits. “There are many myths and misconceptions about autism, with some of the biggest suggesting that those with it aren’t socially motivated, or don’t have any imagination,\" said co-author Gray Atherton, a psychologist at the University of Plymouth. \"Dungeons & Dragons goes against all that, centering around working together in a team, all of which takes place in a completely imaginary environment. Those taking part in our study saw the game as a breath of fresh air, a chance to take on a different persona and share experiences outside of an often challenging reality. That sense of escapism made them feel incredibly comfortable, and many of them said they were now trying to apply aspects of it in their daily lives.” Prior research has shown that autistic people are more likely to feel lonely, have smaller social networks, and often experience anxiety in social settings. Their desire for social connection leads many to \"mask\" their neurodivergent traits in public for fear of being rejected as a result of social gaffes. \"I think every autistic person has had multiple instances of social rejection and loss of relationships,\" one of the study participants said when Atherton et al. interviewed them about their experiences. \"You've done something wrong. You don't know what it is. They don't tell you, and you find out when you've been just, you know, left shunned in relationships, left out.... It's traumatic.\" TPRGs like D&D can serve as a social lubricant for autistic players, according to a year-long study published earlier this year co-authored by Atherton, because there is less uncertainty around how to behave in-game—unlike the plethora of unwritten social rules that make navigating social settings so anxiety-inducing. Such games immerse players in a fantastical world where they create their characters with unique backstories, strengths, and weaknesses and cooperate with others to complete campaigns. A game master guides the overall campaign, but the game itself evolves according to the various choices different players make throughout. A critical hit Small wonder, then, that there tend to be higher percentages of autistic TRPG players than in the general populace. For this latest study. Atherton et al. wanted to specifically investigate how autistic players experience D&D when playing in groups with other autistic players. It's essentially a case study with a small sample size—just eight participants—and qualitative in nature, since the post-play analysis focused on semistructured interviews with each player after the conclusion of the online campaign, the better to highlight their individual voices. The players were recruited through social media advertisements within the D&D, Reddit and Discord online communities; all had received an autism diagnosis by a medical professional. They were split into two groups of four players, with one of the researchers (who's been playing D&D for years) acting as the dungeon master. The online sessions featured in the study was the Waterdeep: Dragonheist campaign. The campaign ran for six weeks, with sessions lasting between two and four hours (including breaks). Participants spoke repeatedly about the positive benefits they received from playing D&D, providing a friendly environment that helped them relax about social pressures. \"When you're interacting with people over D&D, you're more likely to understand what's going on,\" one participant said in their study interview. \"That's because the method you'll use to interact is written out. You can see what you're meant to do. There's an actual sort of reference sheet for some social interactions.\" That, in turn, helped foster a sense of belonging and kinship with their fellow players. Participants also reported feeling emotionally invested and close to their characters, with some preferring to separate themselves from their character in order to explore other aspects of their personality or even an entirely new persona, thus broadening their perspectives. \"I can make a character quite different from how I interact with people in real-life interactions,\" one participant said. \"It helps you put yourself in the other person's perspective because you are technically entering a persona that is your character. You can then try to see how it feels to be in that interaction or in that scenario through another lens.\" And some participants said they were able to \"rewrite\" their own personal stories outside the game by adopting some of their characters' traits—a psychological phenomenon known as \"bleed.\" “Autism comes with several stigmas, and that can lead to people being met with judgment or disdain,\" said co-author Liam Cross, also of the University of Plymouth. \"We also hear from lots of families who have concerns about whether teenagers with autism are spending too much time playing things like video games. A lot of the time that is because people have a picture in their minds of how a person with autism should behave, but that is based on neurotypical experiences. Our studies have shown that there are everyday games and hobbies that autistic people do not simply enjoy but also gain confidence and other skills from. It might not be the case for everyone with autism, but our work suggests it can enable people to have positive experiences that are worth celebrating.” Autism, 2024. DOI: 10.1177/13623613241275260 (About DOIs). reader comments 75 Jennifer Ouellette Jennifer is a senior reporter at Ars Technica with a particular focus on where science meets culture, covering everything from physics and related interdisciplinary topics to her favorite films and TV series. Jennifer lives in Baltimore with her spouse, physicist Sean M. Carroll, and their two cats, Ariel and Caliban. Advertisement Channel Ars Technica ← Previous story Next story → Related Stories Today on Ars",
    "commentLink": "https://news.ycombinator.com/item?id=41464347",
    "commentBody": "Study: Playing D&D helps autistic players in social interactions (arstechnica.com)130 points by tomgp 9 hours agohidepastfavorite71 comments thom 8 hours agoMy wife's an art psychotherapist and I DM for a couple of our kids and their friends. We've talked about this a fair bit - being able to externalise and contain difficult emotions can be extremely powerful. But also just having that relationship of trust, which I think D&D really demands, can be somewhat therapeutic. You're not going to get mocked for being serious, you're not going to get in trouble for being silly, and sometimes when there's conflict it helps to be able to mediate that through your character's persona. And sometimes you really just want to work out your rage and attack the nearest NPC and undo hours of preparation by your friendly local DM, who in turn will seek out his own favoured form of therapy. reply bane 1 hour agoparentI'm reminded of this old video https://youtu.be/zng5kRle4FA What makes it really humorous is how incredibly well it captures the particulars of an actual session, most notably the socially awkward interactions and in-jokes which normally would have been the focus of bullying, but in this space resonate as the sort of very earnest fun play they were intended as. Having these places to go to, when the rest of your week is full of generally challenging interactions designed to tear people down, can be absolutely incredible sources needed to build up a sense of self-worth. D&D in some ways was possibly the place where the proto-seed for this kind of nerd-safe place was created. There may be some prior versions of this, maybe golden age Sci-fi book clubs or Trek gatherings or something, but D&D seems to be where it particularly gelled and crystalized hard. It's no wonder that it became part of the 80's moral panic since it threatened to provide a place where nerd culture could find itself and took a measure of control away from those in charge of the panic with regards to how one should behave and think. Today there are many many of these kinds of environments, and in a sense when formed a certain way like Open Source Software, have turned global industries upside-down. But even competitive card playing tournaments, demoscene parties, cosplay conventions, video game conventions, and so on are all an outgrowth of what D&D really started. My heart swells when I see little nerd culture shops that sell comic books and manga and figurines have signs out front for \"Boardgame Thursdays!\" or \"Magic Tournament this Saturday!\" Because there will for certain be at least one person who attends, who had an absolutely terrible month being shat on by most of the people they encounter, and will thrive in this place. Where it's safe to joke, be yourself, have fun. And that confidence and those social encounters might be not just enough to turn a nerdy kid into a CTO, but could also keep them away from the deep black hole of self-worthlessness, depression, and maybe worse. reply ksymph 4 hours agoprevI'm autistic, but I've never found the appeal of D&D. All the challenges and social pitfalls are still there in interacting with other players, but on top of that there's an additional set of unfamiliar rules and expectations for how to play my character and the game. Outside of the social aspect, I don't enjoy it as a game much either, with its slow pace and focus on narrative. Though, both groups I've played it with consisted of close seasoned players, none of whom I was particularly comfortable with, which isn't the best introduction. I'm curious how much the particular setup in the study affected the outcome, with the social reference sheets and presumably other unique factors - with how much D&D can vary based on the DM and players, it'd be interesting to see this study done with a variety of DMs guiding things in different ways. reply mystified5016 1 hour agoparentI hear you there. My first introduction to D&D was in a long-form campaign like this. It was pretty much as stressful as you describe. There were also a couple of incidents where I got pushed past my limits or something hit one of my triggers. However. After that, my husband and I joined a D&D club where the campaigns are 16 weeks long. Every few months you're at a new table with new players and new characters. I found that to be a lot more tolerable, and has really improved my social skills. The thing about clubs like this is there's always new people playing for the first time, and no one takes anything too seriously. Plenty of room to fuck up without real consequence. On the other hand, after four or five seasons, I'm real sick of short form campaigns and the lack of routine or continuity. It's also pretty tiring to invent a new persona for a character all the time. reply _a_a_a_ 3 hours agoparentprev> with its slow pace and focus on narrative am curious, could you elaborate a touch on these? TIA reply michaelt 3 hours agorootparentThere are plenty of valid ways to play D&D, and they might not all have a slow pace. But it's very easy for D&D to end up pretty slow. In a combat scene with 4 party members and 4 enemies, 7/8 of the time it's not your turn. And if you're playing a simple character that just hits with a sword, while other players are wizards with dozens of spells to choose between their turns will naturally take longer. Computer games are much faster paced. reply ksymph 2 hours agorootparentYes, this is exactly what I meant. TTRPGs typically have more time spent not doing anything compared to computer games (and board and card games too, to a lesser extent) simply by involving a group of people and being largely 'single-threaded'. As for what I mean by narrative, much of the appeal of D&D seems to lie in crafting the story and adventure, being a part of the plot. If the setting and narrative were completely removed, and the game was reduced down to the most basic mechanical actions - go to location x,y and do foo to bar, etc., it would be a very different game. Not to say the mechanical aspects don't make up part of the appeal of D&D and other TTRPGs too, but they're not a focus as much as in, say, a computer strategy game, or even something like an action platformer, where that is the game, and story/characters/etc. make up little (if any) of the gameplay. reply a1o 3 hours agorootparentprevI must have played a different D&D, the group I used to play very much favored Hack & Slash. When we wanted something more narrative we used a different system (GURPS was a good one) reply zzo38computer 36 minutes agorootparentI prefer GURPS myself (although I prefer a \"point-free\" variant; you can put whatever advantages, disadvantages, skills, etc that you want to without worrying about the points or whether or not the modifier you want has been published in any book). However, I think that GURPS can be OK for combat as well as narrative and other stuff. If you use many expansions books as well, then more options are possible. GURPS combat also has many options, and also I like the rules better than D&D in many ways. (Still, I think there are some problems with GURPS, and had tried to make up SciRPS to be better (in my opinion). Although GURPS has many skills, I think too many things are often combined in one skill; e.g. Brawling skill involves all unarmed combat (by punch, kick, claws, bite, horns, etc), but if you are skilled at only biting but not punch/kick, then it doesn't do that; skill of Morse code is the same skill as operating the communications devices to use it and are not separated; etc. \"Point-free\" helps a bit with this, but I think that it could be improved further, which is what I intended with SciRPS.) To me, the RPG is that you can have many things together, including combat, magic spells, narrative, strategy/tactics, etc. This is what makes it what it is, rather than a computer game which is a different kind of game. Although you might have plans (and the GM might have plans), many things will happen unexpectedly, due to what others are doing, due to the results of dice, etc, so that is another thing that RPG is. reply tstrimple 2 hours agorootparentprevThat's interesting, I find the combat in GURPS to be FAR more satisfying and less restrictive than D&D. It's definitely more number crunching and more complex, but it's an internally consistent system so once you know it things flow pretty well. The leaky abstractions from D&D feel too much like it's trying to replicate a video game and doing so poorly. reply entropicdrifter 1 hour agorootparentIronically it's closer to the other way around: Most video game RPGs are mechanically either based on D&D, based on another tabletop RPG that came about in the same era (Runequest, etc), or based on a tabletop RPG that was in-turn based on D&D. reply tstrimple 1 hour agorootparentYes and no. There are some major issues in my mind like Armor Class which fortunately video games don’t really mess with. I started playing D&D back in the Skills and Powers days. You had a lot more character creation options and more granular systems than what D&D has simplified into. It’s really the latest versions of D&D that I feel like are a bad video game abstractions. Probably because of their streamlining efforts for the D20 system. reply beezlebroxxxxxx 5 hours agoprevThe popularity of D&D with people on the spectrum is similar to the popularity of fantasy/sci-fi lit and games and movies for the same population group, and for the same reasons (ime): technical abstractions and a strong focus on \"systems\" ('logical' magic systems are valorized over 'illogical' ones), often simplistic characters with very clear telegraphed and consistent archetypes, plots with heavy focus on simpler good vs. evil conflict, more chances to identify with non-human characters (a vehicle for expressing divergent thought processes/behaviors). The difference maker seems to be that well done D&D games, with good DMs, force the players to interact with each other and problem solve together. Which, to me, suggests there's nothing particularly special about D&D beside it being something that people on the spectrum like --- what is special is the social interaction and problem solving. It would be interesting to see how gender plays into further studies. In my experience, autism in women can often look quite different than autism in men (generalizing of course). reply devbent 2 hours agoparentThe other major difference is that table top gaming is a constrained environment where one is allowed to act socially different than normal, and mistakes at the table are left at the table. Players are allowed to play someone with a completely different personality, and spend extended amounts of time stepping into someone else's head and thinking how someone different would act. There aren't any other situations in life where you can take someone socially awkward and say \"ok now act really charismatic\" and then, w/o judgement, that person spends 2 or 3 hours a week for months on end trying to figure out what a charismatic person would say and do. reply baerrie 5 hours agoparentprevI challenge the notion that autistic people seek more logical systems or simpler moral situations. Imo the day to day interactions of people and the world views they ascribe to are far simpler than many complex games or fantasy/scifi themes and or stories. In my experience, i have an excess of thinking around every single thing so seeing that complexity and nuance captured in media or a game, and in people willing to dive into those intricacies, makes me feel seen. reply beezlebroxxxxxx 5 hours agorootparentThat's interesting. In my experience with people on the spectrum, obviously acknowledging that the spectrum is so broad and inclusive at this point as to be almost meaningless in terms of specificity, they really, really, want logical systems and struggle with ambiguity, whether that be in moral, social, or fictional, situations. Clear cut distinctions between wrong and right, and these media properties themselves, give them an almost joyous sense of ease and confidence. It can be very personal for them. Fantasy and sci-fi themes in media can be complex, but, in my experience, the people I know on the spectrum are far more drawn to fare of a particular kind: systems focused and morally clear-cut. Complexity for them is often more about scale. They'll pick a Brandon Sanderson book/series over a Gene Wolfe book (or Peake's Gormenghast) or a much more thematically and emotionally rich and complicated realist story like Proust's In Search of Lost Time (comparable in a way to the giant fantasy epics with multi volumes). They'll pick an enormous space opera over Ursula K Le Guin's The Dispossessed. But these are all generalizations. Manifestations of autism can look and be wildly different. reply voidUpdate 5 hours agoparentprevAnother thing that I've found seems to unite a lot of ND people liking fantasy and such is the escapism, being able to imagine yourself in a \"better\" world where weird people are accepted and liked, and especially with roleplaying games you can almost literally be in that world, making a difference and feeling like you matter reply starkparker 3 hours agoprev> Atherton et al. wanted to specifically investigate how autistic players experience D&D when playing in groups with other autistic players. It's essentially a case study with a small sample size—just eight participants This is a nice study but not one to extrapolate anything from. reply carom 1 hour agoparentWhy is this style of comment on every single study that gets posted? It was a small sample size in rats, we get it. reply AdmiralAsshat 4 hours agoprevSeems like an extension of the observation that very introverted people can unexpectedly flourish in acting professions: I think people who are socially awkward can have an easier time compartmentalizing their social anxieties when under a persona because there's a part of the brain that can say, \"It's not me; I'm playing a role.\" reply BurningFrog 1 hour agoparentI suspect it's more that there is a script. You don't have the \"what am I supposed to say now??\" panic, and you don't have to understand an unfamiliar social situation. reply AdmiralAsshat 1 hour agorootparentYou arguably have a \"script\" in D&D, too, in the form of your character sheet. \"I am a chaotic neutral dwarf. I will act aggressively towards elves.\", etc. You are encouraged to act and speak as your character, not as yourself. reply zzo38computer 18 minutes agorootparentI think it is not really a \"script\"; it is a description of the character. This will affect as you will do in the game, and you will have to make it up what happens according to the circumstances as it is being done, instead of everything being written ahead of time. (Even if you do have plans, which you might (I often will, and the GM also often will), things will happen unexpectedly and cannot use the plans exactly like they are anyways.) I think that you do not generally need game mechanical traits in your character sheet to do this; you can write it in a spare section if you want to do (it is useful to have spare sections for this and other purposes; I will often want to add many extra notes that there are not pre-defined sections for). In GURPS, you would generally represent some of such things with mental disadvantages and quirks. I prefer to not use mental disadvantages unless I specifically want the game effects of those disadvantages (e.g. if you are unlucky, or cursed, or take only half as many turns as other characters, or you will tell the truth half of the time that you do not intend to do so, etc), and would generally rather have a choice, even if my character's personality is supposed to be something, I can do it by myself instead of making the game to try to do it for me. I do usually add quirks though, and I do more often want physical and social disadvantages. reply idiotsecant 1 hour agoparentprevIntroversion seems like it would be orthogonal to acting ability. Acting does need a very strong model of the 'other', though. An actor needs to be able to model how someone else might be feeling and more importantly, manifesting those feelings externally. So while an introvert might be a good actor someone on the autism spectrum might not be. reply 1GZ0 8 hours agoprevHad many similar experiences when role playing in video games like Minecraft with an autistic relative. Him putting his needs and emotions in the context of the game made him readily engage in banter in a way that he would normally have a tough time doing. reply idiotsecant 1 hour agoparentPeople on the spectrum are often quite adept at 'task based' communication, in the service of clear objectives and common goals. To the point that neurotypical friends and family might be frustrated that they are so focused on the task. It becomes more difficult when that socialization is open-ended. reply fiftyacorn 6 hours agoparentprevFrom experience it can be hard to judge whether participation in the banter is truly them putting themselves in the context of the game, or just mirroring the existing banter reply Der_Einzige 2 hours agoparentprevnext [8 more] [flagged] shepherdjerred 1 hour agorootparentI would love to see some evidence reply Der_Einzige 1 hour agorootparenthttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC7251476/ From the abstract \"The game Minecraft is extremely popular and of particular interest to children diagnosed with autism spectrum disorder.\" From the paper \"The open-ended narrative structure of Minecraft, especially when used in Creative Mode, facilitates constructive play of a type that resembles real-life block-building play along the lines of Lego or similar interlinking toy systems. These real-world block building toys are similarly popular among children diagnosed with autism spectrum disorder (ASD\" \"The popularity of Minecraft with children with ASD seems fairly universal\" \"the very use of Minecraft as a tool for supporting the reinforcement of a positive social communication skillset is in a way, an approach which is aligned to, rather than opposed to, particular aspects of neurodiversity.\" \"Certain communication skills, such as facial expression, gestures, or tone of voice, do not have parallels in the video games environment of Minecraft,\" ----- Even if it doesn't fully directly show \"causality\" at the level you'll likely want, the quotes are clear that if you have ASD, you almost certainly play minecraft, and minecraft is tailor made for neuro divergent people. And there's some compelling evidence showing that if you put some \"normal\" people around folks with ASD, it can have \"social contaigen\" effects - https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2927813/ reply idiotsecant 1 hour agorootparentprevThat's like saying that round holes are catalysts for round pegs. The kids playing Minecraft are doing it because the experience resonates with them. reply recursive 2 hours agorootparentprevWhat does that mean? reply talldayo 2 hours agorootparentprev\"Source? I made it the fuck up!\" reply Der_Einzige 1 hour agorootparentAssumptions make an ass out of you. reply talldayo 21 minutes agorootparentCorrelations without proven causality makes you no better than Freud. reply torginus 7 hours agoprevHonestly I think socially awkward people quickly get ostracized, and socially isolated early in life. Due to this, they get less chances to practice social interaction, something they were somewhat worse at in the first place, and fall even further behind on these skills. DnD allows them to practice these skills, such as high-stakes social conflict, bargaining, and just plain old getting along, in a relatively safe environment. reply CuriouslyC 6 hours agoparentIt's not just lack of practice, when these people get picked on they internalize low self value, so even if they practice social skills enough to get the hang of it they're still going to be awkward because they tend to act from a \"loser\" frame. That internalized low self value can be incredibly hard to fix, much harder than just developing social skills. reply imbnwa 2 hours agorootparentAlso known as \"Loser's Lose\" and \"Winner's Win\". A lot of social dynamics run on this principle. reply JaumeGreen 4 hours agoparentprevIt also gives people a framework in where to learn how to communicate. They can try different approaches, the stakes are low (in real life terms) if they fail, their companions and the DM will not only serve an example but give hints on how to do that better. Anyone with problems in social communication could make use of it as a great resource. reply idiotsecant 1 hour agoparentprevYes, this is correct, I think. It is a painful but true fact that the world is constructed according to the preferences of the majority neurotypical population, and if you want to survive in it you need strong masking and coping strategies if your brain doesn't work the same way. It is not fun developing or using these strategies but it's vitally important. reply throwaway-x881 1 hour agoprevRelated: Seminar on \"Dungeons and Dragons Group Therapy\": https://www.youtube.com/watch?v=8PwP8Jhkl3w reply blobbers 1 hour agoprevAll-in podcast was presenting RFK recently who highlighted autism rates of 1/22. Is it just me or is the spectrum of autism now just labeling anyone with social awkwardness or challenges expressing feelings as autistic? Because I feel like there is socially awkward, and then there is 'Dating on the spectrum' level autistic. I'm not super up to date yet, but is there an actual 'science' based test (blood, dna, something other than observing behaviors). I've seen the diagnosis of l1, l2 and l3 autism, but this isn't cited by the paper (or at least wasn't in my skim). The paper does indicate that imagination, social interactions and community are benefits from D&D. These benefits aren't specific to autistic people though; all growing kids can benefit from these types of activities and they're challenges that neurotypical kids encounter as well. reply mock-possum 3 hours agoprevI think for me, and maybe this should be obvious - what truly helps is having a good DM. Because then you’re not just having a chance to ‘play’ at social interactions - you’re playing under the watch of a caring mediator. The DM is going to clarify things, guide the discussions and dialogues, suggest options, correct misassumptions, etc. - in a way that almost no one ever would IRL. Play-acting social interaction isn’t really any less nerve wracking to me than having a ‘real’ interaction, because to me all interactions are acting anyway as far as I’m concerned. There isn’t any fundamental difference in terms of energy expended - unless someone else, e.g. the DM, is there to shoulder some of that workload. Then it’s a little easier, a little lower stakes. reply lcnPylGDnU4H9OF 3 hours agoparent> to me all interactions are acting anyway as far as I’m concerned I suspect this is a point that is often under-appreciated. I don’t have much else to add but it really can’t be overstated how accurate this is. Just wanted to highlight the statement since I think it expresses the idea well. reply lupire 4 hours agoprevMost of the result is \"Autistic people are more comfortable playing D&D than in natural social interactions\", which is well known. A small part was that some people \"bleed\" personality from their fantasy persona to their real persona. You can do that in D&D, but you can also do that with any kind of self-talk / persona building / masking, which non-autists also do. Actors in movies and plays do it too. reply holsta 8 hours agoprevI've run games with self-described autistic players, and I found it a supreme challenge. * Being unable to complete a character sheet unless someone walked them through it and made every decision for them * Being unable to come up with character background * Not being able to communicate if they were coming to a game or not * Being 30-40 mins late without communicating * Walking around, playing on their phone * Demanding handwritten journals / game tracking because the sounds of typing ruined the immersion for them * Constantly having to remind them of rules from session 0, such as 'no alcohol before or during the game' * Extreme arguing over dice rolls * Projecting their trauma onto many character and DM interactions * Showing up with real-life gifts for the DM, expecting in-game rewards Most recently, I lasted 12 sessions of 4-6 hours each before I cancelled the game. It killed my joy and I haven't DM'd since. It's been years now. Typing that out made feel sad. reply ergonaught 5 hours agoparentKnowing several autistic players for whom absolutely none of that is applicable, I'd say you had bad players. The \"self-described autistic\" element doesn't have much to do with that. Not everyone who wants to do a thing can or should do the thing. reply WaitWaitWha 26 minutes agoparentprev> self-described autistic players I am going to say the terribly unfashionable, nay almost heretical for today's climate. I am fairly convinced vast majority of self-described medical conditions, are not. I believe they are \"trendy diagnosis\" or \"fad syndrome\". Certain medical conditions receive heightened attention in media, leading to increased self-diagnosis or people claiming to have the condition because it's seen as socially or culturally relevant. Anyone recall the rash of Tourette syndrome TikTokers after an individual with the syndrome posted a highly viewed clip? e.g., ADHD, Gluten Sensitivity, Chronic Lyme Disease, Fibromyalgia, Multiple Chemical Sensitivity (MCS), and Autism or Asperger’s Syndrome. reply voidUpdate 8 hours agoparentprevIt sounds like you just had some awful players, I've played with a lot of people on the spectrum and the majority of the time they've been fine to play with reply AnEro 6 hours agorootparentYea mostly they are obsessive about the game like I'd say they'd be more likely to be min-maxers from my experience. Just unintentionally so you don't have alot of the toxic downsides of the min-maxers of forcing xyz situations or not having a backstory, it was more thats how they had fun building a character. reply voidUpdate 5 hours agorootparentYeah, generally I will minmax a bit, but I do try to bear in mind the character themself when I design them, so I'll try to organise stats optimally, but pick thematic spells, for example. I have fun not dying, but also in having a character that makes sense to me reply AnEro 4 hours agorootparentWhich makes it so fun to dm! I had someone make basically a batman character, but it was a min-maxed goblin shadow monk. Who thought he was a great investigator but wasn't, which always was funny to have a dumb batman trying to insecurely inserting himself into situations he shouldn't. He didn't meditate, he 'brooded' and was only technically useful in stealing/combat or when wisdom was in play. So at the campfire he'd be able to console the warrior for losing with the wisest thing that character has heard, only to follow up with something extremely dumb immediately after. reply jbverschoor 5 hours agoparentprevThose are not autism problems. Those are indeed, self-described and they’ll find any currently popular excuse to clear them of any responsibilities reply dspillett 7 hours agoparentprevI'm sure it is all more pronounced with someone who is truly deep enough in the autistic gamut, but for each of those complaints I can name at least one person in my life who, while not on the spectrum at all as far as I know, exhibit that trait. Particularly the time keeping and communications ones, I could name several for those. Myself certainly on timekeeping (though I do at least let people know my estimated delay!). reply mikebonnell 7 hours agoparentprevWould highly recommend checking out Critical Core - https://gametogrow.org/criticalcore/ which makes it much easier for both players to start and DMs to manage reply PaulHoule 5 hours agoparentprevIf you are running a pickup game open to new players you will probably have all the above problems which is part of the reason why I'd never run a D&D game. If I were going to run a game it would be a second-generation or later game like Toon or Paranoia or Call of Cthulhu which were all designed by people who played D&D and recognized what was wrong with D&D and the culture around it. To be fair newer versions of the game fix some of the brokenness such as too many kinds of dice (you think it is fun until you realize that unless you buy 20x as many dice as you need you're going to always be looking around on the floor the right dice, and there's nothing dramatic about rolling 20d6 for a dragon's attack because it's always going to do about 60 points of damage, etc.) Second-generation games give you everything you need to start in a single book (even a scenario) whereas with D&D you need to buy several books just to get started. The long-term character progression works OK in a group of committed players but it makes the stakes so high that players take it so seriously so it is not a lot of fun for the DM. In a shorter, simpler game with higher character mortality you can give the guy who came in 30-40 min late a preroll, a minute of instruction, and some pretense for why they are late and it's NP. I am not going to say it is the high point of DMing because it isn't but if I want to run a Paranoia game in a hurry I can kill off most of their clones before they get to the briefing room in my very dangerous Alpha complex with little-more-than random encounters and have them rolling on the floor laughing and coming back for more. Prerolls are probably more important preparation than an actual scenario because if people aren't fluent with character creation they're going to ruin it for each other (e.g. if you are creating new characters you want to have 1-1 sessions with players and not do it in a group... In D&D in particular you could spend years with a character and there is no way you want to rush the process, if I really wanted to do a D&D activity with young people I might just have them do nothing but create characters so they can get fluent) Unfortunately the same way that \"autism\" and pill-seeking behavior have crowded out awareness of other neurodivergences, developmental disabilities and mental health conditions, D&D has crowded out awareness of other tabletop RPG's so you will never see some study where people find 5 out of 75 depressed people had fun playing D&D and 62 out of 75 depressed people had fun playing Toon. reply tourmalinetaco 7 hours agoparentprevI’ve had similarly poor experiences, unfortunately. I have two autistic friends, and they’re good people, but they both have very… specific ideas of what a fantasy world must entail, one of which is far more attainable than the other, if they could properly play along. So one wished to be a mary sue-esque elven princess wizard, which I okayed because they were at least trying, although decisions such as weapons, prepared spells, and especially combat were harder for them so I guided most of those. My other autistic friend was particularly difficult though. His favorite character is from a retro video game, and he wanted to play that character, which by itself is fine. However, he wanted to play his fanfiction version, which he said was a “lone wolf” who wouldn’t stick with the party, and he wanted his uber-special one-shot sword. I worked to bring him down a peg and got him to agree that, for the sake of the mission, he should stay with the party and if “lone wolf” is particularly important we can do games outside of the main ones too. Unfortunately that session ended rather poorly because not one of my 5 players could focus. The last session I tried a year or so ago, and had the same person fanfic-writer attempting to demand control for everyone in the party because he “was the better tactician” because he “played Fire Emblem before”. My players ignored him and he got upset, and I had another player leave for unrelated reasons (D&D just wasn’t their thing, which I understood). Now he’s been “trying” to make his own campaign, so he can get the control he desires from running the monsters, but that’s been somehow slower than his other projects. Typing this out made me sad too, I haven’t been able to DM properly for a while. reply Fnoord 6 hours agoparentprevMy experience with people on the spectrum (I'm a card carrying member myself) is very diverse but there is a constant: they're stubborn on specific stuff where others are not. For example, I don't want to sit near someone who's eating hard cheese (non-melted). I don't mind someone eating whatever though (and even if I would, personal choice). Looking back in my life, I learned a lot from RPGs (Hero Quest, Star Quest, various Gameboy Classic games, Warhammer Quest, Warcraft franchise (story-wise, too). More so than RTS or FPS. But I have also been nigh annoying whilst playing them. It helps to learn you are being annoying, as conflict allows one to rise up to the occasion. That being said, you need to accept certain quirks as being part of the package. That is how any friendship or relation works; just people with autism are usually more accentuated. My wife and I are both on the spectrum, and we need to work with/around each other's quirks. Just the other day she demanded me to clean and refill a water bottle as she tastes other people otherwise. She even has that w/me, I found out (we are together for almost a decade). So I ended up cleaning it (she was with our son who was ill). reply lupire 4 hours agoparentprevBullets don't work in HN markdown. reply c-c-c-c-c 6 hours agoparentprevConstantly having to remind them of rules from session 0, such as 'no alcohol before or during the game' That sounds like the most boring DnD session ever, we get so high that any underlying condition is masked by having a damn good time. ;) reply Fnoord 6 hours agorootparent(I'm diagnosed.) You wouldn't wanna be around me playing D&D if I was high. No gaming would be done, only laughing and craziness. Besides, I had various psychotic episodes on marihuana (whilst mushrooms and various other drugs were OK). There's a good reason I don't consume marihuana anymore. Any drugs for tgat matter, but specifically I want to avoid a common one (here in Amsterdam Area). Similarly, I'm aware some people cannot behave or function on other drugs such as alcohol (same for me). I wouldn't say others aren't allowed to drink but I don't want to smell cigarettes or cannabis. Smelling alcohol does nothing to me (obviously?) So it boils down to constructing a social agreement based on consensus. Something which works for everyone. Which is more difficult the more people on the spectrum are there, and the less flexible other players are regarding their quirks. So if the consensus is sober, be sober or don't join the team. Quite a simple concept. What happens here is that boundaries aren't respected (common with people on the spectrum). Explain the issue and (possible) consequences. reply pavel_lishin 3 hours agorootparentprev> we get so high that any underlying condition is masked by having a damn good time. ;) I'm glad that works for you, but I've both tried playing D&D while high, and had some players who'd get high, and it was not particularly pleasant. In my experience, D&D requires more clarity of mind than marijuana tends to leave you with. And I say this as someone who's going to start drinking less during D&D games, because I've noticed that after my third beer, my DMing is not as good as it is after my first beer. reply entropie 7 hours agoparentprev> Being unable to complete a character sheet unless someone walked them through it and made every decision for them We used to play various table-top role-playing games over 20 years ago. D&D is known for its totally humiliatingly complex character creation, which is usually totally unnecessary, especially when ‘learning’ new players. Edit: sorry for my confused mind; I meant DSA not D&D. Character background is also not that important in my opinion. You simply explain that the goal is to play a role and that the character's background is important and determines his actions. Demanding that everything is well thought out increases the barrier to entry immensely. So keep it simple. I remember my first ~~D&D~~ (Edit: DSA) sessions with new groups where it literally took us 5 hours to get all the characters ready. Our group, after years of experience, simply explained the world to new players (we preferred to play World of Darkness, or shadowrun). We asked them what they wanted to play and roughly decided together with them what their strengths and weaknesses were. Rolling dice was more of a show for the newcomers, we hardly ever rolled dice ourselves. If you had 9/10 points in physical strength, we didn't think you needed to roll if you hit someone in the face. That just hurt. Our rounds became more and more enjoyable over time. Fewer rules, fewer dice orgies. More common sense. More focussed on each other and on the game itself. At the very end, we even played without a game master. Often ancestor rounds in world of darkness (vampires that were several hundred years old. Something like demigods.) Dice rolling was more or less obsolete. We had night-long in-charachter conversations. Oh, I miss that very much. I have autistic traits and it definitely helped me to put myself in other people's shoes. But it helped me even more to overcome my speech disorder and to learn how to deal with it (stuttering). reply thfuran 6 hours agorootparentHas there been any edition of d&d where character creation is more involved than any edition of shadowrun? reply aetherson 6 hours agorootparentNo. I don't know what your parent poster is talking about. D&D chargen is not in any edition of the game terribly complex. It's not wildly simple, either -- D&D is squarely \"rules medium\" and there are plenty of RPGs with simpler chargen. But it's not notably hard for its space. 20 years ago there was more manual calculation of numbers on a character sheet, that now is likely to be handled by a digital sheet reply entropie 6 hours agorootparentYeah you right; I meant DSA and edited my comment accordingly. reply entropie 6 hours agorootparentprevAh my mistake, I meant DSA and not D&D. In my opinion, character creation in shadowrun is relatively simple, if a little time-consuming. In WoD character creation takes 10 to 30 minutes max, even for a complete beginner. reply throwway120385 4 hours agorootparentBackstory and internalizing the game system is a lot less straightforward in WoD though because the intent is to provide just enough rail to facilitate creativity within the setting. reply Aardwolf 5 hours agorootparentprev> D&D is known for its totally humiliatingly complex character creation, which is usually totally unnecessary, especially when ‘learning’ new players. Had to do that as \"homework\" before my first D&D session long ago, and it was indeed a long process, but that actually made it very exciting for me and made me invested in the character from the start! reply jbverschoor 5 hours agoprev [–] Please stop classifying socially awkward or socially underdeveloped people as autistic. It’s not the same. Just like ADD, ADHD, narcissists, and gaslighting, highly overused and misused. But hey, we sure like to have some labels and bling to groups reply ziddoap 5 hours agoparent>Fifteen autistic children, ten males and five females, ten- to fifteen-years old, participated in this study. They attended a special educational school specifically for children diagnosed with autism Those that participated in the study were diagnosed with autism. reply shlant 4 hours agoparentprev [–] > Please stop classifying socially awkward or socially underdeveloped people as autistic. It’s not the same. who are you talking to? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A study published in the journal Autism indicates that playing Dungeons & Dragons (D&D) helps autistic players improve social interactions.",
      "Researchers found that D&D's structured environment and clear social rules boost confidence and foster a sense of belonging among autistic players.",
      "The study, involving eight participants playing the Waterdeep: Dragonheist campaign online, suggests that D&D can act as a social lubricant, providing positive experiences and skills for autistic individuals."
    ],
    "commentSummary": [
      "A study indicates that playing Dungeons & Dragons (D&D) can aid autistic players in enhancing social interactions by externalizing emotions and building trust.",
      "The structured environment of D&D offers a safe space for social practice, though some autistic individuals may find the game's rules and dynamics challenging.",
      "The study had a small sample size, suggesting the need for further research to confirm these findings."
    ],
    "points": 130,
    "commentCount": 71,
    "retryCount": 0,
    "time": 1725613550
  }
]
