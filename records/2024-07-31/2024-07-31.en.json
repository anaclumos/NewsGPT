[
  {
    "id": 41114839,
    "title": "Our audit of Homebrew",
    "originLink": "https://blog.trailofbits.com/2024/07/30/our-audit-of-homebrew/",
    "originBody": "Our audit of Homebrew Post July 30, 2024 Leave a comment By William Woodruff This is a joint post with the Homebrew maintainers; read their announcement here! Last summer, we performed an audit of Homebrew. Our audit’s scope included Homebrew/brew itself (home of the brew CLI), and three adjacent repositories responsible for various security-relevant aspects of Homebrew’s operation: Homebrew/actions: a repository of custom GitHub Actions used throughout Homebrew’s CI/CD; Homebrew/formulae.brew.sh: the codebase responsible for Homebrew’s JSON index of installable packages; Homebrew/homebrew-test-bot: Homebrew’s core CI/CD orchestration and lifecycle management routines. We found issues within Homebrew that, while not critical, could allow an attacker to load executable code at unexpected points and undermine the integrity guarantees intended by Homebrew’s use of sandboxing. Similarly, we found issues in Homebrew’s CI/CD that could allow an attacker to surreptitiously modify binary (“bottle”) builds of formulae and potentially pivot from triggering CI/CD workflows to controlling the execution of CI/CD workflows and exfiltrating their secrets. This audit was sponsored by the Open Tech Fund as part of their larger mission to secure critical pieces of internet infrastructure. You can read the full report in our publications repository. Homebrew Homebrew is the self-described “missing package manager for macOS (or Linux).” It serves as the de facto standard package manager for software developers on macOS, and serves hundreds of millions of package installs annually. These installations include “keystone” packages such as Golang, Node.js, and OpenSSL, making Homebrew’s security (and the integrity of its builds) critical to the security of downstream software ecosystems as a whole. Homebrew’s core (not to be confused with homebrew-core) is a Ruby monolith responsible for providing the brew CLI to users along with an importable Ruby API. Since its inception in 2009, Homebrew has undergone several architectural shifts aimed at improving the reliability and usability of packages delivered to users: binary builds (bottles) were implemented, made into the default installation mechanism (replacing local source builds), and subsequently built solely on CI/CD to limit the risk of a compromised developer machine. Despite this increasingly static approach, Homebrew’s core codebase is fundamentally dynamic and, in many places, reflects Homebrew’s historical need for dynamic loading of DSL-specified formulae via user-controlled Ruby code. Scope Homebrew is both a user-installable package manager (the brew CLI) and a packaging ecosystem, with an extensive and bespoke CI/CD configuration for reviewing, building, and distributing bottles to end users. Our audit focused on aspects of both of these, and aimed to answer questions like (but not limited to) the following: Can a local actor induce unexpected execution of a formula’s DSL, e.g. without an explicit invocation of brew install? Can a local actor induce unexpected evaluation of a tap’s formulae, e.g. from just brew tap with no subsequent user actions? Can a local actor induce namespace confusions or conflicts within brew, resulting in brew install foo installing an unexpected formula? Can a locally installed formula surreptitiously subvert or bypass Homebrew’s build isolation mechanisms? Can an unprivileged or low-privilege CI/CD actor (such as a third-party contributor) pivot to a higher privilege in Homebrew’s CI/CD? Can an unprivileged or low-privilege CI/CD actor surreptitiously taint or compromise a bottle build? Can an unprivileged or low-privilege CI/CD actor establish persistence in Homebrew’s CI/CD? Highlighted findings brew During our review of the brew CLI’s codebase, we uncovered a number of findings that, while not critical, could potentially undermine Homebrew’s per-formula integrity and isolation properties. We also uncovered findings that could allow loading of formulae (i.e., executable code) from surprising sources, such as remote URLs. Some findings of interest include: TOB-BREW-2, wherein a formula can influence the construction of its sandbox through string injection, resulting in a sandbox escape. TOB-BREW-5, wherein Homebrew used a collision-prone hash function (MD5) for a synthetic namespace (FormulaNamespace) could allow an attacker to induce runtime confusion between formulae. TOB-BREW-8, wherein a formula can surreptitiously include networked resources in its build without explicitly listing them via resource stanzas. TOB-BREW-11, wherein a formula can potentially use a socket pivot to escape its build sandbox on macOS. TOB-BREW-12, wherein a formula could opportunistically perform a privilege escalation through a user’s previously activated sudo token. TOB-BREW-13, wherein brew install can be induced to install formulae from non-local URLs for any protocol supported by the version of curl being used, such as SFTP or SCP. Our overall evaluation of Homebrew/brew is reflected in our report: while extensively tested, Homebrew’s large API and CLI surface and informal local behavioral contract offer a large variety of avenues for unsandboxed, local code execution to an opportunistic attacker. These avenues do not necessarily violate Homebrew’s core security assumptions (which assume trustworthy formulae), but may be subverted either by malicious formulae or through unexpected sources of formula loading (such as insufficiently sanitized inputs). Homebrew’s CI/CD Our review of Homebrew’s CI/CD workflows and actions uncovered findings that, while not critical, could undermine the integrity of Homebrew’s CI/CD runs and allow a less-privileged user to pivot to a position of higher privilege or even obtain persistence on Homebrew’s self-hosted GitHub Actions runners. Some findings of interest include: TOB-BREW-18, wherein multiple CI/CD workflows use the pull_request_target trigger to allow third-party pull requests to run code in the context of Homebrew’s upstream repository, potentially enabling either credential disclosure or tampering with Homebrew’s bottle builds. TOB-BREW-23, wherein multiple CI/CD workflows inadvertently allow shell injection via unsanitized workflow_dispatch inputs, potentially enabling vertical movement by a less-privileged user (i.e., one who can dispatch workflows but not modify them). Beyond CI/CD-specific findings, many brew findings are also salient in the CI/CD setting: TOB-BREW-6, which describes a lack of sandboxing/isolation during archive extraction, could be used by a less-privileged CI actor to pivot into a higher-privileged context by inducing extraction of a formula or other executable code that gets auto-loaded and executed during the CI’s lifecycle. TOB-BREW-13, described above, could be used by a less-privileged CI actor to pivot into a higher-privileged context, by inducing arbitrary code execution through brew install of a formula not present in the CI’s pre-configured (presumed trusted) context. Our report concludes that Homebrew’s CI/CD, while mature and effective at reducing the number of human touch-points in Homebrew’s package lifecycle, is complex and relies on misuse-prone patterns common in GitHub Actions workflows (such as dangerous workflow triggers and mixing of configuration, code, and data via template expansion). These patterns do not necessarily enable persistence or pivoting by a fully external actor, but may be leveraged by a lower-privileged insider (such as a rogue maintainer) to undermine the integrity and isolation assumptions made by Homebrew’s CI/CD. Takeaways Auditing a package management ecosystem such as Homebrew poses unique challenges. Local package management tools install and execute arbitrary third-party code by design and, as such, typically have informal and loosely defined boundaries between expected and unexpected code execution. This is especially true in packaging ecosystems like Homebrew, where the “carrier” format for packages (formulae) is itself executable code (Ruby scripts, in Homebrew’s case). Throughout the audit, we worked closely with the Homebrew maintainers and the Homebrew PLC and would like to thank them for sharing their extensive knowledge and expertise. We would also like to thank Patrick Linnane, Homebrew’s security manager, in particular for his triage and coordination efforts on behalf of Homebrew. Share this: Twitter LinkedIn Reddit Telegram Facebook Pocket Email Print Like this: Like Loading... Related By Trail of Bits Posted in Research Practice",
    "commentLink": "https://news.ycombinator.com/item?id=41114839",
    "commentBody": "Our audit of Homebrew (trailofbits.com)713 points by zdw 20 hours agohidepastfavorite139 comments woodruffw 19 hours agoI'm the author of this post and one of the people behind the audit; happy to answer questions about it. If you're having trouble finding the audit itself (it's linked indirectly), I'm linking a copy here as well[1]. [1]: https://github.com/trailofbits/publications/blob/eb9344f2261... greggsy 18 hours agoprevExcellent work - a methodical review like this is exactly what I’ve been looking for in these sorts of open source solutions. I know it’s not the focus of a code review like this, but I’m interested to hear your views on the general supply chain lifecycle problems inherent to open-source package management platforms. Principally, are vetting processes appropriate to ensure that new formulas refer to the correct source? How does the user gain confidence that their brew update is still referencing a trusted source? What happens when a domain is taken over? How quickly can the team respond to untrusted sources from formulas? I know these aren’t all Homebrew problems to solve, but they’re important ecosystem considerations. (These problems also exist in the winget and choco platforms, but less so in commercially supported repos like apt and yum. For me, and many other admins, they are a major concern when it comes to the Windows Store.) Edit: lastly, in case the homebrew team are watching: an npm-style vulnerability notice would be awesome reply dotBen 1 hour agoparentI can't emphasize enough how much of a genuine issue this is, especially where package managers are being used on production environments or within CI/CD pipelines. There's enough publicized cases of Chinese CCP operatives gaining pull request access to key packages, and I'm sure many more get discovered that are covered up/not made public. Even just turn over of package ownership from reputable entities to lesser known individuals is of course worrying. As a SWE/EngMgr turned VC, I'm curious if there's startups or commercial companies providing some kind of assurance here (but also worried the $ TAM for solving this problem probably isn't enough to make it a standalone business). reply brimwats 58 minutes agorootparent> enough publicized cases of Chinese CCP operatives gaining Like? not doubting you, just not aware of multiple cases beyond the big near-miss earlier this year reply azurezyq 54 minutes agorootparentAlso for that case, I don't think we have any clue who the guy is. Name just not meaning anything. Or anyone has any link to a formal trace to the origin? reply koito17 14 hours agoprevBefore moving to Nix, I was using MacPorts since Homebrew had some...eccentric behavior at the time (didn't work with multi-user setups, owned your /usr/local, lots of \"works on my machine\" problems from auto-updating and lack of version control, ...). One thing that has always felt insecure about Homebrew to me was the ability to use GitHub (not Git) URLs as ad-hoc packages. I wonder if that is how TOB-BREW-13 worked? That feature of Homebrew has always sounded like a security incident waiting to happen. In any case, I'd be interested in seeing an audit of Nix on Mac OS. Especially if there is a flaw in how `nix develop` and related commands work. reply justusw 13 hours agoparentFunny that you mention it, I also went Homebrew -> MacPorts -> Nix. Homebrew had analytics and broke versions too often. MacPorts is way more stable, but some niche packages would not build well, and I had terminfo issues with tmux. Nix allows me to override most of that, and I can share home manager config with my Debian workstation. reply ninetyninenine 13 hours agoparentprevNix also allows github. reply koito17 12 hours agorootparentSure, Nix is extremely flexible in input definition, but it's different in the sense that Homebrew exposes a single command to e.g. install a cask from a user-inputted GitHub repository. So all an attacker needs to do is typo squat or take control of the GitHub repository that people are using to install a certain cask. In Nix, flakes are pure functions and run in pure evaluation mode. One needs to consciously add a Git repository (URL + commit hash, branch, or tag) and then make use of something malicious exported by the input. But to find out what the flake exposes at all, reading the flake (or its documentation) is pretty much necessary. reply duijf 10 hours agorootparentAll the Nix commands that take an 'installable' can take GitHub URLs. For instance: $ nix run github:NixOS/nixpkgs#hello Hello world! That command will download nixpkgs from GitHub, evaluate the `hello` flake attribute, build it (or download it from a cache), and run it. > But to find out what the flake exposes at all, reading the flake (or its documentation) is pretty much necessary. If the flake exposes default packages or apps, then you do not need to provide a flake attribute: $ nix run github:NixOS/nixpkgs error: flake 'github:NixOS/nixpkgs' does not provide attribute 'apps.aarch64-darwin.default', 'defaultApp.aarch64-darwin', 'packages.aarch64-darwin.default' or 'defaultPackage.aarch64-darwin' So you can run e.g. Alejandra [1], a Nix formatter, like so: $ nix run github:kamadorueda/alejandra [1]: https://github.com/kamadorueda/alejandra EDIT: For what it's worth, I think this feature can be useful sometimes, but it does also suffer from the same typosquatting problems as we see in other ecosystems. reply saagarjha 12 hours agoprevI peeked at the sandbox escape bug and its associated fix: https://github.com/Homebrew/brew/pull/17700/commits/f4e5e0c7.... Is this…correct? Like, this is to prevent it from being interpolated into a sandbox profile and messing things up. How confident are we about this list of characters? reply js2 3 hours agoparentThe commit message could have answered that question, but instead, it only repeats what the diff already tells us: \"Don't allow special characters in sandbox rule paths\". It doesn't explain why, or what's special about the particular characters that it disallows. A better message would have said something like \"Prevent certain characters in the path because otherwise ... We need to worry about these specific characters but not others because...\" Even if I wrote this code and knew what it did today, if I come across this it a year from now, I'm left scratching my head: why did I make this change? A real world example of a good commit message: https://github.com/git/git/commit/92fe7c7d42cc941ed70d6fce98... reply frenchman99 3 hours agoparentprevSurprised too, if that is the fix. Wouldnt a whitelist be better than a blacklist? reply hk__2 5 hours agoprevI’m a bit puzzled by the wording of this blog post, because it says you’ve worked with Homebrew to do this audit, but your name sounds familiar to me, and indeed if we check Homebrew’s README [1]: > Homebrew's maintainers are […long list of names…] William Woodruff […] [1]: https://github.com/Homebrew/brew Is there any reason this is not mentioned in the blog post? I don’t think it would make a difference, but just to clarify things. reply woodruffw 4 hours agoparentI wasn’t a maintainer at the time I did the audit :-). I’ve been a non-maintaining “member” of the project for a long time, which is the pseudo-emeritus position we give to previous maintainers who want to continue participating in internal conversations and governance. I was then offered membership again, months after the audit, due to some unrelated work on Homebrew that didn’t exist and wasn’t planned before the audit was planned. This was all disclosed as part of a conflict-of-interest disclosure I did, both with my company and with the Homebrew maintainers, but I agree that the blog post could also say that explicitly. I’ll try and get it added today. TL;DR: I was not a maintainer at the time the audit was performed, but I was previously (years before) and am currently a maintainer. The audit was performed by myself and my colleagues in our professional capacities. reply hk__2 4 hours agorootparentThank you! reply tucosan 6 hours agoprevThe main attack vector IMHO is the simple fact that one can sneak in new packages with malicious intent by simply contributing a new formula. The team of maintainers is too small to audit all of the newly contributed formulae. I'm suprised that this attack vector wasn't part of the audit. reply woodruffw 5 hours agoparentI don’t think the current Homebrew core formulae reviewers consider their team too small to sufficiently review all new incoming formula requests. But even if it was: this is one of the vagaries of packaging that’s explicitly called out in the post: the boundary between first- and third-party execution is inherently murky, and there’s IMO relatively more security “value” in determining where third-party execution can surprisingly happen than pointing out all of the unsurprising things that happen when you intentionally run third-party code. (With that being said, I think packagaging ecosystems in general should be reviewed for those kinds of acceptance processes. But that would be closer to a “red team” style audit than a software audit, since it’s about human processes.) reply Bluecobra 9 minutes agoparentprevYeah, I just had a scare the other day with someone downloading a console emulator called \"Cmder\" which is a collection of a bunch of FOSS tools. It literally had ~1,000 files that could be malicious including powershell scripts, perl scripts, python scripts, shell scripts, DLLs, EXEs, etc. It turned out it was benign, but it's really scary that people just clone these Git repos and hope for the best. reply j16sdiz 5 hours agoparentprevThey noted that and just assume formulae are trustworthy. > ... These avenues do not necessarily violate Homebrew’s core security assumptions (which assume trustworthy formulae),... reply arandomhuman 15 hours agoprevIf macs supported PKGBUILDs like Pacman with a similar level of performance and there were correctly maintained packages for core programs I'd feel like using a mac would have a lot less compromises for convenience. Homebrew is great and the formulae are maintained really well but the simplicity of PKGBUILDS, the fast syncing, and lack of cognitive burden of recalling multiple arguments/flags for package managers make me wish pacman just worked on macs. reply izik 10 hours agoparentThe vanilla pacman will not work on macos as expected but there are attempts [1],[2] to make it works with some modifications/hacks. [1] https://github.com/liudongmiao/pacman [2] https://github.com/kladd/pacman-osx reply pxc 14 hours agoparentprevThere have been a few attempts at this. I think some of them may even be working. reply megamix 13 hours agoparentprevIs MacPorts not the same? Genuinely asking. reply sirn 9 hours agorootparentThe concept is the same (given a definition file, build a package from a central repo, aka ports-like), but one of the features of PKGBUILD has is that it's easy to build an ad-hoc package outside the main tree. For example, you can download a bundle of PKGBUILD and `makepkg` in any directory to build a package. In other ports-like build systems, this can be a bit more complicated. For example, MacPorts allows you to use a local repository, but it requires configuring that local repository in `/opt/local/etc/macports/sources.conf` and `portindex` it beforehand before MacPorts could pick it up. Some others don't support building out of the main tree at all. Personally, out of all ports-like building systems, I like MacPorts' Portfile the most. It's similar to FreeBSD Ports' BSD Makefile (MacPorts was created by Jordan Hubbard who also co-created FreeBSD Ports) but using DSL via Tcl interp instead of being a shell script (POSIX shell in the case of Alpine's APKBUILD, bash in the case of others). From my experience, the syntax is very nice to work with, though you need to know a bit of Tcl for a non-trivial package. reply yjftsjthsd-h 19 hours agoprevThere's a bunch of TOB-BREW-n listed - are those like CVE numbers just for this project? Edit: Oh, it's \"Trail Of Bits - homeBREW\". But probably still yes. reply woodruffw 19 hours agoparentYep. We use the TOB-$PRODUCT-$XXXX convention for our audit findings, where $PRODUCT is the target under audit and $XXXX is a unique incrementing counter for each finding. (As far as I know, a lot of audit firms do similar things.) reply Alifatisk 19 hours agorootparentFirst time seeing TOB being used honestly, it would’ve helped saying something along the lines of ”Trait of Bits (TOB from now on)” reply RulerOf 17 hours agorootparentOther companies do similar things. Red Hat creates RHSA-YYYY:XXXX for example, like this one for Log4Shell: https://access.redhat.com/errata/RHSA-2022:0442 reply jonahx 17 hours agorootparentprevI cannot reply to your top comment for some reason, so asking here: What is your personal recommendation for Mac users? Would you suggest a different package manager and, if so, which? reply woodruffw 16 hours agorootparentGiven that I did the audit, I don’t think it’s appropriate for me to offer an endorsement (or a negative endorsement) in this context. What I’ll say is this: the findings on Homebrew were not inconsistent with what I’d expect to find on any similarly sized userspace package manager that serves its own binary builds. reply luckman212 13 hours agorootparentMy dumb brain had to read it 3 times before realizing that by saying \"the findings were not inconsistent with what I'd expect\" you meant \"the findings _were_ consistent with what I'd expect\" reply simonklitj 12 hours agorootparentThat’s not necessarily what was meant though. “Not inconsistent” is more cautious and less assertive. It allows for some ambiguity rather than claiming perfect consistency. reply Brian_K_White 12 hours agorootparentprev\"not inconsistent\" is a common phrase and is used for a reason. It's a subtle difference but \"not inconsistent\" is not exactly the same as \"is consistent\". reply freep1zza 13 hours agorootparentprevOne should try to avoid using double negatives in both speech and programming to make intent more obvious ;-) reply Brian_K_White 48 minutes agorootparentHuman language is not math. It needs to convey concepts that are infinitely variable rather than binary. When a poet or novelist says something in an unusual way, they are being more accurate not less accurate. If there is ambiguity, it is because the concept or observation they mean to express has some ambiguous element. Trying to avoid that is just downsampling analog color reality to a 200ppi 1bpp fax. A related concept that even the most aspbergers STEM head should be able to understand, is how a scientist almost never asserts anything unequivocally. Almost every statement is qualified with whatever is appropriate to the context. Even the most fundamental constants of the universe like the speed of light are famously relative. Are those scientists being more or less ambiguous when they decline to say something simple and direct? Everything they don't say is deliberate and carefully crafted to be as correct as possible, not some sloppy ommission. reply gorlilla 7 hours agorootparentprevExcept the ambiguity was the intent. reply Cloudef 15 hours agorootparentprevI use nix on both mac and linux, also on CI where homebrew is especially brittle reply lifty 11 hours agorootparentDon’t you have to disable SIP to use nix on macOS? reply socksy 11 hours agorootparentNo, see https://nix.dev/manual/nix/2.18/installation/installing-bina... reply Cloudef 11 hours agorootparentprevNo. Even though SIP is slightly annoying because you can't have strace equivalent with it. reply scovetta 18 hours agoprevWell done! And thank you to the Open Tech Fund for sponsoring work to protect everyone who uses Homebrew. reply mootoday 4 hours agoprevThere's an interesting alternative to Homebrew: Devbox It abstracts Nix in a way you don't have to know or learn anything about the Nix language. I wrote a few words on how I use it instead of Homebrew [1]. [1] https://mootoday.com/blog/i-replaced-homebrew-with-devbox https://mootoday.com/blog/i-replaced-homebrew-with-devbox reply charlie0 4 hours agoparentAs someone unfamiliar with Nix, how is this better than Homebrew? reply mootoday 4 hours agorootparentFor me, the key push towards using it as a Homebrew replacement was the fact that I already used Devbox to create isolated dev environments for individual projects I work on. Now I have one tool to manage all dependencies. Other than that, it likely comes down to personal preference. One neat thing is `devbox global push/pull ` to persist my config in a repo. reply replete 53 minutes agorootparentOh this looks pretty cool. I started using Docker a while ago for dev projects to avoid package/language version hell, but sometimes its a bit overkill reply alberth 3 hours agoprev> Since 2012, Trail of Bits has helped secure some of the world’s most targeted organizations and products. We combine high-­end security research with a real­ world attacker mentality to reduce risk and fortify code. It's interesting that I don't see any analysis referencing OpenBSD (either as a product or as an alternative to something else they have done research on). reply efitz 14 hours agoprevWere the reported issues all addressed by the Homebrew maintainers or are any still unmitigated? reply zargon 14 hours agoparenthttps://brew.sh/2024/07/30/homebrew-security-audit/ reply pmarreck 16 hours agoprevI ditched `brew` for `nix` a while back and while the TUI could be more end-user-friendly (to the point that I wrote a wrapper called \"ixnay\" just so I could do \"ixnay install \" as easily as with brew, https://github.com/pmarreck/ixnay), the overall guarantees make it worth it. reply pyjamafish 5 hours agoparentI wish I had known about ixnay earlier! I also got annoyed of the user experience, to the point where I also wrote my own tool, hdn: https://github.com/seasonedfish/hdn I added a mention of ixnay to its readme :) reply bokchoi 13 hours agoparentprevI also find the nix command line annoying. I'll give this a try. I like the embedded `#help` documentation! reply Brian_K_White 11 hours agorootparentSo do I ;) I've had some form of `grep '^#h ' $0` in most of my scripts forever. This one is a purity stunt and doesn't use grep, or anything else: https://github.com/bkw777/pdd.sh (the script itself is of no use to you since it only talks to a piece of hardware) The command dispatcher case statement and all the embedded help is in do_cmd() at 2857, and the help reader is help() at 425 I like their explicit #args vs #help One jank in mine is I have a verbosity level setting which affects most messages, and help() uses it to filter some of the help. Normal verbosity shows only the normal help for the normal commands. If verbosity is set higher, then help() shows more commands. The way that's implimented in help() is extra comments that change the behavior of help() as it's scanning the file from top to bottom. When it hits a '#v 2' it starts only displaying the help if the user has currently set verbosity>=2 until further notice. Later down the file it hits a '#v 1' and starts displaying help again... It works but it feels kind of 70's or assembly. #v 1 #h normal help for mortals #h ... #v 2 #h don't confuse the simple folk with this dangerous powerful stuff... #h ... #v 1 #h a few more normal commands #h ... #v 0 #h display this even the user has set verbosity to 0 to request silence #h ... reply eddyg 14 hours agoprevAny idea how much impact the audit has and/or applies to Workbrew[0], their new business-oriented MDM-manageable package tool? [0] https://workbrew.com/ reply mikemcquaid 13 hours agoparentWorkbrew wraps a vanilla, unmodified Homebrew on Macs running it under a ‘workbrew’ user for user privilege separation and better multi-user support. reply sohrob 14 hours agoprevGreat that there are people looking into this. I wonder if there would be similar findings were they to perform an audit on MacPorts or the Nix package manager. reply apitman 19 hours agoprevA while back I was trying to understand why Homebrew requires pre-built executables to be installed into /home/linuxbrew. I asked about it here[0]. This requirement basically makes it impossible to use homebrew to quickly install programs on systems where you don't have root, or at least have homebrew already configured (not sure if that would solve it but I assume so). They pointed me to an example program that would break if not run this way: Facebook's Watchman[1]. It bizarrely (to me) has hard coded paths compiled into it, which force you to run it from specific directories. Would love to understand what's going on here and why you would ever make software work this way. I feel I'm missing a fairly obvious Chesterton's Fence. [0]: https://github.com/orgs/Homebrew/discussions/5371 [1]: https://facebook.github.io/watchman/docs/install#prebuilt-bi... reply woodruffw 19 hours agoparentThe short (but possibly not satisfying) answer is that Homebrew's relocation of packages (including binary relocation) is best effort, in part because of the myriad ways in which packages can embed absolute (or incorrect relative) paths and other state in their build products. macOS bottles are generally more relocatable (in part because of a lot of scar tissue around binary relocation), but it's a general problem with build system quality, build complexities, and - reasonably - disinterested upstreams. reply bagels 19 hours agoparentprevIn the case of Watchman, I have to assume that internal use is the most supported use case, and uniformity of deployment is desirable across the fleet there, and so, configurability wasn't as big of a concern? reply apitman 19 hours agorootparentThat makes sense. The weird part to me is that Homebrew would limit their approach and eliminate an entire class of use cases to accommodate programs that work this way. There has to be more to it. reply nightpool 18 hours agorootparentI don't think that's accurate—homebrew specifically says that it only uses the .linuxbrew directory when a formula contains a hardcoded path (which it scans for), and only if you choose not to install it from source. So, based on the responses from the maintainers, for the .linuxbrew directory to be used, you have to satisfy 2 conditions: 1. you have to be installing one of the ~10% of formula that isn't trivially relocatable. 2. you have to be using a precompiled binary (which it seems like homebrew is smart enough to not do if condition #1 fails and you're not using sudo) reply cqqxo4zV46cp 19 hours agorootparentprevMy short experience with Watchman (a few years ago) indicates this. It’s pretty clearly only technically open-source, without much regard at all paid to third parties actually using it. reply chatmasta 18 hours agorootparentI’ve had a few build pipelines break over the years because of a watchman dependency. IIRC it was usually an issue with an npm library depending on watchman but downloading a binary that was incompatible with the architecture or implemented the wrong syscalls for the operating system. reply razodactyl 13 hours agoprevThe amount of value returned to the Apple ecosystem through brew is remarkable and while this post makes me even more in awe of the care that goes towards the community, I'm sad that one of the richest companies in the world isn't giving more back. reply jmbwell 19 hours agoprevWith so many other package managers available, I often wish something else was the de facto package manager on macOS. Something like pkgsrc, which follows conventions much better and is thereby much easier to manage. reply CaliforniaKarl 18 hours agoparentI've been using MacPorts for as long as I've wanted a macOS package manager, and it's been working very well for me. reply brandall10 17 hours agorootparentAnyone know why Homebrew overtook MacPorts? I only have a vague recollection of a Rails colleague pushing me to switch circa 2013 or so and haven't given it much thought since, but it (MacPorts) seemed to be similarly ubiquitous prior. reply sizeofchar 16 hours agorootparentWhen I started using a Mac in 2009, MacPorts, Fink (and I think there was another I can't recall the name) simply wouldn't work for me. They would take very long to build what I wanted, there weren't nearly as many packages as was in Debian/Ubuntu, and many were old versions. Worse, many build attempts would just fail. In that scenario, brew worked like a charm. It was quick, had most or even more packages than Debian/Ubuntu and they were newer. Failure to install was rare. Then, Apple started yearly release of OS X, and that both broke brew and my system hard, so I started investigating and found out about the many \"shortcuts\" that brew took and how it violated systems components. I was dismayed, and abandoned brew for good. So, I stood a period where I would use many of my tools inside a Ubuntu VM, until probably 2013-2014, when for some reason I tried again MacPorts, and I don't know why, but that time it was much more reliable, and because of Apple's insane atm SSDs with 2 GB/s bandwidth, install became quick enough. Packages were still somewhat lagging behind in available versions, but the variety of them kinda reached the levels of what was in Debian/Ubuntu, so it was good enough for me. Then, the killer feature, I found out about macports variants and selectors, which I find the most awesome thing to this date in package managers (I haven't tried nix, still, it might be magnitude better in that regard). No needing to use rvm, pyenv, custom installs of gcc messing with make/autotools, and the only sane way of compiling various Haskell projects (before haskell-stack). reply CaliforniaKarl 15 hours agorootparentI don't know when they introduced it, but I believe MacPorts will build the common variants of the more-used packages. So, if you install a package with the default variants, you'll get a binary download instead of building from source. But indeed; fast SSDs, parallel compilation, and modern CPUs really help! reply saagarjha 13 hours agorootparentI think MacPorts builds basically everything and offers it as a binary if they think they can distribute it legally reply 1123581321 17 hours agorootparentprevMacPorts was slower (bringing in its own dependencies for everything meant longer build steps) and required sudo more. There were some annoying fiddly parts that made it seem like the homebrew users around you were having more fun exploring packages. It was also exciting how many packages and casks were in homebrew and it was easy to make your own. Also, back then there were lots of people experiencing package managers for the first time and they took to homebrew easily. Then so many projects started to publish brew install links as a way to get started; homebrew felt like a default. Now, with our faster computers, more space, and more packages installed, and macports shipping more binaries and using its own normal user, macports' duplication of dependencies looks more like an advantage than a disadvantage. And because homebrew taught so many people how to use package managers, macports is not their first so easier to start using. reply BeFlatXIII 6 hours agorootparentI’d push back slightly on the “more space” claim due to Apple’s notorious stinginess for SSD & RAM. reply steve_adams_86 16 hours agorootparentprev> Also, back then there were lots of people experiencing package managers for the first time and they took to homebrew easily. I suppose it was almost 15 years ago now but this is what I recall. Homebrew was easier, snappier, and the general friction coefficient felt smaller. It's a little funny reading this and then wonder... Why did I leave MacPorts behind? I don't think I put much thought into it at the time and rather went by feel. I was still somewhat new to this stuff having started my career more in design than development. reply pxc 13 hours agorootparentprevHere's my guess. Homebrew had at least these things going for it: - it has always had a strong emphasis on presenting a simple, clean, pleasant, pretty, playful UI and executed that well - when it came out, source-based package managers for macOS generally didn't have any binary caching mechanisms, so compile time mattered - Homebrew's embrace of the base system as opposed to bringing its own dependencies bought it greater reuse at the cost of robustness, driving down total time to install many packages - the language that `brew` and its packages were written in was trendy at thw time as well as pre-installed on macOS, which made them instantly accessible to huge numbers of web developers - the older macOS package managers generally drew on traditions and tooling from the Linux world (e.g., Fink, with Debian tooling) or the wider Unix world (e.g., MacPorts and various *BSD ports systems and packages written in some Tcl IIRC). The type of person with the experience that would lead them to prefer tools and conventions like one sees in Fink, MacPorts, and Pkgsrc, or to contribute to those projects, has likely always been dismayed, if not repulsed, by a number of Homebrewisms. I think we can therefore conclude that Homebrew didn't win the package availability race by converting MacPorts contributors— Homebrew succeeded in attracting a largely untapped pool of new contributors. Eventually there followed the majority of non-contributor users who just want to use whatever already offers the software they want to run. reply jrochkind1 16 hours agorootparentprevAt the point I switched from MacPorts to Homebrew, homebrew just worked more reliably in my experience. It installed things quicker and with fewer build/install failures. i don't know enough about what was going on under the hood to have any theory as to why this was my experience; I don't want to know what's going on under the hood, I just want to type `install whatever`, and have it work. reply llimllib 17 hours agorootparentprevHere’s why I switched early on in homebrew’s life from ports - brew had and has many more packages available - brew updates versions more quickly - brew uses much more simple paths that fit my brain better - brew has a pleasing simplicity reply fragmede 13 hours agorootparentprevthis was a while back, in the Gentoo Linux heyday, so it was popular to compile things, except that this was when computers were slow, so that meant waiting for compiles. the problem with macports was that (iirc, it's been a while) it compiled its own version of Python instead of just using the system python, which also broke sometimes. and then you had to compile all that shit again. brew won out because it was faster, and didn't duplicate redundant shit for no perceived reasom. reply steve1977 13 hours agorootparentprevI guess MacPorts was (and is) geared more towards users with some proper UNIX or BSD background, e.g. people coming from FreeBSD. Whereas Homebrew targets the typical Mac user who might need a CLI application occasionally, i.e. someone looking for simplicity, without being too technically savvy. The latter group certainly makes up a much bigger share of users on macOS, especially nowadays. reply throwaway290 7 hours agorootparentprevPeople like beer but also Homebrew had a cute site and made ports simpler than MacPorts. Turns out complexity was maybe not unwarranted. I was among first adopters of brew but now I port for years reply wwalexander 17 hours agorootparentprevMacPorts is awesome. The PortGroups also make it super easy to make new packages. reply nsagent 18 hours agorootparentprevYeah, I switched from Homebrew to MacPorts a few years ago and couldn't be happier. reply throwaway290 17 hours agorootparentSame here. reply arprocter 18 hours agoparentprevIt'd be nice if brew was a little more apt-y, and all the beer nomenclature is a bit silly My first exposure to Mac package stuff was fink in the early aughts - compiling everything on a Pismo G3 was pretty slow going reply jonhohle 16 hours agorootparentSwitch to MacPorts. It supports precompiled packages, doesn’t take over the world and force anything on you the same way Homebrew does. I’m really disappointed in how Homebrew took a lot of attention away from the existing package managers, made a bunch of terrible decisions related to packaging and flexibility and genera Unix philosophy, and then ate the world. : shakes fist at clouds, get off my lawn reply bainganbharta 18 hours agoparentprevThis is the pkgsrc-based package manager I use on macOS. It's simple and has the packages I need. https://pkgsrc.smartos.org/install-on-macos/ reply throw0101a 5 hours agorootparent> https://pkgsrc.smartos.org/install-on-macos/ Note that Pkgsrc is a NetBSD-derived project. * https://pkgsrc.org The Joyent folks leveraged it to allow their customers, who were perhaps not as familiar with Solaris/SmartOS, a larger pool of packages. Pkgsrc was running on Solaris before Joyent, Joyent built on top of it. reply 8b16380d 18 hours agoparentprevJust use pkgsrc or macports. IMO way easier and less intrusive than homebrew. reply paholg 18 hours agoparentprevWhen I've had to use a Mac, I've used nix to good success. I'm actually surprised how well it worked; I was able to basically just use the same config I use on Linux, removing just the few Linux-specific packages. reply SOLAR_FIELDS 17 hours agorootparentDo you not use many packages and only strictly use FOSS tooling? I have a large and growing list of packages that have to be managed in Homebrew still because the package is one of the following: 1. Not available at all in nixpkgs (e.g. Docker Desktop, BetterTouchTool, etc) 2. In nixpkgs, but completely broken or missing some architecture support (e.g. Firefox) 3. Actually available and somewhat functional in nixpkgs, but some significant features don't work because of code signing requirements and needing to be managed in the Applications folder (e.g. 1Password) Quite a few tools do in fact work well with nix on Mac. Especially if it's FOSS and/or a cli-only based tool. And for FOSS tooling such as Firefox, there is often a convoluted workaround (I'm currently using `github:bandithedoge/nixpkgs-firefox-darwin`). And of course you can always package it yourself by doing things The Hard Way. But the platform is still quite a ways away from being able to be used as a daily driver on Mac without Homebrew. reply Cloudef 14 hours agorootparentIf you want graphical apps to be handled by nix on macos, you might be interested in . nixpkgs does not package macos sandboxed apps AFAIK, that means typically only cli utilities, libraries and development tools only work. reply paholg 17 hours agorootparentprevHuh, interesting. I did primarily use FOSS and CLI applications. It's been a couple years, so I don't remember what exactly I used it for. I probably installed Docker Desktop via whatever method docker recommends, and I'm not sure about Firefox. For alacrity, I remember it being annoying to integrate into Mac's launcher, but it otherwise worked. Pretty much everything else was programming-related and just worked. reply pxc 13 hours agorootparentprevI recently tried out mac-app-util¹, which fixes some of the usual pain with GUI apps. In conjunction with brew-nix², it looks like it might be most of what I'll need to move away from having Nix manage Homebrew for me. I don't use very many GUI apps so now that the installation piece is taken care of, I can just package everything I use if it really comes down to it. That'd be worth it for me just to get rid of the painfully slow `brew` invocations that lurk in my activation scripts. -- 1: https://github.com/hraban/mac-app-util 2: https://github.com/BatteredBunny/brew-nix reply ggm 18 hours agoparentprevFor people who don't know, pkgsrc works fine on macOS, the complaint was well made: its not the default. I use brew, and have used pkgsrc in the past. I could go back for low pain. reply marxisttemp 17 hours agoprevMacPorts is always waiting for you with more packages, a better design, and Jordan Hubbard’s history with BSD/Apple :) reply jagged-chisel 17 hours agoparentso many projects release only formulas for homebrew. I keep both and try to use McPorts first. reply ggm 17 hours agorootparentMost homebrew users started in macports, or fink. Very few I talk to (admittedly not many and curmugeons) want to go back. reply dmd 17 hours agorootparentThat was probably true in homebrew’s first year. At this point I would be shocked if more than a fraction of a percent of homebrew users have ever even heard of macports or fink. reply ggm 16 hours agorootparentOn reflection I think you are very probably right. I should have thought more about my origin story before posting. Once, long ago... reply atribecalledqst 13 hours agorootparentprevOn an old Macbook I keep around for various rare offline tasks, I actually did go back to MacPorts from Homebrew. Chief reason being: Homebrew doesn't support old versions of the OS so I was SOL trying to install a new package on it. The backwards compatibility is a nice feature! My current machine is also not on the latest so I wonder if an attempt to brew update would nag me now... reply eduction 17 hours agorootparentprevKey difference is Mac ports keeps its tree separate in /opt. This means things take longer initially to install because it can’t just leverage system stuff already there. Upside is greater reliability because it doesn’t have to worry about a system update changing its dependencies. I prefer the greater reliability of macports. reply parhamn 17 hours agorootparent> Key difference is Mac ports keeps its tree separate in /opt What do you mean by this? brew has been linking from /opt/homebrew for years now. reply ggm 16 hours agorootparentThe person you're responding to may have been using homebrew on Intel. It's been in /opt on ARM since inception on ARM. reply eduction 15 hours agorootparentprevI did not know about the new directory practice, thanks. From what their site says it looks like it was done this way to keep ARM native stuff separate from old intel code which can still work under Rosetta. But I don't see any indication homebrew stopped linking system libraries as a matter of course (correct me if I'm wrong). MacPorts makes a point of not doing this. /opt/local is its own universe and dependencies can be upgraded more or less aggressively than Apple's. https://trac.macports.org/wiki/FAQ#syslibs reply azinman2 13 hours agorootparentI much rather them use system libraries than build parallel libs that don’t go through Apple’s vetting / changes. This has worked well for me in practice. I’ve actually never run into an issue where the system library got updated and that broke homebrew’s apps. reply MilaM 13 hours agoparentprevI was wondering recently if there are any downsides of using MacPorts and homebrew for different packages on the same system. Homebrew excels at keeping all my single binary CLI tools up to date, but I don't particularly like how it forces me to upgrade more complex software packages like MySQL or FFmpeg constantly. There is also the issue, that my iMac is stuck on Ventura, and soon won't be supported by homebrew anymore. reply Asmod4n 10 hours agorootparentThe approach of Mac ports and Homebrew have been the complete opposite when Homebrew came into existence. Mac ports tried to make packages compatible with whatever Apple shipped, aka their own twists on Perl, python, OpenSSL etc. While Homebrew tried to make macOS compatible with whatever existed out there. As a developer Homebrew gave you a more up to date and fully functional experience. Can’t tell you how it is today since Apple removed all interpreters and such from macOS. reply eviks 15 hours agoparentprevIt's also a worse design in some aspects, so not a clear winner reply remram 5 hours agorootparentFor example? reply eviks 5 hours agorootparent- too much sudo friction - homebrew's design of having a single app's folder is better, e.g., can use your basic file manager to see the total size - updates requiring manual inervention - fewer/less updated packages (mabye due to the previous deficiency?) - large duplicate database wasting space (and think it's even uncompressed) (brew got better when it moved to it API) reply nothrowaways 15 hours agoprevApple should have been the one funding the audit. reply CydeWeys 13 hours agoparentApple should have written it themselves. It's embarrassing that they didn't. Nonprofit Linux distros with one-millionth the resources manage to write package managers and run repos, and then with MacOS, Apple gives you diddly-squat. reply arvinsim 13 hours agorootparentIMO, it's just counter to what Apple aspires MacOS to be. If they would do it all over again, I would bet that they would have wanted to make MacOS be like iOS. reply Lio 11 hours agorootparentI’m not sure. Back in the day Apple marketed macOS as a serious Unix system for scientists and engineers boasting about NASA’s use of it. I think if Apple aspired to lockdown general purpose computing they would push the ipad pro range with more models and slowly kill off the Mac but they’re not doing that. reply throw0101a 5 hours agorootparent> Back in the day Apple marketed macOS as a serious Unix system for scientists and engineers boasting about NASA’s use of it. They still jump through the necessary hoops to be certified as UNIX® with each macOS release: * https://www.opengroup.org/openbrand/register/ reply robxorb 10 hours agorootparentprev> IMO, it's just counter to what Apple aspires MacOS to be. Every OS wants to be attractive to developers. Apple has a long history of underdelivering this core proposition. To me it's an odd situation to reason about - look at Apple's dev conferences and then look at what it's like on the ground in dev's reality. reply meindnoch 8 hours agorootparentprev>Apple should have written it themselves. Please don't. It would be a resource hog SwiftUI monstrosity like the new Settings app. And while they are at it, they would probably introduce the 46353th bespoke feature into the Swift language too, because why not? reply CydeWeys 3 hours agorootparentIt would be (or at least have) a command-line utility like rpm, npm, apt, or pacman. That's necessary for it to integrate well with various installation scripts. So you wouldn't have to use a UI at all, especially if it's bad. reply rurban 13 hours agorootparentprevApple would certainly favor macports over that rubbish ruby thing. Ports are from FreeBSD, MacOS is from FreeBSD. reply latexr 6 hours agorootparentThat is provably false from so many angles. * Apple has no aversion to Ruby, and on the contrary has multiple developers pushing for it. They themselves had MacRuby, a project that allowed one to create Mac OS X (at the time) applications with Ruby.¹ * The reason there’s even an Xcode command line tools package available officially from Apple is because of Homebrew. A third-party made it first by extracting the necessary bits and then Apple officially supported it.² * There’s a liaison between Homebrew and Apple, who helped during the Intel to Apple Silicon transition.³ ¹ https://web.archive.org/web/20100908131627/http://developer.... ² I know this from a reliable source and it is public information, but it was so long ago it’s hard to find. ³ The official Homebrew Twitter account tweeted about this at the time. I no longer have a Twitter account so can’t dig it up. reply dewey 11 hours agorootparentprevNo need to call someone’s free open source project “rubbish”. reply pxc 13 hours agorootparentprevThen why did Apple hire the creator of Homebrew to work on the package manager for Swift? reply saagarjha 13 hours agorootparentYou should read https://en.wikipedia.org/wiki/MacPorts#History. But to answer your question: why not? Apple employs thousands of software engineers. reply freep1zza 13 hours agorootparentprevWhat a nonsensical conclusion. Homebrew existing is no reason for Apple to do replicate that trainwreck. reply CydeWeys 3 hours agorootparentI thought it was clear from my comment that I was suggesting Apple would do it better. Think of how useful something like apt, npm, or pip is, and then realize that MacOS has no in-house equivalent. reply user3939382 18 hours agoprevI’m still good on MacPorts. Seems I’m alone these days. Works fine for me. reply 8b16380d 18 hours agoparentNah I’ve been on macports for years now. No problems; the community is very active, just follow the mailing lists etc reply _0xdd 4 hours agoparentprevYou are not. I've been using MacPorts for 15+ years at this point. Started with fink and then made the switch around the days of Snow Leopard. I'm also a BSD user, so no surprise there. I enjoy being able to compile ports with non-standard variants (e.g., non-free codecs in ffmpeg, removing un-needed interpreters from packages, etc.) reply blt 16 hours agoparentprevI got sick of Homebrew after a while and tried switching to MacPorts, but it feels like an endless uphill battle when so many packages only offer source and Homebrew distributions. reply pxc 13 hours agoparentprevI mostly just use Nix, but I also have pkgsrc, MacPorts, and (kinda) Homebrew installed on my Mac. The only ones with any CLI tools installed, though, are Nix and pkgsrc. reply wwalexander 17 hours agoparentprevThere are dozens of us! reply paradox460 18 hours agoparentprevI keep ports around for things like lilypond (which I use for quasi-professional score engraving) and some other packages that homebrew is weird on. The removal of options a few years back still stinks for be reply bdangubic 18 hours agoparentprevhonebrew works too :) reply KennyBlanken 14 hours agoprevnext [2 more] [flagged] mrpippy 13 hours agoparentOn Apple Silicon Macs, Homebrew installs in /opt/homebrew. reply alxmdev 18 hours agoprevnext [2 more] [flagged] trav4225 18 hours agoparentHah! IIRC, it was a binary tree of some sort. reply Ferret7446 11 hours agoprevnext [5 more] [flagged] latexr 7 hours agoparentThat’s like saying you dislike the current state of the USA because of George Washington. You’re referring to Max Howell, who started Homebrew but hasn’t been part of it for over a decade. Max has been out of Homebrew for longer than he was ever in it, so everything you associate between the two is wrong. reply leokennis 10 hours agoparentprevCan you supply supporting evidence (links etc.) regarding \"the author was being extremely upset (...) about not passing a Google interview\" and \"Homebrew having... weird design decisions\"? reply andruby 9 hours agorootparent(I'm not the other poster) They're probably referring to this tweet from Max Howell [0] > Google: 90% of our engineers use the software you wrote (Homebrew), but you can’t invert a binary tree on a whiteboard so fuck off. I personally wouldn't hold that against him (or Homebrew). We also don't really know if Google rejected him based on the binary tree, or if it was something else (personality?). [0] https://x.com/mxcl/status/608682016205344768 [1] https://news.ycombinator.com/item?id=15713801 reply latexr 7 hours agorootparent> I personally wouldn't hold that against him (or Homebrew). No one should hold that against Homebrew. Max was already not part of it when that happened and he does not speak for the remaining team. reply neverrroot 18 hours agoprev [–] Not surprised to see some problems. Still sad to see security take a backseat as opposed to convenience. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "An audit of Homebrew, a critical package manager for macOS and Linux, revealed non-critical security issues that could allow unexpected code execution and compromise CI/CD workflows.",
      "Key findings included vulnerabilities in the brew CLI, such as sandbox escapes and privilege escalations, and issues in CI/CD workflows like shell injection vulnerabilities.",
      "The audit, sponsored by the Open Tech Fund, aimed to secure critical internet infrastructure, highlighting the importance of Homebrew's security given its extensive use."
    ],
    "commentSummary": [
      "Trail of Bits conducted a comprehensive security audit of Homebrew, a popular open-source package manager for macOS, revealing several security concerns and areas for improvement.",
      "The audit has sparked discussions about the inherent supply chain security issues in open-source package management platforms, emphasizing the need for better vetting processes and quicker responses to untrusted sources.",
      "The audit findings have led to increased interest in alternative package managers like Nix, which some users find more secure and flexible, despite its complexity."
    ],
    "points": 713,
    "commentCount": 139,
    "retryCount": 0,
    "time": 1722379161
  },
  {
    "id": 41116473,
    "title": "macOS in QEMU in Docker",
    "originLink": "https://github.com/sickcodes/Docker-OSX",
    "originBody": "Docker-OSX · Follow @sickcodes on Twitter Run Mac OS X in Docker with near-native performance! X11 Forwarding! iMessage security research! iPhone USB working! macOS in a Docker container! Conduct Security Research on macOS using both Linux & Windows! Docker-OSX now has a Discord server & Telegram! The Discord is active on #docker-osx and anyone is welcome to come and ask questions, ideas, etc. Click to join the Discord server https://discord.gg/sickchat Click to join the Telegram server https://t.me/sickcodeschat Or reach out via Linkedin if it's private: https://www.linkedin.com/in/sickcodes Or via https://sick.codes/contact/ Author This project is maintained by Sick.Codes. (Twitter) Additional credits can be found here: https://github.com/sickcodes/Docker-OSX/blob/master/CREDITS.md Additionally, comprehensive list of all contributors can be found here: https://github.com/sickcodes/Docker-OSX/graphs/contributors Big thanks to @kholia for maintaining the upstream project, which Docker-OSX is built on top of: OSX-KVM. Also special thanks to @thenickdude who maintains the valuable fork KVM-OpenCore, which was started by @Leoyzen! Extra special thanks to the OpenCore team over at: https://github.com/acidanthera/OpenCorePkg. Their well-maintained bootloader provides much of the great functionality that Docker-OSX users enjoy :) If you like this project, consider contributing here or upstream! Quick Start Docker-OSX Video setup tutorial is also available here: https://www.youtube.com/watch?v=wLezYl77Ll8 Windows users: click here to see the notes below! First time here? try initial setup, otherwise try the instructions below to use either Catalina or Big Sur. Any questions, ideas, or just want to hang out? https://discord.gg/sickchat Catalina docker run -it \\ --device /dev/kvm \\ -p 50922:10022 \\ -v /tmp/.X11-unix:/tmp/.X11-unix \\ -e \"DISPLAY=${DISPLAY:-:0.0}\" \\ sickcodes/docker-osx:latest # docker build -t docker-osx . Big Sur docker run -it \\ --device /dev/kvm \\ -p 50922:10022 \\ -v /tmp/.X11-unix:/tmp/.X11-unix \\ -e \"DISPLAY=${DISPLAY:-:0.0}\" \\ sickcodes/docker-osx:big-sur # docker build -t docker-osx --build-arg SHORTNAME=big-sur . Monterey docker run -it \\ --device /dev/kvm \\ -p 50922:10022 \\ -v /tmp/.X11-unix:/tmp/.X11-unix \\ -e \"DISPLAY=${DISPLAY:-:0.0}\" \\ -e GENERATE_UNIQUE=true \\ -e MASTER_PLIST_URL='https://raw.githubusercontent.com/sickcodes/osx-serial-generator/master/config-custom.plist' \\ sickcodes/docker-osx:monterey # docker build -t docker-osx --build-arg SHORTNAME=monterey . Ventura docker run -it \\ --device /dev/kvm \\ -p 50922:10022 \\ -v /tmp/.X11-unix:/tmp/.X11-unix \\ -e \"DISPLAY=${DISPLAY:-:0.0}\" \\ -e GENERATE_UNIQUE=true \\ -e MASTER_PLIST_URL='https://raw.githubusercontent.com/sickcodes/osx-serial-generator/master/config-custom.plist' \\ sickcodes/docker-osx:ventura # docker build -t docker-osx --build-arg SHORTNAME=ventura . Sonoma docker run -it \\ --device /dev/kvm \\ -p 50922:10022 \\ -v /tmp/.X11-unix:/tmp/.X11-unix \\ -e \"DISPLAY=${DISPLAY:-:0.0}\" \\ -e GENERATE_UNIQUE=true \\ -e CPU='Haswell-noTSX' \\ -e CPUID_FLAGS='kvm=on,vendor=GenuineIntel,+invtsc,vmware-cpuid-freq=on' \\ -e MASTER_PLIST_URL='https://raw.githubusercontent.com/sickcodes/osx-serial-generator/master/config-custom-sonoma.plist' \\ sickcodes/docker-osx:sonoma # docker build -t docker-osx --build-arg SHORTNAME=sonoma . Run Catalina Pre-Installed # 40GB disk space required: 20GB original image 20GB your container. docker pull sickcodes/docker-osx:auto # boot directly into a real OS X shell with a visual display [NOT HEADLESS] docker run -it \\ --device /dev/kvm \\ -p 50922:10022 \\ -v /tmp/.X11-unix:/tmp/.X11-unix \\ -e \"DISPLAY=${DISPLAY:-:0.0}\" \\ -e GENERATE_UNIQUE=true \\ sickcodes/docker-osx:auto # username is user # passsword is alpine Older Systems High Sierra docker run -it \\ --device /dev/kvm \\ -p 50922:10022 \\ -v /tmp/.X11-unix:/tmp/.X11-unix \\ -e \"DISPLAY=${DISPLAY:-:0.0}\" \\ sickcodes/docker-osx:high-sierra # docker build -t docker-osx --build-arg SHORTNAME=high-sierra . Mojave docker run -it \\ --device /dev/kvm \\ -p 50922:10022 \\ -v /tmp/.X11-unix:/tmp/.X11-unix \\ -e \"DISPLAY=${DISPLAY:-:0.0}\" \\ sickcodes/docker-osx:mojave # docker build -t docker-osx --build-arg SHORTNAME=mojave . Download the image manually and use it in Docker This is a particularly good way for downloading the container, in case Docker's CDN (or your connection) happens to be slow. wget https://images2.sick.codes/mac_hdd_ng_auto.img docker run -it \\ --device /dev/kvm \\ -p 50922:10022 \\ -v \"${PWD}/mac_hdd_ng_auto.img:/image\" \\ -v /tmp/.X11-unix:/tmp/.X11-unix \\ -e \"DISPLAY=${DISPLAY:-:0.0}\" \\ -e GENERATE_UNIQUE=true \\ -e MASTER_PLIST_URL=https://raw.githubusercontent.com/sickcodes/Docker-OSX/master/custom/config-nopicker-custom.plist \\ sickcodes/docker-osx:naked Use your own image and manually and automatically log into a shell Enable SSH in network sharing inside the guest first. Change -e \"USERNAME=user\" and -e \"PASSWORD=password\" to your credentials. The container will add itself to ~/.ssh/authorized_keys Since you can't see the screen, use the PLIST with nopicker, for example: # Catalina # wget https://images2.sick.codes/mac_hdd_ng_auto.img # Monterey wget https://images.sick.codes/mac_hdd_ng_auto_monterey.img docker run -it \\ --device /dev/kvm \\ -p 50922:10022 \\ -v \"${PWD}/mac_hdd_ng_auto_monterey.img:/image\" \\ -v /tmp/.X11-unix:/tmp/.X11-unix \\ -e \"DISPLAY=${DISPLAY:-:0.0}\" \\ -e \"USERNAME=user\" \\ -e \"PASSWORD=alpine\" \\ -e GENERATE_UNIQUE=true \\ -e MASTER_PLIST_URL=https://raw.githubusercontent.com/sickcodes/Docker-OSX/master/custom/config-nopicker-custom.plist \\ sickcodes/docker-osx:naked-auto Share directories, sharing files, shared folder, mount folder The easiest and most secure way is sshfs # on Linux/Windows mkdir ~/mnt/osx sshfs user@localhost:/ -p 50922 ~/mnt/osx # wait a few seconds, and ~/mnt/osx will have full rootfs mounted over ssh, and in userspace # automated: sshpass -psshfs user@localhost:/ -p 50922 ~/mnt/osx (VFIO) iPhone USB passthrough (VFIO) If you have a laptop see the next usbfluxd section. If you have a desktop PC, you can use @Silfalion's instructions: https://github.com/Silfalion/Iphone_docker_osx_passthrough (USBFLUXD) iPhone USB -> Network style passthrough OSX-KVM Docker-OSX Video setup tutorial for usbfluxd is also available here: https://www.youtube.com/watch?v=kTk5fGjK_PM This method WORKS on laptop, PC, anything! Thank you @nikias for usbfluxd via https://github.com/corellium! This is done inside Linux. Open 3 terminals on Linux Connecting your device over USB on Linux allows you to expose usbmuxd on port 5000 using https://github.com/corellium/usbfluxd to another system on the same network. Ensure usbmuxd, socat and usbfluxd are installed. sudo pacman -S libusbmuxd usbmuxd avahi socat Available on the AUR: https://aur.archlinux.org/packages/usbfluxd/ yay usbfluxd Plug in your iPhone or iPad. Terminal 1 sudo systemctl start usbmuxd sudo avahi-daemon Terminal 2: # on host sudo systemctl restart usbmuxd sudo socat tcp-listen:5000,fork unix-connect:/var/run/usbmuxd Terminal 3: sudo usbfluxd -f -n Connect to a host running usbfluxd This is done inside macOS. Install homebrew. 172.17.0.1 is usually the Docker bridge IP, which is your PC, but you can use any IP from ip addr... macOS Terminal: # on the guest brew install make automake autoconf libtool pkg-config gcc libimobiledevice usbmuxd git clone https://github.com/corellium/usbfluxd.git cd usbfluxd ./autogen.sh make sudo make install Accept the USB over TCP connection, and appear as local: (you may need to change 172.17.0.1 to the IP address of the host. e.g. check ip addr) # on the guest sudo launchctl start usbmuxd export PATH=/usr/local/sbin:${PATH} sudo usbfluxd -f -r 172.17.0.1:5000 Close apps such as Xcode and reopen them and your device should appear! If you need to start again on Linux, wipe the current usbfluxd, usbmuxd, and socat: sudo killall usbfluxd sudo systemctl restart usbmuxd sudo killall socat Make container FASTER using https://github.com/sickcodes/osx-optimizer SEE commands in https://github.com/sickcodes/osx-optimizer! Skip the GUI login screen (at your own risk!) Disable spotlight indexing on macOS to heavily speed up Virtual Instances. Disable heavy login screen wallpaper Disable updates (at your own risk!) Increase disk space by moving /var/lib/docker to external drive, block storage, NFS, or any other location conceivable. Move /var/lib/docker, following the tutorial below Cheap large physical disk storage instead using your server's disk, or SSD. Block Storage, NFS, etc. Tutorial here: https://sick.codes/how-to-run-docker-from-block-storage/ Only follow the above tutorial if you are happy with wiping all your current Docker images/layers. Safe mode: Disable docker temporarily so you can move the Docker folder temporarily. Do NOT do this until you have moved your image out already https://github.com/dulatello08/Docker-OSX/#quick-start-your-own-image-naked-container-image killall dockerd systemctl disable --now docker systemctl disable --now docker.socket systemctl stop docker systemctl stop docker.socket Now, that Docker daemon is off, move /var/lib/docker somewhere Then, symbolicly link /var/lib/docker somewhere: mv /var/lib/docker /run/media/user/some_drive/docker ln -s /run/media/user/some_drive/docker /var/lib/docker # now check if /var/lib/docker is working still ls /var/lib/docker If you see folders, then it worked. You can restart Docker, or just reboot if you want to be sure. Important notices: 2021-11-14 - Added High Sierra, Mojave Pick one of these while building, irrelevant when using docker pull: --build-arg SHORTNAME=high-sierra --build-arg SHORTNAME=mojave --build-arg SHORTNAME=catalina --build-arg SHORTNAME=big-sur --build-arg SHORTNAME=monterey --build-arg SHORTNAME=ventura --build-arg SHORTNAME=sonoma Technical details There are currently multiple images, each with different use cases (explained below): High Sierra Mojave Catalina Big Sur Monterey Ventura Sonoma Auto (pre-made Catalina) Naked (use your own .img) Naked-Auto (user your own .img and SSH in) High Sierra: Mojave: Catalina: Big-Sur: Monterey make your own image: Ventura make your own image: Sonoma make your own image: Pre-made Catalina system by Sick.Codes: username: user, password: alpine Naked: Bring-your-own-image setup (use any of the above first): Naked Auto: same as above but with -e USERNAME & -e PASSWORD and -e OSX_COMMANDS=\"put your commands here\" Capabilities use iPhone OSX KVM on Linux using usbfluxd! macOS Monterey VM on Linux! Folder sharing- USB passthrough (hotplug too) SSH enabled (localhost:50922) VNC enabled (localhost:8888) if using ./vnc version iMessage security research via serial number generator! X11 forwarding is enabled runs on top of QEMU + KVM supports Big Sur, custom images, Xvfb headless mode you can clone your container with docker commit Requirements 20GB+++ disk space for bare minimum installation (50GB if using Xcode) virtualization should be enabled in your BIOS settings a x86_64 kvm-capable host at least 50 GBs for :auto (half for the base image, half for your runtime image TODO documentation for security researchers gpu acceleration support for virt-manager Docker Images built on top of the contents of this repository are also available on Docker Hub for convenience: https://hub.docker.com/r/sickcodes/docker-osx A comprehensive list of the available Docker images and their intended purpose can be found in the Instructions. Kubernetes Docker-OSX supports Kubernetes. Kubernetes Helm Chart & Documentation can be found under the helm directory. Thanks cephasara for contributing this major contribution. Support Small questions & issues Feel free to open an issue, should you come across minor issues with running Docker-OSX or have any questions. Resolved issues Before you open an issue, however, please check the closed issues and confirm that you're using the latest version of this repository — your issues may have already been resolved! You might also see your answer in our questions and answers section below. Feature requests and updates Follow @sickcodes! Professional support For more sophisticated endeavours, we offer the following support services: Enterprise support, business support, or casual support. Custom images, custom scripts, consulting (per hour available!) One-on-one conversations with you or your development team. In case you're interested, contact @sickcodes on Twitter or click here. License/Contributing Docker-OSX is licensed under the GPL v3+. Contributions are welcomed and immensely appreciated. You are in fact permitted to use Docker-OSX as a tool to create proprietary software. Other cool Docker/QEMU based projects Run Android in a Docker Container with Dock Droid Run Android fully native on the host! Run iOS 12 in a Docker container with Docker-eyeOS - https://github.com/sickcodes/Docker-eyeOS Run iMessage relayer in Docker with Bluebubbles.app - Getting started wiki Disclaimer If you are serious about Apple Security, and possibly finding 6-figure bug bounties within the Apple Bug Bounty Program, then you're in the right place! Further notes: Is Hackintosh, OSX-KVM, or Docker-OSX legal? Product names, logos, brands and other trademarks referred to within this project are the property of their respective trademark holders. These trademark holders are not affiliated with our repository in any capacity. They do not sponsor or endorse this project in any way. Instructions Container images Already set up or just looking to make a container quickly? Check out our quick start or see a bunch more use cases under our container creation examples section. There are several different Docker-OSX images available that are suitable for different purposes. sickcodes/docker-osx:latest - I just want to try it out. sickcodes/docker-osx:latest - I want to use Docker-OSX to develop/secure apps in Xcode (sign into Xcode, Transporter) sickcodes/docker-osx:naked - I want to use Docker-OSX for CI/CD-related purposes (sign into Xcode, Transporter) Create your personal image using :latest or big-sur. Then, pull the image out the image. Afterwards, you will be able to duplicate that image and import it to the :naked container, in order to revert the container to a previous state repeatedly. sickcodes/docker-osx:auto - I'm only interested in using the command line (useful for compiling software or using Homebrew headlessly). sickcodes/docker-osx:naked - I need iMessage/iCloud for security research. sickcodes/docker-osx:big-sur - I want to run Big Sur. sickcodes/docker-osx:monterey - I want to run Monterey. sickcodes/docker-osx:ventura - I want to run Ventura. sickcodes/docker-osx:sonoma - I want to run Sonoma. sickcodes/docker-osx:high-sierra - I want to run High Sierra. sickcodes/docker-osx:mojave - I want to run Mojave. Initial setup Before you do anything else, you will need to turn on hardware virtualization in your BIOS. Precisely how will depend on your particular machine (and BIOS), but it should be straightforward. Then, you'll need QEMU and some other dependencies on your host: # ARCH sudo pacman -S qemu libvirt dnsmasq virt-manager bridge-utils flex bison iptables-nft edk2-ovmf # UBUNTU DEBIAN sudo apt install qemu qemu-kvm libvirt-clients libvirt-daemon-system bridge-utils virt-manager libguestfs-tools # CENTOS RHEL FEDORA sudo yum install libvirt qemu-kvm Then, enable libvirt and load the KVM kernel module: sudo systemctl enable --now libvirtd sudo systemctl enable --now virtlogd echo 1sudo tee /sys/module/kvm/parameters/ignore_msrs sudo modprobe kvm I'd like to run Docker-OSX on Windows Running Docker-OSX on Windows is possible using WSL2 (Windows 11 + Windows Subsystem for Linux). You must have Windows 11 installed with build 22000+ (21H2 or higher). First, install WSL on your computer by running this command in an administrator powershell. For more info, look here. This will install Ubuntu by default. wsl --install You can confirm WSL2 is enabled using wsl -l -v in PowerShell. To see other distributions that are available, use wsl -l -o. If you have previously installed WSL1, upgrade to WSL 2. Check this link to upgrade from WSL1 to WSL2. After WSL installation, go to C:/Users//.wslconfig and add nestedVirtualization=true to the end of the file (If the file doesn't exist, create it). For more information about the .wslconfig file check this link. Verify that you have selected \"Show Hidden Files\" and \"Show File Extensions\" in File Explorer options. The result should be like this: [wsl2] nestedVirtualization=true Go into your WSL distro (Run wsl in powershell) and check if KVM is enabled by using the kvm-ok command. The output should look like this: INFO: /dev/kvm exists KVM acceleration can be used Use the command sudo apt -y install bridge-utils cpu-checker libvirt-clients libvirt-daemon qemu qemu-kvm to install it if it isn't. Now download and install Docker for Windows if it is not already installed. After installation, go into Settings and check these 2 boxes: General -> \"Use the WSL2 based engine\"; Resources -> WSL Integration -> \"Enable integration with my default WSL distro\", Ensure x11-apps is installed. Use the command sudo apt install x11-apps -y to install it if it isn't. Finally, there are 3 ways to get video output: WSLg: This is the simplest and easiest option to use. There may be some issues such as the keyboard not being fully passed through or seeing a second mouse on the desktop - Issue on WSLg - but this option is recommended. To use WSLg's built-in X-11 server, change these two lines in the docker run command to point Docker-OSX to WSLg. -e \"DISPLAY=${DISPLAY:-:0.0}\" \\ -v /mnt/wslg/.X11-unix:/tmp/.X11-unix \\ Or try: -e \"DISPLAY=${DISPLAY:-:0}\" \\ -v /mnt/wslg/.X11-unix:/tmp/.X11-unix \\ For Ubuntu 20.x on Windows, see #458 VNC: See the VNC section for more information. You could also add -vnc argument to qemu. Connect to your mac VM via a VNC Client. Here is a how to Desktop Environment: This will give you a full desktop linux experience but it will use a bit more of the computer's resources. Here is an example guide, but there are other guides that help set up a desktop environment. DE Example Additional boot instructions for when you are creating your container Boot the macOS Base System (Press Enter) Click Disk Utility Erase the BIGGEST disk (around 200gb default), DO NOT MODIFY THE SMALLER DISKS. -- if you can't click erase, you may need to reduce the disk size by 1kb (optional) Create a partition using the unused space to house the OS and your files if you want to limit the capacity. (For Xcode 12 partition at least 60gb.) Click Reinstall macOS The system may require multiple reboots during installation Troubleshooting Routine checks This is a great place to start if you are having trouble getting going, especially if you're not that familiar with Docker just yet. Just looking to make a container quickly? Check out our container creation examples section. More specific/advanced troubleshooting questions and answers may be found in More Questions and Answers. You should also check out the closed issues. Someone else might have gotten a question like yours answered already even if you can't find it in this document! Confirm that your CPU supports virtualization See initial setup. Docker Unknown Server OS error docker: unknown server OS: . See 'docker run --help'. This means your docker daemon is not running. pgrep dockerd should return nothing Therefore, you have a few choices. sudo dockerd for foreground Docker usage. I use this. Or sudo systemctl --start dockerd to start dockerd this now. Or sudo systemctl --enable --now dockerd for start dockerd on every reboot, and now. Use more CPU Cores/SMP Examples: -e EXTRA='-smp 6,sockets=3,cores=2' -e EXTRA='-smp 8,sockets=4,cores=2' -e EXTRA='-smp 16,sockets=8,cores=2' Note, unlike memory, CPU usage is shared. so you can allocate all of your CPU's to the container. Confirm your user is part of the Docker group, KVM group, libvirt group Add yourself to the Docker group If you use sudo dockerd or dockerd is controlled by systemd/systemctl, then you must be in the Docker group. If you are not in the Docker group: sudo usermod -aG docker \"${USER}\" and also add yourself to the kvm and libvirt groups if needed: sudo usermod -aG libvirt \"${USER}\" sudo usermod -aG kvm \"${USER}\" See also: initial setup. Is the docker daemon enabled? # run ad hoc sudo dockerd # or daemonize it sudo nohup dockerd & # enable it in systemd (it will persist across reboots this way) sudo systemctl enable --now docker # or just start it as your user with systemd instead of enabling it systemctl start docker More Questions and Answers Big thank you to our contributors who have worked out almost every conceivable issue so far! https://github.com/sickcodes/Docker-OSX/blob/master/CREDITS.md Start the same container later (persistent disk) Created a container with docker run and want to reuse the underlying image again later? NB: see container creation examples first for how to get to the point where this is applicable. This is for when you want to run the SAME container again later. You may need to use docker commit to save your container before you can reuse it. Check if your container is persisted with docker ps --all. If you don't run this you will have a new image every time. # look at your recent containers and copy the CONTAINER ID docker ps --all # docker start the container ID docker start -ai abc123xyz567 # if you have many containers, you can try automate it with filters like this # docker ps --all --filter \"ancestor=sickcodes/docker-osx\" # for locally tagged/built containers # docker ps --all --filter \"ancestor=docker-osx\" You can also pull the .img file out of the container, which is stored in /var/lib/docker, and supply it as a runtime argument to the :naked Docker image. See also: here. I have used Docker-OSX before and want to restart a container that starts automatically Containers that use sickcodes/docker-osx:auto can be stopped while being started. # find last container docker ps -a # docker start old container with -i for interactive, -a for attach STDIN/STDOUT docker start -ai -iLibGTK errors \"connection refused\" You may see one or more libgtk-related errors if you do not have everything set up for hardware virtualisation yet. If you have not yet done so, check out the initial setup section and the routine checks section as you may have missed a setup step or may not have all the needed Docker dependencies ready to go. See also: here. Permissions denied error If you have not yet set up xhost, try the following: echo $DISPLAY # ARCH sudo pacman -S xorg-xhost # UBUNTU DEBIAN sudo apt install x11-xserver-utils # CENTOS RHEL FEDORA sudo yum install xorg-x11-server-utils # then run xhost + RAM over-allocation You cannot allocate more RAM than your machine has. The default is 3 Gigabytes: -e RAM=3. If you are trying to allocate more RAM to the container than you currently have available, you may see an error like the following: cannot set up guest memory 'pc.ram': Cannot allocate memory. See also: here, here. For example (below) the buff/cache already contains 20 Gigabytes of allocated RAM: [user@hostname ~]$ free -mh total used free shared buff/cache available Mem: 30Gi 3.5Gi 7.0Gi 728Mi 20Gi 26Gi Swap: 11Gi 0B 11Gi Clear the buffer and the cache: sudo tee /proc/sys/vm/drop_caches10023:container:1002380:guest On the host machine, run: docker run -it \\ --device /dev/kvm \\ -p 50922:10022 \\ -e ADDITIONAL_PORTS='hostfwd=tcp::10023-:80,' \\ -p 10023:10023 \\ sickcodes/docker-osx:auto In a Terminal session running the container, run: /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\" brew install nginx sudo sed -i -e 's/8080/80/' /usr/local/etc/nginx/nginx.confcd # sudo nginx -s stop sudo nginx nginx should now be reachable on port 10023. Additionally, you can string multiple statements together, for example: -e ADDITIONAL_PORTS='hostfwd=tcp::10023-:80,hostfwd=tcp::10043-:443,' -p 10023:10023 \\ -p 10043:10043 \\ Bridged networking You might not need to do anything with the default setup to enable internet connectivity from inside the container. Additionally, curl may work even if ping doesn't. See discussion here and here and here. Enable IPv4 forwarding for bridged network connections for remote installations This is not required for LOCAL installations. Additionally note it may cause the host to leak your IP, even if you're using a VPN in the container. However, if you're trying to connect to an instance of Docker-OSX remotely (e.g. an instance of Docker-OSX hosted in a datacenter), this may improve your performance: # enable for current session sudo sysctl -w net.ipv4.ip_forward=1 # OR # sudo tee /proc/sys/net/ipv4/ip_forward . For example, to kill everything, docker psxargs docker kill. Native QEMU VNC example docker run -i \\ --device /dev/kvm \\ -p 50922:10022 \\ -p 5999:5999 \\ -v /tmp/.X11-unix:/tmp/.X11-unix \\ -e \"DISPLAY=${DISPLAY:-:0.0}\" \\ -e EXTRA=\"-display none -vnc 0.0.0.0:99,password=on\" \\ sickcodes/docker-osx:big-sur # type `change vnc password myvncusername` into the docker terminal and set a password # connect to localhost:5999 using VNC # qemu 6 seems to require a username for vnc now NOT TLS/HTTPS Encrypted at all! Or ssh -N root@1.1.1.1 -L 5999:127.0.0.1:5999, where 1.1.1.1 is your remote server IP. (Note: if you close port 5999 and use the SSH tunnel, this becomes secure.) Building a headless container to run remotely with secure VNC Add the following line: -e EXTRA=\"-display none -vnc 0.0.0.0:99,password=on\" In the Docker terminal, press enter until you see (qemu). Type change vnc password someusername Enter a password for your new vnc username^. You also need the container IP: docker inspect| jq -r '.[0].NetworkSettings.IPAddress' Or ip n will usually show the container IP first. Now VNC connects using the Docker container IP, for example 172.17.0.2:5999 Remote VNC over SSH: ssh -N root@1.1.1.1 -L 5999:172.17.0.2:5999, where 1.1.1.1 is your remote server IP and 172.17.0.2 is your LAN container IP. Now you can direct connect VNC to any container built with this command! I'd like to use SPICE instead of VNC Optionally, you can enable the SPICE protocol, which allows use of remote-viewer to access your OSX container rather than VNC. Note: -disable-ticketing will allow unauthenticated access to the VM. See the spice manual for help setting up authenticated access (\"Ticketing\"). docker run \\ --device /dev/kvm \\ -p 3001:3001 \\ -p 50922:10022 \\ -e \"DISPLAY=${DISPLAY:-:0.0}\" \\ -e EXTRA=\"-monitor telnet::45454,server,nowait -nographic -serial null -spice disable-ticketing,port=3001\" \\ mycustomimage Then simply do remote-viewer spice://localhost:3001 and add --spice-debug for debugging. Creating images based on an already configured and set up container # You can create an image of an already configured and setup container. # This allows you to effectively duplicate a system. # To do this, run the following commands # make note of your container id docker ps --all docker commit containerid newImageName # To run this image do the following docker run \\ --device /dev/kvm \\ --device /dev/snd \\ -v /tmp/.X11-unix:/tmp/.X11-unix \\ newImageName docker pull sickcodes/docker-osx:auto # boot directly into a real OS X shell with no display (Xvfb) [HEADLESS] docker run -it \\ --device /dev/kvm \\ -p 50922:10022 \\ sickcodes/docker-osx:auto # username is user # passsword is alpine # Wait 2-3 minutes until you drop into the shell. Run the original version of Docker-OSX docker pull sickcodes/docker-osx:latest docker run -it \\ --device /dev/kvm \\ --device /dev/snd \\ -v /tmp/.X11-unix:/tmp/.X11-unix \\ -e \"DISPLAY=${DISPLAY:-:0.0}\" \\ sickcodes/docker-osx:latest # press CTRL + G if your mouse gets stuck # scroll down to troubleshooting if you have problems # need more RAM and SSH on localhost -p 50922? Run but enable SSH in OS X (Original Version)! docker run -it \\ --device /dev/kvm \\ --device /dev/snd \\ -p 50922:10022 \\ -v /tmp/.X11-unix:/tmp/.X11-unix \\ -e \"DISPLAY=${DISPLAY:-:0.0}\" \\ sickcodes/docker-osx:latest # turn on SSH after you've installed OS X in the \"Sharing\" settings. ssh user@localhost -p 50922 Autoboot into OS X after you've installed everything Add the extra option -e NOPICKER=true. Old machines: # find your containerID docker ps # move the no picker script on top of the Launch script # NEW CONTAINERS docker exec containerID mv ./Launch-nopicker.sh ./Launch.sh # VNC-VERSION-CONTAINER docker exec containerID mv ./Launch-nopicker.sh ./Launch_custom.sh # LEGACY CONTAINERS docker exec containerID bash -c \"grep -v InstallMedia ./Launch.sh > ./Launch-nopicker.sh chmod +x ./Launch-nopicker.sh sed -i -e s/OpenCore\\.qcow2/OpenCore\\-nopicker\\.qcow2/ ./Launch-nopicker.sh \" The big-sur image starts slowly after installation. Is this expected? Automatic updates are still on in the container's settings. You may wish to turn them off. We have future plans for development around this. What is ${DISPLAY:-:0.0}? $DISPLAY is the shell variable that refers to your X11 display server. ${DISPLAY} is the same, but allows you to join variables like this: e.g. ${DISPLAY}_${DISPLAY} would print :0.0_:0.0 e.g. $DISPLAY_$DISPLAY would print :0.0 ...because $DISPLAY_ is not $DISPLAY ${variable:-fallback} allows you to set a \"fallback\" variable to be substituted if $variable is not set. You can also use ${variable:=fallback} to set that variable (in your current terminal). In Docker-OSX, we assume, :0.0 is your default $DISPLAY variable. You can see what yours is echo $DISPLAY That way, ${DISPLAY:-:0.0} will use whatever variable your X11 server has set for you, else :0.0 What is -v /tmp/.X11-unix:/tmp/.X11-unix? -v is a Docker command-line option that lets you pass a volume to the container. The directory that we are letting the Docker container use is a X server display socket. /tmp/.X11-unix If we let the Docker container use the same display socket as our own environment, then any applications you run inside the Docker container will show up on your screen too! https://www.x.org/archive/X11R6.8.0/doc/RELNOTES5.html ALSA errors on startup or container creation You may when initialising or booting into a container see errors from the (qemu) console of the following form: ALSA lib blahblahblah: (function name) returned error: no such file or directory. These are more or less expected. As long as you are able to boot into the container and everything is working, no reason to worry about these. See also: here.",
    "commentLink": "https://news.ycombinator.com/item?id=41116473",
    "commentBody": "macOS in QEMU in Docker (github.com/sickcodes)445 points by lijunhao 14 hours agohidepastfavorite109 comments replete 7 hours agoThe only chance at GPU acceleration is passing through a supported dGPU (>= AMD RX 6xxx @ 14.x, no chance modern nvidia) with PCI passthrough. Intel iGPUs work up to Comet lake, and some Ice Lake, but anything newer will not work. Apple Silicon build of MacOS probably not going to be emulatable any time soon, though there is some early work in booting ARM darwin Also Intel VT-x is missing on AMD, so virtualization is busted on AMD hosts although some crazy hacks with old versions of virtualbox can make docker kind of work through emulation reply dang 2 hours agoprevRelated: Docker-OSX: Run macOS VM in a Docker - https://news.ycombinator.com/item?id=34374710 - Jan 2023 (110 comments) macOS in QEMU in Docker - https://news.ycombinator.com/item?id=23419101 - June 2020 (186 comments) reply xandrius 6 hours agoprevI'd love to try and see if it's possible to simply build for iOS. Say Unity, React Native, etc. This could be pretty awesome in terms of freedom, even if the build takes 5x more. reply shepherdjerred 2 hours agoparentCross-compiling is likely a better approach: https://github.com/tpoechtrager/osxcross This is how Godot targets iOS: https://github.com/godotengine/build-containers/blob/main/Do... Here's a Docker image with the tools preinstalled, though you'll need some tweaks to target iOS: https://github.com/shepherdjerred/macos-cross-compiler While at RStudio (now called Posit), I worked on cross-compiling C/C++/Fortran/Rust on a Linux host targeting x86_64/aarch64 macOS. If you download an R package with native code from Posit Package Manager (https://p3m.dev/client/), it was cross-compiled using this approach :) reply arcanemachiner 6 hours agoparentprevI did this. I had to share my USB port over Docker somehow (black magic I guess, instructions in the repo) and I was able to build iOS apps and run them on an iPhone. reply flawn 6 hours agorootparentWhat was the speed like? reply arcanemachiner 3 hours agorootparentFor a basic Flutter app: tolerable reply ProfessorZoom 6 hours agoparentprevThat would impressive if you could build for React Native iOS (with native Swift modules) and run it on a simulator in this on a Windows machine reply arilotter 56 minutes agorootparentyou can! you can also run it on a real iOS device using this tech. it's explicitly documented in the repo :) reply airstrike 4 hours agorootparentprevAt glacial speeds, indubitably. reply daft_pink 3 hours agoprevThis would be awesome to run iCloud sync on my homeserver. Currently, there is no good way to physically backup iCloud on a homeserver/nas, because it only runs on windows/apple. reply toomuchtodo 3 hours agoparentThis might assist you in syncing this data and then either storing locally or pushing elsewhere for backups: https://github.com/steilerDev/icloud-photos-sync https://github.com/icloud-photos-downloader/icloud_photos_do... reply bm3 1 hour agoparentprevHow would this help with that? What would this let you do that's different than just rsync'ing your iCloud folder from a connected Mac/PC to your NAS? reply prmoustache 11 hours agoprevIs the redistribution of MacOS images allowed by the license or is this project distributing illegal copies in plain sight on docker hub? reply yao420 5 hours agoparentIdk but Correlium virtualizes iOS instances and was sued by Apple before settling the case. reply meatjuice 7 hours agoparentprevThis is clearly illegal reply diggan 5 hours agorootparent\"Illegal\" might be a bit strong, \"Against the EULA\" a bit more realistic, which may or may not be illegal, depending on the context and involved country. reply scintill76 2 hours agorootparentI’m not a lawyer, but pretty sure unauthorized redistribution of copyrighted material is a crime (in the US.) This docker image contains Apple copyrighted files, probably, but anyone feel free to explain if I’m wrong. reply tombert 1 hour agorootparentI suspect that it probably doesn't matter; Apple has generally not cared about Hackintoshes as long as you aren't selling pre-made Hackintoshes. Apple probably doesn't really mind for stuff like this, since this probably isn't realistically eating much into Apple's market. reply nine_k 11 hours agoprevSo, to clarify things: it's QEMU running in a container, and macOS running under QEMU inside it. This is really nice WRT the ease of installation: no manual setup steps and all. This likely expressly violates the [macOS EULA], which says: «you are granted a limited, non-exclusive license to install, use and run one (1) copy of the Apple Software on a single Apple-branded computer at any one time» — because the point is to run it not on a Mac. So, pull it and keep it around; expect a C&D letter come any moment. [macOS EULA]: https://www.apple.com/legal/sla/docs/macOSMonterey.pdf (Other versions contain the same language.) reply jbverschoor 11 hours agoparent(iii) to install, use and run up to two (2) additional copies or instances of the Apple Software, or any prior macOS or OS X operating system software or subsequent release of the Apple Software, within virtual operating system environments on each Apple-branded computer you own or control that is already running the Apple Software, for purposes of: (a) software development; (b) testing during software development; (c) using macOS Server; or (d) personal, non-commercial use reply wildzzz 4 hours agorootparentSo basically you can run macOS however you want as long as you're already running macOS on Apple hardware. The question I've always had is how enforceable is that really? Obviously the whole point of Apple making macOS freely available is to run it on Apple hardware. They don't give it out for free to run on other hardware but can they really do anything about that other than require you to enter a serial number to download an image? If they really cared, they would just do something like hashing the serial number and current date and time against a secret key (maybe inside a read-only portion of the TPM) and only Apple would be able to verify that the hardware is legit. You would need to somehow expose the TPM to the hypervisor to be able to generate hashes for macOS to verify it's license. Clearly this is not a huge problem for Apple because they would already be doing this if it was an issue. reply angulardragon03 3 hours agorootparentIt’s sort of enforceable - Apple’s own virtualisation framework that lots of VM providers use (on Apple Silicon) actually enforces a hard cap of two guests, and won’t allow you to spawn more. With other hosts, it’s kind of an Adobe approach - you either weren’t gonna buy a Mac anyways, or you might be tempted to buy a Mac after using macOS in a VM. Realistically, it’s not worth Apple coming after you unless you’re an enterprise making your money by breaking the EULA. reply pjmlp 2 hours agorootparentprevVia surprise audits from organisations like BSA, in collaboration with the police. https://www.bsa.org/ reply skeaker 1 hour agorootparentFor organizations, sure, but has this ever been done to an individual? reply pjmlp 1 hour agorootparentIndividuals most likely not. reply obituary_latte 4 hours agorootparentprevProbably as enforceable as any other EULA. Windows surely has similar language. I'd guess that somewhere buried deep in the agreements, or somewhere, it says they can audit your usage somehow. Does it ever happen? I'd be curious to know. reply naikrovek 2 hours agorootparentWindows doesn’t have similar language. Not directly, anyway. Depending on the edition of Windows you purchase and how your overall license agreement works, you get anywhere from zero to ten VM licenses per paid Windows license. I’m omitting a few details for brevity (MS licensing is nuts when you get into the weeds). reply nine_k 11 hours agorootparentprevIndeed. That would cover a conventionally installed VM, like VirtualBox. But this is packaged as a Docker image, and Docker is Linux-specific. Linux is not officially supported by Apple on their hardware, and is certainly not prevalent on it. I doubt that the intended target audience of this project is limited to Asahi Linux. reply jkaplowitz 6 hours agorootparentDocker actually ships their easy-to-use and commercially supported Docker Desktop product for macOS, which uses Apple's standard virtualization framework under the hood. I think it then runs the Docker containers within a Linux VM that it manages. For people who want an open-source CLI solution rather than a commercial product which for larger businesses requires payment, there's also colima which does roughly the same thing. So, lots of people very successfully use Docker on macOS, including on Apple hardware. This particular software would need nested virtualization to be highly performant, but at least on M3 or newer Macs running macOS 15 or newer, this is now supported by Apple's virtualization framework: https://developer.apple.com/documentation/virtualization/vzg... So, if that's not easy to do in a useful and performant way now, it will absolutely be possible in the foreseeable future. I'm sure that the longtime macOS virtualization product Parallels Desktop will add support for nested virtualization quite soon if they haven't already, in addition to whatever Docker Desktop and colima do. (Tangent: Asahi Linux apparently supports nested virtualization on M2 chips even though macOS doesn't.) reply nine_k 3 hours agorootparentRunning Linux in a VM (for Docker) to run an emulator (QEMU) in it to run macOS in that looks to me like a senseless waste of resources. Linux and Docker add no value into the mix here. The same result can be achieved by running macOS right in the VM. This can be extra efficient since both the host OS and the guest OS are macOS, and the VM could use this fact. It may make sense to run macOS in an emulator like QEMU under macOS, if the host version us ARM and the guest version is x64 (or vice versa). But I don't see where Linux and Docker would be useful in this case. reply jkaplowitz 1 hour agorootparentI agree the particular combo I was discussing is likely not very useful when compared to just directly virtualizing macOS directly, except in niche cases. One such case, however, is when the user is already managing Linux Docker containers for other parts of their development or testing workflow and wants to manage macOS containers with the same tooling. That’s legitimate enough, especially when it ends up supporting nested virtualization of the same architecture and not true emulation, to keep the performance penalty modest enough. reply rbut 10 hours agorootparentprevDocker can run on macOS (albeit in a VM), but its still running on a Mac \"that is already running the Apple Software\". So its a perfectly valid option for Mac owners, even if its a VM + container + VM deep. reply monocasa 9 hours agorootparentThis requires kvm exposed in the container. Does docker on mac support kvm? reply nine_k 8 hours agorootparentAFAICT, with QEMU, access to KVM is only required if you care about performance %) Otherwise it can emulate everything for you. reply monocasa 8 hours agorootparentThis dockerfile explicitly enables kvm in a way that will cause qemu to fail if it's not present. reply prmoustache 11 hours agorootparentprev> I doubt that the intended target audience of this project is limited to Asahi Linux. I guess that part of the license is meant to automatically disqualify an apple branded computer running a linux distro as host OS from running MacOS in a VM: \"on each Apple-branded computer you own or control that is already running the Apple Software\" Some smart ass might argue that \"already running the Apple software\" doesn't mean at the exact same time but more like \"I am still running it sometimes as dual boot\" but I am not sure this would pass the court test. And since I believe docker on MacOS runs on linux VM, so this would be running qemu on top of a linux vm on top of MacOS. I can't see any legit use of this. Anyone who would need automatized and disposable environments for CI/CD would simply use UTM on mac minis: https://docs.getutm.app/scripting/scripting/ reply exe34 10 hours agorootparentprevI run Linux on a Mac book air, so this would allow me to run macos in a controlled environment if I could think of a good reason to do so. reply EspadaV9 8 hours agorootparentNot sure that would be the case since it also includes this part > that is already running the Apple Software Running Linux on Apple hardware would not follow that part of the EULA. reply rfoo 6 hours agorootparentI believe it matches the base term, as you are allowed to run only one copy of the Apple software on an Apple hardware, unconditionally. It could be in a VM. reply thfuran 6 hours agorootparentAnd I guess once you've booted the VM, you are suddenly permitted to boot two more, as long as you have a lawyer on retainer just in case. reply exe34 7 hours agorootparentprevgood thing I can't think of any reason to run macos. reply ramses0 7 hours agorootparentThe Tao of Programming, 7.3: \"\"\" \"Corporate Headquarters has commanded,\" continued the magician, \"that everyone use this workstation as a platform for new programs. Do you agree to this?\" \"Certainly,\" replied the master, \"I will have it transported to the data center immediately!\" And the magician returned to his tower, well pleased. Several days later, a novice wandered into the office of the master programmer and said, \"I cannot find the listing for my new program. Do you know where it might be?\" \"Yes,\" replied the master, \"the listings are stacked on the platform in the data center.\" \"\"\" https://quasi.in/digital/ttop.html#Book7 reply exe34 6 hours agorootparentwell put. reply pzo 5 hours agorootparentprevSome unfortunately needs Xcode for building iOS or macOS apps locally even if you are coding in unity, flutter, react native, qt, unreal reply hundchenkatze 6 hours agoparentprev> expect a C&D letter come any moment. This repo is 4 years old... I don't think it's coming. reply riiii 5 hours agoparentprevI like the moaning sound the EULA makes when it gets violated. reply promiseofbeans 6 hours agoparentprevHey, not if you run it on a mac running Asahi reply m463 10 hours agoparentprevYou can run linux on a mac. In fact older intel used macs are inexpensive and run pretty well with little noise. ubuntu installs and runs easily. Other versions of linux - it depends. reply dqh 6 hours agorootparentUbuntu 24.04 is a disaster in my mid-2015 MBP. Ubuntu 22.04 is surprisingly good though. reply resource_waste 5 hours agorootparentTo be fair, I'm not sure any linux veterans are using Ubuntu. Its a popular OS, but its not a good OS. (Think terrible pop music that teenagers will still listen to) Even Debian has lost its favorability by having sooo much legacy bloat, bugs, and outdated kernels that wont run Nvidia GPUs(2023) or other recent peripherals. I'd be much more curious how Fedora or OpenSUSE hold up. reply skeledrew 4 hours agorootparentHow do you define \"veteran\"? I've been a Linux-only user for 10 years, and 9.5 of it is strictly with Kubuntu. reply ctoth 3 hours agoparentprevCan I get a whole bunch of Apple stickers and brand the heck out of an old Dell r630 Server and run this on it? Or how about a cattle brand with an Apple logo? reply arilotter 55 minutes agorootparenti remember making this joke a decade ago on the tonymacx86 forums, lots of people did it for the lulz reply user_7832 9 hours agoparentprev> So, to clarify things: it's QEMU running in a container, and macOS running under QEMU inside it. A bit tangential but is this more performant/\"better\" than running MacOS on say Hyper-V? I understand my zen 4 laptop anyway won't allow GPU acceleration, I'm only looking to run a few apps (and maybe Safari) on it. reply ptspts 7 hours agorootparentMy guess is that macOS on Hyper-V is faster. reply actionfromafar 8 hours agoparentprevHow much of these EULAs are actually enforceable though, and in which jurisdictions? Also, wouldn’t it be the end user potentially in violation of the EULA, not the git repo provider? Edit: agreed about OS images, that does not look legit. reply 7bit 8 hours agorootparentGitHub repost are taken down all the time because they offer means to violate EULAs. See youtube-dl which was taken down couple of months back. reply hoistbypetard 8 hours agorootparentThis youtube-dl? https://github.com/ytdl-org/youtube-dl Did it get taken down again? The takedown I remember was a few years ago, and GitHub announced some policy changes to make it harder for that to happen when they very loudly reinstated it: https://github.blog/news-insights/policy-news-and-insights/s... reply nine_k 8 hours agorootparentprevFair. But the docker image provider would be in violation, never having received a license to redistribute macOS images. Without these, the seamless usability aspect is gone, though the repo remains pretty useful because it automates all other steps. reply windexh8er 6 hours agorootparentIt's trivial to build these containers by grabbing the install images from Apple directly. Beyond that this is all covered in the documentation. I guess I'm curious why you're so focused on this violating anything? Apple clearly doesn't care as folks like myself have used it for years. Apple's target market is hardware buyers, not people who do things like this. If this actually impacted sales, sure - but Apple doesn't sell OSX anymore. As an aside the sickcodes work is great for people wanting to leverage Apple's \"Find My\" network with non-Apple devices by leveraging OpenHaystack [0]. [0] https://github.com/seemoo-lab/openhaystack reply rty32 5 hours agorootparentI assume EULA is mainly intended for preventing companies from running Hackintosh at a massive scale than aimed at individuals -- although build your business/infrastructure based on Hackintosh is a very questionable business and technical decision by itself. reply znpy 10 hours agoparentprev> you are granted a limited, non-exclusive license to install, use and run one (1) copy of the Apple Software on a single Apple-branded computer at any one time» In that case... If I run Asahi Linux on my apple-silicon macbook pro as main operating system and then run macOS in a container I should be fine. reply prmoustache 10 hours agorootparentSee the rest of the license, the host must be \"already running the MacOS operating system\" which I understand as host OS, not as capable of still running it because the sshd hasn't been wiped of a MacOS install. reply manojlds 7 hours agoparentprevWhy are you talking as though this is a new project. It's been around for years reply elliotto 10 hours agoparentprevWho cares lol reply mosselman 6 hours agorootparentI don’t think Apple would feel very threatened by this indeed. I share the who cares lol reply slivanes 12 hours agoprevI wonder if progress will halt once newer versions of MacOS without Intel support are released? Can I run docker inside this container to get MacOS to run inside MacOS? ;) reply vbezhenar 12 hours agoparentTheoretically you can always run qemu in full emulation mode. reply itsTyrion 4 hours agorootparentAnd practically even a minimal debian install takes minutes to boot to TTY with qemu-aarch64 on AMD64 reply ProfessorZoom 6 hours agoparentprevwe must go deeper reply fragmede 12 hours agoparentprevI mean you can just do that in any supported vm program. reply Izmaki 10 hours agoprevI really hate when \"USB Passthrough\" is used in situations when, at best, a \"USB over ethernet proxy\" is what is happening. That's not passthrough... It introduces a whole range of disadvantages that regular passthrough does not (and advanced passthrough might not) have. reply arghwhat 10 hours agoparentEh? QEMU USB passthrough is true USB passthrough. The problems with USB passthrough stem from issues related to USB controllers themselves and how device enumeration works, with the only better solution being PCIe passthrough of entire USB controllers... Which then present a different set of problems. Speaking from experience in large VM test farms with a significant amount of forwarded hardware. (However, \"USB over ethernet proxy\" is also a true passthrough, just one with higher latency than VirtIO.) reply Izmaki 9 hours agorootparentI skimmed the README only and just saw the big section of USB over ethernet with the video image and everything, not the tiny mentioning of VFIO above it. Lol. But tell me please, which problems do you have with PCIe passthrough? Also speaking from experience in large VM test farms with a significant amount of forwarded hardware. I've never experienced problems with hundreds of machines doing exactly this, for years. reply arghwhat 9 hours agorootparentPCIe passthrough has a few quirks: 1. VMs operate on a copy of certain PCIe descriptors obtained during enumeration/when forwarding was setup, meaning that some firwmare updates that depend on these changing cannot work correctly. The exact details have left my memory. 2. Foo states that only happen when forwarding. Hardware that seems so stable when used directly that bugs would seem inconceivable enter into broken states when forwarded and fail to initialize within the VM. Hardware and drivers are both full of bugs, and things become \"fun\" when either get surprised. You can deal with it when you're doing the forwarding your own hardware and using your own drivers so discovered issues can be debugged and sorted out, but it's much less fun when you're forwarding stuff from other vendors out of necessity. Dealt with this one just this morning. 3. Reset bugs. Hardware reset and sequencing is a tricky area (speaking from old FPGA experience), and some devices cannot recover without a full power cycle. In some cases, I can recover the device by stopping the forward, removing the device (echo 1 > /sys/bus/pci/devices/.../remove), rescanning and letting the host kernel temporarily load drivers and initialize the device, and then forward it again. Did that today. 4. Host crashes. Yay. Forwarding a single device on a user machine that still gets regular reboots tends to work fine, but things get hairy when you scale this up. I've had to do a lot of automation of things like handing devices back to the hypervisor for recovery and firmware management. reply Izmaki 8 hours agorootparentStrange... Sounds like you may be doing too many things manually or that what you're testing is the device that is connected directly to USB? In my case I need 3rd party USB devices (that always just work(™)) to communicate and interact with hardware. Been automating/running literally hundreds of these configurations without a single issue related to USB or PCI passthrough. Even got switchable HUBs for USB in the mix sometimes, too (for power cycling specific USB devices). Works fine as well. reply arghwhat 8 hours agorootparent\"Manually\"? There is only QEMU/KVM, how many layers you put in between does not matter. Proxmox is just a pile of perl scripts doing the same. My experience is in testing both USB downstream devices and PCIe devices developed in-house. Some of the forwarded devices might be 3rd-party devices like hubs, relays for power cycling and USB isolators to simulate hot-plug, but the DUTs are stuff we manufacture. In the USB test scenarios (we have about ~100 such machines, on average connected to a dozen DUTs, some more), the symptom of failure is generally that the entire controller can discover downstream devices but permanently fail to communicate with any of them, or that the controller itself fails to initialize entirely. The PCIe test scenarios is not something I actively work with anymore, but involves a server room full of machines with 4-7 DUTs each and much more custom handling - such as hot-unplugging the device from the VM, resetting and firmware updating the device, and hot-plugging it back as part of the test running in that VM - as testing PCIe devices themselves exercise many more issues that you don't see with standardized hardware. I have done this for about a decade, so I've been through a few iterations and tech stacks. One can find things that work, but it's not in any way or form guaranteed to work. reply ThatMedicIsASpy 9 hours agorootparentprevOn proxmox with a USB DAC/AMP it is impossible to get correct audio without pcie passthrough of the usb controller reply Izmaki 9 hours agorootparentYeah, isochronous mode is unfortunately not supported for USB passthrough on Proxmox. There were experimental implementations in oVirt back in the days (that is: experimental implementations in a non-prod, only-for-evaluation solution...). reply bckr 7 hours agoprevLet’s say I wanted to run a headless Logic Pro for programmatic music production. Would I use this? Or should I containerize the application itself? It’s okay if I have to run it on Apple hardware. reply replete 6 hours agoparentDepends on whether you have plugins requiring GPU acceleration, as there is none reply JayDustheadz 10 hours agoprevCan this be launched on an M1 Mac? I'm trying to find a way to run a Big Sur VM on my M1 Mac on Monterey/Ventura. reply bspinner 3 hours agoparentCheckout tart: https://tart.run/quick-start/ It uses Apples Virtualization framework and works well, besides issues with virtiofs. But those can be worked around with virtual block devices aka images. reply hamandcheese 2 hours agorootparent+1 for Tart (and seconded on avoiding virtiofs - which as a virtualization.framework problem, not and indictment on Tart's quality). reply dyllon 10 hours agoparentprevCouldn’t you use UTM to run a macOS VM? reply JayDustheadz 10 hours agorootparentSadly it doesn't look like it: https://mac.getutm.app/ \"Note that macOS VM support is limited to ARM based Macs running macOS Monterey or higher.\" reply orbat 8 hours agoparentprevHave you run into Viable https://eclecticlight.co/virtualisation-on-apple-silicon/ or VirtualBuddy https://github.com/insidegui/VirtualBuddy ? I think at least Viable has some limitations though Edit: \"some\" limitations is putting it lightly. From https://eclecticlight.co/2022/11/17/lightweight-virtualisati... which is apparently still current: > Apple’s current implementation of lightweight virtualisation still has no support for Apple ID, iCloud, or any service dependent on them, including Handoff and AirDrop. Perhaps the most severe limitation resulting from this is that you can’t run the great majority of App Store apps, although Apple’s free apps including Pages, Numbers and Keynote can still be copied over from the host and run in a guest macOS. Same deal with VirtualBuddy, apparently the root of the problem is that some sort of hardware validations fail in VMs https://github.com/insidegui/VirtualBuddy/discussions/27 reply synchrone 7 hours agoprevAny word if this would run the iOS simulator? Edit: it actually does! reply arusahni 7 hours agoprevLooking forward to kicking the tires on this to validate functionality in Safari. reply dariosalvi78 12 hours agoprevCan this run xcode? reply XiS 12 hours agoparentI tried this last year. It works though it's pretty slow. I really hate having to also support the Apple ecosystem. Development, CI/CD integration is really poor without having to buy the hardware. reply keyle 11 hours agorootparentI run full apple hardware andDocker-OSX now has a Discord server & Telegram! The Discord is active on #docker-osx and anyone is welcome to come and ask questions, ideas, etc. No forum eh? Everyone should come to the live channels and ask the same questions again :) reply 42lux 8 hours agoparent [–] Discussions are open on their repo... reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Docker-OSX allows users to run macOS in a Docker container with near-native performance, supporting versions from High Sierra to Sonoma.",
      "The project is maintained by Sick.Codes and includes features like X11 forwarding, iMessage security research, and iPhone USB passthrough.",
      "This tool is particularly useful for conducting security research on macOS using both Linux and Windows environments."
    ],
    "commentSummary": [
      "Running macOS in QEMU within Docker is feasible but has limitations, particularly with GPU acceleration, as newer Intel and NVIDIA GPUs are unsupported.",
      "Docker-OSX enables running macOS virtual machines in Docker, which is beneficial for iOS builds using tools like Unity or React Native.",
      "Redistribution of macOS images may breach Apple's End User License Agreement (EULA), which restricts macOS to Apple hardware, yet the project is popular for development and testing."
    ],
    "points": 445,
    "commentCount": 109,
    "retryCount": 0,
    "time": 1722401472
  },
  {
    "id": 41115941,
    "title": "`find` + `mkdir` is Turing complete",
    "originLink": "https://ogiekako.vercel.app/blog/find_mkdir_tc",
    "originBody": "Randomly updated(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])self.__next_f.push([1,\"1:HL[\\\"/_next/static/media/c9a5bc6a7c948fb0-s.p.woff2\\\",\\\"font\\\",{\\\"crossOrigin\\\":\\\"\\\",\\\"type\\\":\\\"font/woff2\\\"}]2:HL[\\\"/_next/static/css/02c5d06015cc815a.css\\\",\\\"style\\\"]3:HL[\\\"/_next/static/css/5a5a5b27c0aa3b33.css\\\",\\\"style\\\"]4:HL[\\\"/_next/static/css/5c2046c3bdb9f716.css\\\",\\\"style\\\"]\"])self.__next_f.push([1,\"5:I[5751,[],\\\"\\\"]7:I[6513,[],\\\"ClientPageRoot\\\"]8:I[2288,[\\\"954\\\",\\\"static/chunks/d3ac728e-4b206cbaf69c01f2.js\\\",\\\"740\\\",\\\"static/chunks/740-a5a946ff64441fea.js\\\",\\\"667\\\",\\\"static/chunks/app/blog/%5B%5B...slug%5D%5D/page-d219266bed70eb59.js\\\"],\\\"default\\\"]9:I[9275,[],\\\"\\\"]b:I[1343,[],\\\"\\\"]d:I[6130,[],\\\"\\\"]a:[\\\"slug\\\",\\\"find_mkdir_tc\\\",\\\"oc\\\"]e:[]\"])self.__next_f.push([1,\"0:[[[\\\"$\\\",\\\"link\\\",\\\"0\\\",{\\\"rel\\\":\\\"stylesheet\\\",\\\"href\\\":\\\"/_next/static/css/02c5d06015cc815a.css\\\",\\\"precedence\\\":\\\"next\\\",\\\"crossOrigin\\\":\\\"$undefined\\\"}],[\\\"$\\\",\\\"link\\\",\\\"1\\\",{\\\"rel\\\":\\\"stylesheet\\\",\\\"href\\\":\\\"/_next/static/css/5a5a5b27c0aa3b33.css\\\",\\\"precedence\\\":\\\"next\\\",\\\"crossOrigin\\\":\\\"$undefined\\\"}]],[\\\"$\\\",\\\"$L5\\\",null,{\\\"buildId\\\":\\\"uu7g4PJ_liuMYS5crqjLe\\\",\\\"assetPrefix\\\":\\\"\\\",\\\"initialCanonicalUrl\\\":\\\"/blog/find_mkdir_tc\\\",\\\"initialTree\\\":[\\\"\\\",{\\\"children\\\":[\\\"blog\\\",{\\\"children\\\":[[\\\"slug\\\",\\\"find_mkdir_tc\\\",\\\"oc\\\"],{\\\"children\\\":[\\\"__PAGE__\\\",{}]}]}]},\\\"$undefined\\\",\\\"$undefined\\\",true],\\\"initialSeedData\\\":[\\\"\\\",{\\\"children\\\":[\\\"blog\\\",{\\\"children\\\":[[\\\"slug\\\",\\\"find_mkdir_tc\\\",\\\"oc\\\"],{\\\"children\\\":[\\\"__PAGE__\\\",{},[[\\\"$L6\\\",[\\\"$\\\",\\\"$L7\\\",null,{\\\"props\\\":{\\\"params\\\":{\\\"slug\\\":[\\\"find_mkdir_tc\\\"]},\\\"searchParams\\\":{}},\\\"Component\\\":\\\"$8\\\"}]],null],null]},[\\\"$\\\",\\\"$L9\\\",null,{\\\"parallelRouterKey\\\":\\\"children\\\",\\\"segmentPath\\\":[\\\"children\\\",\\\"blog\\\",\\\"children\\\",\\\"$a\\\",\\\"children\\\"],\\\"error\\\":\\\"$undefined\\\",\\\"errorStyles\\\":\\\"$undefined\\\",\\\"errorScripts\\\":\\\"$undefined\\\",\\\"template\\\":[\\\"$\\\",\\\"$Lb\\\",null,{}],\\\"templateStyles\\\":\\\"$undefined\\\",\\\"templateScripts\\\":\\\"$undefined\\\",\\\"notFound\\\":\\\"$undefined\\\",\\\"notFoundStyles\\\":\\\"$undefined\\\",\\\"styles\\\":[[\\\"$\\\",\\\"link\\\",\\\"0\\\",{\\\"rel\\\":\\\"stylesheet\\\",\\\"href\\\":\\\"/_next/static/css/5c2046c3bdb9f716.css\\\",\\\"precedence\\\":\\\"next\\\",\\\"crossOrigin\\\":\\\"$undefined\\\"}]]}],null]},[\\\"$\\\",\\\"$L9\\\",null,{\\\"parallelRouterKey\\\":\\\"children\\\",\\\"segmentPath\\\":[\\\"children\\\",\\\"blog\\\",\\\"children\\\"],\\\"error\\\":\\\"$undefined\\\",\\\"errorStyles\\\":\\\"$undefined\\\",\\\"errorScripts\\\":\\\"$undefined\\\",\\\"template\\\":[\\\"$\\\",\\\"$Lb\\\",null,{}],\\\"templateStyles\\\":\\\"$undefined\\\",\\\"templateScripts\\\":\\\"$undefined\\\",\\\"notFound\\\":\\\"$undefined\\\",\\\"notFoundStyles\\\":\\\"$undefined\\\",\\\"styles\\\":null}],null]},[[\\\"$\\\",\\\"html\\\",null,{\\\"lang\\\":\\\"en\\\",\\\"children\\\":[\\\"$\\\",\\\"body\\\",null,{\\\"className\\\":\\\"__className_aaf875\\\",\\\"children\\\":[\\\"$\\\",\\\"main\\\",null,{\\\"className\\\":\\\"flex min-h-screen flex-col items-center justify-between p-4 md:p-24\\\",\\\"children\\\":[\\\"$\\\",\\\"$L9\\\",null,{\\\"parallelRouterKey\\\":\\\"children\\\",\\\"segmentPath\\\":[\\\"children\\\"],\\\"error\\\":\\\"$undefined\\\",\\\"errorStyles\\\":\\\"$undefined\\\",\\\"errorScripts\\\":\\\"$undefined\\\",\\\"template\\\":[\\\"$\\\",\\\"$Lb\\\",null,{}],\\\"templateStyles\\\":\\\"$undefined\\\",\\\"templateScripts\\\":\\\"$undefined\\\",\\\"notFound\\\":[[\\\"$\\\",\\\"title\\\",null,{\\\"children\\\":\\\"404: This page could not be found.\\\"}],[\\\"$\\\",\\\"div\\\",null,{\\\"style\\\":{\\\"fontFamily\\\":\\\"system-ui,\\\\\\\"Segoe UI\\\\\\\",Roboto,Helvetica,Arial,sans-serif,\\\\\\\"Apple Color Emoji\\\\\\\",\\\\\\\"Segoe UI Emoji\\\\\\\"\\\",\\\"height\\\":\\\"100vh\\\",\\\"textAlign\\\":\\\"center\\\",\\\"display\\\":\\\"flex\\\",\\\"flexDirection\\\":\\\"column\\\",\\\"alignItems\\\":\\\"center\\\",\\\"justifyContent\\\":\\\"center\\\"},\\\"children\\\":[\\\"$\\\",\\\"div\\\",null,{\\\"children\\\":[[\\\"$\\\",\\\"style\\\",null,{\\\"dangerouslySetInnerHTML\\\":{\\\"__html\\\":\\\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\\\"}}],[\\\"$\\\",\\\"h1\\\",null,{\\\"className\\\":\\\"next-error-h1\\\",\\\"style\\\":{\\\"display\\\":\\\"inline-block\\\",\\\"margin\\\":\\\"0 20px 0 0\\\",\\\"padding\\\":\\\"0 23px 0 0\\\",\\\"fontSize\\\":24,\\\"fontWeight\\\":500,\\\"verticalAlign\\\":\\\"top\\\",\\\"lineHeight\\\":\\\"49px\\\"},\\\"children\\\":\\\"404\\\"}],[\\\"$\\\",\\\"div\\\",null,{\\\"style\\\":{\\\"display\\\":\\\"inline-block\\\"},\\\"children\\\":[\\\"$\\\",\\\"h2\\\",null,{\\\"style\\\":{\\\"fontSize\\\":14,\\\"fontWeight\\\":400,\\\"lineHeight\\\":\\\"49px\\\",\\\"margin\\\":0},\\\"children\\\":\\\"This page could not be found.\\\"}]}]]}]}]],\\\"notFoundStyles\\\":[],\\\"styles\\\":null}]}]}]}],null],null],\\\"couldBeIntercepted\\\":false,\\\"initialHead\\\":[null,\\\"$Lc\\\"],\\\"globalErrorComponent\\\":\\\"$d\\\",\\\"missingSlots\\\":\\\"$We\\\"}]]\"])self.__next_f.push([1,\"c:[[\\\"$\\\",\\\"meta\\\",\\\"0\\\",{\\\"name\\\":\\\"viewport\\\",\\\"content\\\":\\\"width=device-width, initial-scale=1\\\"}],[\\\"$\\\",\\\"meta\\\",\\\"1\\\",{\\\"charSet\\\":\\\"utf-8\\\"}],[\\\"$\\\",\\\"title\\\",\\\"2\\\",{\\\"children\\\":\\\"Randomly updated\\\"}],[\\\"$\\\",\\\"link\\\",\\\"3\\\",{\\\"rel\\\":\\\"icon\\\",\\\"href\\\":\\\"/icon.png?bc4a317ea05d9cfa\\\",\\\"type\\\":\\\"image/png\\\",\\\"sizes\\\":\\\"24x24\\\"}],[\\\"$\\\",\\\"meta\\\",\\\"4\\\",{\\\"name\\\":\\\"next-size-adjust\\\"}]]6:null\"])",
    "commentLink": "https://news.ycombinator.com/item?id=41115941",
    "commentBody": "`find` + `mkdir` is Turing complete (ogiekako.vercel.app)287 points by thunderbong 16 hours agohidepastfavorite73 comments IncRnd 1 hour agoFrom the top of the page: find + mkdir is Turing complete (retracted) The proof is flawed and I retract the claim that I proved that find + mkdir is Turing complete. See https://news.ycombinator.com/item?id=41117141. I will update the article if I could fix the proof. reply vanderZwan 11 hours agoprevSo can you implement Folders with it? https://www.danieltemkin.com/Esolangs/Folders/ reply dspillett 8 hours agoparent> In Windows, folders are entirely free in terms of disk space! For proof, create say 352,449 folders and get properties on it. To be that guy for a moment: well, hackchewally…¹ Directory entries do take up space in the MFT, but that doesn't show up in explorer which is only counting allocated blocks elsewhere. You will eventually hit a space issue creating empty directories as the MTF grows to accept their allocation. You can do similar tricks with small files. Create an empty text file and check, it will show 0 bytes size and 0 bytes on disk. Put in ~400 bytes of text and check again: explorer will show 400 bytes in length but 0 size on disk because the data is in the directory entry in the pre-allocated MFT. Double up that data, and it will be big enough that a block on the disk is allocated: in properties in Explorer you'll now see 800 bytes length and 4,096 bytes (one block) on disk. Drop it back to 400 bytes and it won't move the data back into the MFT, you'll now see 400 bytes length, 4096 bytes consumed on disk. -- [1] though don't let this put you off enjoying the splendid thing overall! reply vanderZwan 8 hours agorootparentRemember that esolangs are arguably the \"purest\" medium of artistic expression for programming, and that artworks often are about challenging or confronting implicit assumptions. Or to put it differently: yes, that is indeed the joke :). Thank you for elaborating the technical details though (plus I did not know the small file trick, that's a neat bit of trivia). reply sumtechguy 6 hours agorootparentprevAlso MFT can also grow in size if you exceed the current allocated size. Depending on your version of windows that growth rate is different. Also once the MFT grows it will not shrink. The tools for MFT cleanup are rather poor. With the usual recommendation of 'just format a new drive and start over'. reply philistine 3 hours agorootparentApple finally managed to switch its file system and escape the pains of late 80s technology. When will Microsoft replace NTFS? reply deepsun 3 hours agorootparent\"Don't touch if it works\" (c) /s reply lelandfe 5 hours agorootparentprevMaster File Table reply moffkalast 4 hours agorootparentprev\"Disk manufacturers hate this simple trick for free data storage.\" reply dspillett 3 hours agorootparentOh, that might make a great April 1st release: a mirror filesystem module for WinFSP that splits files into 500 byte chunks on disk. “See, we saved that 4Mbyte photo to the new filesystem, and it, using the NTFS infinite space for small files trick, made it take absolutely zero disk space! Now we'll make a sub-folder and drop a few more files in that, and look, they show as taking no space in the magic backing store but can be properly opened as normal!”. Drop it on youtube or tt, get your popular friends (this might scupper me, if anyone I know is an online influenza they have the good sense not to let me know about such proclivities!) to make a review of it, and see how far and wide it spreads with people either in on the joke or idiots just parroting it for views. reply Moosturm 11 hours agoparentprevThis is phenomenal reply indigo0086 6 hours agoprevRetracted >The proof is flawed and I retract the claim that I proved that find + mkdir is Turing complete reply deredede 11 hours agoprevI don't understand how this shows Turing completeness. The implementation of the rule 110 automaton seems to be limited by both width (not Turing complete because there is a finite number of states of a given width) and iteration limit (not be Turning complete because it always terminates). Can you write an implementation of rule 110 with arbitrary (i.e. unbounded) width and depth? reply viraptor 11 hours agoparentIt's still ok if the implementation limits it rather than the concept. I mean, your computer has finite memory rather than infinite tape, so it doesn't meet that requirement either regardless of language/method. reply upwardbound 5 hours agorootparentI don't know this field very well so I might be misunderstanding, but I think this is different than \"infinite tape\" in Turing Machines. As I understand it, the proof of universality for Rule 110 required that the program code which is called the \"production rules\" be repeated infinitely on the tape even for a finite size program. https://en.wikipedia.org/wiki/Rule_110#:~:text=An%20infinite... If you had a halting problem oracle to tell you how much runtime is needed to run a certain program to completion, you could get away with having only a finite number of repetitions of the \"production rules\", and simply pretending that they're infinitely repeated. This would only work for programs that halt. If I understand correctly, any program that loops forever, if implemented within Rule 110 Cyclic Tags, requires infinite repetition of the production rules. I think this is a difference of Rule 110 vs Turing Machine tape. If I understand correctly, a Turing Machine with finite, even quite small, tape can loop forever. But a Rule 110 program must have infinitely sized tape to be able to loop forever. Basically (if I understand correctly), Rule 110 Cyclic Tags essentially \"consume\" tape symbols as basically a non-renewable resource, like an electrical computer server powered by the burning of coal. Infinite runtime (looping forever) requires infinite repetition of the tape symbols (both the \"production rules\" and the \"clock pulses\" - see the Wiki page above). I believe this is unlike Turing Machines, which can loop forever without \"consuming\" any non-renewable resource. To clearly state this again: Running a simple \"while(true)\" loop in a Turing Machine only needs finite tape, but requires infinite tape in Rule 110. reply klyrs 3 hours agorootparent+[->+] Turing machines can also eat tape infinitely. If they're allowed such an appetite, why would we forbid it for rule 110? To be fair I've never been 100% sold on the Turing-completeness of rule 110, but your argument isn't landing with me either. reply zamadatix 1 hour agorootparent\"Allowed\" is probably covering too wide a meaning in your description. Just because something is capable of defining infinite consumption does not mean it was allowed to do so in the proof. reply deredede 11 hours agorootparentprevI am not talking about limitations of find or mkdir like other commenters are. I can write a Python program that simulates rule 110 with unbounded state width and unbounded iteration depth. I might not be able to execute it on any computer (it's going to run out of memory at some point), but I can still reason about it and its behavior with a (theoretical) infinite memory. After reading the blog post, I am not convinced I can write such a program using `find` and `mkdir`, since the provided example uses explicit limits for WIDTH and ITER in the program itself. reply camel-cdr 10 hours agorootparentThe same argument would make C non turing complete. Because the size of pointers is a compile time constant and because everything needs to have an address that puts a large, but hard limit on tape length. There are ways to argue arround that, e.g. C might be able to interface with a infinite tape file via the stantard library, and maybe strict aliasing and pointer provenance let's you create a system where bit identical pointers can be different. But the mental model most people have of C wouldn't be turing complete. reply deredede 10 hours agorootparentWhile strictly speaking true I don't think it is the same argument at all. You are talking about a restriction of the runtime (much like mkdir argument length or maximum filesystem depth), even though it leaks into the standard because standard people care about physical hardware, not theoretical ones. The WIDTH and ITER limit being actual constants that are part of the program makes all the difference compared to C pointer limitations that are part of the execution environment. reply Joker_vD 7 hours agorootparentBut C is not Turing-complete, because its numbers (and pointers) are required to have an arbitrary limit which itself must be representable and useable in C. Python, on the other hand, has no such requirement and you could imagine an implementation that could grow indefinitely (well, until it ran out of the physical universe). C is prohibited from doing that, there is always a theoretical limit present. You can set that limit hella high, but it's still there. reply a_cardboard_box 6 hours agorootparentIt's still not comparable to mkdir and find. The arbitrary limit in C is not fixed by the code. So if you run out of space on a 32-bit machine with sizeof(size_t) == 4, you can run the same code on a 64-bit machine with sizeof(size_t) == 8. With mkdir and find, you have to change the code to do this. You can translate any Turing Machine into a single C program, which will behave identically so long as you have enough memory. You cannot do this if you need to change the program when the amount of memory changes. reply camel-cdr 6 hours agorootparentI'd argue that the process of taking a C program and compiling and running it on ever larger pointer sizes it turing complete, but not a single iteration of this process. reply lupire 7 hours agorootparentprev\"Python\" doesn't exist though. It's silly to claim that Python is more powerful just because it doesn't tell you what it's going to do (run on some limited hardware) and C lets you choose. Reality is fundamentally, necessarily different from theory. Everything real is a mere approximation of theory, and vice versa. Even Turing's machine is limited by all the paper in the universes, unless you ignore reality (which is fine!). It's false precision to say that C in reality with bounded pointers is different from C with unbounded pointers, but Python in reality with secretly bounded pointers is the same as Python with unbounded pointers. reply Joker_vD 6 hours agorootparentNo, it's not a false precision. The C requires the numbers (and memory size) to have an upper limit which it is obliged to tell you. The Python doesn't require such limitations to exist. They will, of course, exist in practice since it's impossible to build a Turing machine but only a sufficiently huge finite-state machine, but that is the practical consideration. In practice, all language implementations are FSMs. But C is a FSM even in theory, unlike Python. You would have better luck trying to argue that there is a reading of standard that allows for unboundedly huge file streams and that fread()/fwrite()/fseek() then could be used to faithfully implement Turing machine. reply PhunkyPhil 3 hours agorootparent> But C is a FSM even in theory, unlike Python Write a python interpreter in C and it's clear to see why your logic fails. You've reaped your claimed benefits of Python while remaining in C. reply osmarks 1 hour agorootparentPython-the-language can be Turing-complete even if Python-as-actually-implemented is not. reply camel-cdr 9 hours agorootparentprevThe difference is very small though, you could say that WIDTH amd ITER must be defined in the execution enviroment (shell)before execution and that the rest of the code is the program, and we are at the same situation as in C. reply deredede 9 hours agorootparentIf you define WIDTH and ITER prior to execution you are just giving arguments to your program. Maybe using the term \"environment\" was not the best choice; what I mean is that WIDTH and ITER are program variables that impact program behavior and output (appear in regexes etc.) whereas (most) C programs don't actually reference or depend on the pointer width (other than crashing if it's too small); it is an internal detail of the C compiler and underlying hardware that only happens to be visible to the programmer due to leaky abstractions. I don't think those are comparable. reply horsawlarway 5 hours agorootparentI mean... isn't this just `sizeof` in c? Honestly, I'm struggling to think of any real world code base I've worked with in C that didn't care about pointer size. reply oecumena 5 hours agorootparentprevC is definitely not Turing complete. The standard library provides no escape, because file sizes are also limited (due to ftell (3)), and there is no chdir in the C standard library, so the total number of files is also limited. I have a recollection of an attempt to construct a possible Turing-complete interpretation of the C standard involving recursion and va_arg, but I don't think it went anywhere. reply tomsmeding 10 hours agorootparentprevOn the other hand, a C running on a machine with a significantly larger address space would have appropriately larger pointers. The C standard does not specify any particular pointer bitwidth. With these things together, C as a language has a decent claim to Turing-completeness. reply camel-cdr 10 hours agorootparentYes, but you still configure (choose a compiler) it to a fixed size before running, that is in my mind no different than specifying a fixed tape size, like in the find + mkdir example. reply oecumena 5 hours agorootparentprevFor any C program there is a number N, that depends on the program, compiler, architecture, etc., but does not depend on the program input, such that the program won't be able to access more than N bits of state at any moment in any of its possible executions. Hence, the program is equivalent to a finite state automaton. reply osmarks 1 hour agorootparentprevC is indeed not Turing-complete for more or less this reason. reply ori_b 41 minutes agorootparentNeither is the universe: we have (as far as we know) a limited number of matter and energy that can be converted to computation, which limits the size of an implementable system. Real Turing completeness is necessarily theoretical. reply thih9 3 hours agorootparentprevLooks like you're treating Python as a spec; in this case I'd say we should treat mkdir+find as a spec too. Programming language implementations often have some hard limits built in. E.g.: https://peps.python.org/pep-0611/ reply deredede 1 hour agorootparentI'm treating mkdir+find as a spec. The values for WIDTH and ITER are in the program itself and will impact any implementation of mkdir and find you use, including theoretical ones. reply adrianN 10 hours agoparentprevC is maybe technically not Turing compete either: https://cs.stackexchange.com/questions/60965/is-c-actually-t... reply FartyMcFarter 6 hours agorootparentAccording to the second answer, C99 is Turing complete. reply safeimp 4 hours agoparentprevThe author has since updated their post: > The proof is flawed and I retract the claim that I proved that find + mkdir is Turing complete. See https://news.ycombinator.com/item?id=41117141. I will update the article if I could fix the proof. reply aabhay 14 hours agoprevI thought that this was going to use some interesting form of lambda calculus but instead it simply relies on the regex parser of find to compute things. reply userbinator 14 hours agoparentNot the first time someone has coerced a regex into doing some nontrivial computation; here's a memorable example: http://realgl.blogspot.com/2013/08/battlecode.html (scroll down to \"Regular Expression Pathfinding\" reply nibbula 49 minutes agoprevMy find is not only provably Turing complete, but not even a Turing tarpit and compiles to native code. reply usr1106 14 hours agoprevOf course no implementation is infinite, but in this case PATH_MAX with 4096 as a typical value seems particularly low. reply Bootvis 13 hours agoparentCheck out section “Expected questions and answers”. For GNU it seems to work with path lengths larger than 4096. reply Arch-TK 13 hours agoparentprevThe blog post addresses this by using relative paths. Tested up to a path length of 30k apparently. reply omoikane 13 hours agorootparentI believe somewhere after 30k is when they will run into file system limits. Despite being able to create directories nested to arbitrary depth with short file names, find() might not be able to read a directory if the total path length is too long. I found this out when I couldn't open a file with the path \"./././name.h\" where there are lots of \"./\" in front. And the reason why I got so many \"./\" was due to a clang preprocessor bug that modifies __FILE__: https://github.com/llvm/llvm-project/issues/43825 reply niederman 12 hours agoprevI suspect this proof could be greatly simplified by the use of tag systems (https://en.m.wikipedia.org/wiki/Tag_system) rather than cellular automata. reply zmmmmm 12 hours agoprevwell, it also supports `-exec` so it would imply rather a big problem with the host OS if that wasn't turing complete reply kachnuv_ocasek 12 hours agoparentWhy would an OS need to be Turing complete? reply eru 11 hours agorootparentYes, that wouldn't necessarily be a problem. Of course, getting a computer that's useful in practice out of this would require some thought. A simple model: you could only allow programs written in Coq (or similar), ie progams that come with a proof of termination (or a slight generalisation, that allows for infinite event loops, as long as each run threw the loop behaves well, in some sense). There's a trivial escape hatch, where you just take your normal unproven program but forcefully terminate it after 2^64 steps. That's strictly speaking not Turing complete, but you wouldn't be able to tell the difference during the lifetime of the computer. reply peter_d_sherman 13 hours agoprevObservation: Any piece of software/service or piece of software/service used in a software/service chain which implements and/or consumes Regular Expressions (aka RE's, RegExp's) -- is potentially Turing Complete, and should be audited for Turing completeness if security in that context is a concern... reply acchow 13 hours agoparentSpeaking strictly, the original definition of Regex required only a finite state machine with zero stacks. You need 2 stacks for Turing completeness. Tho a lot of regex libraries can support much more than just “regex” reply peter_d_sherman 11 hours agorootparent>\"You need 2 stacks for Turing completeness.\" I am not completely sure about that assertion... We know that Rule 110 is Turing complete: https://en.wikipedia.org/wiki/Rule_110 >\"Rule 110 with a particular repeating background pattern is known to be Turing complete.[2]\" So if Rule 110 = Turing completeness, then we could either prove Turing completeness by proving Turing completeness OR we could prove Turing completeness by proving Rule 110 equivalence... Next we have Markov algorithms: https://en.wikipedia.org/wiki/Markov_algorithm >\"a Markov algorithm is a string rewriting system that uses grammar-like rules to operate on strings of symbols. Markov algorithms have been shown to be Turing-complete , which means that they are suitable as a general model of computation and can represent any mathematical expression from its simple notation.\" (Note that Markov algorithms do not use stacks (nor do Turing machines, nor does Rule 110, nor do stackless \"Turing tarpit\" esoteric languages, nor does Langton's Ant or other Turing complete cellular automata).) RegExp's are basically a \"string rewriting system that uses grammar-like rules to operate on strings of symbols\" So if a such a string rewriting system used in conjunction with a Regular Expression functionality can be proved to be a Markov algorithm, then we have automatic proof that it is also Turing complete, with no need for stacks! Why not read the following: Simplest Turing-complete ruleset for Markov algorithm https://cs.stackexchange.com/questions/44717/simplest-turing... And possibly this: https://esolangs.org/wiki/Nopfunge >\"Nopfunge is a fungeoid designed by Hubert Lamontagne in 2015. It is a two-dimensional esoteric programming language based on a severely restricted subset of the well known Befunge language. Its goal is to show that having access to a sufficiently flexible program geometry is indeed the only thing that is needed to achieve Turing completeness.\" [...] >\"The ONLY valid commands in Nopfunge are the PC direction change commandsv ^ and empty space (which are the same as in Befunge). This means that Nopfunge has no stack, no numbers and no conditionals: there are NO stack manipulation commands and NO commands to store or retrieve data from the program grid. There are no variables or data storage or functions or objects of any kind. The ONLY thing that ever happens in Nopfunge is PC movement. In spite of this, Nopfunge is Turing complete.\" Point is: If it were me, and I were designing a system, then I'd be highly careful (perhaps \"circumspect\" is a better word) about code that implements or evaluates, produces or consumes Regular Expressions (or implements any text rewrite rules for that matter!) if the system which that code was to be part of, was intended to be as secure as possible... reply deredede 11 hours agorootparent> >\"You need 2 stacks for Turing completeness.\" > I am not completely sure about that assertion... What GP means is that a finite state machine is not Turing-complete, and neither is a finite state machine with a single stack (pushdown automaton / stack automation). reply klyrs 3 hours agorootparentPiet is another near-exception to this -- the language only has a single \"stack\" but the \"stack\" is equipped with a 'roll' operation that cannot be implemented with a proper stack and O(1) memory. reply anonymoushn 10 hours agorootparentprev> do not use stacks (nor do Turing machines A Turing machine has two stacks. They're the part of the tape to the left of the head and the part of the tape to the right of the head. The other Turing complete systems described use arbitrarily large amounts of storage that are addressed more often, and for example Langton's Ant uses a two-dimensional tape, which is \"not two stacks\" in the sense that it is more complex than two stacks. reply lupire 7 hours agorootparentMore complex how? Both are abstract and can simulate each other. The difference in complexity would wend into practicality arguments that don't apply in Turing world. Turing machine uses a tape, which is equivalent to two stacks, and also equivalent to a 2-dimensional tape (Farey Sequence), and (I guess, per previous comment) equivalent to Rule 110. The word \"Equivalent\" always carries some load, though. For example, the Langton Ant tape and Rule 110 use a more interesting version of \"blank\" initial state, similar to the \"send a message by flipping a coin on a chess board with an arbitrarily flipped coin on each square\" puzzle. reply behnamoh 14 hours agoprevWhat's the implication of this for users of these commands? reply langcss 14 hours agoparentNot much practically other than watch out for non-terminating find queries. reply PokestarFan 13 hours agorootparentI mean I had never thought about the case where the command that find executes creates subfolders of the directory it's executed in. reply adrian_b 13 hours agoprevI have found interesting this in the parent article: \"The proof leverages a common technique: showing the system can execute Rule 110.\" because I was not aware about \"Rule 110\". Nevertheless, reading the Wikipedia page about \"Rule 110\", I find it astonishing that \"Rule 110\" not only has been the subject of a research paper, but that paper has been even the ground for a legal affair based on a non-disclosure agreement with Wolfram Research, which has blocked the publication of the paper for several years. The demonstration that \"Rule 110\" is capable of universal computation is completely trivial and it requires no more than a sentence. It cannot be the subject of a research paper of the last decades. There are several known pairs of functions that are sufficient for computing any Boolean functions, for example AND and NOT, OR and NOT, OR and XOR, AND and XOR. The last pair is a.k.a. multiplication and addition modulo 2. Whenever there is a domain where all the possible functions can be expressed as combinations of a finite set of primitives, it is also possible to express all the members of the finite set of primitives by using a single primitive function that combines all the other primitives in such a way that composing that function with itself in various ways can separate each of the original primitives from the compound primitive. Applying this concept to Boolean functions it is possible to obtain various choices for a single primitive function that can generate all Boolean functions, for instance NAND, which combines NOT and AND or NOR, which combines NOT and OR. In general all the ado about how various kinds of computational domains can be reduced to a single primitive function is not warranted and it is not interesting at all. The reason is that such combined primitives do not change in any way the actual number of primitives. They just replace N distinct simple primitives with 1 compound primitive that must be used in N distinct ways. This does not change in any way the complexity of the domain and it does not make it easier to understand in any way. \"Rule 110\" is just another banal example of this technique. Like NAND combines NOT and AND in a separable way, \"Rule 110\" combines multiplication and addition modulo 2, a.k.a. AND and XOR, in a separable way. Therefore it can express any Boolean function, therefore, by encoding, also any computable function. There is absolutely no advantage in showing that some system can compute \"Rule 110\". It is simpler and clearer to show that it can compute AND and XOR, or AND and NOT. reply eigenket 11 hours agoparentAs far as I can tell from your comment you have the terms \"functional complete\" and \"Turing complete\" confused. These are emphatically not the same thing. A circuit of (e.g.) NAND gates defines a mathematical function over a fixed, finite number of variables (the number of input wires to your circuit) and with a fixed number of outputs (likewise the output wires). A Turing complete computer accepts inputs which are unbounded in length, I.e. it accepts an input of at least length n for any natural number n. It can also output unbounded strings. These two are fundamentally completely different. Functional completeness for a set of gates doesn't tell you much about Turing completeness. For all of the interesting stuff to do with Turing machines you need this unbounded input size so you can do things like consider descriptions of other Turing machines as inputs to your Turing machine. Essentially what you need is something equivalent to looping or recursion. Note that the Halting problem is completely trivial for NAND circuits, exactly because there is no looping. reply adrian_b 10 hours agorootparentPerhaps you have not read TFA. Of course \"functional complete\" is not a sufficient condition for being Turing complete (because a Turing machine is not reduced to its arithmetic-logic unit, which must be functionally complete, but it is a complete automaton with memories). However, \"functional complete\" is a necessary condition for being Turing complete. Most proofs of Turing completeness do not go as low as the Boolean functions, but they suppose the availability of higher level functions that ensure the functional completeness, i.e. incrementing, decrementing and testing if a value is zero (which in real hardware must be implemented by using Boolean functions). My comment was based on the line that I have quoted from the parent article, which was one of its first lines. Moreover, a Turing machine with infinite memory has a fundamental difference only in theory, i.e. in the set of problems that can be solved with it, in comparison with a machine having an identical structure, but finite memory. For practical purposes, the difference between a machine that is identical with a Turing machine, except by having a finite memory, and other simpler machines, like an automaton with one stack or a finite-state automaton, is much more fundamental. Because an infinite memory is irrealizable, all the proofs that some real system is \"Turing complete\" are proofs that the system is equivalent with a Turing machine whose infinite memory is replaced by a finite memory, which is actually the only kind of computing machine that can be made. So in such a context, any discussion about the infinite memory of a Turing machine is pointless. reply eigenket 10 hours agorootparentSpecifically I was responding to this >There is absolutely no advantage in showing that some system can compute \"Rule 110\". It is simpler and clearer to show that it can compute AND and XOR, or AND and NOT. Which is explicitly wrong. You need extra stuff (roughly) equivalent to looping as well as the ability to interact with an unbounded inputs (110 does this by emulating a tag system). Fixed-width boolean circuits implement AND and XOR, but they are not Turing complete. Showing a system can implement rule 110 is a lot stronger than showing it can implement AND and XOR or AND and NOT. You can even have a system with a single unbounded stack and access to those functions and it still won't be able to implement rule 110 (it will be a pushdown automaton). reply adrian_b 10 hours agorootparentThat sentence did not contain any reference to Turing machines. \"Rule 110\" by itself is just a Boolean function, which, as I have mentioned is completely equivalent with the pair AND + XOR. By using a suitably initialized memory and an automaton that besides other features that are needed to address the memory (a.k.a. \"move the tape\", when the memory is modeled as a tape or shift register) is able to compute \"Rule 110\", it is possible to build the equivalent of a Turing machine. My point is that using \"Rule 110\" does not bring any simplification or any other advantage instead of just using the pair AND + XOR. The machine using \"Rule 110\" and which is equivalent with a Turing machine is completely equivalent with an otherwise identical machine, except that the \"Rule 110\" function is replaced by the AND + XOR pair. The only effect of \"Rule 110\" is to make the description of the machine more complicated and more obscure and if that machine were implemented in real hardware or software it would be more inefficient, due to redundant gates or computations. Even using the equivalent machine with AND + XOR does not bring any advantage instead of the traditional definition of a Turing machine, which uses higher-level functions, whose implementation details are not relevant for proving Turing completeness. reply eigenket 9 hours agorootparentRule 110 is not a simple boolean function. It's a cellular automata. The boolean function is part of its description but not the whole thing. For example if you take the standard rule 110, but run it with a different background pattern (for example the one where every cell is by default in state 0) it isn't Turing complete any more. I suggest you take a look at the proof that 110 is Turing complete (pdf here http://www.complex-systems.com/pdf/15-1-1.pdf). It doesn't just follow from elementary properties of the boolean gates AND and XOR. reply lupire 7 hours agorootparentTo be fair, it's pretty nasty that the Rules are named ambiguously, where a critical part of the \"Rule+\" of interest is something (the background pattern) in the CA system but outside the Rule system. It's fixable, but still gross, and plays into Wolfram's style of making things seem more profound by hiding the ball. reply XorNot 15 hours agoprevNeat now we just need a compiler for a scripting language... reply anthk 9 hours agoparentCheck awka for posix awk. reply Zambyte 7 hours agorootparentThey probably meant one that targets the environment described in the post :-) reply marvinborner 3 hours agoprev [–] I believe that if you could also move and link files, you could actually simulate lambda calculus with a similar technique. I imagine something like this would work, where applications are described by shared prefix in same directory depth and order of application is encoded in lexicographical name order: λx.x: $ tree . . └── x └── a -> ../x/ λsz.(s (s (s z))): $ tree . . └── s └── z ├── a -> ../../s/ ├── b -> ../../s/ ├── ca -> ../../s/ └── cb -> ../z/ reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "The claim that using `find` and `mkdir` commands is Turing complete has been retracted due to a flawed proof.",
      "The discussion involves technical details about file systems, directory entries, and the Master File Table (MFT) in Windows, as well as debates on the Turing completeness of various systems like C and Python.",
      "The conversation also explores theoretical aspects of Turing machines, Rule 110, and functional completeness, with an update promised if the proof is corrected."
    ],
    "points": 287,
    "commentCount": 73,
    "retryCount": 0,
    "time": 1722392561
  },
  {
    "id": 41116635,
    "title": "Meta introduces Segment Anything Model 2",
    "originLink": "https://ai.meta.com/sam2/",
    "originBody": "Our approach Research Product experiences Llama Blog Try Meta AI About us Responsibility People Careers Overview Infrastructure Resources Demos Meta AI AI Studio Clear Clear Our approach > Research > Product experiences > Llama Blog Try Meta AI A Meta FAIR release Introducing Meta Segment Anything Model 2 (SAM 2) SAM 2 is a segmentation model that enables fast, precise selection of any object in any video or image. Try the demo Download the model Explore the research Capabilities SAM 2 demo Our approach Resources Key capabilities Segment any object, now in any video or image SAM 2 is the first unified model for segmenting objects across images and videos. You can use a click, box, or mask as the input to select an object on any image or frame of video. Read the research paper Select objects and make adjustments across video frames Using SAM 2, you can select one or multiple objects in a video frame. Use additional prompts to refine the model predictions. Robust segmentation, even in unfamiliar videos SAM 2 is capable of strong zero-shot performance for objects, images and videos not previously seen during model training, enabling use in a wide range of real-world applications. Real-time interactivity and results SAM 2 is designed for efficient video processing with streaming inference to enable real-time, interactive applications. State-of-the-art performance for object segmentation SAM 2 outperforms the best models in the field for object segmentation in videos and images. Highlights SAM 2 improves on SAM for segmentation in images SAM 2 outperforms existing video object segmentation models, especially for tracking parts SAM 2 requires less interaction time than existing interactive video segmentation methods Try it yourself Track an object across any video interactively with as little as a single click on one frame, and create fun effects. Try the demo Our approach The next generation of Meta Segment Anything SAM 2 brings state-of-the-art video and image segmentation capabilities into a single model, while preserving a simple design and fast inference speed. Model architecture Meta Segment Anything Model 2 design The SAM 2 model extends the promptable capability of SAM to the video domain by adding a per session memory module that captures information about the target object in the video. This allows SAM 2 to track the selected object throughout all video frames, even if the object temporarily disappears from view, as the model has context of the object from previous frames. SAM 2 also supports the ability to make corrections in the mask prediction based on additional prompts on any frame. SAM 2’s streaming architecture—which processes video frames one at a time—is also a natural generalization of SAM to the video domain. When SAM 2 is applied to images, the memory module is empty and the model behaves like SAM. The Segment Anything Video Dataset A large and diverse video segmentation dataset SAM 2 was trained on a large and diverse set of videos and masklets (object masks over time), created by applying SAM 2 interactively in a model in the loop data-engine. The training data includes the SA-V dataset, which we are open sourcing. Please email support@segment-anything.com with any issues or questions regarding the SA-V dataset. Explore the dataset Highlights ~600K+ masklets collected on ~51K videos Geographically diverse, real world scenarios collected across 47 countries Annotations include whole objects, parts, and challenging occlusions Access our research Open innovation To enable the research community to build upon this work, we’re publicly releasing a pretrained Segment Anything 2 model, along with the SA-V dataset, a demo, and code. Download the model Highlights We are providing transparency into the SAM 2 training data We prioritized geographic diversity in the SA-V dataset for real-world representation We conducted a fairness evaluation of SAM 2 Potential model applications SAM 2 can be used by itself, or as part of a larger system with other models in future work to enable novel experiences. Download the model Extensible outputs The video object segmentation outputs from SAM 2 could be used as input to other AI systems such as modern video generation models to enable precise editing capabilities. Extensible inputs SAM 2 can be extended to take other types of input prompts such as in the future enabling creative ways of interacting with objects in real-time or live video. Explore additional resources Read the AI at Meta blog Read the research paper Download the dataset Explore the dataset Download the model Try the demo Our approach About AI at Meta Responsibility People Careers Research Infrastructure Resources Demos Product experiences Meta AI AI Studio Latest news Blog Newsletter Foundational models Llama Our approach Our approachAbout AI at MetaResponsibilityPeopleCareers Research ResearchInfrastructureResourcesDemos Product experiences Meta AIAI Studio Latest news Latest newsBlogNewsletter Foundational models Llama Privacy Policy Terms Cookies Meta © 2024",
    "commentLink": "https://news.ycombinator.com/item?id=41116635",
    "commentBody": "Meta introduces Segment Anything Model 2 (meta.com)264 points by bambax 13 hours agohidepastfavorite89 comments null_investor 9 hours agoMeta is killing it. Google seems to be lagging behind them in AI research and useful things that is shared within the community. I'm sure this, LLAMA and the other projects that they have will help drive up new creations, companies and progress. I'm also sure that this kind of openly sharing code and research will drive up business value for them. It may be hard to say right now what it is, but I'm sure it will. That's the difference of a founder-led company vs. market led. Google is mostly concerned on short-term goals so they don't report a single bad quarter or has too high CAPEX on a project without profit on its sight (like VR). Once Meta finds the killer app for VR, all the other companies will be so many years behind that they will need to buy software from Meta or not take any market share in this new space. Similar to what happened about AI chips and Nvidia. Nobody was investing enough on it. reply nabla9 8 hours agoparentGoogle still leads in AI research. They are doing the opposite of short term. The reason why it does not seem like it may be because most of their work is either basic research or related to chemistry, physics or things that are not public like Facebook. They are behind in productization of the research. So far they seem to do the minimal effort from the trained model to product. reply nolist_policy 8 hours agorootparentAlso don't forget Waymo. reply 93po 4 hours agorootparentwaymo is pretty far behind in terms of self driving tech reply lytigas 3 hours agorootparentI was under the impression Waymo was the leader. Who are they behind and how? reply johneth 1 hour agorootparentprevPretty far behind who? reply ryukoposting 7 hours agorootparentprevWhat should we take away from the AI Overview snafu? Is it an example of an ill-conceived concept for an AI product? Or, is it an example of a technically inferior model hampering an otherwise good product? reply QuantumGood 1 hour agorootparentInsufficient red teaming, presumably due to release pressure from higher up, and lack of work processes requiring more red teaming. reply nsonha 7 hours agorootparentprevwhy aren't they a research institution then? We live in a funny world where academia is ridden with paper mills and fail to do its job, and a for profit company like Google is doing academia's job and... fail to do its job on applications and commercialization also. reply markovs_gun 8 hours agorootparentprevYeah I have noticed all of the actually useful ML papers I have read come from Deep Mind and Google because they seem more interested in stuff that actually matters like industrial control systems and other boring stuff that makes money reply sverhagen 9 hours agoparentprevI know nothing here, but isn't that also the difference: Meta is just trying out things, and can find that killer application later. Google meanwhile existentially feels that search must be the killer application, and tries to shoehorn everything into that. And in doing so put the bar for success so, so high, ignoring where things are really at. reply SXX 9 hours agorootparentProblem is that Google core product is not search, but ads. Over years they were slowly degrading search experience because making search better, faster and more efficient means we would spend less time watching ads. Situation is the same on YouTube where Google have insane market monopoly, but still depreoritize actual creators who made their platform successful to appeal to brands and push more and more ads. Demonetization of everything ever slightly controversial. Somehow Google index whole internet 100 times a day, their OS run on majority of smartphones, their browser is monopoly, they know everything about everyone, but can't even filter spam efficiently. I never liked or used Facebook / Instagram much, but at least Meta core products are not deteriorating at same insane pace Google products are. I can still use WhatsApp daily without ads being fed down my throat. reply autoexec 9 hours agorootparentFor a long time Search was what Google needed you to use in order to collect massive amounts of personal information about you. Today they have Android, and Gmail, and youtube, and Nest, and fitbit, and Maps, and Chrome all feeding google a steady stream of data on the most intimate details of your life. Google doesn't need Search anymore to track what you're doing online or to learn about what you're doing offline, so Search gets neglected and filled with an ever increasing amount of ads and trash. If you have a website, all the spam and AI garbage filling up Google's search results can make it very hard for people to find your website using Google. Don't worry though, because you can pay Google to fix the problem Google has made for you, in fact, you might increasingly feel like you need to pay Google to fix the problem they're causing you or people won't be able to find your website at all. You can try to tell people your domain name, but Google has trained the pubic to search from the address bar and they've mostly forgotten what a URL even is. reply ffsm8 9 hours agorootparentprev> Over years they were slowly degrading search experience because making search better, faster and more efficient means we would spend less time watching ads. That honestly sounds like revisionism to fit your narrative. Occam's razor would decree that the degradation simply came through SEO, and it's inverse correlation of quality (SEO means essentially pushing terrible content higher for advertising revenue) It most likely wasn't Google's aim to reduce their search quality, it was just a side effect of them becoming too successful, that it became unreasonably profitable to game the system reply croes 8 hours agorootparentIt wasn't SSO that put ads before the real search results. https://news.ycombinator.com/item?id=40133976 reply schmidtleonard 7 hours agorootparentSEO didn't get rid of the yellow backgrounds on ads either. A few times during the peak of LLM fever I found that I could search an LLM-related term and get zero organic results above the fold. Every visible \"result\" was actually an ad disguised as a result. reply SXX 8 hours agorootparentprevGoogle actually have a daily history of internet available on palm of their hand as well as insane access to both user behaviour (Android, Chrome) and website statistics (Analytics, Adsense, Google DNS, etc). They had the power to not succumb to \"SEO\" content spam, but this wouldn't improve their ads revenue baseline. Pushing their own services and centralised internet on other hand... reply zo1 8 hours agorootparentprevThe feedback loop with Google is they got better and better at indexing everything, so more \"indexable\" content got created to take advantage of it. There was probably some sort of tipping point where normal human behavior and content-generation couldn't keep up with Google's increased capability, so the increase came in generated/copied/llmd/spam content which outpaced the natural growth of real content. This further pushed google to get better and better at \"indexing\" everything, making the issue worse. Cherry on top for Google: Due to the sheer \"volume\" of content this loop ended up creating, it posed a larger moat for any new entrants into the search market thus strengthening their monopoly position. There will be a subsequent tipping point: Where due to the sheer volume of generated/spammed/seo crap on the internet, the volume of \"real\" content will be so small that it'll become within reach of being indexable again by smaller players. We're already seeing this to some extent, and it'll only get better. reply Majromax 4 hours agorootparent> Where due to the sheer volume of generated/spammed/seo crap on the internet, the volume of \"real\" content will be so small that it'll become within reach of being indexable again by smaller players. Will it be discoverable, though? reply Imagesegmetanto 9 hours agoparentprevFacebook has nothing besides their social network. They care very little about a lot of stuff (after all they didn't care about fakenews and other things). The metaverse was a huge waste of money. Their AI Character thing is weird. They cater to a lot of small businesses, thats definitly helping them. But besides that? They have very little to do what Google, Microsoft, Apple and co are actually doing. reply apwell23 7 hours agoparentprevNot sure how meta is killing it. Their AI integrations into their apps like whatsapp, instagram are beyond useless. They were stuffed in there just to fool markets into beliving meta is some sort of ai player. > That's the difference of a founder-led company vs. market led. Zuckerberg is the most unimaginative CEOs of the them all. Meta never had a single original product ( save for portal device). All their products are acquisitions. Meta is phenomenally bad at innovation. Zuckerberg seems to have pulled some sort PR campaign to cleanup his image. But we all know FB is still a shady company run by a shady man, nothing has changed in its rotten core. It was fined billions of dollars just this week by Texas. Meta is far from a \"founder led company\" . All the founders of the apps he buys leave immediately and are in turn run by managment consultant types like Adam Mosseri . > Once Meta finds the killer app for VR Sad to see that ppl are still buying into metaverse hailmary zuckerburg scammed to convince markets that meta is still an innovative company amid slowing user growth. I still don't understand how metaverse fraud pulled by zuckerberg wasn't some sort of SEC violation. reply Adrig 7 hours agorootparentMeta has insane distribution. Even if they don't match the best AI integration in a couple of months, they can push it to 1 billion people in days when it hits. Same thing for AR/VR, they can afford to invest massively in different plans, use cases and form factors. Fitness, work, social, metaverse, gaming, hardware... It's a collection of bets and in this day an age, one great product-market fit can scale into billions of revenue. In a recent interview Zuck stated that he was surprised by how well the RayBans worked. It's also a great synergy with this new wave of AIs. Because they invested so much they might well get ahead in this race reply 1d22a 7 hours agorootparentprevMeta can still very much be an innovative company regardless of user growth though, right? They are very much innovating in the AI research space, and are absolutely leading in open* source research/models, even if their AI integrations are flopping. Sure, none of this research might be obviously contributing to their products in a share market sense, but it's still innovation which is contributing to the (entirely separate to their \"product\") AI research community. reply apwell23 6 hours agorootparent> Meta can still very much be an innovative company regardless of user growth though, right? only till market tolerates it . they will shut it down once patience runs out like they did with metaverse nonsense reply bradleyjg 7 hours agoparentprev* That's the difference of a founder-led company vs. market led. Google is mostly concerned on short-term goals so they don't report a single bad quarter or has too high CAPEX on a project without profit on its sight (like VR).* It really depends on the founder. Some are very unhappy to see the stock price drop even if they don’t really need the money this second. Also, it’s a mixed bag. I personally think Zuck is wrong on VR but right on AI. reply michaelt 8 hours agoparentprev> That's the difference of a founder-led company vs. market led. Are they really so different? Facebook throws things at the wall, even expensive things without a clear path to profitability, such as Llama. Google throws things at the wall, even expensive things without a clear path to profitability, such as waymo, google glass, google fiber, stadia, and everything on https://killedbygoogle.com Facebook made a big companywide re-orientation to deliver a vision that flopped - the metaverse. Google made a big companywide re-orientation to deliver a vision that flopped - google plus. Facebook renamed themselves to Meta. Google renamed themselves to Alphabet. Facebook has an AI research division founded by a French-American computer science professor and Turing award winner. Google has an AI research division founded by a British-Canadian computer science professor and Turing award winner. Facebook released a widely used open source Python ML library with a camelcase name, PyTorch. Google released a widely used open source Python ML library with a camelcase name, TensorFlow. Perhaps they're following the same playbook, it's just luck that Facebook's gambles paid off recently. reply killerstorm 8 hours agorootparentWell, Meta is not as arbitrary with closing projects. Google closes things which are getting traction, that's a really disturbing aspect of interna politics and incentives Also you mixed up tensorflow and pytorch. reply Mikefox2k 7 hours agorootparentafaik tensorflow is by google brain team and pytorch is by FAIR (Facebook AI Research) reply latentsea 7 hours agoparentprev> Once Meta finds the killer app for VR The killer app for VR is porn. reply indigo0086 6 hours agoparentprevGoogle is notorious for in creating and sunsetting projects who's only purpose is yo showcase talent without regard for any other business model outside of their primary money makers. No support, no open sourcing, just something to show off and show that they are in the innovative app space. reply maximus-decimus 9 hours agoparentprevIf Meta doesn't care for money, then I really don't understand what Facebook has devolved into. It used to be a chronological feed of what your friends are doing. Now all I see is an infinite steam of anger-bait, thirst traps and ai-generated spam. How can it still be controlled by the same guy? reply logicchains 9 hours agorootparent>Now all I see is an infinite steam of anger-bait, thirst traps and ai-generated spam. How can it still be controlled by the same guy? The stream isn't controlled by Zuck, it's controlled by AI, an AI trained to \"give the people whatever they want\" to maximise engagement. The more deep learning you put into a product, the harder it is to directly control the output. reply maximus-decimus 8 hours agorootparentI find people's faith in the AI disturbing. I'm a Canadian who's never set foot in the U.S. or a striper bar, but for a long while it was intent on showing me ads for bikini bars in Florida or Hooters. Even if you assumed I loved titty bars, I'm not even in the right country! Plus, it showed me what I want so much I completely left the platform. reply Zambyte 7 hours agorootparentprevPlease do not use the term \"AI\" as a way to deflect responsibility. People use AI. The people who use it are responsible for its use. reply Imagesegmetanto 9 hours agorootparentprevThey can easily control the output. You just need a filter. They don't care about the output reply mrweasel 8 hours agorootparentThey care a great deal about the output, but their priorities and goals are very different from that of their users. The same holds true for Google. It's not that Facebook could design and build social networking sites that aren't terrible for the health or their users and society, or that Google could build a better search engine/search engine UI. They absolutely can, but that's less profitable. reply WithinReason 8 hours agorootparentprevIf Google can't solve the SEO problem what makes you think Facebook \"just needs a filter\"? reply Imagesegmetanto 5 hours agorootparentIm answering inside a context. Telling me that Facebook can't control its output because of AI / complexity, than thats just wrong. reply WithinReason 4 hours agorootparentWhy doesn't Google have higher quality results? It's about just controlling the output too. reply Imagesegmetanto 2 hours agorootparentNo its a different thing or argument. If facebook can't 'control' the output because of AI or whatever as an argument, thats facebook specific. Can google control its output? Yes for censoring etc. but Google shows you external self indexed and self analyzed content, Facebook doesn't do that. It has logged in users using their tools to create content and Facebook uses their internal algo to show whatever they want to you. reply andrepd 7 hours agorootparentprev> The stream isn't controlled by Zuck, it's controlled by AI The laziest possible excuse, one rung below \"just following orders\" even: the \"it wasn't me, it was the machine I built\" defence. reply petters 8 hours agoparentprevI don’t think this is true at all. Alphabet has Waymo and Isomorphic Labs, trying to commercialise solutions to problems with very, high impact. Time scale is at least a decade reply raincole 9 hours agoparentprevThat's a lot extrapolation from a few open models. reply joelanman 8 hours agoparentprevI still find Gemma 2 9b to be better than Llama 3.1 8b often reply jrnx 8 hours agoparentprevthey are both, they have a different focus though. E.g. AlphaProof and AlphaGeometry 2 are \"killing it\" also in their fields. But for consumers Meta seems to have a lead indeed... reply nolist_policy 9 hours agoparentprevGoogle Gemini recently enabled 32k context in their free tier. reply SXX 8 hours agorootparentYet they still locking access to reading files from Google Drive to some \"advanced\" plan or might be it's not implemented at all. Just 6 months ago or something ago \"Bard\" could do it and it was one of few actually useful features to summarise PDFs. I really dont want to have any dependencies in my workflow on Google products and features because they'll surely break them. reply nolist_policy 8 hours agorootparentHmm, I just tried it and it works fine. I had to enable workspace access under https://gemini.google.com/extensions reply SXX 8 hours agorootparentIt's enabled for me. It can now even access list of files on Google Drive and print them. Yet every time I trying to make it read PDF it's just doesn't work: > Sorry, I can't access your Google Drive files. You'll need to upload the file or describe the content of the pages to me. Any example of prompt you using that is working for you? reply nolist_policy 7 hours agorootparentYes, I had to prefix it with @Google Drive. E.g. \"@Google Drive Hi, Can you extract the table at page 3 of the ti lm317 datasheet?\" reply SXX 6 hours agorootparentWow. Okay actually it does seems to work now. When they initially moved from Bard to Gemini nothing worked for sure, but with your trick it does work. Also find out right now that it can actually work if you ask to look for a file on Google Drive and within the same command ask to do something to specific file. Thank you. reply killerstorm 8 hours agoparentprevYeah, Google Deepmind is doing useless stuff like protein folding and math. While Meta excels at chatbot of the day reply dontwatchthis 8 hours agoparentprevTotally agree with you reply andrepd 7 hours agoparentprev> Once Meta finds the killer app for VR I like that it's taken as a premise that billionaires do have some kind of superhuman vision, that it's not even a matter of \"if\" but \"when\" Zuck's VR gamble pays off. reply gnabgib 13 hours agoprevDiscussion (720 points, 1 day ago, 130 comments) https://news.ycombinator.com/item?id=41104523 reply cubefox 9 hours agoparentSurprising how quickly big news disappear from the front page. Hacker News seems to be optimized for people who check the website multiple times per day. reply buran77 9 hours agorootparentI'm also periodically surprised that topics that seem to be of core interest and very popular on HN just drop off the front page in a matter of hours. Meanwhile discussions like this one [0] (which stayed on the front page with not even 20 upvotes and 4-5 comments for almost 20h before some discussion picked up) seem to artificially stay on the front page for a day or more. It's probably less algorithmic and more arbitrary. [0] https://news.ycombinator.com/item?id=41067079 reply temp_account_32 8 hours agorootparentprevthe algorithm that fudges the order of the front page can be so annoying sometimes, i accidentally refresh the page, and a link that was top 10 on the front page a few minutes ago is now buried in page 3 suddenly reply yjftsjthsd-h 35 minutes agorootparentThat's not the reason I use https://hckrnews.com/ , but it's another good reason. reply pjmlp 9 hours agorootparentprevGotta to do something between CI/CD deployments. :) reply tgv 9 hours agorootparentprevTry something like https://news.ycombinator.com/?over=100. It decays less quickly (at the expense of lesser scoring, recent posts). reply mattmanser 8 hours agorootparentLooking at that list HN has really shifted from a tech entrepreneur website to a programmer, especially linux, centric site. That is nothing like the list I would have seen 15 years ago when I first joined in 2009. Then again I don't miss the \"101 ways to not need sleep and work all night on your startup\" posts. Really seems to have shifted away from anything entrepreneurship or running your own business, the mantle it took over from Joel's \"Business of Software\" forum. Wonder where that discussion's all gone. Plus I just got a reminder how rubbish Google is right now and how vulnerable they are to having their lunch eaten. I couldn't remember what Joel Spolsky's foum was called, and it kept returning absolute crap for various search terms that would have instantly worked 5 years ago. God, I sound like a grumpy old man, but the internet has turned shite. Or at least how I consume it has. reply liamYC 8 hours agorootparentprevI built an email notifier for alerting me when there is a popular news article which I defined by X number of comments. I think forums like hacker news are a really cool indicator for an emerging technology, an opportunity, or some exciting tech story. I get a tonne of false positives though, mostly articles that are inflammatory get sent to me. However, crowd strike triggered it as did the release of chat gpt so there are some hits reply greenchair 7 hours agorootparentprevIt probably has more to do with employees working at the company downvoting the thread. reply SXX 9 hours agoprevIf someone would tell me just a decade ago that Facebook will become one of the most open innovating companies and Mark Zuckerberg one of sane billionares I would really laugh in their face. But now... Regardless of how actually successful their attempts at VR and AI end up they already going to have some place in history for that. reply cube2222 8 hours agoparentTo be fair, they have a very long history of open-sourcing internal software, and it becoming industry standards, this is not at all new, as some have been saying. Especially so in database technology: rocksdb, zstd compression, presto, Cassandra, Hive, Velox (this one’s new) are all Meta’s doing. And those are just the popular ones, there’s way more (database-related) projects they open sourced that didn’t get too popular! So all in all, as much as I’m happy to complain about them as a company, they’ve always been huge contributors to the open-source ecosystem. reply iddan 7 hours agorootparentAlso in web development technologies: React, React Native, Jest, GraphQL, & Docusaurus reply SXX 8 hours agorootparentprevWhile this is true they wasn't so different before compared to Google and even Microsoft in later years. Other companies also released a lot of open source software. AI research is different though. Everyone else decided against open source and started to dig their own moats justifying it with different kind of BS. Yet Facebook / Meta has decided to be on side of open innovations. reply 01945503192 13 minutes agoparentprevhttps://www.facebook.com/profile.php?id=100083868796961&mibe... reply space_oddity 7 hours agoparentprevI love my Oculus but VR has yet to achieve the cultural ubiquity (mb off topic). reply latentsea 7 hours agorootparentI first had a headset back in 2017 for the fun factor of playing around with the hot new thing. It has to be tethered to a powerful gaming PC, was heavy, and the resolution / FOV was relatively poor, and of course no passthrough. I got a quest 3 about months ago and it's a world of difference from where the form factor was at in the past. It's to the point now where it's actually better for certain use cases than other alternatives and hence sees some daily use from me. If the trend continues to get better and hardware that's smaller, lighter, more comfortable, and generally more useful, then I do see it hitting mass adoption at some point. I think the demo Zuck did with Lex on his podcast where they did the podcast in VR using their avatars was pretty neat and the point where that is commercially available and as easy to use as a smartphone, it's a no brainer that it'll sell well. reply SXX 6 hours agorootparentprevI totally understand that VR is loss leader for Meta and a lot of Metaverse stuff they do is cringey, but at least they do have some vision. They actually build some new tech and trying to make it work for mass market. What Google trying to do other than maintain their ad revenue? IDK. reply sverhagen 9 hours agoparentprevGrading on a curve... reply switchstance 7 hours agoprevI would have killed for this back in my editing and motion graphics days. The Roto Brush in After Effects is similar, but its quality has always been lacking and it takes forever to process. reply space_oddity 7 hours agoparentRoto Brush in After Effects is a lifesavers but with limitations. SAM is definitely a game-changer! reply jdhzzz 2 hours agoprevNo love for Firefox. reply d3m0t3p 10 hours agoprevit says that the released the code, but I couldn't find any except some example code, Did they release the training code ? reply Sayrus 9 hours agoparentI think that repository is what they are talking when they say \"releasing a pretrained Segment Anything 2 model, [...] and code\": https://github.com/facebookresearch/segment-anything-2 reply moffkalast 9 hours agorootparentNow we just need sam2.cpp ;) reply npiano 9 hours agoprevI always think of the holographic orbit mapping UI from The Expanse when I see something like this. It's the paper of the future that will be hooked into everything we think about. Such a powerful tool for exploring the world. reply asah 8 hours agoprevImpressive results! Here's a test video from inside Mercer Labs: https://youtu.be/W7kM0ISXkpQ?feature=shared reply afro88 8 hours agoparentWhat am I looking at, and how is it related to SAM2? reply jonatron 9 hours agoprevThanks the thousands of African workers doing the boring repetitive dataset work. reply anentropic 8 hours agoparentthe real heroes reply lakfha 9 hours agoprev [–] So you can track \"objects\" like people in a shopping mall and they are releasing it as a commoditized complement. What are possible scenarios? 1) Advertisers build tracking systems in supermarkets and malls and Facebook sells them the profiles of the victims. 2) Facebook is getting people hooked on the \"free\" models but will later release a better and fully closed model with tracking software so advertisers have to purchase both profiles and the software. 3) Facebook releases the model in order to create goodwill among (a subset of) the developer population and normalize tracking. The subset of developers will also act as useful idiots in the EU and promote tracking and corporate power. reply artificialprint 9 hours agoparentTracking objects is a different task from segmentation, whatever you are describing doesn't need what Facebook released today. In AI a lot of things are overlapping and some stuff that they have been releasing has no direct use for them. Segmentation is helpful in creative applications, think of video editors that can segment the objects in the video and replace the background etc. Green screen type of thing. reply IshKebab 7 hours agorootparentIt's a closely related task. This seems capable of at least some tracking. reply SXX 9 hours agoparentprevWouldn't it be easier to achieve these nefarious goals if it's was a closed model that only few actors know about and have access to? Do you think such models not yet exist or deployed? If you want to look for something behind what Facebook doing now then it's pretty clear they damaging a moat of their competitors like Google and Microsoft (AI.com). Meta competitors dump shitloads of money on GPUs and running their cloud AIs. When Meta releasing open models in wild where everyone and their cat can run them it's only make this arm race more expensive for proprietary AI offerings. reply thinkingemote 8 hours agoparentprev [–] It's (still) for the metaverse even when people say it has flopped, this is directly for that aim. Tracking of everything via live camera vision reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Meta has introduced the Segment Anything Model 2 (SAM 2), a segmentation model for precise object selection in images and videos using clicks, boxes, or masks as input.",
      "SAM 2 excels in zero-shot performance, real-time interactivity, and efficient video processing, outperforming existing models in object segmentation.",
      "Meta is releasing a pretrained SAM 2 model, the SA-V dataset, a demo, and code to the research community, promoting open innovation and further research."
    ],
    "commentSummary": [
      "Meta has launched the Segment Anything Model 2, generating significant interest in its potential impact on AI research and the tech industry.",
      "Some experts suggest Meta is surpassing Google in AI advancements and community contributions, which could lead to new innovations and business value.",
      "The discussion also includes Meta's open-source efforts and the broader implications of AI technology, as well as the competitive dynamics between major tech companies."
    ],
    "points": 264,
    "commentCount": 89,
    "retryCount": 0,
    "time": 1722404557
  },
  {
    "id": 41114825,
    "title": "Creativity fundamentally comes from memorization",
    "originLink": "https://shwin.co/blog/creativity-fundamentally-comes-from-memorization",
    "originBody": "July 2024 I'm often made fun of for bringing a \"system\" into creative outlets. Things like: written-down heuristics on best DJ transitions breaking down the humor patterns of comedians and memes or a checklist of best practices for competitive video games (e.g. Rocket League, Call of Duty). But I think this critique misunderstands what creativity truly is: a flash of inspiration connecting internalized concepts. The inspirational lightning bolt writers and artists experience can't happen unless they know how to write or draw. A pun can't be created unless the author sees the similarity between one word and another they already know. A DJ can't mashup two songs unless they're familiar with both. By definition, you can't even be certain of novelty without familiarity of existing works. Creativity comes to those who have internalized the patterns of their art -- they can see the connection or novelty because it's all in their head. Therefore autonomy enables creativity, and a system helps achieve autonomy quicker. It all starts with learning Some time back I discovered a method for learning anything quickly. It involved two steps: Memorizing the different classifications/patterns in a concept [1] Exposing myself to a breadth of cases so I could match the real-world example to one of the previously learned patterns For many that remember school, this won't sound novel. Yet what's often missed is the application beyond academic subjects: sports - learning to recognize weaknesses in a defense sales - learning to recognize someone's \"conversational type\" humor - recognizing common opportunities for humor in a situation Even academically, while older western curriculums seemed to emphasize memorization, new school teaching seems to have shifted towards understanding-based, which is just a memorization aid. [1] Eastern cultures, on the other hand, have maintained focus on drilling these primitives to unlock autonomy, as shown by popular tutoring services like Kumon -- which involve daily, timed tests to develop speed. Growing up with Indian parents in California, I was exposed to both. My mom would write daily Kumon sheets out by hand for me to do, and teach me from Indian textbooks from the same grade (which were much more advanced than the US equivalents). The result was me breezing through the US school system without much thought. [2] The key here is memorization's role in learning. We often tout the difference between memorization and true \"understanding\", which are indeed distinct. Memorizing the different methods of attacking mathematical integrations is different from being able to use the right one in the moment. But I maintain that such pattern recognition is just another form of memorization, though often a more subconscious one. This is learned from repeated exposure, and what I'm attempting to do when I try to see a \"breadth\" of cases after learning the framework and available patterns to use. What this is really doing under the hood, is creating a heuristic and... wait for it... memorizing it! Once this heuristic is internalized, it becomes a new primitive and we focus our attention to higher-level problems. Yet even if knowledge is memorized without understanding (as high schoolers so often do) — this creates an opportunity for understanding to manifest at a later date. I’ll never forget the shock I received when working through a proof in college on electromagnetic waves and suddenly ending up with 3e8 — a value I’d memorized blindly as the speed of light. But doesn't this make things mechanical instead of creative and intuitive? But doesn't this stifle creativity? Making things mechanical instead of creative and intuitive? On the contrary, it enables creativity and intuitiveness by reducing energy needed for the basics, freeing you up to focus on higher-level novelty. Once a dancer learns the fundamental movements of their specialization, they're able to improvise. So are pianists once they learn scales, and mathematicians (though sadly many of us never experience the joy of mathematical improvisation -- as Paul Lockhart covers in his Mathematician's Lament). The key is understanding that a system doesn't directly make creativity, it just enables it. Memorization’s role is similar. Another strategy that works well in both humor and famous EDM drops is \"violating the expectation\", but you need to know the expectation before you can violate it. Once you learn music theory, you're able to violate it in ways that resonate. Avant-garde art requires knowing what the establishment is to push the boundaries as orthogonally as possible. One of my best personal examples is learning sales (which eventually be another blog post). As a not-intuitively charismatic guy, I had to learn systems for it. Things like tactical delivery skills: pause for 2 seconds before responding don't use too many conditionals in a sentence start with the answer, then go into detail (McKinsey Pyramid Principle) As well as what questions to ask (from SPIN selling): situation questions problem questions impact questions needs-payoff questions While at first calls were clunky, once internalized -- creativity abounds. Recognizing when the convo is naturally jumping straight to the \"Impact\" section of questions means I don't force us back to the \"Problem\" questions, we just shift forward. All of a sudden sales calls (and human interactions in general) get fun, life improves. Ramifications The obvious thing I've taken from this is my learning system: using the steps above I can learn things quickly to accomplish personal/career goals. Most recently: how to sell how to fundraise how to be wittier The less obvious thing is a creativity system. If creativity is born from autonomy in multiple areas, then one way to become more creative is to become autonomous in many areas! This can be within a single domain, like music. Deeply studying and learning the patterns of hip-hop and country can lead to the creation of a hit fusion like Lil Nas X's Old Town Road. But it can also be across domains -- like we see in most startups today. I used to work as a reverse engineer hacking drones at Skysafe, which was a company born of intersecting expertise in information security + radio. Even Dopplio emerged from my understanding of information security exploits, magic tricks, and sales. As the internet democratizes information and low-hanging fruit is harder to come by, we're seeing that expertise in multiple fields like this is needed to create something novel and valuable (as seen in startups, music). \"Generalists\" these days are more like \"repeat specialists\". So if you want to be creative, learn lots of things in-depth, and learn how to learn them fast. Embrace systems to achieve this, and use them to free you up from the basics -- so you can focus on the novel. If you’re interested in more dissections like this you can follow me on Twitter Footnotes [1] I made both the \"memorization\" step and \"US schools shifting to understanding-based\" footnotes point here b/c they touch on something I call the \"web of knowledge\". Understanding something deeply means fitting into your model of the world and seeing how it connects to other learned patterns. Besides the connections to other subjects, the biggest value in this is ease of recall from having multiple \"entryways\" via the connected subjects. This is extremely valuable, and I naturally do this during my memorization step, but functionally is just another way to aid recall imo. [2] Yet America tends to dominate when it comes to creativity, why? My theory is that while eastern students start with a much stronger base from this discipline, many never unlock the exponential gains that come from the joy of learning. Part of this is probably due to more stability in the US, with a more developed safety system, stable (although it may not seem like it) political and financial system relatively, with lots of opportunity -- we can focus on higher Maslow's-hierarchy needs like passion and self actualization. This is partly why I think we're seeing (and will continue to see) Indians and Asians rise in prominence as kids raised with eastern fundamentals but the US love of learning unlock new levels of creativity. And as generational wealth builds, a branch out from the more traditionally \"Asian\" fields like STEM and into arts and US politics (we're already seeing this, with Vivek, Nikki Haley, etc.)",
    "commentLink": "https://news.ycombinator.com/item?id=41114825",
    "commentBody": "Creativity fundamentally comes from memorization (shwin.co)255 points by shw1n 20 hours agohidepastfavorite201 comments zharknado 4 hours agoOP and others here are stretching the definition of “memorize” to mean “anything that leads to something being retained in memory.” I reject this idea. The trauma of burning your hand on a hot pan creates a memory you won’t soon forget, but almost no one would understand it as an act of memorization. Memorization to me refers to a set of cargo-culty “learning” practices wherein we believe that by using language to drill exposure to an abstract representation of a concept, that somehow we will absorb the concept itself. We do this mainly because experts suck at empathizing with learners and fail to understand that the symbol has meaning for them but not for the learner. It’s the difference between drilling vocabulary flashcards and actually reading, listening, or talking to someone. Young children do not use vocab flashcards to learn their L1. They aren’t being “drilled” to learn “mama.” They have actual needs in an actual social context and attend to nuanced details of that context to make complex statistical inferences about the world, their perceptions, and their body. Mostly subconsciously. Yes, there are specific areas where drilling can help us accelerate or catch up. Many kids seem to need explicit phonetics instruction in order to make the leap to reading words. Phonological speech interventions are often drill-like. Practicing musical scales does make you more fluent in improvisation. Drilling the mechanics of a repertoire piece frees your mind to focus on higher-order expression and interpretation. They’re valuable, they have a place. But this is just a small slice of learning. It’s disproportionately important for passing tests (And getting hired at tech companies!), which to me is the crux of the issue. If I had to reformulate OP’s argument to something I can get behind, it would be more about deliberate practice or “putting in the reps.” This is also often boring, and differentiates highly successful people from average performers. But it’s a broader and more purposeful set of activities than “memorization” would imply. reply WalterBright 1 hour agoparentThe EEs I have known that carried around a card with: V = I * R I = V / R R = V / I because they couldn't remember it were all bad at EE and bad at math. If you can't remember the pieces making up a concept, how are you going to remember the concept? > It’s disproportionately important for passing tests (And getting hired at tech companies!) I don't remember anyone who couldn't pass tests but was really a great engineer. BTW, one of the tests fighter pilots go through is they are blindfolded, and then have to put their hand on each control the instructor calls out. I also have some written tests for certifying pilots. There are questions like max takeoff weight, fuel burn rate, max dive speeds, etc. Stuff a pilot had better know or he's a dead pilot. reply jjk166 5 minutes agorootparent> There are questions like max takeoff weight, fuel burn rate, max dive speeds, etc. Stuff a pilot had better know or he's a dead pilot. You don't want a pilot who is creative when it comes to max takeoff weight. Obviously there are good reasons to memorize certain things, creativity just isn't one of them. reply agumonkey 1 hour agorootparentprevSome times the brain is wired to intuit the concept. That's something that fascinates me. You grasp the idea before any articulate explanation. Somebody shows you a problem and rapidly you start discussing solutions with the other person and even go further. Most of the time memorization is a key role for creativity, the easier you can jump between ideas the more combinations you can explore (seems like the brain is constrained by some cache bottleneck in a way). reply stonemetal12 2 hours agoparentprevMemorize means \"to retain in and quickly recall from memory\". Weather that is by synthetic or natural process is irrelevant. From the point of understanding how memory and recall work, yes burning your hand is an act of memorization. Sure there is a natural repetitive process that leads to base learning like L1 you mention. On the other hand no one adds or multiples enough in daily life for natural memory formation. Humans consider the skill vital enough that we have developed methods to memorize them. Same for spelling, especially for infrequently used words. Flashcards used with Spaced repetition isn't cargo cult, it is a well studied, and pretty good method of inducing memory formation. reply zharknado 33 minutes agorootparentI’d say that’s the definition of “remember” rather than “memorize.” To most people I’d wager “memorize” has a strong connotation for the synthetic version only, with an emphasis on a stripping-out of context. I recognize that stripping away context can be valuable—-drilling a tennis serve over and over outside the real-time context of a game is extremely helpful. Flashcards are rarely valuable in the same way. For semantically oriented tasks, an impoverished context is usually not very helpful. Receptive skills like letter and character recognition might be an exception. But even then you’ve got to make the leap to reading at some point. > no one adds or multiplies enough in daily life for natural memory formation To the contrary, there’s a fascinating study of children in South America who had very fluent mental math skills for making change because they sold fruit on the side of the road. They couldn’t solve the exact same problem in story problem format in a classroom, though. Synthetic contexts usually don’t transfer well to real life. reply pfortuny 15 minutes agoparentprevYou are changing the definition of memory we have had for like 25 centuries in the West. That is your choice but there is no stretching on the other side. “To me” is not what defines what something is. reply gwervc 3 hours agoparentprev> It’s the difference between drilling vocabulary flashcards and actually reading, listening, or talking to someone. Those are not opposite activities. Drilling vocabulary flashcard is the most efficient way to start being able to read/listen/speak; and it's not even clear from research that output (speaking and writing) is useful at all for learning. Also good luck learning to read Chinese or Japanese without rote learning a few hundred characters. Even native speakers learn them by repetition. You can't be serious advocating \"just go read stuff\" as a way to learn a language. Some foundation, acquired by explicit learning, is required to even start reading. > Young children do not use vocab flashcards to learn their L1. That's a bad argument: the life of a toddler is vastly different than an adult. A young child has basically nothing but figuring out what's going around him (including language) at least 16 hours per day, every day. An adult has much less time for that. reply zharknado 5 minutes agorootparent> and it's not even clear from research that output (speaking and writing) is useful at all for learning. Only if your goals don’t include being able to speak or write. > You can’t be serious advocating “just go read stuff” True, not “just.” And Chinese is particularly tricky because the ideograms convey little to no phonetic information. Even so, almost any activity I can imagine seems superior to traditional flashcards. Photo flashcards (vs. translation), listening along to highlighted text or closed captions, deciphering street signs or memes, even the written drills you mentioned. (Or better, “write 5 phrases that all start with character X”). Our brains crave meaning, and flashcards offer very little of it. > even native speakers learn them by repetition No argument there, most everything is learned by repetition, but I’m interested in context. Native speakers already know the verbal form of most words they’re learning to write, even in Chinese. I’d argue the meaning is stronger. > life of a toddler is vastly different than an adult True. The scale of their learning tasks are much bigger than ours. They have to learn that they exist, that their family exists, that they can vocalize, that language is a thing, that they want and need things, and that they can get them by communicating. > An adult has much less time for that I think this is a good entry point to the core of the issue for me—-small children don’t “set aside time to learn,” they just learn. You and I do this also, though it’s less novel and flexible and therefore maybe less salient. I think we place too much value on structured or synthetic learning as “real” learning when in fact it’s often extremely inefficient compared to our natural learning tendencies. There’s a spectrum of structure, starting with what we choose to pay attention to, to an open-ended “study time,” to guided classroom activities, to timed math drills. Flashcards are at the extreme reductivist end of that spectrum. I suspect we like them because they’re easy to understand, uniform, predictable, and convenient to create and use. Creating more effective learning opportunities and supports is substantially harder, but generally worthwhile IMO. reply kqr 2 hours agorootparentprev> That's a bad argument: the life of a toddler is vastly different than an adult. Also it takes a surprisingly long time for children to learn language. I used to think it sorta-kinda happened over a year or two, but having children myself revealed how wrong I was. I have written up a fairly hefty dictionary of words they mispronounce or even just invent on their own because they don't know the one in their native tongue. My oldest rarely contributes individual words to this dictionary anymore, but he still improvises expressions and idioms. reply nickburns 2 hours agorootparent> I have written up a fairly hefty dictionary of words they mispronounce or even just invent on their own because they don't know the one in their native tongue. Ah, beautiful little displays of an attempt to understand, not merely memorize. reply doubled112 2 hours agorootparentSometimes those made up words were way more fun than the correct ones. I could usually see why my little ones combined them that way. reply WalterBright 1 hour agorootparentI remember one where the kid was asked, \"do you want some half-and-half?\" \"No, I want whole and whole!\" reply bunderbunder 1 hour agorootparentprevAn anecdote I once heard provided in support of this point in a lecture: there are aspects of Spanish grammar that native speakers typically don't grasp until their teenage years. I suspect that, if one were to sit down and count hours of practice so that we could do a better apples-to-apples comparison, we'd find that children learn languages at a glacial pace compared to adults. And the rest is pure selection bias. reply nickburns 2 hours agorootparentprev> A young child has basically nothing but figuring out what's going around him Right—not simply memorizing what's happening around them. Those are fundamentally different activies. That is the gist of the parent comment's point. They've also acknowledged expressly that rote memorization techniques are \"valuable\" and \"have a place.\" reply bunderbunder 2 hours agorootparentprev> Drilling vocabulary flashcard is the most efficient way to start being able to read/listen/speak This isn't actually a settled matter. I did a literature dive a while back and found that drilling vocabulary flashcards shows the highest benefit on artificial recall tasks (like multiple choice tests), and over relatively short time scales (days to weeks). Studies that looked at longer time scales (months to years) and more organic tasks generally showed mixed results. Which I generally interpret as a sign that the literature in question is highly susceptible to the file drawer effect. And that in turn suggests that the magnitude of flashcarding's value for this kind of thing has a lot to do with your goals. In a nutshell, are you more interested on the science on how to develop communicative proficiency over the long run, or are you more interested on the science on how to get a good grade in class? I'm studying Chinese right now, and I do use flashcards, but it's not because I believe it's the best way, per se. It's because it's a convenient option for reviewing characters and words that don't appear often in the reading material I have. When they do appear often in my reading material, I find (anecdotally) that it takes a lot fewer organic repetitions to get the character or word to stick in my head than it does with flashcard repetitions. It's also worth mentioning there's no particular reason to assume Chinese and Japanese schools are any less likely than schools elsewhere in the world to cling to inefficient pedagogical techniques out of a sense of tradition. So one can't necessarily assume that the way they are doing it is the way they ought to be doing it. reply Izkata 2 hours agorootparentprev> Also good luck learning to read Chinese or Japanese without rote learning a few hundred characters. Even native speakers learn them by repetition. I've tried this for years with Japanese kanji and never really got very far. Just didn't work well, they largely were just a big blob of lines. Then I found an Android app (Kanji Study) that mixes this in with informational screens that break down kanji into radicals and puts them alongside a bunch of multi-kanji words and uses them in sentences so we can see them in context, and it's actually been working. reply hosh 1 hour agorootparentLearning to read Chinese is done by learning to write Chinese. The strict (but structured) stroke order while writing becomes part of muscle memory, and in turn, becomes a kind of kinesthetic mnemonic device while reading. reply Izkata 1 hour agorootparentThe app I mentioned has that too, but stepping back and giving context helps me more. For example, 語 being composed of 言, 五, and 口 reduces it down to 3 things instead of 14 strokes. This is an easy one since the parts are distinct, but plenty aren't nearly as obvious, like the left side of 教 reply watwut 2 hours agorootparentprevVocabulary flashcards are not all that efficient way to start being able to read/listen/speak. They teach you translation rather then meaning directly, you don't get context or the \"context\" is super repetitive sentence and so on. And plus, general recommendation is to learn words elsewhere and just put them into anki to not forget. Some people like it, but it is not the only or the most recommended way to learn speak and write. reply ugh123 1 hour agoparentprevMakes total sense. Kinda like how we can't train an LLM how to speak by just giving it a dictionary. reply lo_zamoyski 47 minutes agorootparentI am not commenting on or agreeing with the OP, but your response is false. LLMs aren't given just a dictionary, and they do not know how to speak. Speech implies grasp of semantics. There is zero semantics in a block of text, only, according to some interpretation, various textual correlations. reply linearrust 3 hours agoparentprev> It’s the difference between drilling vocabulary flashcards and actually reading, listening, or talking to someone. You need the 'flashcards' before you can read, listen or talk. Go try reading a book where you don't know most of the words. Heck you need 'flashcards' before you needs 'flashcards for words'. You need to memorize the alphabet first. Try reading a text where you haven't learned the writing system. > Young children do not use vocab flashcards to learn their L1. Because they can't read. > They aren’t being “drilled” to learn “mama.” Obviously you aren't a parent. You think a child magically decides one day to say mama? Or do you think it's the mother constantly saying 'mama' to the child until the child 'remembers it' and repeats it? > They have actual needs in an actual social context and attend to nuanced details of that context to make complex statistical inferences about the world, their perceptions, and their body. What? Complex statistical inferences about the world? reply watwut 2 hours agorootparentYou should be aware that people are able to become fluent without ever using flashcards. reply chaps 2 hours agorootparentprevHow are you defining a \"flashcard\"? reply MisterBastahrd 57 minutes agorootparentprevKids say mama almost universally and regardless of their local language because it's an easy sound to make. reply usrbinno 2 hours agoparentprev> ...experts suck at empathizing with learners... Or maybe we just don't want to coddle them. When has learning anything been easy, and why do you expect people to be able to acquire new knowledge and skills without putting in the effort? It shouldn't be grueling, not for its own sake, but yeah, you might have to stare at a compiler error for a few hours or even a few days before you figure out what's broken. Truly, how else are you supposed to learn if you don't, eventually, do it yourself? I'm so sick of this anti-expert, anti-knowledge attitude. It's why we have bootcamp juniors being thrown into otherwise-senior roles, with laughably predictable consequences for the field. reply zharknado 47 minutes agorootparentPerhaps I worded it too emotionally. I mean that experts struggle to remember what it was like before they understood something. It’s very common for experts to ask novices to make leaps that they aren’t capable of making, because they seem natural or obvious from an expert POV. I’m all for hard work; learning is usually very hard work. I also think we need expert guidance. But let’s make the difficulty useful/effective rather than counterproductive. reply lovethevoid 2 hours agorootparentprevThis attitude seems unrelated to the topic at hand quite frankly. Experts suck at empathizing with learners not because of this spite, but often because it's actually quite difficult to switch gears in language and understanding. It's a completely different way of sharing knowledge, where you have to explicitly express things that are just assumed shared understanding among colleagues. Also, to answer your questions in a very simple way: the entire reason you even became an expert is because another expert somewhere along the way gave you an easy in to the knowledge, they coddled you. This is why you can \"stare at a compiler error for a few hours before figuring out what's broken\". Without that expert, you wouldn't even understand what a compiler even is. reply apsurd 1 hour agorootparentprevParent is saying there's a big difference between being an expert in a field and being a good teacher. reply tikhonj 17 hours agoprev\"a flash of inspiration connecting internalized concepts\" Well, okay, but rote memorization is neither necessary nor sufficient to internalize concepts. One of the reasons people make fun of the author's approach to creativity is that systematic memorization fundamentally can't teach taste—so the systematic approach reeks of awkward, try-hard, low-brow, tasteless art. More broadly, memorization doesn't help much with any sort of tacit knowledge, not just taste. I just figure taste is especially important in creative endeavors. That's definitely the case for programming! Memorization in programming gives us architecture astronauts and design-pattern soup rather than elegant code. For what it's worth, I do think that it is useful and important to have a good mental model of what expertise is and how you can develop it. Memorization might be a component of this, but it's going to be a small component at most. I expect that realistic practice with fast feedback and expert mentorship matters far more. (If you're curious, I found the book Sources of Power by Gary Klein gave me a good way to think about how expertise works.) At the same time, memorization has a real cost: it takes time and it's frightfully dull. For me, at least, trying to memorize something without context is not just ineffective but also totally kills any intrinsic motivation I have for whatever I'm learning. Sometimes a bit of memorization is unavoidable, but I've found that to be relatively rare. Otherwise, my time is generally better spent on some sort of practice in context. reply shw1n 17 hours agoparentThanks for reading and the response! One of the points I'm trying to make is that taste and elegance fundamentally stem from an internalized heuristic -- which at it's core is memorization. I understand the connotation of \"memorization\" evokes an image of blindly memorizing without connecting, but isn't the tastefully developed expertise just memorization of a better heuristic? reply Llamamoe 12 hours agorootparentI don't think I can agree, as an extremely creative person with extremely bad memory - to a point where I pretty much never memorize anything, whether intentionally or by accident. What I find instead, is that by just processing novel information, especially if I focus on analysing it, my brain internalizes insights and builds model of that type of thing, allowing me to either imperfectly reconstruct what I've seen, or to come up with an infinite array of permutations, extrapolations, etc which is where the real ideas come from. Further, ideas crucially revolve not around just the information itself, but the \"feel\" for what role they play in the whole, how well they do it, in what way they're notable, etc. In fact I'd straight up claim that memorization is antithetical to creativity - a perfect ML autoencoder or GAN would just regurgitate the training data. Creativity comes from generalisation while memorisation is analogous to overfitting. reply XenophileJKO 12 hours agorootparentA million times this.. I also am extremely creative and in fact I think the MOST creative people are really bad at intentional memoration, but are good at seeing patterns. I feel like often the reason a creative person is hyper creative is they haven't memorized things so they are trying to rebuild information all the time in their heads from very sparse details. This creates the transformative and relational combinations of information that a person memorizing can't see because it is created from a lack of organized specific information rather than a bounty of it. reply bobbruno 5 hours agorootparentprevI think we have a problem of semantics here. Your notion of \"the brain internalizes insights\" is very close to what the author means as memorizing patterns. They even gäbe a few examples where they started with rote memorizations, which were not that useful at first, but eventually a pattern, an insight if you will, emerged. reply pfortuny 5 hours agorootparentprevAnything you “know” is because you have memorized it. It has nothing to do with either effort, or consciousness. Memory is the basis of knowledge. reply moate 3 hours agorootparentWhich is why the thesis here is boring/less useful. “All colors come from memorization” is also accurate. “All thought comes from memorization”. At that point, you’re factually accurate but saying little of use. If you’re trying to teach creativity, what do you make people memorize? The author even points out: some cultures are great at memorizing and bad at innovation and vice versa. That’s interesting to talk about. “Try-hards use spreadsheets to be funnier” is…sad? reply kqr 8 hours agorootparentprevI would describe myself exactly the same way as you, and I've always been that way (noticed it at first in school where I would take forever to hand in the memorisation half of an exam but finish the analytical half in record time.) I recommend giving spaced repetition a serious go. It doesn't cost much and you might be surprised how far it takes even someone like you. It completely changed how I view the role of memorisation in analytical work. Strictly speaking, someone like you does not need to memorise things because you can always derive them from more fundamental principles. But being able to do that, while a blessing, is also a crutch. Reasoning from first principles every time is slow compared to pulling out the right relationship for the problem at hand right away. reply philipov 5 hours agorootparentprevYes! Creativity often happens when you try to reconstruct something you failed to memorize, but succeed at making something else. reply Sammi 11 hours agorootparentprev\"What I find instead, is that by just processing novel information, especially if I focus on analysing it, my brain internalizes insights and builds model of that type of thing\" Sorry, but this is memoization. reply guitheeengineer 10 hours agorootparentI feel like every reply making a point against memorisation would benefit from having their definition of what is memorization, because every single one of those replies sound like they're still implicitly describing some sort of memorization as the better way reply maksimur 6 hours agorootparentI feel like this is about the difference between rote/explicit memorization and organic/implicit/tacit memorization, for a lack of better words. I suspect the former could narrow/restrict your understanding because it may be constrained/limited by the vocabulary/definition itself. reply djeastm 6 hours agorootparentprevI think perhaps there's a confusion of \"memorization\" with \"rote memorization\". The word \"rote\" connotes flashcards and dull drills, but memorization by itself, to me at least, is more like \"a focused attempt at internalizing information\", in whatever way that means to a person, as opposed to just ingesting it or letting it wash over you/osmosis. But that's just my interpretation of the terms. I don't know what the \"official\" meanings are. reply alan-hn 5 hours agorootparentprevExactly, everyone here is just describing different forms of memorization reply barrkel 8 hours agorootparentprevWhat do you call it when you remember things so you can repeat them but you can't generalize? E.g. if you learn a poem or phrase in a foreign language, but can't reuse the words in different contexts? Or being able to recite a rule, but not automatically applying it? Is there a word for this? Similarly, we should have a word for knowing how to reuse something in a different context, but not recall its origin or its canonical portrayal. Being able to apply a rule, without being able to recite it. Do you think there's one word which means both of these things, which are opposites, as I've stated them? reply Izkata 6 hours agorootparent> What do you call it when you remember things so you can repeat them but you can't generalize? E.g. if you learn a poem or phrase in a foreign language, but can't reuse the words in different contexts? Or being able to recite a rule, but not automatically applying it? \"Rote memorization\" reply barrkel 1 hour agorootparentRote means learning by repetition. reply Izkata 1 hour agorootparentAnd \"rote memorization\" is a compound term that means what you were asking for. It's one of those things you can't get the exact meaning of by just looking at the components. reply Llamamoe 47 minutes agorootparentprevIf I cannot recall the information or even that I've come across it unprompted, is it really? Because that's my norm, and I still retain insights from that, that are then applicable across topics. reply mensetmanusman 5 hours agorootparentprevI think I would call it internalization instead of memorization. People memorize equations not knowing what the variables are, others internalize the concepts of what is trying to be calculated. reply XenophileJKO 10 hours agorootparentprevIs it? If I don't remember any of the detail, but just the general \"feel\" of the concept.. is that memorization? reply jaggederest 8 hours agorootparenthttps://qbi.uq.edu.au/brain-basics/memory/types-memory reply Izkata 1 hour agorootparentprev> > and builds model > memoization Was this intentional and no one caught on? https://en.m.wikipedia.org/wiki/Memoization Or just a typo? reply Sammi 40 minutes agorootparentTypo. Funny typo given we're on hn. reply inciampati 6 hours agorootparentprevModeling is not memorization. It's more generic and can't allow you to reproduce the memorized information, only describe its underlying structure. reply bccdee 5 hours agorootparentprevWhy are you attached to the word \"memorization\" here? Certainly taste comes from experience and learning. Maybe you could argue that all learning is an oblique and imperfect form of memorization—but why argue that at all? The only reason I can see is if you think memorization could be a shortcut to good taste, which it can't. Acquiring good taste requires broad experience—more information than you can possibly remember—such that you retain a suite of sophisticated intuitions. Cutting that information down to something that can be memorized would require you to (1) already have the intuitions you're seeking to acquire, and (2) be able to express them all in plain English, which, as far as I know, cannot be done. No painter has ever expressed their aesthetic in such a way that a student could memorize that expression and then have the same creative sensibilities as the original painter. Ultimately, there's no substitute for the process of simply consuming lots of art while paying close attention to what you like about it. reply tikhonj 17 hours agorootparentprevThat's true if you broaden the definition of \"memorization\" to cover all learning, but \"learning is necessary for creativity\" would not be a particularly interesting thesis. Expertise is the result of learning from past experience, both in developing an internal intuition for what you're doing and in having past patterns to draw upon. To the extent that experts have simple easily verbalizable heuristics, these are largely post-hoc attempts at explaining their intuition rather than an accurate reflection of how they make decisions. And, in fact, experts can't even always do that: it is perfectly possible for experts to make good decisions without being consciously aware of why they are making them, and explaining how to make good decisions is a separate skill from being able to make them in the first place. The book I mentioned has a memorable story about a firefighter who thought he had precognition after pulling his team out of a dangerous situation without any specific indicator of the danger, but I figure a more common example is experts saying they did something because it was the \"obvious\" or \"clean\" or \"better\" way to do it and getting a bit flustered when pushed further. We can see this in action pretty clearly if we look at advice for, say, writing. There is a lot of advice from good writers but just memorizing and blindly following this advice is actively counterproductive. Advice you can memorize fundamentally must lack nuance and context. We can see this clearly because so many different pieces of writing advice contradict each other and because good writers do not follow any of those suggestions with any consistency. The same definitely applies to programming, which is why we have both \"don't repeat yourself\" and \"you ain't going to need it\", and why new programmers trying to apply either rule (or both!) to a codebase inevitably create a mess. What I've found with programming advice is that most suggestions are either actively wrong or too vague to be useful. (By the time you've learned enough about programming to be able to follow the vague advice, you don't need it very much!) reply ahazred8ta 15 hours agorootparentThis happened about 20 years ago when they were trying to automate recognizing cancer cells. They showed photos to experienced diagnosticians and asked 'What features do you look for?' They couldn't articulate what they were seeing. reply heenrik 14 hours agorootparentThe concept is called 'tacit knowledge'. reply bryanrasmussen 8 hours agorootparentprev>One of the points I'm trying to make is that taste and elegance fundamentally stem from an internalized heuristic -- which at it's core is memorization. seems to me there is a relatively big inductive gap there, you believe that there is an internalized heuristic and at its core is memorization, you may even have some evidence that this internalized heuristic has strongly informed your development of taste, but it is pretty difficult to make an argument that is the case for all people. Aside from that I would say that \"internalized heuristic with memorization as the core\" puts everything on nurture and no input of nature - which I am pretty much in the camp of combinations of nature and nurture creating the person - of which taste must surely be a big component. reply passion__desire 8 hours agorootparentprevSchmidhuber reached your conclusions first. Driven by Compression Progress: A Simple Principle Explains Essential Aspects of Subjective Beauty, Novelty, Surprise, Interestingness, Attention, Curiosity, Creativity, Art, Science, Music, Jokes https://arxiv.org/abs/0812.4360 reply etrautmann 17 hours agorootparentprevnot the parent poster but I think I agree with your perspective here. The alternative is that some individuals' taste or sense of aesthetics is somehow innate and unmoored from the statistics of the things they experience. There may be something to this, but for most practical purposes I would agree with your point. reply tikhonj 16 hours agorootparentAnother alternative is that taste is something you can only learn through experience and mentorship, where memorizing simple rules and heuristics is not sufficient. Taste is an example of tacit knowledge[1]. [1]: https://en.wikipedia.org/wiki/Tacit_knowledge reply shw1n 16 hours agorootparentPerhaps this is where I disagree -- I believe while difficult, all tacit knowledge can be made explicit, but is just hard to do so This may be because I'm not good at picking up on social cues, so had to learn things more consciously But ofc I could also be wrong and maybe there are things the subconscious can learn that the conscious cannot reply etrautmann 3 hours agorootparentThere’s another argument though that some taste is genetically programmed, like our affinity for campfires or sweeping views. Those don’t seem to be learned as they seem to be entirely cross cultural and innate. Those aren’t examples of art of course but make the point that some sense of aesthetics may not be learned. reply bryanrasmussen 7 hours agorootparentprevalso a question - if you have better long term or short term memory how does that affect taste? How does it affect creativity, if all of these things are essentially memorization you would have to assume that people were more creative and had better taste the greater their ability to memorize things, which in the case of taste especially seems slightly absurd. In the case of creativity it may be easier to make an argument - but surely you can find people who seem more creative with less ability to memorize. reply hosh 1 hour agoparentprevI think it is more of becoming fluent with primitives that can be composed in versatile ways. I can see how that can be poorly understood as memorization. The main implication is that if what you are “memorizing” is not easily composable, then you won’t be able to apply them broadly or creatively. However, I disagree with the author on what creativity is, although his definition is one experience of a creative inspiration. reply naasking 9 hours agoparentprev> Memorization in programming gives us architecture astronauts and design-pattern soup rather than elegant code. Elegance is probably orthogonal to creativity, and likely follows from some kind of minimization principle, like minimum program length. You are effectively distilling the \"essence\" of something from all of the noise. Creativity seems different, more like novelty, and creativity following some kind of remix of memorized elements + some randomization seems very plausible. You can create something novel but not elegant, and something elegant but not novel, and you can distill an elegant version of something novel that your or someone else created and that's the best of all creations. reply flir 3 hours agoparentprev> One of the reasons people make fun of the author's approach to creativity is that systematic memorization fundamentally can't teach taste—so the systematic approach reeks of awkward, try-hard, low-brow, tasteless art. Well... can you think of an artist who didn't have a deep knowledge of their art-form before they pushed it forward? Three that jump out for me, in no particular order, are Picasso, Borges and Jack White. After all, great artists steal. reply tikhonj 3 hours agorootparentThere's a big difference between \"artist who didn't have a deep knowledge of their art-form\" and \"artist who didn't follow an explicit system to memorize a bunch of rules to make their art\". reply boppo1 2 hours agorootparentprevPicasso was a hack. People often cite his \"early masterpieces\", but those pieces are pretty mid in the context of 19th c. painting. reply anonymoushn 3 hours agorootparentprevPollock is often regarded as pushing painting forward, for example reply flir 3 hours agorootparentThanks, I don't know enough about him - does that support my hypothesis or tear it down? reply watwut 2 hours agorootparentprevI think that argument is that these artists did not memorized rules or previous pictures and then applied them. They did put a lot of effort into learning, but that is different claim. If you define \"memorization\" as \"any learning of anything\", then the word is kind of useless. reply groby_b 3 hours agorootparentprevWait, why do you think Picasso didn't have deep knowledge? He studied both at the School of Fine Arts in Barcelona & the Royal Academy of San Fernando in Madrid, for ~5 years before moving to Paris. Borges was incredibly talented, but it's worth keeping in mind his dad was a writer too. Good art very much relies on being exposed to lots of other good art first. I don't know that rote memorization is the best way to achieve that, but you definitely need that exposure. reply flir 1 hour agorootparentSorry, I must have expressed myself badly. I'm picking examples of people I think did/do have deep knowledge of their chosen mediums. I don't think it's possible to have \"good taste\" without exposure to lots of examples, because I believe taste it culturally bound. Whether you do it explicity via a system, or on a more ad hoc basis, I think most artists need it. It might be interesting to look at film, where the process is compressed into a couple of generations. I don't know it it will support my argument or not. reply keybored 5 hours agoparentprevThe book Make it Stick taught me that this Don’t Cramp My Style With Your Boring Rote Learning (Man) attitude is prevalent in teaching. At least American. They argue that it is wrong for the same reason that the author does. But saying this to a programming crowd must be the most futile thing. At least instrumentalists have to rote train their muscle memory. That lowest bar has to be passed, even if it’s just three chords. But the article isn’t about programming creativity though. It is a general concept. But if honing in on the mythical lone-genius activity (geniuses never practice in a structured way) helps you win an argument then so be it. reply knighthack 16 hours agoparentprevI completely disagree with your assertion that \"...rote memorization is neither necessary nor sufficient to internalize concepts.\" I would recommend reading the book Moonwalking with Einstein. There is a lot of discussion there on how memory is linked directly to creativity, and to understanding concepts deeply. --- A choice passage: \"...If the essence of creativity is linking disparate facts and ideas, then the more facility you have making associations, and the more facts and ideas you have at your disposal, the better you'll be at coming up with new ideas. As Buzan likes to point out, Mnemosyne, the goddess of memory, was the mother of the Muses. The notion that memory and creativity are two sides of the same coin sounds counterintuitive. Remembering and creativity seem like opposite, not complementary, processes. But the idea that they are one and the same is actually quite old, and was once even taken for granted. The Latin root 'inventio' is the basis of two words in our modern English vocabulary: inventory and invention. And to a mind trained in the art of memory, those two ideas were closely linked. Invention was a product of inventorying. Where do new ideas come from if not some alchemical blending of old ideas? In order to invent, one first needed a proper inventory, a bank of existing ideas to draw on. Not just an inventory, but an indexed inventory. One needed a way of finding just the right piece of information at just the right moment. This is what the art of memory was ultimately most useful for. It was not merely a tool for recording but also a tool of invention and composition. \"The realization that composing depended on a wellfurnished and securely available memory formed the basis of rhetorical education in antiquity,\" writes Mary Carruthers. Brains were as organized as modern filing cabinets, with important facts, quotations, and ideas stuffed into neat mnemonic cubbyholes, where they would never go missing, and where they could be recombined and strung together on the fly. The goal of training one's memory was to develop the capacity to leap from topic to topic and make new connections between old ideas. \"As an art, memory was most importantly associated in the Middles Ages with composition, not simply with retention,\" argues Carruthers. \"Those who practiced the crafts of memory used them---as all crafts are used---to make new things: prayers, meditations, sermons, pictures, hymns, stories, and poems.\" ...\" reply kiwi_kim 12 hours agorootparentGreat book, motivated me to then read The Art of Memory by Frances Yates. Although I'd say traditional mnemonic devices like memory palaces are basically linear information storage and recall devices. This can create issues in building a flexible web of information, because loci or the order of the path can become dependencies and you can run out of unique spots in a given space, leading to memory interference. Even spaced repetition methods (e.g. Anki) tend towards fragmentation of micro-ideas. Its perfect for terms, languages, and simple one question -> one answer ideas. I've found a hybrid method of images, nested loci and spaced repetition to be most useful, because its flexible over time, and preserves relationships of ideas. (Context: I co-founded a SaaS in this space: www.sticky.study) reply mewpmewp2 8 hours agorootparentprevDidn't Einstein say that don't memorise what you can look up? E.g. nothing nowadays since we have the Internet. reply djeastm 6 hours agorootparentAll of us over here memorizing words to speak instead of looking up each word each time... reply shw1n 16 hours agorootparentprevGreat passage -- this is exactly what I was trying to get at, though they've described it with much more eloquence and historical backing. Have never heard of this book but adding to my list now! reply euvin 17 hours agoparentprevInteresting perspective. I do agree that there are people out there who develop a distinct \"taste\", but I can't tell if this refers to a \"style\", an emergent property of multiple \"habits\", etc? I've always wondered how one develops their \"taste\". Also, would you consider a subconscious habit \"memory\"? What's the difference between the two? reply andai 11 hours agoparentprevCounterargument: the alphabet. reply linearrust 4 hours agoparentprev> Well, okay, but rote memorization is neither necessary nor sufficient to internalize concepts. Of course it is. It's how every human child learns initially. By rote memorization. How does a toddler learn how to say mama? By constantly hearing and repeating it. How does a kid learn their ABCs? Rote memorization is the basis of all memory. > Memorization in programming gives us architecture astronauts and design-pattern soup rather than elegant code. Dumbest thing I've ever read. You write programs well by doing and remembering. Same with writing. Memorization is the necessary component to programming well. In other words, you program well by remembering elegant code. > For me, at least, trying to memorize something without context After the basics, most memorization is contextual. > At the same time, memorization has a real cost: it takes time and it's frightfully dull. Oh dear. Something isn't fun all the time. What a childish worldview. It's more fun to eat candy and drink soda than eating 'dull'. It's more fun to sit and watch youtube than to workout. > Sometimes a bit of memorization is unavoidable, but I've found that to be relatively rare. Relatively rare? In order to be competent in anything, you have to memorize lots. You can't write a good essay without having memorized much of the material. Trying reading a book where you have to constantly look up definitions of words because you lack the vocabulary. Try having a conversation with someone who has to constantly look up words because he lacks the vocabulary. Try having code review with someone who doesn't remember anything about their code. > Otherwise, my time is generally better spent on some sort of practice in context. Why? Because it helps you remember? To the idiot ( probably OP ) who downvoted, try coding without having 'memorized' the keyboard. The anti-intellectual, anti-hard work, anti-memorization agenda pushed by some 'people' online bears looking into. reply herdrick 2 hours agorootparentStrong points, but insults and emotion aren't how we do it on HN. reply dash2 5 hours agoprevThe most striking comment was this: > Growing up with Indian parents in California, I was exposed to both. My mom would write daily Kumon sheets out by hand for me to do, and teach me from Indian textbooks from the same grade (which were much more advanced than the US equivalents). The result was me breezing through the US school system without much thought. Ukrainian refugees I know are finding the same things in the UK school system, where the maths is much less advanced. Philippines schools, meanwhile, have better discipline and more motivated students. I conclude that Western public education is in a bad state, and this is a source of chronic social weakness. reply ChrisKnott 3 hours agoparent> Ukrainian refugees I know are finding the same things in the UK school system, where the maths is much less advanced. This doesn't appear to be reflected in PISA scores (489 UK, 441 Ukraine) reply watwut 2 hours agoparentprevWhy do you assume Ukrainian math is memorization based? They actually do a lot of problem solving, they are not doing rote memorization. reply groby_b 3 hours agoparentprevWith the caveat that I haven't looked in a while, the rot seemed very anglo-specific. Coming over from Germany almost three decades ago, it was amazing how much US text books just didn't cover. There were a few developments in Germany that pointed in the same direction, but there a large gap at the time. Meanwhile, even back then, eastern Europe certainly had even higher standards. (I replaced a lot of math textbooks with a copy of Bronshtein & Semendyayev) reply rickydroll 3 hours agorootparentThe influence of religious and conservative types has weakened US textbooks. Do a deep dive into how Texas can dictate what is presented in schoolbooks nationwide. reply tonmoy 3 hours agorootparentThere are plenty of south/East Asian counties that have just as much if not more restrictions in textbooks. So I don’t think that alone accounts for the discrepancy reply tuennesje 2 hours agorootparentprevBe careful about reading and comprehending schoolbooks in Texas. Parents don't like to be pressed on most of the content, and are sometimes going to great lengths to get your book banned entirely. reply unix_fan 3 hours agorootparentprevnext [3 more] [flagged] twojacobtwo 3 hours agorootparentThat seems like a much more recent and much smaller phenomenon. The censorship and attempted or succesful modification of school curricula (esp. evolution/biology and sex education) by 'right wing' christian groups goes back many decades across much of the southern US. reply boppo1 2 hours agorootparent>smaller Didn't some states remove math requirements for highschool graduation? reply kqr 13 hours agoprevI was the sort of person who did not believe in memorisation as a solution for anything. Then I tried getting really good at spaced repetition for a year (yes, it is a skill that needs to be trained for good results) and I've completely changed my mind. Spaced repetition allows me to become proficient even in things I don't get the natural opportunity to practise daily, so that when the day comes and I need them, I have some level of knowledge already. This has happened to Kubernetes troubleshooting, statistics, PowerShell windows programming, and traffic engineering just in recent history. I have yet to publish some of these, but I have examples from statistics: https://two-wrongs.com/intuition-and-spaced-repetition.html https://two-wrongs.com/inventing-fishers-exact-test.html The latter is certainly creative in my book, although it does imply creativity within strict bounds. reply parmenidean 4 hours agoparentI really enjoyed both blog posts, thank you for sharing! And I have to say, your explanation of the subexponential distribution property was remarkably clear for someone without a background in statistics :) Would you mind sharing the flashcards you generated to build this intuition? I've been using Anki for a while and really trying to focus now on improving my prompt writing; would love to see how you managed it for this problem. reply kqr 4 hours agorootparentAs much as I would like to, I think getting to that understanding required at least 500 flashcards on general statistical and probability concepts, ranging from fundamentals to extreme value theory. Most of those are only barely relevant at face value, but still contribute to understanding. It's not that I set out to understand this specific thing but that I had studied statistics with flashcard support for a year and that happened to work after a few attempts. reply parmenidean 2 hours agorootparentCompletely makes sense, appreciate the thoughtful reply. Any tips for writing flashcards when studying a textbook? reply kiwi_kim 12 hours agoparentprevI'm similar. This from your top link stood out to me: \"It’s a little like building with lego bricks or something – spaced repetition helps ensure all the tiny pieces are in the right place, so that the big castle can happen without structural integrity issues.\" The book Make it Stick (by Henry L. Roediger III) had a similar idea they called 'Structure Building'. Very similar to what you described, more experienced and effective learners were creating mental schemas of how the little, but crucial parts of a subject fit together, and successfully cut through the noise. Structure Building was associated with interleaved practice (shuffling of problem types) and spaced retrieval practice. reply naasking 9 hours agoparentprevYou're always memorizing something at some level, even in math where you can derive so much after memorizing some core concepts and deductions. reply kqr 7 hours agorootparentMy argument is that it is worth memorising also the derivations, rather than re-deriving from scratch each time. Meorising the derivation makes it easier to derive a second-order derivation, and so on. At some level of abstraction, going from first principles becomes prohibitively expensive and caching intermediary results, or so to speak, unlocks that again. reply naasking 7 hours agorootparentSometimes yes, just like jargon is sometimes useful. Why use long-winded terms or descriptions when shorthand works between professionals. reply HPsquared 5 hours agorootparentprevMath proof and derivations are a bit like remembering a walking route. You've seen the start and end, and the main turns taken, and there's also a general \"walking\" skill you need. reply alecco 10 hours agoparentprevAnki flash cards? reply kqr 8 hours agorootparentI use org-drill in Emacs but it's the same idea, yes. The trick is not so much which software or settings one uses, but writing high-quality prompts. reply saint_fiasco 50 minutes agoprevBeing forced to do rote exercises sometimes makes you creative. Solve a thousand trivial multiplication problems and you will spontaneously discover lots of shortcuts, patterns, intuitions that can warn you when you make a mistake and so on. A common issue I notice when people discuss the terrible state of math education in the US is that teachers demand that you solve a problem a specific way, such as multiplying two-digit numbers by drawing base-ten blocks and applying the distributive property. People who are good at doing multiplication in their head think the method makes perfect sense and don't know what all the fuss is about. But I believe that those people learned how to apply the distributive property \"by themselves\". That is, by adults forcing them to multiply two-digit numbers over and over until they developed an intuition of the distributive property by necessity. When people who didn't go through countless drills are taught the base-ten method directly, they have a harder time understanding it. So ironically it is the students who \"mindlessly\" drill trivial computations over and over that are more prepared to have a \"true\" understanding of the distributive property, while the ones whose teachers believe drilling is for chumps and try to just explicitly show them the true distributive right away, they end up memorizing the words of the distributive property without understanding it. reply sam0x17 41 minutes agoprevI think this analysis as a bit guilty of over-fitting -- it is quite easy to rote memorize a bunch of things while having little to no understanding of what they are or how they work. Trivial examples include training a room of people to memorize a series of facts written in a language they don't speak (the fact that they have memorized doesn't at all mean they have any understanding of the content). So I would say it's not memorization per say, but meaningful exposure to a thing, the more chances you have to meaningfully interact with a thing, the higher the chance is you will learn how to manipulate it and do things with it. This is the difference between understanding and mere memorization, and the more exposure you have, the greater the chance you will start to see the patterns and understand, versus focusing your efforts on memorizing which will just lead to over-fitting and not understanding. As with NNs, so with humans. reply lubesGordi 2 hours agoprevKind of shocking to see so much angst against memorization here. Memory has been long thought to be a critical component of intelligence, with elaborate mnemonics systems developed by people to help memorize more things (see Francis Yates' The Art of Memory, and to a lesser extent her book on Giordano Bruno). I would contend that memorizing concepts is a first step in understanding them. Also, that generally understanding concepts isn't a one and done thing, usually there's layers. Personally I found that memorizing things in math helped me immensely when years later I needed to actually understand the things I had memorized. reply knallfrosch 1 hour agoparentA fellow CS student didn't understand a theorem, because he didn't understand any of the three definitions used to state it. We went through the definitions together and suddenly the theorem was \"trivial\" That is true understanding. He won't need to remember the theorem, because in his mind, it automatically follows from the raw data. reply knallfrosch 2 hours agoprevCreativity is actually defined by this transformation of finding connections between raw data that you already have to know. Consider use cases for a rock. Boring would be using it as a paperweight or throwing it through a window. Novel but uncreative would be throwing it at the sun, or painting it red. Novel, but kind of useless. But what about using a rock to play rock paper scissors? Planting it in the soil and watching it grow? That's kind of novel, by way of subverting rock's rules (it doesn't grow, unlike plants) or transforming the concept of 'rock' itself — a real rock isn't needed for rock paper scissors. So only connections between known concepts are creative. Others might be novel, but useless. reply euvin 17 hours agoprevI think memorization gets a bad rep because you need to be acutely aware of what you're memorizing, like memorizing the sequence of an answer sheet instead of core concepts. But when done sufficiently rigorously, the foundations of memorization make room for higher-level critical thinking and reasoning. Practice is an oft suggested solution to developing mastery, but I did like how the article framed it: creating subconscious heuristics and memory. reply usrbinno 2 hours agoparentRight. I noticed this acutely in an abstract algebra course. We learned several different proof methods, then the exam was just \"prove these theorems with the tools you have\". I'd never been challenged with math like that before. I mean, I bombed it lol, but nobody was going to pass if they didn't remember, say, how to do a proof by induction or what it means. At some point, you need to be able to recall this information. Maybe the psychologists categorize these things differently, but I'd argue it's clear that some form of memorization is necessary for the task. reply kiwi_kim 12 hours agoparentprevAbsolutely, especially in real world application. If you don't have the ability to pull on fundamental ideas anywhere, anytime, then have you really mastered the learning material? reply shw1n 17 hours agoparentprevCouldn't have said it better, exactly -- the negative connotations of the word prevent us from recognizing what powers learning at its core But imo acknowledging this unlocks greater speeds and gets us to the \"fun part\" quicker reply relaxing 16 hours agoprevAll very nice and handwavey, but then you see the user’s current venture is scammy deepfakes as a service, which is about as creatively bankrupt as it gets. Shame about the national stereotypes as well. There is plenty of creativity in Asian countries. Just bizarre assertions all around. reply CuriouslyC 14 hours agoparentHistorically eastern Asian cultures have placed duty to a whole host of things before oneself, and in many cases the old aphorism \"the nail that sticks up gets hammered down\" applies as well. Plus Japan and Korea have well established cultures of adherence to tradition and mastering simple, time tested things to a ridiculous degree rather than trying to innovate. Not true of everyone, but if you compare a culture that values conformity and tradition to a country that values the freedom for the individual and trying new things, of course it's not going to measure up by western standards of creativity. reply watwut 12 hours agorootparentHave you seen their art and entertainment? I assure you there is whole lot of creativity in there. And it has a whole lot MORE variety then western tend to have. reply corimaith 11 hours agorootparentTheir art and entertainment in many cases are rebellions and critiques from mainstream norms. The funny thing is that if you have a rigid conformist society, the rejects are going to double down on the \"weird\" much more than a well adjusted creative would. reply Barrin92 6 hours agorootparent>Their art and entertainment in many cases are rebellions and critiques from mainstream norms No, that's just the art that Western readers notice because that's the only thing they recognize as art in the first place. Calligraphy (in China traditionally considered the most important form of visual art) for example has an astonishing tradition in East Asia, also notably related to the topic of the thread, memorization and repetition and practice and has very little to do with critiques of norms. reply CuriouslyC 2 hours agorootparentAre you seriously going to hold up calligraphy as an example of extreme Asian creativity? The art of writing letters with subtle flourish? It's literally an art of understatement, and embodies all the characteristics that I stated are reasons east Asians are culturally biased towards being less innovative. reply watwut 6 hours agorootparentprevI found asian genres to be way more diverse and creative then western entertainment even when they dont criticize anything. Western entertainment tend to produce the same story, in like, two genres, again and again and again and again. Most of the time you can predict the movie storyline down to minute - and people will argue that it is the only correct way. reply CuriouslyC 2 hours agorootparentThe people arguing that is the only correct way are the capitalists putting their money on the line, and that comes from a perspective of being risk averse, which is why \"corporate art\" in America is in such a shambles. Independent video and music are in a great state though. reply nvln 4 hours agoprevThere is deliberate practice for skill-building. There is exploratory \"making\" that fuels originality. There is inspiration hunting and incremental tweaking to get to creative mutation. There is high productivity that triggers eventual ingenuity. I find the article hyperbolic in its thesis and execution especially when it comes to the final hand-wavy bit about how there is more per-capita creativity in non-rote learning. While its hard to prove or disprove without a long study to prove or disprove the author's claim, I'm willing to die on the following hills: 1. Kumon sheets are the antithesis to creativity 2. Understanding is not a form of memorization (not the rote variety anyway) reply ants_everywhere 4 hours agoparentI've thought a lot about education, and my personal take is that in the US we way undervalue drilling (by which I mainly mean building up familiarity and muscle memory) and way overvalue understanding. I've been collecting quotes about these topics for a few years. One relevant to creativity and drilling is Bob Dylan's > If you sang \"John Henry\" as many times as me.... you'd have written \"How many roads must a man walk down?\" too. reply nvln 3 hours agorootparentThere is definitely a lot of value in practice and repetition. I don't think rote memorization / drilling are the only means of getting that practice and repetition. Ironically, with a bit of creativity, we can provide both. Lot of practice, lot of repetition, paired with understanding, play and making things. reply suzzer99 13 hours agoprev\"Repetitio est mater studiorum\" - repetition is the mother of learning. My creative writing professor, of all people, used to repeat this three times before every class. He was my favorite teacher at any level. reply jack_pp 13 hours agoparentAh, I knew that phrase but never connected it to the title \"mother of learning\" (web novel). Thanks for that tiny epiphany reply djeastm 6 hours agoparentprevMy Arabic teacher liked to say \"التكرار يعلّم الحمار\" which rhymes and says \"Repetition teaches the donkey\" Not the most flattering of proverbs, but it stuck with me. reply arminiusreturns 6 hours agoparentprevI fear not the man who has practiced 10,000 kicks once, but I fear the man who has practiced one kick 10,000 times. Bruce Lee reply Herz 6 hours agoprevUmberto Eco had already discussed this extensively in his paper “the combinatorics of creativity”. Unfortunately, I couldn't find the English version, but it should be very easy to translate, it's only 16 pages. http://www.umbertoeco.it/CV/Combinatoria%20della%20creativit... reply leocgit 6 hours agoparentThanks for the link. Didn't know the text. I found an English translation here: - https://w4nderlu.st/media/pages/publications/combinatorics-o... Translated by Piero Molino at https://w4nderlu.st/publications reply Herz 6 hours agorootparentOh wonderful. I hope you can find time to read it! Umberto Eco was one of the most important modern Italian philosophers. I love his pragmatic and rational approach. reply bootcat 3 hours agoprevI agree and feel likewise the author's comments on the above about memorization, but I realized - A higher framework and is as below, https://rajivkapur.com/3-pillars-of-vedantic-practices/ reply jjk166 6 hours agoprevDeveloping heuristics to categorize patterns and internalize concepts != memorization. If anything, it is the opposite of memorization. reply shw1n 5 hours agoparentCompletely -- it's sort of glanced over in my post as an intermediary step to get the next \"thing to be memorized\" for two reasons: 1) I've often found these heuristics from books/online/mentors and just had to memorize instead of create them 2) In my own experience heuristic creation has been less of a bottleneck than committing to memory But it is certainly a key piece of info to have reply wokwokwok 16 hours agoprevIs there anything substantive here? It’s just a bunch of arbitrary unprovable assertions. Everyone here seems to have, broadly speaking; neither a) the qualifications to knowledgeably comment of the (honestly poorly understood, afaik) function of “creativity” or b) anything more meaningful than “here is my naive personal lived experience and opinion” to contribute on the topic. It’s just armchair psychology. If you want to wax philosophical, by all means, but I think anyone taking “thoughtful insight” away from this article or thread is fooling themselves. reply HarHarVeryFunny 3 hours agoparentI think semi-obvious would be a better criticism than unprovable. You can't make connections unless you have things to connect to. You can't recognize (your own discovered/inspired) novelty unless you have memorized normality. If you are creative in the absence of knowledge of what already exists then that's considered as reinventing the wheel, and not very useful, even it it's Ramanujan reinventing much of established mathematics. reply bubblyworld 12 hours agoparentprevWhatever the epistemic quality of the article is, it's triggered some interesting discussion here which I think is valuable. No need to denigrate talking about human experience with other humans, I think? reply kreetx 8 hours agoparentprevYou'll experience the creativity outlined in the article directly when you start doing deliberate memorization, i.e spaced repetition. No qualification needed. reply threatofrain 12 hours agoparentprevOne might talk about it from the perspective of birdsong, which is used by mates to judge sexual fitness. First a tutee bird learns from a tutor bird, and then eventually applies variability to the original song. It's strongly suspected that anterior forebrain pathway (AFP) may be a source of behavioral variability. We naturally age over time, including our vocal musculature, so in some sense we must constantly relearn how to use our muscles to deliver a song. When a bird is deafened its birdsong will naturally drift, but when we precisely damage the AFP along with deafening we find that birdsong remains stable for a longer period of time, until of course inevitably it must drift due to aging vocal musculature. reply qingcharles 18 hours agoprevI genuinely thought creativity was something else until LLMs hit escape velocity and humbled me hard. After that I realized that creativity wasn't some magical quality that would be hard to reproduce mechanically. And that also made me a little sad. reply sva_ 5 hours agoparentBut LLMs to date can't really differentiate well between a creative insightful answer, and a nonsensical one. The selection process is still done by a human. reply qingcharles 2 hours agorootparentThis is true. I hadn't thought about that aspect. reply shw1n 18 hours agoparentprevI'm glad you said this -- I felt the same way after making this discovery through my method outlined in this post It similarly took the magic out of creativity and learning a bit, and made it all seem like work The main way I've found around it is the joy in being creative once basic autonomy is achieved in new skills Consciously discovering the heuristic is another fun part reply rokob 18 hours agoprevThis seems to resonate with my experience, although I feel myself bristling due to the baggage of the word memorization. Although sometimes “memorization” doesn’t happen because you sit down to do it but rather that you keep using the same things over and over when solving problems that they become internalized. I find that to be a more fruitful path towards understanding that I don’t want to call memorization but it is. reply shw1n 18 hours agoparentThanks for reading! And agreed -- it's this exact realization that led me to both this method and title Imo this negative connotation has made many people refrain from calling internalization what it is But acknowledging that it's memorization has actually made me more efficient at learning, since I can now consciously look for the heuristic, codify it, and try to commit it to memory reply Sakos 11 hours agoparentprevMaybe you should first try to separate the negative feelings you have towards the word \"memorization\" and the word itself \"memorization\". There's nothing bad about memorization. This sort of negative bias about inconsequential things is something that can easily hold us back from things that could help us further ourselves. reply rokob 5 hours agorootparentTell me about it. Trying to get better every day. reply brushfoot 46 minutes agoprevFriendly reminder: This blog post represents a software engineer's personal opinion on creativity, upvoted here by fellow software engineers. No studies are cited. The assertions are corroborated by the author's personal experience. Take its claims with a grain of salt. reply shw1n 18 minutes agoparent^ 100x this, absolutely reply ArcaneMoose 16 hours agoprevWhat's more is that memories are just a replaying of neuron connections activating in the brain - and when we are prompted by the world around us those connections will fire in response to the stimulus. Quite similar to how AI neural networks function - which is why I believe that AI can indeed be creative and create \"new\" ideas reply ArcaneMoose 16 hours agoparentI actually made a video diving deeper into this and comparing responses from people and ChatGPT for a creative thinking problem - https://youtu.be/l-9EUBbktqw reply somenameforme 14 hours agorootparentI think your hypothesis here (and probably the entire article as well) is strongly challenged by the 'progenitor argument.' Take humans at the dawn of humanity. Language did not even exist beyond what may have been crude sounds or gesturing and collective knowledge did not fall that far beyond 'poke him with the pointy side.' Somehow we went from that to putting a man on the Moon in what was essentially the blink of an eye. Training an LLM on the entirety of knowledge at this dawn of humanity and, even if you give it literally infinite training time, it's never going to go anywhere. It's going to just continue making relatively simple recombinations of its training set until somebody gives it a new training set to remix. This remix-only nature is no different with modern knowledge, but simply extremely obfuscated because there's such a massive base of information, and nobody is aware of anything more than a minuscule fraction of it all. --- As for the 'secret' of LLMs, I think it's largely that most language is extremely redundant. One thought or point naturally flows.... why do I complete the rest of this statement? You already know exactly what I'm going to say, right? And from that statement the rest of my argument will also mostly write itself. Yet we do write out the rest, which is kind of weird if you think about it. Anyhow the point is that by looking at language 'flow correlations' over huge samples, LLMs can reconstruct and remix arbitrarily long dialogue from even the shortest of initial inputs. And it usually sounds at least reasonable, except when it doesn't and we call it a hallucination, but it's quite a misnomer because the entire process is a hallucination. reply ArcaneMoose 13 hours agorootparentInteresting point - thanks for sharing! I think one big missing piece we have with AIs today is the ability for them to learn on the fly and reconfigure the weights. We are constantly bombarded with input and our neurons adjust accordingly. Current LLMs just use a snapshot. I would be really curious to see how online-first AI models could work, focusing on a constant input stream and iterating on weights. Also I wonder how much knowledge is baked into our DNA through evolution. I have a hunch that this is somewhat analogous to model architectures. Btw - although I see evidence of LLMs creating \"new ideas\" through combinations of ideas, I am a bit mystified by their apparent reasoning issues. I wonder how that is different in nature from the memory-based approach. ARC-AGI benchmark has had me thinking about this for sure. reply rychco 17 hours agoprevI agree with the author, at least in my own creative experiences. However, it's more likely the case that 'creativity' is arrived at differently for everyone. I find memorization to be a comforting foundational activity that builds knowledge & confidence, which I can later express creatively. reply shw1n 17 hours agoparentExactly -- memorization provides the base for creativity to take place upon But that creativity can come from many places and in many forms! reply hosh 1 hour agoprevI think the more precise term used by educators is “fluency” reply miika 6 hours agoprevI see it like this: after I have seen some colors and a ball I can then imagine a ball in any of those colors. In other words, everything I have experienced and memorized becomes this pool of resources I can imagine from. More I have seen, more combinations I can imagine. Then I understand how traveling actually broadens my view. It’s not just some nice phrase but hard reality. Also this means maybe anything we can imagine we can also create. Because whatever I can imagine I can also plot a path from here to there, imagine all the steps in-between. reply UltraLutra 4 hours agoprevI'm not in anyway an expert, so I googled what some research says. Here's an interesting meta-analysis (https://link.springer.com/article/10.3758/s13423-023-02303-4). Memory and creativity are a lot more complex than I realized. There are different types of each, and it seems like they interact in complex ways. Here's the findings from the abstract: > We found a small but significant (r = .19) correlation between memory and creative cognition. Among semantic, episodic, working, and short-term memory, all correlations were significant, but semantic memory – particularly verbal fluency, the ability to strategically retrieve information from long-term memory – was found to drive this relationship. Further, working memory capacity was found to be more strongly related to convergent than divergent creative thinking. We also found that within visual creativity, the relationship with visual memory was greater than that of verbal memory, but within verbal creativity, the relationship with verbal memory was greater than that of visual memory. Finally, the memory- creativity correlation was larger for children compared to young adults despite no impact of age on the overall effect size. These results yield three key conclusions: (1) semantic memory supports both verbal and nonverbal creative thinking, (2) working memory supports convergent creative thinking, and (3) the cognitive control of memory is central to performance on creative thinking tasks. So some memory seems to be correlated with convergent creativity, which according to wikipedia (https://en.wikipedia.org/wiki/Convergent_thinking) is \"the ability to give the 'correct' answer to questions that do not require novel ideas, for instance on standardized multiple-choice tests for intelligence.\" It sounds like there's less correlation with divergent creativity, which (again from wikipedia (https://en.wikipedia.org/wiki/Divergent_thinking)) is \"a thought process used to generate creative ideas by exploring many possible solutions.\" But my real takeaway is that people here seem to have strong (emotional?) opinions on \"memorization vs creativity: which is better\", but few people seemed to bother reading page 1 google results on the topic. So I like to think that bothering to do some cursory research beats both. :) reply noideawhattoput 14 hours agoprevA Columbia b-school professor has written a lot about this and developed a very compelling framework based on this. Bill Dugan - https://www.goodreads.com/author/list/7325584.William_Duggan. The first two books are fantastic. reply Terr_ 16 hours agoprevOn the other hand, episodic memory (insofar as that is distinct from \"3*9=27\" memorization) is built on top of creativity. The vast majority of what we consider \"memories\" are the creative brain doing an on-the-fly story generation, massaged until it \"seems right\" and serviced plus a big dollop of emotional confidence. reply navaed01 17 hours agoprevI disagree with elements of this article, but enjoyed reading it. True creatives do not subvert norms consciously or with an acute awareness as part of this article suggests, I agree they need to be exposed to the norms to generate their own interpretation, but I don’t believe that true creativity is a conscious exercise. reply shw1n 17 hours agoparentCompletely agree -- but isn't internalization of their art (i.e. memorization) needed to achieve this subconscious creativity? That's the point I'm trying to make at least -- that unintentional creativity stems from learning, which at it's core is memorization reply ArcaneMoose 16 hours agorootparentWell said - what's funny is that many creative ideas (from an outside perspective) are often very simple connections of two existing ideas for the person that actually did something creative! It's just that other people don't have the same context/knowledge as the creator, so an idea can seem extremely original to them reply highfrequency 1 hour agoprevA lot of debate in the comments about the definition of \"memorization\"; this is just semantics and misses the point. Creativity is aided by 1) exposure to a wide variety of existing ideas, 2) deep understanding and integration of those ideas, 3) recombination of those ideas. Superficial exposure to existing ideas alone won't get you there, and neither will isolated deep reflection. You need both. reply lukko 5 hours agoprevWow, what a load of rubbish. I hate this kind of reductive, formulaic view of creativity. I think true creativity expands what is possible – so some kind of awareness of the current state of things is important, but rote memorisation has no real part in it. The idea that memorisation leads to creativity is actually very misleading - especially the assumption that what you are learning is 'true'. It just means you are more aware of the restrictions and existing work in a field - often the most exciting work comes from the excitement and slight naivety of exploring something new - 'beginner's mind'. Kids are very creative, partly because their model of the world is not fully established. reply ambyra 17 hours agoprevIt’s not memorizing, it’s actually knowing and understanding the utility of different concepts. When you learn of a problem in a new field, you go through your bucket of tools and modify one to fit the new problem. reply RRWagner 17 hours agoparentExactly. And \"synthesis\" is the better word than \"creativity\". I wrote an essay about this very topic some years ago: https://docs.google.com/document/d/1tbMTpkPWkkN8_KH2KSpteFsb.... (if you can't open Google docs, an older draft is here: https://rogerwagner.com/creativity.html) reply shw1n 17 hours agorootparentInteresting -- hadn't heard of this synthesis vs creativity take before I could see that -- agreed that \"creativity\" can be too blunt of a word to use for all situations reply shw1n 17 hours agoparentprevThanks for reading! Isn't learning which tools in the bucket fits the a problem best just memorizing a heuristic? That's the point I'm attempting to make, that it's not blind memorization without context, but still memorization of a heuristic at its core reply suzzer99 13 hours agoparentprevFor me anyway, it's getting so familiar with something that your mind wanders and considers other possibilities. reply naasking 9 hours agoprevCreativity is probably some combination of memorization + randomization. reply Mindey 4 hours agoprevThen a hard drive without processing is very creative? False. reply hello_kitty2 3 hours agoprevDisagree. Best technique is no technique. reply singleshot_ 17 hours agoprevThis claim makes little sense because it fails to distinguish between memory and memorization. I memorize almost nothing, but I remember the broad strokes of a lot of things. This allows me to be creative. In a way, memorization is a severe risk: if you memorized something before it changed, for example, your creativity may not mean much. reply shw1n 17 hours agoparentHey thanks for reading! What I was trying to convey is that fundamentally learning is memorization, whether conscious \"rote memorization\" or more less-intentional committing to memory from doing an activity And that recognizing this allows us to speed up the process of learning fundamentals Which in turn enables creativity as most people see it reply ahazred8ta 14 hours agorootparentrepetitio mater studiorum est -- repetition is the mother of learning \"Repetition is the mother of learning, the father of action, which makes it the architect of accomplishment.\" reply watwut 9 hours agorootparentprevConscious memorization and rote memorization are two different things. I can intentionally put things into memory without doing rote memorization - or even intentionally avoiding rote memorization. The techniques you use also give you different results in terms of whether or how you use the memorized concept or word in foreign language. (For example getting the effect where you can translate a word between foreign and your language, but can not use it foreign language sentence and do not understand it in context without translating.) reply lelandbatey 17 hours agorootparentprevYou state that \"learning is memorization\" but I don't think that is true. Of course learning involves something being persisted in one's brain, but stating that memorization and brain persistence persisting are synonyms seems like an incorrect description. reply galkk 18 hours agoprevI will disagree. Creativity comes from applying acquired knowledge (that's where memorization comes into account) in new contexts. reply shw1n 18 hours agoparentAppreciate you reading! But how do you know how to apply this acquired knowledge in this new context? It's some form of pattern matching right -- which imo is just a less obvious form of memorization i.e. you've memorized the match between inherent traits of the context with a specific application of that knowledge reply GavinMcG 18 hours agorootparentTo me, “memorization” implies an active process focused on learning a particular set of “matches” (to adopt the term you’re using here). But it seems to me that tacit knowledge (and other products of less concentrated/deliberate learning) often plays a substantial role in creativity. That is, creativity fundamentally comes from internalized knowledge (as the article says) but internalized knowledge doesn’t necessarily come from memorization. reply shw1n 17 hours agorootparentI think I see -- in your view \"memorization\" only refers to conscious learning While internalized knowledge comes from \"subconscious\" (for lack of a better word) learning? I guess I'm equating the two here and just using memorization as \"committing to memory\", with the belief being that you can construct the heuristic you'd normally acquire subconsciously and cut down time to mastery reply GavinMcG 16 hours agorootparentI think memorization can play a role in internalizing knowledge, but it isn’t a “fundamental” as in necessary. Internalized knowledge can also come from other sources. reply drewcoo 17 hours agorootparentprev> But how do you know how to apply this acquired knowledge in this new context? That question has a false precondition baked in. If you know how, it's not creative. > It's some form of pattern matching right -- which imo is just a less obvious form of memorization No. Sensing and matching patterns does not imply memorization. Everything you're saying is completely loaded. Did you just discover memorization? Because the pattern I see in your words is similar to anyone who's just learned a new tool or technique - they overapply it everywhere as they learn to use it. reply shw1n 16 hours agorootparentBut you must have knowledge of the basic units of your chosen art to apply that to the new situation right? E.g. if you're an artist, at the very least you need the knowledge of how to draw a line From other comments here it seems the definition of \"memorization\" seems to be where disagreements are Maybe this is a better explanation: once I started trying to make whatI just learned is called \"tacit knowledge\" more explicit and then committing it to memory, I was able to cut learning times down significantly reply Sakos 11 hours agorootparentI think the disagreements are largely from this weird cultural bias against any form of explicit \"memorization\". It's very, very strange. reply shw1n 20 hours agoprevSomething I noticed from being raised by Indian parents while going through the US school system And again after learning how to acquire new skills quickly reply samirillian 8 hours agoprev> breaking down the humor patterns of comedians and memes This guy does sound funny but I doubt he can write a joke reply bamboozled 4 hours agoprevMy phone book is super creative. reply lanstin 16 hours agoprevSome minds get a lot done with a lot of memorization and some minds get a lot done with seeing commonalities and creating simplifying abstraction. We need all sorts of minds. reply sgt101 11 hours agoprevThis is better : https://www.interaliamag.org/articles/margaret-boden-creativ... reply nyc111 10 hours agoprevI agree with the conclusions of the article. A concert pianist can only add his/her creativity to the piece if he/she totally internalized the piece. reply kiwi_kim 12 hours agoprevWe recently described this to a parent of one of our students as: Understanding -> Remembering -> Applying If you don't understand the basics of a concept, and you're talking about memory, its probably just rote memorization. Students generally find this tedious, and since it's shallow its very hard to retain and connect to disparate but parallel ideas from other fields (roots of creativity). But, most schools and students stop there. They hear 'memory' or 'memorizing' as only rote memory. Step 2 is critical if you want to get to higher levels of learning. As you said in the essay - \"Creativity comes to those who have internalized the patterns of their art\". At www.sticky.study this is what we focus on. It's fast 2D memory palaces + spaced repetition. Only if you have understanding + remembering can you get to step 3 - applying what you learn reliably at relevant moments in your life. This is the gold standard that schools claim they desire - analysis, synthesis, application, broad transfer, and creativity. You can't reach master efficiently if you lose 80% of all you read or learn. reply dzink 15 hours agoprevOne would argue it’s the opposite as people with memory problems have less imprint of old and more creative new ideas. reply keiferski 14 hours agoparentI don’t think that’s true. People with memory problems more seem to retread the same foundational ideas repeatedly, whereas those with good memories recognize this repetition and then seek something novel. reply swayvil 16 hours agoprevYou may as well say that creativity comes from writing. Because obviously all of the most creative writers write. And the writings of creative non-writers are entirely absent. reply Joel_Mckay 11 hours agoprevI hear with llm/chatGPT people don't have to blog anymore, but rather the generated plausible-sounding well-structured nonsense flows like an open sewer onto the web. 1. Creativity in a commercial context once stolen/cloned through back-channels accrues value, and manifests as several competitive campaigns 2. New disruptive ideas are usually shelved until the IP/patents expire. No one wants to go through the sometimes impossible licensing process 3. Emerging technology is usually degraded in the rush for IP assets by established firms i.e. large firms dump billions on ridiculous concepts out of fear of market fragmentation 4. Startups do not usually have cash to burn on speculative IP. Thus, real cutting-edge experimental technology is sometimes never made public for numerous reasons. Creativity: https://www.youtube.com/watch?v=VUVix0STUqo Best of luck, =3 reply wakawaka28 17 hours agoprev [–] You have to know things to be reasonably creative but there is a point where memorizing more stifles creativity. Memorization is often very passive and is fundamentally different from searching for new ways of doing things. It's hard to make sweeping statements like this because there are different modes of memory and different modes of creativity. There is a lot of memory involved in being creative, but I think setting out to memorize things is a bad way to be creative. You have to practice being creative. In doing so, you will naturally remember a lot of stuff like what works, what doesn't, and most importantly which types of things you ought to memorize. For example if you're programming you will find it useful to remember the syntax of your languages. If you're writing you'll find it useful to remember styles and vocabulary. And so on... reply shw1n 17 hours agoparent [–] Agreed -- I'm not trying to suggest that memory is a replacement for creativity I'm suggesting that it enables it, as it's hard to be creative when you're still trying to remember the basics of your art But once things become autonomous -- you can focus on those higher-level explorations reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author argues that applying systems to creative pursuits, such as DJ transitions and humor patterns, enhances creativity by internalizing knowledge and patterns.",
      "They advocate for a learning method that involves memorizing patterns and exposing oneself to various cases, which can be applied beyond academics to fields like sports and sales.",
      "The author suggests that mastering fundamentals through systems allows for higher-level innovation and creativity, as seen in cross-domain expertise in startups and music."
    ],
    "commentSummary": [
      "Creativity is often linked to internalized knowledge, which can be a result of memorization.",
      "There is a debate on whether rote memorization is essential for creativity, with some arguing for the importance of understanding and context over mere repetition.",
      "Internalizing concepts through repeated exposure can help develop heuristics and patterns useful for creative applications."
    ],
    "points": 255,
    "commentCount": 201,
    "retryCount": 0,
    "time": 1722379044
  },
  {
    "id": 41114569,
    "title": "Troubleshooting: Terminal Lag",
    "originLink": "https://lock.cmpxchg8b.com/slowterm.html",
    "originBody": "Troubleshooting: Terminal Lag Tavis Ormandy $Id: a07cf90837a3c4373b82d6724b97593810766af7 $ Background Window Effects Profiling Features Caching Conclusion I think I should blog more about random troubleshooting sessions, if nothing else it will remind me what steps I took when it inevitably happens again! Okay, here is the first one – why is my xterm opening so slowly? Background I have two similarly specced machines at my desk – my primary workstation running Fedora Linux, and a Windows 11 machine. They share the same monitor and input devices, and I switch between them with an iogear KVM. I do the bulk of my work in either a browser or a terminal. This is true even on Windows, where I rely heavily on WSL. This works well for me, and I’m happy enough with the setup. Issue I have the shortcut Super+1 bound to xterm on both machines, and I probably use this hundreds of times per day. Here is how that looks on Fedora: Fedora Terminal It takes about 300ms from key activation to a terminal being ready. This is fine, I’ve never noticed any problem. However, let’s compare that to Windows: Windows Terminal That’s about 1600ms before I can type, over 5 times slower! This is slow enough that it bothers me, and I use this shortcut so often that I want to solve it. I don’t think many people care about xterm performance on Windows, so I guess that means it’s up to me to solve this 🙂 Window Effects Hey, wait a minute… ENHANCE! 👀 Windows Fading Effect Why does the window fade in like that? It looks like the Window is ready when the effect starts, but I can’t interact with it until it completes. If I count those frames, this animation must be costing me ~200ms! 🤬 I always disable anything like animation or compositing effects, so I’m confused where this is coming from. Windows Performance Settings I tested with some native windows programs like notepad and calc – they just appear instantly… so what is causing that? I experimented with it a bit, I can see other windows behind it as it fades in, so I think something must be changing the opacity. Searching msdn, it looks like the function for that is SetLayeredWindowAttributes(). Could something be calling that, is my X server betraying me? $ dumpbin /imports X410.exegrep SetLayeredWindowAttributes 33A SetLayeredWindowAttributes This looks like the culprit!! I’m using a server called X410, it seems like it’s adding it’s own animation effects, and doesn’t have any way to disable it. I’m reluctant to switch to an alternative – that could just replace this issue with a different issue to troubleshoot. Is it possible I can just stop it from doing that with a debugger? $ cdb -p 6624 (19e0.2ad0): Break instruction exception - code 80000003 (first chance) ntdll!DbgBreakPoint: 00007ff9`1f9b3c90 cc int 3 0:014> eb win32u!NtUserSetLayeredWindowAttributes c3 0:014> .detach Detached NoTarget> q quit: Ah-ha, that actually worked!!! I’ve added that cdb command into my xinit initialization, and it looks a lot snappier. That saved nearly 300ms, so we’re down to just 4 times slower than Fedora! Profiling Okay, let’s try get some real numbers. I like the tool hyperfine for this, here are the initial results: Hyperfine Windows If we run it under optimal conditions, it takes about 900ms on Windows, and about 100ms on Fedora. Now that I can reproduce the delay reliably, I can start exploring some theories… Filesystem My first thought is that filesystem performance under WSL can be very slow, could that explain the difference? taviso@WORKSTATION:~$ strace -wc -efile xterm -e true % time seconds usecs/call calls errors syscall ------ ----------- ----------- --------- --------- ---------------- 43.93 0.014870 56 261 56 openat 23.79 0.008053 31 257 33 access 20.48 0.006932 32 211 12 newfstatat 7.07 0.002394 23 100 54 readlink 4.72 0.001596 1596 1 execve ------ ----------- ----------- --------- --------- ---------------- 100.00 0.033845 40 830 155 total Nope, it’s actually a bit faster on Windows! If I browse the logs, it looks related to fonts, and I do have fewer fonts installed on Windows. I suspect that causes fontconfig to query less files on initialization. Whatever the reason, I concluded it wasn’t a big proportion of startup time, so it doesn’t seem worth worrying about. X Server The issue must be the X server, how fast is a very simple X client? taviso@fedora:~$ hyperfine xdpyinfo Benchmark 1: xdpyinfo Time (mean ± σ): 4.6 ms ± 0.8 ms [User: 1.9 ms, System: 1.6 ms] Range (min … max): 3.1 ms … 9.4 ms 317 runs That does run slower on Windows, but not significantly slower – perhaps I actually need to create a window to see a difference? taviso@fedora:~$ x11perf -repeat 1 -subs 8 -popup 5600000 reps @ 0.0010 msec (1040000.0/sec): Hide/expose window via popup (8 kids) That is also slower on Windows – this is understandable, it has to translate from X11 to win32 – but not so slow that it adequately explains the problem alone. FreeType Could it be a FreeType or FontConfig issue? taviso@WORKSTATION:~$ ftbench -p consola.ttf executing tests: Load 2.491 us/op 809010 done Load_Advances (Normal) 2.437 us/op 827190 done Load_Advances (Fast) 0.022 us/op 88575990 done Load_Advances (Unscaled) 0.013 us/op 147448890 done Render 2.039 us/op 390870 done Get_Glyph 0.921 us/op 509040 done Get_Char_Index 0.018 us/op 111551968 done Iterate CMap 21.539 us/op 88503 done New_Face 6.271 us/op 284029 done Embolden 2.491 us/op 357540 done Stroke 24.663 us/op 69690 done Get_BBox 0.865 us/op 487830 done Get_CBox 0.679 us/op 506010 done Loading fonts is slightly slower, but the other numbers seem fine, and it’s not that much slower. I don’t think it’s this. Features Maybe I can get some clues from ltrace? $ ltrace -c xterm -e true % time seconds usecs/call calls function ------ ----------- ----------- --------- -------------------- 26.74 1.977389 988694 2 XtRealizeWidget 22.18 1.640132 14139 116 XtSetValues 13.39 0.989966 197993 5 XtVaCreateManagedWidget 6.42 0.474410 200 2361 strlen 5.51 0.407617 203808 2 read 4.21 0.311086 197 1572 FcCharSetHasChar 2.92 0.215975 2571 84 XtCreateManagedWidget 2.80 0.207397 69132 3 XtVaCreatePopupShell 2.39 0.176458 218 808 XftTextExtents32 1.51 0.111306 111306 1 XpmReadFileToPixmap 1.48 0.109486 109486 1 XtOpenApplication 1.44 0.106786 203 524 malloc This XtRealizeWidget call does seem slow, and I don’t see that on Fedora, what is calling that? $ gdb --args ./xterm -e true Reading symbols from ./xterm... (gdb) b XtRealizeWidget Breakpoint 1 at 0x2db20 (gdb) r Breakpoint 1, 0x00007fffff43d940 in XtRealizeWidget () from /lib/x86_64-linux-gnu/libXt.so.6 (gdb) bt #0 0x00007fffff43d940 in XtRealizeWidget () from /lib/x86_64-linux-gnu/libXt.so.6 ... #4 0x00007fffff44c4f6 in XtSetValues () from /lib/x86_64-linux-gnu/libXt.so.6 #5 0x0000000008086683 in UpdateMenuItem (menu=0x811c5c0 , which=0, val=1) at ./menu.c:1026 #6 0x000000000808a763 in update_toolbar () at ./menu.c:3366 Ah-ha – it’s the toolbar feature. It’s disabled at compile time on Fedora, but I quite like it and enable it on Windows. If I disable that, startup is a little faster, I wonder if there are any other features that are slowing down initialization…? Parameter Scanning The hyperfine utility has a feature called parameter scan, where it it will try a bunch of settings for you and tell you which one is fastest. Let’s ask XTerm what features are available, and toggle each one on and off. $ xterm -report-xres -e true activeIcon : default allowBoldFonts : true allowC1Printable : false allowColorOps : true allowFontOps : false allowMouseOps : true ... I’ll start by extracting all the settings that are booleans. $ xterm -report-xres -e truegrep -Po '^\\S+(?=\\s+: (true|false))'tr '' ',' allowBoldFonts,allowColorOps,allowMouseOps... Note: xterm has a lot of features, I’m truncating the list for brevity! Now we can give each of those to hyperfine, and let it figure out which settings have the most noticable effect. That took about 20 minutes to run, and reports: $ hyperfine --parameter-list res allowBoldFonts,allow... \\ --parameter-list bool true,false \\ \"xterm -xrm 'XTerm*{res}: {bool}' -e true\" ... Benchmark 240: xterm -xrm 'XTerm*xftTrackMemUsage: false' -e true Time (mean ± σ): 140.1 ms ± 7.4 ms [User: 30.8 ms, System: 23.4 ms] Range (min … max): 129.2 ms … 153.4 ms 21 runs Summary xterm -xrm 'XTerm*tekInhibit: true' -e true ran 1.01 ± 0.08 times faster than xterm -xrm 'XTerm*allowSendEvents: false' -e true ... This helped a little, I found a combination of options that saved around 200ms total. One example was tekInhibit, which disables the Tektronix emulation. That’s usually used as a graphing mode – it’s actually pretty cool. Still, it isn’t a big enough difference, and this is as far as I was able to get through tweaking settings. I’m starting to think that this is just death by a thousand cuts, everything just has some small overhead on Windows and it adds up… Caching There’s a simple generic solution to slow startup performance: server mode. The idea is to cache a few processes in the background, then all the slow stuff will already be done, ready for you to start working immediately. XTerm doesn’t have this feature natively, but it’s not complicated, I can add it. To do this, I will use deferred mapping – that just means that a program is running, but the window is not visible yet. I tried a few solutions and found one that works well, an LD_PRELOAD library. All it does is intercept any toplevel XMapWindow() calls, then pause execution until it receives a signal. It’s a bit hacky, but my code is here, if you’re interested. To use it, you need something to manage the cache for you in the background, xargs will work! $ xargs --null --arg-file=/dev/zero --max-procs=3 --replace -- \\ env LD_PRELOAD=defermap.so xterm -display :0 [PARAMS...] This will keep three xterms running in the background. Note: If you often rapidly start terminals in quick succession, increase max-procs. When you want a new terminal, instead of running xterm as you normally would, do this instead: $ pkill --oldest --signal SIGUSR1 xtermserver A terminal should appear near-instantly. You can now execute that instead of xterm, and startup performance should be solved. Conclusion This whole process took a while! Now I need to adjust my shortcuts to run pkill instead of xterm, and I can compare the results. Windows Terminal Counting the frames in that video, it’s down to about 366ms, just 60ms slower than Fedora, this is totally acceptable! I’ve been using this configuration for a few days, so far it’s working great. I haven’t noticed any issues running it this way. I highly doubt anyone else will find this useful, who else is using XTerm on Windows? 😆 Nevertheless, if you have a better solution, or can think of something else I can try, let me know! HOME • ABOUT • CONTACT",
    "commentLink": "https://news.ycombinator.com/item?id=41114569",
    "commentBody": "Troubleshooting: Terminal Lag (cmpxchg8b.com)188 points by janvdberg 20 hours agohidepastfavorite42 comments vijucat 14 hours agoLove such articles where I learn something new. cdb is completely new to me. It's apparently the Microsoft Console Debugger. For others like me who were wondering how `eb win32u!NtUserSetLayeredWindowAttributes c3` neutered the window animation: \"By executing this command, you are effectively replacing the first byte of the `NtUserSetLayeredWindowAttributes` function with a `ret` instruction. This means that any call to `NtUserSetLayeredWindowAttributes` will immediately return without executing any of its original code. This can be used to bypass or disable the functionality of this function\" (Thanks to GitHub Copilot for that) Also see https://learn.microsoft.com/en-us/windows-hardware/drivers/d... reply xelxebar 13 hours agoparentNice. Here's a breakdown for anyone interested: - eb[0] \"enters bytes\" into memory at the specified location; - The RETN[1] instruction is encoded as C3 in x86 opcodes; and - Debuggers will typically load ELF symbols so you can refer to memory locations with their names, i.e. function names refer to their jump target. Putting those three together, we almost get the author's command. I'm not sure about the \"win32u!NtUser\" name prefix, though. Is it name-munging performed on the compiler side? Maybe some debugger syntax thrown in to select the dll source of the name? [0]:https://learn.microsoft.com/en-us/windows-hardware/drivers/d... [1]:http://ref.x86asm.net/geek64.html#xC3 reply Joker_vD 6 hours agorootparentThe \"win32u!\" prefix is for the name of the DLL where the symbol lives. On Windows, the imported symbols are bound to their DLLs, instead of floating in the ether like they do on Linux where the dynamic loader just searches for them in whatever shared objects it has previously loaded. reply therein 10 hours agorootparentprevYes, NtUserSetLayeredWindowAttributes is in win32u.dll. And if you are wondering what's the difference between win32u.dll and user32.dll. > win32u.dll is a link for System calls between User mode (Ring 3) and Kernel mode (Ring 0) : Ring 3 => Ring 0 https://imgbb.com/L8FTP2C [0] [0] - https://learn.microsoft.com/en-us/answers/questions/213495/w... reply zokier 1 hour agoprevJust for fun I did film some video footage from my 60Hz monitor to see how quickly my terminal starts up. Seems like 2-3 frames to show up the terminal window, and 1-2 frames to show shell prompt. So 50 ms - 83 ms. This is with foot terminal on Sway. My very unscientific methodology was to run $ echo hello && foot in a terminal and measure the time between the hello text appearing and the new window appearing. Looking at my video, the time from physical key press to \"hello\" text appearing might be 20ish ms but that is less clear, so about 100 ms total from key press to shell prompt. This is pretty much completely untuned setup, I haven't done any tweaks to improve the figures. Enabling foot server might shave some milliseconds, but tbh I don't feel that's necessary. It'd be fun to do this with better camera, and also with better monitors. Idk how difficult it would be to mod in some LED to keyboard to capture the exact moment the key is activated, just trying to eyeball the key movement is not very precise. reply txdv 12 hours agoprevSo the root cause of the slowness was not found, it was just circumvented by keeping 3 xterms open and just using hiding/showing them? reply imp0cat 3 hours agoparentBut that does not make his solution any less valid. Or does it? In fact, keeping something preloaded and ready to go is quite common, these two examples are off the top of my head: - The Emacs server way - https://ungleich.ch/u/blog/emacs-server-the-smart-way/ - SSH connection reuse. reply aardshark 16 hours agoprev300ms for startup still sounds slow to me. Not ridiculously so, but it won't give that snappy feeling. reply jlarocco 15 hours agoparentI thought so, too. I'm not interested enough to benchmark it, but for all practical purposes it's instantaneous on my machine. As fast to open a new terminal as it is to switch to the existing one. reply macromaniac 7 hours agorootparentMine takes 50ms, assuming wsl is hot (recorded screen and compared mouse click frame to window pop up frame). I think op should try a different wsl distro or a blank machine and compare differences. I have on access scanning off, performance on, Ubuntu wsl distro, and windows 10. reply rfoo 5 hours agorootparentI believe OP recorded him pressing a key on keyboard and counted between key is clearly pressed and the moment when xterm is up. Compare to screen recording, this adds latency introduced by keyboard and monitor, which sometimes could be 100ms+. See https://danluu.com/input-lag/ reply Szpadel 9 hours agoparentprevinteresting side note, our brain is compensating for delay, it can do it to around 250ms so if anything lags up to that amount our brain will compensate and make it feel imstantenious there was interesting experiment that I reproduced at university, create app that slowly build up delay to clicks to allow brain to adapt, and then remove it completely. result is that you have feeling that it reacts just before you actually click until brain adapts again to new timing reply arghwhat 6 hours agorootparentI don't think it's right to say that the compensation makes things feel instantaneous, but rather that we are able to still feel the association between input and result, allowing for coordinated feedback loops to be maintained. We do grow accustomed to the latency, but I do not think it is right to say that it feels like zero latency. If the delay is long enough, the output does not just feel delayed, but entirely unrelated to the input. A latency perception test involving a switch can easily be thrown off by a disconnect between the actual point of actuation vs. the end-users perceived point of actuation. For example, the user might feel - especially if exposed to a high system latency - that the switch actuation is after the button has physically bottomed out and squeezed with an increased force as if they were trying to mechanically induce the action, and later be surprised to realize that the actuation point was after less than half the key travel when the virtual latency is removed. Without knowing the details of the experiment, I think this is a more likely explanation for a perception of negative latency: Not intuitively understanding the input trigger. reply pcthrowaway 13 hours agoprev> I’ve been using this configuration for a few days, so far it’s working great. I haven’t noticed any issues running it this way. The journey was very useful, even the destination may be pretty specific to your needs. The process of how to go about debugging minor annoyances like this is really hard to learn about. reply abraae 17 hours agoprevI'm at the tail end of my career, so working on efficiency gains like this doesn't usually add up for me. However I was interested in knowing whether it does for the author. Assuming he/she does suffer this 1300 ms delay \"hundreds\" of times a day (let's say 200) and for the sake of argument they use their computer 300 days a year and have 20 years of such work ahead of them with this config, then this inefficiency will total 1300 x 200 x 300 x 20 / 1000 / 60 / 60 hours wasted during author's lifetime - some 430 hours. So well worth the effort to fix! reply anonymoushn 16 hours agoparentI find that annoyances cost me much more than the wall-clock time of the delay. You're lucky to disagree :) reply sllabres 12 hours agoparentprevI had a printout of [1] at my office. Of course at is base it is only a simple multiplication table, but nevertheless is reminded me several time that a issue is worth fixing. [1] https://xkcd.com/1205/ reply jd3 15 hours agoprevI'm so distracted by latency that I run my macOS with vsync disabled 24/7 (through Quartz Debug). When I used to use Windows 10+ years ago, I had decent luck using xming + cygwin + Cygwin/X + bblean to run xterm in a minimal latency/lag environment. I also launch Chrome/Spotify/Slack desktop using: $ open -a open -a Google\\ Chrome --args --disable-gpu-vsync --disable-smooth-scrolling reply abhinavk 14 hours agoparentOne way to have the cake and eat it too is to upgrade to a high-refresh rate display. No tearing + less latency + smoother display. Although it's diminishing returns even 60Hz -> 144Hz+ will make a lot of difference. On a 240Hz display, vsync penalty is just 4ms. Also if you are using a miniLED M-class MBP, its pixel response is abysmal. reply fellerts 10 hours agorootparentI've been running uncomposited X for years to reduce latency, but after getting a dual 120 Hz monitor setup, I might finally consider Wayland! This is good advice. Too bad vscode doesn't support higher refresh rates. It's locked to 60 for some reason I haven't been able to grasp. reply jd3 6 hours agorootparentSince vscode is an electron app, have you tried opening it with $ open -a open -a Visual\\ Studio\\ Code --args --disable-gpu-vsync --disable-smooth-scrolling --disable-frame-rate-limit reply jd3 14 hours agorootparentprevYep, have been planning to upgrade to a 240hz+ OLED for awhile! I find the typing input latency on my M1 MacBook Pro to be pretty abysmal when using the built-in retina display and no external monitor — I almost feel like I can only get work done when I have it plugged into my external monitor in clamshell mode and disable vsync. reply itsTyrion 4 hours agorootparent\"abysmal\"?? Literally the first time I've seen someone negatively mention latency on a recent Macbook reply tedunangst 9 minutes agorootparentPixel response time is something like 30ms on MacBook Pro. So the 120hz screen can feel more like 30hz. reply swah 7 hours agorootparentprevI'm happy to report I have no idea what you're talking about and find the typing on the Macbook the best computer experience I ever had :D I'll be careful not to use higher refresh rates devices though, that could show me what you're talking about :) reply bee_rider 14 hours agorootparentprevIt just seems so wasteful to run desktop and office programs at hundreds of hertz… reply maccard 9 hours agorootparentThis is one of those things where if your applications are written using native frameworks the difference is minimal, and you get the benefit of an actual smooth experience. Meanwhile if the app is a \"custom lightweight framework\", you're likely just burning CPU cycles. reply NavinF 9 hours agorootparentprevHow so? Anything under 1000Hz has obvious delays: https://youtu.be/vOvQCPLkPt4?si=oXDiV9gagyZdnkkM reply account42 5 hours agorootparentprevDesktop programs should only repaint when they need to. So you are only actually rendering the programs at hundreds of hertz when something is animated. reply apazzolini 14 hours agoparentprevOut of curiosity, have you tried a 144hz monitor on macOS with vsync enabled? reply jd3 14 hours agorootparentI use a cheap 75hz IPS from my office, though, ideally, I'd like to upgrade to a 240hz+ OLED w/ VRR since macOS now supports adaptive sync[0]; i've been waiting because I'm not satisfied w/ any of the OLED monitors currently on the market and my monitor upgrade request was denied by my employer. Though I've used the Apple Magic Keyboard w/ Touch ID exclusively for awhile, I'm also thinking about upgrading to the new Wooting 80HE keyboard this fall since it has a 8kHz polling rate, analog hall effect switches, and is designed to be ultra low latency w/ tachyon mode enabled. [0]: https://support.apple.com/guide/mac-help/use-adaptive-sync-w... reply aardshark 16 hours agoprev300ms for startup still sounds slow to me. Not ridiculously so, but it won't give that snappy feeling. reply mberning 16 hours agoprevThis is a tour de force on the type of curiosity it takes to be really successful with computers. reply pikseladam 19 hours agoprevit was a fun read reply aftbit 19 hours agoprev [–] Upvote just for teaching me about the existence of `hyperfine`. $ hyperfine 'alacritty -e true' Benchmark 1: alacritty -e true Time (mean ± σ): 84.1 ms ± 4.9 ms [User: 40.1 ms, System: 30.8 ms] Range (min … max): 80.5 ms … 104.4 ms 32 runs $ hyperfine 'xterm -e true' Benchmark 1: xterm -e true Time (mean ± σ): 81.9 ms ± 2.6 ms [User: 21.7 ms, System: 7.9 ms] Range (min … max): 74.9 ms … 87.1 ms 37 runs $ hyperfine 'wezterm -e true' Benchmark 1: wezterm -e true Time (mean ± σ): 211.7 ms ± 13.4 ms [User: 41.4 ms, System: 60.0 ms] Range (min … max): 190.5 ms … 240.5 ms 15 runs reply JNRowe 17 hours agoparentIf we're handing out tips, then as noted in a few examples from the article hyperfine is even more useful when called with multiple commands directly. It presents a concise epilogue with the information you're probably trying to gleam from a run such as yours: $ hyperfine -L arg '1,2,3' 'sleep {arg}' … Summary sleep 1 ran 2.00 ± 0.00 times faster than sleep 2 3.00 ± 0.00 times faster than sleep 3 If your commands don't share enough in common for that approach then you can declare them individually, as in \"hyperfine 'blib 1' 'blob x y' 'blub --arg'\", and still get the summary. reply LanternLight83 17 hours agorootparenti once used hyperfine to micro-bench elisp functions. i se $SHELL to a script that evaluated it's arguments in emacs by talking to a long-running session over a named pipe. Hyperfine runs a few no-ops with $SHELL and factored out the overhead, though it was still helpful to run a nested loop in elisp for finer results. reply Shugyousha 9 hours agoparentprevI also didn't know about `hyperfine`, very nice! Even 80ms seems unnecessarily slow to me. 300ms would drive me nuts ... I'm using a tiling window manager (dwm) and interestingly the spawning time varies depending on the position that the terminal window has to be rendered to. The fastest startup time I get on the fullscreen tiling mode. hyperfine 'st -e true' Benchmark 1: st -e true Time (mean ± σ): 35.7 ms ± 10.0 ms [User: 15.4 ms, System: 4.8 ms] Range (min … max): 17.2 ms … 78.7 ms 123 runs The non-fullscreen one ends up at about 60ms which still seems reasonable. reply JNRowe 7 hours agorootparentYou could maybe find out where the delay is by using st's Xembed support? Create a window with tabbed¹ in a tiling layout, open st in to it with \"st -w-e true\". If it is close to the monocle time, it is probably the other windows handling the resize event that is causing the slowdown not the layout choice. To prove it to myself: I'm using river² and I can see a doubling-ish of startup time with foot³, iff I allow windows from heavier apps to handle the resize event immediately. If the time was a little longer(or more common) I'd be tempted to wrap the spawn along the lines of \"kill -STOP ; ; kill -CONT \" to delay the resize events until my new window was ready. That way the frames still resize, but their content resize is delayed. ¹ https://tools.suckless.org/tabbed/ ² https://codeberg.org/river/river ³ https://codeberg.org/dnkl/foot reply pimlottc 16 hours agoparentprevHandy project link: https://github.com/sharkdp/hyperfine reply oguz-ismail 15 hours agoparentprev [–] Does it parse commands and call exec*() or spawn a new shell for every run of every command? reply JNRowe 15 hours agorootparent [–] You can choose the behaviour with the --shell option¹. The default behaviour is nice because it allows you to benchmark pipelines easily, but if you want to change it you can. ¹ https://github.com/sharkdp/hyperfine#intermediate-shell reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The user experienced significant lag when opening xterm on a Windows 11 machine compared to a Fedora Linux workstation, with Windows taking around 1600ms initially.",
      "Profiling and debugging revealed that disabling window effects and certain xterm features, such as the toolbar and Tektronix emulation, improved performance.",
      "Implementing a server mode with deferred mapping using an LD_PRELOAD library further reduced the startup time to approximately 366ms on Windows, making it nearly as fast as on Fedora."
    ],
    "commentSummary": [
      "The article discusses troubleshooting terminal lag, specifically focusing on the Microsoft Console Debugger (cdb) and its commands to modify function behavior.",
      "It highlights the use of the `eb win32u!NtUserSetLayeredWindowAttributes c3` command to disable a function by replacing its first byte with a `ret` instruction, making it return immediately.",
      "The discussion includes various user experiences and methods to measure and reduce terminal startup time, such as using the `hyperfine` benchmarking tool and different terminal emulators."
    ],
    "points": 188,
    "commentCount": 42,
    "retryCount": 0,
    "time": 1722377079
  },
  {
    "id": 41116639,
    "title": "Rustgo: Calling Rust from Go with near-zero overhead (2017)",
    "originLink": "https://words.filippo.io/rustgo/",
    "originBody": "15 Aug 2017 rustgo: calling Rust from Go with near-zero overhead [русский] Go has good support for calling into assembly, and a lot of the fast cryptographic code in the stdlib is carefully optimized assembly, bringing speedups of over 20 times. However, writing assembly code is hard, reviewing it is possibly harder, and cryptography is unforgiving. Wouldn't it be nice if we could write these hot functions in a higher level language? This post is the story of a slightly-less-than-sane experiment to call Rust code from Go fast enough to replace assembly. No need to know Rust, or compiler internals, but knowing what a linker is would help. Hello, readers from the future! In the seven years since writing this a couple things changed, but note that this was always a fun technical exploration, not a production guide. If you're looking for serious ways to call Rust from Go, know that cgo these days is faster and still getting faster. There are also some experimental cgo-less alternatives, like purego and wazero. Still, experimenting with this stuff is fascinating. I toyed for years with the idea of using Wasm for cross-platform Go FFI withg better DX. I admit I even used a tecnique similar to this in the standard library, to invoke the macOS X.509 verifier. As for me, I gave a talk about this at a Go conference wearing a (freshly printed) Rust Evangelism Strike Force t-shirt. That kind of landed me a job on the Go team at Google, which I left to become an independent Go maintainer. The fight against cryptographic assembly continues, but now with strict policies and dedicated generators. Just yesterday I livestreamed a benchmarking session to replace some P-256 curve assembly with formally verified Go code. Subscribe to Cryptography Dispatches for more! Subscribe Why Rust I'll be upfront: I don't know Rust, and don't feel compelled to do my day-to-day programming in it. However, I know Rust is a very tweakable and optimizable language, while still more readable than assembly. (After all, everything is more readable than assembly!) Go strives to find defaults that are good for its core use cases, and only accepts features that are fast enough to be enabled by default, in a constant and successful fight against knobs. I love it for that. But for what we are doing today we need a language that won't flinch when asked to generate stack-only functions with manually hinted away safety checks. So if there's a language that we might be able to constrain enough to behave like assembly, and to optimize enough to be as useful as assembly, it might be Rust. Finally, Rust is safe, actively developed, and not least, there's already a good ecosystem of high-performance Rust cryptography code to tap into. Why not cgo Go has a Foreign Function Interface, cgo. cgo allows Go programs to call C functions in the most natural way possible—which is unfortunately not very natural at all. (I know more than I'd like to about cgo, and I can tell you it's not fun.) By using the C ABI as lingua franca of FFIs, we can call anything from anything: Rust can compile into a library exposing the C ABI, and cgo can use that. It's awkward, but it works. We can even use reverse-cgo to build Go into a C library and call it from random languages, like I did with Python as a stunt. (It was a stunt folks, stop taking me seriously.) But cgo does a lot of things to enable that bit of Go naturalness it provides: it will setup a whole stack for C to live in, it makes defer calls to prepare for a panic in a Go callback... this could be will be a whole post of its own. As a result, the performance cost of each cgo call is way too high for the use case we are thinking about—small hot functions. Linking it together So here's the idea: if we have Rust code that is as constrained as assembly, we should be able to use it just like assembly, and call straight into it. Maybe with a thin layer of glue. We don't have to work at the IR level: the Go compiler converts both code and high-level assembly into machine code before linking since Go 1.3. This is confirmed by the existence of \"external linking\", where the system linker is used to put together a Go program. It's how cgo works, too: it compiles C with the C compiler, Go with the Go compiler, and links it all together with clang or gcc. We can even pass flags to the linker with CGO_LDFLAGS. Underneath all the safety features of cgo, we surely find a cross-language function call, after all. It would be nice if we could figure out how to do this without patching the compiler, though. First, let's figure out how to link a Go program with a Rust archive. I could not find a decent way to link against a foreign blob with go build (why should there be one?) except using #cgo directives. However, invoking cgo makes .s files go to the C compiler instead of the Go one, and my friends, we will need Go assembly. Thankfully go/build is nothing but a frontend! Go offers a set of low level tools to compile and link programs, go build just collects files and invokes those tools. We can follow what it does by using the -x flag. I built this small Makefile by following a -x -ldflags \"-v -linkmode=external '-extldflags=-v'\" invocation of a cgo build. rustgo: rustgo.a go tool link -o rustgo -extld clang -buildmode exe -buildid b01dca11ab1e -linkmode external -v rustgo.a rustgo.a: hello.go hello.o go tool compile -o rustgo.a -p main -buildid b01dca11ab1e -pack hello.go go tool pack r rustgo.a hello.o hello.o: hello.s go tool asm -I \"$(shell go env GOROOT)/pkg/include\" -D GOOS_darwin -D GOARCH_amd64 -o hello.o hello.s This compiles a simple main package composed of a Go file (hello.go) and a Go assembly file (hello.s). Now, if we want to link in a Rust object we first build it as a static library... libhello.a: hello.rs rustc -g -O --crate-type staticlib hello.rs ... and then just tell the external linker to link it together. rustgo: rustgo.a libhello.a go tool link -o rustgo -extld clang -buildmode exe -buildid b01dca11ab1e -linkmode external -v -extldflags='-lhello -L\"$(CURDIR)\"' rustgo.a $ make go tool asm -I \"/usr/local/Cellar/go/1.8.1_1/libexec/pkg/include\" -D GOOS_darwin -D GOARCH_amd64 -o hello.o hello.s go tool compile -o rustgo.a -p main -buildid b01dca11ab1e -pack hello.go go tool pack r rustgo.a hello.o rustc --crate-type staticlib hello.rs note: link against the following native artifacts when linking against this static library note: the order and any duplication can be significant on some platforms, and so may need to be preserved note: library: System note: library: c note: library: m go tool link -o rustgo -extld clang -buildmode exe -buildid b01dca11ab1e -linkmode external -v -extldflags=\"-lhello -L/Users/filippo/code/misc/rustgo\" rustgo.a HEADER = -H1 -T0x1001000 -D0x0 -R0x1000 searching for runtime.a in /usr/local/Cellar/go/1.8.1_1/libexec/pkg/darwin_amd64/runtime.a searching for runtime/cgo.a in /usr/local/Cellar/go/1.8.1_1/libexec/pkg/darwin_amd64/runtime/cgo.a 0.00 deadcode 0.00 pclntab=166785 bytes, funcdata total 17079 bytes 0.01 dodata 0.01 symsize = 0 0.01 symsize = 0 0.01 reloc 0.01 dwarf 0.02 symsize = 0 0.02 reloc 0.02 asmb 0.02 codeblk 0.03 datblk 0.03 sym 0.03 headr 0.06 host link: \"clang\" \"-m64\" \"-gdwarf-2\" \"-Wl,-headerpad,1144\" \"-Wl,-no_pie\" \"-Wl,-pagezero_size,4000000\" \"-o\" \"rustgo\" \"-Qunused-arguments\" \"/var/folders/ry/v14gg02d0y9cb2w9809hf6ch0000gn/T/go-link-412633279/go.o\" \"/var/folders/ry/v14gg02d0y9cb2w9809hf6ch0000gn/T/go-link-412633279/000000.o\" \"-g\" \"-O2\" \"-lpthread\" \"-lhello\" \"-L/Users/filippo/code/misc/rustgo\" 0.34 cpu time 12641 symbols 5764 liveness data Jumping into Rust Alright, so we linked it, but the symbols are not going to do anything just by sitting next to each other. We need to somehow call the Rust function from our Go code. We know how to call a Go function from Go. In assembly the same call looks like CALL hello(SB), where SB is a virtual register all global symbols are relative to. If we want to call an assembly function from Go we make the compiler aware of its existence like a C header, by writing func hello() without a function body. I tried all combinations of the above to call an external (Rust) function, but they all complained that they couldn't find either the symbol name, or the function body. But cgo, which at the end of the day is just a giant code generator, somehow manages to eventually invoke that foreign function! How? I stumbled upon the answer a couple days later. //go:cgo_import_static _cgoPREFIX_Cfunc__Cmalloc //go:linkname __cgofn__cgoPREFIX_Cfunc__Cmalloc _cgoPREFIX_Cfunc__Cmalloc var __cgofn__cgoPREFIX_Cfunc__Cmalloc byte var _cgoPREFIX_Cfunc__Cmalloc = unsafe.Pointer(&__cgofn__cgoPREFIX_Cfunc__Cmalloc) That looks like an interesting pragma! //go:linkname just creates a symbol alias in the local scope (which can be used to call private functions!), and I'm pretty sure the byte trick is only cleverness to have something to take the address of, but //go:cgo_import_static... this imports an external symbol! 2024 note: cgo_import_static is not usable anymore, but there are alternative strategies. Armed with this new tool and the Makefile above, we have a chance to invoke this Rust function (hello.rs) #[no_mangle] pub extern fn hello() { println!(\"Hello, Rust!\"); } (The no-mangle-pub-extern incantation is from this tutorial.) from this Go program (hello.go) package main //go:cgo_import_static hello func trampoline() func main() { println(\"Hello, Go!\") trampoline() } with the help of this assembly snippet. (hello.s) TEXT ·trampoline(SB), 0, $2048 JMP hello(SB) RET CALL was a bit too smart to work, but using a simple JMP... Hello, Go! Hello, Rust! panic: runtime error: invalid memory address or nil pointer dereference [signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x0] 💥 Well, it crashes when it tries to return. Also that $2048 value is the whole stack size Rust is allowed (if it's even putting the stack in the right place), and don't ask me what happens if Rust tries to touch a heap... but hell, I'm surprised it works at all! Calling conventions Now, to make it return cleanly, and take some arguments, we need to look more closely at the Go and Rust calling conventions. A calling convention defines where arguments and return values sit across function calls. The Go calling convention is described here and here. For Rust we'll look at the default for FFI, which is the standard C calling convention. To keep going we're going to need a debugger. (LLDB supports Go, but breakpoints are somehow broken on macOS, so I had to play inside a privileged Docker container.) ![Zelda dangerous to go alone](/content/images/2017/08/zelda-2.png) The Go calling convention The Go calling convention is mostly undocumented, but we'll need to understand it to proceed, so here is what we can learn from a disassembly (amd64 specific). Let's look at a very simple function. // func foo(x, y uint64) uint64 TEXT ·foo(SB), 0, $256-24 MOVQ x+0(FP), DX MOVQ DX, ret+16(FP) RET foo has 256 (0x100) bytes of local frame, 16 bytes of arguments, 8 bytes of return value, and it returns its first argument. func main() { foo(0xf0f0f0f0f0f0f0f0, 0x5555555555555555) rustgo[0x49d785]: movabsq $-0xf0f0f0f0f0f0f10, %rax rustgo[0x49d78f]: movq %rax, (%rsp) rustgo[0x49d793]: movabsq $0x5555555555555555, %rax rustgo[0x49d79d]: movq %rax, 0x8(%rsp) rustgo[0x49d7a2]: callq 0x49d8a0 ; main.foo at hello.s:14 The caller, seen above, does very little: it places the arguments on the stack in reverse order, at the bottom of its own frame (rsp to 16(rsp), remember that the stack grows down) and executes CALL. The CALL will push the return pointer to the stack and jump. There's no caller cleanup, just a plain RET. Notice that rsp is fixed, and we have movqs, not pushs. rustgo`main.foo at hello.s:14: rustgo[0x49d8a0]: movq %fs:-0x8, %rcx rustgo[0x49d8a9]: leaq -0x88(%rsp), %rax rustgo[0x49d8b1]: cmpq 0x10(%rcx), %rax rustgo[0x49d8b5]: jbe 0x49d8ee ; main.foo + 78 at hello.s:14 [...] rustgo[0x49d8ee]: callq 0x495d10 ; runtime.morestack_noctxt at asm_amd64.s:405 rustgo[0x49d8f3]: jmp 0x49d8a0 ; main.foo at hello.s:14 The first 4 and last 2 instructions of the function are checking if there is enough space for the stack, and if not calling runtime.morestack. They are probably skipped for NOSPLIT functions. rustgo[0x49d8b7]: subq $0x108, %rsp [...] rustgo[0x49d8e6]: addq $0x108, %rsp rustgo[0x49d8ed]: retq Then there's the rsp management, which subtracts 0x108, making space for the entire 0x100 bytes of frame in one go, and the 8 bytes of frame pointer. So rsp points to the bottom (the end) of the function frame, and is callee managed. Before returning, rsp is returned to where it was (just past the return pointer). rustgo[0x49d8be]: movq %rbp, 0x100(%rsp) rustgo[0x49d8c6]: leaq 0x100(%rsp), %rbp [...] rustgo[0x49d8de]: movq 0x100(%rsp), %rbp Finally the frame pointer, which is effectively pushed to the stack just after the return pointer, and updated at rbp. So rbp is also callee saved, and should be updated to point at where the caller's rbp is stored to enable stack trace unrolling. rustgo[0x49d8ce]: movq 0x110(%rsp), %rdx rustgo[0x49d8d6]: movq %rdx, 0x120(%rsp) Finally, from the body itself we learn that return values go just above the arguments. Virtual registers The Go docs say that SP and FP are virtual registers, not just aliases of rsp and rbp. Indeed, when accessing SP from Go assembly, the offsets are adjusted relative to the real rsp so that SP points to the top, not the bottom, of the frame. That's convenient because it means not having to change all offsets when changing the frame size, but it's just syntactic sugar. Naked access to the register (like MOVQ SP, DX) accesses rsp directly. The FP virtual register is simply an adjusted offset over rsp, too. It points to the bottom of the caller frame, where arguments are, and there's no direct access. Note: Go maintains rbp and frame pointers to help debugging, but then uses a fixed rsp and omit-stack-pointer-style rsp offsets for the virtual FP. You can learn more about frame pointers and not using them from this Adam Langley blog post. The C calling convention \"sysv64\", the default C calling convention on x86-64, is quite different: The arguments are passed via registers: RDI, RSI, RDX, RCX, R8, and R9. The return value goes to RAX. Some registers are callee-saved: RBP, RBX, and R12–R15. We care little about this, since in Go all registers are caller-saved. The stack must be aligned to 16-bytes. (I think this is why JMP worked and CALL didn't, we failed to align the stack!) Frame pointers work the same way (and are generated by rustc with -g). Gluing them together Building a simple trampoline between the two conventions won't be hard. We can also look at asmcgocall for inspiration, since it does approximately the same job, but for cgo. We need to remember that we want the Rust function to use the stack space of our assembly function, since Go ensured for us that it's present. To do that, we have to rollback rsp from the end of the stack. package main //go:cgo_import_static increment func trampoline(arg uint64) uint64 func main() { println(trampoline(41)) } ⬇ TEXT ·trampoline(SB), 0, $2048-16 MOVQ arg+0(FP), DI // Load the argument before messing with SP MOVQ SP, BX // Save SP in a callee-saved registry ADDQ $2048, SP // Rollback SP to reuse this function's frame ANDQ $~15, SP // Align the stack to 16-bytes CALL increment(SB) MOVQ BX, SP // Restore SP MOVQ AX, ret+8(FP) // Place the return value on the stack RET ⬇ #[no_mangle] pub extern fn increment(a: u64) -> u64 { return a + 1; } CALL on macOS CALL didn't quite work on macOS. For some reason, there the function call was replaced with an intermediate call to _cgo_thread_start, which is not that incredible considering we are using something called cgo_import_static and that CALL is virtual in Go assembly. callq 0x40a27cd ; x_cgo_thread_start + 29 We can bypass that \"helper\" by using the full //go:linkname incantation we found in the standard library to take a pointer to the function, and then calling the function pointer, like this. import _ \"unsafe\" //go:cgo_import_static increment //go:linkname increment increment var increment uintptr var _increment = &increment MOVQ ·_increment(SB), AX CALL AX Is it fast? The point of this whole exercise is to be able to call Rust instead of assembly for cryptographic operations (and to have fun). So a rustgo call will have to be almost as fast as an assembly call to be useful. Benchmark time! We'll compare incrementing a uint64 inline, with a //go:noinline function, with the rustgo call above, and with a cgo call to the exact same Rust function. Rust was compiled with -g -O, and the benchmarks were run on macOS on a 2.9GHz Intel Core i5. name time/op CallOverhead/Inline 1.72ns ± 3% CallOverhead/Go 4.60ns ± 2% CallOverhead/rustgo 5.11ns ± 4% CallOverhead/cgo 73.6ns ± 0% rustgo is 11% slower than a Go function call, and almost 15 times faster than cgo! The performance is even better when run on Linux without the function pointer workaround, with only a 2% overhead. name time/op CallOverhead/Inline 1.67ns ± 2% CallOverhead/Go 4.49ns ± 3% CallOverhead/rustgo 4.58ns ± 3% CallOverhead/cgo 69.4ns ± 0% A real example For a real-world demo, I picked the excellent curve25519-dalek library, and specifically the task of multiplying the curve basepoint by a scalar and returning its Edwards representation. The Cargo benchmarks swing widely between executions because of CPU frequency scaling, but they suggest the operation will take 22.9µs ± 17%. test curve::bench::basepoint_mult ... bench: 17,276 ns/iter (+/- 3,057) test curve::bench::edwards_compress ... bench: 5,633 ns/iter (+/- 858) On the Go side, we'll expose a simple API. func ScalarBaseMult(dst, in *[32]byte) On the Rust side, it's not different from building an interface for normal FFI. I'll be honest, it took me forever to figure out enough Rust to make this work. #![no_std] extern crate curve25519_dalek; use curve25519_dalek::scalar::Scalar; use curve25519_dalek::constants; #[no_mangle] pub extern fn scalar_base_mult(dst: &mut [u8; 32], k: &[u8; 32]) { let res = &constants::ED25519_BASEPOINT_TABLE * &Scalar(*k); dst.clone_from(res.compress_edwards().as_bytes()); } To build the .a we use cargo build --release with a Cargo.toml that defines the dependencies, enables frame pointers, and configures curve25519-dalek to use its most efficient math and no standard library. [package] name = \"ed25519-dalek-rustgo\" version = \"0.0.0\" [lib] crate-type = [\"staticlib\"] [dependencies.curve25519-dalek] version = \"^0.9\" default-features = false features = [\"nightly\"] [profile.release] debug = true Finally, we need to adjust the trampoline to take two arguments and return no value. TEXT ·ScalarBaseMult(SB), 0, $16384-16 MOVQ dst+0(FP), DI MOVQ in+8(FP), SI MOVQ SP, BX ADDQ $16384, SP ANDQ $~15, SP MOVQ ·_scalar_base_mult(SB), AX CALL AX MOVQ BX, SP RET The result is a transparent Go call with performance that closely resembles the pure Rust benchmark, and is almost 6% faster than cgo! name old time/op new time/op delta RustScalarBaseMult 23.7µs ± 1% 22.3µs ± 4% -5.88% (p=0.003 n=5+7) For comparison, similar functionality is provided by github.com/agl/ed25519/edwards25519, and that pure-Go library takes almost 3 times as long. h := &edwards25519.ExtendedGroupElement{} edwards25519.GeScalarMultBase(h, &k) h.ToBytes(&dst) name time/op GoScalarBaseMult 66.1µs ± 2% Packaging up Now we know it actually works, that's exciting! But to be usable it will have to be an importable package, not forced into package main by a weird build process. This is where //go:binary-only-package comes in! That annotation allows us to tell the compiler to ignore the source of the package, and to only use the pre-built .a library file in $GOPATH/pkg. 2024 note: binary-only-package is also gone, but using a .syso file was probably the correct answer back then, too. Still, this was a fun detour into linking tooling. If we can manage to build a .a file that works with Go's native linker (cmd/link, referred to also as the internal linker), we can redistribute that and it will let our users import the package as if it was a native one, including cross-compiling (provided we included a .a for that platform)! The Go side is easy, and pairs with the assembly and Rust we already have. We can even include docs for go doc's benefit. //go:binary-only-package // Package edwards25519 implements operations on an Edwards curve that is // isomorphic to curve25519. // // Crypto operations are implemented by calling directly into the Rust // library curve25519-dalek, without cgo. // // You should not actually be using this. package edwards25519 import _ \"unsafe\" //go:cgo_import_static scalar_base_mult //go:linkname scalar_base_mult scalar_base_mult var scalar_base_mult uintptr var _scalar_base_mult = &scalar_base_mult // ScalarBaseMult multiplies the scalar in by the curve basepoint, and writes // the compressed Edwards representation of the resulting point to dst. func ScalarBaseMult(dst, in *[32]byte) The Makefile will have to change quite a bit—since we aren't building a binary anymore we don't get to keep using go tool link. A .a archive is just a pack of .o object files in an ancient format with a symbol table. If we could get the symbols from the Rust libed25519_dalek_rustgo.a library into the edwards25519.a archive that go tool compile made, we should be golden. .a archives are managed by the ar UNIX tool, or by its Go internal counterpart, cmd/pack (as in go tool pack). The two formats are ever-so-subtly different, of course. We'll need to use the platform ar for libed25519_dalek_rustgo.a and the Go cmd/pack for edwards25519.a. (For example, the platform ar on my macOS uses the BSD convention of calling files #1/LEN and then embedding the filename of length LEN at the beginning of the file, to exceed the 16 bytes max file length. That was confusing.) To bundle the two libraries I tried doing the simplest (read: hackish) thing: extract libed25519_dalek_rustgo.a into a temporary folder, and then pack the objects back into edwards25519.a. edwards25519/edwards25519.a: edwards25519/rustgo.go edwards25519/rustgo.o target/release/libed25519_dalek_rustgo.a go tool compile -N -l -o $@ -p main -pack edwards25519/rustgo.go go tool pack r $@ edwards25519/rustgo.o # from edwards25519/rustgo.s mkdir -p target/release/libed25519_dalek_rustgo && cd target/release/libed25519_dalek_rustgo && \\ rm -f *.o && ar xv \"$(CURDIR)/target/release/libed25519_dalek_rustgo.a\" go tool pack r $@ target/release/libed25519_dalek_rustgo/*.o .PHONY: install install: edwards25519/edwards25519.a mkdir -p \"$(shell go env GOPATH)/pkg/darwin_amd64/$(IMPORT_PATH)/\" cp edwards25519/edwards25519.a \"$(shell go env GOPATH)/pkg/darwin_amd64/$(IMPORT_PATH)/\" Imagine my surprise when it worked! With the .a in place it's just a matter of making a simple program using the package. package main import (\"bytes\"\"encoding/hex\"\"fmt\"\"testing\"\"github.com/FiloSottile/ed25519-dalek-rustgo/edwards25519\" ) func main() {input, _ := hex.DecodeString(\"39129b3f7bbd7e17a39679b940018a737fc3bf430fcbc827029e67360aab3707\")expected, _ := hex.DecodeString(\"1cc4789ed5ea69f84ad460941ba0491ff532c1af1fa126733d6c7b62f7ebcbcf\")var dst, k [32]bytecopy(k[:], input)edwards25519.ScalarBaseMult(&dst, &k)if !bytes.Equal(dst[:], expected) { fmt.Println(\"rustgo produces a wrong result!\")}fmt.Printf(\"BenchmarkScalarBaseMult\\t%v\", testing.Benchmark(func(b *testing.B) { for i := 0; i! { unsafe { intrinsics::abort() } } #[lang = \"eh_personality\"] extern fn eh_personality() {} extern crate compiler_builtins; // rust-lang/rust#43264 extern crate rlibc; And with that, go build works (!!!) on macOS. Linux On Linux nothing works. External linking complains about fmax and other symbols missing, and it seems to be right. $ ld -r -o linux.o target/release/libed25519_dalek_rustgo/*.o $ nm -u linux.o U _GLOBAL_OFFSET_TABLE_ U abort U fmax U fmaxf U fmaxl U logb U logbf U logbl U scalbn U scalbnf U scalbnl A friend thankfully suggested making sure that I was using --gc-sections to strip dead code, which might reference things I don't actually need. And sure enough, this worked. (That's three layers of flag-passing right there.) $ go build -ldflags '-extld clang -linkmode external -extldflags -Wl,--gc-sections' But umh, in the Makefile we aren't using a linker at all, so where do we put --gc-sections? The answer is to stop hacking .as together and actually reading the linker man page. We can build a .o containing a given symbol and all the symbols it references with ld -r --gc-sections -u $SYMBOL. -r makes the object reusable for a later link, and -u marks a symbol as needed, or everything would end up garbage collected. $SYMBOL is scalar_base_mult in our case. Why wasn't this a problem on macOS? It would have been if we linked manually, but the macOS compiler apparently does dead symbol stripping by default. $ ld -e _scalar_base_mult target/release/libed25519_dalek_rustgo/*.o Undefined symbols for architecture x86_64: \"___assert_rtn\", referenced from: _compilerrt_abort_impl in int_util.o \"_copysign\", referenced from: ___divdc3 in divdc3.o ___muldc3 in muldc3.o \"_copysignf\", referenced from: ___divsc3 in divsc3.o ___mulsc3 in mulsc3.o \"_copysignl\", referenced from: ___divxc3 in divxc3.o ___mulxc3 in mulxc3.o \"_fmax\", referenced from: ___divdc3 in divdc3.o \"_fmaxf\", referenced from: ___divsc3 in divsc3.o \"_fmaxl\", referenced from: ___divxc3 in divxc3.o \"_logb\", referenced from: ___divdc3 in divdc3.o \"_logbf\", referenced from: ___divsc3 in divsc3.o \"_logbl\", referenced from: ___divxc3 in divxc3.o \"_scalbn\", referenced from: ___divdc3 in divdc3.o \"_scalbnf\", referenced from: ___divsc3 in divsc3.o \"_scalbnl\", referenced from: ___divxc3 in divxc3.o ld: symbol(s) not found for inferred architecture x86_64 $ ld -e _scalar_base_mult -dead_strip target/release/libed25519_dalek_rustgo/*.o This is also the part where we learn painfully that the macOS platform prepends a _ to all symbol names, because reasons. So here's the Makefile portion that will work with external linking out of the box. edwards25519/edwards25519.a: edwards25519/rustgo.go edwards25519/rustgo.o edwards25519/libed25519_dalek_rustgo.o go tool compile -N -l -o $@ -p main -pack edwards25519/rustgo.go go tool pack r $@ edwards25519/rustgo.o edwards25519/libed25519_dalek_rustgo.o edwards25519/libed25519_dalek_rustgo.o: target/$(TARGET)/release/libed25519_dalek_rustgo.a ifeq ($(shell go env GOOS),darwin) $(LD) -r -o $@ -arch x86_64 -u \"_$(SYMBOL)\" $^ else $(LD) -r -o $@ --gc-sections -u \"$(SYMBOL)\" $^ endif The last missing piece is internal linking on Linux. In short, it was not linking the Rust code, even if the compilation seemed to succeed. The relocations were not happening and the CALL instructions in our Rust function left pointing at meaningless addresses. At that point I felt like it had to be a silent linker bug, the final boss in implementing rustgo, and reached out to people much smarter than me. One of them was guiding me in debugging cmd/link (which was fascinating!) when Ian Lance Taylor, the author of cgo, helpfully pointed out that //cgo:cgo_import_static is not enough for internal linking, and that I also wanted //cgo:cgo_import_dynamic. //go:cgo_import_static scalar_base_mult //go:cgo_import_dynamic scalar_base_mult I still have no idea why leaving it out would result in that issue, but adding it finally made our rustgo package compile both with external and internal linking, on Linux and macOS, out of the box. Redistributable Now that we can build a .a, we can take the suggestion in the //go:binary-only-package spec, and build a tarball with .as for linux_amd64/darwin_amd64 and the package source, to untar into a GOPATH to install. $ tar tf ed25519-dalek-rustgo_go1.8.3.tar.gz src/github.com/FiloSottile/ed25519-dalek-rustgo/ src/github.com/FiloSottile/ed25519-dalek-rustgo/.gitignore src/github.com/FiloSottile/ed25519-dalek-rustgo/Cargo.lock src/github.com/FiloSottile/ed25519-dalek-rustgo/Cargo.toml src/github.com/FiloSottile/ed25519-dalek-rustgo/edwards25519/ src/github.com/FiloSottile/ed25519-dalek-rustgo/main.go src/github.com/FiloSottile/ed25519-dalek-rustgo/Makefile src/github.com/FiloSottile/ed25519-dalek-rustgo/release.sh src/github.com/FiloSottile/ed25519-dalek-rustgo/src/ src/github.com/FiloSottile/ed25519-dalek-rustgo/target.go src/github.com/FiloSottile/ed25519-dalek-rustgo/src/lib.rs src/github.com/FiloSottile/ed25519-dalek-rustgo/edwards25519/rustgo.go src/github.com/FiloSottile/ed25519-dalek-rustgo/edwards25519/rustgo.s pkg/linux_amd64/github.com/FiloSottile/ed25519-dalek-rustgo/edwards25519.a pkg/darwin_amd64/github.com/FiloSottile/ed25519-dalek-rustgo/edwards25519.a Once installed like that, the package will be usable just like a native one, cross-compilation included (as long as we packaged a .a for the target)! The only thing we have to worry about is that if we build Rust with -Ctarget-cpu=native it might not run on older CPUs. Thankfully benchmarks (and the curve25519-dalek authors) tell us that the only real difference is between post and pre-Haswell processors, so we only have to make a universal build and a Haswell one. $ benchstat bench-none.txt bench-haswell.txt name old time/op new time/op delta ScalarBaseMult/rustgo 22.0µs ± 3% 20.2µs ± 2% -8.41% (p=0.001 n=7+6) $ benchstat bench-haswell.txt bench-native.txt name old time/op new time/op delta ScalarBaseMult/rustgo 20.2µs ± 2% 20.1µs ± 2% ~ (p=0.945 n=6+7) As the cherry on top, I made the Makefile obey GOOS/GOARCH, converting them as needed into Rust target triples, so if you have Rust set up for cross-compilation you can even cross-compile the .a itself. Here's the result: github.com/FiloSottile/ed25519-dalek-rustgo/edwards25519. It's even on godoc. Turning it into a real thing Well, this was fun. But to be clear, rustgo is not a real thing that you should use in production. For example, I suspect I should be saving g before the jump, the stack size is completely arbitrary, and shrinking the trampoline frame like that will probably confuse the hell out of debuggers. Also, a panic in Rust might get weird. To make it a real thing I'd start by calling morestack manually from a NOSPLIT assembly function to ensure we have enough goroutine stack space (instead of rolling back rsp) with a size obtained maybe from static analysis of the Rust function (instead of, well, made up). It could all be analyzed, generated and built by some \"rustgo\" tool, instead of hardcoded in Makefiles and assembly files. cgo itself is little more than a code-generation tool after all. It might make sense as a go:generate thing, but I know someone who wants to make it a cargo command. (Finally some Rust-vs-Go fighting!) Also, a Rust-side collection of FFI types like, say, GoSlice would be nice. #[repr(C)] struct GoSlice { array: *mut u8, len: i32, cap: i32, } Or maybe a Go or Rust adult will come and tell us to stop before we get hurt. In the meantime, you might want to follow me on Twitter. 2024 note: Twitter is also not usable anymore. Instead, you can follow me on Bluesky at @filippo.abyssdomain.expert or on Mastodon at @filippo@abyssdomain.expert. EDIT: It was pointed out to me that if we simply named the Rust object file libed25519_dalek_rustgo.syso, we could skip all the go tool invocations and simply use go build which automatically links .syso files found in the package. But what's the fun in that. Thanks (in no particular order) to David, Ian, Henry, Isis, Manish, Zaki, Anna, George, Kaylyn, Bill, David, Jess, Tony and Daniel for making this possible. Don't blame them for the mistakes and horrors, those are mine. P.S. Before anyone tries to compare this to cgo (which has many more safety features) or pure Go, it's not meant to replace either. It's meant to replace manually written assembly with something much safer and more readable, with comparable performance. Or better yet, it was meant to be a fun experiment.",
    "commentLink": "https://news.ycombinator.com/item?id=41116639",
    "commentBody": "Rustgo: Calling Rust from Go with near-zero overhead (2017) (filippo.io)173 points by telotortium 13 hours agohidepastfavorite68 comments nickcw 10 hours agoThat was a great read. All that linker wrangling is sure to break on the next version of go/rust/linker isn't it? I wonder if it would have been easier to disassemble the rust binary and turn it into Go assembly and use that. That would need a fairly complicated program to process the binary back into assembler. Maybe getting the rust compiler to output assembly and processing into Go assembly would be the way. Using Go assembly would save fighting with the linker, be more likely to survive upgrades and it would be cross platform (well at least on platforms with the same CPU arch). reply FiloSottile 7 hours agoparentThat exist(ed)! c2goasm would compile C and then decompile it into Go asm. https://github.com/minio/c2goasm reply neonsunset 9 hours agoparentprevnext [25 more] Imagine picking a language with terrible FFI overhead and weak compiler only to fight these two worsts aspects of it in an attempt to fix them. C# with zero-cost FFI, none of the performance penalty and ability to statically link everything together is a strictly better choice. Saner type system and syntax too. reply kgeist 9 hours agorootparentC#'s FFI is kind of zero-cost with blittable types (int, float). You still need to do marshalling for anything more complex (strings was a common issue on Linux, UTF8UTF16), also memory pinning. Last time I checked, it also notifies the GC the thread entered native code (can't be preempted, the stack needs to be scanned conservatively etc.) After exiting a native function IIRC there's a safepoint check. I remember years ago it was common knowledge that P/Invoke is not suitable for calling hot functions in a loop, you had to create native helper functions which make all the calls in one go. Maybe it has changed? reply neonsunset 9 hours agorootparentMemory pinning is practically free and GC does quite a bit of work to further minimize its impact on throughput, common practice is to use stack buffers or natively allocated memory for marhsalled or other data anyway (remember - free FFI, so you can always do malloc and free which marshallers do). In practice UTF-16UTF-8 conversion rarely shows up on flamegraph as it turns out built-in transcoding is very fast and does not leave dangling data that GC needs to clean up. It is also not as frequently needed - you can just get a byte* for free out of \"hello, world\"u8 and pass it without any extra operations (the binding generator will do that for you). On top of that, complex blittable structures are first and foremost expressible in C# - you can easily have C binary tree, or an array of arrays with byte**. Performance-sensitive code that does interop heavily exploits that to give actual C-like experience. Also short-lived FFI calls do not need to notify GC (which is also cheap it toggles a boolean), libraries that care about extra last nanosecond annotate them with `[SuppressGCTransition]` which further streamlines assembly around FFI call. For performing FFI in a loop - the cost comes from the same reason a non-inlineable cross-compilation-unit calls are expensive within C++. Because we're talking plain call level of overhead, which is by definition as cheap as FFI gets. Of course that can still be a bottleneck if you have a small function beyond FFI boundary within a hot loop. In that case you might as well port it to C# to make it inlineable which is going to be faster, or have an FFI call for a batched operation. Try `dotnet publish -o . -p:StripSymbols=false`ing this: https://github.com/U8String/U8String/tree/main/Examples/Inte... and then disassembling it with Ghidra. You will be positively impressed with how codegen looks - there will be simple direct calls into Rust with single bool checks for a potential GC poll after them (and compiler will merge those too after multiple consecutive calls). reply aatd86 8 hours agorootparentSo it's actually about the same situation in Go from what I can understand. reply kgeist 8 hours agorootparentThe only significant conceptual difference between Go's and C#'s FFI mechanisms when it comes to call overhead that I can think of is the fact that Go has to switch the current stack to a special C stack. In C#, it runs on the same stack. reply neonsunset 8 hours agorootparentprevNo, Go FFI is so slow it makes Python look fast which has great FFI performance, just being an interpreted language hurts. It needs to perform stack switching and worker thread pinning, and for some reason even that is slow. I don't know why. Note on tinygo as I've been put in the jail heh: Realistically no one runs TinyGo in production as in back-end workloads or larger user-facing applications. And when you do run it, at most you match pre-existing FFI performance of .NET which ranges at 0.5-2ns at throughput (which I assume how you are testing it) depending on flags and codegen around specific arguments. Up to 50 times difference with a standard Go, that is a lot, isn't it? All custom runtime flavours in Go usually come with significant performance issues or other tradeoffs. Something I never need to deal with when I solve the same problems with .NET, maybe occasionally addressing compatibility with AOT for libraries that have not been updated if it's a desired deployment mode. reply randomdata 8 hours agorootparent> No, Go FFI is so slow it makes Python look fast Which Python and which Go? There are so many different implementations and different versions of those implementations that this broad statement is meaningless. From what I have installed on my machine, CPython 3.11.6 seems to take around 80ns to call a C function, gc 1.22.0 takes around 50ns to call the same C function, and tinygo 0.32.0 only takes around 1ns! Such benchmarking is always fraught with problems, so your milage may vary, but on my machine under this particular test Go wins in both cases, and tinygo is doing so at about the same speed as C itself. reply darby_nine 3 hours agorootparent> CPython 3.11.6 seems to take around 80ns to call a C function, gc 1.22.0 takes around 50ns to call the same C function How does this make any sense? C shares a runtime with CPython. What is it doing where it manages to be slower than go? reply gen2brain 7 hours agorootparentprevMaybe it just looks slow to you, for example, check the raylib bindings benchmarks, Go is usually at the top, together with Rust, C#, etc. and Python is at the very bottom. Perhaps not the best way to benchmark FFI but it shows that Python is not even usable besides playing. reply jerf 6 hours agorootparentprevIn Go, once you've FFI'd, you're likely to be able to use the Go data directly in C. In Python, you generally have to crawl over the Python-based data at Python speeds, converting it into data that your C library can understand, and then when C is done, convert it back into a Python data type at, again, effectively Python speeds. Unless you're willing for it to just be opaque data that Python effectively can route, but not manipulate. (This works, but is distinctly less useful. Of course sometimes, like for image data, it's the best option.) Combined with the sibling comment that actually times calls and finds Go is faster anyhow, even if it is a microbenchmark, I don't think your argument carries water. It sounds to me like you've latched on to some propaganda that you like and are happy to share but don't have any personal experience with. Go's FFI is relatively slow for a compiled language, but it isn't even remotely uniquely slow. Many languages have a C FFI with some sort of relatively expensive C conversion operation, and as I point out here, that actually includes Python in many, if not most, uses (it's pretty rare to want to write code to bind to C that just ships over two integers and returns another integer or something, usually we're doing something interesting). It is the languages like Rust or Zig that can do it for effectively free that are the exception, not the rule. Go's FFI costs are not all that expensive compared to programming languages in general, and if you're worried about the FFI performance, Go also generally needs FFI less in the first place than Python because it's a fast language (not the fastest by any means, but fast), and the higher proportion of Go code will generally smoke Python anyhow. Unless you foolishly write a very tight loop of C FFI code in Go, which is a bad idea in most langauges anyhow (again excepting the exceptions like Rust and Zig), Go's going to outpace a Python program that is mostly Python but uses a bit of FFI here and there by a lot anyhow. The idea that Go is brought to its knees by a single C call that takes 100ms or something reminds me of the people who think that as soon as you use a garbage collected language you've signed up for a guaranteed 250ms stop-the-world pause every three seconds or something. Is it free? No. Is it expensive? In relative terms maybe. In absolute terms, not really. Most programs, most of the time you won't notice, and if you are in a situation where Python is even a performance option virtually by definition you're in a situation where it won't be a problem for Go. This is not rah-rah for Go or slagging on Python. This is just stuff engineers need to know. Python is a very capable language, but you definitely pay for it. It is not free. Every greenfield project, you need to sit down and calculate the costs and pick a good tool, but you're going to make dumb, project-killing decisions if you're using costs that are multiple orders of magnitude off of reality. I've seen it kill projects, it's not just theory. reply darby_nine 3 hours agorootparent> but it isn't even remotely uniquely slow. Most languages share a runtime and stack model with C. Go is \"unique\" among popular languages in that it decided to do its own thing, which results in much slower FFI calls. Like sure, so did GHC, but most people don't expect GHC to behave like C. TBH it's enough to put me off of the language outside of writing servers. There's just too much to draw from in terms of libc-based libraries and the drawbacks in Go are too severe to make its interesting concurrency ideas generally worth it. EDIT: Not to mention if you have WASI as a target go is a terrible choice for the exact same reasons—it has its unique memory and stack model that don't work well with web assembly. reply jerf 1 hour agorootparentAgain, people throw around \"much slower\" and it comes off like it's 100ms or something. It's not that much slower, it's not even close. It's only an issue if you're planning on making tens or hundreds of thousands of FFI calls per second, routinely. That describes a non-zero set of software people may want to write. If you are writing one of them, you need to know that. But it doesn't describe anything like a majority of software cases in general. It is one of the things you need to know, but you need to have a correct view of the costs to make correct decisions, or, at least, not one that's off by orders of magnitude and leads to people running around claiming Go is \"uniquely slow\" at FFI and bragging about how much faster Python is when it turns out \"uniquely slow\" Go is actually faster than Python. Costs aren't a matter of feelings or what reinforces your decisions about what language to use or how much you hate that Go doesn't have sum types. Costs are what they are. My personal favorite, and bear with me because this is going to be generally a negative for Go, is the number of databases that for some reason are getting written in Go. My rule of thumb is that Go is 2-3x slower than C/C++ (and, increasingly in that set, Rust). On the grand landscape of programming languages, this puts it distinctly towards the faster end in a general sense; there are very popular languages clocking in at \"generally 40x-50x slower and also can't use more than one CPU at a time\". But if you're writing a database, you're going into a market where it's virtually guaranteed that's going to be a problem. Maybe don't do that. But then deciding that you aren't going to use Go to write your command-line app to hit an HTTP API because it's not the fastest language for databases is not a correct engineering conclusion to draw. reply neonsunset 4 hours agorootparentprevThank you for responding. Indeed, it's not quite as bad as Python in overall performance. But I'm happy it brought attention to the fact that Go is still pretty inadequate at this. My main point is engineers keep trying to shoehorn it in domains, where, should they not want to use Rust or Zig as you mentioned (which are great), they should have chosen C# (which is also great for FFI, look at Stride3D, Ryujinx or even its Sqlite driver speed, all of which are FFI heavy), but instead they keep attempting to use Go where they have to work hard to counteract its inadequacy, instead of using a platform where their solution would perform great not despite the tool but because of it. reply randomdata 3 hours agorootparentThe biggest problem with FFI in Go (gc, at least) isn't in the FFI operation itself, rather FFI functions that block for a long time mess with the scheduler. It seems C# suffers the same problem as real-world benchmarks often show it to be slower than Go when performing FFI, even if it should be theoretically faster. As usual, performance can be hard to predict. Benchmarking the actual code you intend to use is the only way to ensure that what you think is true actually is. If you aren't measuring, you aren't engineering. reply neonsunset 3 hours agorootparentDo you have any example of code that can demonstrate how it is possible to meaningfully slow down .NET and its threadpool and GC when performing FFI where Go does not suffer to a significantly greater extent? (if you fashion a Go example - that'll be enough and I'll make a C# one) .NET's threadpool is specifically made with the consideration of worker threads being potentially blocked in mind, and has two mechanisms to counteract it - hill-climbing algorithm that grows and shrinks the active number of threads to minimize task wait time in queues, and another mechanism to actively detect blocked threads (like system sleep or blocked by synchronous network read) and inject additional workers without waiting for hill-climbing to kick in. It is a very resilient design. Go's and Tokio threadpool are comparatively lower effort - both are work-stealing designs but neither has the active scaling mechanism .NET has already had since .NET Framework days. GC implementation at the same time is pinning-aware and can shuffle around memory in such a way to allow other objects to participate in collection or promotion to older generations while keeping the pinned memory where it is. There have been years of work towards improving this, and there is also an additional pinned memory heap for long-lived pinned allocations on the rare occasion where just performing malloc is not appropriate. I doubt there is any other high-level language or platform that can compete on FFI with .NET, something that has been considered as a part of its design since the very first version. If you want better experience your main upgrade options are literally C, C++, Zig, Rust, and honorable mention Swift (it is mostly a side-grade, with the heavy lifting done by LLVM). reply randomdata 3 hours agorootparent> Do you have any example of code No better than your own code. Why not put it to the test? In the end you will either know that you made the right choice, or have the better solution ready to swap in. You can't lose. The key takeaway from the previous comment isn't some pointless C# vs Go comparison, it is that performance can be hard to predict. Someone else's code isn't yours. It won't tell you anything about yours. Measure and find out! reply neonsunset 3 hours agorootparentYou did mention there exists an FFI scenario where Go supposedly performs better. It would be interesting to look at it, given the claim. reply randomdata 2 hours agorootparentWhat, exactly, is interesting about arbitrary benchmarks? It might just be the C# code is slower because the developer accidentally introduced different, less performant, logic. It doesn't tell you anything. Only your own code can tell you something. I am not sure how to state this more clearly. What would actually be interesting is to see you gain those important nanoseconds of performance that is so critical to your business. We want to see you succeed (even if you don't seem the want the same for yourself?). reply Capricorn2481 2 hours agorootparent> It might just be the C# code is slower because the developer accidentally introduced different, less performant, logic That is why the user is asking for specific code. So they can audit whether this is a case when someone claims Go FFI is fine. As an outsider, all I see are two people saying \"no it's not slow,\" just about different languages. But until I have a production app in either I'll never know. reply randomdata 1 hour agorootparent> So they can audit whether this is a case when someone claims Go FFI is fine. Of course nobody would claim such a thing. The cost is real. Whether or not Go is fine will depend entirely on what kind of problem environment you are dealing with and what your own code actually looks like. Someone else's code will never tell you this. There is no shortcut here other than to measure your own code. > As an outsider, all I see are two people saying \"no it's not slow,\" just about different languages. It is slow, relatively speaking. But does that matter in your particular situation? Random internet benchmarks show that Python is always slower, way slower, yet people find all kinds of productive uses for Python – even in domains where computational performance is very important! And if it does matter for what you're doing, are you sure you actually picked the fastest option? Measure and find out. It is good to have rough estimates, but all of these languages are operating within the same approximate timescale here. It's not like Go, C#, or any other language is taking minutes to perform FFI. When you really do need to shave those nanoseconds off, guessing isn't going to get you there. Measure! reply Capricorn2481 58 minutes agorootparentI'm in agreement, but it's even simpler than you're making it. If Go is slow in a certain context, I would want to know what that context is. If there's a certain task that takes a few more ms in goroutines due to some implementation detail, I would know not to use Go if that task needed to be 100,000 times. Perhaps I need to rethink the task itself, or maybe that's not possible for an organizational reason. It wouldn't be a \"random internet benchmark\" unless I didn't understand the context. What's random is saying this >It seems C# suffers the same problem as real-world benchmarks often show it to be slower than Go when performing FFI, even if it should be theoretically faster How is this better than asking for code examples? randomdata 21 minutes agorootparent> If Go is slow in a certain context, I would want to know what that context is. You'll know as soon as you measure it. Not exactly rocket science, just plain old engineering. Measuring is what engineers do. You wouldn't build a bridge without first measuring the properties of the materials, and you wouldn't build a program without measuring the properties of its 'materials'. You make a good point that it is strange we don't get better datasheets from 'material manufacturers' about the base measurements. That wouldn't fly in any other engineering discipline, but I guess that's the nature of software still being young. As unfortunate as that may be, you can't fight the state of affairs, you're just going to have to roll up your sleeves. Such is life. > How is this better than asking for code examples? Cunningham's law explains why it is better. superb_dev 1 hour agorootparentprevCould it be that Go has other benefits that outweigh ffi being a little slower? reply aatd86 8 hours agorootparentprevAre there some recent measurements? All I could find is somewhat old and I think there has been some work done since. reply fingerlocks 9 hours agorootparentprevThis is _hacker_ news, doing the thing it wasn’t designed to do is the point. The harder the challenge, the better. Yes there are tons of better choices for rust interop. Any LLVM language will work. That’s not interesting. reply hardwaregeek 1 hour agoprevlol I remember looking at this when doing our major port from Go to Rust. I noped out once I saw the raw assembly portion. Great for a side project but probably not the move for a cross platform binary run by thousands of people. Still a very cool post and the literature for Go/Rust interop is def lacking reply yutijke 10 hours agoprevhttps://github.com/petermattis/fastcgo, which is now 7 years old seems to do something similar without the need to about obscure CGO FFI configuration. It also seems to be more generally applicable for any language with C interop. There had been an issue for having something similar in the language itself - https://github.com/golang/go/issues/42469, but the Golang compiler team rejected it. If you have followed similar discussions around this with the Golang compiler team, you will notice a pattern of interaction that strongly indicates that they are very much opposed to ever accepting this into the compiler. reply dontlaugh 9 hours agoparentfastcgo links to rustgo reply zxilly 12 hours agoprevThere are many years since the article being written. I'm wondering if there is a better solution in 2024. reply mappu 11 hours agoparentCgo overhead was made 5-30x faster in go1.21, and it was already within noise levels in this article, so i'd use that. reply chabad360 4 hours agorootparentCan you provide a reference for that? A quick search for me didn't bring up anything. I'm curious to read more. reply lossolo 4 hours agorootparenthttps://shane.ai/posts/cgo-performance-in-go1.21/ reply mananaysiempre 3 hours agorootparent> Cgo calls take about 40ns, about the same time encoding/json takes to parse a single digit integer. As an aside, that sure feels like a lot of time to parse a single-digit integer. Not catastrophic by any means, but still, 100 to 200 cycles is a sign the program is definitely Doing Something. Perhaps that’s the memory allocator? reply benmmurphy 9 hours agoparentprevthey changed the ABI in 1.17 to pass arguments in registers instead of the stack: https://go.dev/doc/go1.17#compiler so if you used this solution you might not need to do the fixup anymore if the ABI matches. reply ozgrakkurt 11 hours agoparentprevDoesn’t seem like there is. Probably because go developers want code to be pure go if possible reply gnabgib 12 hours agoprev(2017) Discussions: 2017 (282 points, 68 comments) https://news.ycombinator.com/item?id=15017519 2019 (107 points, 37 comments) https://news.ycombinator.com/item?id=20600178 reply odanalysis 10 hours agoprevDoes this mean you could now use gokrazy to run rust apps on an sbc with better startup speeds than linux?? reply sureglymop 8 hours agoparentIf you're calling rust from go, wouldn't you still have the go startup time before you could call the rust code? reply roundup 9 hours agoprevAlso, https://blog.yuchanns.xyz/post/83397808-6849-4bc5-8a09-18765... reply ethegwo 8 hours agoprevit makes me think about https://news.ycombinator.com/item?id=41117749 it is the mirror of this project: effient wal to call Go from Rust reply sitkack 11 hours agoprevThis is totally sick! I can't wait to go through these repro steps using new versions. reply Havoc 11 hours agoprev [–] What is the benefit of this? I was under the impression that go isn't that far off from rust on most speed metrics being both compiled. So this adds complexity for what gain? reply Yoric 11 hours agoparentIn benchmarks I've seen, Go is ~6 times slower. But generally speaking, the reason I prefer Rust to Go for most developments is its type system. I could see myself using Rust to handle business-specific/safety-critical logic and Go as a fast prototyping language to assemble them. reply dewey 8 hours agorootparentWhat part of the Go typing system is lacking for \"business-specific/safety-critical logic\"? reply Yoric 1 hour agorootparentI wasn't planning to turn this into a language flame war, so I'm not going to give details. Let's just say that the designers of Rust and Go have prioritized very different feature sets when designing their type systems. If you develop in Rust, it's typically because you want to write \"fearless code\", i.e. attach sophisticated invariants to types to avoid safety issues later in development/coming from client code. If you develop in Go, it's typically because you want \"productivity\", i.e. reach quickly a point where you code can run and you can start testing it. As usual, it's a tradeoff. For most tasks, I happen to click better with the former. YMMV reply kbolino 6 hours agorootparentprevGo doesn't have any closed or sealed types. An \"enum\" is just a subtype and subtypes can't restrict the range of their values. It's possible to have something like a closed tagged union using an interface with an unexported method and type-switching, but the language won't understand this for e.g. detecting whether a switch without default is exhaustive. There's also no way to declare a non-nil pointer nor to work cleanly with nested nil-able struct fields. reply randomdata 7 hours agorootparentprevIt lacks expressiveness, which means you actually have to put some thought into your design to avoid butting heads with it. You can't throw up garbage and then keep massaging the types until you can make whatever gobbledygook you came up with fit. Business/safety critical logic tends to get complicated, and, at least in the case of business software, is more than likely is venturing into unexplored territory, so when you're not very skilled at programming finding the right design can become an insurmountable challenge. A more expressive type system offers a bandaid to work around that. reply smodo 7 hours agorootparentA bit of cart-horse-y reasoning…. An expressive type system helps me to model the nuances that are actually present in the business logic. If I simplify or restructure my model more than real life allows for I would say that causes much more trouble than actually modeling what’s happening on the ground. Yes, when I’m behind my desk I always find ways to make the business logic better and simpler and more fitting. But those damn humans never follow my rules. reply mr90210 7 hours agorootparentprevnext [2 more] [flagged] randomdata 7 hours agorootparentStrictly speaking, that is true. Even the worst code ever written had some thought put into it. But the \"actually put some thought\" was meant to imply more than putting down the first characters that spew out; to consider the design more holistically and carefully. But you are right to not take anything that software says seriously. Seriousness is for interactions with humans. reply gkbrk 10 hours agoparentprev> go isn't that far off from rust on most speed metrics being both compiled The only way I see this happening for the same code snippet is if the Rust code was being compiled in debug mode instead of release mode. reply Kinrany 3 hours agoparentprevLibraries can be written once and then used in both languages. reply aranw 10 hours agoparentprevThe benefit isn't necessarily for speed there are some libraries for example available in Rust that are not in Go. This is something I am exploring at the moment rather than having to totally rewrite the library in Go reply null_investor 11 hours agoparentprev [–] That's widely incorrect, Rust and C are like 2-5x faster than Go? Go has arguably a better concurrency model, so for some usecases it can work much better, but for some realtime programming stuff, Go is a no-go ba-dum-tss. For webdev I would never chose Rust over Go, each language has their own advantage. reply lionkor 11 hours agorootparentGo's concurrency model lets you just access the same mutable variable from multiple goroutines - that kind of \"good model\" you can also get with C and some implementation of channels and green threads. reply null_investor 10 hours agorootparentYes, but having coded in both languages you can see how Go's concurrency system works well with it and fits neatly. Try using async in Rust and you'll see what I mean, it sucks to use it. The same applies to cpp, you'll need years and years of experience to write somewhat decent cpp what you can write in Go with a few weeks learning coroutines, and will still be prone to make mistakes. I've done lots of cpp and can affirm that after decades I'm still not sure if my concurrent solution will run as well as my half-assed Go coroutine code. Go coroutines is a good abstraction that is very fitting to the language, similar to the actor model and the BEAM VM (erlang/elixir). Use the same abstraction in another language (like JVM or C) and you'll see how the devex makes a huge difference. reply littlestymaar 9 hours agorootparentI'd chose async/await over threads any day, and many people do too, that's why this construct has gained so much popularity in many different languages. Async/await is a rare example in PL design where a new concept is implemented in one language and then adopted by many in the following years. In fact, the “threads are more ergonomic than async/await” seems to be more of an HN meme than a popular opinion in the wild. (And please don't quote What color is your function since it's mostly a rant about callback-based concurrency which everyone agree it sucks). reply cube2222 9 hours agorootparent> since it's mostly a rant about callback-based concurrency which everyone agree it sucks It really isn’t, it’s a rant about there being two worlds (colors) of functions - async and not async, which don’t compose that well together. I believe Rust is exploring the ability to genericize functions over their asyncness, and I wish them luck in that endeavor. Async/await is, if anything, a tradeoff for performance and ffi over usability. As they are generally stackless and in the case of rust don’t need allocations. With green threads like in Go you’ll generally have to allocate at least a small stack for each goroutine, and you’ll have to fix up things for ffi, but it’s much more straightforward, all functions have the same color (you just write “blocking” code, but the underlying implementation is async), you don’t have an ecosystem split, and you don’t have to war with the type system every other day (as many feel like they’re doing in Rust when writing async). It’s a pretty good point in case that Java just spent a few years making project loom happen, which effectively brings the Go approach to Java. Async/await has its place, especially in very performance-critical code, but its usability is, IMO, miles behind threads. Of course, an ideal world would be green threads with rusts compile-time checking of concurrency safety… reply dgroshev 4 hours agorootparentI'm not sure what you mean by \"don't compose well\". You can call sync code from an async function perfectly well. Going the other way around is either very simple in a throwaway code (just use pollster or tokio's block_on), or requires appropriate care (because async means IO and calling a function doing IO means your function now does IO too). I believe what most people are struggling with is having to think about doing IO instead of just doing IO wherever. But that's a feature, not a bug, and an overarching theme in Rust: you need to think what you're doing and how everything will work together. Yes you can't just put an async call somewhere down the stack without changing the signatures, but that's a good thing. reply cube2222 2 hours agorootparentRust doesn’t model IO in terms of types though, does it? Sure, an async function likely does IO, but maybe it’s just receiving from a channel? At the same time 90% (completely made up number) of Rust just does plain blocking IO and you absolutely won’t get that in the signature either (other than looking into error types, that is). We’re not in Haskell here. You can just make a blocking call in your async code, not notice it does IO (or you’re just not proficient in async), and it falls to pieces, your runtime just hung. While “you can just use pollster” means you now have to wrap every function call to an async-first library in your async-less codebase. Again, this isn’t “composing well” in my book, it absolutely does create a divide in the ecosystem. While in Go all code is written in a blocking fashion, but all IO is done async (either via threadpool or non-blocking syscalls), handled by the runtime, because the threads are green. Of course, that’s less performant and falls apart if you start using C libraries that do blocking IO (but it’s not like Rust would do better in that latter case). At the same time, whether modeling IO in the type system is good or not, is I think something where opinions very much differ. To be clear, again, I’m not bashing Rust async in general, I just think it’s a tradeoff and I very much think its usability is worse than just writing straightforward blocking code. reply dgroshev 1 hour agorootparentI disagree with your \"just\" in \"just receiving from a channel\". Receiving from a channel is hardly distinguishable from IO, since it can take an arbitrary amount of time and the receiver needs to handle external resource failures (ie the other side of the channel getting dropped). That's very different from normal sync functions parsing JSON, adding matrices, or doing date math. Also note how functions that can't block are still sync, like tokio::sync::oneshot::Sender::send. I also can't agree with the argument that if it's possible to hang the runtime there's no point in explicit async. Yes people can still make mistakes, but it's better when it's explicitly a mistake and not just haphazard IO everywhere being the norm. What is the \"async-less\" codebase for? Why does it have to be \"async-less\"? A Go codebase is fully async at all times, so why shouldn't a Rust system extend async up to main() (or at least encapsulate IO-heavy parts in a separate async part)? Runtime behaviour of async rust is ~equivalent to Go, so coming back to my original point, the difference is that 1) Rust allows to have non-async, predictable functions, async is opt-in 2) the opt-in must be explicit 3) you have more choice between intra- and inter-future concurrency (select! vs spawn). All those points are important and empowering, they aren't problems to be solved. I agree that the flip side is that Rust forces explicit decisions upfront, but that's one of the core premises of Rust. reply LtdJorge 4 hours agorootparentprevI think you mean block_on. Spawn blocking would be for your first use case, calling sync from async. reply dgroshev 4 hours agorootparentYes, thank you, my bad. Fixed. reply thadt 5 hours agorootparentprevNot \"threads are more ergonomic than async/await\", but \"threads and channels can be ergonomic\". I've been a big fan and user of async/await in various languages for over a decade now, and it can absolutely improve reading sequential asynchronous logic flow, but lets not pretend it isn't without tradeoffs. Compared to wrangling synchronization contexts and function colors, channels can be rather straightforward. reply brightball 10 hours agorootparentprevIt still offers good structures to help you be careful in these situations, but you’re right. It’s not as complete of a concurrency model as BEAM languages. reply masklinn 10 hours agorootparentprev [–] > Go has arguably a better concurrency model Go might have a better concurrency implementation, Go’s concurrency model is pretty much just threads and telling you to git gud scrub. reply null_investor 10 hours agorootparent [–] That's true, it's more precise to say that it's an implementation. I'm happy you understood what I meant though. The developer experience on using it is much better than using coroutines in another lang. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The post explores calling Rust from Go to replace assembly code, aiming for near-zero overhead without requiring deep Rust or compiler knowledge.",
      "Rust is chosen for its high optimizability and readability compared to assembly, and the approach shows better performance than using cgo for small, hot functions.",
      "Benchmarking indicates that calling Rust from Go is nearly as fast as a native Go function call and significantly faster than cgo, making it suitable for performance-critical tasks."
    ],
    "commentSummary": [
      "Rustgo is a tool that allows calling Rust code from Go with near-zero overhead, which is significant for performance-sensitive applications.",
      "The discussion highlights the complexities and potential pitfalls of using Foreign Function Interface (FFI) between different programming languages, particularly Go and Rust.",
      "Comparisons are made with other languages like C# and Python, emphasizing the trade-offs in FFI performance and the importance of choosing the right tool for the job."
    ],
    "points": 173,
    "commentCount": 68,
    "retryCount": 0,
    "time": 1722404613
  },
  {
    "id": 41120254,
    "title": "I prefer rST to Markdown",
    "originLink": "https://buttondown.email/hillelwayne/archive/why-i-prefer-rst-to-markdown/",
    "originBody": "July 31, 2024 Why I prefer rST to markdown I will never stop dying on this hill I just published a new version of Logic for Programmers! v0.2 has epub support, content on constraint solving and formal specification, and more! Get it here. This is my second book written with Sphinx, after the new Learn TLA+. Sphinx uses a peculiar markup called reStructured Text (rST), which has a steeper learning curve than markdown. I only switched to it after writing a couple of books in markdown and deciding I needed something better. So I want to talk about why rst was that something.1 Why rst is better The most important difference between rst and markdown is that markdown is a lightweight representation of html, while rst is a midweight representation of an abstract documentation tree. It's easiest to see this with a comparison. Here's how to make an image in markdown: ![alttext](example.jpg) Technically, you don't even need a parser for this. You just need a regex to transform it into . Most modern markdown engines do parse this into an intermediate representation, but the essence of markdown is that it's a lightweight html notation. Now here's how to make an image in rst: .. image:: example.jpg :alt: alttext .. image:: defines the image \"directive\". When Sphinx reads it, it looks up the registered handler for the directive, finds ImageDirective, invokes ImageDirective.run, which returns an image_node, which is an object with an alt field containing \"alttext\". Once Sphinx's processed all nodes, it passes the whole doctree to the HTML Writer, which looks up the rendering function for image_node, which tells it to output antag. Whew that's a mouthful. And for all that implementation complexity, we get… an interface that has 3x the boilerplate as markdown. On the other hand, the markdown image is hardcoded as a special case in the parser, while the rst image is not. It was added in the exact same way as every other directive in rst: register a handler for the directive, have the handler output a specific kind of node, and then register a renderer for that node for each builder you want. This means you can extend Sphinx with new text objects! Say you that instead of an , you want awith a . In basic markdown you have to manually insert the html, with Sphinx you can just register a new figure directive. You can even make your FigureDirective subclass ImageDirective and have it do most of the heavy lifting. The second benefit is more subtle: you can transform the doctree before rendering it. This is how Sphinx handles cross-referencing: if I put a foo anchor in one document and :ref:`image ` in another, Sphinx will insert the right URL during postprocessing. The transformation code is also first-class with the rest of the build process: I can configure a transform to only apply when I'm outputting html, have it trigger in a certain stage of building, or even remove a builtin transform I don't want to run. Now, most people may not need this kind of power! Markdown is ubiquitous because it's lightweight and portable, and rst is anything but. But I need that power. Subscribe One use case Logic for Programmers is a math-adjacent book, and all good math books need exercises for the reader. It's easier to write an exercise if I can put it and the solution right next to each other in the document. But for readers, I want the solutions to show up in the back of the book. I also want to link the two together, and since I might want to eventually print the book, the pdfs should also include page references. Plus they need to be rendered in different ways for latex (pdf) output and epub output. Overall lots of moving parts. To handle this I wrote my own exercise extension. .. in chapter.rst .. exercise:: Fizzbuzz :name: ex-fizzbuzz An exercise .. solution:: ex-fizzbuzz A solution .. in answers.rst .. solutionlist:: How these nodes are processed depends on my compilation target. I like to debug in HTML, so for HTML it just renders the exercise and solution inline. When generating epub and latex, though, things works a little differently. After generating the whole doctree, I run a transform that moves every solution node from its original location to under solutionlist. Then it attaches a reference node to every exercise, linking it to the new solution location, and vice versa. So it starts like this (using Sphinx's \"pseudoxml\" format): -- chapter.rst FizzbuzzAn exercise A solution -- answers.rstAnd it becomes this: -- chapter.rst FizzbuzzAn exerciseSolution -- answers.rstA solution(back) The Latex builder renders this by wrapping each exercise and solution in an answers environment, while the epub builder renders the solution as a popup footnote.2 Making this work: It's a complex dance of operations, but it works enormously well. It even helps with creating a \"free sample\" subset of the book: the back of the free sample only includes the solutions from the included subset, not the whole book! \"But I hate the syntax\" When I gush about rST to other programmers, this is the objection I hear the most: it's ugly. To which I say, are you really going to avoid using a good tool just because it makes you puke? Because looking at it makes your stomach churn? Because it offends every fiber of your being? ...Okay yeah that's actually a pretty good reason not to use it. I can't get into lisps for the same reason. I'm not going to begrudge anybody who avoids a tool because it's ugly. Maybe you'd find asciidoc more aesthetically pleasing? Or MyST? Or Typst? Or Pollen? Or even pandoc-extended markdown? There are lots of solid document builders out there! My point isn't that sphinx/rst is exceptionally good for largescale documentation, it's that simple markdown is exceptionally bad. It doesn't have a uniform extension syntax or native support for pre-render transforms. This is why a lot of markdown-based documentation generators kind of hack on their own preprocessing step to support new use-cases, which works for the most part (unless you're trying to do something really crazy). But they have to work around the markdown, not in it, which limits how powerful they can be. It also means that most programmer tooling can't understand it well. There's LSP and treesitter for markdown and rst but not for gitbook-markdown or md-markdown or leanpub-markdown.3 But if you find a builder that uses markdown and satisfies your needs, more power to you! I just want to expose people to the idea that doc builders can be a lot more powerful than they might otherwise expect. No newsletter next week I'll be in Hong Kong. Update 2024-07-31 Okay since this is blowing up online I'm going to throw in a quick explanation of Logic for Programmers for all of the non-regulars here. I'm working on a book about how formal logic is useful in day-to-day software engineering. It starts with a basic rundown of the math and then goes into eight different applications, such as property testing, database constraints, and decision tables. It's still in the alpha stages but already 20k words and has a lot of useful content. You can find it here. Reader feedback highly appreciated! rst is actually independent of Sphinx, but everybody I know who writes rst writes it because they're using Sphinx, so I'll use the two interchangeably. Also typing rST is annoying so I'm typing rst. ↩ This is why I attach exsol_ref_nodes and not default reference_nodes. Sphinx's epub translator uses an attribute passlist I need to workaround in post-rendering. ↩ This is also one place where rst's ugly syntax works in its favor. I've got a treesitter query that changes the body of todo directives and only todo directives, which is only possible because the rst syntax tree is much richer than the markdown syntax tree. ↩ If you're reading this on the web, you can subscribe here. Updates are once a week. My main website is here. Don't miss what's next. Subscribe to Computer Things: Subscribe",
    "commentLink": "https://news.ycombinator.com/item?id=41120254",
    "commentBody": "I prefer rST to Markdown (buttondown.email/hillelwayne)172 points by BerislavLopac 3 hours agohidepastfavorite184 comments Arainach 1 hour ago>To which I say, are you really going to avoid using a good tool just because it makes you puke? Because looking at it makes your stomach churn? Because it offends every fiber of your being?\" Yes. A thousand times yes. Because the biggest advantage of Markdown is that it's easy to read, and its second-biggest advantage is that it's easy to write. How easy it is to parse doesn't matter. How easy it is to extend is largely irrelevant. Markdown may or may not be the best tool for writing a book, but Markdown is the best tool for what it does - quickly writing formatted text in a way that is easy to read even for those who are not well versed in its syntax. I don't want to write a book. If I did I'd use LaTeX before RST. I want something to take notes, make quick documentation and thread comments. reply bityard 55 minutes agoparentI thought Markdown was clearly very silly back when it started gaining traction amongst developer types. There were already so many other better options--even at the time--for plaintext-to-formatted document markup languages.) But still, developers were designing whole apps (CMSes, productivity apps, document management, etc) and plugins around Markdown, sometimes as businesses. But then I realized, after using it in some apps, that wasn't really what Markdown was about. Markdown is about a bare-minimum amount of styling that is just as readable and at home in plaintext as formatted in HTML. The amount of formatting it supports is small _on purpose_, so that it fits in your brain and doesn't require a toolbar to use. It is _meant_ for things like comment fields, chat programs, commit messages, and so on. Maybe even blog articles. But it certainly is not something you'd want for writing the documentation for an enterprise-grade product. These days, I write Markdown even in place where it will never be rendered into HTML. Because it's quite readable as-is. (And I wish HN supported it.) reply keybored 5 minutes agorootparentMarkdown is like a virus of an idea: 1. Apparently simple enough to implement to get the basics right (not that I could do it) 2. But there is plenty of room for accidental edge cases in the implementation 3. Many then implement it with or without edge cases 4. But it’s not enough because a lot of the people who use it are programmers so they naturally want to extend it to do just a little more 5. Now the standardization effort (Commonmark) has to take all of those edge cases into account plus have to figure out how to deal with extensions (especially for popular ones) 6. Then you get a heroically (in terms of effort and grit) wordy standard All for the initial idea which is so simple that it seems redundant: look as good plain as rendered. (Then what’s the point of rendering it, and in turn what’s the point of a formal syntax instead of the (still existing) ad hoc email and whatnot conventions?) Right now it’s fantastic for chat applications (here you definitely want rendering and not the visible markup). It’s been pretty good for things like forum comments as well. With the exception of block quotes which are a pain to fiddle with (the only prefix syntax if you don’t include the indentation-for-code since that is de facto optional now that so many applications support code fences… all because that’s how email does it). reply tetha 30 minutes agorootparentprevI arrived at a similar conclusion, just from the other direction: It is really hard to get people to document. It is even harder to get those people to care a little bit about formatting. Markdown is... limited, I acknowledge. But with a very small amount of learning, markdown is as fluent and simple to write as normal text. In fact, 90% of what I wrote before I knew markdown was valid and decently formatted markdown already. If you asked people who don't document to document in rST or tex... then you'd have no documentation at all. Because that suddenly adds a lot of effort on top of what you want to write down. Now for some customer-facing whitepapers and documentation, we do use rST. But there you have people who are tasked with paying some effort to create some decently looking docs. Not trying to coax developers into writing down some of their state of mind while doing stuff. reply packetlost 35 minutes agorootparentprev> But it certainly is not something you'd want for writing the documentation for an enterprise-grade product. I guess that depends. If you're making a print manual, yeah probably not. IME markdown gets painful as soon as you start doing a bunch of tables. Most enterprise web applications would probably be completely fine with just markdown-based docs. reply paholg 26 minutes agorootparentI think a good example is all of the wonderful documentation that's been created with mdBook. Heck, the Rust book was written with it, and they also made a print edition, so maybe markdown is enough even for that. https://github.com/rust-lang/mdBook reply steveklabnik 11 minutes agorootparentCarol put in a tremendous amount of work to build tooling to go between Markdown and Docx. The publishers used the docx versions for print. That doesn’t mean that I think Markdown is inadequate or the wrong decision, but it’s not just a “write in Markdown and you’re good” sort of situation. reply pclmulqdq 59 minutes agoparentprevI am probably in the 90th percentile of TeX users, but I have to say that it's hard for me to think that there's much space between markdown and TeX for another typesetting language. Markdown is easy to write and read but very constrained, while TeX is a bit harder and essentially infinitely flexible. The biggest issue I have seen with TeX is a people problem: people frequently write spaghetti TeX with horrible style. This is terrible, but it is not actually a language issue. Writing it with a \"docs are code\" mindset can produce some very clean results. The second biggest issue is that there isn't a good TeX -> HTML compiler. reply slaymaker1907 42 minutes agorootparentYou should check out Scribble which uses Racket. It has a bunch of different renderers including HTML and Markdown. However, unlike Markdown, you can easily write extensions for it in Lisp, even within the document itself. https://docs.racket-lang.org/scribble/running.html#%28part._... I suppose that makes it inappropriate for something like rendering comments, but it's a great way to write documents. I used it a lot for writing papers since there's a lot less boilerplate and was much easier to use than TeX. reply philistine 9 minutes agoparentprev> I don't want to write a book. If I did I'd use LaTeX before RST. 100 times yes. Markdown for light styling. LaTeX for anything else. The next revolution in standardized text parsers will not come from replacing Markdown, but from replacing LaTeX. reply thomascgalvin 54 minutes agoparentprevI have used markdown to write books, and it worked just fine. Now, these were novels, not technical documents, but I never encountered something that couldn't be solved with markdown plus some occasional HTML. I've also generated quite a bit of technical documentation using markdown, and Pandoc's extensions[1] allow you to include pretty much any formatting you might require, complicated math and syntax highlighted code blocks included. That markdown can then be transformed into HTML, a Word doc, a ePub, a PDF ... There needs to be a very compelling reason for me to reach for something other than markdown. [1] https://pandoc.org/MANUAL.html reply bluGill 27 minutes agorootparentMost novels don't need anything more complex than a link to the next chapter at the end of the page. Maybe bold text, but a lot get by without. As such markdown will work for most. I've seen some novels with some really complex formatting, but those are rare (I read a lot of litRPG and still call them rare). However I mostly write technical documentation and I often hit limits of things markdown cannot do even though my documents are much shorter than a novel. reply sureglymop 53 minutes agoparentprevAnd it actually can be easily extended with custom blocks ( ::: ). https://github.com/vokimon/markdown-customblocks reply bilater 59 minutes agoparentprevyup - my knee jerk reaction at seeing the first couple of samples was to recoil. Great if it works for ppl but I'm gonna stick with markdown. reply edgarvaldes 54 minutes agoparentprevThe very next paragraph in TFA agrees with you: >...Okay yeah that's actually a pretty good reason not to use it. I can't get into lisps for the same reason. I'm not going to begrudge anybody who avoids a tool because it's ugly. reply ajross 53 minutes agoparentprev> Because the biggest advantage of Markdown is that it's easy to read, and its second-biggest advantage is that it's easy to write. I'd go so far as to flip those two. By far, it's more important to ensure that documentation can be easily written (the raisin d'etre of MD) than it is to optimize for the job of the people trying to collate/edit/format/improve/maintain the documentation (something that RST speaks to, primarily). Because the primarily failure mode in this space is not that we have imperfectly edited documentation. It's that we lack docs at all, because the hackers didn't understand the doc tools. In Zephyr, we use RST. And... it's fine. I've made my peace with it. But \"please write some docs\" is a routine comment in review, and in my experience many-probably-most contributors just don't know how and don't want to take the time to learn. The barrier to markdown would be much, much lower. reply kaycebasques 2 hours agoprevContext: I've been a technical writer for ~12 years. I actually started out my career migrating a startup's docs from Word to Sphinx. Then I did a lot of time on Google's proprietary CMS/platform for developer docs. Then a few years on Eleventy-based sites. For the last two years I've been back on a Sphinx-based site (pigweed.dev). I've also done some odd jobs for readme.com-based startups and have dabbled in Docusaurus, Astro, and Hugo. reStructuredText (reST) by itself can be pretty rough. reST combined with Sphinx is pretty great. I.e. the strengths of Sphinx far outweigh the weaknesses of reST. For big, professional docs sites (+100 pages, +10 contributors) I have pretty strong opinions that Sphinx is probably the most responsible choice, long-term. > The most important difference between rst and markdown is that markdown is a lightweight representation of html, while rst is a midweight representation of an abstract documentation tree. Yes, what this means in practice is that it's easy to customize common aspects of your site (such as how images are displayed). A teammate of mine on Pigweed recently created a shortcut for linking to bugs consistently. You type :bug:`59385981` and the link gets transformed into https://pwbug.dev/59385981. If we ever need to mass-migrate all of our bug links, it's now trivial. Another profoundly important consequence of this architecture: all internal links are guaranteed to always resolve (you get warnings/errors if you link somewhere that doesn't exist). I previously wrote about how baffling it is that this is not the industry standard for docs sites: https://technicalwriting.dev/src/link-text-automation.html The other thing that Sphinx excels at: well-defined extension and theme APIs. It's not exactly easy to build extensions or themes, but lots of people have figured it out (including me). There's a pretty rich ecosystem of extensions and themes on PyPI. Lately I've been calling Sphinx the sleeping giant of docs systems. It's already pretty great and with a little concerted effort I think we can collectively make it absolutely phenomenal. The upstream Sphinx repo now has a GitHub Discussions section that gets a little traffic; a lot of us seem to congregrate on the #sphinx channel in the Write The Docs Slack. reply pbowyer 29 minutes agoparent> Another profoundly important consequence of this architecture: all internal links are guaranteed to always resolve (you get warnings/errors if you link somewhere that doesn't exist). I previously wrote about how baffling it is that this is not the industry standard for docs sites: https://technicalwriting.dev/src/link-text-automation.html This, so much this. It's a problem in an even more general form (for you're writing about linking to sections within a page): the number of CMS systems or static site builders that make you insert the final URL when you write is _insane_. If the slug changes, you reorganise your site - now you have to do a search and replace through the site to update all your links. Static site generators could enable linking like [Hello](../hello.md) and resolve the link at build time, instead of expecting everyone to type [Hello](/why/hello/). And yet the popular ones I've used or looked at don't do this. It seems to be a marmite feature (you love it or you don't): I've raised it with static site builder team members and received a \"Why would you want that?\" response. Explanations got nowhere. I'm not sure if it's a niche feature, you have to have experienced the problem to appreciate the solution, or people are used to writing once and not maintaining for a decade or longer, but it'd be great to see wider support. reply ak217 2 hours agoparentprevAgreed that Sphinx is extraordinary and wildly underrated. Sphinx is the only architecturally sound, extensible, widely used documentation framework that I know of. Its plugin ecosystem is amazing and gives me incredible leverage to improve documentation for teams and projects. I'm not a fan of reStructuredText, but nowadays it's possible to do most things that previously tightly coupled Sphinx to RST in Markdown, courtesy of MyST-Parser: https://github.com/executablebooks/MyST-Parser reply bluGill 1 hour agorootparentExcept that the plugins are not compatible with each other or the latest version. That means I'm seeing some bugs that are fixed in the latest but I can't get the fix because my doxygen plugin doesn't work with the latest, and even if it did is the mermaid plugin updated yet? (please don't ask which versions of each I'm using - I believe there are at least 2 different ones that can do both of the above and they all have different abilities...) reply eska 43 minutes agoparentprevYes, what this means in practice is that it's easy to customize common aspects of your site (such as how images are displayed). I found this to be very easy using Markdown+pandoc. I turned image tags containing youtube links to thumbnails with video tag and alt text, hooked up image tags to local video files to ffmpeg to optimize and resize videos to then do the same, etc in a few lines of code. reply skybrian 1 hour agoparentprevSome drive-by feedback on pigweed.dev: It seems like it’s missing a “What is Pigweed” section? I was wondering what Pigweed does and eventually found the Github README, which is somewhat better. (I’ve used Arduino, but I’m not quite sure what I’m looking at.) reply shepherdjerred 1 hour agoparentprevWhy do you like Sphinx so much? Have you ever used MkDocs/Material for MkDocs? How do they compare? At my last job I spent a fair amount of time on documentation, but I don't have a great understanding of what technical writers like/dislike, or what documentation systems are best. reply bluGill 1 hour agorootparentI like sphinx because I can make it do all the weird links between documents that I want. Markdown can't do that. I've never used MkDocs so I cannot comment. reply einpoklum 1 hour agoparentprev> reStructuredText (reST) by itself can be pretty rough. reST combined with Sphinx is pretty great. So, you've made a convincing argument of why we should prefer Markdown to reST, 9 times out of 10. If we're working with Sphinx we'll give it serious consideration. reply Spivak 50 minutes agorootparentI'm not really sure what your point is. What you're saying agrees with both the parent and the OP. reply BerislavLopac 2 hours agoprev> markdown is a lightweight representation of html This is my main problem with the article, as this is decidedly incorrect. Markdown was designed as a tool of conversion of de facto standard of formatting text in email messages and Usenet posts of early nineties. The basic 7-bit ASCII nature of those technologies inspired people to informally annotate the text with special signs to denote formatting like emphasis, section titles and the like. True, HTML shares a lot of similarities with that nameless standard, so John Gruber in 2004 wrote a basic script [0] to convert the latter to the former, never expecting it to become such a universally used actual standard. [0] https://daringfireball.net/projects/markdown/ reply velcrovan 2 hours agoparentThe very first sentence in that link says “Markdown is a text-to-HTML conversion tool for web writers.” Gruber did not take a \"de facto standard\" from Usenet and simply write an HTML converter for it. He designed his own markup, borrowing from Usenet and other conventions. The “Acknowledgements” section at the bottom of your link alludes to this fact. Markdown was from the beginning intended as a markup syntax for web CMSs. To say it is a lightweight representation of HTML is correct. The whole point was that every part of the syntax produce a direct HTML equivalent. reply CharlesW 2 hours agorootparentGruber writes that Markdown is two things: (1) a plain text formatting syntax; and (2) a software tool, written in Perl, that converts the plain text formatting to HTML. > To say it is a lightweight representation of HTML is correct. It's correct in the context of (2) but not (1). In the context of (1), Markdown is a lightweight markup language for rich text. For example, Pandoc can convert Markdown to formats like PDF, LaTeX, and ePub. reply rpdillon 1 hour agorootparentIt's also true in the context of (1), since the syntax specification specifically falls back to HTML for difficult things like tables. This is made abundantly clear on the Syntax page[0]: > Markdown’s syntax is intended for one purpose: to be used as a format for writing for the web. > Markdown is not a replacement for HTML, or even close to it. Its syntax is very small, corresponding only to a very small subset of HTML tags. The idea is not to create a syntax that makes it easier to insert HTML tags. In my opinion, HTML tags are already easy to insert. The idea for Markdown is to make it easy to read, write, and edit prose. HTML is a publishing format; Markdown is a writing format. Thus, Markdown’s formatting syntax only addresses issues that can be conveyed in plain text. > For any markup that is not covered by Markdown’s syntax, you simply use HTML itself. There’s no need to preface it or delimit it to indicate that you’re switching from Markdown to HTML; you just use the tags. Markdown is very coupled to HTML, and is hobbled as a result compared to formats like Tiddlywiki and Org that not only have sophisticated syntax for all kinds of content like tables, but also directives to the parser itself to render particular blocks using an external tool. I wrote a bit about this in 2021 in response to query about why Org mode doesn't use Markdown[1]. [0]: https://daringfireball.net/projects/markdown/syntax [1]: https://rpdillon.net/why-doesnt-emacs-org-mode-just-use-mark... reply The_Colonel 1 hour agorootparentprevIsn't inline HTML valid within Markdown? You could say that Markdown is a superset of HTML. reply CharlesW 1 hour agorootparentThat's an excellent point. Time to update https://www.wikiwand.com/en/Markdown. :^) reply simonw 2 hours agoparentprevI disagree. Markdown has always been about HTML - to the point that Markdown parsers support dropping actual HTML tags mixed in the the markup. The fact that Markdown was inspired by email conventions doesn't make the statement \"markdown is a lightweight representation of html\" any less correct. reply SoftTalker 1 hour agorootparentI thought a goal of Markdown was to be a set of conventions that were readable on their own as well as being transformable to a rich text/HTML representation. You can read a Markdown document pretty easily using \"less\" or any other character-based interface. The same is not really true of reST. Maybe I'm confusing that with some other plain-text markup convention? reply woodrowbarlow 44 minutes agorootparentall of that is true, but markdown targets HTML as its \"native backend\", if you will. it is not feasible to render markdown -> pdf without having an intermediate HTML representation. this is clear from the fact that HTML can be inlined in a markdown document; this is part of the spec (in so much as there even is a \"spec\" for markdown, anyway). reply paiute 1 hour agorootparentprevThe article convinced me that markdown is better for its purpose. reply Spivak 45 minutes agorootparentprevreST is also designed to have human readable source. You might not like it compared to markdown but it has to serve as a the docstring format of Python and does so fairly well. reply latexr 1 hour agorootparentprev> to the point that Markdown parsers support dropping actual HTML tags mixed in the the markup. Some Markdown parsers support some HTML. You cannot, for example, add a YouTube video embed to a GitHub comment. Webpages that allow Markdown quite reasonably limit what’s accepted. reply The_Colonel 1 hour agorootparentGruber: > Markdown’s syntax is intended for one purpose: to be used as a format for writing for the web. Both Gruber's original and CommonMark (the closest thing to a standard) support inline HTML. Both Gruber and CommonMark specs are defined in terms of its HTML output. reply latexr 33 minutes agorootparentYes, that’s why I said “some”. I don’t understand what’s ambiguous about that. reply samatman 1 hour agorootparentprevUsually, the colloquial conflation of Markdown with CommonMark and the numerous Markdown-esque dialects is helpful language, I've defended it here before. On this question, it isn't. Markdown qua Markdown, unambiguously supports HTML tags. You can verify that yourself: https://daringfireball.net/projects/markdown/ The introduction being: > Markdown is a text-to-HTML conversion tool for web writers. Markdown allows you to write using an easy-to-read, easy-to-write plain text format, then convert it to structurally valid XHTML (or HTML). It's not possible to read the original specification without agreeing that, yes, Markdown is specifically a way to generate HTML. It also has a nice syntax which has become popular in contexts where embedding HTML isn't a good idea, and there are some tools which allow Markdown to be converted to other formats as well (usually, but not always, these disallow most HTML tags, meaning that they aren't Markdown sensu stricto either). I would say that all of this supports Hillel's basic point here: Markdown is in fact tied to HTML semantics, in a way which makes it painful to do things with it which aren't tied to those semantics in the same way. Dialects in the Markdown family exist which make this less painful, and they do so by diverging from the original Markdown spec. reply latexr 1 hour agorootparent> Markdown qua Markdown, unambiguously supports HTML tags. The section I quoted (and responded to) didn’t say “Markdown supports HTML tags”, it said (emphasis added) “Markdown parsers support (…)”. So unless you’re arguing that a tool cannot be considered a true Markdown parser¹ unless it parses HTML, the distinction is irrelevant. I wasn’t making a general argument, I was responding to a specific claim. > You can verify that yourself Yes, I am quite familiar with that subpar piece of code and specification. I have spent some time implementing a Markdown parser myself (the output wasn’t HTML) and Gruber’s resources were by far the worst. For various reasons he has been an awful steward of Markdown; its ubiquity is despite him, not because of. Forgive me if I don’t find the author to be the authoritative source anymore. ¹ https://en.wikipedia.org/wiki/No_true_Scotsman reply travisjungroth 53 minutes agorootparentI think you’ve kinda lost the thread. From the top comment: > Markdown was designed… Surely Gruber is an authority on that. And anyway, “ markdown is a lightweight representation of html” is true enough that calling it “decidedly incorrect” is wrong. Certainly it’s not a point that’s supported by going to author intent. reply latexr 29 minutes agorootparent> And anyway, “ markdown is a lightweight representation of html” is true enough that calling it “decidedly incorrect” is wrong. Yes, I completely agree with that. And that wasn’t the point I quoted or responded to. > From the top comment Again, I wasn’t replying to the top comment, I was replying to what I quoted, from the comment I replied to. reply chrismorgan 2 hours agoparentprevMarkdown, Markdown, is nothing to do with email and Usenet formatting. It was a specific syntax, poorly defined, which has since become a broad family of mostly similar syntaxes; and it was inspired by various conventions from things like email and Usenet, some of which predate computers (e.g. pretty sure I’ve seen or heard of asterisks being used for italics in old typewritten stuff); but Markdown is all about HTML, its syntax is extremely constrained by HTML, and any attempts to separate it from HTML are fairly thoroughly doomed. reply masklinn 2 hours agorootparentSaying that it has nothing to do with email/usenet is a bridge too far in the other direction, it was very much inspired by such formatting, something it never hid: https://daringfireball.net/projects/markdown/ > the single biggest source of inspiration for Markdown’s syntax is the format of plain text email reply chrismorgan 1 hour agorootparentYeah, it was inspired by those things, as I said, but it was never connected to them, and is quite incompatible with them. I also express things that strongly because I’ve observed a distinct tendency to interpret Markdown as the successor of those things or the inventor of such syntax ideas. Whereas in fact, Markdown was not the first lightweight markup language, and is not the only one, and isn’t even the LML unquestionably closest to plaintext email conventions (reStructuredText is an obvious contender; overall, I’d consider reStructuredText a little closer than Markdown, but it’s subjective). Perhaps my intent would be more clearly expressed by inverting it: email formatting has nothing to do with Markdown. reply masklinn 38 minutes agorootparent> Yeah, it was inspired by those things, as I said, but it was never connected to them You seem to have a very peculiar interpretation of the word \"connection\" > and is quite incompatible with them. It can't be incompatible with ad-hoc unspecified and informal formatting habits. > Perhaps my intent would be more clearly expressed by inverting it: email formatting has nothing to do with Markdown. That's just as inane for the same reasons. reply js2 1 hour agoparentprevDear HN: stop leaving comments like this. It's arguing over semantics and makes for boring conversation. It also violates HN guidelines for leaving comments: - Please respond to the strongest plausible interpretation of what someone says, not a weaker one that's easier to criticize. Assume good faith. - Please don't pick the most provocative thing in an article or post to complain about in the thread. Find something interesting to respond to instead. https://news.ycombinator.com/newsguidelines.html If you disagree with the substance of the article, say you prefer Markdown to rST, then address that. Explain why despite the author's preference for rST, you prefer MD. It's silly to argue over this single sentence about exactly what Markdown is or isn't. reply keybored 2 hours agoparentprevYou’re both right. The original implementation was a superset of HTML. Do the lightweight syntax for the common stuff and HTML for the rest. reply tombert 51 minutes agoparentprevYeah, that's what I feel gives markdown an edge over nearly anything else; markdown is adopting conventions that were meant to be readable without any kind of rendering. I can very easily tell what my markdown document is going to look like before I render it with Pandoc, because it's basically just taking stuff people were using with plain text that was meant to be read directly anyway. I haven't used rST, but looking at the examples it looks considerably less readable out of the box. reply Spivak 37 minutes agorootparentOh it's not that bad. * one * two * buckle my shoeinspiring quote- some famous guy foo a kind of bar bar part of a foo :red: stop :yellow: speed up :green: go - code:: python def fun(): pass Go here_ for more info. - :: here: https://google.com My **strong** text is well *emphasized*. Very ``literally``. reply unoti 1 minute agoprevFor the motivating use cases, I wonder if YAML and a simple script to transform to other formats as needed would be more effective, easier to read, easier to write, and easier to work with in general. reply arp242 10 minutes agoprev> When I gush about rST to other programmers, this is the objection I hear the most: it's ugly. To which I say, are you really going to avoid using a good tool just because it makes you puke? Because looking at it makes your stomach churn? Because it offends every fiber of your being? I like my Markdown documents to be nicely readable in source form. Because that's what I'm editing so being readable helps, and it's also what I read most of the time. I don't think Markdown is perfect. I have gripes. But it's \"good enough\", and damn near everywhere already so it's \"in the fingers\", so to speak. > Markdown doesn't have a uniform extension syntax or native support for pre-render transforms. Well no, but \"Markdown\" is also a standard with more implementations you can shake a stick at, whereas most of the alternates mentioned n the article are basically just a program written in $lang, and that's it. I think some do have a spec document, but also don't really have complete alternative implementations, so it doesn't really matter. And I get the point; for my own website I have this ... piece of art ... to transform some of the HTML: https://github.com/arp242/arp242.net/blob/master/_plugins/ma... On one hand: eww. On the other hand: it's not strictly needed, hard to do cross-platform, and has been working fine for a long time now. So whatever. reply philistine 5 minutes agoparent> Well no, but \"Markdown\" is also a standard with more implementations you can shake a stick at This ubiquity comes in large part from its lineage. Gruber based Markdown on the established cultural standards in raw text emails. The people who quickly adopted it where doing so based on familiarity. reply photonthug 1 hour agoprevI’ve done this thing a few times where I have a nice layout of about 5-10 pages of markdown docs, themselves rendered from more dynamic jinja templates, and feel that life is pretty good. Looks great, got a real build process for auto docs, but too big for a monolithic GitHub readme. Now the pain starts. GitHub’s own docs for project pages don’t work. Do I need a .nojekyl file, are gh-pages branches still required? Is there a config error in the repo or did changes just not prop? I guess I’ll try actions. Fast forward a few hours and this is getting unreasonable, haven’t looked at read the docs in a while, let’s see if that works. Ok it’s being weird and wants sphinx maybe, let’s get sphinx to work with markdown, ok cool. The build works but the page width is broken after deployment even though I can’t reproduce on my machine so it must be the ads injection on the community tier. I know all this is working fine for lots of projects and have done it myself in the past. It works after it’s working. But it’s all so unbelievably fiddly. Bottom line, Markdown vs Rst isn’t even a choice/pain point on my radar, it’s more down to finding that good fit for medium sized docs projects / static hosting. reply paholg 17 minutes agoparentHave you looked into mdBook? I haven't used it myself, but I've enjoyed the documentation of many projects that do and it seems really nice once you get past the point where a single readme file works well. They also have some nice instructions on automated deployments. https://github.com/rust-lang/mdBook reply PaulHoule 3 hours agoprevI was looking at RST as an answer for a documentation system with similar complexity to the system he's building and an intense need to mark stuff up with definite semantics, both in the case of capturing structures in the RST file in a database and mixing database results into the content. Two problems I had were: (1) common with a lot of systems, the RST tools don't contain an RST unparser. I really wanted to be able to generate RST files automatically by merging content from other RST files and other sources and working with them via a document API. The RST tools don't support that. (2) The RST tools expect a certain defined set of blocks for a particular document; it would be very possible for a system to represent blocks in a generic way which would make possible tools that can transform documents without necessarily knowing the definitions of blocks inside it. These are problems w/ the tools, not problems with RST itself but every time I'm forced to strip my code back to the walls is an opportunity to think about some other markup system such as something HTML-based. reply hgs3 2 hours agoparent> something HTML-based Instead of HTML you can use XML to write structured documents. With XML you can define whatever custom tags you need with schema validation if desired. The advantage of this approach is you have full control over the input schema and output, but the downside is XML is much more syntactically noisy compared to Markdown or RST and you will need a script to parse & convert the XML to your preferred output format(s). reply tannhaeuser 45 minutes agorootparentPro-tip: use SGML which has it all: - is a superset of XML (XML is derived from SGML as a simplified, proper subset) - can parse HTML precisely with all bells and whistles such as tag omission, enumerated attributes and other shortforms (which are based on SGML after all) - can define markdown syntax as an SGML SHORTREF customization (note that SGML can not cover all of markdown syntax; for example, defining reference links somewhere at the end of a document and expecting SGML to pull a href URL into the place where the link is referenced won't work with SGML SHORTREF) The combination of markdown-as-sgml and inline HTML or HTML blocks is particularly nice and predictable, and also informs further customization such as using entities (text variables), custom elements, and other advanced SGML stuff with markdown that comes up frequently as a requirement. reply _heimdall 2 hours agorootparentprevOnce you get that far, XSLT is waiting for you if you need to render XML to HTML. reply andrewflnr 18 minutes agorootparentYes, waiting in the dark, with teeth. (I kid, mostly. It was a mild pain in the projects I used it for, and I've heard much worse horror stories than mine.) reply _heimdall 17 minutes agorootparentSame. I've used it for small projects, like styling an RSS feed. I imagine it gets tricky fast in anything larger. reply giantrobot 2 hours agorootparentprev> Markdown or RST and you will need a script to parse & convert the XML to your preferred output format(s). XSLT will happily output any number of formats from an XML doc. There's also a number of existing and very capable XML schemas for documentation like DocBook. You can even go from a lightweight markup like RST or Markdown to DocBook and then have an XSLT pipeline that delivers that intermediary to any number of formats. There's also very capable graphical editors that will spit out DocBook directly. I find the aversion to XML very strange. It was definitely applied in some places poorly by products with \"Enterprise\" somewhere in the name but the language itself is very useful. The aversion to XML has led to a lot of work re-learning of the lessons that led to some XML features. It's also led to implementing XML features poorly in other languages. reply SoftTalker 1 hour agorootparentYeah I always liked XML as a data format and combined with XSLT it is quite powerful. reply PaulHoule 58 minutes agorootparentWhat I really like with XSLT is what you can do with user-defined functions. Not only are they helpful in implementing transforms but you can also write stateful functions that insert rows into a database or something. reply zdw 2 hours agoparentprevI don't think this is the case. In python, rST is just one of many supported input formats for docutils: https://docutils.sourceforge.io/README.html#purpose The entire point docutils is to parse formats and convert using an API: https://www.docutils.org/docs/index.html#api-reference-mater... reply PaulHoule 1 hour agorootparentMy beef is that it doesn't have an RST writer. What I want is a central hub where I can suck in documentation that was originally in different formats and then manually edit it in a format where I can capture essential semantics and then feed it through the system again to produce output documents. If it had that it would be a 200 foot tall giant robot, as it is it's just another documentation generator. reply zdw 1 hour agorootparentAh, you want something like pandoc, but you can manipulate the internals as needed? reply PaulHoule 9 minutes agorootparentYes, and with a somewhat different focus. I wish I could throw in 1000 pages of reference documentation, align it semantically with a few pages of documentation about a particular topic and then enrich those pages with snippets pulled out of the reference material. And things like that. reply complex_pi 22 minutes agoparentprevI can't test (no computer right now) but can't include directives achieve what you want? reply euroderf 2 hours agoparentprevrST and Asciidoc seem roughly equivalent in terms of capabilities. Are they roughly equivalent in terms of weaknesses and missing features, I wonder. reply jawns 2 hours agoprev> markdown is a lightweight representation of html, while rst is a midweight representation of an abstract documentation tree To me, the whole point of markdown is to allow you to do simple things faster than writing raw HTML, but with the ability to intersperse raw HTML when needed. In projects where I've needed the power of RST over markdown, I've felt more comfortable just writing raw HTML directly. reply strongpigeon 2 hours agoparentThat’s pretty much how I feel. When the author writes: > This means you can extend Sphinx with new text objects! Say you that instead of an , you want awith a . In basic markdown you have to manually insert the html I can’t help but wonder what’s wrong with just writing HTML if you want those features? Why the extra layer? reply ryan-c 1 hour agorootparentConvenience? I have a \"spoiler\" role for rST, for example, which works like this: # state class to contain the counter class _spoiler: count = defaultdict(lambda: 0) def id(src): _spoiler.count[src] += 1 src_hash = sha256(src.encode()).hexdigest()[:7] return f'spoil-{src_hash}{_spoiler.count[src]:03}' def spoiler_role(name, rawtext, text, lineno, inliner, options={}, content=[]): src = inliner.document.attributes['source'] html = ( ''+\\ '{text}' ).format(text=text, id=_spoiler.id(src)) return [nodes.raw('', html, format='html')], [] I don't want to do that manually, and this lets me write :spoiler:`Rosebud was the name of his sled`. reply scott_s 1 hour agorootparentprevThe author wrote an entire article explaining their use case which answers your question. Short version: they’re writing a book which they want to render to multiple formats with semantic linking between items and different rendering based on formats. reply eddd-ddde 1 hour agorootparentprevThat's like saying why use C++ templates if you can just write the same function for every type that needs it. Now you don't need template instantiation! The point is that it's objectively better when you want to separate the concerns of writing content and rendering it. It makes writing much easier and keeping the layout consistent as well. reply osmarks 1 hour agorootparentprevPreserving the semantic content is helpful if you think you might want to switch the rendering later. reply fefe23 28 minutes agoprevI don't understand the argument for rST. If you need more control than Markdown can deliver, then write your stuff in HTML to begin with. I have written a ton of documents in plain HTML, including slide decks, documentation for customers, reports for customers, a blog. I have not written a book yet. If I were to write a book, I would use LaTeX because then the typographic fidelity of the output would be my paramount objective. Plain HTML is actually pretty awesome. It allows you to encode the structure of the document and then style if however you wanted. When I started in this business, you had to use LaTeX for that kind of flexibility. HTML has gotten a bad rep, I think, because it's dark side of including Javascript and a ton of frameworks for whatever perceived goal looks easy and seductive and then forces you into serfdom by obstructing future reuse. If you stick with the bare minimum HTML you'll be fine. Better than fine actually. Text processors can these days usually import bare metal HTML just fine if need be. They only fail if you give them the \"processed food\" output of some kind of rendering pipeline. The only other system for documentation we haven't covered in this thread is troff for man pages :-) Any takers? reply bluGill 24 minutes agoparentHTML is a bad choice - I want to be able to reorganize my site without have a million dead links. Even if I know what the correct organization is today, requirements will change and so in the future something will be wrong. With rST I can link to a section and move that section to a different document and the links all still work (or if they don't I get an error for each and so I know where to look). With markdown and html I link to a specific document and since each is a document generator there is no warning if I typo the page name (there are a number of tools to look for dead links in html). With markdown I cannot link into a section of the page, only the page itself (some extensions to markdown allow this) reply paholg 14 minutes agorootparentWhat you see as annoying, I see as a strength. You shouldn't break links; they don't only exist in your site. People will have them bookmarked or shared on the web. There's nothing worse than finding a post online that seems like it will cover your exact issue, but the link is now a 404. reply smlavine 2 hours agoprevI think commenters are missing that the author is talking about this in the context of typesetting their own book. They aren't claiming that rST is better than Markdown in the general case; in general, Markdown's simplicity is a reason why it is so widely used. But that's not what the author is talking about. reply justin66 2 hours agoparentnext [7 more] [flagged] jerf 2 hours agorootparentWell, the simple mental hack for yourself is just to prepend all blog content, if not all content in general, with #includeand you'll find yourself much happier in life. Speaking as one who actually produces blogs on rare occasions, I have to say starting every post with \"This is just my experience and may not apply to you this is not a claim of global applicability this is just applicable to this circumstance you're the one who chose to read this I didn't force you\" and so on isn't exactly the most compelling way to open a post. Though I have to admit now I'm really tempted to add that into my post template in like 2pt font or something, just so when people on HN complain I can point them at it. reply justin66 1 hour agorootparentBut that's all beside the point - we're not talking about a \"general disclaimer.\" (I am intrigued by how blurry the lens you look at the world must be, if you live by that \"#include \" nonsense) People interested in the blogger's rather specific Markdown use case would be better served by a more specific title, as would the nine out of ten Markdown users who are not. reply jerf 39 minutes agorootparentNo, I was just recommending it to you since you seem to be perturbed. I just give people a general measure of grace in their writing and it all seems to work out fairly well. You can try that as well, if you like. reply 12_throw_away 1 hour agorootparentprevIf the title \"Why I prefer rST to markdown\" (which a 100% accurate summary of the content) is somehow \"clickbait\", then the term \"clickbait\" has been redefined into meaningless. reply justin66 1 hour agorootparentI mean, which of the following is more precise? \"Why I prefer rST to Markdown\" or \"Why I prefer rST to Markdown for Typesetting\" Since it's a clearer statement of the author's meaning, and since very few users interested in Markdown are going to be doing any typesetting, it seems like a more meaningful title to me. But less likely to draw in readers... to \"bait\" them, if you will. reply keybored 1 hour agorootparentprevSubjective preference is not clickbait. reply smore 1 hour agoprevMarkdown has a great linter in markdownlint. When I worked in rST, I found the syntax to be super extensible, and tables much easier to write (list tables! amazing!) but without an effective linter, writing in rST was consistently painful. Whitespace has meaning, so I had to set up all sorts of indent highlights and dots for each space in my IDE to try to avoid screwing up the syntax inadvertently. rst-lint and others exist, but don't seem to be maintained, and didn't seem to have documentation about how to add support for custom directives (which are definitely one of the key advantages of rST). I'd write in rST again, but without an effective linter to stop me from making easy mistakes, I wouldn't be happy about it. reply SparkyMcUnicorn 1 hour agoparentI believe Mozilla uses rstcheck for linting, and it's actively supported. https://github.com/rstcheck/rstcheck reply simonw 2 hours agoprevA few years ago I wrote up some notes on the subset of reStructuredText that's worth committing to memory: https://simonwillison.net/2018/Aug/25/restructuredtext/ I've started using MyST for my more recent projects, which gives me the features I care about from reStructuredText - references and table of contents - but lets me use markdown syntax, which is easier for contributors. reply smore 1 hour agoparentGreat points about links, especially external links — it makes a lot more sense in the context of a documentation site where you might have the same external link referenced multiple times in the site, but you only want to have to update it once if it changes. The real gamechanger is for internal links (rST+Sphinx) and the use of the `:ref:` and `:doc:` directives so that you can reference an anchor or a doc link in the same content without having to type the header manually (which will inevitably go stale). https://www.sphinx-doc.org/en/master/usage/referencing.html#... that is one of the things I miss most about writing in rST, for sure. reply wodenokoto 1 hour agoprevI like writing markdown because it is so simple, but I agree with the author that it is too simple for more advanced stuff. But at the same time, I find the writing experience for more advanced stuff too poor. The author talks about references, but do we have a language server that can look up available references, headlines, figure names etc and help you auto complete? That’s what would make me take the plunge to a more advanced system. reply smore 1 hour agoparent> do we have a language server that can look up available references, headlines, figure names etc and help you auto complete? That would be a total gamechanger! Having the ability to do ref/doc links and not have to worry about stale topic headers is another thing I loved about writing in rST that I miss now that I'm back in markdown. reply hwayne 1 hour agoparentprevYeah, the rst lsp server (esbonio) can autocomplete and jumpto references in your project. I believe the markdown lsp can do this too, but only to a limited extent. reply gregopet 29 minutes agoprevI used to hate Markdown (am partial to AsciiDoc myself) but it has \"won\" and I've just accepted it & use it every day. Not the first time an inferior product did so, and won't be the last. There are a few hills I'd die on, but Markdown alternatives are not one of them. reply joekrill 2 hours agoprevThe thing I like about markdown is that it's very readable as just a raw format. With the bonus that it's easily converted to HTML. But it doesn't need to be converted to HTML. I guess this sort of falls under the \"But I hate the syntax\" section of the article, but I don't think it quite gets the point. I can look at a Markdown file and read or write it without even really thinking. Which is not really the case with rST (or even HTML, for that matter). reply bluGill 50 minutes agoparentI can look at a rST file and read it, and I think you will have no problem reading every rST file I've ever looked at. Sure it will take you a few seconds to realize you can ignore various syntax things, but that isn't a big deal and then the whole makes sense. Of course rST gives a lot more options to write documents that are not human readable, but it isn't that hard to make them readable. reply mg 2 hours agoprevMarkdown: ![alttext](example.jpg) RST: .. image:: example.jpg :alt: alttext The author prefers RST because: ... you can extend Sphinx with new text objects! Say you that instead of an , you want awith a... What I would do: ![alttext](example.jpg)[caption] And write a renderer which supports this syntax to create a figure with a figcaption. A markdown renderer is simple enough to write your own or extend an existing one. reply eichin 2 hours agoparentExactly - does anyone (well, maybe the author does since he did use markdown in previous works) use \"basic\" markdown anyway? There are always some extensions (either front-text metadata or syntax extensions like this one) in the \"interesting\" apps. (The python markdown module API kind of feels like it's entirely about extension and only a little bit about actually parsing, but that did make it easy to add an `ASIN()` token for a review site without needing a preprocessing stage...) That does make it a little worse for interchange, but that's maybe less important for markdown anyway. reply eichin 2 hours agorootparent(Even with pandoc, https://pandoc.org/MANUAL.html#extensions lists a bunch of syntax for things like this, brought in from github, php, and other places - for the example above, `implicit_figures` and `link_attributes` are a good starting point.) reply Ericson2314 1 hour agoparentprevOK that specific example works, but what about his later problem vs solution one? One runs out of hacks pretty quickly. reply beej71 17 minutes agoprevI started looking at converting my books to use Sphinx (from pandoc) and got almost there. What stopped me was something a little odd: I wanted to use different fonts in a link, notably some proportional and some monospace in the same link. And it was my read that this wasn't possible...? reply teamspirit 2 hours agoprevIsn’t this just a case of different tools for different jobs (or the right tool for the right job)? Rst clearly has some advantages for this use case but, at least for me, markdown is much faster and clearer to understand when jotting down my daily notes. reply hwayne 2 hours agoparentAbsolutely. I prefer rst for the use case of writing a technical book, because of the specific benefits I get from its additional complexity. My blog is still in markdown. reply bluGill 2 hours agoparentprevHaving done a little of both, I find RST is faster just because I can lookup whatever syntax I need to keep going while with markdown I often stop to scream because I can't make it do what I want. Either is easy enough to understand when reading raw text - this is mostly about good style though, RST gives you more options for bad style that is hard to read. reply karaterobot 2 hours agoprevI thank the author for explaining their reasoning. I still disagree, but I appreciated reading the argument. Apart from the ugliness of the syntax from a devex perspective, I think one of the big advantages of Markdown is that it's highly readable even without being interpreted, which rST is not. So if you have a markdown document and no markdown interpreter, an average person can still make more or less perfect sense of the contents, including the hierarchy and emphasis. reply 8organicbits 1 hour agoprev> it's that simple markdown is exceptionally bad. It doesn't have a uniform extension syntax or native support for pre-render transforms. I feel like \"simple markdown\" is a straw man here. If you're doing anything complex with markdown you're going to pick a flavor and learn it. Many flavors of markdown can do the things described. Here's a Hugo figure which looks easier to understand than the \"ugly rST\" equivalent: https://gohugo.io/content-management/shortcodes/#embedded-sh... reply kaizendad 1 hour agoprevWhile I definitely understand what the author is saying, the reality is that, for the majority of writing developers will be doing, having something that is easy-to-produce and easy-to-consume is paramount. There are tons of more powerful and flexible options than Markdown, but none that let you create a document that is both computer- and human-readable quite as quickly. Documentation that is written is better than documentation that isn't. reply bluGill 54 minutes agoparentWhich is why I use rST - just as easy to write, but enough more powerful that I'm not left hanging when I realize I need to do something more complex. > Documentation that is written is better than documentation that isn't. I have to disagree with this. I've read too many out of date documents. If documentation exists that isn't correct it is worse than no documentation at all. The only useful documentation is documentation that is correct, easy to navigate, easy to search, and easy to update as the world changes (there might be more?). Good documentation is better than bad, it is debatable if bad documentation is better than no documentation or not (in part because some bad documentation is worse than others). reply keybored 1 hour agoprevA lot of lightweight markup languages get the basics right (except MediaWiki). Then eventually when it comes to making extensions—and especially if it is supposed to be terse, or look it—people get into the game of strategizing ascii symbol use (maybe `!` for images, maybe `@` for a figure). At some point (and Rst[1] has a tendency to look like this, but only a little) it can start to look like some alternative, less regular markup language. Maybe you just use more backticks rather than angle “brackets”. Or maybe you have (like previously stated) marshalled all the ascii symbols so that all the common stuff can have a terse representation. Maybe they should just make a regular-looking markup for the unusual cases/user defined things. They could do something like Pollen with its Latex[1] syntax inspiration. [1] Initial caps for proper nouns reply samatman 1 hour agoparentWords are styled the way they're styled. McDonald is a proper noun with two capital letters, Mcdonald is simply not correct. I'll note that you didn't manage your footnote consistently, since you spelled MediaWiki correctly, rather than spelling it wrong as Mediawiki. For some reason, you decided not to do that with rST and LaTeX, without explaining why. Latex and LaTeX aren't even pronounced the same way, so I fail to see the purpose in your (inconsistent) stylistic choices here. reply keybored 1 hour agorootparentI can make concessions for names that are based on real people. I assure you my mistake was not because of good-intent towards Media[Ww]iki. reply samatman 1 hour agorootparentWhat I'm not understanding is why you've invented an incorrect rule for the English language and cited it. What purpose does this serve? reply pradn 1 hour agoprevI was thinking of how to setup a simple static blog without the baggage of a full-blow framework. Of course, I'd be re-inventing the wheel, but at least it'll make sense to me, personally. What I came up with: * Each page gets its own folder. * An optional METADATA file in each folder has stuff like the type of the page (blog post, photo gallery, code listing). * The index file can be in Markdown or rST or something. I'd just branch to a different parser based on the file name suffix. This is simple and lets me evolve the blog over time. For a personal blog, an ideal mix might be just branching to a different HTML converter based on the reply vunderba 40 minutes agoparentI have a customized version of pelican which is a python based static side generator. It basically supports this type of structure, except that in place of a physical separate meta-data file all the metadata goes in the front matter section at the top of the markdown file, and it gets stripped out of the actual rendered HTML. reply benji-york 3 hours agoprevI lament the lack of rST support in much of modern tooling. I'm reminded of all of the alternate worlds that didn't quite come to fruition, but could have (Lisp, Smalltalk, BeOS, etc.). reply bunderbunder 2 hours agoparentAn interesting commonality among the three examples you listed: they're all designed for a world when computing was a more solitary activity than it is now. For Lisp and Smalltalk, image-based development is a genuine hurdle in the modern world. It complicates many aspects of modern highly-collaborative software development, including version control and continuous integration. I think that the language's respective hacker ethoses might also be a challenge in light of how often people switch jobs nowadays. I haven't used Smalltalk for pay money, but my experience has been that initially getting settled into a large pre-existing Lisp project does take more brain effort than it seems to with a language like Java. (In the long run I'd rather inherit a Lisp project, but I also acknowledge that first impressions are important.) And BeOS was not a multiuser OS and didn't seem to have a clear path to becoming one. I'm pretty sure the main thing preventing it from becoming as much of a cybersecurity disaster as Windows 95 was is the simple fact that there wasn't any honey in that pot. reply marcosdumay 2 hours agorootparentImage-based development was never good. So we pushed it back again and again, so that we nowadays have a single image component we named \"database\" and most of the work is free from its problems. That doesn't mean we stopped doing it. reply Macha 2 hours agoparentprevThis largely occurs because the only real spec of rST is the Python implementation. And tools written in other languages are loath to include a Python library just to support one document format. While writing a new compatible implementation is much more work given the larger scope than it is for Markdown. So every language has a markdown implementation, but if you want to use rst in your Rust based static site generator or your PHP based CMS or whatever, it's a lot more work. reply bluGill 2 hours agorootparentEvery language has its down markdown - but they are not compatible with each other unless you stick to the very basic which doesn't do much. Which is why every implementation has extensions - it isn't hard to add extensions and there are a lot of obviously missing things from the basic. reply Macha 2 hours agorootparentYet at the same time I'm able to write Markdown that parses and renders correctly in VS Code, Obsidian, and the Rust-based static site generator I use. Sure, Obsidian has incompatible features I could use like [[Wiki Links]] but I don't have to. reply bluGill 34 minutes agorootparentThat is easy enough as long as you are only writing a simple one page readme type document. To be fair that is the majority of what people write. However if you write anything more complex you will run into issues. reply jcranmer 2 hours agorootparentprevIs there any rich text format which is well-supported across multiple languages? The closest I can think of is HTML, but even that has its fair number of issues... reply osmarks 1 hour agorootparentprevCommonMark mostly fixes this. reply marcosdumay 2 hours agoparentprevPeople don't add it because it is ugly and verbose. And then people don't create any new format for its use case because it already exists. Almost everything good we have only exists because some person irrationally decided to do it, against all common sense and logic. reply Karellen 2 hours agoprevAny sufficiently complicated lightweight markup format contains an ad-hoc, informally-specified, bug-ridden, and only slightly easier to use implementation of half of either DocBook or TeX. reply nequo 2 hours agoparentYes but Djot is pretty good though! Wouldn’t call it informal nor bug-ridden, it’s well thought out and doesn’t have many corner cases: https://djot.net/ Designed by one of the authors of CommonMark, an attempt to specify a standardized flavor of Markdown. reply keybored 2 hours agorootparentDjot insists that this nesting of bullet points is wrong: - first - second Instead you need this: - first - second I’m very picky about the aesthetics of lightweight MLs so this is tough to swallow. EDIT: By the way, recent comment from the primary developer: https://github.com/jgm/djot/discussions/310#discussioncommen... reply 0cf8612b2e1e 2 hours agorootparentprevI just wish it would move along already. I get it, some tough calls need to be made on edge cases that do not have a correct answer. Yet I want a 1.0 release so I can feel confident that the language will have staying power. Then again, it is already in pandoc, so I suppose you can trivially move out of it. reply the__alchemist 2 hours agoparentprevIndeed; Github will now render TeX in markdown documents, eg when displayed as a repo's readme. Very convenient. reply geenat 36 minutes agoprevIMHO, ignoring the parsing difficulty, the main issue with Markdown is it's difficult to write for non-technical users- 1 misplaced character can mess you up if you stick to the \"spec\". Markdown has already won over the technical users. Enjoy your infinite support tickets caused by markdown. RST does nothing to help this. reply queuebert 2 hours agoprevPersonally, besides it being a nice format, I use Markdown to honor Aaron Swartz. reply Ericson2314 1 hour agoparentHaha on one hand its probably Aaron Swartz's worst work. On the other hand, this is definitely the best reason to use markdown. RIP reply Decabytes 1 hour agoprevAnother good documentation choices is Racket’s scribble^1. I like that you can embed Racket code directly into the text, and the language oriented programming of Racket means the syntax is more ergonomic than other systems. There is also pollen^2 but that is more set up for online books by default 1. https://docs.racket-lang.org/scribble/ 2. https://docs.racket-lang.org/pollen/ reply taeric 39 minutes agoprevI dislike rST for how cumbersome it is with some of its markers. Trailing underscores, tons of dots, non-fenced sections, nested lists needing extra lines, etc.. It seems actively made to make it hard for me to read the source. Now, granted, I am clearly ok with fenced sections. And I love org-mode for most all things. reply thesnide 1 hour agoprevRst is technically vastly superior to MD. Yet I predict that MD will prevail. VHS style. I hugely prefer to write in RST, but as soon as I'm not alone we always switch to MD, given enough coworkers. reply 12_throw_away 1 hour agoparentYep, it seems like the platonic ideal of a \"worse is better\" situation. I do think this is, ironically, partly a documentation problem - when I last tried to create docs for a python codebase (several years ago), I found the rST docs to be sorely lacking in basic, introductory \"here are the core mental models for how this works\" sorts of content. Maybe the situation is better now? (Or maybe I just missed them, but not for lack of trying) But I feel like then, it's obvious README.md prevailed and will continue to be the standard - you can use markdown for a very long time without ever reading any documentation at all. Worse is better, I guess. reply bloopernova 1 hour agorootparentIn my opinion, I don't think it's \"worse\", just simpler. Plus it's more ubiquitous, supported by Github etc etc. Although Github may not be the best yardstick there, because they render documents written in Emacs' org-mode too! (which I very much appreciate, I prefer writing in org to writing in Markdown) I'm hoping that LLMs will make it more streamlined when documenting existing code. Not so much as a replacement for text written by experts, but in converting code into diagrams. LLMs or similar \"understand\" a codebase by tokenizing it (as is my understanding), so turning that into a nice documentation skeleton should be possible. reply runningmike 1 hour agoprevEverything you can do with rst can be done now with markdown. But easier and better. The toolchain is superb now. MyST extends Markdown for technical, scientific communication and publication - https://mystmd.org/ and use Jupyterbook, which builds upon spinhx. reply mmphosis 25 minutes agoprevI prefer What You See Is What You Get (WYSIWYG.) reply andrewflnr 9 minutes agoprev> ...Okay yeah that's actually a pretty good reason not to use it. I can't get into lisps for the same reason. I guess this is why he's not using Pollen, which is explicitly designed for this sort of thing, but based on Racket. I actually settled on rST for writing fiction manuscripts, I think because I actually liked the syntax? Maybe I just needed proper header support. I'm compiling to DOCX via pandoc, so I'm not using the extensibility in the slightest. Anyway, it's amusingly validating to see someone else use it for a similar job. reply bradboimler 38 minutes agoprevSure, for quick throwaway notes or messaging apps Markdown is fine. But if I'm gonna sit down and write a proper document? I prefer handcrafting HTML. reply prpl 2 hours agoprevSphinx + markdown (Myst) is a nice middle ground here I think, with the sphinx directives implemented as code blocks. reply skybrian 1 hour agoprevIt seems like Markdown works pretty well for writing API docs, where the language has a tool for generating documentation that also gets things like type signatures from the source code itself. The result of running that tool is always API documentation, so you might need something for docs that aren’t structured that way. reply blt 2 hours agoprevIf the author is here: Before the first code display, where you write: > Here's how to make an image in html: I think you meant \"markdown\" instead of \"html\". reply JoshTriplett 1 hour agoprevI do appreciate that reStructuredText is extensible and Markdown (currently) isn't. I don't think that's an argument that outweighs rST's verbosity. But I do think it's an excellent argument for adding a standard extension point to Markdown. reply meribold 1 hour agoprevWasn't reStructuredText the one where you can't make text a link if any of it is bold/italic/monospaced? IIRC, nesting of inline markup is generally not possible. It works in Markdown… reply hwayne 24 minutes agoparentYes, and this sucks. reply mjburgess 2 hours agoprevI believe the big selling point is supposed to be the directives syntax of rST. I had a similar need to extend markdown, but pandoc already supports directive syntax -- and so do some libraries, eg., the marked library, which I use to render MD as HTML in-browser rather than with pandoc. The iirc, syntax is :inline{property} and ::: block-directive {options} contents ::: It doesnt nest well, so I applied any document-level styles using the filename; but I'd imagine the yaml-style lead-in tags should be the correct way to do it. reply KronisLV 1 hour agoprevI like Markdown because it's simple and doesn't give me that many headaches. You know what I don't like? HTML, for user submitted content in particular. The mess I've seen, after someone opted for using HTML for messages in a system, because that's what JS based editors were available for at the time. Endless need to work against XSS, with more and more incremental updates needed to the sanitization logic, some of which broke the presentation of the data in the DB. Never again. Markdown, BBCode, anything but that. As for docs? Currently just some Markdown, because that's what GitHub, GitLab, Gitea and others all know how to render. Maybe something like https://www.mkdocs.org/ for the more standalone use cases. reply xixixao 1 hour agoprevThis is why MDX rocks. It doesn’t have all of this builtin, but you get a lot of the same benefits. reply bluGill 2 hours agoprevThe problem with RST is the same with everything else: it isn't supported everywhere. I wrote a bunch of nice RST documentation at work, the next month some company wide team announced a new standard for documentation (backstage) which is markdown based, and has all the problems of markdown. (In their defense I'm not aware of any tool that would compete with backstage for what we need in a company wide documentation system) reply f1shy 2 hours agoparentOne solution: https://pandoc.org/ Or “how I stopped caring about doc formats” reply Animats 1 hour agoprevIf you want all that extensibility, use TeX or something similar. Or write HTML yourself. Markdown was supposed to be simple. Yes, you can't do everything you can do in HTML. That's the point. reply insane_dreamer 1 hour agoprevI would say which is better depends on the use case. For note taking and most simple documents, Markdown wins hands down due to its readability and speed. For complex document sets where custom rendering may be required, rST+Sphinx is probably what you want. reply jasonpeacock 2 hours agoprevLemons vs limes. They're both markup languages, but they have different purposes. Yeah, using markdown to write a book is very limiting and doesn't offer the control needed for typesetting. OTOH, using markdown to write is liberating - you only get a few markup options, so you can focus on the content: [It is] notable that the Feynman lectures (3 volumes) write about all of physics in 1800 pages, using only 2 levels of hierarchical headings: chapters and A-level heads in the text. It also uses the methodology of sentences which then cumulate sequentially into paragraphs, rather than the grunts of bullet points. Undergraduate Caltech physics is very complicated material, but it didn’t require an elaborate hierarchy to organize. Edward Tufte, forum post, ‘Book design: advice and examples’ thread reply somat 1 hour agoprev\"markdown is a lightweight representation of html\" No, markdown is a set of standards around transforming a good looking text file into a rich format(this is usually html, but it does not have to be). The most important part about markdown is that it is a \"good looking text file\". If a markdown extension does not result in good looking text it has failed the one point of markdown. This is why markdown editors leave me confused, the whole point of markdown is to write a nice looking plain text document, if you are going to use a specialized editor why not use a better format? Note that markdown is a terrible document format, with only vague presentational cues and no semantic ones. it starts to suck real quick. However, it is a great idea if you want a good looking plaintext document. People understandably keep trying to \"fix\" markdown with better semantic options but these by and large miss the point of markdown leaving a ugly document. So RST may be the best thing since sliced bread, but it is not really in the same category as markdown, the plaintext for one is decidedly ugly. reply Ericson2314 1 hour agoparentSure, the markdown AST is its own thing, but no doubt its a isomorphic to an obvious subset of HTML and that's not a coincidence. Moreover, you are missing Hillel's second point, which is that there is nothing like an \"abstract node\" syntax which can be used for custom extensions. Lisp has (NAME ...) and XML has ..., and these are separate from the choice of NAME. (GitHub-flavored) Markdown's one extensible thing is ```NAME ``` but this isn't so useful because the inside is unstructured text (on purpose). You want a custom node which doesn't escape everything within, so you can have more regular or custom nodes on the inside. reply Morizero 1 hour agoprev> You just need a regex to transform it into . Is this what the author means by markdown being lightweight, since the inverse isn't true except trivially? reply psychoslave 2 hours agoprev>The most important difference between rst and markdown is that markdown is a lightweight representation of html, while rst is a midweight representation of an abstract documentation tree. Not really. Quoting https://en.wikipedia.org/wiki/Markdown >Its key design goal was readability, that the language be readable as-is, without looking like it has been marked up with tags or formatting instructions, unlike text formatted with 'heavier' markup languages, such as RTF, HTML, or even wikitext So, for use cases that don’t make a good match of this chief constraint, Markdown might not be the most relevant option. It’s just as meaningful as saying that we prefer TeX over Markdown because fine typographical tuning is an important concern of our specific usecase. I admit I already dealt with a screw using a hammer, not having the right toolset at hand. But when the situation don’t call for adhoc heterodox actions, I prefer to match a screwdriver with a screw and a hammer with a nail. reply westurner 14 minutes agoprevA Table of Contents instruction that works across all markdown implementations would be an accomplishment. OTOH, Markdown does not require newlines between list elements; which is more compact but limits the HTML that can be produced from the syntax. MyST Markdown adds Sphinx roles and directives to Markdown. nbsphinx adds docutils (RST) support back to Jupyter Notebooks. (IPython notebook originally supported RST and Markdown.) reply louwrentius 2 hours agoprevThe one-line summary is: > I think Restructured Text is better for writing books than Markdown. That would be a better title. reply osmarks 1 hour agoprevI solve this for my usecases with custom Markdown rendering which accepts a few new block elements (via a markdown-it plugin). https://github.com/osmarks/website/blob/master/src/index.js reply Ericson2314 1 hour agoprevI am proud to say this is might be the first time I finally agree with Hillel Wayne and something (at least mildly) controversial. reply Analemma_ 1 hour agoprevTo me rST targets such a narrow middle band of scenarios that I can't see any compelling reason to use it. For simple documents where Markdown is enough, I'll use that, and if I need more layout configuration and control I'll use LaTeX or HTML. What is rST for? reply IshKebab 1 hour agoprevI would strongly recommend using Asciidoc over Restructured Text. Even though Asciidoctor is written in Ruby which IMO is much worse than even Python, the actual RST codebase is a total incomprehensible mess. You can extend it with custom processing etc, but... fuck, I really want to never have to do that again. Asciidoc just seems to be much higher quality in general. reply jszymborski 1 hour agoparentI echo your sentiments, but sadly the Asciidoc python compiler (as far as I can tell) is deprecated and no longer supported. I think that leaves Asciidoctor as the only mature compiler. There's a spec being drafted, so hopefully that will spur some more action. For my purposes, Asciidoc is the best markup with the worst tooling, and Markdown is the worst markup with the best tooling. reply YakBizzarro 4 minutes agorootparentOh yes, I could mot agree more. We moved from Antora/asciidoc to mkdocs/markdown. Overall the situation improved (better HTML, faster builds, syntax highlighting of code,...) but I miss how good writing in asciidoc was reply FartinMowler 19 minutes agorootparentprevI run asciidoctor's Docker container. It does what I want it to do without leaving a mess behind on my laptop. reply 60secs 38 minutes agorootparentprevthe toc macro on asciidoc is sublime :table-caption!: :toc: macro :sectlinks: toc::[] reply IshKebab 8 minutes agorootparentprevYeah a nice Rust or Go-based implementation of Asciidoc would be fantastic. Having to deal with Ruby and Gems is not fun. That's a mountain of work though and even if there is a spec, at this point it's complex enough and the Ruby implementation is enough of a de facto spec that I'm doubtful you'll ever make it past \"this behaves differently to Asciidoctor\" territory. Btw a more recent alternative is https://github.com/jgm/djot which actually does have multiple implementations and looks like a way better option than Markdown, but maybe not as powerful as Asciidoctor still. I haven't tried it. reply betaby 2 hours agoprevasciidoc anyone? reply schaefer 1 hour agoparentI keep my journal in a blend of asciidoc and markdown. In asciidoc, I love xref soooo much, which lets you make cross-document links to .adoc files that still work after being translated to html. But I'm so sad that asciidoc isn't supported by pandoc. reply argonaut68 17 minutes agorootparent+1. My current workaround is the use of asciidoctor to convert my docs to docbook. This format is supported by pandoc. reply tristor 2 hours agoprevI use Markdown constantly, every single day, and I have tried multiple times to switch to RST and failed. Ultimately the reason Markdown works the best for me is that it gets out of my way. I can just type, I don't have to invest significant effort in formatting structures and can just write. This makes Markdown ideal for my primary use case, which is note-taking live during meetings, and because I already use it there, I also use it for writing blog posts, documentation, and most other document writing purposes. I will freely acknowledge RST is better for writing documentation and formal structured documentation, but the learning curve/barrier for RST is enough higher than Markdown, that it's not worth it for me to use both systems. reply RomanPushkin 1 hour agoprevNo offense, but when I downloaded a sample PDF I expected to see a better formatting. The file is little bit clunky. I think it's not a failure of a formatter, but the design in general. The default markdown formatter in Leanpub works good enough, to a degree when I don't need to think about it. So, while I understand all the good parts, I am still kinda not convinced it's a better option looking at the final product. reply hwayne 18 minutes agoparentNo offense taken! Sphinx gives a lot of options for customizing pdf formatting, but I'm not thinking about that just yet. Step one is to get the book's content done, step two is to revise the content, step three is to revise it again... Getting it to look good is on my list, but ultimately a problem for future me. reply paxys 1 hour agoprevIMO the most important feature of markdown is that any random person, whether they are technical or not or know what markdown is or not, can view markdown-formatted text and understand it perfectly fine. A UI layer added on top is nice to have, but not at all necessary. Most alternative formats miss that critical point. reply breck 2 hours agoprevHere is how you would do your image example in Scroll: rst: .. image:: example.jpg :alt: alttext scroll: image example.jpg caption alttext \"Directives\" in rST are \"Parsers\" in Scroll. The item above would be parsed by the `imageParser`, which at ~50 lines of code (https://github.com/breck7/scroll/blob/b8fd72aa38742cc6cd575f...), is actually more code than the average parser. To write your \"exercise extension\" in Scroll, you would just need to write a few lines of code definining an \"exerciseParser\". You could put that in the same file you use it in, or in a file named \"exercise.parsers\". I think you should explore Scroll -- https://scroll.pub/ -- might do everything you need in a simpler way! reply kelsey98765431 2 hours agoprevWhen you call a book v0.2 and say \"now with epub, get it here\" in the first line of your blog on why not to use the most popular of a thing, I am assuming we are going to be having a above board conversation about pros and cons, and I an receptive to your position. When the first link is also the second link, and both are to BUY a 15 dollar book with the default \"pay anything price\" bar set to 20, I am just clicking out and ignoring literally everything in your marketing post. Others can discuss this RST thing I have never heard about, I am just here to point out you have now alienated one of your potential converts. Put the book link at the bottom, and dont double link to the same purchase page in the same paragraph. FFS. reply nailer 54 minutes agoprev\"Now here's how to make an image in rst:\" .. image:: example.jpg :alt: alttext Great, I can close this article now. reply numlock86 2 hours agoprev> markdown is a lightweight representation of html Never before on an article I've felt the vibes of the \"I stopped reading there\"-meme harder than here. reply morbicer 2 hours agoprev [–] RST might be technologically superior but markdown is easy to write and has a huge ecosystem. For hobby usage, use whatever. But I would strongly oppose anyone who would try to make RST standard at my workplace. A scrum-master, PO or marketing can write markdown. RST would be a hard sell. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author has released \"Logic for Programmers v0.2,\" featuring epub support, constraint solving, and formal specification content.",
      "The author prefers reStructuredText (rST) over Markdown due to its superior customization and extensibility, particularly useful for complex documentation needs.",
      "A custom exercise extension in rST was created for the book to handle different rendering requirements for HTML, epub, and PDF formats."
    ],
    "commentSummary": [
      "reStructuredText (rST) is favored for technical books due to its extensibility and semantic capabilities, especially when combined with Sphinx.",
      "Markdown is simpler and more readable, making it ideal for quick notes and everyday documentation.",
      "rST's features like custom text objects and guaranteed internal link resolution are crucial for complex documentation projects, but Markdown's simplicity and support make it more popular for general use."
    ],
    "points": 172,
    "commentCount": 186,
    "retryCount": 0,
    "time": 1722440995
  },
  {
    "id": 41115619,
    "title": "Call of Duty: Warzone Caldera Data Set for Academic Use",
    "originLink": "https://blog.activision.com/activision/2024/activision-releases-call-of-duty-warzone-caldera-data-set",
    "originBody": "var curUrl = window.location.href; var isPrevOrStage = window.location.host.includes(\"stage\") || window.location.host.includes(\"preview\") || window.location.host.includes(\"test\"); var domain = isPrevOrStage ? \"s-dev\" : \"s\"; var siteId, fetchUrl; if(curUrl.includes(\"callofduty.com\") > 0) { siteId = \"cod\"; fetchUrl = \"https://profile.callofduty.com\" } else if(curUrl.includes(\"crashbandicoot.com\") > 0) {siteId = \"crash\"; fetchUrl = \"https://\" + domain + \".crashbandicoot.com\"; } else if(curUrl.includes(\"tonyhawkthegame.com\") > 0) { siteId = \"th\"; fetchUrl = \"https://\" + domain + \".tonyhawkthegame.com\"; } else if(curUrl.includes(\"sekirothegame.com\") > 0) { siteId = \"sekiro\"; fetchUrl = \"https://\" + domain + \".sekirothegame.com\"; } else if(curUrl.includes(\"activision.com\") > 0) { siteId = \"activision\"; fetchUrl = \"https://\" + domain + \".activision.com\"; } var OneTrust = { dataSubjectParams: {id: \"\",isAnonymous: false,token : \"\" }};function otGetCookie (cookieName) { var i = 0,cookies = document.cookie.split(\";\"),length = cookies.length,trimRegex = /^\\s+|\\s+$/g,cookiePair; for (; iresponse.json()) .then((json) => {OneTrust = { dataSubjectParams: {id: json.userId,isAnonymous: false,token : json.token }};console.log(\"OneTrust: \",OneTrust); }) .catch(error => { // Handle errors console.error('Fetch error:', error); });}window.addEventListener(\"OneTrustGroupsUpdated\", handleOneTrustGroupsUpdated);function handleOneTrustGroupsUpdated() { if(loggedIn) {var xsrfToken = otGetCookie(\"XSRF-TOKEN\"); var ssoCookieValue = otGetCookie(\"ACT_SSO_COOKIE\"); var headers = {'Cookie': \"ACT_SSO_COOKIE=\" + ssoCookieValue, 'X-XSRF-TOKEN': xsrfToken };fetch(fetchUrl + \"/\" + siteId + \"/regulations/onetrust/preferences?activeGroups=\" + OnetrustActiveGroups, {method: \"POST\",credentials: 'include',mode: 'cors',headers: headers}) .catch(error => { // Handle errors console.error('Fetch error:', error); }); }} var dataLayer = dataLayer || [], digitalData = {\"page\":{\"pageInfo\":{\"charSet\":\"UTF-8\",\"language\":\"EN\",\"country\":\"US\",\"site\":\"activision\",\"pageName\":\"activision:blog:activision:2024:activision-releases-call-of-duty-warzone-caldera-data-set\",\"siteSection\":\"web\",\"siteSubsection\":\"activision-releases-call-of-duty-warzone-caldera-data-set\"},\"pageCategory\":{\"primaryCategory\":\"base\",\"pageType\":\"sub category\",\"subCategory1\":\"en\"},\"targetEntity\":{\"locale\":\"en_US\",\"brand\":\"activision\",\"categoryId\":\"['base', 'base:en', 'activision:blog:activision:2024:activision-releases-call-of-duty-warzone-caldera-data-set']\",\"pageURL\":\"https://blog.activision.com/content/atvi/activision/atvi-touchui/web/en/blog/activision/2024/activision-releases-call-of-duty-warzone-caldera-data-set.html\",\"id\":\"activision-releases-call-of-duty-warzone-caldera-data-set\",\"name\":\"Activision Releases Call of Duty®: Warzone™ Caldera Data Set for Academic Use\"}}};(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-53WQ4Q4'); Activision Releases Call of Duty®: Warzone™ Caldera Data Set for Academic Use { \"@context\": \"http://schema.org\", \"@type\": \"VideoGame\", \"author\": { \"@type\": \"Organization\", \"name\": [\"\"] }, \"contentRating\": \"\", \"datePublished\": \"\", \"description\": \"\", \"gamePlatform\": [], \"genre\": [], \"image\": \"\", \"name\": \"\", \"contentLocation\": [],\"playMode\": [],\"isAccessibleForFree\": \"False\", \"inLanguage\": [ { \"@type\": \"Language\", \"name\": \"English\" } ], \"thumbnailUrl\": \"\", \"publisher\": { \"@type\": \"Organization\", \"name\": \"Activision Publishing\", \"sameAs\": [ \"http://www.activision.com\", \"https://www.youtube.com/user/ActivisionGames\", \"http://en.wikipedia.org/wiki/Activision\" ] }, \"applicationCategory\": \"Game\", \"operatingSystem\": [], \"url\": \"\", \"isPartOf\": { \"@type\":\"VideoGameSeries\", \"name\":\"\" } }var ATVI = ATVI || {},wcmmode; if (false) wcmmode = 'edit'; if (false) wcmmode = 'design'; if (!false && !false) wcmmode = ''; ATVI.pageMode = wcmmode; ATVI.pageEnv = ('blog.activision.com'.indexOf('cmsauthor') > -1) ? 'dev' : 'prod'; ATVI.pageLocale = 'en'; (function() { var winUrl = window.location.hostname,url = 'https://s.activision.com/resources/common/scripts/sso.bar.js',prev = 'https://s.activision.com/resources/common/scripts/sso.bar.js',stage = '',author = 'https://s.activision.com/resources/common/scripts/sso.bar.js',scriptTag = document.createElement('script'); if (winUrl.indexOf('preview.') > -1 || winUrl.indexOf('test.') > -1 && prev) url = prev; //switch between \"prev\" and \"url\" for support team. if (winUrl.indexOf('stage.') > -1 && stage) url = stage; if (winUrl.indexOf('cmsauthor') > -1 && author) url = author; scriptTag.setAttribute('src', url); scriptTag.id = 'sso-bar-script'; document.write(scriptTag.outerHTML); })(); var config = {containerId: 'cdo-bar', locale: 'en',cms: true, communityId: 'activision', customSupportPath: '' || null };(function() { var initSsoLibrary = function() { if (typeof SSO == \"object\") { window.ssobar = new SSO.Bar(config);} else {setTimeout(function() {initSsoLibrary(); }, 250); } }; initSsoLibrary();})();Activision Call of DutyCrash BandicootTony Hawk’s Pro SkaterSekiro: Shadows Die TwiceSpyro The DragonActivision Search SearchActivision Call of Duty Crash Bandicoot Tony Hawk’s Pro Skater Sekiro: Shadows Die Twice Spyro The Dragon Activision Search Go Back July 30, 2024 by Call of Duty StaffActivision Releases Call of Duty®: Warzone™ Caldera Data Set for Academic Use Access Call of Duty: Warzone Caldera OpenUSD Data Set Activision Releases Call of Duty®: Warzone™ Caldera Data Set for Academic UseAccess Call of Duty: Warzone Caldera OpenUSD Data SetJuly 30, 2024by Call of Duty Staff Announcing the Open-Source Caldera Map Release With a vision to expand the knowledge base of the gaming industry, Activision is excited to share the release of an open-source data set featuring the map Caldera from Call of Duty®: Warzone™ for non-commercial use. This first-of-its-kind data set release for Call of Duty, now available in OpenUSD, contains the near-complete geometry of Caldera as well as a collection of randomly selected anonymized time samples showing how players move around the map. This initiative represents Activision’s commitment to innovation and growth in multiple fields, including AI learning, within the communities of academia and research, while propelling the advancement of game development. It brings to life the colossal and carefully crafted map that was home to many epic brawls in Call of Duty: Warzone and is production-proven and battle-tested.Why Open-Source Matters In an era where AI training and the evolution of authoring tools are pivotal, the availability of production-proven maps is crucial. By releasing Caldera as an open-source asset for non-commercial use, the technology teams at Activision aim to empower developers and educators with high-quality, production-validated and accessible resources. This is about collaborating with the gaming and research community to build a foundation for responsible innovation and learning across the industry. A Resource for Education and Training Our commitment to open source goes beyond development; Activision envisions these assets as invaluable educational resources. Students, educators, and professionals can utilize Caldera for training, demonstrations, and experimentation. This initiative encourages learning and skill development within the gaming community and beyond. Supporting AI Development Open-source assets like Caldera play a vital role in the advancement of artificial intelligence. By providing a rich, diverse environment, we facilitate the training of AI models, enhancing the industry’s understanding of complex geometries and interactions. This can lead to more intelligent systems, paving the way for the next generation of gaming and simulation technologies. Evolving Authoring Tools The gaming industry is consistently evolving with new authoring tools emerging regularly. By contributing assets to the open-source community, the Activision technology teams encourage the development of robust tools that can handle complex geometries and environments. This collaborative approach will drive innovation, making it easier for developers to create immersive experiences. In a brief discussion with Activision’s Chief Technology Officer Natalya Tatarchuk and Senior Vice President, Fellow Software Engineer Michael Vance, the technology team details everything included in the set, the vision for the release, and how providing Caldera to academics and researchers can benefit the Call of Duty Community and positively impact the future of gaming. What is the size and scale of the Caldera Data Set? Michael Vance: The Call of Duty Data Set featuring Caldera represents an extensive, in terms of world-size, scene-graph depth and geometric complexity, production-quality map, used for multiplayer games in Call of Duty: Warzone. The release of this map represents one of the largest production-validated open data set releases from the gaming industry in terms of complexity of geometry and instance counts. It also is one of the largest publicly available OpenUSD data sets, providing an excellent test harness for OpenUSD itself. Natalya Tatarchuk: We, at Activision, believe that it’s important for the gaming industry to help foster growth and innovation within the industry, to help evolve authoring tools, as well as provide excellent data for AI training and evolution of content generation techniques, and we believe that this data set provides a unique benefit for these goals. The map's geometry data is approximately 4 GB but is comprised of more than five million meshes, 28 million primitives, and more than one-billion-point instances, which can also represent scene metadata such as volumes that we use for lighting processing. Its complexity is also a testament to the richness and detail that the team at Raven Software built, with help from Beenox, High Moon Studios, and the broader Call of Duty development teams. Besides the geometry representing the Caldera map, what other data did you include in this data set? Vance: We have also included in-game character pathing and time samples showing how players behave on the map. For instance, one of the sets shows the paths players take throughout a match. While we have not included specific visualizations of these, the data is easily accessible, allowing different ways to explore and visualize them. Why was Caldera selected as the map to release as part of this set? Vance: As our team looked through a variety of scenarios for the best data set, including multiple smaller multi-player maps, our priority was to choose a map that best represents the scale and complexity of our current design philosophy. It’s exciting for us to see Caldera continue to live on and help expand the games industry through academia and research. The hierarchical arrangement of the map also allows users to select sub-sections of the map to limit the scope of analysis or providing multiple smaller areas for comparison, which is useful in avoiding over-fitting issues by leaving other sections of the map for validation. What do academics and researchers typically do with data sets such as this? Tatarchuk: Researchers are constantly in search of data sets that represent the fullness and complexity of modern-day production data, which is difficult for them to approximate in a traditional academic setting. The computer graphics industry has a strong legacy of canonical data sets—some may be familiar with for example the Stanford bunny, Dabrovic Sponza, or more recently Disney’s Moana Island, or Animal Logic’s ALab. Each of these has become an important part of research in the broader graphics and gaming industries, fostering innovation in areas such as mesh simplification, deferred rendering, and other modern lighting and shading approaches. With the lack of available production data at this scale, Caldera provides researchers an opportunity to explore these types of sets with more rigor. What is your vision for what can come from the Caldera Data Set being released publicly? Tatarchuk: Activision is committed to continuously being innovative in technology and AI space to further the development of video games and to help drive the gaming community forward. Responsible innovation in AI technologies can help propel industry-wide development of video games forward in a way that creates richer gaming experiences for players in the future. One element of releasing Caldera is giving back to the community of research that has been so beneficial to the industry over the past decades. One of our goals is to broaden access to production data, allowing researchers to test their approaches in real-world scenarios, which will help accelerate the development of new solutions, as well as provide confidence that solutions can be deployed at production scale. We believe that Caldera’s release will be an impactful and material benefit to that effort. Vance: We are also interested in what new insights the research community will develop around object relationships, scene creation and editing, and other topics related to environmental construction with Caldera. The tabular data and metadata include providing opportunities for richer understanding of how players interact with the game, which can potentially lead to new insights on what makes specific layouts compelling for users. As we learn what the research and academic community finds useful in the set, we want to create an ongoing dialog with them so we can continuously make updates that are helpful. How can new technology or learnings from the Caldera Data Set benefit the Call of Duty community? Vance: While our game environments are already enormously complex, we feel a constant need to improve the play experience and deliver even more richness and detail. Innovations that come from this data set release could give more freedom and flexibility for our content teams to find the most engaging scenarios for our players. Insights into object relationships, procedural approaches to our world data, and other ideas could lead to more compact data representations on both disk and in memory. We are excited about what the academic community will produce based on Caldera and look forward to seeing new techniques that we could never have imagined. Join the Movement We believe that the industry can greatly benefit from more open-source contributions. Our motivation stems from a shared desire to inspire creativity and collaboration. We invite everyone—students, studios, vendors, partners, and beyond—to explore, utilize, and contribute to the further growth of our incredible industry. Download the Call of Duty Data Set Now Join us in this exciting journey and become part of a vibrant community dedicated to innovation, education, and collaboration. Together, let’s shape the future of gaming and beyond! © 2024 Activision Publishing, Inc. ACTIVISION, and CALL OF DUTY are trademarks of Activision Publishing, Inc. All other trademarks and trade names are the property of their respective owner Back to Top Activision.com SupportUnited States Selected region: United States Close Menu+United States United Kingdom English Canada Australia France Canada Français España México Portugal Activision Call of Duty Tony Hawk’s Pro Skater Spyro The Dragon Crash Bandicoot Sekiro: Shadows Die Twice Connect Facebook Twitter Instagram LinkedInLegal Terms of Use Privacy Policy Cookie Policy Cookie Settings© 2024 Activision Publishing, Inc. ACTIVISION, CALL OF DUTY, CALL OF DUTY BLACK OPS, CALL OF DUTY MODERN WARFARE, CALL OF DUTY BLACK OPS COLD WAR, CALL OF DUTY WARZONE, CALL OF DUTY: MOBILE, PRO SKATER, CRASH, CRASH BANDICOOT, SPYRO, SPYRO REIGNITED TRILOGY and SPYRO THE DRAGON are trademarks of Activision Publishing, Inc. TONY HAWK is a registered trademark of Tony Hawk, Inc. SEKIRO is a registered trademark of FromSoftware, Inc. All rights reserved. ESRB rating icons are registered trademarks of the Entertainment Software Association (ESA) and may not be used without permission of the ESA. All other trademarks and trade names are the properties of their respective owners. Activision makes no guarantees regarding the availability of online play or features and may modify or discontinue online services in its discretion without notice. The Software License and Service Agreement will be updated. Please follow this link [https://www.activision.com/legal/ap-eula] in order to see these changes.×Privacy Policy Update We’ve updated our Privacy Policy. You can view the revised policy here. By continuing to use Activision’s websites, products or services, you acknowledge this revised Privacy Policy. ×if (typeof _satellite !== 'undefined') { _satellite.pageBottom(); // Execute if _satellite exists }",
    "commentLink": "https://news.ycombinator.com/item?id=41115619",
    "commentBody": "Call of Duty: Warzone Caldera Data Set for Academic Use (activision.com)159 points by noch 17 hours agohidepastfavorite86 comments blopker 16 hours agoLink to the data is in a Github repo at the bottom: https://github.com/Activision/caldera Reading the article, they don't seem to know what people should do with it. It feels like a recruiting tool more than anything, especially given the non-commercial license. reply AHTERIX5000 12 hours agoparentIt's useful to have AAA tier sample game level assets available for engine development or for apps like Blender. reply bArray 2 hours agoparentprevFrom an information theory perspective, it should be possible to define strategically important locations in terms of Empowerment [1]. As a map designer there are likely some rough rules you want to abide by, such as roughly equal highly empowered locations throughout the map to reduce location bias. I remember an old game where they defined map rules in FPS CTF maps that there should be more than one path to each flag (usually three) and flag areas should be partially visible from one base to another. There were lots of rules like these, some more flexible than others. [1] https://arxiv.org/abs/1310.1863 reply SkyPuncher 15 hours agoparentprevAs an avid CoD player, I literally have no idea why this would be useful. Map data isn’t really interesting. The player data seems far too low of resolution to be meaningful. reply a_e_k 15 hours agorootparentThese sorts of data sets can be useful for graphics research, particular as a data set to test ray tracing algorithms on. See for example, the Moana Island data set. [1] I definitely foresee papers on BVH construction using this scene. For graphics research in academia, there's a dearth of real-world data sets like this, so the ones that do get released are gold. And for graphics research in industry, one may have access to good internal data sets for development and testing, but getting permission to publish anything with them tends to be a giant hassle. It's often easier to just use publicly available data sets. Plus, that makes it easier to compare results across papers. [1] https://www.disneyanimation.com/resources/moana-island-scene... reply modeless 12 hours agorootparentThe Moana island has complete material data though. This release seems to be only geometry. No materials or textures at all. reply a_e_k 9 hours agorootparentYep. That's still fine for building BVHs and shooting some rays around. reply SkyPuncher 4 hours agorootparentprevThank you for explaining that. Very helpful. reply minimaxir 15 hours agorootparentprevSince they provide player movement data, you can train a transformer to predict which player will win the BR given movement patterns. Or maybe create \"player embeddings\" to see if player behaviors can be clustered. That could be a fun project...but definitely not useful. Extracting and converting the player data from the .usd files would not be fun, though. reply krowek 3 hours agorootparent> Since they provide player movement data, you can train a transformer to predict which player will win the BR given movement patterns. You didn't consider the main factor for CoD - cheating. Which clearly seems to be an inside thing. Not sure if anything meaningful can be obtained by analyzing anything that has player data on it considering every video game out there is prone to this. reply refulgentis 3 hours agorootparentWhy would having player movement data help cheating? Why is the cheating clearly an insider thing? Why aren't you sure if anything meaningful can be derived from the movement data? What do you mean by \"prone to this\"? Are you sure they didn't consider \"cheating\" as a possible use of the movement data? Could they have considered it but thrown it away as off-topic and implausible? reply minimaxir 2 hours agorootparentThey are implying player teleporting, which is a common hack in BRs. Player movement data that is too fast for normal players could be seen as cheating. An AI isn't strictly needed for that, just check displacement over time. reply highcountess 14 hours agorootparentprevGiven all the other variables that introduce a bunch of noise to the player movement data, I doubt you could ever determine any useful predictive pattern. If anything though, I could see how player behavior of match winners could be used to both identify varying level of cheaters and players that use various methods for providing an advantage (i.e., keyboard mouse, joystick extensions, etc) and automatically sequester or even handicap their accounts. It appears to me that so much effort is placed on trying to identify and hamper cheaters in real time, when that both seems extremely resource intensive and unnecessary, considering you have all the digital evidence proof of cheating you need after the fact, you just have to understand what you are looking at. reply SkyPuncher 4 hours agorootparent> considering you have all the digital evidence proof of cheating you need after the fact, It's actually getting increasingly hard to tell. Old cheating use to be snap-to-the head type of cheating. The newer cheats work really hard to resemble natural players. Soft aim, intentionally missed shots, non-perfect recoil control. reply buran77 10 hours agorootparentprev> so much effort is placed on trying to identify and hamper cheaters in real time, when that both seems extremely resource intensive and unnecessary, considering you have all the digital evidence proof of cheating you need after the fact, you just have to understand what you are looking at It's not resource intensive at all compared to the alternative of ahaving humans doing post match reviews. It's all \"AI\" and automated reviews because it's cheaper. Half of the \"anti-cheat\" tactic is anyway using your computer resources to run some anti cheat tool. These games are optimized for revenue so every action is dictated by that. Including catching/banning cheaters. If it costs too much to do it properly, or (and this is actually plausible) cheaters are a significant enough portion of the already small chunk of players who create recurring revenue, then there's no incentive to take real action. This data is probably useful for actual academic rather than practical purposes today. They're building the knowledge they might want to use in a few years. reply amonon 5 hours agorootparentprev>Given all the other variables that introduce a bunch of noise to the player movement data, I doubt you could ever determine any useful predictive pattern. Predicting a winner will be difficult but I would not be surprised if you could loosely predict rank (does Warzone track player rank?) off of movement alone. You may be able to predict more accurately by looking at the associations between two players and their movement. From my prior experience in FPS games, positioning, awareness, and aim are the core pillars of success. Unfortunately as far as I can tell from the data set, only player position is tracked. reply Cthulhu_ 7 hours agorootparentprevIt sounds like this is simply not for you, then, and that's fine. reply 0cf8612b2e1e 15 hours agoparentprevIs there anything particularly novel about this vs the game map of a different FPS? reply bee_rider 14 hours agorootparentNot that it makes it novel, but this appears to be a “battle royale” map based on the picture shown in the post. So it is fairly large, for whatever that’s worth. The assumption with this type of game is that player will play the same big map over an over for the season (or something like that, changing the map is very rare, might not happen at all over the lifespan of the game), and but they can pick which part of the map they start in and explore from there. So it is, I guess, more similar to having data from all of the maps, for classic first person shooters. reply minimaxir 13 hours agorootparentSpecifically, during each play session, the map has a \"storm\" which converges on a random location over time: staying in the storm is lethal, so you are forced to eventually go to that location and points-of-interest along the way, which adds play variance. reply elabajaba 11 hours agorootparentprevOther fps game maps don't have licenses that let you use them to stress test your renderer or game engine. Existing freely available scenes are all too small and poorly made to be proper stress tests with modern hardware (eg. Old sponza is way too light, Intel sponza they just spammed the subdivision modifier to make it stupidly high poly, Bistro is small and really weirdly made, etc). reply aa_is_op 4 hours agoparentprevNot really, they released it primarily for artist training and tutorials. Getting hold of XXL gaming maps of this high-quality from a super popular game is definitely something that most game design training courses will use 100%. reply ackbar03 15 hours agoparentprevMake killer robots on the island of caldera reply bee_rider 14 hours agoprevEnemy AI has been pretty stagnant for the last couple decades, right? Can somebody use this to make less inhuman bots? reply IvanAchlaqullah 7 hours agoparent> less inhuman bots In games, player don't want AI that 100% strong (it's not fun), what we want is AI that make mistakes like human do. So it's possible (assuming if the datasets is good), in fact it's already done in chess[1]. > Maia’s goal is to play the human move — not necessarily the best move. As a result, Maia has a more human-like style than previous engines, matching moves played by human players in online games over 50% of the time. Also something that I just realized: in this particular case, we want the AI to be biased like human, which is easier to do since the bias is already in the datasets. AI safety is the exact opposite, which is harder if not impossible. [1] https://maiachess.com/ reply jncfhnb 3 hours agorootparentWe don’t even want that. Human like AI in a game like this would be really annoying for that vast majority of players that absolutely suck. People who want to play against AI generally want something that’s really dumb. reply bee_rider 1 hour agorootparentI think what people really want is a “human”-like AI that is worse than them, maybe quite a bit worse. But maybe not exactly what this type of dataset can offer. Which is to say: I want to play against an AI that is dumb enough for me to beat it, but is dumb in human-ish ways. Depending on the genre of the game, I want it to make the sort of mistakes that actual people make in wars, but more often. Or I might want it to make the types of mistakes that the baddies make in action movies. Human players in videogames might provide a little bit of a signal, but they do engage in a lot of game-y and not “realistic” movements, so point taken there. Some people are less familiar with games I think, so they tend to make less gamey movements. Anyone who’s been playing games since the 90’s will bounce around and circle strafe, so they need to be filtered out somehow, haha. Maybe they can provide training data for some sort of advanced “robot” enemy. But the existing AI characters also make some pretty non-human mistakes. Like often it seems that AI difficulty slider is just like: I’m going to stand stupidly in the middle of the road either way, but on easy I’ll spray bullets randomly around you, and in very hard I’ll zap you with lightning reflex headshots. Moves like examining a tree of possible movements, flanking, cover, better coordination, that sort of stuff would be more interesting. Maybe the player data-set can provide some of that? I’m actually not sure. As far as I can think, early Halo games and the FEAR series had be best AI. It’s been a while. Time to advance. reply jncfhnb 1 hour agorootparentYeah but the AI in the games you like was good because it was fun, not because they were circle strafing or doing movement mechanics that are explicitly effective but not realistic. Doing these things would make those AI much less fun as well as immersion breaking. reply cstejerean 3 hours agorootparentprevPlaying against an AI that's really dumb gets boring quickly. Playing against an AI that's way too good gets annoying quickly. I want an AI that can play like a human at my level would, such that the game is competitive and fun. reply jncfhnb 3 hours agorootparentYou probably don’t though. It’s actually really unfun to lose 50% of matches against an AI, or worse, because it doesn’t get tired or tilted or distracted. It’s much more fun to go against an AI that is dumber than you but generally more powerful. reply bathtub365 36 minutes agorootparentDifferent kinds of AI are likely fun for different players. Games have difficulty levels partly because not everyone wants the same level of difficulty relative to their own skill level. Some may want something easily beatable for them, some may want something difficult for them to beat. reply Levitz 3 hours agoparentprevThe problem regarding enemy AI is not lack of capability, it's that the market just doesn't care much. At the end of the day, when playing against the computer, you want to be a badass shooting baddies. The vast majority of the playerbase doesn't care enough about the baddies being able to bait and flank you, they just want to shoot the baddies and those who want a challenge find it in multiplayer anyway reply Cthulhu_ 7 hours agoparentprevI haven't paid attention to player-simulating bots in online shooters in forever, what are the current issues? I'd argue that players are a bigger issue, e.g. cheaters, big skill gaps, or the fact they keep shooting at me. There's singleplayer games, but those are intended to be gameplay challenges, not simulate other players. And in that area, I haven't heard any \"this is really good\" since F.E.A.R. which is nearly 20 years old now. reply TeaBrain 2 hours agorootparentThe original F.E.A.R. also still remains the game that has most impressed me with the enemy behavior patterns. reply chrishare 9 hours agoparentprevI wonder what that would look like for the twitch shooter genre? reply 2OEH8eoCRo0 8 hours agoprevVery cool. Does anyone remember how Bungie would release heatmaps and other data for each Halo match? reply aubanel 3 hours agoprevGreat, now I can finally find the top 5 hiding places for these friggin campers! reply dagmx 7 hours agoprevA lot of the comments here are very cynical, perhaps because they’re focused on the license or the use for gaming. However as someone in the graphics community, these kinds of assets are great for researchers and demo purposes. Other scenes like this are the Disney Moana Island, Intels Moore Lane house, Sponza, various NVIDIA scenes, Amazons bistro, and animal logics Alab2 scene. Khronos also maintains a set of test assets for the same purpose with glTF. When we develop content creation applications, they’re great for benchmarking ingest and making sure we have good feature coverage. They’re great for graphics researchers to have shared bases for data processing, rendering and other important R&D. The non-commercial aspect just means you can’t use them for commercial marketing, but they’re hugely beneficial for any kind of graphics research. Having real production quality data is a huge undertaking for researchers to do in addition to their own novel work. Thus far, many sample assets have been simple standalone assets, film quality production assets, or archvis. Activision releasing something from a AAA game is a huge boon for people targeting that market. I’ll also call attention to Natalya being involved. She’s recently joined Activision as CTO , but has been a very influential graphics engineer with a long and storied career before that. She has long helped run the excellent Advances in Real-time Rendering courses at SIGGRAPH (https://advances.realtimerendering.com/) and I believe this release comes from the same intention of mutually advancing shared knowledge. reply ghawr 2 hours agoparentAre there similar data sets for video & audio assets? reply jchw 16 hours agoprevYet again the word \"open source\" is being used in a way that doesn't make any sense. We're going to wind up with a weird situation where \"open source\" means \"free and open source\" for software specifically but just means \"available free-of-charge\" for data and ML model weights. Which is strange. The word \"free\" is right there. This is not \"source code\", and it certainly isn't \"open source\" even if it was. I know this is a tangent, but unfortunately it bears repeating. reply bogwog 5 hours agoparentThese files are source assets, which is as close to source code as you can get with non-code stuff. For regular people who didn't drink the OSI koolaid, this is a perfectly valid and logical use of the term \"open source\". I don't know if that's the angle you're coming from, or if you just didn't know what usd was, but either way this is a good release. reply hgs3 14 hours agoparentprevRight or wrong licensing source code separately from data isn't a new thing. I can think of some very famous video games that have released their source code under a Free Software license, but kept the game data proprietary. According to the FSF there is a separation between data and code [1] (search for \"data\" on that page). They specifically say that data inputted or outputted by a program isn't affected by the programs license which indicates a separation from their perspective. [1] https://www.gnu.org/licenses/gpl-faq.en.html reply wasmitnetzen 10 hours agorootparentFor any given data, it can be used as code, and vice versa. But for any given program, it should be very clear what's code and what's data. If I send a Python file over SSH, it should most definitely be data for all software involved. And I for sure should be able to send a Python file via OpenSSH, not matter what either is licensed as. reply userbinator 14 hours agorootparentprevAccording to the FSF there is a separation between data and code Which of course is a complete denial of the reality. Code is data, and data is code. That duality is the crucial reason why general-purpose computers are so powerful. The only ones to profit from trying to make a distinction, as usual, are the lawyers and corporations behind them who seek to restrict instead of empower. Especially in this era when decompilers are close to \"perfect\" (and can sometimes even be better than reading the original source code!), and with the rise of AI, IMHO the whole idea of \"source code\" being somehow more special than the executable binary is quickly losing relevance. reply nolist_policy 13 hours agorootparentdecompilers are close to \"perfect\" (and can sometimes even be better than reading the original source code!) Citation needed. reply userbinator 5 hours agorootparentPersonal experience. There is a lot of decompiler research which isn't public. A sibling comment mentions Hex-Rays and Ghidra. Those are only now slowly approaching the capabilities of what I've used. The fact that the majority of code tends to not be intentionally obfuscated and is compiler-generated and thus easily pattern-matched also makes it quite straightforward. Of course the fact that decompilers are often used on code that is (e.g. malware, DRM) skews a lot of people's perceptions. reply jchw 3 hours agorootparentJust to be completely clear, the conditions I have been using Ghidra/Hex-Rays/BN with were not that bad. I wasn't analyzing malware or heavily-DRM'd software. Even with symbols and full debug info, many of those gripes still apply. (Hex-Rays is able to do a lot more with debug info. It can usually get a lot of the vtable indirections typed correctly, including with a bit of effort, multi-inheritance offset this pointers.) I'd love to see this non-public decompiler research but I have some skepticism, as a lot of the information that is lost would require domain-specific reconstruction to get back to anywhere near full fidelity. I do not deny that you have seen impressive results that I have not, but I really do wonder if the results are as generalizable as you're making it sound. That sounds like quite a breakthrough that I don't think Ghidra or IDA are slowly approaching. But since it's non-public, I suppose I'll just have to take you at your word. I'll be looking forward to it some day. reply mplewis9z 12 hours agorootparentprevI have definitely read some teammates’ code that felt like it would be more readable doing a compiler-decompiler round-trip. Never actually did it, but I doubt it would be less readable than that seemingly intentionally obfuscated garbage. reply InDubioProRubio 3 hours agorootparentCant want for the jetbrains \"deabstract\" plugin, that compiles it, decompiles it and reconstructs a indirection free AST and then cleaner code from that AST via AI. De-Tech-Bro-My-Code. Pull the plug on all-the-patterns in one project devs and get cleaner code today. Refactor> ThrowIt> IntoTheBin reply jchw 8 hours agorootparentprev> Especially in this era when decompilers are close to \"perfect\" (and can sometimes even be better than reading the original source code!) As someone who is knee-deep in a few hobby reverse engineering projects, I certainly wish this was the case :) Hex-Rays and Ghidra both do a very commendable job, but when it comes to compiled languages, it is almost never better than reading the original source code. Even the easier parts of reversing C++ binaries still aren't fully automated; nothing that I'm aware of is going to automatically pull your vtables and start inferring class hierarchies. Variable names are lost in executable code. When it comes to naming variables, most of the tools support working backwards from \"known\" API calls to infer decent function names, but only Binary Ninja offers a novel approach to providing variable names. They have an LLM service called Sidekick which offers suggestions to improve the analysis, including naming variables. Of course, it isn't very impressive if you were to just drop into a random function in a random binary where you have no annotations and no debug information. Most of the \"framework\" stuff that compiles down, by some form of metaprogramming, is nearly non-sense and requires you to know the inner workings of the frameworks that you're touching. In my case I spend a lot of time on Win32 binaries, so the tricky things I see often are a result of libraries like MFC/ATL/WTL/etc. And I'll grant you that in some cases the original source code wouldn't exactly be the most scrutable thing in the world, but I'd still really rather have the MFC message handler mapping in its original form :) COM becomes a complete mess as its all vtable-indirected and there's just no good way for a decompiler to know which vtable(s) or (to some degree) the function signatures of the vtable slots, so you have to determine this by hand. Vectorized code is also a nightmare. Even if the code was originally written using intrinsics, you are probably better off sticking to the graph view in the disassembly. Hex-Rays did improve this somewhat but last I checked it still struggled to actually get all the way through. The truth is that the main benefit of the decompiler view in IDA/Ghidra/etc. is actually the control flow reconstruction. The control flow reconstruction makes it vastly easier to read than even the best graph view implementation, for me. And this, too, is not perfect. Switch statements that compile down to jump tables tend to be reconstructed correctly, but many switch statements decompile down to a binary tree of conditionals; this is the case a lot of the time for Win32 WndProc functions, presumably because the WM_* values are almost always too sparse to be efficient for a jump table. So I'd much rather have the original source code, even for that. Of course it depends a bit on the target. C code on ELF platforms probably yields better results if I had to guess, due to the global offset table and lack of indirection in C code. Objective C is probably even better. And I know for a fact that Java and C# \"decompiling\" is basically full fidelity, since the bytecode is just a lot less far away from the source code. But in practice, I would say we're a number of major breakthroughs away from this statement in general not being a massive hyperbole. (I'm not complaining either. Hex-Rays/Ghidra/BN/etc. are all amazing tools that I'm happy to have at my disposal. It's just... man. I wish. I really wish.) reply fxd123 15 hours agoparentprevThe repo contains some source code, so therefore it's open source reply captainhorst 6 hours agoparentprevThe map data is provided in the USD format which is a 3D authoring and interchange format that can be used with a lot of software. Unlike the final optimized data used by the game this doesn't require revere engineering and can be seen as source data that is in fact useful for graphics researchers and game developers. reply blitzar 13 hours agoparentprevThe phrase \"open source\" is itself open source and is freely available for use, modification and redistribution. reply insomniacity 13 hours agorootparentNot exactly - https://opensource.stackexchange.com/a/8369 reply fragmede 12 hours agorootparentprevOpen Source, with the capitals, however, is not, and is a trademark of the Open Source Initiative (OSI). https://opensource.org/trademark-guidelines reply insane_dreamer 11 hours agorootparentNo, it's not. From the page you linked to: > OSI, Open Source Initiative, and OSI logo (“OSI Logo”), either separately or in combination, are hereinafter referred to as “OSI Trademarks” and are trademarks of the Open Source Initiative. reply bee_rider 14 hours agoparentprevI’m confused as to why the convention isn’t to consider ML weights data-sets instead of any type of code (closed or open). reply jncfhnb 3 hours agorootparentModel weights are functions. In the same way `lambda x: x > 0.25` is a function. reply dkersten 14 hours agoparentprevThe article claims it’s open source (which it clearly isn’t, especially since they say things like “open source for non-commercial use” which is a bit of a contradiction), but the GitHub makes no such claim only stating that the OpenUSD format is open source. reply ssss11 15 hours agoparentprevFeels like a covert way to destroy the term “open source” by making it meaningless over time. reply WheatMillington 15 hours agorootparentYes it's all one big conspiracy. reply 01HNNWZ0MV43FF 15 hours agorootparentNo, it's a Schelling point but evil reply highcountess 13 hours agorootparentprevI find it rather odd that after all the years of exposed and revealed conspiracies too numerous and pervasive to even necessitate listing any of them, people like you just reject the notion that any additional, unknown conspiracies may exist. It is an odd phenomenon among humans that I at least don’t quite understand, the seeming tendency to ignore or dismiss possibilities of proven negative outcomes … for whatever reason. “I know all those other conspiracies I dismissed all turned out to be true, but I am sure I would know if there were any additional conspiracies” … totally ignoring one’s track record. It appears to be the same kind of mentality of “hey, you know who we should trust with our lives … the government made up of people who lie to us, steal from us, and mass murder on a regular basis; that’s who we should give control over to.” People conspire, I’ve witnessed it personally numerous times; sometimes for greedy business reasons, at other times to mass murder and commit genocide on a scale not seen since. Humans conspire, even if sometimes only because they’re not prevented from doing so naturally. reply ssss11 9 hours agorootparentIt’s probably convenient for them to dismiss this as it aligns with whatever goals they have.. reply jncfhnb 16 hours agoparentprevML weights are code reply jchw 16 hours agorootparentI'll accept that if you would like. However, they are not source code if so. They are object code. And open source is about source code, not object code. (And this particular press release isn't about ML weights anyways, at least unless I'm grossly misunderstanding; it is just a dataset. So even failing this, it still doesn't really make any sense.) reply jncfhnb 15 hours agorootparentNo it is not object code unless you want to get so stupidly pedantic that you want to argue a Python script in a zip file can’t be considered open source because it’s compressed. The model pickles unpack back to their original form. The picked binary forms are merely for convenience. reply jchw 9 hours agorootparentLook, please go do research as to what \"object code\" and \"source code\" are before saying my argument is \"stupidly pedantic\". I'm not elaborating because the example you gave has nothing to do with what I said. reply jncfhnb 6 hours agorootparentYour analogy does not make sense. ML weights are distributed in binary form, like object code, but it is nothing like compiled binary. It’s just temporarily in binary form for convenience. It unpacks directly into its original form. This is not a technicality like “technically up can reverse engineer or modify binary code”. The binary form of model weights is just a fancy zip file format that is useful because they are so large that text is impractical. reply jchw 3 hours agorootparentSource code is human readable. Object code is not, and produced from some mechanical process. Model weights are not written by hand. You don't manually tweak individual weights. You have to run a training process that has multiple \"raw\" inputs. Trying to read model weights directly is no better than trying to read object code directly. Heck, reading object code directly is probably easier, because at least it's just machine code at the bottom; I will never be able to comprehend what's going on in an ML model just by reading the weights. The closest thing to \"source code\" in ML models would be the inputs to the training process, because that's the \"source\" of the model weights that pops out the other end. If the analogy doesn't make sense, that's because ML models are probably not really code in the same sense that source code and object code. (It may be tempting to look at \"ML weights\" as source code because of the existence of \"closed-weight\" API services. Please consider the following: If Amazon offers me a unique database service that I can only use with Amazon Web Services, and then releases a closed-source binary that you can run locally, that is still closed-source, because you don't have the source code.) reply jncfhnb 2 hours agorootparent“Human readable” is not a requirement. Visual programming code breaks down to some obtuse data structure. But with the right tools, it’s easy for humans to interact with it. Visual programming node workflows can be open sourced. ML models are the same. Tooling is required to interact with it. The limits of your human understanding do not determine if something is open source. Otherwise a really complicated traditional program might be argued as not open source. You can individually explore specific vectors and layers of a model and their significance. Produced by a non mechanistic process is not a requirement. I can generate a hello world script with code, and open source the hello world script. It does not matter how it was formed. I do not need to open source the hello world generator either. Data and training code is not source code of the model. That is the source code of a model maker. That’s `make_hello_world.py` not `hello_world.py` The closed source database is not a correct analogy. Excluding unreasonably difficult efforts to decompile the binary, you CANNOT modify the program without expecting it to break. With an ML model, the weights are the PREFERRED method of modifying the program. You do NOT want the original data and training code. That will just be a huge expense to get you what you already have. If you want the model to be different, you take the model weights and change them. Not recreate them differently from scratch. Which is the same for all traditional code. Open source does not mean I provide you with the design documents and testing feedback to demonstrate how the code base got created. It means you get the code base. Recreating the codebase is not something we think about because it doesn’t make sense because we have the code and we have the models. reply jchw 1 hour agorootparentHuman readable is a requirement. The existence of things that don't fit into this paradigm doesn't invalidate it entirely, it just proves that it is imperfect. However, it being imperfect does not mean that 1 + 1 != 2. Semantics debates don't grant you the power to just invalidate the entire purpose of words. What you are proving repeatedly is that model weights are not code, not that they are \"source\" code. - The existence (barely, btw) of visual programming does not prove that model weights are code. It proves that there are forms of code other than source code that are useful to humans. There are not really forms of model weights that are directly useful to humans. I can't open any set of model weights in some software and get a useful visualization of what's going on. It's not source code. (Any visual programming language can output some useful human readable equivalent if it wants to. For some of them, the actual on-disk format is in fact human-readable source code.) (A key point here: if you write assembly code, it's source code. If you assemble it, it's object code. This already stresses the paradigm a bit, because disassembly is reversible... but it's only reversible to some degree. You lose macros, labels, and other details that may not be possible to recover. Even if it was almost entirely reversible though, that doesn't mean that object code is source code. It just means that you can convert the object code into meaningful source code, which is not normally the case, but sometimes it is.) - The existence of fine-tuning doesn't have anything to do with source code versus object code. Bytecode is easy to modify. Minecraft is closed source but the modding community has absolutely no trouble modifying it to do literally anything without almost any reverse engineering effort. This is a reflection of how much information is lost during the compilation process, which is a lot more for most AOT-compiled languages (where you lose almost all symbols, relocations, variable and class names, etc.) than it is for some other languages (and it's not even split on that paradigm, either; completely AOT languages can still lose less information depending on a lot of factors.) The mechanical process of producing model weights loses some information too; in some models, you can even produce models that are less suitable for fine-tuning (by pruning them and removing meta information that is useful for training). A closer analogy here would be closed source with or without symbols. reply jncfhnb 1 hour agorootparent> Human readable is a requirement. The existence of things that don't fit into this paradigm doesn't invalidate it entirely, it just proves that it is imperfect. However, it being imperfect does not mean that 1 + 1 = 2. Semantics debates don't grant you the power to just invalidate the entire purpose of words. well first of all, 1+1 does actually equal 2 Secondly, contradictions to your supposed hard rules absolutely means you don’t have hard rules. If you want to play the semantic game of saying words can mean whatever you want them to mean then sure. But then that’s pointless and you’re just saying you just want to be stubborn. > I can't open any set of model weights in some software and get a useful visualization of what's going on. It's not source code. Yes you can. Do you actually have any experience with what you’re talking about? This is a huge red flag that you do not. Your Minecraft example is a straw man. I did not claim that the existence of fine tuning meant models are source code. I claimed that because fine tuning models is the preferred form of modifying models means that it meets the definitional requirement of being called open source. Minecraft can be modified, but it is not the preferred form to do so, so it is not open source. You are still failing to address helloworldmaker vs hello world. Helloworldmaker is explicitly not the source code of hello world. Model maker is not the source code of model. Appealing to your own lack of capabilities to understand something doesn’t make it not source code. reply jchw 1 hour agorootparent> well first of all, 1+1 does actually equal 2 Sigh. That's a typo. I almost feel like it's not important to fix it considering that it's pretty obvious what I meant, but alas. > Secondly, contradictions to your supposed hard rules absolutely means you don’t have hard rules. If you want to play the semantic game of saying words can mean whatever you want them to mean then sure. But then that’s pointless and you’re just saying you just want to be stubborn. The \"semantics game\" I'm using is the long-understood definition of the term 'source code'. American Heritage® Dictionary of the English Language, 5th Edition: > source code, noun > 1. Code written by a programmer in a high-level language and readable by people but not computers. Source code must be converted to object code or machine language before a computer can read or execute the program. > 2. Human-readable instructions in a programming language, to be transformed into machine instructions by a compiler, assembler or other translator, or to be carried out directly by an interpreter. > 3. Program instructions written as an ASCII text file; must be translated by a compiler or interpreter or assembler into the object code for a particular computer before execution. Oxford Languages via Google: > source code /ˈsôrs ˌkōd/ > noun: source code; plural noun: source codes; noun: sourcecode; plural noun: sourcecodes > a text listing of commands to be compiled or assembled into an executable computer program. Merriam-Webster: > source code, noun > : a computer program in its original programming language (such as FORTRAN or C) before translation into object code usually by a compiler Wikipedia: > In computing, source code, or simply code or source, is a plain text computer program written in a programming language. A programmer writes the human readable source code to control the behavior of a computer. So every source pretty much agrees. Merriam-Webster falls short of actually specifying that it must be \"human readable\", but all of them specify in enough detail that you can say with certainty that ML model weights simply don't come anywhere near the definition of source code. It's just not even close. > Yes you can. Do you actually have any experience with what you’re talking about? This is a huge red flag that you do not. I'm trying to be patient but having to explain things in such verbosity that you actually understand what I'm trying to say is so tiring that it should be a violation of the Hacker News guidelines. YES, I am aware that tools which can input model weights and visualize them exist. NO, that doesn't mean that what you see is useful the way that a visual programming language is. You can not \"see\" the logic of model weights. This is the cornerstone of an entire huge problem with AI models in the first place: they're inherently opaque. (P.S.: I will grant you that escalating my tone here is not productive, but this arguing goes nowhere if you're just going to take the weakest interpretation of everything I say and run with it. I have sincerely not been doing the same for you. I accepted early on that one could argue that model weights could be considered \"code\" even though I disagree with it, because there's absolutely zero ambiguity as to whether or not it's \"source code\", and yet here we are, several more comments deep and the point nowhere to be found.) > Your Minecraft example is a straw man. I did not claim that the existence of fine tuning meant models are source code. I claimed that because fine tuning models is the preferred form of modifying models means that it meets the definitional requirement of being called open source. First of all, to be called \"open source\", it first needs to meet the definition of being \"source code\". That's what the \"source\" part of \"open source\" means. Secondly, to be called \"open source\", it also needs to meet the definition of being \"open\". That's the \"open\" part of open source. Open-weight models that have actual open source licenses attached to them do meet the criteria for \"open\", but many models, like Meta's recent releases, do not. They have non-commercial licenses that don't even come close to meeting the requirements. > Minecraft can be modified, but it is not the preferred form to do so, so it is not open source. Whether or not source code is the preferred form to modify something is entirely beside the point. I'm not sure where you got this, but it's simply wrong. Please stop spreading blatant misinformation. > You are still failing to address helloworldmaker vs hello world. Helloworldmaker is explicitly not the source code of hello world. Model maker is not the source code of model. I'm not addressing it because it's not 100% agreed upon. If you read my above definitions, you will see that in some of them, the results of \"Helloworldmaker\" will qualify as source code, and in some of them, it wouldn't. Likewise, you can compile any Wasm blob down to C code, and I'd strongly argue that the resulting C code is not human readable source code, it's just in a programming language. This definition, though, has a degree of fallibility to it. Unfortunately, a rigid set of logic can not determine what should be considered source code. That's OK though, because it actually has nothing to do with whether or not model weights are source code. They don't even come remotely close to anything resembling source code in this entire debate. Model training doesn't produce human-readable source code, it produces model weights, a bunch of data that is, on its own, not even particularly useful, less readable. > Appealing to your own lack of capabilities to understand something doesn’t make it not source code. With all due respect, I am not concerned about your judgement of my capabilities. (And it has nothing to do with this anyways. This is a pretty weak jab.) reply shevis 16 hours agorootparentprevNo, they really aren’t and I’m not sure why I keep seeing this take. ML weights are binary and it’s painfully obvious. They are the end result of a compilation process in which the training data and model code are compiled into the resulting weights. If you can’t even theoretically recreate the weights on your own hardware it isn’t open source. reply jncfhnb 15 hours agorootparentML weights are not binary. They are modifiable. If produce a program that outputs a hello world file, I can open source the hello world script without open sourcing the hello world generator. reply i_read_news 15 hours agorootparentprevWe can also say binaries are code, but if we are being pedantic that likely isn’t the source code that generated the binary (I also doubt the intention of hand writing binary or manually inputting billions of weights). I’d reckon that’s why it’s called open source, not open code or open binary, as the source code that generates the data is distributed. I’d actually just call this for what it is - open weights. reply jncfhnb 15 hours agorootparentBinary is not the equivalent of models. Source code is the equivalent of models. It doesn’t matter if a machine generated source code or a human did for it to be open source code. reply EnigmaFlare 12 hours agorootparentYou keep asserting this but without any reason. Do you have a reason? It seems to go against the general open source idea of source code being convenient for people to modify. reply jncfhnb 6 hours agorootparentML weights ARE convenient for people to modify. You can go look at the dozens of modifications of diffusion models being produced, daily, on civit ai. It’s very easy. reply kennyadam 15 hours agorootparentprevTechnically, but it feels like you're intentionally missing the point being made. Sure, providing the weights is very useful given the cost of generating them, but you can't exactly learn much by looking through the 'code', make changes and gain an in-depth understanding in the same way you can from the code provided by an actual open source project. reply jncfhnb 15 hours agorootparentYou absolutely can and people do all the time. There are mountains of forks and dissections and improvements on open source models. reply Takennickname 14 hours agoprev [–] \"Find us an AI use case that we can then turn around and market without compensating you for it you researching piece of shit. Sincerely, Activision\" reply rasz 10 hours agoparent [–] Player movement data can be used to build aimbot with undetectable lifelike movement. Thanks Activision! reply reportgunner 8 hours agorootparent [–] This is not even necessary since current cheaters seemingly can't be detected anyway. reply bogwog 5 hours agorootparent [–] I wonder if the data includes information about which players were banned for cheating? That could open the door to new research into cheat detection. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Activision has released a Call of Duty®: Warzone™ Caldera data set for academic use, as indicated by the page metadata.",
      "The release is significant for researchers and academics interested in game data analysis and could foster new studies and insights in the gaming industry.",
      "The data set is accessible through Activision's blog, highlighting the company's support for academic research and data transparency."
    ],
    "commentSummary": [
      "Activision has released a Call of Duty: Warzone Caldera data set for academic use on GitHub, including game level assets and player movement data.",
      "The data set is useful for graphics research, engine development, defining strategic locations, and testing ray tracing algorithms, with potential applications in AI development and cheat detection.",
      "The release is viewed as beneficial for academic and research purposes, though some see it as a recruiting tool due to its non-commercial license."
    ],
    "points": 159,
    "commentCount": 86,
    "retryCount": 0,
    "time": 1722387969
  },
  {
    "id": 41114601,
    "title": "Building static binaries with Go on Linux",
    "originLink": "https://eli.thegreenplace.net/2024/building-static-binaries-with-go-on-linux/",
    "originBody": "Building static binaries with Go on Linux July 30, 2024 at 14:35 Tags Go , Compilation , Linkers and Loaders , Linux One of Go's advantages is being able to produce statically-linked binaries [1]. This doesn't mean that Go always produces such binaries by default, however; in some scenarios it requires extra work to make this happen. Specifics here are OS-dependent; here we focus on Unix systems. Basics - hello world This post goes over a series of experiments: we take simple programs and use go build to produce binaries on a Linux machine. We then examine whether the produced binary is statically or dynamically linked. The first example is a simple \"hello, world\": package main import \"fmt\" func main() { fmt.Println(\"hello world\") } After building it with go build, we get a binary. There are a few ways on Linux to determine whether a binary is statically or dynamically linked. One is the file tool: $ file ./helloworld helloworld: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), statically linked, Go BuildID=Flm7stIXKLPfvBhTgXmR/PPwdjFUEkc9NCSPRC7io/PofU_qoulSqJ0Ktvgx5g/eQXbAL15zCEIXOBSPZgY, with debug_info, not stripped You can see it says \"statically linked\". Another way is to use ldd, which prints the shared object dependencies of a given binary: $ ldd ./helloworld not a dynamic executable Alternatively, we can also use the ubiquitous nm tool, asking it to list the undefined symbols in a binary (these are symbols the binary expects the dynamic linker to provide at run-time from shared objects): $ nm -u ./helloworldAll of these tell us that a simple helloworld is a statically-linked binary. Throughout the post I'll mostly be using ldd (out of habit), but you can use any approach you like. DNS and user groups There are two pieces of functionality the Go standard library defers to the system's libc on Unix machines, when some conditions are met. When cgo is enabled (as it often - but not always - is on Unix machines), Go will call the C library for DNS lookups in the net package and for user and group ID lookups in the os/user package. Let's observe this with an experiment: package main import ( \"fmt\" \"net\" ) func main() { fmt.Println(net.LookupHost(\"go.dev\")) } If we build this program, we notice it's dynamically linked, expecting to load a libc shared object at run-time: $ go build lookuphost.go $ ldd ./lookuphost linux-vdso.so.1 (0x00007b50cb22a000) libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007b50cae00000) /lib64/ld-linux-x86-64.so.2 (0x00007b50cb22c000) This is explained in the net package documentation in some detail. The Go standard library does have a pure Go implementation of this functionality (although it may lack some advanced features). We can ask the toolchain to use it in a couple of ways. First, we can set the netgo build tag: $ go build -tags netgo lookuphost.go $ ldd ./lookuphost not a dynamic executable Second, we can disable cgo entirely with the CGO_ENABLED env var. This env var is usually on by default on Unix systems: $ go env CGO_ENABLED 1 If we disable it explicitly for our build, we'll get a static binary again: $ CGO_ENABLED=0 go build lookuphost.go $ ldd ./lookuphost not a dynamic executable Similarly, some of the functionality of the os/user package uses libc by default. Here's an example: package main import ( \"encoding/json\" \"log\" \"os\" \"os/user\" ) func main() { user, err := user.Lookup(\"bob\") if err != nil { log.Fatal(err) } je := json.NewEncoder(os.Stdout) je.Encode(user) } This produces a dynamically-linked binary: $ go build userlookup.go $ ldd ./userlookup linux-vdso.so.1 (0x0000708301084000) libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x0000708300e00000) /lib64/ld-linux-x86-64.so.2 (0x0000708301086000) As with net, we can ask the Go toolchain to use the pure Go implementation of this user lookup functionality. The build tag for this is osusergo: $ go build -tags osusergo userlookup.go $ ldd ./userlookup not a dynamic executable Or, we can disable cgo: $ CGO_ENABLED=0 go build userlookup.go $ ldd ./userlookup not a dynamic executable Linking C into our go binary We've seen that the standard library has some functionality that may require dynamic linking by default, but this is relatively easy to override. What happens when we actually have C code as part of our Go program, though? Go supports C extensions and FFI using cgo. For example: package main // #include// void helloworld() { // printf(\"hello, world from C\"); // } import \"C\" func main() { C.helloworld() } A program built from this source will be dynamically linked, due to cgo: $ go build cstdio.go $ ldd ./cstdio linux-vdso.so.1 (0x00007bc6d68e3000) libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007bc6d6600000) /lib64/ld-linux-x86-64.so.2 (0x00007bc6d68e5000) In our C code, printf is a call to libc; even if we don't explicitly call into the C runtime in our C code, cgo may do it in the scaffolding code it generates. Note that cgo may be involved even if your project has no C code of its own; several dependencies may bring in cgo. Some popular packages - like the go-sqlite3 driver - depend on cgo, and importing them will impose a cgo requirement on a program. Obviously, building with CGO_ENABLED=0 is no longer an option. So what's the recourse? Linking a libc statically To recap, once we have C code as part of our Go binary, it's going to be dynamically linked on Unix, because: The C code calls into libc (the C runtime) The libc typically used on Unix systems is glibc The recommended way to link to glibc is dynamically (for various technical and license-related reasons that are outside the scope of this post) Therefore, go build produces dynamically-linked Go binaries To change this flow of events, we can interpose at step (2) - use a different libc implementation, one that's statically linked. Luckily, such an implementation exists and is well used and tested - musl. To follow along, start by installing musl. The standard instructions using ./configure --prefix= and make / make install work well. We'll use $MUSLDIR to refer to the directory where musl is installed. musl comes with a gcc wrapper that makes it easy to pass all the right flags. To re-build our cstdio example using musl, run: $ CC=$MUSLDIR/bin/musl-gcc go build --ldflags '-linkmode external -extldflags \"-static\"' cstdio.go $ ldd ./cstdio not a dynamic executable The CC env var tells go build which C compiler to use for cgo; the linker flags instruct it to use an external linker for the final build (read this for the gory details) and then to perform a static link. This approach works for more complex use cases as well! I won't paste the code here, but the sample repository accompanying this post has a file called use-sqlite.go; it uses the go-sqlite3 package. Try go build-ing it normally and observe the dynamically linked binary produced; next, try to build it with the flags shown above to use musl, and observe that the produced binary will be statically linked. Another curious tidbit is that we now have another way to build a statically-linked lookuphost program - by linking it with musl: $ CC=$MUSLDIR/bin/musl-gcc go build --ldflags '-linkmode external -extldflags \"-static\"' lookuphost.go $ ldd ./lookuphost not a dynamic executable Since we didn't provide -tags netgo and didn't disable cgo, the Go toolchain uses calls into libc to implement DNS lookup; however, since these calls end up in the statically-linked musl, the final binary is statically linked! Using Zig as our C compiler Another alternative emerged recently to achieve what we want: using the Zig toolchain. Zig is a new systems programming language, which uses a bundled toolchain approach similar to Go. Its toolchain bundles together a Zig compiler, C/C++ compiler, linker and libc for static linking. Therefore, Zig can actually be used to link Go binaries statically with C code! Instead of installing musl, we could instead install Zig and use its x86_64-linux-musl target (adjust the architecture if needed). This is done by pointing to the zig binary as our CC= env var; assuming Zig is installed in $ZIGDIR: $ CC=\"$ZIGDIR/zig cc -target x86_64-linux-musl\" go build cstdio.go $ CC=\"$ZIGDIR/zig cc -target x86_64-linux-musl\" go build use-sqlite.go These will produce statically-linked Go binaries; the zig driver takes care of setting the right linker flags automatically, so the command-line ends up being slightly simpler than invoking musl-gcc. Another advantage of Zig here is that enables cross-compilation of Go programs that include C code [2]. I did find some issues with this approach, however; for example, attempting to link the lookuphost.go sample fails with a slew of linker errors. Summary Making sure Go produces a statically-linked binary on Linux takes a little bit of effort, but works well overall. There's a long standing accepted proposal about adding a -static flag to go build that would take care of setting up all the flags required for a static build. AFAICT, the proposal is just waiting for someone with enough grit and dedication to implement and test it in all the interesting scenarios. Code The code for all the experiments described in this post is available on GitHub. [1] A statically-linked binary doesn't have run-time dependencies on other libraries (typically in the form of shared objects), not even the C runtime library (libc). I wrote much more about this topic in the past. [2] Go is well-known for its cross-compilation capabilities, but it depends on the C toolchain to compile C code. Therefore, when cgo is involved, cross-compilation is challenging. Zig can help with this because its toolchain supports cross compilation for Zig and C! It does so by bundling LLVM with a bunch of targets linked in. For comments, please send me an email.",
    "commentLink": "https://news.ycombinator.com/item?id=41114601",
    "commentBody": "Building static binaries with Go on Linux (thegreenplace.net)153 points by ingve 20 hours agohidepastfavorite51 comments acatton 11 hours agoThe secret with sqlite is to use \"-tags sqlite_omit_load_extension\", if you don't use any extension. (which is 99% of the users) This is explained in https://www.arp242.net/static-go.html reply daenney 11 hours agoprevIn the specific case of SQLite, you can use it through WASM now [1]. It uses the dependency and Cgo-free Wazero runtime. Performance so far has been better than the modernc transpile and it’s probably sufficient for a lot of use cases. [1] https://github.com/ncruces/go-sqlite3 reply acheong08 6 hours agoparentWhy not https://pkg.go.dev/modernc.org/sqlite reply daenney 5 hours agorootparentThe WASM solution doesn’t rely on a custom libc or transpiler to convert C code to Go. The transpile is an amazing feat of engineering, but it’s hard to debug. I can wrap my head around the small amount of wrapping the go-sqlite3 WASM library does. If I had to I can maintain that should the maintainer lose interest. I can’t say the same for the modernc transpile. You can also apply the WASM trick to other libraries with much less effort. And as noted, it seems to be performing better. As the wasm runtime improves it should pull further ahead. reply kyrra 5 hours agorootparentprevPerformance is likely part of it. The WASM solution looks faster than modernc: https://github.com/cvilsmeier/go-sqlite-bench reply ncruces 4 hours agorootparentAuthor here. Faster was a by product. Maintainability was the goal. API coverage, ergonomics, extensibility all rank higher in my book than performance. An example I'd like to cite is sqlite-vec. Alex was able to build a Cgo-free version of it, on his own, which works fine with my bindings. This would be much harder to do with modernc. https://github.com/asg017/sqlite-vec-go-bindings I'm also adding support for building off the bedrock branch (begin concurrent, wal2). You just build the branch with wasi-sdk, then embed the resulting blob. reply nrvn 8 hours agoprevProducing static PIE binaries is a bigger challenge still. $ go build -ldflags '-linkmode external -s -w -extldflags \"--static-pie\"' -buildmode=pie -tags 'osusergo,netgo,static_build' main.go For anyone curious to delve into what is this and why: https://www.leviathansecurity.com/blog/aslr-protection-for-s... reply bradfitz 16 hours agoprevCareful. We (Tailscale) tried to use static Go binaries a year or two ago built with Zig (zig cc) and the SQLite performance was atrocious. It passed all our tests but it didn't survive deploying to prod. It was a very quick (and uneventful) rollback at least. (Needless to say, we have better load testing tooling now) I forget the details, but something about the libc allocator used by SQLite-with-Zig-libc being ... not good. reply dylanh 14 hours agoparentThis sounds like the musl allocator. Using mimalloc or jemalloc would probably fair a lot better. reply tarruda 11 hours agorootparentIs this a problem in distributions that use musl as the system libc (Alpine) ? reply eliben 16 hours agoparentprevI wonder if it's Zig or musl that's to blame; did you end up statically linking with musl using musl-gcc, or did you forego static linking entirely? reply jcelerier 6 hours agorootparentIt's well-known that musl is in general much, much slower than glibc. People keep rediscovering that for some reason, likely because they hear of stuff like old echoes of Usenet posts ranting against glob \"bloat\", not being aware that a lot of what people call bloat is specialization of a lot of performance-sensitive algorithms to leverage SIMD, special-casing, math optimisations, etc. When you check the glibc mailing lists, it's obvious performance is a predominant concern. reply tuxxi 16 hours agoparentprevI’ve experienced the same performance issues with cgo + a library compiled with zig cc. IIRC it seemed like an issue with the zig tooling not plumbing the optimization flags through the ancient autotools build system for our required dependency. After a while fiddling, we just rolled it back too. I haven’t tried this in about a year, so maybe the tooling doesn’t have these issues now. reply JackYoustra 15 hours agoparentprevI've heard you can just swap out allocators pretty easily - did something prevent this? Or perhaps its not as straightforward as I've thought... reply SpecialistK 17 hours agoprevVery interesting and well described! If I were to have one nitpick, it would be the use of \"Unix\" when it's more specific to Linux. Ex. \"The libc typically used on Unix systems is glibc\" However I'm sure all of the concepts still apply on BSD, Solaris, etc. reply Onavo 17 hours agoparentGo is also famous for bypassing libc and issuing syscalls directly on quite a few platforms. reply galangalalgol 17 hours agorootparentI thought I'd read they backed off of that and started using posix as an abstraction layer. reply bradfitz 16 hours agorootparentGo used to do raw syscalls on macOS but changed. Same with some BSDs. Go always did ~libc on Windows (and Solaris) and still does. Go still does raw syscalls on Linux, as that's a stable ABI. reply pjmlp 12 hours agorootparentlibc is a UNIX concept, as the OS API surface, as described by POSIX. On any other no-UNIX derived OS, it is the C compiler standard library, covering only the ISO C specifies. All the remaining OS services are exposed by other libraries, which in Windows case, the bare minimum is user, kernel and gdi dlls for the Win32 personality. Systems like IBM i, IBM z, ClearPath MCP, .... also have similar set of libraries, as do non-POSIX RTOS for embedded. reply wwarner 16 hours agoprevThere’s also Filippo Valsorda linking directly to Rust via .a files. https://words.filippo.io/rustgo/ reply moondev 3 hours agoprevWhat's the best way to include the go runtime itself, as in ability to invoke the \"go\" program from the program itself . I'm not talking about embedding it or downloading it. I want it included within the program. reply diggan 3 hours agoparentHow are you supposed to include it within the program without somehow \"embedding\" it? Or am I missing some vital understanding of what \"include\" vs \"embedding\" means here? reply moondev 2 hours agorootparentBy embedding it, I mean using the embed feature to pack the golang binary into the program. What I am going after is similar to kubectl and kustomize. The kustomize source code included with kubectl, it's not a binary packed in and extracted reply sbstp 16 hours agoprevI feel like there's a lot of potential between Go and Cosmopolitan libc. Go itself does not use libc much, as shown in the blog, but some great libraries like SQLite3 need it (unless you use https://pkg.go.dev/modernc.org/sqlite). The ability to build a single static binary that works on Linux, Mac and Windows using Go would be life changing for the internal tools I develop at work. reply latchkey 16 hours agoparent> The ability to build a single static binary that works on Linux, Mac and Windows using Go would be life changing for the internal tools I develop at work. Just curious, life changing in what way? Obviously, 1 is better than 3, but I'm wondering if there is some other interesting reason. reply spease 12 hours agoparentprevHmmm…what about compiling to wasm, and/or then converting the wasm to C? https://github.com/wasm3/wasm3/releases/tag/v0.4.8 https://github.com/WebAssembly/wabt/tree/main/wasm2c reply daenney 11 hours agorootparentHas been done and works pretty great: https://github.com/ncruces/go-sqlite3. Though doesn’t convert the WASM to C, it runs the WASM in Wazero instead. reply spease 3 hours agorootparentHow does that solve what the person I replied to was asking for? reply fsmv 14 hours agoparentprevThe same exact binary working isn't going to happen without runtime performance penalties because the syscall numbers are different on different platforms. Also I believe on windows it's not possible to avoid linking some system libraries to use windows.h stuff, there is no stable ABI. reply actionfromafar 10 hours agorootparentThough msvcrt.dll has a stable subset of functions available on all Windows versions. reply pjmlp 12 hours agorootparentprevLinux is the exception among modern OSes to have a stable syscall ABI, everyone else offers only the proper OS API as entry point into OS services. Once upon at time, static linking was the only thing OSes were capable of, all of them moved away from that, and there is no turning back outside embedded bare metal deployments, just become some people are obsessed with static linking. reply oguz-ismail 15 hours agoparentprevI recall reading about new Macs with ARM chips not supporting static binaries. Is it not true? reply zamadatix 14 hours agorootparentThat's been Apple's stance on full static linking MacOS in general, many years prior to the move to ARM e.g. https://developer.apple.com/library/archive/qa/qa1118/_index... You're welcome to ignore it of course, it's just unofficial and a large pain. reply oguz-ismail 14 hours agorootparent>You're welcome to ignore it of course How do you mean? Like, is it possible to run such binaries on M1? If so I'd really like to know how reply telotortium 13 hours agorootparentYou can always disassemble libc and look for the system call numbers used by the syscall assembly instructions. It’s just that these numbers (and associated arguments and return values) are not stable and can and do change upon kernel updates (in which case libc will be updated to keep the libc interface stable). I believe Linux is the only major OS these days to guarantee binary compatibility of the syscall interface. reply oguz-ismail 13 hours agorootparentI know this works on Macs with Intel chips. But the ones with ARM chips just won't execute fully static binaries, and I'm wondering if there's a workaround. reply zamadatix 1 hour agorootparentFor clarity it's not the chip/ARM that causes the limitation, you can recompile the kernel (it's open source) to remove the block and it'll work fine - it's just a ton of work. Alternatively, Linux :). reply telotortium 12 hours agorootparentprevI’m guessing not. According to man ld on macOS, the -static flag, to produce a fully static executable, is only used to build the kernel. I don’t believe fully-static executables were ever officially supported on macOS, although they would work. reply jcelerier 6 hours agorootparentprevIt only works if you don't ever upgrade macOS. Even a patch update sometimes can break it. reply saagarjha 12 hours agorootparentprevNope. reply oguz-ismail 12 hours agorootparentThanks. That sucks reply saagarjha 12 hours agorootparentIf you can convince Apple to change this code let me know: https://github.com/apple-oss-distributions/xnu/blob/94d3b452... reply cyberax 14 hours agorootparentprevAll Macs don't support static binaries. That's because the syscall interface on macOS is not stable, only libc is guaranteed to be stable. reply neonsunset 9 hours agoprev [9 more] [flagged] dang 1 hour agoparentSince you've continued to start programming language flamewars after we asked you to stop (https://news.ycombinator.com/item?id=40979059), I've banned this account. We really don't want that type of flamewar here (or any type, really) because it's not compatible with curious conversation, the purpose of the site. If you don't want to be banned, you're welcome to email hn@ycombinator.com and give us reason to believe that you'll follow the rules in the future. They're here: https://news.ycombinator.com/newsguidelines.html. We detached this subthread from https://news.ycombinator.com/item?id=41117094. reply qaq 9 hours agoparentprev [–] and yet a ton of fundamentally important projects are written in Go like k8s, Docker, Prometheus, Terraform ... reply papichulo2023 8 hours agorootparentAnd barely any big open source is written in .NET, the only one I can recall without googling is Ryujinx reply tmjwid 5 hours agorootparentJellyfin is one of the bigger ones for sure. reply neonsunset 4 hours agorootparentYup, and Bitwarden is another one. Many larger game publishers run their infrastructure exclusively on .NET like Roblox or Ubisoft. At the end of the day, all the tools written in Go that are listed above are not exactly paragons of performance. Ryujinx is probably one of the best showcases of the kind of task that is impossible to solve in Go effectively, and yet can be solved very well with .NET. Or you could look at Garnet which is a pure C# Redis implementation which beats vanilla Redis, KeyDB and Dragonfly. reply qaq 3 hours agorootparentMany large companies including Google, Uber and so on run a ton of Go services :) reply neonsunset 8 hours agorootparentprev [–] This doesn't make Go's FFI not suck. It's one of the worst across all general purpose languages that are in use today. reply pjmlp 5 hours agorootparent [–] Quite true, but it shows how much work Microsoft is yet to do in UNIX shops, and bosting about performance improvements on twitter isn't going to change the culture and attitute towards .NET. Wouldn't it great if even Azure would contribute to CNCF projects using .NET, instead of Go and Rust, as they do currently? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Go can produce statically-linked binaries on Unix systems, but it requires specific build tags or disabling cgo.",
      "Tools like `file`, `ldd`, and `nm` can verify if a Go binary is statically linked.",
      "Using Zig as a C compiler simplifies the process and supports cross-compilation for static linking."
    ],
    "commentSummary": [
      "Building static binaries with Go on Linux involves specific flags and considerations, such as using `-tags sqlite_omit_load_extension` for SQLite if no extensions are used.",
      "The discussion highlights the use of WebAssembly (WASM) for SQLite, which offers better performance and maintainability compared to traditional methods like modernc transpile.",
      "There are challenges and performance issues associated with using different allocators and libc implementations, such as musl, when building static Go binaries, as experienced by companies like Tailscale."
    ],
    "points": 153,
    "commentCount": 51,
    "retryCount": 0,
    "time": 1722377273
  },
  {
    "id": 41115591,
    "title": "Superconducting Microprocessors? Turns Out They're Ultra-Efficient (2021)",
    "originLink": "https://spectrum.ieee.org/new-superconductor-microprocessor-yields-a-substantial-boost-in-efficiency",
    "originBody": "COMPUTING NEWS Superconducting Microprocessors? Turns Out They're Ultra-Efficient The 2.5 GHz prototype uses 80 times less energy than its semiconductor counterpart, even accounting for coolingMICHELLE HAMPSON13 JAN 20213 MIN READ The AQFP-based MANA microprocessor seated on a chip holder. The microprocessor die contains over 20,000 superconductor Josephson junctions. It is the first ever adiabatic superconducting microprocessor. PHOTO: CHRISTOPHER AYALA",
    "commentLink": "https://news.ycombinator.com/item?id=41115591",
    "commentBody": "Superconducting Microprocessors? Turns Out They're Ultra-Efficient (2021) (ieee.org)136 points by actinium226 17 hours agohidepastfavorite65 comments incompatible 16 hours ago: The research group in Japan sought to create a superconductor microprocessor that’s adiabatic, meaning that, in principle, energy is not gained or lost from the system during the computing process. I thought that there was a law of information theory that requires expending energy, I think it's Landauer's principle. It seems to be disputed though. https://en.wikipedia.org/wiki/Landauer%27s_principle reply philipswood 15 hours agoparentEnergy is expended when you zero or set a bit. If you compute reversibly you need use special logic gates to not throw any bits away during the computation, like the Toffoli gate. All your operations need to have the same number of input and output bits and needs to be able to run forwards and backwards. Effectively you set or zero no bits during the entire computation that can't be losslessly reversed. If you structure your computation this way you can do it adiabatically. You still however need to expend energy when you set all the bits your program requires for execution when you start a computation. reply AnthonyMouse 12 hours agorootparentWait, so does this imply (ignoring the time requirements) that you could do NP calculations with a feasible amount of energy, because the inputs and outputs are small? Combine that with something that uses time dilation to make it go fast (from our frame of reference) and you'd be giving even hypothetical quantum computers a silver medal. reply stracer 2 hours agorootparent> time dilation to make it go fast (from our frame of reference) The only way to do that is that we move to a place from which the computer processes appear accelerated, e.g. into a strong gravity well. That isn't very useful, because we do not have such a well nearby, as only very dense hypothetical objects can provide it (e.g. black holes), and it would not be compatible with life to move there. reply philipswood 5 hours agorootparentprevI think a longer runtime for a terminating program will require more state to be kept. Every step needs to keep extra reversibility information. So I don't think this gives any edge on NP. I suspect that even if you waited for the universe to cool down a lot by waiting aeons and then performed computations arbitrarily slowly you'd still be limited by your starting energy (maximum bits you can write to start with). Although maybe using random bits might help somehow? reply wizzwizz4 1 hour agorootparentThe amount of energy it takes to write a bit depends on the temperature. But you'd still be limited by the amount of substrate available. reply Strilanc 10 hours agorootparentprevNot unless you can isolate the computer from environmental noise exponentially well. Otherwise you'll need to spend exponential energy on entropy removal / error correction (e.g. keeping the dilution fridge running). reply Dylan16807 11 hours agorootparentprevIf you're going to use time dilation so you can wait for the computer to calculate, it's hard to imagine a setup where the power needs of the computer are more than a rounding error in comparison. reply AnthonyMouse 11 hours agorootparentIf you're using time dilation the power needs of the computer (in terms of how much fuel you need) are proportional to the rate time passes inside. If the goal is to get the ratio way up there, the power consumption gets important. Especially if you're using the velocity-based method and have to accelerate the fuel. reply Dylan16807 10 hours agorootparentYou'd be accelerating yourself, not the computer. If you launch the computer it just takes longer. reply oceanplexian 12 hours agorootparentprevMy analogy probably isn’t perfect but isn’t this how an abacus or a slide rule works? You expend energy to set the values for computation but the act of computing and then reading them expends no energy. reply bgnn 10 hours agorootparentYeah this is a good analogy reply m463 13 hours agorootparentprevI think maybe we need the idea of a \"bit well\" to match the \"bit bucket\". Then it would be possible to just borrow bits when we set bits. reply Thorondor 15 hours agoparentprevLandauer's limit assumes that computation uses a thermodynamically irreversible process and erases bits of information. This is not necessarily true for all useful computers [0]. So theoretically speaking, it's not impossible to create an adiabatic microprocessor. Skepticism is definitely warranted though. [0] https://en.m.wikipedia.org/wiki/Reversible_computing reply bryanlarsen 16 hours agoparentprevIf the superconducting microprocessor is 80x as efficient as a normal micro, that means that it uses about 100 million times as much energy as Landauer's principle. (A normal micro uses a billion times as much, and Landauer's energy is ~1/5th at superconducting temperature). reply incompatible 16 hours agorootparentYes, but the quote suggests no energy transfer at all. All you need then is a cold place (somewhere in remote space perhaps, or after the heat death of the Universe) and your computation can continue forever without power. It doesn't seem intuitive that that would be possible. reply reaperman 16 hours agorootparentIt is extremely likely that the quote is hyperbolic (wrong / inaccurate). If someone broke Landauers limit, that would be a massive headline in academia. Hell even reasonably approaching Landauer’s limit would be huge news. Most likely this headline is a confusion from how signal/power transmission (rather than calculation/work) is truly lossless in superconductors. reply jakobson14 14 hours agorootparentprevContinue forever? no. Be performed once at no cost? maybe. I'm kinda sceptical that a computation to which the 2nd law is indifferent would occur spontaneously without immediately reversing. The 2nd law is what determines the direction that things typically progress. reply KiranRao0 16 hours agoparentprevPer the wikipedia article: “Modern computers use about a billion times as much energy per operation.” I’m guessing the efficiency gains can be considerable before hitting this limit. reply HPsquared 11 hours agorootparentThat's actually fewer zeroes than I was expecting. reply bgnn 10 hours agoprevInteresting. To give some context to the current problem: the classical (CMOS) logic gates energy is expended to charge or discharge the load capacitance of each electrical node during a state change. Charging a capacitor to a certain voltage requires E=CV^2 amount of (Joules) energy (C in Farads, V in volts). From this, half of it is the energy stored at the capacitor, other half is the energy converted to heat on the transistors. This is so far the most efficient way we can build large scale integrated logic, and at best it is 50% efficient. In reality there is also unwanted inefficiencies, making it close to 30% or so. Good to keep in mind: 100% of the energy becomes heat because the charged capacitor needs to be discharged at some point to change its state. This is becoming a huge thermal management nightmare. reply lytedev 15 hours agoprevPardon my ignorance, but would this then be a semisuperconductor or a supersemiconductor? reply kragen 8 hours agoparentno, they use jjs reply d_silin 16 hours agoprevA more recent take on this subject: https://diginomica.com/superconducting-chips-could-pack-data... reply lacoolj 2 hours agoprevThis will be incredible when the cooling at consumer-level has been figured out. I do wonder what kind of material requirements/availability there will be though. Even things like touchscreens and other rare earth metals are either getting scarce or controlled by one or two countries. Regardless, exciting news here for all of us reply marcosdumay 17 minutes agoparentLots of people handle liquid nitrogen in all kinds of different field applications. Cooling things is not that hard. reply est31 11 hours agoprevAccording to the paper, their demonstration chip MANA has 21k of JJ units, which according to their estimates correspond to around 5k transistors. To compare, a single Nvidia GA100 has 54 * 10^9 transistors. reply timschmidt 10 hours agoparentSome versions of the venerable MOS Technologies 6502 have only 3,218 transistors. The Intel 8080 has somewhere between 4,500 and 6,000. 5k transistors is square in the middle of \"plenty for a classic 8 bit micro\". Enough to run a basic *nix or embedded RTOS. reply actinium226 5 hours agorootparentThere's something I'm missing, they say the prototype hits 2.5 GHz, how is that possible if they only have the equivalent of 5k transistors? Or is clock cycle independent of transistor count? reply johntb86 4 hours agorootparentAdding more transistors doesn't make your clock got faster, and it doesn't increase the speed of an individual transistor. The reason computers got both more transistors and faster in the past was that the transistors were continually shrinking; for a traditional MOSFET, Dennard scaling means that the smaller the transistor (and therefore the smaller its capacitance and voltage), the faster it switches. This device doesn't use MOSFET technology, so its scaling rules are different. reply g15jv2dp 5 hours agorootparentprevIt depends on what you have your transistors do. You could even have one single transistor that you switch on/off very very quickly. You'd need to find a transistor with sub-ns switching time to reach >1GHz. It's not a very interesting \"computation,\" though. reply mrguyorama 36 minutes agorootparentprevI'm very confused but I mean this in the utmost sincerity: What made you think transistor count and clock speed were linked? What was your line of thought? How did you think overclocking worked, by dynamically removing transistors from the chip? reply BenoitP 11 hours agoprevThis is the future. As we try to go 3D and start stacking dies, the limiting factor of heat is getting even more blocking. It's not about consuming less electricity. It's about dissipating less of it as heat inside the microprocessor. The future will made of tiny porous cubes that are tall sandwiches of RAM and CPU/GPU/etc reply sigmoid10 11 hours agoparentSuperconductivity with current materials is hard. Allost always because of the cooling. You can't just fabricate a porous cube of transistors and put it in a liquid helium ice bath. You need to have excess heat flowing out in a stable and predictable way. Otherwise once the center reaches critical temperature, the whole thing will explode. There's a reason why everyone is desperately searching for room temp low pressure sc materials. I doubt we'll see industry applications in large scale computing before that. reply mlhpdx 3 hours agorootparentTotally true, but it’s interesting that this technology lends itself to incremental improvements. And those improvements can be driven both from the hardware side and the software side. It seems like a virtuous cycle driving this to economic viability and optimization is possible. I’m no expert, though, so this is strictly my imagination. reply cashsterling 1 hour agoprevI worked on a team (at a Company) that built a Scanning SQUID Microscope (SSM) to image magnetic flux trapping in superconducting circuits. The organization that bought the SSM is working on these kinds superconducting microprocessors. A SSM uses a SQUID (superconducting quantum inference device) as an extremely sensitive magnetic flux sensor; SQUID sensor requires further amplification which is also typically a SQUID-based low-noise amplifier (long story). Same Company (I worked for) built cryostats for quantum computing research and all kinds of other cryogenic needs. There are a lot of issues with designing, fabricating, operating these sort of circuits at large scale... hence the need for a microscope to study flux trapping and other phenomena of operating circuits. But, overall, I'm optimistic that this technology can work. A note about energy consumption of this technology. Niobium thin film superconducting circuits have to be cooled to about 4 Kelvin to be 'properly 'operational'. Heat leaks from higher temperature stages into the 4 Kelvin cooling zone via conduction of thermal insulating supports, electrical signal lines, and thermal blackbody radiation. Several kW of power are required to provide 1 Watt of cooling power at 4 Kelvin. There are also small resistive/impedance losses in electrical signal lines connecting room temperature electronics to the superconducting chip. So... I think calling the microprocessor 'adiabatic' is a little disingenuous. Small amounts of power, in the form of many nano-amp and micro-amp currents are required to operate and interface with the chip... the chip cannot operate without this electrical interface. In additional, in a test environment where researchers are only running one chip... the overall cryogenic system, electronics, and superconducting chip are wildly energy inefficient compared to current microprocessors. But the \"forward looking statement\" is that hundreds of microprocessors could be run in one cryostat and the 5kW cooling budget would replace the power draw of 100's of classical microprocessors while also provide higher equivalent FLOPS per process processor. But this \"forward looking statement\" is NOT true today, as far as I am aware. reply written-beyond 1 hour agoparentI appreciate your comment it's probably very informative to a lot of people here on HN. I will admit this comment for me, read like something out of r/vxjunkies. Props to you and your team for building amazing stuff. Squid and Niobium are very entertaining names. reply boznz 15 hours agoprevGreat, I can make my software even more shitty, and nobody will notice. reply 77pt77 1 hour agoparentConvenience always wins against quality. reply dschuetz 9 hours agoprevHow much energy was needed for the cryostat? I haven't found anything on that in the article. reply Hugsun 6 hours agoprevI'm surprised that this wasn't done earlier. An experiment like this seemed like an obvious useful thing to try the first time I heard about superconductors, some decades ago. Perhaps it is due to the technical difficulty of the experiment. reply rapsey 15 hours agoprevIs there any company trying to bring this to market? reply campers 13 hours agoparentImec working on this approach too https://spectrum.ieee.org/superconducting-computer reply kragen 8 hours agoprevunfortunately the title says 'superconducting' when it should say 'reversible' reply quux 4 hours agoprevTo quote Norm MacDonald: ... according to a report in the medical journal \"DUH\" reply wizardforhire 17 hours agoprev [–] Another notch on the belt for a cryocooler boom. Oh “superconducting is hard”, “if only we had high temperature superconductors”. All valid, but if we work with what we got and disrupt cyrocoolers make them a commodity like magnetrons all those laments become moot. Prove me wrong. reply tarikjn 2 hours agoparentI’ve been thinking about making cheaper cryocoolers for CO2 condensation. I’d love to hear your perspective on other applications :) reply yeknoda 17 hours agoparentprevIs the cost of cryocoolong capex or Opex dominated? reply hn72774 16 hours agorootparentAre you referring to the hardware cost vs operating cost? Or how the units are financed? reply idiotsecant 15 hours agorootparentThat's what it means. Some things are expensive to buy, some things are expensive to run, and some things are both. reply tuatoru 15 hours agorootparentprevcapex = capital expenditure; opex = operational expenditure. There's some theorem about investments that says it doesn't matter how they are financed. A good one is good, and a bad one is bad, whether or not you use debt. reply marcosdumay 10 minutes agorootparent> it doesn't matter how they are financed If you have spherical banks in a vacuum, you can simply follow \"capital_opex = capex * interest_rate\" and then \"profit = revenue - total_opex\". But things tend to not work that way on practice. reply actinium226 5 hours agorootparentprevI'll bet you I can find a way to finance a good deal that turns it into a bad one. The other way around seems harder. reply nine_k 16 hours agoparentprevWould running a cryocooler spend more energy than a superconducting CPU / GPU would save? reply moralestapia 16 hours agorootparent>The 2.5 GHz prototype uses 80 times less energy than its semiconductor counterpart, even accounting for cooling It's in the header of the article. reply hypercube33 16 hours agorootparentThe way it reads though is that the chip itself uses less power but still needs to be cooled which takes a lot of energy (traditionally) reply moralestapia 15 hours agorootparent>even accounting for cooling No. reply Grimblewald 13 hours agorootparentstuff like this makes me wonder what the distribution on human context limits is. reply pjerem 12 hours agorootparent3 reply jasonwatkinspdx 12 hours agoparentprevI'm fond of this argument but I would point out that magnetrons are remarkably simple devices once you figure out how the waves are interacting. reply XorNot 17 hours agoparentprevAlso notable because heat rejection on that scale till you enter the superconducting regime is a reinforcing loop: the device no longer makes heat, you just need to keep the environmental heat out. reply Terr_ 17 hours agoparentprev [–] So someone else needs to prove a negative, that there exists no possible technology that will \"disrupt\" cryocoolers by bringing them to an unspecified price/performance point by an unspecified time in the future to service an unspecified computing use-case? That seems more than a little unfair. :p reply JumpCrisscross 16 hours agorootparent [–] > someone else needs to prove a negative, that there exists no possible technology that will \"disrupt\" cryocoolers Look at the Wikipedia references for crycoolers [1]. Note the dates and volume. Now look at room-tempuerature superconductors [2]. 1990 vs 2023. 5 vs 57. OP is arguing that a greater fraction of high-temperature superconducting research dollars might find purchase in improving the cryocooler than we presently spend. [1] https://en.wikipedia.org/wiki/Cryocooler#References [2] https://en.wikipedia.org/wiki/Room-temperature_superconducto... reply Terr_ 16 hours agorootparent> Now look at room-tempuerature superconductors [2]. As a tangent: Don't forget to look at pressures too. Some newer superconductors that are near-room-temperature aren't quite as exciting when it turns out that requires over 1.5 million times normal atmospheric pressure. (\"Hey, I think I over-tightened the CPU heatsink...\") Ex: https://en.wikipedia.org/wiki/Lanthanum_decahydride reply tliltocatl 6 hours agorootparentprev [–] The problem is, cryocooler theory is pretty well established and \"solved at this point, so there is no reason to expect something completely new phenomena there, just some engineering improvements. Solid-state physics, on the other hand, is just computationally infeasible to \"solve\", so there is a plenty of possibility to discover something unpredicted. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A 2.5 GHz superconducting microprocessor prototype has been developed, using 80 times less energy than traditional semiconductor microprocessors, even when accounting for cooling.",
      "The MANA microprocessor, based on Adiabatic Quantum-Flux-Parametron (AQFP) technology, contains over 20,000 superconductor Josephson junctions.",
      "This is the first adiabatic superconducting microprocessor, marking a significant advancement in energy-efficient computing technology."
    ],
    "commentSummary": [
      "Researchers in Japan are developing ultra-efficient superconducting microprocessors that operate adiabatically, theoretically avoiding energy loss or gain during computation.",
      "This technology challenges Landauer's principle, which states that erasing information requires energy, by using reversible computing with special logic gates like the Toffoli gate to minimize energy expenditure.",
      "Despite its promising efficiency, practical implementation faces significant challenges, particularly in cooling and scaling for practical use, and still requires energy to set initial bits and manage environmental noise."
    ],
    "points": 136,
    "commentCount": 65,
    "retryCount": 0,
    "time": 1722387626
  },
  {
    "id": 41119874,
    "title": "Why the CrowdStrike bug hit banks hard",
    "originLink": "https://www.bitsaboutmoney.com/archive/crowdstrike-bug-hit-banks-hard/",
    "originBody": "Why the CrowdStrike bug hit banks hard Patrick McKenzie (patio11) • Jul 31st, 2024 Programming note: I recently launched a weekly podcast, Complex Systems with Patrick McKenzie. About 50% of the conversations cover Bits about Money's beat. The remainder will be on other interesting intersections of technology, incentives, culture, and organizational design. The first three episodes covered teaching trading, Byrne Hobart on the epistemology of financial firms, and the tech industry vs. tech reporting divide. Subscribe to it anywhere you listen to podcasts. If you enjoy it, writing a review (in your podcast app or to me via email) helps quite a bit. On July 19th, a firm most people have sensibly never heard of knocked out a large portion of the routine operations at many institutions worldwide. This hit the banking sector particularly hard. It has been publicly reported that several of the largest U.S. banks were affected by the outage. I understand one of them to have idled tellers and bankers nationwide for the duration. (You’ll forgive me for not naming them, as it would cost me some points.) The issue affected institutions across the size spectrum, including large regionals and community banks. You might sensibly ask why that happened and, for that matter, how it was possible it would happen. You might be curious about how to quickly reconstitute the financial system from less legible sources of credit when it is down. (Which: probably less important as a takeaway, but it is quite colorful.) Brief necessary technical context Something like 20% of the readership of this column has an engineering degree. To you folks, I apologize in advance for the following handwaviness. (You may be better served by the Preliminary Post Incident Review.) Many operating systems have a distinction between the “kernel” supplied by the operating system manufacturer and all other software running on the computer system. For historical reasons, that area where almost everything executes is called “userspace.” In modern software design, programs running in userspace (i.e. almost all programs) are relatively limited in what they can do. Programs running in kernelspace, on the other hand, get direct access to the hardware under the operating system. Certain bugs in kernel programming are very, very bad news for everything running on the computer. CrowdStrike Falcon is endpoint monitoring software. In brief, “endpoint monitoring” is a service sold to enterprises which have tens or hundreds of thousands of devices (“endpoints”). Those devices are illegible to the organization that owns them due to sheer scale; no single person nor group of people understand what is happening on them. This means there are highly variable levels of how-totally-effed those devices might be at exactly this moment in time. The pitch for endpoint monitoring is that it gives your teams the ability to make those systems legible again while also benefitting from economies of scale, with you getting a continuously updated feed of threats to scan for from your provider. One way an endpoint might be effed is if it was physically stolen from your working-from-home employee earlier this week. Another way is if it has recently joined a botnet orchestrated from a geopolitical adversary of the United States after one of your junior programmers decided to install warez because the six figure annual salary was too little to fund their video game habit. (No, I am not reading your incident reports, I clarify for every security team in the industry.) In theory, you perform ongoing monitoring of all of your computers. Then, your crack security team responds to alerts generated by your endpoint monitoring solution. This will sometimes merit further investigation and sometimes call for immediate remedial work. The conversations range from “Did you really just install cracked Starcraft 2 on your work PC? … Please don’t do that.” to “The novel virus reported this morning compromised 32 computers in the wealth management office. Containment was achieved by 2:05 PM ET, by which point we had null routed every packet coming out of that subnet then physically disconnected power to the router just to be sure. We have engaged incident response to see what if any data was exfiltrated in the 47 minutes between detection and null routing. At this point we have no indications of compromise outside that subnet but we cannot rule out a threat actor using the virus as a beachhead or advanced persistent threats being deployed.” (Yes, that does sound like a Tom Clancy novel. No, that is not a parody.) Falcon punched Falcon shipped a configuration bug. In brief, this means that rather than writing new software (which, in modern development practice, hopefully goes through fairly extensive testing and release procedures), CrowdStrike sent a bit of data to systems with Falcon installed. That data was intended to simply update the set of conditions that Falcon scanned for. However, due to an error at CrowdStrike, it actually caused existing already-reviewed Falcon software to fail catastrophically. Since that failure happened in kernelspace at a particularly vulnerable time, this resulted in Windows systems experiencing total failure beginning at boot. The user-visible symptom is sometimes called the Blue Screen of Death. Configuration bugs are a disturbingly large portion of engineering decisions which cause outages. (Citation: let’s go with “general knowledge as an informed industry observer.” As always, while I’ve previously worked at Stripe, neither Stripe nor its security team necessarily endorses things I say in my personal spaces.) However, because this configuration bug hit very widely distributed software running in kernelspace almost universally across machines used by the workforce of lynchpin institutions throughout society (most relevantly to this column, banks, but also airlines, etc etc), it had a blast radius much, much larger than typical configuration bugs. Have I mentioned that IT security really likes military metaphors? “Blast radius” means “given a fault or failure in system X, how far afield from X will we see negative user impact.” I struggle to recall a bug with a broader direct blast radius than the Falcon misconfiguration. Once the misconfiguration was rolled out, fixing it was complicated by the tiny issue that a lot of the people needed to fix it couldn’t access their work systems because their machine Blue Screen of Death’ed. Why? Well, we put the vulnerable software on essentially all machines in a particular institution. You want to protect all the devices. That is the point of endpoint monitoring. It is literally someone’s job to figure out where the devices that aren’t endpoint monitored exist and then to bring them into compliance. Why do we care about optimizing for endpoint monitoring coverage? Partly it is for genuinely good security reasons. But a major part of it is that small-c compliance is necessary for large-C Compliance. Your regulator will effectively demand that you do it. Why did Falcon run in kernelspace rather than userspace? Falcon runs in kernelspace versus userspace in part because the most straightforward way to poke its nose in other programs’ business is to simply ignore the security guarantees that operating systems give to programs running in userspace. Poking your nose in another program’s memory is generally considered somewhere between rude and forbidden-by-very-substantial-engineering-work. However, endpoint monitoring software considers that other software running on the device may be there at the direction of the adversary. It therefore considers that software’s comfort level with its intrusion to be a distant secondary consideration. Another reason Falcon ran in kernelspace was, as Microsoft told the WSJ, Microsoft was forbidden by an understanding with the European Commission from firmly demoting other security software developers down to userspace. This was because Microsoft both a) wrote security software and b) necessarily always had the option of writing it in kernelspace, because Microsoft controls Windows. The European Commission has pushed back against this characterization and pointed out that This Sentence Uses Cookies To Enable Essential Essay Functionality. Regulations which strongly suggest particular software purchases It would be an overstatement to say that the United States federal government commanded U.S. financial institutions to install CrowdStrike Falcon and thereby embed a landmine into the kernels of all their employees’ computers. Anyone saying that has no idea how banking regulation works. Life is much more subtle than that. The United States has many, many different banking regulators. Those regulators have some desires for their banks which rhyme heavily, and so they have banded into a club to share resources. This lets them spend their limited brainsweat budgets on things banking regulators have more individualized opinions on than simple, common banking regulatory infrastructure. One such club is the Federal Financial Institutions Examination Council. They wrote the tgreatest crossover event of all time if your interests are a) mandatory supervisory evaluations of financial institutions and b) IT risk management: the FFIEC Information Technology Examination Handbook's Information Security Booklet. The modal consumer of this document is probably not a Linux kernel programmer with a highly developed mental model of kernelspace versus userspace. That would be an unreasonable expectation for a banking supervisor. They work for a banking regulator, not a software company, doing important supervisory work, not merely implementation. Later this week they might be working on capital adequacy ratios, but for right now, they’re asking your IT team about endpoint monitoring. The FFEITC ITEH ISB (the acronym just rolls off the tongue) is not super prescriptive about exactly what controls you, a financial institution, have to have. This is common in many regulatory environments. HIPAA, to use a contrasting example, is unusual in that it describes a control environment that you can reduce to a checklist with Required or Optional next to each of them. (HIPAA spells that second category “Addressable”, for reasons outside the scope of this essay, but which I’ll mention because I don’t want to offend other former HIPAA Compliance Officers.) To facilitate your institution’s conversation with the examiner who drew the short straw, you will conduct a risk analysis. Well, more likely, you’ll pay a consulting firm to conduct a risk analysis. In the production function that is scaled consultancies, this means that a junior employee will open U.S. Financial Institution IT Security Risk Analysis v3-edited-final-final.docx and add important client-specific context like a) their name and b) their logo. That document will heavily reference the ITEH, because it exists to quickly shut down the line of questioning from the examiner. If you desire a career in this field, you will phrase that as “guiding the conversation towards areas of maximum mutual interest in the cause of 'advanc[ing] the nation’s monetary, financial, and payment systems to build a stronger economy for all Americans.'” (The internal quotation is lifted from a job description at the Federal Reserve.) Your consultants are going to, when they conduct the mandatory risk analysis, give you a shopping list. Endpoint monitoring is one item on that shopping list. Why? Ask your consultant and they’ll bill you for the answer, but you can get my opinion for free and it is worth twice what you paid for it: II.C.12 Malware Mitigation. Does the FFEITC have a hugely prescriptive view of what you should be doing for malware monitoring? Well, no: Management should implement defense-in-depth to protect, detect, and respond to malware. The institution can use many tools to block malware before it enters the environment and to detect it and respond if it is not blocked. Methods or systems that management should consider include the following: [12 bullet points which vary in specificity from whitelisting allowed programs to port monitoring to user education]. But your consultants will tell you that you want a very responsive answer to II.C.12 in this report and that, since you probably do not have Google’s ability to fill floors of people doing industry-leading security research, you should just buy something which says Yeah We Do That. CrowdStrike’s sales reps will happily tell you Yeah We Do That. This web page exists as a result of a deterministic process co-owned by the Marketing and Sales departments at a B2B software company to create industry-specific “sales enablement” collateral. As a matter of fact, if you want to give CrowdStrike your email address and job title, they will even send you a document which is not titled Exact Wording To Put In Your Risk Assessment Including Which Five Objectives And Seventeen Controls Purchasing This Product Will Solve For. CrowdStrike is not, strictly speaking, the only vendor that you could have installed on every computer you owned to make your regulators happy with you. But, due to vagaries of how enterprise software sales teams work, they sewed up an awful lot of government-adjacent industries. This was in part because they aggressively pursued writing the sort of documents you need if the people who read your project plans have national security briefs. I’m not mocking the Federal Financial Institutions Examining Council for cosplaying as having a national security brief. (Goodness knows that that happens a lot in cybersecurity... and government generally. New York City likes to pretend it has an intelligence service, which is absolutely not a patronage program designed to have taxpayers fund indefinite foreign vacations with minimal actual job duties.) But money is core societal infrastructure, like the power grid and transportation systems are. It would be really bad if hackers working for a foreign government could just turn off money. That would be more damaging than a conventional missile being fired at random into New York City, and we might be more constrained in responding. And so, we ended up in a situation where we invited an advanced persistent threat into kernelspace. It is perhaps important to point out that security professionals understand security tools to themselves introduce security vulnerabilities. Partly, the worry is that a monoculture could have a particular weakness that could be exploited in a particular way. Partly, it is that security tools (and security personnel!) frequently have more privileges than is typical, and therefore they can be directly compromised by the adversary. This observation is fractal in systems engineering: at every level of abstraction, if your control plane gets compromised, you lose. (Control plane has a specific meaning in networking but for this purpose just round it to “operating system (metaphorical) that controls your operating systems (literal).”) CrowdStrike maintains that they do not understand it to be the case that a bad actor intentionally tried to bring down global financial infrastructure and airlines by using them as a weapon. No, CrowdStrike did that themselves, on accident, of their own volition. But this demonstrates the problem pretty clearly: if a junior employee tripping over a power cord at your company brings down computers worldwide, the bad guys have a variety of options for achieving directionally similar aims by attacking directionally similar power cords. When money stops money-ing I found out about the CrowdStrike vulnerability in the usual fashion: Twitter. But then my friendly local bank branch cited it (as quote the Microsoft systems issue endquote) when I was attempting to withdraw cash from the teller window. My family purchased a duplex recently and is doing renovation prior to moving in. For complex social reasons, a thorough recitation of which would make me persona non grata across the political spectrum, engaging a sufficient number of contractors in Chicago will result in one being asked to make frequent, sizable payments in cash. This created a minor emergency for me, because it was an other-than-minor emergency for some contractors I was working with. Many contractors are small businesses. Many small businesses are very thinly capitalized. Many employees of small businesses are extremely dependent on receiving compensation exactly on payday and not after it. And so, while many people in Chicago were basically unaffected on that Friday because their money kept working (on mobile apps, via Venmo/Cash App, via credit cards, etc), cash-dependent people got an enormous wrench thrown into their plans. I personally tried withdrawing cash at three financial institutions in different weight classes, as was told it was absolutely impossible (in size) at all of them, owing to the Falcon issue. At one, I was told that I couldn’t use the tellers but could use the ATM. Unfortunately, like many customers, I was attempting to take out more cash from the ATM than I ever had before. Fortunately, their system that flags potentially fraudulent behavior will let a customer unflag themselves by responding to an instant communication from the bank. Unfortunately, the subdomain that communication directs them to runs on a server apparently protected by CrowdStrike Falcon. It was not impossible at all financial institutions. I am aware of a few around Chicago which ran out of physical cash on hand at some branches, because all demand for cash on a Friday was serviced by them versus by “all of the financial institutions.” (As always happens during widespread disturbances in infrastructure, there quickly arises a shadow economy of information trading which redirects relatively sophisticated people to the places that are capable of servicing them. This happens through offline social networks since time immemorial and online social networks since we invented those. The first is probably more impactful but the second is more legible, so banking regulators pretend this class of issues sprang fully formed from the tech industry just in time to bring down banks last year.) I have some knowledge of the history of comprehensive failures of financial infrastructure, and so I considered doing the traditional thing when convertibility of deposits is suspended by industry-wide issues: head to the bar. A hopefully unnecessary disclaimer: the following is historical fact despite rhyming with stereotype. Back in 1970, there was a widespread and sustained (six months!) strike in the Irish banking sector. Workers were unable to cash paychecks because tellers refused to work. So, as an accommodation for customers, operators of pubs would cash the checks from the till, trusting that eventually checks drawn on the accounts of local employers would be good funds again. Some publicans even cashed personal checks, backed by the swift and terrible justice of the credit reporting bureau We Control Whether You Can Ever Enjoy A Pint With Your Friends Again. This kept physical notes circulating in the economy. As I told my contractors, to their confusion, I was unable to simply go down to the local bar to get them cash with the banks down. I don’t have sufficient credit with the operator of the local bar, as I don’t drink. I told them, to their even greater confusion, that I had considered going down to the parish and buying all their cash on hand with a personal check. Churches, much like bars, have much of their weekly income come through electronic payments but still do a substantial amount of cash management through the workweek heading into the weekend. I’m much more a known quantity at church than I am at the friendly neighborhood watering hole. (Also, when attempting to workaround financial infrastructure bugs to get workers their wages, consider relying on counterparties with common knowledge of James 5:4.) I eventually resolved the issue in a more boring fashion: I texted someone I reasonably assumed to have cash and asked them to bring it over. Financial infrastructure normally functions to abstract away personal ties and replace favor-swapping with legibly-priced broadly-offered services. Thankfully, while this outage was surprisingly deep and broad, banks were mostly back to normal on the following Monday. Working title (insurance) → Want more essays in your inbox? I write about the intersection of tech and finance, approximately biweekly. It's free. Get a biweekly email Great! Check your inbox (or spam folder) for an email containing a magic link. Sorry, something went wrong. Please try again.",
    "commentLink": "https://news.ycombinator.com/item?id=41119874",
    "commentBody": "Why the CrowdStrike bug hit banks hard (bitsaboutmoney.com)135 points by sideway 3 hours agohidepastfavorite192 comments jmuguy 2 hours agoMaybe the IT departments at the affected orgs take solace in the fact that so many other orgs had issues that the heat is off - but in my opinion this was still a failure of IT itself. There's no reason that update should have been pushed automatically to the entire fleet. If Crowdstrike's software doesn't give you a way to rollout updates on a portion of your network before the entire fleet, it shouldn't be used. reply candiddevmike 2 hours agoparentThe update bypassed the controls orgs had in place to defer/schedule updates, AFAIK. reply b4ckup 6 minutes agorootparentDidn't day say in their incident report that they have a batched rollout strategy for software updates but this was a config update and the update path for configs does not have such a mechanism in place. reply jmuguy 2 hours agorootparentprevI've had trouble nailing down if thats the case from searching around online. And if thats true - thats absolutely on Crowdstrike. And that behavior should disqualify it from being used on critical systems. I imagine this incident will cause a lot of teams to consider just what can happen automatically on their systems. reply wisemang 2 hours agorootparentIt’s definitely the case. See Crowdstrike’s preliminary post incident review here: https://www.crowdstrike.com/falcon-content-update-remediatio... The nature of “content updates” vs a full product update. Though you may be right, perhaps they provide controls for those updates, I’ve never used their software. But doesn’t sound like it. reply tantalor 2 hours agorootparentprevnext [6 more] [flagged] Sohcahtoa82 1 hour agorootparentYou're living in a different reality. I can't fathom how anybody could legitimately make that claim. Even if you're defining \"critical system\" as \"critical to humans\" and not \"critical to the business\", then sure, you can say \"Airlines aren't critical\" and for most passengers, yeah, you're probably right. Most industries aren't critical, so businesses being ground to a halt doesn't matter for the consumers. But 911 systems were affected, and those are certainly critical to humans. If 911 doesn't work, ambulances and fire trucks can't be dispatched, and people die. EDIT: Computers attached to hospital beds, including trauma surgery rooms, were affected. I'm really curious what you think defines a critical system. reply SkyBelow 1 hour agorootparentOne interesting thing I saw is, per a snippet that claimed to be part of Crowd Strike's ToS, it shouldn't have been installed on any of those machines where human life depended upon it (along with no nuclear facilities and a few other exceptions). Is there going to be any fallout from people installing it on systems the software wasn't designed for? Did Crowd Strike perhaps know it was being installed on these systems but ignored it since they were getting paid and it wasn't them violating the agreement? reply manvillej 1 hour agorootparentif a user does something the manufacturer told them specifically not to do, I have a hard time blaming the manufacturer for it. Within an approved use? absolutely, blame the manufacturer. but if you shoot yourself in the foot, don't blame the bowyer just because they sold the bow to you. reply lucianbr 2 hours agorootparentprevHow did 911 services go down then? Whatever system caused that, should be by definition critical, imho. reply peddling-brink 1 hour agorootparentprevAccording to the crowdstrike tos, sure.. reply kelnos 2 hours agorootparentprevIf that's the case, that doesn't change GP's point: if Crowdstrike can bypass your org's controls on rolling out updates to its software, it shouldn't be used. reply qaq 2 hours agorootparentprevGenerally none gates content updates as they happen multiple times a day reply lucianbr 2 hours agoparentprevManagement decides to use Crowdstrike, not IT, and IT has no way to rollout updates in controlled fashion. So not really a failure of IT, at least not for this reason. reply jmuguy 2 hours agorootparentMy comment assumes that the IT department (including its executive) gets to make these sort decisions - why wouldn't they? reply mingus88 2 hours agorootparentIn many mature orgs, corporate IT rolls up to the CIO and security will roll up to the CISO The CISO and security ops will demand to be completely independent from corp IT, for legit reasons, as the security team needs to treat IT as potential insider threat actors with elevated privileges. They will also demand the ability to push out updates everywhere at any time in response to real-time threats, and per the previous point they will not coordinate or even announce these changes with IT. There has always been an implicit conflict between security and usability, because of the inherent nature of security deny policies, but they also inherently conflict with conservative change management policies such as IT slow rolling changes through lower environments on fixed schedules and operating with transparency reply valenterry 2 hours agorootparent> The CISO and security ops will demand to be completely independent from corp IT, for legit reasons, as the security team needs to treat IT as potential insider threat actors with elevated privileges. I always wondered: why should security ops not be a potential insider thread actor? In fact, if they were compromised, it would be even worse. Do we need two different security ops that monitor each other? :) reply briffle 1 hour agorootparentIn most clustered systems, you need at least 3 observers, so that its a clear majority of systems can decide that the observer is not working as expected. So I guess 5 security OPS teams in different regions of the world, and they can all call a vote if one of the teams is now 'bad' :) reply com 1 hour agorootparentprevGenerally, act vs monitor is the segregation of duties that I have seen best working between platform or IT ops and engineering (act) vs security ops (monitor). For many high privilege operations there are more segregation of duties in the act side of things - these can be down to plan, authorise, configure, activate, validate or some rollups of these. Another is dual control on the act side, since conspiracy is generally quite hard to do especially if it’s just for pocket-change. Different if it’s $$Billions of fungible cash of course at stake. People often overcomplicate - simple do/check is often enough. reply jachee 1 hour agorootparentprevIsn’t that why some organizations have a red team and a blue team? reply com 1 hour agorootparentprevSecurity should not, in general, have anything but awooga-awooga red lights and sirens break-glass write/change/delete/shutdown access to prod infrastructure or systems, or indeed anything that could compromise them. I’d argue that access to read or copy sensitive data is almost, but not quite as dangerous without extensive controls and internal monitoring too… IMO there are no legit reasons except politics, empire building, NIH and toxic relationships for such a such a crazy state of affairs. reply patmcc 2 hours agorootparentprevIT doesn't steer the ship in banks (and bank-like orgs). IT gets a mandate from the real decision makers that they have to choose something that does x, y, z - see \"Regulations which strongly suggest particular software purchases\" in the article for examples of x, y, z. So sure, IT gets to \"decide\" - between CrowdStrike, SentinalOne, or Palo Alto (and maybe a couple others). But they don't really have much choice, they can't use an OSS solution, or roll their own, or anything else. They have to pick one of a small number of existing solutions. reply Retric 2 hours agorootparentprevMajor purchases tend to be pushed up the ladder. It’s not uncommon for a CEO or non technical director etc to decide what IT systems to use. reply fullspectrumdev 1 hour agorootparentIn my experience the decisions on any non trivial IT system rollout are made by entirely unqualified, non technical execs who are usually swayed by marketing such as clownstrikes Super Bowl advertisement. Technical people will make a recommendation, knowing it’s going to be ignored and that the decisions already been made. reply lucianbr 2 hours agorootparentprevSure, if there's a security exec who made the decision, it may be their fault. I was thinking more of the rank and file, but that's just my bias. reply toddmorey 3 hours agoprevWas anyone else surprised how little disruption they personally experienced? I had braced for impact that weekend. But all my flights were perfectly on time, all my banking worked, providers worked, and sites & resources were available. I don’t know if I somehow just have little exposure to Windows in my life or if there’s an untold resiliency story for the global internet in the face of such a massive outage. All I can say is THANK YOU to all the unsung heroes who answered the call and worked their butts off. Infrastructure doesn’t work without you. We see you & we thank you! reply blackoil 2 hours agoparentIIRC only 5% of Windows machines were affected. So, it is very probable that most people just saw the news but have no real impact on them. Some had minor and maybe memorable impact, like Indian airlines giving handwritten boarding passes. reply bostik 27 minutes agorootparentCrowdstrike took out less than 1% of the global Windows installation base. But they took out a far larger fraction of installation base in regulated industries. The very industries who are tightly regulated because they are supposed to keep the wheels of the society turning. Supply chain risks are everywhere, and in regulated industries they are highly concentrated. reply davio 2 hours agoparentprevI was unaffected on my work laptop. One of my coworkers is a long-timer and said when the company first got laptops there was a huge \"OMG leave your laptops on overnight\" push to make sure updates were applied. I always at least sleep if not shut-down after work so I guess I missed out reply doubled112 2 hours agorootparentI know at least one person who \"survived\" while her coworker's laptops were down. My first question was \"do you shut your machine off at the end of the day?\" She did, and that's probably why about half of her office was affected, and the other half was not. Can't update it if it isn't on. reply duderific 1 hour agoparentprevI was flying back to the US from Mexico on United the day after the meltdown. Reading the news, I was obviously quite concerned about how it was going to go (I was traveling with my 10 and 6 year old kids). Amazingly, everything went off without a hitch; not even the slightest delay. I asked the guy at the luggage counter, and he said the day before was pretty crazy, but they had everything straightened out by the next day. reply marcosdumay 2 hours agoparentprevPeople found a really quick workaround. It would take a couple more days to fix if there wasn't any. reply yowzadave 1 hour agoparentprevI wish that were the case for me! My in-laws had their flight out of JFK delayed by 2-3 days, as did my daughter who was supposed to fly as an unaccompanied minor. reply bdjsiqoocwk 2 hours agoparentprev> all my banking worked Vanguard.co.uk was down. But yes, I echo your feelings. When you examine how complex everything is under the hood it's almost unbelievable that anything works. reply pantulis 3 hours agoprevThis is a good writeup, but to be fair it's just not a matter of banking regulations. Basically all big companies are under similar obligations regarding endpoint protection. reply candiddevmike 3 hours agoparentShould endpoint protection require kernel level access? At what point does it stop becoming protection and start becoming a liability? Obligatory who watches/protects the watchmen/protector... reply greenn 3 hours agorootparentWith the current model kernel level access is required. Real security products have to be able to operate above userland. Ideally in the future there can be a layer in between userland and kernel for this sort of thing. Maybe we use some of those extra protection rings? reply tmm 2 hours agorootparent> Maybe we use some of those extra protection rings? Maybe not. Intel is considering removing rings 1 and 2 for a future 64-bit only x86 architecture, because they \"are unused by modern software\". https://www.intel.com/content/www/us/en/developer/articles/t... reply bluGill 2 hours agorootparentI don't think those extra rings would be useful for what is needed anyway. reply ghusto 3 hours agorootparentprevCouldn't you just ask some OS APIs provided by something in kernelspace for what you need? In fact, isn't this how macOS does things? reply btilly 2 hours agorootparentYou could, and in fact this is what Microsoft wanted to do. The EU said that they couldn't. And the reason why not is simple. Anything that Microsoft thinks is a good thing to add to the API, they'll add for themselves. When the new API is released, their software is released with it. This gives them a competitive advantage over competitors who have to wait for Microsoft to have the idea that they want, and then scramble to implement it after Microsoft does. The EU is suspicious of this for the simple reason that Microsoft has a several decade history of doing exactly that. Repeatedly. My favorite example being the release of Windows 95 with Microsoft Word available at the same time, and with WordPerfect unable to run. By the time WordPerfect had figured out how to port their software to Windows 95, they were no longer the market leader. reply bluGill 2 hours agorootparent> Windows 95 with Microsoft Word available at the same time, and with WordPerfect unable to run That is somewhat revisionist history. WordPerfect admitted at the time they saw OS/2 as the future and were focused on that. Only in hindsight did they realize OS/2 was going nowhere (too bad, it was better than 95) and had to rush to get a WordPerfect for 95. Worse for them, they wrote each release of WordPefect in platform specific code (mostly assembly) so it wasn't a case of port to 95 it was a case of start over mostly from scratch. Yes WordPerfect lost to Word with 95 - but it was bad decisions on WordPerfect's part. They had opportunity to get WordPerfect on 95 much faster. I don't know if it would have been fast enough, but they didn't even try until it was too late. reply btilly 1 hour agorootparentSorry, who is being revisionist here? The use of platform specific code was a performance necessity at the time, everyone did it. Part of the promise of Windows 95 was that it could run your Windows 3.1 programs. They bent over backwards for a ton of programs, but not WordPerfect. Microsoft also had an early access program to Windows 95. WordPerfect applied for it - and was denied access. After that the OS/2 bet was their only real hope. The truth is that Microsoft had a long and documented history of using one monopoly to leverage into another. Over and over again they lost antitrust lawsuits, but internally regarded them as speeding tickets on the way to greater monopoly power. This history showed up in court. The internal documentation on the WordPerfect case showed up in the Netscape case, and is part of why Mocrosoft won. It wasn't until the EU started charging Microsoft over $400 million per day for noncompliance in 2006 that Microsoft's attitude started to change. Now I see them as just normal big guys with a worse than average history. But back in the 90s and early 2000s? They EARNED the title of \"evil empire\". reply diffuse_l 2 hours agorootparentprevThere is another point to consider here. The state of anti-virus solutions before Microsoft released Defender was horrible (probably still is). It was full of ad infested solutions, which would crash your computer from time to time. Defender at least was reasonably performant and tended to be stable. You could say that since they had access to kernel source, they were better informed, but I guess if there was an API, the provided documentation would solve the issue (not necessarily, not everyone bothers to read the docs). But then you get back on how to enforce equal and open access for everyone (the EU did try to make Microsoft open the Word file format, but turned out it was so complicated and documented in legacy code only, that Micorsoft had trouble giving useful docs) Anyway, as you said, it's complicated... reply btilly 50 minutes agorootparentYes. Defender was legitimately better than the alternatives. In fact no AV at all was better - which is something that I learned from Google's Project Zero. reply crmd 2 hours agorootparentprevThis is why tech conglomerates are anti-competitive and need to be broken up. There is no reason a leading operating system company should be allowed to also be a word processing, video conferencing, and music-selling company. They will leverage their control of the operating system business to gain unearned competitive advantage in the unrelated markets. reply bluGill 2 hours agorootparent> There is no reason a leading operating system company should be allowed to also be a word processing, video conferencing, and music-selling company. If I write a new OS how will you force the \"word processing, video conferencing, and music-selling\" companies to write code for it? If they don't write the above my OS is worthless, but if my OS fails in the market anyway they just wasted a lot of money. This is why OS companies tend to have the other things, their OS cannot exist in a vacuum and the only way to ensure they have those needed tools is to write them themselves. reply btilly 1 hour agorootparentYou work deals for early access to your OS, and work to make your OS backwards compatible. Nobody wants to try to be selling consumer software that is optimized for the out of date and unsupported version of the OS. reply bluGill 1 hour agorootparentThat only works if you are big enough. If you are BeOS trying to get your new better OS going you don't have the power to make any deals. For that matter Microsoft wasn't big enough, WordPerfect was going after IBM's OS/2. reply btilly 23 minutes agorootparentLet me check what came out in court. https://redmondmag.com/articles/2014/04/28/court-nixes-novel... The case brought to light an Oct. 3, 1994 memo from then-Microsoft CEO Bill Gates, who indicated that Microsoft should withhold namespace extension APIs in Windows 95 from its competitors, WordPerfect and IBM, in order to gain market advantage for Microsoft Word. In other words, your revisionist history is wrong. Microsoft really was big enough. We know that because WordPerfect asked for early access to Windows 95. It was Microsoft who turned them down. (And no, I don't believe Gate's testimony about security. I think that Gates was bamboozling the judge, and the judge bought it.) (I had misremembered which court case brought that memo to light. But regardless, it was obvious to the whole industry at the time. Incidentally this memo came while Microsoft was under a consent decree signed on July 25, 1994 with the Justice Department to not try to maintain their monopoly by tying specific products to Windows. Technically, they didn't here, but they were walking the line. They crossed the line with IE though, and that later resulted in the Netscape loss.) As for BeOS, the question was how a LEADING operating system company was supposed to cope with getting software for the next version of their OS. No matter how many good things we can say about BeOS, they never got to the point of being a leading operating system company. reply lucianbr 2 hours agorootparentprevThe way I see it, Microsoft sells some antivirus software, and also gets to decide who is allowed or not to compete with their antivirus software, by providing or denying access to the API. Obviously unfair. reply bluGill 2 hours agorootparentI think anti-virus should be part of the core os. This does kill all third party vendors - good riddance to most of them, sorry if there is one that isn't evil (I'm not aware of it) reply lucianbr 2 hours agorootparentOnce the AV vendors exist, killing them, especially by Microsoft, is clearly anticompetitive. If you could prevail on a government to decide that, maybe it could work. One thing I see, is that AV has a component of maintaining a DB of signatures of bad things. This does not seem at all the job of the core os. Would the Debian team maintain such a DB? reply bluGill 1 hour agorootparentIt happens all the time that the big companies take something in house and kill a market. The car radio market is all but dead now that manufactures ship decent radios. reply ghusto 2 hours agorootparentprevInteresting! I guess there's no way to fix this with further regulation either, since it would be some work to prove MS had access to the API contracts before they released them. The ultimate lesson then is to stop using MS stuff. reply davidgerard 2 hours agorootparentprevDon't believe the hype from MS. If this was really an unreasonable requirement MS could have just done it in an EU edition. But they didn't. reply mywittyname 2 hours agorootparentprevMicrosoft was on their way to doing this, but was shot down by EU regulators because the APIs weren't available to all third-party vendors. reply armada651 2 hours agorootparentI think it's kind of ridiculous to then blame the regulators for the fact that Microsoft decided not to go ahead with a more competitor-friendly design. The fact that Microsoft abandoned it as soon as a regulator pointed out how anti-competitive the design of the API was makes you wonder what Microsoft's true intention was. To me that implies the anti-competitive design was its main feature and to Microsoft it would've been pointless to continue without it. reply jen20 2 hours agorootparentprev> With the current model kernel level access is required. On Windows. reply c0balt 2 hours agorootparentNote: At least on Linux the main alternatives for this, either eBPF (e.g., pulsar or falcon) or a kernel module, both require this too. reply kelnos 2 hours agorootparenteBPF is at least somewhat sandboxed, no? So it doesn't quite have the access required to accidentally stomp on any portion of kernel memory it wants? reply c0balt 2 hours agorootparentIndeed it's executed via a Jit on something like a VM. However it can still, make your system quite disfunctional if, e.g., all filesystem or network calls are blocked. reply notepad0x90 2 hours agorootparentprevYes, it needs kernel access given the userspace api's available in windows. Period. not a single person who knows how the tool works and the threats it protects against has said other wise. userpace can't disable or tamper kernel space but an admin/root process in userspace can. reply candiddevmike 1 hour agorootparentFWIW I asked if it should require access, not what the current status quo is/what limitations exist within the OS. reply notepad0x90 8 minutes agorootparentIt isn't a status quo, it is the design of the windows operating system, as well as Linux. Macos does it's own thing but it is somewhat effective because you need to go into recovery before you can disable sysexts as root. Imagine needing to go to windows recovery environment to disable drivers, that won't fly. Apple can do that because they control the hardware and software, you rarely need to mess with sysexts as part of troubleshooting as a result. Unlike normal software development, anti-malware software has to be resilient against all kinds of tampering. The price for having an os that isn't heavily locked down and tamper resistant due to hardware enabled checks is having to rely on kernel mode code to enforce tamper resistance. Evasion is another issue, you can already hook api calls from user space (some EDRs do this) but evading it as a privileged user is trivial. It boils down to how on x86/x64 the cpu enforces 3 major privilege rings, by design things that are integrated with the OS that require OS level privileges and system wide access must run in the same ring as the OS (ring0/kernel mode). There are many ways to tackle this but I haven't heard of any (even from Microsoft's blogs/proposals after the incident) that won't reduce the capabilities and tamper/evasion resiliency of these security softwares. if x64 had a \"secure world\" concept like ARM for example, that would be different but it doesn't. reply jabroni_salad 2 hours agorootparentprevIf you don't do it, someone else will. Unless the OS is locked down to the point that even its owner cannot do that. Actually, this is something I like about Operational Technology, you run into a lot of doodads where the elevation process requires turning a physical key, and the device's main functionality is disabled while it is in service mode. Ofc the doodad has to be engineered to operate reliably, perpetually, for years, and you cant really expect that from a desktop computer. reply bluGill 2 hours agorootparentI have said for 20 years now that Microsoft Word should have a check on startup, if the current user is administrator it should put up a message that administrators are not allowed to use a Word Process, login as someone else. This one change would solve a lot of problems. Even on home machines where no user has a password, having to do something special to get into administrator mode will stop several attacks just because people will slow down and ask. reply codewench 1 hour agorootparentThat's pretty much what Microsoft tried with the UAC prompts, and that was fairly universally disliked. Not that I disagree with you, running as admin by default is a terrible practice, but it's a tough sell to the general public reply Vogtinator 1 hour agorootparentprevWould that actually have a positive effect? Running malicious software in the only user's context can already cause maximum damage: https://xkcd.com/1200/ This would just result in more UAC prompts and thus annoyed users who get taught to click on \"Allow\" whenever a dialog pops up. reply Dalewyn 1 hour agorootparentprevAdministrators can and should be able to do anything and everything, that is literally an administrator's job description. Also, if you want to stop everyone from using administrator accounts, the simplest way is to not have the Windows installer/OOBE setup make an administrator account first. Windows has a built-in Administrator account already not unlike Root in Linux, there is no reason (other than tradition and absolute convenience) the Windows installer/OOBE setup needs to make an administrator account for the user installing/setting up. reply supriyo-biswas 2 hours agorootparentprev> At what point does it stop becoming protection and start becoming a liability? If such outages were more frequent, then it could definitely become a liability. But such risks have to be balanced against the risk of being compromised and leaking customer data and other confidential trade secrets, and the risk posed by the latter one is far higher, not to say it's also more common. reply adrr 2 hours agorootparentprevHow else would you monitor a windows box? EU won't allow Microsoft to lock down their kernel and provide MacOS type solution with APIs for trust publishers. reply imtringued 2 hours agorootparentFrom what I have heard, Microsoft is allowed to do that, they merely aren't allowed to be a competitor to the software that uses the API. reply SkyPuncher 2 hours agorootparentprevYes. Absolutely yes. It's the only way to detect certain types of advanced threats. reply SkyPuncher 2 hours agoparentprevBasically all B2B companies are under some sort of obligation to have endpoint protection. All of these requirements essentially become transitive across a company's entire supply chain. * Big bank needs to comply with X, so do all of their vendors. * Vendor wants to sell to big bank, so they comply with X. They also need all of their vendors to comply with X. * So on and so on. ---- Ultimately, there are a lot more options than CrowdStrike, but this is a case of \"Nobody gets fired for buying IBM\". Even if CrowdStrike isn't the \"best\", it's good enough. Because it's use is sooo widespread, an issue with it often affects dozens and dozens of other companies when you're affected. One of the great things about this effect is everyone \"goes down at the same time\", so people don't tend to point fingers at you. In fact, they might not have any clue you're down because some other, more critical system is down internally and preventing them from accessing you. I remember a similiar situation happening a few years back. A big outage hit large parts of the internet. A pretty major part of our app got taken offline with this outage. This was a known risk and something that we accepted. We expected some backlash and inquires if this situation should ever happen. It was a calculated risk to dedicate more effort towards building customer-facing value. I think we got one inquiry. It was basically just an FYI. This person had so many things broken on their end that \"one more thing\" being broken was just a drop in the bucket. reply SoftTalker 3 hours agoparentprevIf not regulations, then demands by insurers for cyberattack insurance coverage. reply taeric 2 hours agoprevAny explanation that doesn't boil this down to \"software required by corporate policy checklist not written by technical team\" is almost certainly missing something here. This is almost definitionally policy capture by a security team and the all too common consequences that attach. The section that goes over why this wasn't federally pushed is largely accurate, mind. Not all capture is at the federal level. Is why you can get frustrated with customer support for asking you a checklist of unrelated questions to the problem you have called in. And the super frustrating thing is that these checklists are often very effective for why they exist. reply saltminer 1 hour agoprev> This created a minor emergency for me, because it was an other-than-minor emergency for some contractors I was working with. > Many contractors are small businesses. Many small businesses are very thinly capitalized. Many employees of small businesses are extremely dependent on receiving compensation exactly on payday and not after it. And so, while many people in Chicago were basically unaffected on that Friday because their money kept working (on mobile apps, via Venmo/Cash App, via credit cards, etc), cash-dependent people got an enormous wrench thrown into their plans. I never really thought about not having to worry about cashflow problems as a privilege before, but it makes sense, considering having access to the banking system to begin with is a privilege. I remember my bank's website and app were offline, but card processing was unaffected - you could still swipe your cards at retailers. For me, the disruption was a minor annoyance since I couldn't check my balance, but I imagine many people were probably panicking about making rent and buying groceries while everything was playing out. reply MadVikingGod 2 hours agoprevWhile reading this I was struck with an interesting question: What risk does any particular software vendor pose to an industry at large? For example (making up numbers here): if 75% of all airline computers have croudstrike falcon installed that seems like a very concentrated risk. I actually wouldn't be surprised if we had this we would see really high concentrations of a small number of vendors in any industry. reply anticristi 1 hour agoparentThe EU DORA regulation (Digital Operational Resilience Act for Financial Entities) has explicit provisions to avoid concentration risks. I heard a story that a bank was forced to use Google Cloud, because two other banks were already on AWS and Azure. reply kristaps 2 hours agoprevThe article specifically mentions US banks and as I personally didn't see any disruption over here - is there (anec)data on how popular CrowdStrike is in the US vs the EU? reply Muromec 2 hours agoparentCan't have disruption from CrowdStrike if you run on IBM mainframes with cobol coz your math only opens gates for new technologies once in 25 years. reply Ekaros 1 hour agoparentprevMight be question what type of disruption it is. Transfers and web bank is likely to work. Branches offices and ATMs might have issues. So if you try to do anything in person or negotiate anything with workers in bank there could be issues. reply adrr 2 hours agoprevDid it really hit banks hard? Core banking systems don't run windows, they run on mainframes typically on IBM z/OS. I know it hit the financial firms hard and knocked out their trading systems but I don't know of any major bank losing their core bank system due to crowdstrike. Australia got hit hard because they modernized their bank systems and now most are cloud based. I am not aware of any major bank running their core systems on the cloud or on windows. reply tempodox 1 hour agoparent> they modernized their bank systems You mean they made them more vulnerable? reply bob1029 2 hours agoprevI feel like this only impacted the larger banks. I've heard absolutely no explosion noises coming from smaller institutions. The effect of regulations and their enforcement is felt differently across the spectrum. There is something to be said for a diverse banking industry when it comes to this kind of problem. Also, this event is a powerful argument for keeping the core systems on unusual mainframe architectures. I think building a bank core on windows would be a really bad choice, but some vendors have already done this. reply hpen 3 hours agoprevWe blame car manufacturers for defects from suppliers, but we don't blame platform manufacturers (Microsoft) for holes in their architecture? reply cibyr 2 hours agoparentYou don't blame your car's manufacturer if it won't start because the monitoring dongle your insurance provider sent you in exchange for a discount drained the car's battery. reply vel0city 2 hours agoparentprevIf I add a NOS kit to my car and it blows up my engine, is that Honda's fault? reply hpen 1 hour agorootparentDoesn't Honda say \"don't do this or it's your fucking problem\" reply vel0city 50 minutes agorootparentRight, so adding the NOS is making a third party addon that changes the behavior of the product outside the original designs of the product. And installing a third-party kernel module (driver) is...a third party addon that changes the behavior of the product outside of the original designs of the product? Honda didn't build the engine with NOS in mind. Microsoft didn't build the NT kernel for CrowdStrike. It is a third-party modification to the system the user chose to add on after taking delivery of the product that ultimately changes the behaviors of the system. Arguing like Microsoft is liable for CrowdStrike's bad software is like arguing Honda is responsible for that NOS kit. If I write a buggy kernel module that instantly kernel panics my Linux system, is Linus Torvalds responsible? Or am I responsible for the software I wrote? reply hpen 15 minutes agorootparentThe analogy falls apart because Microsoft's platform is meant to integrate with third party software, that's a feature of the system. If the \"feature\" can take down the system it's a fault of the system. If you zoom out, Microsoft has a system, a feature allowed on that system, signed by a cert, etc, can take down 8.5million devices of your system, that is a fault of your system. A counter example of how to architect the thing? MacOS, Linux. reply vel0city 10 minutes agorootparentKernel panics happen on MacOS and Linux as well. I don't get why you seem to think they're immune to buggy kernel modules. https://access.redhat.com/solutions/7068083 https://lists.debian.org/debian-kernel/2024/04/msg00202.html https://forums.rockylinux.org/t/crowdstrike-freezing-rockyli... Anyone can make a program that can crash MacOS or Linux especially when you convince the user to install it with very high permissions. It is really not too difficult. > Microsoft's platform is meant to integrate with third party software Sure, but Microsoft offers no warranty to any of the third-party software. Just like Honda offers no warranty to third party modifications made to your car. Which yes, its normal and fine to use non-OE equipment on your car, but if you swap OE equipment with non-OE equipment they're no longer going to warranty that equipment. It is not like every component of your car is welded together. Going back to your original comment here, CrowdStrike was not in any way a supplier of parts to Microsoft. This is why Microsoft shouldn't be held responsible in the same way auto makers are liable for the parts by their suppliers. And even then, often with the way auto parts suppliers' contracts are written the final liability just might lay on the parts suppliers! It is not like Honda went under with the Takata airbag recall. Microsoft isn't going to warranty Chrome having a security issue with their JS sandbox or Photoshop corrupting a file. Neither is Apple if it happens on MacOS. reply SirMittens 2 hours agoparentprevI think that's the wrong analogy. A more correct one would be \"Should we blame a car company for a broken engine, that was modified after it was sold to you?\". A kernel level driver from a 3rd party is something that you willingly add to the OS, it wasn't there. Just because windows allow you to do it, doesn't mean you should. I mean, you can apply some dangerous mods to your car's engine, but you probably shouldn't, and if you do, it's your responsibility, not the car company. reply hpen 1 hour agorootparentDoes crowdstrike void the warranty like an engine add on? reply vel0city 49 minutes agorootparentIf you had a support contract with Microsoft for your Windows installs and CrowdStrike is breaking your system they'll tell you to go talk to CrowdStrike, yes. reply hpen 6 minutes agorootparentOk I didn't realize that crowdstrike was more of competitor or maybe a hacky add-on (like a NOS). I was under the impression that it was something more in cooperation (not owned by or anything) but with Microsoft in terms of market support. reply voytec 2 hours agoprev> Another way is if it has recently joined a botnet orchestrated from a geopolitical adversary of the United States after one of your junior programmers decided to install warez because the six figure annual salary was too little to fund their video game habit. Fictional statements like this make me reluctant to read further, and ignore source of such \"news\" in the future. reply bdamm 2 hours agoparentIt's obviously fictional, but let's call it contemporary drama based on a true story. I thought the point was well made. The author already noted this was a handwaving segment. reply davidgerard 2 hours agoparentprevwhat makes you think it was fictional? also, bragging about your inability to read text seems an odd way to interact. reply voytec 2 hours agorootparentBragging? Reluctant==unable? reply waihtis 3 hours agoprevRegulations are a big reason why this happened, sure, but also it hit the companies with great security budgets more. Hospitals, for instance, weren't that widely affected as they barely have any money to buy security tooling. Silver linings and all that, I guess. reply cookiengineer 3 hours agoparent> Hospitals Everybody seems to be quick to forget about WannaCry. reply c0balt 2 hours agorootparentWannacry was not an accident. It was inarguably an intentional attach against general IT infrastructure instead of a borked update. reply waihtis 2 hours agorootparentprevThat really just proves my point. reply shadowgovt 1 hour agoprevJust as a general comment on this whole affair: This would be the third incident I'm familiar with of a file of entirely zeroes breaking something big. Folks, as much as we wish it weren't true, null comes up all the damn time, and if you don't have tests trying to force-feed null into your system in novel and exciting ways, production will demonstrate them for you. Never assume 'zero' (for whatever form zero takes in context) can't be an input. reply tempodox 1 hour agoparentAs long as the botchers get away with impunity, they won't “waste” resources on higher standards. reply Retr0id 3 hours agoprev> For historical reasons, that area where almost everything executes is called “userspace.” It's an old term at this point, but I don't think the reasons for it being called \"userspace\" have changed or become outdated since then, so I wouldn't call them historic per se. reply Macha 3 hours agoparentThings have gotten messier with virtualization, containerisation, hypervisors etc. The internet loves to produce pedants to argue the post should go into the finer points of these even when it's not relevant to the message. And so people like the author have a defensive reflex to throw in some language to bounce the pedants away. reply SoftTalker 3 hours agoparentprevI used to like Patrick's posts but lately they are way to long and full of irrelevant minutia. Decide who you're writing for, and write to that audience. reply rescbr 54 minutes agorootparentSome of his audience likes the irrelevant minutia. reply shadowgovt 1 hour agoparentprevWhy is it called \"userspace\" when all it runs is some Docker containers hosting a web frontend's server, and no human being ever telnets into it? Where's the \"user\" in that story? Where is the \"user\" when the machine is a Windows box stuffed behind a façade wall that displays airport directions, notifications, and ads on rotate? reply anticristi 1 hour agorootparentI always understood \"user\" in \"userspace\" as \"the user of the operating system kernel\". reply btbuildem 3 hours agoprevThe takeaway from this article seems to be: buy crowdstrike shares, because major corps are unable to make any changes, and will continue to pay licensing fees for this \"service\" for the foreseeable future. reply candiddevmike 2 hours agoparentThe lawsuits alone are going to be eyewatering. But sure, buy those shares. reply davio 2 hours agorootparentDelta airlines is in the headlines saying they had a $500 million impact and have no choice but to sue reply lucianbr 2 hours agorootparentprevJust spitballing, but I think the lawsuits will take years to come to any conclusion, and in the mean time Crowdstrike will continue to be paid and make a profit. And the conclusion is not really predictable. reply tempodox 1 hour agorootparentprevI admire your optimism. reply dangus 1 hour agorootparentprevDo any of their customers have a case? I'm pretty sure their contracts would cover this kind of outage as an expected eventuality. A lot of lawsuits are going to be thrown out, I think. reply tootie 3 hours agoparentprevThis is going to crush their sales pipeline and lead to at least a few attempting a migration off. Crowdstrike is unlikely to go out of business, but this is not a good time to buy. reply nkassis 3 hours agorootparentSolarWinds comes to mind they haven't fully recovered but they are still around and kicking. reply nappsec 2 hours agorootparentprevThat depends what sort of timeline you're looking at. I wouldn't be surprised if the price fell more, but the markets are forward looking and long term they're a key player in the space. reply nerdponx 2 hours agorootparentprevSeems ideal. Get in while the price is discounted relative to the overall market. reply dangus 1 hour agorootparentprevJust depends how far the stock falls and at what point it's undervalued. reply alephnerd 2 hours agorootparentprevSafe Harbor: Don't follow random internet commentators opinions on public markets. This is just an opinion and not advice. I disagree. Long term, the fundamentals of CRWD continue to remain unabated. Endpoint protection is still a critical need no matter what - for every bug like CRWD, there's always a company you can point to who's operations were shut down due to an attack. CRWD skimped on QA and customer support, but long term there aren't many other vendors that can provide a similar service, and CRWD is large enough to pull a PANW and M&A into entirely new segments (eg. DSPM with Flow Security, Observability/Data Lake with Humio, ASPM with Bionic) along with greenfield category makers like Charlotte AI for AI Security and AI EDR. There will be short term pain for CRWD's Windows endpoint business with churn to MDE, SentinelOne, Tanium, etc but they have enough dry powder and a diversified security portfolio that they can safely recover within a year at most. > crush their sales pipeline With CRWD sized companies, most of their revenue comes from multi-year contracts and renewals. They'll probably have a decently large layoff in the sales org, but enterprise sales tends to be fairly stable due to contract sizes along with riders about liability reply deepsun 3 hours agoprevI'm still amazed how the blame shifted from Microsoft to CrowdStrike. Yes, CrowdStrike update caused that -- but applications fail all the time. It was Microsoft's oversight to put it on Windows critical path. And banks/airlines etc were hit hard because their _Windows_ didn't boot, not because of an application crash on a perfectly working Windows. reply ctxc 3 hours agoparentThe application (Crowdstrike) was part of Windows' booting process. Windows cannot simply \"skip\" failed drivers. Say Crowdstrike driver failed as a one time thing, Windows skipped it instead of retrying which led to the endpoint being vulnerable and a ransomware happens. We'd be saying the opposite now. This is a high-impact ability Windows offers to applications - and applications should take responsibility and treat it as such. I spoke to another EDR lead I know - they said they had provisions in place to read the dump if boot crashed, check if it was due to their driver and skip it if it was (and then send telemetry after startup so that it can be fixed, probably). Crowdstrike should have done the same. One more thing to note is that we cannot say Windows shouldn't provide this ability - that becomes an anti-trust monopoly, because MS themselves are a competitor in this space. reply mewpmewp2 3 hours agorootparentBut then again ransomware would happen like you said if they skipped it? And ransomware sounds even worse. reply burnished 1 hour agorootparentThe difference is that if windows does the skipping then you probably don't find out until its too late, if the application does the skipping there is the opportunity to set up alerting so you can fix whatever went wrong. reply makeitdouble 3 hours agoparentprevWindows could sure handle this kind of error better, but IMHO it would be a mistake to require Microsoft to absolutely block any path Windows could be crashing due to third party software. We'd end in a situation similar to Mac OS where there's a single gatekeeper and whole industries are subjected to the will of the platform owner. Enterprises have chosen Windows because of that flexibility and control, while having a business partner they don't get with linux. If anything the blame should fall on them for getting hosed even as they fully had the means to avoid that situation. reply CydeWeys 3 hours agoparentprevI don't think \"Microsoft should lock down Windows so hard\" is the solution we want here. I don't want my desktop OS to be a walled garden like iOS is. I want to be able to install software on it that does anything I need to be able to do -- and yes, having that capability to run software at the lowest possible level in the OS does also mean that that software has extra responsibility to be well-behaved, as the OS can't protect the system from it. But I still would rather have that option than not have it (and also I wouldn't use CrowdStrike). reply klodolph 3 hours agoparentprevHow did Microsoft put it on the Windows critical path? (Informational question—I’m not following the issue super closely, but I thought CrowdStrike was a third-party system. Crowdstrike was wrong to put so much code in the kernel. Microsoft was reportedly legally bound to provide this access and allow third-party code to run in the kernel.) reply shombaboor 3 hours agorootparentThere was an interesting article that these third parties who lobbied to run in the kernel and microsoft acquiesced about 20 years ago which led us down this path. https://web.archive.org/web/20061023112233/http://software.s... reply musjleman 2 hours agorootparentIf you dig a little more about what this is talking about, Microsoft did not actually make any kernel related changes. This was just Symantec and McAffee ranting about PatchGuard and MS did not remove it. reply dblohm7 2 hours agorootparentprevMicrosoft added a feature to Windows that allows specially-signed antimalware drivers to be loaded extremely early in the boot sequence and be marked as non-optional. The idea is to give antimalware drivers the opportunity to load first, before anything else has had the chance to start. Furthermore, if a driver is marked as optional and crashes, Windows can reboot with that optional driver disabled next time, preventing infinite crash/boot loops. Obviously that's no good if your antimalware driver gets disabled, so they can mark theirs as \"required.\" Obviously in the CrowdStrike case, we got the worst of both worlds. reply umanwizard 3 hours agoparentprevMicrosoft is not who made the decision to put this on Windows' critical path; CrowdStrike was. Nothing stops you from running whatever dodgy third-party kernel modules you like on Linux or FreeBSD and they could easily cause the same sort of problem. reply Bjartr 3 hours agorootparentIn fact, CrowdStrike has taken down Linux systems in much the same way in the past year (in April I think). It's just that the impact was less widespread. reply Cthulhu_ 3 hours agoparentprevIn the article it states that Microsoft HAD to allow Crowdstrike to run in kernelspace by EU laws, because else MS would have the monopoly on kernel-level security solutions / integrations. reply Macha 3 hours agorootparentThey probably had to, in the same way that banks had to use crowdstrike. Much as it's easy for banks to say \"we use crowdstrike, like everyone else\" rather than implement a bespoke and accountable framework for risk assessment and mitigation for every type of endpoint use case (and argue that case to both the auditor and regular). In this case it's easier for Microsoft to say \"see, they can run in kernel space\" rather than provide a bunch of API functions that achieve what's needed, convince all third party vendors to use them, and put in place a process to convince an auditor that Microsoft security software will never use any knowledge or functionality from the OS outside this. reply ghusto 2 hours agorootparentExactly this. Microsoft did this poorly, so they were forced to allow others to do things poorly too. reply Macha 2 hours agorootparentI guess I don't think that's the sole reason, as I think the incentives would still be in place even if Microsoft authored security software did not run anything in kernel space. reply ghusto 2 hours agorootparentYou mean in terms of third-parties wanting that level of access regardless? I agree, but it would be an easy \"no\" then. reply Macha 2 hours agorootparentIn terms of Microsoft convincing regulators that they aren't and won't use any OS knowledge or private APIs ever. reply fmbb 3 hours agorootparentprevDid they have to? Or did they choose to keep their own security software to run in kernel space thus forcing themselves to let others play by the same rules? reply marcosdumay 2 hours agorootparentprevThey had to allow the same kind of access they have on their own \"security\" software. Nothing in that means they need ring-0 access. reply davidgerard 2 hours agorootparentprevSo why didn't MS lock it down in the US if it's an EU-local rule? Their excuse isn't plausible. reply voytec 2 hours agorootparentYou're spilling cheap propaganda. Microsoft likely never had[0] an appropriate userland-level API in place and them blaming the EU should not be repeated by someone calling themselves a journalist. [0] https://www.youtube.com/watch?v=EGttFWntctU - I need to state here that I do not possess the level of knowledge the author of video presents and therefore am unable to confirm findings included in the video reply imiric 3 hours agoparentprevTo be fair, AFAIK the CrowdStrike driver was WHQL-certified. The loophole is that the driver loaded files at runtime, which made it impossible to predict every failure scenario. Maybe this is the loophole that needs closing. You can't claim a driver is certified for Windows if the manufacturer can push arbitrary files that change its behavior. Especially if that manufacturer has sloppy development practices. I understand that a primary goal of endpoint monitoring software is to be able to quickly react to new threats, and that the turn around time for Windows certification is surely unacceptable in this scenario, but this functionality can never be allowed to jeopardize the stability of the system it's supposed to protect. So it's ultimately on Microsoft to fix this for their users. reply shadowgovt 3 hours agorootparentIronically, this is exactly the failure pattern that the changes in Chrome extensions to manifest v3 try to prevent. You can't provide a guarantee to the end-user of pre-vetted safety when the application is downloading and executing arbitrary code from a third-party source. That's like expecting a static code verifier to prevent all runtime errors. It is, perhaps, a guarantee that no vendor should be expected to make. reply SoftTalker 2 hours agorootparent> You can't provide a guarantee to the end-user of pre-vetted safety when the application is downloading and executing arbitrary code from a third-party source. So a web browser can't be trusted or certified, ever. Unless JavaScript is disabled? reply blackoil 2 hours agorootparentJS lives in a sandbox, that will require a bug to escape. Plugins are out of sandbox and random plugins should be disabled if security is a concern. reply shadowgovt 1 hour agorootparentCorrect, and I should have been more clear. By the nature of what they do, Chrome extensions operate outside the sandbox designed to make attacking the underlying operating system running the browser very hard. Sandboxing is such a way to attempt to enforce a guarantee (modulo sandbox bugs, of course). Since crexs aren't entirely in the sandbox, vetting and signoff is supposed to provide the added assurance of security the sandbox can't provide. And those assurances are hollow when the vetted crex is running arbitrary code from a third-party source. reply asr 3 hours agoparentprevNot MSFT’s fault: https://stratechery.com/2024/crashes-and-competition/ reply Saris 3 hours agoparentprevWhat about the previous crowdstrike bugs that hit Linux systems in a similar fashion? I don't understand how this has anything to do with Windows, Crowdstrike is the one who built the application. reply 999900000999 2 hours agoparentprevI’ve used this analogy before. If I sell you a bike and you remove the breaks you can’t sue me when you crash. Any OS which allows users to do what they generally want to do, also allows users to fubar their own systems. reply btbuildem 3 hours agoparentprevIsn't corporate malware by definition on the \"critical path\"? The article outlines the reasons why that jank runs in kernel space, and why MS is unable to \"downgrade\" it to userspace. reply ortusdux 3 hours agoparentprevIs there any merit to Microsoft's argument that the EU forced them into keeping their kernel accessible by 3rd parties? https://www.theregister.com/2024/07/22/windows_crowdstrike_k... reply kmeisthax 2 hours agorootparentThe EU's rules are that Microsoft can't hoard APIs away from competitors, not that they have to give competitors a kernel driver SDK. If Microsoft says Windows Defender needs a kernel driver, then CrowdStrike gets to ship a kernel driver, too. Microsoft, interestingly enough, is working on a project to add an eBPF[0] runtime to the NT kernel. If they were to use this for their own security products then I doubt the EU would prohibit them from transitioning third-party security products to eBPF programs. Antitrust and competition law do not care about specific technical measures competitors use to compete, just that dominant companies are not shutting competitors out of markets. [0] Formerly \"extended Berkley Packet Filter\", eBPF lets you run safety-verified code in kernel space. Notably, the verifier isn't just a signing check, it can actually ensure the code won't crash the kernel directly. reply ghusto 2 hours agorootparentprevYes and no. As others have pointed out above, it is factually correct that they were forced by the EU to give access to kernelspace. However, it is also true that the only reason for that was that _they_ were using kernelspace for the same things (instead of creating a framework and API into the features needed). reply davidgerard 2 hours agorootparentprevNo. They could have done an EU-only edition that behaved that way. But they didn't. reply gciguy 3 hours agoparentprevDave's Garage has a great video on this: https://www.youtube.com/watch?v=wAzEJxOo1ts reply kmeisthax 2 hours agoparentprevMicrosoft didn't write the Falcon sensor software nor did they put it in the kernel. In fact, Microsoft has been shouting to the heavens trying to shift the blame from CrowdStrike onto the European Commission, because they want people to irrationally hate antitrust so they can turn Windows into shitty iOS and monopolize the security market (and applications market) for it. Furthermore, Microsoft does actually have some rules regarding what you can and can't put into a signed kernel driver. Specifically, they won't sign kernel code unless they've seen and tested it first. CrowdStrike deliberately circumvented this rule by implementing their own configuration format - really, just a fancy way of loading code into the kernel that Microsoft doesn't have signing control over. If there is blame to be had here for Microsoft, maybe it's that their kernel code signing program doesn't scrutinize third-party configuration formats hard enough. I mean, if you sign a code loader, you're really signing all possible programs, making code signing irrelevant. And configuration is more often than not, code in a trenchcoat. It's often Turing-complete, and almost certainly more complicated than the actual programming languages used to write the compiled code being signed off on. But at the same time I imagine Microsoft tried this and got pushback. That might be why they feel (incorrectly) like they can blame the EU for this. Every third-party security solution does absolutely unspeakable things in kernel space that no one with actual computer science training would sign off on, using configuration to wrestle signing control away from Microsoft. Remember: Crowdstrike is designed to backdoor Windows systems so that their owners know if an attack has succeeded, not to make them more secure from attacks in the first place. Corporations are states[0], and states fundamentally suffer from poor legibility: they own and operate far too much stuff for a tribe[1] of humans to meaningfully control or remember. The problem is that we have two different entities that all have the ability to stop this madness. When states run into this situation, they impose \"joint and several liability\", which means \"I don't care how we precisely assign blame, I'm just going to say you all caused it and move on\". In other words, it's Microsoft's fault and it's CrowdStrike's fault. [0] ancaps fite me [1] Maximally connected social graph with node degree below Dunbar's number. reply supriyo-biswas 2 hours agorootparent> because they want people to irrationally hate antitrust One only needs to look at what's happening with Google's privacy sandbox to know the perils of antitrust with regard to introducing new interfaces. Even though Google has offered new interfaces and APIs that they themselves intend to migrate to (and take a ~20% revenue reduction), they've attracted the scrutiny of regulators who claim that this is a way of locking out competitors in the advertising space. > [0] ancaps fite me This part is simply inciting a flamewar, and something that you can do without in the spirit of the website guidelines[1]. [1] https://news.ycombinator.com/newsguidelines.html reply kmeisthax 2 hours agorootparentIt's important to remember that every other browser dropped third-party cookie support years before Chrome did. Google dragged their feet on it until they could come up with a solution that would give Google the same level of tracking, because Google is an advertising company. So the competition authorities are telling Google - and only Google - that they can't drop third-party cookies anymore. I've never actually heard anyone claim Privacy Sandbox[0] APIs would give third-party ad networks the same level of tracking as Google. But I imagine even if they did, the APIs would probably be a poor fit for competing ad networks, in the same way that, say, the iOS File Provider APIs are a terrible fit for Dropbox[1]. There are three different ways you can introduce a new standard or interface: - You can go to or form a standards body with all the relevant market players and agree on a technical specification for that interface. This is preferred, and it's how the Web is usually done. - You can take a competitor's interface people are already using and adopt that. This is how you get de-facto standards, and while they might have loads of technical problems[2], none of them give you an unfair market advantage. - You can make your own interface and force competitors to adopt that. You get all the technical problems of a de-facto standard, but those are all problems your competition has to deal with, not you. The difference is a matter of market advantage. Out of all the major browser vendors, only Google has dominance in online marketing. Microsoft and Apple would like to have a piece of that pie, but they all dropped third-party cookies without tying it to their own competing standards that they wanted to force other people to use. [0] Hell of an Orwellian name [1] For example, if you use Dropbox as your file storage, you can't pick folders. At all. On an operating system built by the company whose engineers are obsessed with bundles (directories that look and act like files instead of folders). [2] laughs in SWF reply ClumsyPilot 2 hours agoparentprevThis is the comment I expected, begging to handover your freedoms to run software to a big carry. If you replace parts in your BMW, and put in some garbage or incompatible parts, it your fault if it doesn’t run. You expect to sue your mechanic if he messed up, and for him to cover the full cost. For some reason people do not expect CrowdStrike to pay for their stupidity, which is the root of the problem. And the management that installed crowdstrike without due diligence reply hpen 3 hours agoparentprevThis is a valid opinion and I don't know why you were downvoted (well other than the hacker news bubble mindset (or mindless-set). How is Microsoft not to blame, it's their product? We wouldn't blame a Toyota supplier for a failure in a car, but we somehow segment that in the software world? reply vel0city 2 hours agorootparentToyota chose the supplier, worked with them on the specs and designs, and put it in their OE car delivered to the customer. It has Toyota's name on it, it was bought at a Toyota dealership, is a part of Toyota's warranty. Crowdstrike is entirely optional software that doesn't come from Microsoft. Microsoft doesn't market it. Microsoft had no hand in making it. Microsoft doesn't sell it. Microsoft had no hand in a user installing Crowdstrike. Do you not see the obvious differences there? reply Sohcahtoa82 1 hour agorootparentprev> How is Microsoft not to blame, it's their product? Do you think Crowdstrike is a Microsoft product? reply hpen 1 hour agorootparentNo. My point is that Microsoft allows the damn thing to be ran in kernel space. Mac, linux don't have this problem due to how THEY architected the system. Yes I think that puts Microsoft at blame. reply vel0city 42 minutes agorootparent> Microsoft allows Microsoft should have no say to decide what software I am allowed to run on my computer. > Mac, linux don't have this problem due to how THEY architected the system. You're joking right? You're arguing kernel panics can't happen on Linux? FFS, the CrowdStrike sensor caused kernel panics on multiple Linux distros in the last few months! Linux is not immune to kernel panics for buggy kernel modules. reply hpen 1 minute agorootparentThe first point is pretty philosophical so I'm not gonna go far into that. At the end of the day you bought a product from a company, some of those products have a way to load programs on and some are locked down (a microwave). \"should\" is pretty biased whether I agree with that conclusion or not. Two: Here I'm not arguing about what's possible but rather what happened in the real world. 8.5 M machines down, my org runs Macs, we knew about it from the news... ClumsyPilot 2 hours agoparentprevThis is the comment I expected, begging to handover your freedoms to run software to a big carry. If you replace parts in your BMW, and put in some garbage or incompatible parts, it your fault if it doesn’t run. You expect to sue your mechanic if he messed up, and for him to cover the full cost. For some reason people do not expect CrowdStrike to pay for their stupidity, which is the root of the problem. And the management that installed crowdstrike without due diligence reply hulitu 3 hours agoparentprevI think they said it was a windows driver, not a normal application. Running crap in kernel mode does not end well on any OS. reply concerned_user 3 hours agorootparentYes it is a driver which is signed and tested by Microsoft. Driver allows to run arbitrary unsigned code. Why is that allowed? reply cyberpunk 3 hours agorootparentThe driver is some kind of AV/Signature detection hook. E.g check every open() for this list of checksums and refuse to open known viruses style system. The 'update' was a borked definition file which triggered a bug in that system. It's not code execution without signing, and I think probably they do want these files to be updated hands free. The real problem was the lack of testing, rather than the actual mechanism I think. reply wolpoli 3 hours agorootparentprevTo get a driver signed by Microsoft, the developer of the driver is required to provide a full cert pass log from the Windows Hardware Lab Kit to dev center [0]. Do you have any article that says the CrowdStrike driver has been tested by Microsoft? [0]: https://learn.microsoft.com/en-us/windows-hardware/drivers/i... reply rtkwe 2 hours agorootparentTo avoid going through the full cert process the sensor was certified but it loaded code from an uncertified module too so that it could be quickly updated to catch new threats. It's a tough corner to be in, to function properly it needs to update very quickly but the cert process takes a while to complete so they went with this work around of a signed module loading uncertified code. reply Sohcahtoa82 1 hour agorootparentprevThe Crowdstrike failure was not caused by running unsigned code. reply Joker_vD 3 hours agorootparentprev...you want Microsoft to forbid you from running certain kinds of programs on your own machine, even if you really, really insist on it, do I understand you correctly? reply hpen 2 hours agorootparentMore like: \"...you want Microsoft to forbid you from running certain kinds of programs (with gaping security holes / processes) on your own machine\" YES reply Sohcahtoa82 1 hour agorootparent> (with gaping security holes / processes) The problem is that you're assuming you can prove a program doesn't having security holes and bad processes. reply hpen 1 hour agorootparentYou're moving the goal post waaaay far down. How about just following best practices? How about not allowing runtime code injection? Turns out security holes often have much in common, and with ways to mitigate them. Stop 100% of security holes? nah. Stop 99.9% of security holes? Yes and what an improvement. reply shadowgovt 3 hours agorootparentprevThis is the nugget of the issue. The code-signing process, in this case, was abused to verify something that, fundamentally, cannot give the guarantee \"Doesn't crash your OS\" because it is allowed to run arbitrary code in the form of novel commands in what is essentially a DSL. So if code-signing is supposed to be a guarantee from MS that \"this code can't crash your system,\" it should never have been signed... But then MS would have been on hooks for blocking a competitor. There is no guarantee the law is written soundly. reply jsmith99 2 hours agoparentprevYes, use a different operating system, one that gracefully handles null pointer dereferencing by third party kernel modules? /s reply __MatrixMan__ 2 hours agoprev [–] I like the technical stuff here. I'm not so sure about this: > money is core societal infrastructure, like the power grid and transportation systems are. It would be really bad if hackers working for a foreign government could just turn off money. Sure, it would be inconvenient in the short term. But I think the current design is holding us back. I suspect that most of us would have more to gain than to lose if we managed to shut off money-as-we-know-it and keep it off for long enough to iterate on alternatives. Any design that even tried to step beyond \"well that's how we've always done it\" would likely land somewhere better than what we're doing. Much has changed since Alexander Hamilton. reply Joker_vD 2 hours agoparentIn the early 90's Russia, essentially, voided almost all of the Soviet money that remained in monetary system (most of which were bank deposits; they simply vanished with zero compensation), allowing rather small upper limit on the amount of old Soviet roubles one person was allowed to exchange for the new Russian roubles. Believe it or not, that really did not help the low and low-middle classes with their growing financial problems; and the upper-middle and top classes mostly operated in dollars (or less often, in deutschmarks) by this time anyhow, so that didn't inconvenience them much at all. reply __MatrixMan__ 2 hours agorootparentLosing access to one currency but not others is quite a different thing, I don't think that would help anybody. What I think would help is something that evolved in a less stable computing environment. Something which had to be partition tolerant. Such a thing would have to remain more closely coupled with the consent and merits of its participants because it would lack a reliable connection to a far away authority (currently used to uphold the wishes of extraneous parties to the transaction). Something like local-first software, but for money. reply gadders 2 hours agoparentprevIn the short term people would probably starve to death. reply Joker_vD 2 hours agorootparentProbably not. A competent government could install temporary rationing for the most essential goods such as food. It happened through the the whole of the 1917—1920 Russian revolution, with four or five kinds of paper money being circulated around, and the urban population managed through it only if barely. That government was much less competent than the US government is today. reply mminer237 2 hours agorootparentI mean, millions still starved during the revolution, even with the American Relief Administration feeding 10% of the country. reply Joker_vD 1 hour agorootparentIn the rural areas, mind you. That's one of the most appalling thing about famines in the XIX-XX, that they hit the countryside heavier than they hit the cities. reply imtringued 2 hours agoparentprev [–] I agree there needs to be more competition, but that doesn't mean you need to get rid of the old way. It is better when two approaches run in parallel, to compensate the other's shortcomings. reply __MatrixMan__ 1 hour agorootparent [–] That would indeed be ideal: one as a backup for the other, and when both are functioning, chose the one that suits you best. I just think that it's outages that will convince us that we need this... stakeholders in the status quo certainly aren't going to do it. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "On July 19th, a configuration bug in CrowdStrike Falcon, an endpoint monitoring software, caused catastrophic failures in Windows systems, severely impacting the banking sector and other industries.",
      "The bug led to widespread operational disruptions, including idling tellers and bankers, and even caused some banks to run out of physical cash, highlighting vulnerabilities in financial infrastructure.",
      "U.S. banking regulators indirectly influenced the adoption of such security tools, which, while intended for protection, can introduce significant vulnerabilities due to their high privileges and widespread use."
    ],
    "commentSummary": [
      "A CrowdStrike bug caused significant disruptions in banks due to an automatic update that bypassed existing controls.",
      "The incident has sparked debates about the risks of relying on single vendors and the necessity for better update strategies.",
      "Despite the widespread issues, some users experienced minimal impact, showcasing the resilience of certain systems."
    ],
    "points": 135,
    "commentCount": 191,
    "retryCount": 0,
    "time": 1722438444
  },
  {
    "id": 41116253,
    "title": "Construction of the AT&T Long Lines \"Cheshire\" underground site",
    "originLink": "https://coldwar-ct.com/Home_Page_S1DO.html",
    "originBody": "Home Page Contributors Business and Industry DOE Site List Bradley Int'l Airport Brainard Field CANEL - Middletown Combustion Engineering Convex Dorr Corporation Electric Boat Ensign-Bickford Fenn Machinery Horse Ridge Cellars Htfd State Tech. College Knoll Labs - Windsor Machlett Laboratories Metals Selling, Putnam New England Lime Co. Norden Systems Olin Mathieson Nuclear Perkin-Elmer Radio Station Shelters SBE FAA Tour Seymour Specialty Wire Sperry Products, Inc. Telecommunications Torrington Company United Nuclear Corp. Yale Linear Accelerator Nike Sites of CT Nike BR-04 Ansonia Nike BR-15 West Haven Nike BR-17 Milford Nike BR-65 Fairfield Nike BR-73 Westport Nike BR-94 Monroe Nike HA-08 East Windsor Nike HA-25 Manchester Nike HA-26 Portland Nike HA-48 Cromwell Nike HA-67 Plainville Nike HA-85 Avon/Simsbury Nike 55' Mystery Nike Site Links ALASKA?S COLD WAR NUCLEA Nike Maint. Facility Civil Defense Conelrad/EBS/EAS Crisis Relocation W Hartford Civil Defense Fallout Shelters Bomb Alarm Network Htfd Public High School Military Facilities 103rd Aircraft Squadron Navy Undersea War Lab Nike ABM Sites SAGE New Preston Submarine Base Groton Bomb Alarm Network Nearby Facilities Chepachet, RI Bunker FEMA Regional HQ Maynard Loring AFB MEMA Bunker Montauk - Ft. Hero NAA Cutler OTHR - Moscow, ME Pease AFB Pepperell, MA Bunker Plum Island Sharpner's Pond ABM Site Stonybrook WSA The Notch - Hadley Westover AFB Radio Station Shelters WELI Bomb Shelter WICH Bomb Shelter WILI Bomb Shelter WNLC Bomb Shelter WQQW Bomb Shelter WTIC Bomb Shelter Telecommunications ATT Blackstone, MA ATT Cheshire ATT Chesterfield ATT Durham Site ATT Meriden ATT Mohawk Mountain ATT Netcong N.J. ATT Peru (MA) ATT Portland ATT Winsted ATT Various Blast Detectors Cold War Links Guestbook Contact Us Coldwar-Ct.com ATT Cheshire The Cheshire ATT facility is an underground complex originally built in 1966. It was an underground terminal and repeater station for the hardened analog L4 carrier cable (coax) that went from Miami to New England carrying general toll circuits and critical military communication circuits. It reportedly housed an AUTOVON 4-wire switch as part of the switching fabric of that critical global military communications network. Cheshire also connected via terrestrial microwave to the major, semi-hardened AT&T Durham station which linked to many other sites including paths to New London (Navy Sub base) and to Green Hill, RI to meet a transatlantic cable to Europe. The Official ATT facility description from 1966: The Cheshire central office is a two-story underground, hardened building owned by Lone Lines and located in Cheshire, CT. This office is manned 24 hours daily. The Plant Manager has a staff comprising four Plant Supervisors and eighteen Craftsmen. Cheshire serves as a metropolitan junction station for Hartford and New Haven and as a junction point and Powercenter for 20L4 coaxial cable on The Boston-Miami route, The 20L3 Chesterfield-New Haven route, the 6L4 Green hill, R.I.-Cheshire, the 12L3 Cheshire-Hartford cable and a TD2 route to Durham via Little City. It also has a #1 ESS Machine on The Autovon Network. Located on a mezzanine floor is The Northeastern Area Restoration Center, manned 24 hours daily. It's Plant Manager has a staff comprising six Plant Supervisors and Six Craftsmen. See also: http://www1.shore.net/~mfoster/Cheshire.htm Construction Phase, 1965/66:Construction Phase The circular cut-out on the left in the above photo is for one of several air intake tunnels. The large corregated metal pipes in the above photo are air intake and exhaust tunnels. (see below). Louver type blast valves. Redundant chilled-water system. Massive amounts of rebar were used to reinforce the concrete. The round penetrations allowed outside air and exhaust to enter/leave the building and supported blast valves on the exterior. When the facility was finished it was covered with a minimum of 10 feet of earth. The next four images show the huge air intake and exhaust tunnels. Also visible in the first photo are the fresh water tanks on the left and the four 45,000 gallon generator fuel tanks in the background. In the foreground: the air intake tunnels On the left, two fresh water tanks. Generator fuel takes are in the background. Air intake and exhaust tunnels. Intake and exhaust. Four 45,000 fuel gallon tanks with 180,000 gallon capacity to power the huge generators which would provide emergency power during power outages and when the facility was locked down. Blast valves being installed on the air intake. You can judge the size by comparing the valves to the two workers in the image. Sewage ejector system. Two of the huge air handling blowers can be seen in this picture . . . part of the massive chemical, biological and nuclear air filtration system. One of the three generators ready to be installed. These units were gas-turbine and manufactured by Solar Crop. Kitchen facilities were provided as the workers would have to shelter on site for up to 30 days. Even the plumbing fixtures are on springs and utilize flex joints so that they will still function after the shock wave from a nearby nuclear detonation occurs. One of the original racks hanging from the ceiling by springs. 1971 image of the Cheshire control room. Contemporary Images: Interior: After checking in with Security and getting buzzed in through two above ground doors it's time to go down the stairs, six flights of them! One of the first things that you'll notice as you go down are the interesting lighting fixtures hanging from the ceiling by springs to provide shock protection. Originally these two solid steel blast doors were mechanically interlocked so that only one could be open at a time to provide overpressure protection from a nuclear blast. First stop is the decontamination shower. Once inside you'll notice that all of the original equipment is mounted to the structure with large springs. The facility's air handling system is immense. The heat load produced by the equipment required that a significant amount of air be moved into the building, filtered, cooled and either humidified or de-humidified. The requirement to remove waste heat was just as stringent. Air is drawn into the facility via three huge intakes such as the one below. The above ground vents lead into these huge ventilation tunnels. The tunnels originally had incredibly heavy duty blast valves connecting them to the facilities interior. The valves have been removed and an access passageway has been cut through the exterior wall of the structure. Note the thickness of the outer wall.The facility utilized a sophisticated air filtration system that would filter out chemical, biological and/or nuclear contamination. Just some of the dozens of battery banks. We've seen these spring-mounted toilets at other hardened facilities! Above: Another ventilation tunnel. One of three 750kVa gas-turbine gensets. The actual turbine engine is surprisingly small. Generator exhaust stacks through wall. The gensets exhaust into the HVAC exhaust tunnel. Spring mounted redundant water pumps. Part of the \"CBR\", chemical, biological and radiological air filtration system. Extremely heavy blast door leading to the hoist chamber. Note the thickness of this door and the latch mechanism. Once unlatched it took an immense effort to push the door open due to its weight even though it was well balanced. Note the size of the hinge. Kitchen and cafeteria. Adjacent to the cafeteria was a room stocked with survival supplies including food, cots, blankets, razors and shaving cream, radiation survey equipment and survival manuals. Clothing was available for contaminated workers including dozens of boxes of brand new Converse sneakers, c. 1968! These underground facilities generally used hoists to bring equipment into the facility rather than elevators we assume because it was nearly impossible to harden an elevator. Access corridor. Above ground: This tower used to support AT&T microwave communications antennas that provided a back-up comm path for the underground coaxial cable. Gamma ray detector. In the background you can see one of the air exhaust gratings. \\ A nuclear blast detector located several hundred feet away from the facility. Content copyright 2021. coldwar-ct.com. All rights reserved.",
    "commentLink": "https://news.ycombinator.com/item?id=41116253",
    "commentBody": "Construction of the AT&T Long Lines \"Cheshire\" underground site (coldwar-ct.com)124 points by walrus01 15 hours agohidepastfavorite61 comments Animats 12 hours agoThat's an AUTOVON switching center.[1] There were at least 38 of those centers in the US. They were located in places some distance from major cities and military targets. They were hardened telephone central offices, but with many more redundant links between switches than the commercial system. So this system really was intended to survive a nuclear war. The technology was Western Electric's 1ESS (#1 Electronic Switching System), and all 4-wire out to the handsets, so that conference calls would work clearly without feedback. 1ESS was a very bulky system. It was basically a pair of large mainframe computers running a big dumb switch fabric. The switch fabric is analog and electromechanical, using reed switches with a ferrite element so they stay in the last state to which they were set. That's why these were such big installations, even though they didn't have a huge number of lines. [1] http://autovon.org reply Aloha 7 hours agoparentThey also had Number 5 Crossbar switches as well, the switching fabric wasn't huge in size, like I've seen what the frames look like, ESS was still much smaller than the crossbar that preceded it, and not that much physically larger than a comparable 5ESS reply metadat 11 hours agoparentprevHow deep did they bury the wires? Were they run full depth from point to point? reply walrus01 55 minutes agorootparentGoogle \"L4 transcontinental cable\", but the majority of the long lines network was the famously known horn antennas on towers for FDD microwave point to point links in the 6GHz band. reply fmajid 9 hours agoparentprevI’m surprised they didn’t use crossbar electromechanical switches for EMP resistance. reply Aloha 7 hours agorootparentThey did - it wasn't all ESS http://autovon.org/wp-content/uploads/2018/01/BELL-LAB-RECOR... reply baliex 11 hours agoprevAs a Brit that map at the bottom is very confusing. A Bristol not to far from a Glastonbury, ok yeah, that makes sense but the map mustn't be north-oriented. Oh, and what's Manchester doing so close to Glastonbury, and that's not where Durham would be, or Norwich, or New Haven. Hmm.. and I didn't think we had a _New_ London. https://img1.wsimg.com/isteam/ip/da3386ad-a465-4e41-834e-354... Also, Cheshire is a county in the north of England so the whole article was very confusing from the get go as to where this station was located. Here it is on Google Maps: https://maps.app.goo.gl/aEWT2L6QYqntYDDz5 Bolton, Kensington, Oxford, Coventry, and—slightly left field—Berlin are also nearby. reply Retric 11 hours agoparentThe 42 degrees north goes through the northern US and northern Spain, but is well south of England. https://en.wikipedia.org/wiki/42nd_parallel_north The New is also a hint aka New York, New Jersey, etc. It’s a map of Connecticut, USA. reply wil421 7 hours agoparentprevThere’s a reason they call the area New England. New York was New Amsterdam before the Brits took it over. reply sdwr 3 hours agorootparentOld New York was once New Amsterdam... reply 1-6 1 hour agorootparentWhy they changed it I can't say People just liked it better that way … Istanbul was Constantinople Now it's Istanbul, not Constantinople Been a long time gone, oh Constantinople Why did Constantinople get the works? That's nobody's business but the Turks reply mindslight 1 hour agorootparentprevZoom out a bit and you get a whole bunch of Manchesters, and none of them had a Factory Records. reply worstspotgain 10 hours agoparentprevThat's why it's called New England. Here out west, most of the anglo town names are the names of settlers (with exceptions like Richmond née upon Thames.) reply mrguyorama 27 minutes agoparentprevhttps://www.reddit.com/r/mildlyinteresting/comments/8o6xc5/r... This sign is just for the singular state of Maine. Notice the two distinct \"Sweden\"s, and that ignores \"New Sweden\" we have way up north. The colonists were not creative with names. reply willwade 10 hours agoparentprevI'm with you. I started reading and was like \"wait.. this is not the Cheshire I know of - where has this been hiding\".. Then on the map: Lebanon and Brooklyn. Also Wallingford. I bet thats nothing like the Wallingford I know of (Oxfordshire Town) reply qingcharles 2 hours agorootparentSo many places in the USA have matching British names I had to check to see if Brooklyn was one of them, but looks like it's named for a Dutch town, which makes sense. reply rob 31 minutes agoparentprevWait until you learn we here in Connecticut also have hundreds of miles of stone walls, just like England! reply PietdeVries 10 hours agoparentprevI stared at Google Earth for a while, using the 41:30 and 73 as a guide, but wasn't able to pinpoint the location of the site. With these huge vents, it shouldn't be too hard to find where this site was located. Anyone an idea? reply jonotab 9 hours agorootparenthttps://maps.app.goo.gl/SpeEBjSmiDFAeqr17 reply worstspotgain 10 hours agorootparentprevWell we wouldn't want the Russians to find out too would we. reply fred_is_fred 3 hours agoparentprevWould guess you don't have a Mohawk either. reply mike503 10 hours agoprevAnyone else in awe at all the infrastructure, systems, etc that were setup especially due to the Cold War? Things like Operation Looking Glass, keeping a staffed plane in the air, 24/7/365 for nearly 30 years, all these kind of hardening projects, it's crazy to me how much work and how many decades it spanned. And that's just the stuff we now can openly read about. I can't imagine all the systems and redundancies in place right now... but probably a lot more digital with analog backup only. reply worstspotgain 7 hours agoparentThe thing that really drops my jaw is the handwaving conjecture that the doomsday risk level has decreased a lot since then. reply snakeyjake 4 hours agorootparentIt's not handwaving conjecture, it is cold calculation. Russia has a nuclear triad the same as the US. 1. Russia's submarine forces have been gutted since the Cold War. Poor training and maintenance has led to a slew of launch failures in recent years and analysis of their deployment tempo seems to indicate only a minimum number of submarines are deployed at any given time. 2. The long range strategic bomber forces of the Russian Aerospace Force are so outdated and vulnerable to western air defense systems that they rarely if ever enter the airspace of Ukraine, with the Tu-160 supersonic bomber lobbing cruise missiles from well outside Ukraine's air defense zone, the Tu-95 doing the same, and the Tu-22 only targeting areas not protected by Patriot missiles. 3. Aging systems, poor maintenance, and a lack of adequate funding has severely hampered Russia's Strategic Rocket Forces. They lack the precision to ensure a favorable outcome in the event of a nuclear war because they were designed for scenarios where dozens if not hundreds of warhead were used on individual area targets in an age where there were tens of thousands of warheads available for use. All of Russia's \"superhypersonic killer nuclear-powered unstoppable death machine weapons test\" rhetoric is an attempt to fool the US into believing that they have something up their sleeve because they know that the US knows that each of the three spokes of their triad have been degraded so much. Russia also knows they can't afford to rebuild their forces, so wonderweapons it is. They can't even build enough radios to equip all of their ground forces in Ukraine with communications gear and their megaweapons programs are hollow vanity projects. Do not mistake any of this for hubris. Russia can still launch nuclear weapons and any such usage would be disastrous. The doomsday scenarios at the height of the Cold War where 40,000 Soviet warheads could be mustered for deployment by a variety of difficult to stop systems to be met with a response of 20,000 US warheads thus irradiating the entire northern hemisphere and dooming humanity to extinction is all but impossible. So unless the definition of \"doomsday\" has changed from \"the extinction of all of humanity\" to \"a really shitty time where hundreds of thousands die in an instant\" the doomsday risk level has indeed decreased. reply worstspotgain 3 hours agorootparentLet me put aside your analysis for a second and whether I find it reassuring or not, and entertain a hypothetical that hasn't even been floated much. Let's say a certain character who may not even be an enemy asset has been elected US president. He's on a trip to Ryadh and a door opens and out comes a certain autocrat and would-be world conqueror. He says he just made a huge gamble. The missiles are in the air, but not to worry. The president character can still be a tycoon in the new monoempire. All he has to do is deny the order in the next 12 minutes. reply flyinghamster 6 hours agorootparentprev2022, nay, 2014 should have been a wake-up call that World War III was underway. reply fmajid 9 hours agoparentprevSee also: https://www.smithsonianmag.com/history/the-town-that-kept-it... reply eddyg 7 hours agoprevMore info on the Long Lines system, for those interested: http://personal.garrettfuller.org/blog/2018/01/19/att-long-l... reply rob 36 minutes agoprevAmazing. I live in the next town over and had absolutely no idea about this. Thanks for sharing! reply 9cb14c1ec0 2 hours agoprevThis is the kind of information I read hn for. Really fascinating stuff that I probably wouldn't know about otherwise. reply 082349872349872 13 hours agoprevThat background though... ( https://img1.wsimg.com/isteam/ip/da3386ad-a465-4e41-834e-354... ) reply msisk6 4 hours agoparentThose MIRVs come in kinda fast: https://www.youtube.com/watch?v=3ZM3y5qpMgY reply pixelesque 11 hours agoparentprevMIRV re-entry test... reply TomMasz 9 hours agoprevMy dad would have been very interested in these photos. He worked for Western Electric and spent most of his time working on Long Lines installations in NYC. reply clarionbell 6 hours agoprevI'm afraid we may have to refurbish these ... quickly. reply krunck 44 minutes agoparentWhy? reply A_Duck 7 hours agoprevAll I can think as I read this is how much education and medical treatment this could have paid for Not that it wasn't sadly necessary... but it seems a waste of human endeavour reply zoombippy 1 hour agoprevMakes me depressed to think that I'll never again enjoy the crisp, clear communication of a landline phone call. reply phone8675309 1 hour agoparentThis is fake nostalgia. There were a lot of places in the world (and still are many places in the world) where the copper phone lines are anything but crisp and clear - lots of noise and hums and clicks and static. That's the rule more than the exception in some places. Now these intrusions are typically not enough to disrupt a voice call, but they were a major issue using modems and DSL. reply metadat 13 hours agoprev> Clothing was available for contaminated workers including dozens of boxes of brand new Converse sneakers, c. 1968! Why would the workers be contaminated? Struggling to understand the purpose of this station, at the top it says coax but why all the fancy cooling and contamination protection? reply space_fountain 13 hours agoparentThese facilities were designed to be hardened so as to survive a nuclear war. The air intakes were presumably needed to provide cooling for the communication equipment inside and decontamination was for any workers who needed to visit after the outside has all been contaminated with nuclear fallout reply nrr 12 hours agoparentprevThis facility is what's called a tandem office in the old long distance telephone network here in the US. The idea was that it formed a link in a routing chain between two end offices when a long-distance call was placed. Cheshire, CT, also happened to be an AUTOVON site, which carried with it military and national security significance. This is why it was hardened against nuclear attack, including the air handling augmentations, decontamination shower, gamma ray detection equipment, and so on. reply bregma 8 hours agoparentprevYou mean \"couldn't they just reboot the server remotely using the terminal on their Mac after the crazed fools in the White House and the Kremlin annihilated civilization through nuclear holocaust in 1968?\" Well, all I can say is thank goodness we're not in that situation today so that people don't understand the \"why\"s. Aren't we? reply diggernet 13 hours agoparentprevThe site was built to survive a nearby nuclear attack. reply BoorishBears 13 hours agoparentprevFirst lines: > The Cheshire ATT facility is an underground complex originally built in 1966. It was an underground terminal and repeater station for the hardened analog L4 carrier cable (coax) that went from Miami to New England carrying general toll circuits and critical military communication circuits Critical military communication circuits implies it was meant to survive a nuclear attack. reply HFguy 4 hours agoprevLooks like a Fallout Vault These facilities were not cheap to design and build. Obsolete now. reply trhway 10 hours agoprevThe toilets are on springs to survive the shock wave. My acquaintance long time ago told me that in their deep (much deeper than in this article) underground USSR military communication center the whole floors were on some kind of springs and shock absorbers. reply bregma 8 hours agoparentThere's a bunker outside of Ottawa Canada, intended to house a select core of the federal government during and after a nuclear horrocaust, that is (at least) 10 storeys of underground on a sprung foundation. It's now a museum to the cold war open to the public (and worth a visit if you're in the area) and you can actually see the massive foundation springs. Also, they run escape rooms where you're caught in the bunker during a nuclear event, which would be kind of cool. reply fmajid 9 hours agoparentprevNORAD headquarters at Cheyenne Mountain: they hollowed out a mountain, and installed an entire complex mounted on springs. https://en.m.wikipedia.org/wiki/Cheyenne_Mountain_Complex reply Gud 1 hour agorootparentThis was not just done for fancy bunkers like NORAD headquarters but was common practice for telecommunication stations in many countries. reply msisk6 4 hours agoparentprevJust in case anyone is wondering what kind of shock waves a nearby nuclear blast would generate, watch this video of a 1-megaton test in central Nevada. You can drive right up to this point today: https://www.youtube.com/watch?v=6ETHnsKnKiA reply qingcharles 2 hours agorootparentThat music... o_O reply leoh 12 hours agoprevWhy was there a gamma ray detector? reply Lammy 12 hours agoparentThis other page goes into a little more detail on the detection system: https://coldwar-ct.com/Blast_Detectors.html “Most sites included Gamma detectors that were designed to detect the radiation wave as well. They were redundant systems, any detection, overpressure or Gamma would button-up the site at which point signals were sent to all Continental U.S. sites that a blast was detected, where it was, the size of the blast and wind speed and direction. Sites within 250 miles of any detection would go to Auto-Lock down.” reply jeffbee 4 hours agorootparentI wonder how sensitive they were/are. Can you goof on them with a portable medical gamma ray source? reply phone8675309 1 hour agorootparentThat sounds like a fantastic way to have a SWAT team kick down your door reply jeffbee 1 hour agorootparentI guess. I am just trying to think of the funniest thing a KGB operative could do in his free time. reply nrr 12 hours agoparentprevGamma rays are an early danger from the fallout from a nuclear blast. reply VoidWhisperer 12 hours agoparentprevLikely having something to do with this being a bunker meant to effectively endure a nuclear attack reply DonHopkins 9 hours agoprevI bet the late Robert “Ozzie” Osband (Richard Cheshire, The Cheshire Catalyst) would have loved to hack into there. https://infocondb.org/presenter/richard-cheshire-the-cheshir... >*The Cheshire Catalyst (@Cheshire2600)* (Richard Cheshire) was the last editor of the notorious TAP Newsletter of the 1970s and 1980s. (TAP was a predecessor of 2600 Magazine.) In his \"share the knowledge\" spirit, he has volunteered at every HOPE conference since the first one in 1994. His PHonePHriendly.Com sets up web pages meant to be read on mobile phone web browsers, and allows him to delude himself that he's still into phones as a phreak. reply rasz 12 hours agoprev [2 more] [flagged] p_l 11 hours agoparent [–] They used to be (valve systems designed to protect from shockwave were installed) but are no longer ;) reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Cheshire ATT facility, built in 1966, is an underground complex designed for critical military communications, featuring a hardened analog L4 carrier cable and an AUTOVON 4-wire switch.",
      "The facility includes extensive infrastructure for air filtration, power generation, and blast protection, ensuring operational continuity during nuclear events.",
      "The site also served as a metropolitan junction for Hartford and New Haven, connecting to various other critical communication paths and facilities."
    ],
    "commentSummary": [
      "The AT&T Long Lines \"Cheshire\" underground site was an AUTOVON switching center, built to endure a nuclear war using Western Electric's 1ESS technology.",
      "These centers were strategically located away from major cities and military targets, featuring redundant links, hardened structures, and cooling and contamination protection for workers.",
      "The infrastructure, developed during the Cold War, included extensive microwave point-to-point links and used both 1ESS and Number 5 Crossbar switches, highlighting its resilience and complexity."
    ],
    "points": 124,
    "commentCount": 61,
    "retryCount": 0,
    "time": 1722397662
  },
  {
    "id": 41119080,
    "title": "How great was the Great Oxidation Event?",
    "originLink": "https://eos.org/science-updates/how-great-was-the-great-oxidation-event",
    "originBody": "If water is the key to life, then oxygen is the key to animal life. All animals breathe oxygen. Despite decades of research, however, scientists still don’t know when Earth’s atmosphere held enough free oxygen to support the planet’s early animals. Most geologists agree that oxygen first accumulated in the atmosphere around 2.4 billion years ago. But they don’t agree on how much there was at that time or if it was enough for animals to thrive. My colleagues and I recently found new clues to help answer these questions from an unlikely source: the acidic, metal-rich waters of Rio Tinto in southern Spain. The composition of these waters is considered extreme today, yet the sort of acid rock drainage that causes these conditions was widespread long ago, when newly available atmospheric oxygen first began interacting with sulfur minerals on land. In our work, we showed that the chemistry occurring in these acidic waters can reconcile seemingly contradictory estimates of past levels of breathable oxygen determined from ancient sediments. Our data support growing evidence that enough oxygen was present for animals to have evolved nearly 2 billion years before they burst onto the scene. Earth’s First “Great Oxidation” When the single-celled ancestors of plants learned to combine carbon dioxide and water, these early innovators spat out a waste product formerly absent from their environment: free molecular oxygen. A critical transition in our planet’s history occurred when the single-celled ancestors of plants learned to combine carbon dioxide and water—two chemicals found everywhere on Earth—to make their cells and produce energy. These early innovators spat out a waste product formerly absent from their environment: free molecular oxygen (O2). This highly reactive gas began to run rampant on Earth’s surface, leaving telltale signs of its activity in minerals and sediments. It’s been more than 5 decades since scientists began deciphering these signs from the geologic record. Over that time, most scientists have come to agree that O2 first reached appreciable concentrations in Earth’s atmosphere roughly 2.4 billion years ago, during the Great Oxidation Event (GOE) [Farquhar et al., 2014]. Geologists who first described the GOE estimated that oxygen levels rose from near zero to about 10%–40% of what they are today (oxygen currently makes up 21% of the air we breathe). They also proposed that atmospheric O2 remained at these levels until it reached modern levels more than 1.5 billion years later. This extended interval roughly coincided with the third and longest of the four geologic eons of Earth’s history, the Proterozoic. Other researchers have since challenged those original estimates of Proterozoic O2. They suggest that oxygen concentrations rose to less than 0.1% of today’s level during the GOE and remained there, with only occasional short-term increases, through the ensuing eon. This substantial distinction—10% or more versus less than 0.1%—bears critically on the role of oxygen in animal evolution. Various forms of animal life require different minimum oxygen levels for survival, but even primitive animals like sponges require at least 0.25% of today’s atmospheric oxygen levels to metabolize [Cole et al., 2020]. This newsletter rocks. Get the most fascinating science news stories of the week in your inbox every Friday. SIGN UP NOW In the fossil record, paleontologists have found the oldest undisputed fossil eukaryotes, the single-celled precursors to animals, in marine sediments that accumulated about 1.7 billion years ago [Knoll and Nowak, 2017]. Despite the undisputed antiquity of eukaryotes, fossils of large multicellular life-forms representing putative animals don’t appear until more than a billion years later in the 0.57-billion-year-old Ediacaran biota, and undisputed animals don’t appear until the Cambrian period about 0.54 billion years ago. Some of the earliest putative animals found in the fossil record are represented in this reproduction of life from the Ediacaran period (635–541 million years ago) at the Smithsonian National Museum of Natural History in Washington, D.C. Credit: Ryan Schwark/Wikimedia Commons, CC0 1.0 Universal Paleontologists have also described a pronounced expansion of fossil eukaryotes around 0.8 billion years ago, coinciding with when atmospheric O2 reached near modern levels. Some researchers hypothesize that this rise in O2 allowed these early eukaryotes to diversify and eventually evolve into multicellular animals. But this simple cause-effect scenario relies heavily on debated claims that oxygen remained too low to sustain animal life for roughly 1.6 billion years prior. Controversial Clues from Chromium One problem with attempts to resolve the history of Earth’s breathable oxygen is that the data researchers use to estimate past levels have provided conflicting results. One problem with attempts to resolve the history of Earth’s breathable oxygen is that the data researchers use to estimate past levels have provided conflicting results. The atmosphere doesn’t directly fossilize, so geochemists rely on indirect traces, or proxies, to tease out the gases it contained at different times. One proxy that researchers have widely employed to estimate atmospheric O2 levels in the Proterozoic involves the heavy metal chromium [Wei et al., 2020]. Like many elements, not all chromium atoms are created equal. Although all have 24 protons in their nuclei, they can have different numbers of neutrons; in other words, different isotopes of chromium exist. These different chromium isotopes react at different rates, leading to fractionation, or a change in their ratios, when they undergo chemical reactions in the environment. For example, chromium isotopes are fractionated when they react with manganese oxide minerals. This reaction preferentially releases heavier isotopes of chromium into natural waters that become more concentrated in sediments as a result. Scientists want to resolve these disparate scenarios to understand oxygen’s role in animal evolution on Earth and potentially on other planets too. Manganese oxide minerals such as birnessite and todorokite are very common in modern environments, for example, in soils and fluvial settings and on the seafloor. Researchers have estimated that reactions with these minerals fractionate chromium isotopes when free O2 is present at concentrations above 0.1% of modern atmospheric levels [Planavsky et al., 2014]. So some scientists have argued that chromium isotope fractionation in ancient rocks provides an “oxygen signal,” indicating when O2 exceeded 0.1% of current levels. They have also claimed the corollary, that a lack of chromium isotope fractionation in rocks indicates that oxygen levels at the time the rocks formed were below that threshold. Geochemists who first measured chromium isotopes in Proterozoic rocks found that large chromium isotope fractionations didn’t appear until 0.8 billion years ago, suggesting O2 levels were too low to support animals until late in the Proterozoic [Planavsky et al., 2014]. However, researchers recently found large fractionations in chromium isotopes preserved in ancient soils and marine rocks as far back as 1.9 billion years ago. These researchers contended that Proterozoic O2 levels were at least intermittently high enough for animals to evolve well before their first occurrence in the fossil record [Canfield et al., 2018]. Scientists want to resolve these disparate scenarios to understand oxygen’s role in animal evolution on Earth and potentially on other planets too. Going to the Extreme Spain’s Rio Tinto flows roughly 100 kilometers through the southwest of the country, stained blood red from its headwaters north of the town of Nerva in the Sierra Moreno to its mouth at the Ria of Huelva estuary, where it spills into the Atlantic Ocean. Mining activities over millennia in the Iberian Pyrite Belt, one of the largest hydrothermal ore deposits in the world, have exposed large piles of the iron sulfide mineral pyrite in the headwaters of the river to attack by atmospheric O2 at Earth’s surface. When pyrite reacts with O2, it produces sulfuric acid, which is responsible for the river’s very low pH of 2 (similar to the pH of lemon juice or stomach acid). The reaction and resulting acidity also release iron, which gives rise to the river’s characteristic red tint, and other heavy metals—including chromium—from surrounding rocks. Today, Rio Tinto’s waters are an extreme environment. But such conditions were once far more common. Scientists have proposed that as a result of the GOE, newly liberated O2 in the atmosphere attacked extensive pyrite deposits on the land surface. Like today’s rock weathering in southern Spain, this chemical attack released heavy metals and sulfuric acid, producing widespread acid rock drainage [Konhauser et al., 2011]. In the aftermath of the GOE, it’s likely that rivers like Rio Tinto were the norm rather than the exception. Are scientists today similarly misinterpreting the lack of chromium isotope fractionation in rocks older than 0.8 billion years? Despite the preponderance of acid rock drainage after the GOE, geochemists had not looked into how chromium isotopes fractionate in acidic natural waters. After nearly a decade of teaching geochemistry at Rio Tinto, I knew manganese oxides rarely form in similarly acidic waters. And I figured if manganese oxides are necessary for imparting the chromium isotopic oxygen signal into rocks, then a lack of these minerals might prevent the formation of the signal, even in today’s high-O2 atmosphere. To investigate this hypothesis, I teamed up with my longtime friend and colleague Kate Scheiderich, who was then at the U.S. Geological Survey and had set up a lab to measure chromium isotopes. Returning to Rio Tinto, I collected samples of river water, rocks, and sediment from different locations along the bank of the river. Then I shipped them to Kate’s lab for her and another colleague to analyze. We found that the acidic headwaters of the Rio Tinto were, indeed, leaching chromium from the surrounding rocks, then carrying it downstream to the Atlantic, where it accumulated in sediments around the estuary. However, the river was simply too acidic for manganese oxide minerals to form, despite flowing in an atmosphere with 21% oxygen. The analytical results in our study confirmed that without any manganese oxides to react with, chromium isotopes in the estuary sediments remained unfractionated and the chromium isotope values were identical to those in the source rocks they came from upstream (Figure 1). Fig. 1. Most sediments and waters today show a wide spread in chromium isotope ratios because the chromium they contain has been fractionated through reactions with manganese oxides. In contrast, because manganese oxides do not form in acidic waters, sediments from the Rio Tinto estuary show a very small spread in chromium isotope ratios that centers around a δ53Cr of 0‰, similar to the range measured in rocks supplying chromium to the river. The range of chromium isotope ratios measured in rocks older than 0.8 billion years is also relatively narrow and centers around a δ53Cr of 0‰, indicating that little chromium isotope fractionation is evident in these rocks. δ53Cr (in parts per thousand, ‰) represents depletion (negative values) or enrichment (positive values) of chromium-53 relative to chromium-52 in a sample compared to a standard reference material; δ53Cr = 1,000 × {[(53Cr/52Crsample)/(53Cr/52Crstandard)] − 1}. Millions of years from now, after these estuarine sediments have lithified into marine rocks, future geochemists—analyzing the rocks with the same techniques and understanding of the chromium isotope oxygen signal scientists have employed until now—might thus mistakenly infer that our current air was unbreathable. Are scientists today similarly misinterpreting the lack of chromium isotope fractionation in rocks older than 0.8 billion years? We proposed that the prevalence of acid rock drainage on Proterozoic continents could have hindered development of the chromium isotope oxygen signal until 0.8 billion years ago (when, perhaps, most acid rock drainage had been consumed). This idea reconciles seemingly contradictory chromium isotope data and suggests O2 in the atmosphere could have been elevated above 0.1% of modern levels far earlier in the Proterozoic [Scheiderich et al., 2023]. Why Did Animals Wait? As scientists increasingly focus on oxygen in the Proterozoic, more geochemical estimates [e.g., Mänd et al., 2020] and atmospheric models [e.g., Gregory et al., 2021] are suggesting that atmospheric O2 concentrations were high enough for animals to have thrived more than 2 billion years before the early Cambrian. So why did it take so long for them to appear? One possible explanation is that oxygen concentrations in the Proterozoic ocean fluctuated too much. Most scientists agree that shallow marine habitats, likely hotbeds for evolution, had oxygen levels high enough to support eukaryotes throughout the Proterozoic. But oxygen-free waters from the deep ocean routinely circulated upward, possibly diluting the oxygen oases at the surface. The instability of back-and-forth swings in oxygen in the surface ocean could have posed a big challenge to the evolution of early animals. Some scientists suggest famine could also have held early animals back. The same protoplants that produced oxygen in the Proterozoic also formed the base of the food chain, so researchers have inferred that low oxygen and a low food supply went hand in hand. Animals could also have been starved for nutrients essential to life, such as nitrogen, which is found in nearly all biomolecules, including DNA, RNA, and proteins. Many geochemists have suggested nitrogen was scarce in the Proterozoic, when denitrifying microbes first started converting oxidized nitrogen (e.g., nitrate) into forms that animals can’t use (e.g., nitrogen gas). Other researchers have proposed developmental hypotheses for the lag in animal evolution. They point out that it could have taken billions of years for the core set of genes found in all multicellular life to evolve in eukaryotes and that only after those genes emerged could animal life diversify greatly. Or perhaps, environmental and biological hurdles together slowed animal evolution. For now, more answers to why animals only debuted at the end of the Proterozoic will have to wait. Whatever the explanations, recent research is seemingly making clear that it wasn’t for want of oxygen. References Canfield, D. E., et al. (2018), Highly fractionated chromium isotopes in Mesoproterozoic-aged shales and atmospheric oxygen, Nat. Commun., 9(1), 2871, https://doi.org/10.1038/s41467-018-05263-9. Cole, D. B., et al. (2020), On the co‐evolution of surface oxygen levels and animals, Geobiology, 18(3), 260–281, https://doi.org/10.1111/gbi.12382. Farquhar, J., A. L. Zerkle, and A. Bekker (2014), Geologic and geochemical constraints on Earth’s early atmosphere, in Treatise on Geochemistry, 2nd ed., pp. 91–138, Elsevier, Amsterdam, https://doi.org/10.1016/B978-0-08-095975-7.01304-8. Gregory, B. S., M. W. Claire, and S. Rugheimer (2021), Photochemical modelling of atmospheric oxygen levels confirms two stable states, Earth Planet. Sci. Lett., 561, 116818, https://doi.org/10.1016/j.epsl.2021.116818. Knoll, A. H., and M. A. Nowak (2017), The timetable of evolution, Sci. Adv., 3, e1603076, https://doi.org/10.1126/sciadv.1603076. Konhauser, K. O., et al. (2011), Aerobic bacterial pyrite oxidation and acid rock drainage during the Great Oxidation Event, Nature, 478(7369), 369–373, https://doi.org/10.1038/nature10511. Mänd, K., et al. (2020), Palaeoproterozoic oxygenated oceans following the Lomagundi–Jatuli event, Nat. Geosci., 13(4), 302–306, https://doi.org/10.1038/s41561-020-0558-5. Planavsky, N. J., et al. (2014), Low mid-Proterozoic atmospheric oxygen levels and the delayed rise of animals, Science, 346(6209), 635–638, https://doi.org/10.1126/science.1258410. Scheiderich, K., A. L. Zerkle, and D. Damby (2023), Chromium isotopes in an acidic fluvial system: Implications for modern and ancient Cr isotope records, Geochim. Cosmochim. Acta, 354, 123–145, https://doi.org/10.1016/j.gca.2023.05.024. Wei, W., et al. (2020), Biogeochemical cycle of chromium isotopes at the modern Earth’s surface and its applications as a paleo-environment proxy, Chem. Geol., 541, 119570, https://doi.org/10.1016/j.chemgeo.2020.119570. Author Information Aubrey Zerkle (aubrey.zerkle@bmsis.org), Blue Marble Space Institute of Science, Seattle, Wash. Citation: Zerkle, A. (2024), How great was the “Great Oxidation Event”?, Eos, 105, https://doi.org/10.1029/2024EO240313. Published on 30 July 2024. Text © 2024. The authors. CC BY-NC-ND 3.0 Except where otherwise noted, images are subject to copyright. Any reuse without express permission from the copyright owner is prohibited. Related Tagged: animals, climate, Earth science, everything atmospheric, evolution, fieldwork, isotopes, oxygen, paleoclimatology & paleoceanography, Proterozoic, Spain",
    "commentLink": "https://news.ycombinator.com/item?id=41119080",
    "commentBody": "How great was the Great Oxidation Event? (eos.org)121 points by Brajeshwar 5 hours agohidepastfavorite50 comments andrewla 3 hours agoIt's a remarkable thing to step back for a second and realize that while we try to figure out the exact impact of a parts-per-million change in CO2 concentration, that it's astonishing that CO2 is not 20% of the atmosphere, that the only thing keeping O2 in the atmosphere at all is the large-scale actions of living things. [1] The fact that living organisms are responsible for something so large seems almost dumbfounding -- planets are big, atmospheres are big, and life is small; what is a pool of algae compared to a mountain, etc. But even such a basic thing as \"the only reason we can have something as fundamental as FIRE is because of living things\" is a bit of a mindblowing realization. [1] probably not literally true; if you eliminated all life on earth then most of the O2 would probably be sequestered in oxides rather than remaining resident as CO2, but still. Although I guess a lot of non-living organic matter would eventually burn away as long as there is oxygen to support combustion. reply jmcqk6 3 hours agoparentI'm pretty sure it is literally true that the oxygen in the atmosphere is there only because living things keep putting it there. You're right that without life, it would be sequestered in oxides pretty quickly. That's the local minima for energy dissipation. Life is good at breaking those minimas for cyclic matter dissipation. If there was a natural source for oxygen, it would have to come from some sort of cycle in order to be maintained, and there's not a energetically favorable cycle for that. It's why it makes a good biomarker when looking at exoplanets. If we find an exoplanet with high amounts of oxygen in the atmosphere, we can be fairly confident reply singpolyma3 1 minute agorootparentI've never understood applying this idea to exoplanets. What if the life there puts sulfur into the atmosphere instead of oxygen? Why would the life elsewhere look anything like the life here in terms of gas use, etc reply robwwilliams 42 minutes agorootparentprevI’m surprised by this statement. Here is a quote from Nick Lane’s great text: Power, Sex, Suicide (p 153): > The early Earth, as envisaged by [Michael J] Russell, is a giant electrochemical cell, which depends in the power of the sun to oxidize the oceans. UV rays split water and oxidize iron. Hydrogen, released from the water, is so light that it is not retained by gravity, and evaporates into space. The oceans become gradually oxidized relative to the more reduced conditions of the mantle.” Lanes cites this paper “On the origins of cells: A hypothesis for the evolutionary transition from abiotic to nucleated cells”, 2003, by Martin and Russell https://pubmed.ncbi.nlm.nih.gov/12594918/ Am I missing something? This text forces me to assume that solar UV splitting water is the cause of the O2 atmospheric flooding. reply philipkglass 4 minutes agorootparentHere's the full text of the \"On the origins of cells...\" paper via sci-hub: https://sci-hub.se/10.1098/rstb.2002.1183 There's nothing in it about ultraviolet splitting of water or oceanic oxidation. If Nick Lane meant to paraphrase the paper in that cited passage, he did a poor job. Direct UV homolysis of water to release hydrogen requires a photon with more than 6.5 electron volts of energy [1], corresponding to a wavelength of 190 nm or shorter. As you can see here, solar irradiance is extremely low at wavelengths shorter than 240 nm: https://en.wikipedia.org/wiki/Solar_irradiance#/media/File:S... There just isn't enough energetic UV radiation emitted from the sun to directly oxygenate the Earth via water homolysis. It might be possible for an exoplanet in orbit around a hotter star that emits more energetic UV. [1] https://en.wikipedia.org/wiki/Photocatalytic_water_splitting... reply jmcqk6 8 minutes agorootparentprevI'm a huge fan of Nick Lane, and I'm not an expert, so I may have misunderstood. I have not read \"Power, Sex, Suicide\" but have read \"The vital question\", \"transformer,\" and most importantly in this context, \"Oxygen.\" My understanding, which could absolutely be wrong, is that there are pathways to where Oxygen can be generated without life, but for it to be maintained at high levels of concentration over time, that takes life. I would definitely defer to whatever Nick Lane has to say about it. reply lordgrenville 22 minutes agorootparentprevI'm currently reading another of his books, Oxygen: The Molecule that made the World, which unsurprisingly has lots more about this topic. reply robwwilliams 37 minutes agorootparentprevAnd not true at all that all organisms need O2 to pump protons. Microbes have quite a few alternative ways. Even we do when we run the Krebs cycle backwards. reply patcon 2 hours agorootparentprevWas much more likely true until a week ago, but now there’s a legit competing hypothesis :) https://www.nature.com/articles/s41561-024-01480-8 reply robwwilliams 40 minutes agorootparentYep, exactly what I thought when reading Lane! But what would be the quantitative contribution of benthic O2? reply jmcqk6 2 hours agorootparentprevYeah, that's an exciting discovery. I was excited by this, because I believe it demonstrates a dissipative pathway that could have contributed to abiogenesis. Energy gradients are a driver of emergent complexity. reply tambourine_man 2 hours agoparentprevThat was pretty interesting to me and perhaps changes our idea of how the great oxidation went a bit: (Evidence of dark oxygen production at the abyssal seafloor) https://www.nature.com/articles/s41561-024-01480-8 reply BurningFrog 37 minutes agoparentprevIf you kill all life on earth, I assume all dead biomass would oxidize into CO2. Though I'm not sure what processes would do that. Without microorganisms, nothing rots. Lightning would eventually burn down most forests, but maybe everything else would just lie where it fell for ever. reply BestHackerOnHN 2 hours agoparentprev> \"the only reason we can have something as fundamental as FIRE is because of living things\" is a bit of a mindblowing realization. I am fairly confident living things did not create FIRE. reply andrewla 2 hours agorootparentWell, we (broadly speaking) did not create the concept of a plasma phase of matter, but fire as we know it is only possible because of free oxygen. Fire, for the most part, is just another name for rapid oxidation. Even some things that can burn without air (e.g. magnesium) typically only burn because they are so hot that they cause H2O to separate. Obviously stars exist, so there are other ways of getting to plasma, but oxygen is what makes terrestrial fires possible. So yes -- living things created fire! reply bregma 2 hours agorootparentprevWell, we didn't start the FIRE. It was always burning since the world's been turning. reply solardev 1 hour agorootparentprevWithout living things, who would retire early? The markets aren't going to trade themselves. reply wrycoder 2 hours agorootparentprevBare rocks and water don’t burn, they are already oxidized. Life chemically reduces CO2, providing material than can support combustion. reply SideburnsOfDoom 3 hours agoparentprev> planets are big, atmospheres are big, and life is small; And time is long. The consensus is still that the oxygenation of Earth's atmosphere took \"at least 400 million years\". A lot of that is due to the \"great rust\", i.e. minerals that would take oxygen out of the air had to first exhaust their capacity to oxidise. This took \"nearly a billion years\". Iron ore deposits are from the seabed of this period. See: https://en.wikipedia.org/wiki/Great_Oxidation_Event https://en.wikipedia.org/wiki/Banded_iron_formation reply pfdietz 1 hour agorootparent> Iron ore deposits are from the seabed of this period. Many are, but some are more recent. https://en.wikipedia.org/wiki/Chilean_Iron_Belt https://www.nature.com/articles/s41467-023-43655-8 reply Teever 1 hour agoparentprevLet me share a twist on this train if thought that I've had recently. The nature of the Earth's atmosphere, surface, oceans, and much of the subsurface is entirely the product of a single cell. A single cell lead to more cells which eventually evolved into different forms and became multicellular and so on and so forth until the earth was covered in all kinds of shapes and sizes of life and the landscape was permanently changed. All that from one cell. You and I are composed of trillions of these things and we're able to do incredible things with them, but at the same time our power is much more limited than that of the single cell that created all of life. We can do incredible things with our bodies but we lack the ability to completely control even a single cell in our body. As such a single cell can go rogue and kill you with cancer, or despite your best efforts to nourish, heal and exercise your cells you will eventually die. Imagine if it wasn't so. Imagine if you could control but a single long lived cell in your body. What could you do with that? Anything. Nothing could stop you. You could travel to the deepest depths as a whale or soar to the highest heights as an eagle. You could spawn a mass organism larger than Pando, or evolve something novel that would go to space. So imagine if someone locked you deep in a dark prison in solitary confinement and you could through something akin to meditation come to control a single cell in your body. No prison could hold you. What happens when we achieve mastery over ourselves in such a way through technology? Will we allow individuals this level of control over their own cells? Can we stop them? reply throwaway290 3 hours agoparentprev> The fact that living organisms are responsible for something so large how do you separate living and non living things? (https://en.wikipedia.org/wiki/Life#Challenge) everything is responsible for something. reply exe34 1 hour agorootparentThey meant puny gooey things. reply throwaway290 1 hour agorootparentYes, I figured that's about the level of sophistication:) reply exe34 20 minutes agorootparentIt was a poetic reflection. Don't worry, I didn't always get this sort of thing either. Maybe one day you too will learn to enjoy it :-) reply mannykannot 12 minutes agoprevOne of the problems for the paleontology of this period is that almost all the rocks from it have been eroded away - the great unconformity. It has been speculatively attributed to erosion during Snowball Earth, which preceded the Cambrian explosion, though it seems the story is becoming more complicated. https://www.atlasobscura.com/articles/great-unconformity-geo... reply mannykannot 34 minutes agoprevLooking at chart 1, it seems to me that the distribution of the chromium-53 ratio in today's seawater is a reasonable match to the ratios seen in today's sediments, and not to that seen in ancient rocks, while the distribution for today's rivers and estuaries is not a good match for today's sediments, and, if anything, is a better match to the ancient rocks. Absent any other evidence, this seems to suggest that the fractionation seen in today's sediments may be the result of processes occurring in seawater rather than in rivers, and if so, that would in turn suggest that what happens in rivers and estuaries is not a good guide to the fractionation we should see in ancient rocks, even if we assume ancient rivers were mostly like the Rio Tinto - unless the ancient seawaters were acidic enough to prevent fractionation occurring there. reply duxup 4 hours agoprevPBS had a wonderful series Ancient Earth that covered the geological history of the earth. https://www.pbs.org/wgbh/nova/series/ancient-earth/ My naive understanding was always that the earth or planets just sort of found a natural state of being after a while and were / are just that way now. It's very interesting to see the sea saw type scale of changes that occurred over time. reply s_dev 2 hours agoprevI definitely recommend \"Life on Our Planet\" produced by Spielberg and narrated by Morgan Freeman. Covers all the extinction events in Earths history in a way that would enthuse and educate laymen on this issue. reply glitchc 1 hour agoprevIt's worth noting that the Great Oxidation event was also a mass extinction event, yet we are happy that it occurred. reply s1artibartfast 1 hour agoparentI think that's true for every mass extinction event except the current one reply lazide 1 hour agorootparentPretty sure all those people bouncing around are much happier alive than dead. reply ianbooker 4 hours agoprevThis is a expertly crafted narrative of presumably complicated research. reply tectonic 3 hours agoprevIt’s why we have many tiger’s eyes gemstones and banded iron deposits. reply DrBazza 4 hours agoprevAlso EOS: https://eos.org/articles/metallic-nodules-create-oxygen-in-t.... I can wait for the next Great De-Oxidation Event, when mining companies are allowed to scoop up all these metals without any research. reply dang 1 hour agoprevnext [14 more] [stub for offtopicness] reply adgjlsfhk1 5 hours agoparentI thought this was going to be about Intel... reply db48x 5 hours agorootparentMy first guess was Rust. My third was geology. reply Pet_Ant 4 hours agorootparentWell then you may want to make more time to watch PBS Eons on YouTube: https://youtu.be/qERdL8uHSgI?si=u58MApIHgGp9G60o https://youtu.be/mAkjETPM1s4?si=emy483-M4LYK0Jh5 It's more accessible than PBS SpaceTime, but the rotating hosts I do find makes it harder to binge. reply anticristi 4 hours agorootparentprevWhy? reply Pet_Ant 4 hours agorootparent\"Intel confirms oxidation and excessive voltage in 13th and 14th Gen CPUs\" https://news.ycombinator.com/item?id=41058791 reply hinkley 3 hours agorootparentRust buckets, eh? reply spdegabrielle 4 hours agoparentprevYMMV, but I'm happy it happened. reply short_sells_poo 2 hours agorootparentA great man once wrote: In the beginning the Universe was created. This has made a lot of people very angry and been widely regarded as a bad move. reply olalonde 4 hours agoparentprevI thought this was going to be about Rust taking over the world. reply marcosdumay 4 hours agorootparentIt is! reply ecjhdnc2025 4 hours ago [flagged]parentprevnext [2 more] So great. More people remember being there than could ever have fit in at once. reply exe34 1 hour agorootparentMake Oxidation Great Again! reply danglingptr 3 hours ago [flagged]parentprevthought this is about rust reply csours 4 hours agoprev [–] You ever think about a plate of shrimp and then someone says \"plate of shrimp\" randomly? - Repo Man (1984) > \"I'm reminded of the Oxygen Catastrophe - https://en.wikipedia.org/wiki/Great_Oxidation_Event - we need oxygen to live, but it also kills.\" https://news.ycombinator.com/item?id=41080195 reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Scientists are uncertain when Earth's atmosphere had enough oxygen to support early animal life, despite extensive research.",
      "New findings from Rio Tinto, Spain, suggest that sufficient oxygen for animal evolution might have been present nearly 2 billion years before animals appeared.",
      "Recent research indicates that fluctuating ocean oxygen levels, food scarcity, or genetic development time, rather than oxygen levels, might have delayed animal evolution."
    ],
    "commentSummary": [
      "The Great Oxidation Event (GOE) marked a significant rise in Earth's atmospheric oxygen due to photosynthetic microbes over at least 400 million years.",
      "This increase in oxygen enabled the development of complex life forms and the possibility of fire but caused a mass extinction of anaerobic organisms.",
      "The GOE is crucial for astrobiology, as high oxygen levels on exoplanets can indicate potential biological activity, with ongoing research continually refining our understanding."
    ],
    "points": 119,
    "commentCount": 48,
    "retryCount": 0,
    "time": 1722433249
  },
  {
    "id": 41116414,
    "title": "FakeTraveler: Fake where your phone is located (Mock location for Android)",
    "originLink": "https://github.com/mcastillof/FakeTraveler",
    "originBody": "FakeTraveler Fake where your phone is located (Mock location for Android). Sometimes you need to fake the location of your device (for privacy or to test an app). Fake Traveler provides you a map to select the location where you want your phone to be. How does it work? Long press in the map where you want to be located or type the latitude and longitude, and tap the Apply button. Tapping the \"...\" button you will be shown two settings to mock the location over a period of time. Requirements? In order to work, you need to allow Fake Traveler to mock locations. You have to enable Developer options and select this app in \"Settings/System/Developer options/Select mock location app\" option. Changelogs See fastlane/metadata/android/en-US/changelogs/ License Copyright © 2018 Matías Castillo Felmer This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version. This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details. You should have received a copy of the GNU General Public License along with this program. If not, see https://www.gnu.org/licenses/. The icon launcher is derivative of \"Location, map, navigation, pointer icon\" by First Styles, used under CC 3.0 BY. The icon Launcher was created using Android Asset Studio, and is licensed under CC 3.0 BY, by Matías Castillo Felmer.",
    "commentLink": "https://news.ycombinator.com/item?id=41116414",
    "commentBody": "FakeTraveler: Fake where your phone is located (Mock location for Android) (github.com/mcastillof)109 points by thunderbong 14 hours agohidepastfavorite66 comments tauntz 9 hours agoThere are tens, if not hundreds of mock location provider apps available on Google Play and that feature has been supported on Android since Android 1.5 from 16 years ago. Just curious, why is this app, specifically, any different? reply SushiHippie 7 hours agoparentIt's open source and on F-Droid https://f-droid.org/packages/cl.coders.faketraveler/ reply ctxc 40 minutes agoparentprevI know right? Doesn't feel HN worthy. I used to use these apps back when I played Pokémon Go and it would behave differently based on my location. reply rminla 15 minutes agoparentprev100%. i thought i was missing something reply ramonverse 9 hours agoprevAfaik nearby wifi networks are also used to determine location. As long as you have wifi activated Google can use this to determine where you are. I don't know if they use this as a hard check. The only way I can think of to prevent this is to build a faraday cage with a wired vpn router and your phone inside. reply kop316 6 hours agoparentThis looks to use the dev options to fake it, which I believe bypasses the geolocation apps (as I assume the mock location is used for testing apps if they are in certain locations). That being said, I have tried this for banking apps, and they aren't fooled by it, so I am guessing Android passes on that this is a \"mock\" location, not a real one. Like you said, if you really want to fake it, probably a faraday cage/fake GPS would be necessary. reply amonon 5 hours agorootparentYes, this is the case. I cannot remember the details, but the OS makes applications aware that location mocking is turned on. reply Ambroos 4 hours agorootparentYou can just call .isMock() on the location object you receive: https://developer.android.com/reference/android/location/Loc... - without root that can't be bypassed. reply Teever 1 hour agorootparentprevThat's a pretty anti-user feature if you ask me. Especially for a device so personal as a smartphone. There needs to be legislation that prevents manufactures from overridinf the will of the user at the behest of app makers for devices like this. reply newaccount74 1 hour agorootparentHaving a smartphone provide a hard to fake location is a pretty valuable feature. A lot of businesses depend on the fact that location data is hard to fake. Consider caller ID - legislators around the world are working on making it harder to spoof your identity, because there's so much fraud going on with fake caller IDs. It's the same with location. Being able to easily fake location would open the door to so many frauds... reply singleshot_ 39 minutes agorootparentQuick question: how come every scumbag who calls my phone with a scam has a fake caller ID, but I shouldn’t? Again, this seems pretty user-hostile. reply dmichulke 1 hour agorootparentprevSo how do you stop Google or Samsung from using your location data without your consent? - Not using GPS? Not an option because you need it - Disabling permissions? Not possible for \"system apps\" - Having the 10% privacy aware people block location somehow (via rooted phone or different distribution)? That doesn't help the other 90%. IMO the only solution is to poison the data with fake locations. Are there other options I missed? reply Teever 1 hour agorootparentprev> A lot of businesses depend... Do I care? Like not to be glib but as an end user buying a phone for my personal uses, I dont care about their businesses and I loathe the idea that their business model requires such an anti feature to be widely deployed in personal devices such as smart phones. Tell you what. I have a business model that requires your personal location data. Be a dear and send it to me. And again, why do I care about caller ID. It's been trash for years. I just never answer calls and use diffetent platforms such as Signal to communicate with my friends. It may open the door to so many frauds, but it opens the door to so many more abuses. People will talk about these 'features' differently the first time a large genocidal action takes place that makes use of this data. reply mindslight 50 minutes agorootparentI fully agree with where you're coming from, but you kind of veered off with that last sentence. In general I think the threats from fine-grained surveillance databases are a lot more nuanced and pernicious than genocide. reply bongodongobob 1 hour agorootparentprevI think it might be a legal requirement for emergency services. I used to work a lot with VoIP and each line was required to have an address associated with it. reply Teever 49 minutes agorootparentI'm fine with that, provided that there's sufficient oversight to prevent abuse. What I'm not fine with is one large corporation who makes phones baking this feature in so that other companies that make apps can profit off it. That's two parties conspiring to fuck over their customers. That needs to be regulated. reply autoexec 8 hours agoparentprevnearby wifi networks, nearby cell phones, and also bluetooth devices. Even in airplane mode your phone is looking for beacons and keeping track of your location. Even when you turn your phone off entirely it doesn't give up (https://www.androidpolice.com/android-15-powered-off-finding...) reply sadboi31 7 hours agorootparentThey want accelerometer, temperature and other sensor data too where possible. Not just information on the strength of the wifi/cellular signal (and your estimated location). SIM cards can do the most on qualcomm devices. Poking into both of these systems outside of a lab is definitely a violation of the law ordinarily and it's pretty hard to test this in a lab. reply ape4 4 hours agoparentprevThis app registers a location provider. Probably the phone wouldn't resort to using wi-fi networks if there is a location provider present. Probably, maybe. reply fsflover 8 hours agoparentprevThis is why I use a smartphone with hardware kill switches for WiFi and modem. reply pogue 1 hour agorootparentI just saw this yesterday about losing Authy for 2FA on non-official Android devices w/o play services. I'm curious how phones like this are handling that. https://arstechnica.com/gadgets/2024/07/loss-of-popular-2fa-... reply fsflover 1 hour agorootparentYou can run Android apps with Waydroid, but you can't overcome the DRM. You have to complain that you run an alternative OS, which has a right to exist. reply pogue 1 hour agorootparentSo you can still access 2FA through non-official Android builds.... or no? reply ksp-atlas 8 hours agorootparentprevLibrem 5? reply fsflover 6 hours agorootparentYes. reply reginald78 4 hours agorootparentprevDon't forget bluetooth. reply immibis 3 hours agorootparentUsually it's the same chip that does wifi. reply fsflover 1 hour agorootparentExactly. reply mindslight 5 hours agoparentprev> The only way I can think of to prevent this is to build a faraday cage with a wired vpn router and your phone inside. Another option is to not be running an operating system that betrays your interests. Google can only determine your location using nearby wifi networks if that list of nearby wifi networks has been given to Google through Android/Play backdoors. In fact most privacy issues with phones boil down to running a malevolent OS - protecting against malicious application code is still a difficult problem, but it is at least tractable if you can trust the system code. (Personally I think the functionality of the OP should be included by default as part of the OS permission system, and configurable on a per-application basis) reply gorbypark 1 hour agorootparentAt one point in time the Google street view vehicles were logging wifi position data as well. I don’t know if they still do it, though. reply mindslight 57 minutes agorootparentSure, that's a related but different problem - cataloging the location of wifi APs versus inferring your personal location based on what APs your phone can see. Running user-representing software on your phone doesn't fix all problems everywhere, it just gives you a platform with which you can address them to the fullest extent possible. reply giancarlostoro 4 hours agoprevReminds me of the old FakeOperator for iOS from back in the day, where instead of it saying Sprint or Verizon you could make it say \"CIA\", \"FBI\", or even \"Hacker\" the joys of smartphone hacking. reply neilv 4 hours agoparentSo this location-setting app could be called SmoothOperator. As in the Sade song, \"Coast to coast, LA to Chicago... across the north, and south to Key Largo...\" https://www.youtube.com/watch?v=4TYv2PhG89A&t=1m19s reply therein 22 minutes agorootparentThat's a good name and a backstory. reply qwertox 9 hours agoprev\"Lockito – GPS itinerary faker\" [0] is my go-to app when I need to test location features on Android. [0] https://play.google.com/store/apps/details?id=fr.dvilleneuve... reply stavros 8 hours agoparentThis looks great, thank you! reply acheong08 6 hours agoprevI’m working on something similar for IOS by running MITM & spoofing the response from wloc (API used to determine location based on Wii routers and cell towers). I was surprised that GPS is rarely ever used and almost always substituted by APIs that expose your location to Apple/Google even if VPN is on reply PmTKg5d3AoKVnj0 5 hours agoprevWhen I was a teenager and wanted to go do boyish teenager things, like hang out at $ABANDONED_BUILDING, I used such apps to mock my location to the library, as my parents were tracking it using Life360. reply wormlord 4 hours agoparentOh God I forgot people's parents used to do that. reply vlachen 3 hours agorootparentAccording to my over-50 year old boss in regard to their grown kids, they still do. But it is symmetric nowadays, and has something to do with their faith. reply latexr 3 hours agorootparent> But it is symmetric nowadays, and has something to do with their faith. That raises more questions than it answers. “Thou shall spy on thy family’s whereabouts no fewer than thrice hourly, and thou must use ReligionFamilyTracker™, at $19.99 per week, to do so.” reply vlachen 2 hours agorootparentI won't ever claim that I understand it. As my tiny human says: \"That's creeps.\" reply mrguyorama 52 minutes agorootparentprevIs your boss the current Speaker of the House of Representatives who uses such parent-ware on his children's phones and claims that his child does the same so they can monitor each others (avoidance of) porn habits? reply bdcravens 1 hour agoprevThere's a bunch of commercial apps to do the same for iPhone, but they all feel incredibly scammy (though I've tested a few, and they work fine). I'd love to find an open source option, or even a pointer to the requisite APIs. reply helsinki 1 hour agoparentWhat are they called, please? I need this for Monster Hunter Now. reply mrguyorama 56 minutes agorootparentGPS based games watch for this stuff as table stakes. They don't want you getting more \"free\" currency or items than you are normally expected to get because that screws with their profits reply captaincrunch 8 hours agoprevThis type of tool got me banned from Pokeman Go... gotta' collect them all!! reply MaXtreeM 5 hours agoparentAlways though that's the stupidest way to play the Pokemon Go. Maybe it made a little bit of sense in the beginning when small villages had almost no content but even than you just missing most aspects which make this game interesting. I guess that's the time we live in. reply BLKNSLVR 4 hours agorootparentIt's true that playing in-the-flesh with a crew was the best way to play, but spoofing enabled both levelling up faster (which in turn helps the \"with crew\" outings) and bypassing impossible restrictions like increasing number of geo-locked critters. It does say \"gotta collect 'em all\" pretty clearly... However, I still remember the wave of people coming towards me when a Gyarados spawned right near me. I had some family with me who weren't playing (and therefore didn't know what was going on) and were quite intimidated by the sight of the approaching, stampeding crowd. reply prophesi 4 hours agorootparentprevIt was a lot of fun to spoof my location to Central Park and actually be able to take on gyms while I lived in the sticks. Naturally I also turned off spoofing when I'd have the chance to visit a metro area. reply rootsudo 9 hours agoprevThis doesn’t work anymore because since android 9 or so, there is an api feature that allows any app to query if mock location is enabled. You need to be rooted to disable that “feature.” I use it to gamify (not games or such -) a lot of things, but it’s also used for “fraud” or such, one thing when I was researching was that Pokémon go users do this. I just do it for geoarbritage pricing - without a play account on google phones. IMO I don’t think google play follows geographic pricing like apple does with their store (address/credit card in other geographic region) Coincidentally it’s harder to do the above on an iPhone. reply BLKNSLVR 5 hours agoparentI've done it for Pokemon Go. There are (were, it's been a while) pretty specific setup steps required, and it changed over the course of a couple of years as Android changed things up. One of the older methods worked, but semi-required the back of the phone to have aluminium foil on it so that the real GPS signal wouldn't get through and \"rubberband\" you back to your actual location, earning a soft-ban. I had more than one phone with a couple of layers of alfoil between the phone and the case. There was another method that required a specific version of Google Play Services, so that root wasn't necessary. I think. Also had to rename the FakeGPS app, and use Magisk Hide Good times. I enjoyed \"seeing if I could\" more than the actual fruits of the labour. reply jacooper 48 minutes agoprevThis doesn't work, gmaps shows my actual location. reply SideburnsOfDoom 10 hours agoprev [–] Does this fool the android app store regarding current country, or is that based off who is currently providing Mobile phone signal? reply sofixa 10 hours agoparentAs someone who has had to trick Google Play store country, it's a bit more complicated than that. You can only change the Google Play country setting once a year. You can only change it if Google determine you to be located physically in that country. Based on my testing, the only combination I could use to trick them was: * no SIM in the phone * Wi-Fi connected to another phone's hotspot which is VPNing to the desired country * GPS off * payment method in the desired country That way Google have no way of knowing you're not actually in the desired country. Just certain parts (even including a SIM card in roaming originally from desired country didn't work) weren't enough. reply extraduder_ire 10 hours agorootparentWhy did you need to trick google play into using a different country? reply sofixa 9 hours agorootparentApart from what the sibling comment mentions (certain apps not being available in the country you're in as far as Google Play is concerned), there's also family sharing app plans that are sometimes geofenced (everyone on the same family plan needs to live in the same country which is not how my family works so it doesn't work for me). reply vachina 8 hours agorootparentYou can install region specific APK and use Aurora store to manage the updates. reply yunohn 9 hours agorootparentprevSometimes when traveling, local apps are restricted to their country’s App/Play store. Really annoying! reply LoganDark 9 hours agorootparentprevSome apps are only available in certain countries, and some countries have more favorable prices when exchanging from USD (or etc.). reply Mo3 10 hours agoparentprevGoogle's knowledge of your location is much more detailed than only your phones GPS location. - Billing addresses for Google Play - Wifi and cellular networks seen by your Android devices - IP addresses and other identifiers of all devices you used to access Google services (mobile and web) - GPS metadata in pictures uploaded to Google Images and Drive - Documents with addresses such as bills in your Google Drive and Gmail And probably much more that I can't think of right now. The Google Play store country however can be changed once per year, but you need a valid billing method originating from this country. reply nanomonkey 2 hours agorootparentFrom a conversation with a Google employee, they also know what floor of a building you're in from the accelerometer and barometric pressure sensor. Probably even which direction you're facing from the compass. reply Ambroos 4 hours agoparentprevThe easiest way is to just have multiple accounts, ideally with payment methods/phone numbers for the relevant country. My primary account is locked to Belgium because of family sharing, but I have a separate US one with a US CC I made when I lived there. And a separate Swedish one with a Swedish CC because I live in Sweden now. I can just switch between the accounts in the Play Store and have apps from all three installed and auto-updating at all times. reply pards 7 hours agoparentprev [–] I tried this using Fake Traveller and it didn't work. - Installed Fake Traveller - Set Fake Location App - Set location to Sydney, Australia - Open Play Store - Search for ANZ Shield (Australian banking app) Result: App not available in my region :( reply dewey 3 hours agorootparentAren't almost all app stores linked to the billing country (Country of credit card) for tax reasons alone? reply BLKNSLVR 5 hours agorootparentprev [–] Combine it with a VPN with an exit in Australia and you might have better luck. IP addresses are pretty standard for geo-fencing as well. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "FakeTraveler is an Android app that allows users to fake their phone's location for privacy or app testing purposes.",
      "Users can select a location via a map or enter specific latitude and longitude coordinates, then apply the changes.",
      "To use FakeTraveler, users must enable Developer options and set FakeTraveler as the mock location app."
    ],
    "commentSummary": [
      "FakeTraveler is a mock location app for Android that allows users to fake their phone's location.",
      "The app is open-source and available on F-Droid, a repository for free and open-source Android apps.",
      "Despite its functionality, some users note that it may not bypass certain app restrictions, such as those in banking apps or Pokémon Go, without additional measures like rooting the device."
    ],
    "points": 109,
    "commentCount": 66,
    "retryCount": 0,
    "time": 1722400215
  }
]
