[
  {
    "id": 41422311,
    "title": "1M Users",
    "originLink": "https://blog.spacehey.com/entry?id=1245177",
    "originBody": "Error 503 — Service Unavailable No server is available to handle this request. What to do: Wait a few minutes and try to reload this page Check our System Status Page Check if we already tweeted about this issue: @spacehey Notify us about this error by sending an email to support@spacehey.com Reload Page Send Us an Email",
    "commentLink": "https://news.ycombinator.com/item?id=41422311",
    "commentBody": "1M Users (spacehey.com)668 points by theneedful 15 hours agohidepastfavorite163 comments WoodenChair 8 hours agoWhatever you think of the site itself, this is prime HN content. A kid in high school starts a site that scales to 1,000,000 registered users while working on it during nights and weekends in college. If the founder is on here, what tech stack did you use and how long had you been programming before you built it? reply mg 4 hours agoparentHe uses \"vanilla PHP/HTML/MySQL\": https://x.com/AnTheMaker/status/1530851239310802947 reply rambambram 1 hour agorootparentI call CSS, HTML, Apache, MySQL and PHP the CHAMP stack for a reason. ;) reply grumple 3 hours agorootparentprevSo the same stack as 20+ years ago… good job, kid. reply rchaud 1 hour agorootparentvDOM bros hate this one simple trick. reply EGreg 1 hour agorootparentThe web stack “they” don’t want you to know about reply wutangisforever 1 hour agorootparentprevLove this comment reply herpderperator 32 minutes agoparentprevIt's pretty easy to check if a page is a PHP page: just add a .php suffix, it'll work most of the time depending on where the files are placed in the web directory (also technically depending on how the site implements URL rewrite rules): * https://spacehey.com/index.php * https://spacehey.com/browse.php * https://spacehey.com/reset.php Here you can see that /help/ is a directory on the filesystem, as it appends a slash at the end: * https://spacehey.com/help -> goes to https://spacehey.com/help/ and can also be confirmed by trying index.php at that path: * https://spacehey.com/help/index.php reply riedel 1 hour agoparentprevWas launched on HN 3yrs ago: https://news.ycombinator.com/item?id=25245740 reply ciaran_lee 7 hours agoparentprev(not the founder!) Looks like it's built on ColdFusion reply codethief 6 hours agorootparentWait, that still exists / still gets used for new projects today? Wow, I'm feeling teleported back to the 2000s. reply nop_slide 5 hours agorootparentPeep this, I stumbled on it randomly last week and also was surprised that it still seems to be around and kicking. It’s basically a Rails for cold fusion lol. https://www.coldbox.org/ reply 51Cards 5 hours agorootparentprevWe have several legacy products still running on CF, all running rock solid, but also all ported to Lucee these days. I still like CF but I'm an old fogey that started with it in the late 90's Allaire days. I often wonder if it had been open source from its inception if it would have grown faster than PHP. It really was a 'swiss army knife' of web development. It's still around here and there but mostly in larger corps that don't blink at Adobe's crazy licensing fees. Most everyone else in the communities I talk to has jumped to Lucee. reply password4321 5 hours agorootparentprev\"Well actually\" a relevant discussion hit the front page yesterday: Lucee: A light-weight dynamic CFML scripting language for the JVM - https://news.ycombinator.com/item?id=41409434 - Aug 2024 (37 comments) reply duxup 5 hours agorootparentprevI’m working with it every day. It’s pretty capable even today. Server side rendering is in! reply lelandfe 4 hours agorootparentprevAnd it’s using Silk icons. reply mikeodds 5 hours agorootparentprevThat’s strong commitment to sticking with the original tech stack if it’s not just reskinned the error pages reply herpderperator 2 minutes agoprevI'm curious what sort of infrastructure this runs on (hardware-wise), as I'd bet it's not some crazy highly-available complicated distributed system that is often glorified in tech companies and even on HN. If so, it would be a great example of \"just go do it\" rather than spending weeks and months over-engineering for scale that just isn't needed in 99% of cases. reply networked 7 hours agoprevFirst, let me say I admire the successful effort to revive a piece of the 2000s web and wish the project the best. Having said that, I am of the right age to have been on MySpace, and exploring Spacehey gave me a better understanding of why I wasn't on MySpace. The focus of the site is on you and who you are. It's about presenting your many overlapping identities with style. Your interests and creative output are secondary. Interests serve as more of a way to categorize yourself along standard dimensions (favorite movies, books, etc.). I don't think I want this! It's okay if you do, but it really isn't for me. It seems so optimized for legibility, in the late James C. Scott sense. I feel like all the CSS in the world won't help if this is how you must present yourself. Let me hide in my shell [1] and put forth my work. You'll get a better idea of who I am when I write something or if we talk. GeoCities, LiveJournal, DeviantArt, and Tumblr all seemed less like this, though I also wasn't active on any of them in their heyday. People may think Tumblr is about the user's identity, but identity isn't at the core of the site design. The site design is about tagged posts. Where you might want to push for legibility is on a dating site. I am sure MySpace served as one for quite a few people. :-) [1] I have realized this is a pun because I like pubnixes. reply dansalvato 31 minutes agoparentI wasn't really on MySpace either, but I think it's exactly where your complaint lies that drew such a huge demographic. When I think MySpace, I think teenagers who are still discovering their identity—not seasoned creators with a catalog of work to show off. The masses were given a means to make a page that encapsulated their identity and connect it with others, during a time where it was suddenly made possible for everyone to express themselves, but still difficult to produce meaningful online content. I think Tumblr eventually ended up capturing a lot of that, but I also feel that there is a sense of pressure around having a space where the purpose is to publish content (even if just reblogging). It was really meaningful to a lot of people that they could have a simple space to express themselves through custom mouse cursors, cringey quotes, and autoplaying emo music. Nowadays, this expression of identity for younger audiences seems to be driven by being a part of online communities with common interests, expressing oneself through content (now that it's so easy to make and share). But I think MySpace was there for people at the right time. reply inhumantsar 6 hours agoparentprevI suspect the world would be a bit better, or at least a bit less toxic, social media kept that primary focus on open expressions of identity rather than only the highlights from a person's work or art or daily life. reply DiscourseFan 5 hours agorootparentmy work and art are more important than me reply seanthemon 4 hours agorootparentYour work and art are an expression of you. How can you express something effectively that you deem unimportant? reply aethertron 3 hours agorootparentNot to downplay my personal importance (=make an ostentatious display of humility, lol) I can work on art and projects to express the importance of other things in the world that aren't myself. reply throwaway48540 41 minutes agorootparentBut it's still your expression, or put another way an expression of you. Imagine art critics studying your art - they would be asking what was your history, context, what happened to you and what was going through your head that made you do this. It's always about you, even - maybe especially, considering that defeating one's ego is still noteworthy - if you don't want it to be about you. Making art that's not about the artist is reserved to LLM... At least for now. reply DiscourseFan 2 hours agorootparentprevThey are and at the same time they overcome me, they are more than just \"me.\" And that is why the possibility for greatness lies in the artwork, and not the person. reply simplify 2 hours agorootparentprevFirst, humility is an under-appreciated virtue in today's world. Second, the idea of \"your work and art are an expression of you\" is dangerously self-centered, in that it can limit your growth by pushing you conform to acceptance over aspiration. reply LastTrain 4 hours agorootparentprevAgree - content oriented social media is just advertising. reply herpderperator 4 minutes agoprevI'm curious what sort of infrastructure this runs on (hardware-wise), as I'd bet it's not some crazy highly-available complicated distributed system that is often glorified in tech companies and even on here. reply dang 15 hours agoprevRelated: I rebuilt MySpace from 2007 (2 year update) - https://news.ycombinator.com/item?id=33792956 - Nov 2022 (9 comments) Spacehey: A Space for Friends - https://news.ycombinator.com/item?id=28770637 - Oct 2021 (15 comments) I Rebuilt MySpace from 2007 - https://news.ycombinator.com/item?id=25245740 - Nov 2020 (290 comments) reply kaladin_1 8 hours agoprevI love that it is snappy. I didn't read the article but I spent time examining the browser network calls, not much css and js downloads. I truly love the feel of it. Not sure I care about another SM platform but I was very happy to see a snappy site on a Monday morning. A good reminder to put care in my work this week. During the weekend, I had to fight the urge not to implement a tiny client for interacting with my bank. A company making loads of profit but can't fix their online banking platform. Every page takes not less than a minute to open. No form of caching user details, API calls are made and take same response time not matter how many times you navigate to a screen. reply pech0rin 14 hours agoprevLooks interesting. Definitely nailing the old myspace aesthetic. I’d be more curious about active users versus registered users. Social networks are usually defined by activity. Unfortunately registered users probably contains a lot of bots and spammers. reply Sparkyte 14 hours agoparentWhen I saw this I was like ooh noes not myspace all over again. I feel this style may actually be a hinderance for adopting more users. People really want something more reactive like Discord. Discord is very much disliked, but the software is really good and that is why most people won't abandon it. It is like comparing Slack to Teams. It will be a long time before anything catches immediately up to Slack or Discord in usability. Although I have a short list of things that would be QoL improvements that would make both them soooooo much better. reply sqeaky 13 hours agorootparent> Discord is very much disliked, but the software is really good and that is why most people won't abandon it I dislike every single one of discord's design decisions, I think the software is garbage, and it is riddled with security problems. Their customer service is a nightmare, a hacker got one of my friends accounts and even though he'd paid up for some kind of Discord extra service for more than 2 years in advance they wouldn't refund him or give him his account back. The API is bad too. I use it purely because of the network effect. The people I want to communicate with use it, and the instant that changes if Discord isn't better then I'm out. reply Kiro 10 hours agorootparentWhile I disagree with the parent I personally think Discord is great. I've been on IRC for over 30 years and Discord is what I always imagined IRC 2.0 would be like. reply plufz 9 hours agorootparentI feel sort of ehh the same but also the opposite. I feel with both slack and discord that they are a little better than IRC. But that I so easily can see those features being implemented in IRC and I feel really sad history didn’t go in that direction. What if IRC had became the standard in the same way email did. IRC was so great and I miss it. I know ppl still use it, but I don’t even think I have a client anymore. Learning to program as a kid in the 90s and getting that 28.8k modem with direct chat access to adults at Apple and later Sun/Java was amazing. reply multjoy 9 hours agorootparentprevWhat, owned by a single company and monetised within an inch of it’s life? reply emmet 6 hours agorootparentI would have loved to pay monthly for IRC Nitro™ back in the day to use… uh, forbidden ascii art? reply layer8 7 hours agorootparentprevPeople who liked IRC will generally like Discord. However, there’s a lot of people who prefer asynchronous forums. reply stevage 10 hours agorootparentprevAgreed. I like almost everything about discord. I just wish it did threaded replies in a more low key way. reply llm_trw 12 hours agorootparentprev>Their customer service is a nightmare Having customer service would be a step up. >>We banned your account for illegal activity. >But I just signed up and tried logging in? >>After review we have banned your IP forever for illegal activity. reply marcus_holmes 12 hours agorootparentWhat's the point of banning an IP address? reply michaelt 9 hours agorootparentI love Tor - but the exit node IP addresses do not have a good reputation, because they're a source of a lot of misbehaviour. Sure, 'serious' attackers have botnets of home users' PCs and insecure IoT devices and whatnot. But because Tor exit nodes are easily used by even unsophisticated attackers, they quickly get flagged as sources of abuse. reply draxil 10 hours agorootparentprevSome people (like me) have a fixed IP for their internet connection. Although this isn't super common any more. reply marcus_holmes 9 hours agorootparentYeah, it's really only tech folk who have fixed IP addresses, and they're usually too busy futzing around with servers to post shite on social sites ;) Most IP connections are dynamic, and always were. Assuming that a person is synonymous with an IP connection makes no sense to me. reply Tijdreiziger 7 hours agorootparentFor most dynamic IP connections, as long as your router doesn’t go offline for days on end, you keep the same IP; so in practice your IP (almost) never changes. reply juped 6 hours agorootparentprevYou got an actual useless automated message? The lucky 1%. reply pjc50 9 hours agorootparentprev> Discord is very much disliked, but the software is really good Discord as a text chat app is appalling. Whether on mobile, chromebook or desktop PC it's slow and janky to transition between channels. It is a measurably worse user experience than using IRC on a computer from twenty years ago with 1,000x less raw MIPS. Maybe it has some advantages for voice chat, but to me it's a lowest common denominator we use because of the people and despite the software. reply password4321 5 hours agorootparentDiscord's back end is amazing and they've blogged about a lot of it over the years (https://hn.algolia.com?query=%22How%20Discord%22). Not as smooth sailing on the front end though, and unfortunately they threaten to ban accounts using alternative clients, though there have been several (https://hn.algolia.com?query=Discord%20client). Discord is good enough for most users and since it was one of the first to fully leverage WebRTC in-browser for voice chat (without requiring an account), the network effect is almost impossible to overcome at this point. This is incredibly unfortunate as closed chat ecosystems are an information black hole (except possibly when user generated content is licensed to the highest bidder for LLM training, what a gold mine!) PS. It's worth mentioning in any Discord discussion with the (though the usual \"could get banned\" caveat applies): it is possible to export from Discord using https://github.com/Tyrrrz/DiscordChatExporter reply vunderba 3 hours agorootparentUnfortunately, personal account automation like this is also in the reasons for \"could get banned\". Sigh. I thought about building a scraper using something simplistic like Puppeteer to login to my account since the Discord browser experience is basically the same as the Discord app (which makes sense since its Electron). It would just issue a command to scroll arbitrarily up on a given channel/etc. until a certain earliest date was reached, and scrape all the data. But.... again I'm sure that they have all sorts of mechanisms to detect unusual user behavior, so this might be JUST as vulnerable to detection as the aforementioned DiscordChatExporter. Even leviathan walled gardens like Google let you export your data in a reasonable fashion (Google Takeout) - this is probably my biggest issue. On the other hand even if I could find an equivalent user-friendly platform, I'd never be able to convince all my contacts to migrate off Discord. reply vunderba 4 hours agorootparentprevThe disparate experiences people have on the same piece of software is interesting. I'm on a Mac M1 (so definitely a higher end laptop) and have had zero issues with the Discord app. It sits comfortably on my second monitor and I use the Cmd-K shortcut to quickly snap to the correct channel/user when I want to chat. While I wouldn't call the app \"blazingly fast\", I don't really notice any meaningful latency. I mean it's not like it's a low-level ASIO driver for pete's sake. Memory usage is also reasonable. Continuous uptime is over 4 days now, and combined real mem shows it's using about ~400mb which honestly is about what I would have expected from an Electron app. I think some of it comes down to user expectations. When I'm playing a game, we're primed to look/notice choppiness and dropped frames particularly since the graphics are constantly animated. When I'm using my DAW, I'm primed to hear latency between my interacting with a midi controller and the audio output. I don't have any such expectations when I'm using a glorified text messaging platform, so while there might indeed be some latency, it would have to be significant for me to notice. That being said, I'm not a fan of the Android app - the UI/UX experience is rather rough. reply Voultapher 8 hours agorootparentprevYes on very fast modern hardware, the textbox sometimes takes dozens of frames to display the character I typed, and it is inconsistent. The tech sucks. reply Mashimo 8 hours agorootparentprevWhat makes it appalling? You can press ctrl + K to jump to any channel from anywhere. Feels snappy. reply RunSet 13 minutes agorootparentHexchat feels snappy. Discord feels like an Electron app. reply pjc50 8 hours agorootparentprev> Feels snappy. I wonder if this is just everyone else using it on massive gamer PCs and me using it on mobile/chromebook, but .. no. It it is not snappy. The process of fetching all the new messages and rendering them takes up to a second. I don't understand why people who insist on 60fps games are happy with a 1fps chat app, but I guess they don't have that experience. reply sigseg1v 5 hours agorootparentI'm using a $6000 gaming rig I put together and Discord is one of the worst performing apps I use, so I'm with you on this one. reply Mashimo 6 hours agorootparentprevEven on mobile switching channel feels snappy to me. The images can take a while if they are not cached yet. reply KingMob 7 hours agorootparentprevAnd yet the one thing I can't do is automatically jump to the top of a question. One of my Discord servers loves doing FAQs as separate conversations, and once they get too many replies, I have to scroll endlessly (PgUp, etc) to see the first few comments. It's maddening. reply jazzyjackson 13 hours agorootparentprevDiscord always had a unique way of making me feel old I avoided it because when when a ding occurred there is no indication which channel had just donged, just left me confused as to what was happening reply damaya1982 10 hours agorootparentI get on Discord here and there to discuss Linux, programming and so on. It is definitely much different than IRC. The demographic seems to be 14 year olds trying to customize their WM. reply courseofaction 12 hours agorootparentprevLikewise - a notification history feature would help, the confusion really cripples the real-time experience. reply RheingoldRiver 11 hours agorootparentit has a notification history feature (at least on PC), it's just impossible to find and deleted messages disappear from it. Upper-right corner is your \"inbox\" which is totally worthless, and tabbed behind that is your notification history. I use it to find totally buried @Mods pings that I missed by thousands of messages and that's about it, it's not good. You can usually get most of your notifications with Ctrl+[T or K] and then going through the menu here, but for reasons I've yet to figure out sometimes DMs don't show up here even when they have unread messages. I think there is some incorrect logic that kicks in when you have a high number of unread channels and it can't show as many \"previous channels\" as it wants to. None of this is to defend Discord, I think their UI is bad and I've hated the way DMs function since day 1, and every single part of their app that relies on frecency (or doesn't but should) is abysmal (reaction autocomplete, the reaction pop-up menu, ctrl+T when you start typing something, the mention autocomplete behavior in any channel) But once you learn the poorly-documented navigation flow of ctrl+T and then using @, #, or * to filter users/channels/servers it gets easier to use. My current biggest complaint is lack of a \"previous channel within this server\" hotkey, \"previous channel that you visited globally\" exists but you can't restrict it within one server, and it makes navigating some of my servers an absolute nightmare. reply Mashimo 11 hours agorootparentprevIt's there. Top right corner. \"Inbox\" then select mentions. reply saagarjha 12 hours agorootparentprevIt might be that someone sent a message and then deleted it. reply lelanthran 9 hours agorootparentprev> People really want something more reactive like Discord. Discord is very much disliked, but the software is really good and that is why most people won't abandon it. This probably comes as a surprise to Discord users, but it really is a niche social network. We're talking fractions of a percent of users compared to existing social networks. People don't really want something like Discord - the downsides by far outweigh any upside of \"a closed-off private network of people\", biggest one being lack of visibility and consistency. reply pavo-etc 14 hours agorootparentprevGo use facebook then. This project seems fun. reply BLKNSLVR 14 hours agorootparentprev> hinderance for adopting more users Promotes a smaller, more tightly knit community. One person's X is another's Y. reply creesch 10 hours agorootparentprev> People really want something more reactive like Discord. Citation needed :) This feels like you are parroting either your own preference or something you have heard other people state as fact. reply SubiculumCode 14 hours agorootparentprevI think there is enough space for lots of styles. reply cdelsolar 3 hours agorootparentprevHmm.. I love Discord? reply FranzFerdiNaN 12 hours agorootparentprevAh yes, because real time chatting and a wall to post stuff on like early facebook surely are the exact same hting. reply can3p 8 hours agoprevNice! Personally I think that the more niche social networks we have the better it is. The big problem with the mainstream networks is that they've evolved from a media to communicate and keep in touch with real people into a platform for influencers and businesses. The common complaint I hear about instagram for example is that every second connection of yours would try to sell/teach something and that's just garbage if all you need is to keep in touch with your friends. The main problems to tackle imo are: - information propagation speed. This is good in case you want to get a quick update but it also a double edged sword, since this allows information attacks, trolls etc - Scale. Anything of big scale becomes a problem by itself since it becomes economically viable to target the platform with bots, scam etc. - Incentives. I think we should get to the point where social networks are being run by non profits I've posted the link a couple of time, I'm working on my personal take on this problem[0]. My approach is the following: - Slow down information propagation. Every post is visible to the direct connections, to their connections if you allow it, but no further - No way to get a connection request from a stranger. Either you specifically allow it, or it's introduced by your direct connections - No federation, since my idea was to have small communities - Fully open in the sense of data formats, import/export etc. Migrating between instances is as easy exporting posts in bulk, creating an account on another instance and doing the import. You could do the bulk updates the same way Also, it's all go + htmx just in case anyone else is also tired of modern frontend mess. I have a couple of videos on the feautures[1], if you like. The design is not great, since I wanted to focus on the idea itself [0]: https://github.com/can3p/pcom [1]: https://www.youtube.com/playlist?list=PLa5K-kCUS-FozB6Cw7rJL... reply nunobrito 4 hours agoparentGood post. Have you already took a look into NOSTR? It permits both private/niche communities and public (global) texts. reply can3p 3 hours agorootparentJust checked it, thanks for pointing to it. I think it's more of a decentralized encrypted messaging platform, and my idea was to have a way constrain the visibility of the conversations to naturally connected groups of people while giving a way to slowly expand the connections rather then fighting censorship More or less like in real life, where you chat a lot with your friends, but necessarily with some of their friends you don't know that well. In this case you would ask your friends for the introduction and that what I've tried to model. One other feature I've been thinking about was to make the moderation automatic in a sense of making signups possible only via invitation and putting some weight on it. Basically if you invite somebody who's misbehaving on the platform and they get flagged, you get penalized as well unless you do it first. My theory is that it should make users care about their digital surroundings. reply OptionOfT 5 minutes agoprevSide note: the status page spacehey.com uses is one of those websites that'll do ANYTHING to get traffic. On the blog [0]: 6 Best Self-Hosted Status Pages 0. Instatus Instatus isn't self-hosted, but you can use it to get a quick & beautiful status page that's free forever. [0]: https://instatus.com/blog/best-self-hosted-status-pages Way to go to pollute search results when looking for a self-hosted status page. reply massimosgrelli 11 hours agoprevIt's incredible how this type of revival from the past gained such meaningful traction, but, in a way, I fully understand it. The online world has become so confusing that many desire a simple one. The same feeling drove me to adopt Threads over Twitter/X—even if I still use them both. reply grishka 9 hours agoparentThe problem is that all mainstream social media has degenerated into entertainment. Staying up to date about the lives of people you know irl is seemingly no longer their intended purpose. But people's need to connect in this way — just updates from those who they chose to follow, displayed chronologically, and no other content whatsoever — has not gone anywhere. That's why I'm also working on my own project that implements this type of social network with ActivityPub support: https://github.com/grishka/Smithereen It's beta quality for now and I'm not promoting it much yet, but I hope to bring it to 1.0 by the end of this year. reply z3t4 8 hours agorootparentYou should add some screenshots or video to the Readme, I'm too lazy to build it just to experience it. reply grishka 8 hours agorootparentYes I should. A proper website that explains what it is and contains docs about the client API (that also doesn't exist yet) is something I plan to have for 1.0. In the meantime, here it is live on my server: https://friends.grishka.me/ reply apples_oranges 11 hours agoparentprevThe confusion, especially on X, is caused by focusing on what advertisers want vs what users want reply blitzar 10 hours agorootparentThe confusion, especially on X, is caused by focusing on what the loudest dumbest users want vs all else. reply lelanthran 9 hours agorootparent> The confusion, especially on X, is caused by focusing on what the loudest dumbest users want vs all else. I'm not on X, so I don't know, but IME on every other place on the internet since forever is that the loudest, dumbest users ARE the advertisers. An environment that monetarily rewards users pushing their message into other peoples faces performs an environmental selection to make the advertisers the loudest and dumbest users. reply blitzar 6 hours agorootparentShilling scams, cosplaying as an influencer or being a bot does not make users an advertiser. reply pjc50 8 hours agorootparentprevNo, Twitter was never especially advertiser focused, although it did do a bit of \"brand\" stuff. The destruction of Twitter was because as a a \"free speech platform\" it naturally picked up the most aggressive, nastiest, confrontational politics. It then algorithmically shoved this in front of the people most likely to make retaliatory posts. It is dying because it now focuses on what the owner wants, which is a set of increasingly fringe right wing lunatics and some guy called \"catturd2\". Hence getting banned in Brazil. I guarantee that is not an outcome any advertiser wanted. reply ineedaj0b 2 hours agorootparentI still use X and it's still very good. It's tough rn (as it always was) 6 months before the big US election but it'll go back to normal. I've been on twitter since 2011 and it's been the same pattern all these years. The secret, always is - follow new people in small increments and generously unfollow at the slightest annoyance. There are still lots of interesting people to find! You'll discover there's people on both sides of political issues who can make their points and not be annoying about it but these are maybe 1-3% of political people. You can also completely ignore politics by being judicious with your unfollows. reply hk__2 10 hours agorootparentprev> The confusion, especially on X, is caused by focusing on what advertisers want vs what users want Is it? Last time I heard about it advertisers were going away because Musk is focusing on what loudest users want (being able to speak loudly) and not what advertisers want (moderation) reply alt227 7 hours agorootparentI feel like this is a relatively new situation, whereas the parent post describes very well the development of the service over the last decade. reply globular-toast 10 hours agoparentprevIt's happened time and time again already. Firefox was the light version of Mozilla. Then that got bloated. Chrome was the light version of Firefox. Now that's bloated. Very few things resist bloat over time. This website is an example. People sometimes ask for new features, but the only change I can think of is pagination for long comment threads, which was driven by necessity. Can't wait for IRC to become popular again. I'll still be there, waiting. reply insane_dreamer 2 hours agoprevExcellent achievement!! A good feel of the Internet before monetization poisoned it. > I've stopped myself from working on any new features in the past months, but rather improve the existing ones and make SpaceHey overall a bit smoother. Wise. Not everyone is willing to do the hard word of slogging behind the scenes with little or no visible changes to users, but it makes a huge difference. Kudos. reply enumer8 13 hours agoprevI've been on Spacehey since 2021 and it's remarkable how fun and cozy the place has stayed over the years. reply meowtimemania 13 hours agoparentHow often do you login? What makes it sticky for you? reply enumer8 11 hours agorootparentI stay logged in almost all the time. I wanted some place where I felt like I could blog freely, and one that _felt_ like a blog instead of some ad-ridden mess. It was partially the customisation aspect that drew me in at the beginning, having that much control over my profile (even if it was just basic HTML and CSS with some JS) reminded me of what I loved about being online. I have a personal website and don't really pay much heed to the 'social' aspect of SpaceHey but having a little corner where I can just go and blog/post bulletins about things I'm thinking about, especially because it has a straightforward interface, feels really nice. The lack of ads and algorithms and general 'social media' paradigms of the modern age do a lot to make sure I keep going back. reply trwhite 7 hours agorootparentWhat's your username (if you don't mind me asking)? reply thelastparadise 5 hours agorootparentprevHey man, I'm getting started on the platform. Mind sharing your username? reply shortrounddev2 6 hours agorootparentprevI wanted to get more involved in the community on that site but it seems there's a LOT of teenagers on it reply aurareturn 12 hours agoparentprevEdit reply llm_trw 12 hours agorootparentSubs get bad with more people, to really ruin them you need power mods. reply asdf6969 1 hour agoprevI love it. I’d like to make something similar. > One million people from all over the world have used SpaceHey so far - an independently run platform that does not track you and does not show you personalized feeds nor ads. Does anyone here know how it’s funded or what this would cost to host? reply jchook 14 hours agoprevMySpace ran so SpaceHey could walk reply ryukoposting 3 hours agoprevThis site is more usable on my phone than 90+% of \"mobile sites.\" It loads instantly, even on a crummy cell connection. There's no ad divs that load 5 seconds after everything else and screw with the layout while you're reading something. There's no attempt at \"infinite scroll,\" which universally results in stuttery scrolling and a generally sluggish experience. No fake modals with infuriatingly small close buttons, heckling you for your email address. The WWW has become stuffy and stale, and this site is truly a breath of fresh air. reply hinkley 3 hours agoparentI enabled ad blocking on my iPad primarily because a webcomic I read put one of these fucking ads at the top of the comic page, and it seems to be “optimized” to load in just as I’m about to click the comic image to zoom in on it. I must have clicked that ad on accident a hundred times and I hate it. How many cookies is that? How many networks now know how much more about me. Fuck that. You’ve gotten a lifetime of ad revenue from me boyo and we are done. Everybody is done. reply rust1npeace 8 hours agoprevI like the UI. I think the old UI of web is pretty cool. I think making old UI websites with modern backends would be a great design choice. reply IsopropylMalbec 4 hours agoparentThat's what I have been trying to do with the B3ta site[0]. It is a UK humour site forum that was founded in the very early 2000s. I have been looking after it's backend for about five or so years, trying to modernise what I can and keep it stable and maintainable. I have learnt a lot of respect for people who create a site like Spacehey, it quickly spirals in to a job in itself. [0]: https://b3ta.com/ reply qingcharles 2 hours agorootparentb3ta is awesome. It's had a crucial, but mostly unknown, role in Internet culture for two decades. Thank you for your service :) reply IsopropylMalbec 2 hours agorootparentThanks, I only do it for the childish laughs! It crazy how it shaped so much yet only a very specific slice of people know it exists. reply tock 13 hours agoprevThis looks so cool! And I love the feel of basic server rendered pages! reply troupo 11 hours agoparentIt's also so much more responsive and predictable than most of today's crap reply troymc 3 hours agoprevNeocities has a similar vibe. https://neocities.org/browse As its name suggests, it was inspired, in part, by Geocities. reply ZacnyLos 10 hours agoprevAs long as this site doesn't implement the ActivityPub protocol, I don't see any reason for me to move to this site. I don't have time to maintain another account, and I want to keep in touch with people from Mastodon and Threads. reply rchaud 1 hour agoparentThis feels like a very 2010s comment, when it was assumed that one has to be on every single social network app, copy/pasting the same 'content' into each of them, in order to be visible online. All that did was turn the net into a giant monoculture of hot takes and too-short posts. Only influencers and shovel-sellers need that. reply layer8 7 hours agoparentprevBeing its own local place is a feature, IMO. reply idonov 13 hours agoprevPlease let this go viral, it's about time to make social media great again reply michaelteter 13 hours agoparentAnd it’s time to stop saying “make ___ great again”. reply edm0nd 11 hours agorootparentmake HN great again reply jaza 10 hours agorootparentWe're gonna build a wall, and Slashdot is gonna pay for it! reply throwmeaway222 11 hours agorootparentprevDoesn't everyone want everything to be great again? reply imhoguy 10 hours agorootparentprevWe need MSGA hats! reply nurettin 13 hours agorootparentprevO Rly? reply hunter2_ 13 hours agorootparentThere's a paradox almost worth discussing somewhere, but not here. reply Ylpertnodi 11 hours agorootparentMake \"And it’s time to stop saying “make ___ great again” great again? reply lawgimenez 13 hours agoparentprevAnyone here tired of social media? I’m almost 40. Just curious of my age group. reply marcus_holmes 11 hours agorootparentMore angry than tired. To clarify: angry at Social Media rather than on it. FB was great in about 2010, but is now ridiculous and basically unusable. My wife is addicted to IG, and spends multiple hours each day scrolling the feed. My social life revolves around WA groups. I tried moving people to Signal but got few takers. I'm enjoying Mastodon at the moment. I'm scared that if I install TikTok I'll get addicted. I've seen it happen to friends. I would like to return to email, circa 2000, that was fun. reply helboi4 8 hours agorootparentI have been addicted to ig. Still can be if I let myself. Reddit can also get me hard. Whatsapp groups I actually love because there's nothing to scroll. Just people lmk about an event and I can interact with them like a human, and I can go to the event. I get to know about things and I don't have to interact with meaningless content alongside it. I love it. What exactly is wrong with Whatsapp groups other than that it's owned by Meta? I also have some Telegram groups. reply 4k93n2 5 hours agorootparentprevzulip seems like a nice sweet spot between email and instant messaging apps, and maybe forums. ive havnt actually used it yet but its on my self hosting todo list reply oxygen_crisis 10 hours agorootparentprevWe may be choosier than most about social media, but here we are typing our thoughts into a web page expecting nothing in return except the possibility of hearing other peoples' thoughts. We all know people who are truly tired of social media, we're not going to hear from them here. reply alex1138 5 hours agorootparentprevI don't know how to interpret statements like this. In my mind there has to be a clear separation between problems individual platforms have (ie an algorithmic feed where you may or may not see what your friends actually post despite explicitly following them) and... the rest of the discussion. \"Social media\" (a very broad term) as a medium people dislike, well, that's individual. It means no matter how a platform does some people will always be against it. I don't understand that. I think the more important discussions to have are how we can improve specific sites reply nicholassmith 10 hours agorootparentprevAlmost 40 as well, also tired of social media but I do miss social networks. This seems to hew more closely to the social network concept than being a media outlet which is lovely to see coming back. reply manuelmoreale 6 hours agorootparentprevDefinitely am. I’m 35. Thankfully I found a great place to be in the blogging world. I write posts, I read posts from others, we connect via email. It’s great. reply helboi4 8 hours agorootparentprevI'm 26 and I'm tired of social media. I was addicted to insta for a bit and I've teared myself away. Now when I go back, I can still feel the addictive quality but for the most part I look at people's posts and wonder how they aren't embarassed. Like why do I care to see this photo of you? Did you really just set your camera up in this complicated way to take a photo in your room? Isn't that sad? Do people actually get anything from these reels that are so vapid? The fact that one of my favourite songs is being used as background music to the most inane \"comedy\" makes me angry because it's ruining my experience of the art itself! All these things go through my head. I couldn't take myself seriously posting any more unless it was strictly for business. reply CalRobert 10 hours agorootparentprevNo, I moved abroad and when sm was good it let me preserve my friend networks. Now it’s a wasteland. I miss it. reply Heliodex 9 hours agoprevIt's been over a year and a half since I was last able to access their site at all without seeing just a \"403 Forbidden\" page. reply floppydiscen 7 hours agoprevJust curious, without ads, what are the running costs and how are they paid for? reply high_priest 10 hours agoprevScrolling through these profiles in the age of text generating AI, gives me this uncanny feeling, that what I am reading is just random gibberish spat out by a LLM. I feel like anything I'd post on this platform, would get lost in giant noise of generated feces. Maybe it's just, the unknown world of \"artsy\" people is what is really so off-putting. Maybe I am just getting old and don't understand this joy of childish expression anymore. But the other, most popular platforms, seem to have more appeal for followong reasons: - Facebook works around ads (pages) & groups about my (technical) interests, there isn't really a reason for AI spam. If any would appearx it is easy to make them disappear. You get some ads here & there, but content generating bots are often named bots & post content we've agreed to. - Discord gives you high walled gardens for every topic you are interested in. So, one really needs to get out of their way to get content they are not interested in right now. Plus, everything feels like a DM, even the public chats are all just quick chats. - X is literally a politics platform, so I am not expecting AI content from verified account of a diplomat, or media person. reply Fokamul 10 hours agoparent>\"FB and there isn't really a reason for AI spam.\" Heh good joke. Facebook is full of spam bots, phishing etc. Using following template, hack legitimate account, buy ADs for your phishing campaign with stolen CCs, phish people, rinse and repeat. And quantity of phishing/spam is so huge, Meta is basically unable to fight this. reply boingo 8 hours agorootparentYou're right about it existing, but FB could definitely fight it, removing 90% or more. But sadly it generatesa LOT of extra revenue for them (stolen account with stolen CC = thousands spent on ads) so they have monetary incentive to turn a blind eye and let people get scammed. reply patcon 10 hours agoparentprevI was very stressed last year and had what felt like a dissociative episode: Knowing what was becoming possible with LLMs, I one day just couldn't shake the feeling of unreality while reading any online spaces, including hacker news. I felt like maybe 70% of comments I was reading might not be real. Everything, including HN, just seemed so predictable or unsurprising It was an altered state that felt like the leading edge of... something reply Hendrikto 9 hours agorootparent> Everything […] just seemed so predictable or unsurprising That are people for you. Most of the time, we are uninteresting, predictable, and unoriginal. Especially when you got used to some subset, like HN, where there is a bit if self reinforcement, through the voting system. reply jazzyjackson 2 hours agorootparentprevhttps://en.m.wikipedia.org/wiki/Derealization reply panyanyany 14 hours agoprevCongrats! How do you promote ? Post links everywhere ? reply jazzyjackson 12 hours agoparentthey've got merch, you can be the promotion you want to see in the world! (jokes aside the hat is pretty classy) https://shop.spacehey.com/ reply JCharante 5 hours agoprevThis is my first time hearing of this site but wow I love the design! It’s so intuitive. reply AlienRobot 1 hour agoprevI love this website's design. Look at those icons. They have color! reply pndy 12 hours agoprevIt's a total blast from the past - even profiles look exactly the same reply holistio 8 hours agoprevThis feels like giving a cigarette to heroin addicts saying it won't f them up so badly. reply jeffrallen 13 hours agoprevThe kids are alright. reply skeptrune 13 hours agoparentAgreed :joy reply fhdsgbbcaA 13 hours agoprevHow much of the 1M is the bots they found? Hopefully none, but that’s a big number of humans. reply richardburton 3 hours agoprevLet's be friends: https://spacehey.com/ricburton reply andrewstuart 13 hours agoprevPresumably that is 1M people in the database, I'm curious to know how many active users who sign in once a day, once a week. In essence, how big is the community versus how many people have stepped in the front door once. reply marapuru 11 hours agoparentI did a quick check on the Online Users [0] via the Browse functionality and found there is a filter for online users. Currently it's 9:19 AM in the Netherlands. And there is about 7 pages filled with Online users. 45 users per page. About 7 pages filled with users [1]. So that's around 315 Online users in Europe during the day. My guess is that during US daytime numbers will be higher. Maybe someone in the US can do a check in a few hours? :) [0] https://spacehey.com/browse?view=online [1] https://spacehey.com/browse?page=7&view=online reply andrewstuart 11 hours agorootparentThat's pretty active, assuming the system somehow pulls them all together in some way. reply hyperbrainer 10 hours agoprevHow does it make money? reply hk__2 10 hours agoparent> SpaceHey is a small, independent social network, funded by your donations. https://spacehey.com/support reply xyst 12 hours agoprevappreciate the nostalgia. reply talonx 13 hours agoprevNo MFA? reply 0xbadcafebee 11 hours agoparentIt's funny, normally I would say \"MFA? for this??\" But actually I used to curate a MySpace for punk shows/bands in the city I lived in. I found every local band's page and added them as friends. Reposted flyers for upcoming shows. Posted pictures from shows. Had a blog. And one day a girl I broke up with found my password (or reset it, not sure), logged in, and deleted everything. Years of work down the tubes. So even for a MySpace clone, I'd say MFA is pretty handy, in those few cases that you need it. reply briandear 10 hours agorootparentThat combined with less psychotic girlfriends in your case. reply shreddit 11 hours agoparentprevYou can actually enable 2FA in your account settings reply mrweasel 12 hours agoparentprevI get why they wouldn't offer it. Support nightmare and very few people would use it anyway. Almost everything should have MFA, but it's not a solved problem. The overhead is to high and if you force it upon users you'll lose many of them. reply talonx 11 hours agorootparentValid point about support but if you enforce it everyone will have to use it unconditionally. Not having MFA opens it up to potential data breaches causing havoc. reply mrweasel 11 hours agorootparentAbsolutely, but not even Facebook enforced MFA... Though they do offer it. I just can't imagine the absolute nightmare it must be to get Facebook, Google or Microsoft to reset your MFA if you lose it. You might as well create a new account. We did a MFA reset for a remote coworker a few weeks ago, the about of validation and procedures we had to go through was insane, but also the only way to ensure that this is a correct reset. MFA is really really important, but there's no good solutions for it yet. reply jongjong 11 hours agoprevGreat, but will the powers-that-be allow it to grow beyond that? reply jazzyjackson 13 hours agoprev [–] Home page has a lot of red flags (Does every comment need a \"report comment\" hyperlink? I like how HN does it, timestamps are permalinks, permalinked page has additional options to flag and favorite.) (edit: timestamps are permalinks, at least) (Edit edit omg people customize their profile markup like it's 2006 again) reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "A high school student developed SpaceHey, a social media site reminiscent of MySpace, using basic technologies like vanilla PHP, HTML, and MySQL, and it has reached 1 million users.",
      "SpaceHey avoids modern social media issues such as ads and algorithms, offering simplicity and customization, which users find appealing.",
      "Discussions on Hacker News focus on the site's tech stack, user experience, and the broader implications for social media design, with debates on nostalgia and platform merits."
    ],
    "points": 668,
    "commentCount": 163,
    "retryCount": 0,
    "time": 1725246788
  },
  {
    "id": 41420597,
    "title": "Extreme Pi Boot Optimization",
    "originLink": "https://kittenlabs.de/blog/2024/09/01/extreme-pi-boot-optimization/",
    "originBody": "Extreme Pi Boot Optimization 🚀 3.5 sec to Linux userspace code By Manawyrm (@manawyrm@chaos.social)Sunday, September 01, 2024 Motivation A while ago, the SolarCamPi project, a off-grid solar-powered WiFi camera, was built. In this project, a Raspberry Pi Zero 2 W is being booted into Linux, a picture is taken, WiFi connectivity is established and the Pi is shut down again (to save power). This repeats every couple of minutes to always deliver a fresh image to a cloud service. Each second the Pi Zero is powered up uses valuable electricity, which is a scarce resource in a solar-powered device (at least in West European winters…). The user space application (server connection, picture upload, etc.) was already optimized as best as possible. The electronics setup was also specifically designed to use as little power as possible while asleep. There a 2 possible ways to reduce total energy consumption further: decrease power consumption / current decrease time spent running However, in some situations a balance needs to be found between the two. For example: Disabling CPU turbo just to save some current consumption is a bad choice, because the resulting extra time will use more energy than just getting the job done quickly and shutting off. We want the least area under the graph (of current vs. time) possible. Hardware setup Having a short cycle time between making a change and actually seeing it run is critical when optimizing embedded boot processes. Swapping SD cards, messing with card readers and power supplies while working is distracting and annoying. In order to avoid this, a number of useful tools exist: Nordic Power Profiler Kit II USB-SD-Mux Fast USB-UART converter Power Profiler Kit The Power Profiler Kit II (now called PPK) can supply power to a device-under-test (DUT) and will measure it accurately over time. You can enable/disable the DUT, see the power consumption at any point and also see the status of 8 digital inputs! We’ll connect one of the digital inputs to a GPIO pin on the Raspberry Pi. This way, the first action of “our application” (aka the finish line) will be to toggle the GPIO pin. We then just have to measure the time between power-up and GPIO toggle. USB-SD-Mux The USB-SD-Mux is a very useful tool for hardware hackers - it’s an interposer between a microSD card and a DUT with a USB-C interface. A computer can “steal” the microSD card from the DUT, rewrite its contents and then plug the microSD card back into the DUT, without ever having to touch the device. This makes the workflow of testing changes much easier and faster by avoiding unplugging the card, plugging it into a microSD reader, flashing it, plugging the card back into the DUT, etc. It can even be used to automate the reset or power of the DUT with on-board GPIOs. USB-UART converter Some form of UART interface is pretty much required. These changes will break system boot, WiFi connectivity, etc. at some point and without a UART console we would be flying blind. A standard CP2102, FTDI, etc. will work well. Measurement / Test setup On a clean Debian 12 (bookworm) arm64 Lite image, the /boot/firmware/cmdline.txt file was modified to include init=/init.sh. This means that the kernel will execute the script at /init.sh as the very first thing in userspace (before running systemd or anything else). Such an init.sh script might look like this: #!/bin/bash gpioset 0 4=0 sleep 1 gpioset 0 4=1 sleep 1 gpioset 0 4=0 exec /sbin/init which will toggle the GPIO4 and then resume normal boot by replacing itself with /sbin/init (aka systemd). In this screenshot from Nordic’s Power Profiler software, you can see the current consumption of the Raspberry Pi (at 5V) while booting. After about 12 seconds, digital input 0 is going low, showing that our init.sh was executed. In doing so, a total charge of 1.90 coulomb (coulomb and ampere-seconds are equivalent) was used. Calculating 1.9As * 5.0V comes out to 9.5Ws energy usage for this boot process. For reference: A single AA-alkaline battery can deliver about 13500 Ws of energy. Reducing current Let’s get the easy part out of the way first and reduce the operating current as much as possible. Disabling HDMI We can disable the HDMI encoder entirely. Disabling the GPU is not possible, because we need it to encode our camera data. If your application doesn’t require camera/GPU support, try disabling the GPU entirely. This reduces the current consumption from 136.7mA down to 122.6mA (over 10%!). Relevant config.txt parameters: # disable HDMI (saves power) dtoverlay=vc4-kms-v3d,nohdmi max_framebuffers=1 disable_fw_kms_setup=1 disable_overscan=1 # disable composite video output enable_tvout=0 Disabling Activity LED Just by disabling the activity LED, we can save 2mA (122.6mA down to 120.6mA). dtparam=act_led_trigger=none dtparam=act_led_activelow=on Disabling Camera LED Repeat the same for the camera LED (if present). It will also reduce the chance of the LED reflecting back into the image. disable_camera_led=1 Turbo tweaking As mentioned before, saving current while wasting time might not be ideal. With our current changes, the Pi can boot while using 1.62As. force_turbo=0 initial_turbo=10 arm_boost=0 Without forced turbo mode, 1.58As were used: For some, unknown reason, disabling the turbo/boost mode also inverts the default state of GPIO4 (thus I’ve switched the polarity in init.sh). Reducing time The ~13% reduction in current is helpful, but there’s still a long way to go. The Pi takes 8s (while consuming ~1As) before the first line of Linux output appears on the console. Luckily, there a number of ways to get more info about those 8 seconds. Debug boot In the boot process of the Raspberry Pi family, the GPU initializes first. It talks to the SD card and looks for a bootcode.bin file (Pi 4 and newer use an EEPROM instead). We can modify this bootcode.bin to enable detailed UART logging: sed -i -e \"s/BOOT_UART=0/BOOT_UART=1/\" /boot/firmware/bootcode.bin Backup the original bootcode.bin first, this process is potentially destructive. Rebooting with BOOT_UART enabled gives us loads of nice information: Raspberry Pi Bootcode Found SD card, config.txt = 1, start.elf = 1, recovery.elf = 0, timeout = 0 Read File: config.txt, 1322 (bytes) Raspberry Pi Bootcode Read File: config.txt, 1322 Read File: start.elf, 2981376 (bytes) Read File: fixup.dat, 7303 (bytes) MESS:00:00:01.295242:0: brfs: File read: /mfs/sd/config.txt MESS:00:00:01.300131:0: brfs: File read: 1322 bytes MESS:00:00:01.335680:0: HDMI0:EDID error reading EDID block 0 attempt 0 [..] MESS:00:00:01.392537:0: HDMI0:EDID error reading EDID block 0 attempt 9 MESS:00:00:01.398632:0: HDMI0:EDID giving up on reading EDID block 0 MESS:00:00:01.406335:0: brfs: File read: /mfs/sd/config.txt MESS:00:00:01.411272:0: gpioman: gpioman_get_pin_num: pin LEDS_PWR_OK not defined MESS:00:00:01.918176:0: gpioman: gpioman_get_pin_num: pin LEDS_PWR_OK not defined MESS:00:00:01.923999:0: *** Restart logging MESS:00:00:01.927872:0: brfs: File read: 1322 bytes MESS:00:00:01.933328:0: hdmi: HDMI0:EDID error reading EDID block 0 attempt 0 [..] MESS:00:00:01.995436:0: hdmi: HDMI0:EDID error reading EDID block 0 attempt 9 MESS:00:00:02.002052:0: hdmi: HDMI0:EDID giving up on reading EDID block 0 MESS:00:00:02.007955:0: hdmi: HDMI0:EDID error reading EDID block 0 attempt 0 [..] MESS:00:00:02.070610:0: hdmi: HDMI0:EDID error reading EDID block 0 attempt 9 MESS:00:00:02.077225:0: hdmi: HDMI0:EDID giving up on reading EDID block 0 MESS:00:00:02.082840:0: hdmi: HDMI:hdmi_get_state is deprecated, use hdmi_get_display_state instead MESS:00:00:02.091586:0: HDMI0: hdmi_pixel_encoding: 162000000 MESS:00:00:02.799203:0: brfs: File read: /mfs/sd/initramfs8 MESS:00:00:02.803082:0: Loaded 'initramfs8' to 0x0 size 0xb0898e MESS:00:00:02.821799:0: initramfs loaded to 0x1b4e7000 (size 0xb0898e) MESS:00:00:02.836318:0: dtb_file 'bcm2710-rpi-zero-2-w.dtb' MESS:00:00:02.840194:0: brfs: File read: 11569550 bytes MESS:00:00:02.849171:0: brfs: File read: /mfs/sd/bcm2710-rpi-zero-2-w.dtb MESS:00:00:02.854262:0: Loaded 'bcm2710-rpi-zero-2-w.dtb' to 0x100 size 0x8258 MESS:00:00:02.876038:0: brfs: File read: 33368 bytes MESS:00:00:02.892755:0: brfs: File read: /mfs/sd/overlays/overlay_map.dtb MESS:00:00:02.927145:0: brfs: File read: 5255 bytes MESS:00:00:02.933541:0: brfs: File read: /mfs/sd/config.txt MESS:00:00:02.937568:0: dtparam: audio=on MESS:00:00:02.948005:0: brfs: File read: 1322 bytes MESS:00:00:02.971952:0: brfs: File read: /mfs/sd/overlays/vc4-kms-v3d.dtbo MESS:00:00:03.023016:0: Loaded overlay 'vc4-kms-v3d' MESS:00:00:03.026278:0: dtparam: nohdmi=true MESS:00:00:03.031105:0: dtparam: act_led_trigger=none MESS:00:00:03.048180:0: dtparam: act_led_activelow=on MESS:00:00:03.149316:0: brfs: File read: 2760 bytes MESS:00:00:03.154502:0: brfs: File read: /mfs/sd/cmdline.txt MESS:00:00:03.158504:0: Read command line from file 'cmdline.txt': MESS:00:00:03.164369:0: 'console=serial0,115200 console=tty1 root=PARTUUID=26bbce6b-02 rootfstype=ext4 fsck.repair=yes rootwait cfg80211.ieee80211_regdom=DE init=/init.sh' MESS:00:00:03.195926:0: gpioman: gpioman_get_pin_num: pin EMMC_ENABLE not defined MESS:00:00:03.269361:0: brfs: File read: 146 bytes MESS:00:00:03.812401:0: brfs: File read: /mfs/sd/kernel8.img MESS:00:00:03.816343:0: Loaded 'kernel8.img' to 0x200000 size 0x8d8bd7 MESS:00:00:05.364579:0: Device tree loaded to 0x1b4de900 (size 0x8605) MESS:00:00:05.370571:0: uart: Set PL011 baud rate to 103448.300000 Hz MESS:00:00:05.377080:0: uart: Baud rate change done... MESS:00:00:05.380495:0: uart: Baud rate[ 0.000000] Booting Linux on physical CPU 0x0000000000 [0x410fd034] Disabling HDMI probing The bootloader spends a lot of time trying to auto-detect video parameters for a possibly attached HDMI monitor. We don’t have HDMI (it’s disabled anyway, remember?), so it doesn’t make much sense to wait for an I2C response with EDID (resolution, frame rate, etc.) information. By simply hardcoding an EDID string, we can disable any probing: # don't try to read HDMI eeprom hdmi_blanking=2 hdmi_ignore_edid=0xa5000080 hdmi_ignore_cec_init=1 hdmi_ignore_cec=1 Disable HAT, PoE and LCD probing The boot process will additionally try to detect I2C EEPROMs on HATs, will try to detect a PoE hat (which needs a fan) and some other things. We can safely disable those: # all these options cause a wait for an I2C bus response, we don't need any of them, so let's disable them. force_eeprom_read=0 disable_poe_fan=1 ignore_lcd=1 disable_touchscreen=1 disable_fw_kms_setup=1 Disable camera & display probing Probing for an attached MIPI camera or display will also take some time. We know which camera is attached (HQ Camera, IMX477 in this case), so let’s hardcode this: # no autodetection for anything (will wait for I2C answers) camera_auto_detect=0 display_auto_detect=0 # load HQ camera IMX477 sensor manually dtoverlay=imx477 Disabling initramfs The above changes brought the (self reported) boot time from 5.38s down to 4.75s. We can disable the initramfs entirely by removing auto_initramfs=1. Savings depend on the size of the initramfs of course, but this brings us down to 4.47s. Tested, with no significant difference Overclocking the SD peripheral to 100 MHz is often recommended online but did not create a measurable difference in boot performance. # not recommended! data corruption risk! dtoverlay=sdtweak,overclock_50=100 Operating the SD peripheral at such high speeds also risks data corruption (on write accesses), which is very undesirable in remote IoT devices. Kernel load At this point, loading the kernel is one of the slowest operations: MESS:00:00:03.816343:0: Loaded 'kernel8.img' to 0x200000 size 0x8d8bd7 MESS:00:00:05.364579:0: Device tree loaded to 0x1b4de900 (size 0x8605) Loading 9276375 Bytes takes about 1.54s -> about 6 MiB/s transfer speed. This load is being done by the GPU (!) with the internal, proprietary VideoCoreIV processor. It’s possible that the loader code is just inefficient and slow, it’s also possible that it is using very conservative settings. Sadly, it’s a black box and we can’t touch registers or mess with the parameters in any other useful way. I haven’t found a good way to optimize this yet, so a smaller kernel is needed. Overclocking the GPU processor core is theoretically possible with # Overclock GPU VideoCore IV processor (not recommended!) core_freq_min=500 core_freq=550 which does lead to a 20% reduction in kernel load time. The side effects (reliability, etc.) of this are unknown. Buildroot / Custom kernel It’s time to migrate the system from Raspbian/Debian to a custom built Buildroot distro (especially to get the custom kernel). Using buildroot 2024.02.1, a very stripped down system was configured. Native aarch64 toolchain, still with full glibc and the Raspberry Pi userland tools (like camera utilities). The kernel was configured: without sound support without most of the block device & filesystem drivers (except SD/MMC and ext4) without RAID support without USB support without HID support without DVB support without video & framebuffer support (HDMI is disabled anyway) without advanced networking features (tunnels, bridging, firewalling, etc.) uncompressed (not Gzip) modules uncompressed (not Gzip) In testing, having both the kernel and the modules uncompressed results in a net-positive energy result (even if more time is spent in the GPU loading the kernel). Decompressing Gzip takes a lot of energy (and effectively involves another relocation step). A security feature called KASLR was also disabled. KASLR randomizes the load address of the kernel in memory, making it harder to write exploit code (because the memory location of the kernel is unknown). This requires the kernel to be re-located after it has been loaded by the GPU. In our usecase, the network attack surface is very limited, so KASLR can be disabled (all application software runs as root anyway). Mitigations for speculative execution vulnurabilies like Spectre were also disabled. The resulting kernel is 8.5MiB (uncompressed) in size, 4.1MiB compressed as Gzip (which isn’t used here, just for comparison). The original Raspbian kernel was 25 MiB (uncompressed), 8.9 MiB compressed as Gzip. Final result We can now boot into a Linux user space program in less than 3.5s! ~400ms is spent in the Linux kernel (difference between pin 0 and pin 1) Total energy consumption: 0.364 As * 5.0 V = 1.82 Ws We reduced the energy required by a factor of 5 (compared to stock Debian at 9.5 Ws until user space). Reducing input voltage After publishing this blog post, Graham Sutherland / Polynomial pointed out that the regulators in the Pi Zero aren’t very efficient at 5.0V input. This might not be applicable in all situations, but in our test scenario and also finished product, we can just reduce the input voltage down to 4.0V. Running at 5.0V: Take good note of the units at play here. The mC (milli Coloumb / milli Ampere seconds) increase by switching to 4.0V (because of the higher current), but the total energy decreases significantly! 350.94mAs * 5.0V = 1.754 Ws Running at 4.0V: 390.77mAs * 4.0V = 1.563 Ws We can go down even further: Running at 3.6V: 399.60mAs * 3.6V = 1.438 Ws We just decreased the energy consumption by another 20%, just by operating the switch-mode-regulators at a more ideal operating point! This requires further testing for stability/reliability of course (as it’s technically out-of-spec), but this is a very impressive result. Links SolarCamPi config.txt: Complete config.txt SolarCamPi Linux kernel defconfig: Stripped down kernel config SolarCamPi-Buildroot (v2 branch): Full Buildroot tree (work-in-progress!) ←Previous Next→",
    "commentLink": "https://news.ycombinator.com/item?id=41420597",
    "commentBody": "Extreme Pi Boot Optimization (kittenlabs.de)472 points by todsacerdoti 21 hours agohidepastfavorite129 comments jakogut 4 hours agoYou can still save quite a bit by bundling your application in an initramfs linked into the kernel, which obviates the needs for any filesystem mounts in simple cases. In some cases, you can even replace something like BusyBox init with a simple bash script that does the bare minimum to boot your application. Mounting devtmpfs, proc, sysfs, etc. Dumping glibc is also worth exploring, if feasible. Chroot is a good tool to test your initramfs and see if all the necessary application dependencies are present before bundling it into the kernel. If you can run it in a chroot, the kernel can run it during boot, and the development loop is much tighter. Disabling kernel modules and enabling only the features needed linked into the kernel will save further space and boot time. It would also be helpful to test zstd compression instead of gzip. reply amluto 1 hour agoparentOn the flip side of this, if your kernel + initramfs is being loaded slowly (either the previous boot stage and is not using the hardware at its full capacity or the image is large enough that it would be better to do something else in parallel with loading the image), then having the smallest practical image that can load the remaining software after userspace starts can be faster. reply rubenbe 3 hours agoparentprevYou actually don't need a shell script to mount the different pseudo filesystems. You can do that in your application. So all that remains is an initramfs with a statically linked binary. reply jakogut 2 hours agorootparentVery true, you can call into the C library or use system calls directly and have your application do all the init itself. reply dgacmu 19 hours agoprevPower is really one of the weaknesses of the rpi family (I'm quite excited for the new pico 2 for exactly this reason - it seems like they're finally making it easy to enter a relatively deep sleep without external hardware). I built some cameras for an application like this using a Google Coral mini, whose camera is not nearly as good as the HQ cam, unfortunately, but it supports a built in suspend + wake from onboard RTC that is very easy to use and perfect for a periodic camera app - while still having enough oomph and 2GB of memory to handle a high resolution image. (You can physically hook an HQ camera up but the software pipeline doesn't exist to manage it on the coral AFAIK.) The Rpi ecosystem is a lot more mature and (sorry, friends) I trust the future availability of rpi more than I trust Google to keep delivering the coral line, but it really underscored how helpful good power support in the hw was. (Ironically, we ended up outsourcing the next version of these cameras to a firm that built them using an rpi and we just threw in a much larger battery to compensate. Which means I have a stack of 100 unopened coral dev minis + cameras looking for either good ideas or to sell to someone. Oops.) reply KeplerBoy 11 hours agoparentIsn't the Coral line already dead/discontinued? The site (coral.ai) seems to have been last updated in 2021 and it says Copyright 2020. Oh god, just searched for \"google coral twitter\" looking for an official twitter presence of the project and the second hit was a tweet of yours looking to sell your 100 excess boards. reply dgacmu 7 hours agorootparentI haven't seen anything official indicating it's discontinued, and they've released a few updated libraries, but there certainly seems to be very little momentum and I'm skeptical about its future. I think some friends have still bought the USB accelerator version of it to use with the frigate DVR, though. Not a good sign when offers to sell old ones feature prominently in the search results. :) It's a shame. They're actually really quite nice boards. I may have to sell them from the startup to my academic self and use them for some project or another if nobody wants them - but I don't really want to teach a machine vision course. reply michaelt 7 hours agorootparentprevWell, they haven't announced it's dead. In the electronics industry, even 30-year-old microcontrollers often have pin- and software-compatible replacements available to this day. So just because something has long been surpassed, doesn't mean it becomes unavailable. The electronics industry also has an orderly process for discontinuing parts, where customers are given advanced notice and a chance to place one last order if they want to stock up. This process hasn't been started for the Coral accelerators. With all that said - it's pretty clear that Google has lost interest in the product. When you're making hundreds of billions of dollars from ads, who's got the time for a product line that's bringing less than 0.1% of that? So personally I wouldn't base a new product on Coral today. reply Aherontas 4 hours agorootparentIt is really common for Google to delete projects out of the blue. So don't be surprised that they haven't much updates. reply shrubble 3 hours agoparentprevCurious if you have looked at the BeagleBone hardware with its PRU devices for low-power operation; they can stay awake while the system sleeps. reply cgearhart 18 hours agoparentprevInteresting, I’ve always run pis from wall power. Is the pi hardware incapable of similar power optimizations to coral, or is this a problem of a lack of software support for power management on pi? (I assume from your mention of external hardware to manage power that it’s not just a software issue.) reply michaelt 7 hours agorootparentA typical battery-powered IoT device like the Ring video doorbell will last ~2 months on a ~6000mAh ~3.3v battery. An average power draw of about 14 milliwatts. This is quite low - a power LED can use more than 14 milliwatts. Of course some products have power consumption even lower than that, right down to the tens-of-microwatts level. Meanwhile a raspberry pi, when idle, consumes ~3 watts [1]. That's 200x more than the video doorbell. Getting the power consumption down requires (a) that your hardware draws very little power when it's in sleep mode, and (b) that it spends as much time as possible in that sleep mode. Hardware and software have to work together to achieve this, and the software changes can be extensive. [1] https://www.jeffgeerling.com/blog/2024/new-2gb-pi-5-has-33-s... reply rcxdude 9 hours agorootparentprevI'm pretty sure it's the hardware. The SOCs they use in the mainline pi products are generally targeted at applications which aren't battery powered, so they don't focus on fast sleep support and similar power optimisations (which make the system design much more complex). Unfortunately if you want that you generally need to go with phone SOCs which are generally incredibly NDA-bound, very hard to buy even if you're as big as the rpi company, and have short availability windows which runs counter to requirements of large parts of the SBC market segment. reply dgacmu 17 hours agorootparentprevI'm really mixing two things and wasn't very clear about it. The pico can kinda deep sleep but it requires an external wakeup trigger. It can't deep sleep from its own clock. Even so its deep sleep is pretty high power compared to most embedded chips. The zero (w) and zero 2 w don't have the equivalent of suspend-to-ram with a low sleep current. I'm not sure if that's a limitation of the SOC or the driver or both, but rpi was fairly clear it wasn't in the cards: https://github.com/raspberrypi/linux/issues/1281 reply brk 18 hours agoparentprevOut of curiosity what are you doing that can’t be done with an OTS camera these days? reply dgacmu 17 hours agorootparentDual cameras at 90deg to each other with lightweight onboard ml to decide capture / no capture + geotargeted higher frame rate captures for regions of interest. In a housing that can handle hard impacts from brush and off-road use (we take pictures of pasture). A lot of the video solutions have much worse image quality than a still camera operating at 1fps to 1/20 fps; you can stick a quite good camera on an rpi. It's quite likely we could COTS this but there was no interest from vendors when we wanted to start with 200 of them. So we went with a custom solution. (We are https://enriched.ag -- if you scroll down you can see our overly-heavy-metal but quite tough camera unit. Some day it will be injection molded instead...) reply brk 9 hours agorootparentI will contact you, I may be able to help with a better solution. This is something I do a lot of. reply dgacmu 7 hours agorootparentPlease do, I'd love to learn. We just completed a run of our latest version so we're a ways from thinking about a new design, but it would be helpful to know know what I should be thinking about for our roadmap. dave.andersen at Gmail is probably my easiest address. reply turblety 11 hours agoprevThe real tragedy is the proprietary bootcode.bin gpu code that is a blackbox and we don't have the source code for. How horrible that a tinkering/hobbies project has to have these hidden secret blackboxes that can't be modified. reply pandemic_region 9 hours agoparentI'm guessing that having the source of the bootcode available would allow for extreme tinkering to the point that RPI can no longer guarantee it functioning properly? Or maybe it has something to do with proprietary drivers loading? Curious as well what's in there that they need to keep it closed source. reply pta2002 9 hours agorootparentWell, you can already do extreme tinkering to the point that RPi can no longer guarantee it functioning properly :) IIRC it's just that the bootcode.bin file is provided by Broadcom, and not the RPi foundation, so they can't open source it because they don't have the license to do so (this isn't the only proprietary blob in the default Pi distribution, but most of the other ones have open source alternatives/aren't that necessary/are open source now that they use the RP1 chip instead of broadcom peripherals). There's similar, slightly more open arrangements, with the Pi Pico W, where they can't provide the firmware for the Wifi chip, but they can provide a library to interface with it, with the caveat that the license _only_ allows for that library to be used with the RP* family of microcontrollers [1] [1]: https://github.com/georgerobotics/cyw43-driver/blob/faf36381... reply jonatron 9 hours agorootparentOther than broadcom licensing, I can guess that there's a warranty issue because the firmware controls the voltage. reply vbezhenar 8 hours agorootparentYou can kill Pi with a thousand ways. I don’t really understand how could a warranty work outside of obvious cases… reply hysan 18 hours agoprevTwo other good articles on decreasing Pi boot times are: - https://www.furkantokac.com/rpi3-fast-boot-less-than-2-secon... - http://himeshp.blogspot.com/2018/08/fast-boot-with-raspberry... I used these two to make a digital photo frame with a Pi that boots very quickly to a browser in kiosk mode. If you have very minimal requirements, you can get some very impressive boot times. reply LeonM 8 hours agoparentReading the first article it seems like OP could benefit from using start_cd.elf (3rd stage bootloader, but with the graphic subsystem removed), they report a 0.5s improvement in loading time reply rvdca 12 hours agoparentprevThabks for the link ! Got the code accessible for this kiosk picture frame by any chance ? reply rcarmo 12 hours agoprevImpressive. But every time I read one of these pieces I remember when I recorded Plan 9 booting on a Pi Zero: https://taoofmac.com/space/blog/2020/09/02/1900#resurrecting (GIF is real time output). reply throw10920 15 hours agoprevI like the article as a whole, but I'm unsure about this point: > For example: Disabling CPU turbo just to save some current consumption is a bad choice, because the resulting extra time will use more energy than just getting the job done quickly and shutting off. In one of my computer engineering classes, I learned that power consumption rises as the square of clock frequency - so doubling the clock will quadruple the power. That seems like it'd imply that you'd actually have to measure the power difference to determine if the quadratic increase from the clock boost will outweigh the product of the constant power consumption with the additional time spent on the task. Related - it'd be nice if the Pi's CPUs included granular power consumption information, either derivable from the datasheet, or as real-time values exposed in registers. reply MobiusHorizons 4 hours agoparentThis is a well understood power optimization strategy called race to idle. It works because there are a lot of periferals taking power in addition to the cpu that you can’t switch off until the cpu is done. There is also definitely a sweet spot. If you overclock the cpu too much your performance per watt drops too far and race to idle won’t work anymore. reply daalex 13 hours agoparentprev> In one of my computer engineering classes, I learned that power consumption rises as the square of clock frequency - so doubling the clock will quadruple the power. This is not quite correct. Switching power of a chip (ignoring static leakage) is proportional to voltage squared times frequency. Most chips require a higher voltage to reach higher clock speeds, so there is a quadratic relationship there. However, I believe that the raspberry pi does not have dynamic voltage control, so reducing clock speed without also reducing voltage will not effect total switching energy consumption. reply heavypixels 9 hours agoparentprevFor a continuous workload that's a reasonable rule of thumb, but it doesn't tell the whole story. You always have a certain static power draw, just from having a component enabled. So modern embedded systems will often use a \"race-to-sleep\" or \"race-to-halt\" strategy where they will execute tasks really quickly, before shutting down most of their components waiting for the next event to trigger. reply Salgat 14 hours agoparentprevThere's a base amount of power overhead the device will use no matter what, even if it does nothing. They even provide benchmarks that show that current consumption for turbo increases 10% but reduces boot time by 11%, for a small but measurable difference in total energy used. reply mortenlarsen 12 hours agorootparentWhat about the internal resistance of the battery? Doesn't that increase with higher current? As in 1A for 2 seconds uses less actual battery power than 2A for 1 second due to internal loss in the battery? I may be remembering this wrong, It has been a long time since I studied this stuff. reply hinkley 3 hours agorootparentThat’s true when you’ve saturated all of those subsystems but not when you’re just CPU bound. If you’re doing high throughput from disk to memory to CPU and back to disk, there are levels of use where throttling IO helps with battery draw. There are old papers on the subject, and I have a suspicion that OS X started doing something of the sort when they went to nonremovable batteries in the MacBook. There’s a 30% reduction in power draw in that generation that they brag about but don’t really explain, and it was a handful of years after that first paper showed up. reply naming_the_user 15 hours agoparentprevThis is very interesting, thanks for sharing! So if it takes 1J to do some computation in 1 second (say 1GHz at 1W), you're saying that in the perfectly spherical cow case, it takes 2J to do that same computation in 0.5 seconds (2GHz at 4W). However, that's just CPU consumption, if the overall system has a static rate of 4W, then it takes 5J (1J CPU, 4J system) at 1Ghz to do the task in a second, or 4J (2J CPU, 2J system) at 2GHz to do the task in 0.5 seconds. Am I understanding you correctly? Basically, if the overall system's power consumption is similar to the CPU's power consumption at turbo, then it makes sense to turbo, if not, it doesn't? reply bjackman 8 hours agorootparentI think you have it right but also my experience from optimising Android power usage was: your your intuitions are helpful for knowing what to try, but you have to test and measure everything as there are always complications. Luckily you are well equipped to benchmark it already :) reply throw10920 14 hours agorootparentprevYes, this is all correct, as long as you're implicitly assuming that the CPU itself has some static power dissipation as well (which it does) in addition to the rest of the system. Unfortunately I missed the actual benchmarks in the article that empirically measured the power difference. reply Avamander 20 hours agoprevIMHO boot times of Linux distros in general are rather sad, which is then significantly amplified on weak(er) hardware such as this. I've gone through similar efforts with the MQ-Pro SBC. One can also really feel this on laptops (except Macbooks I guess). Annoying. reply lionkor 20 hours agoparentIt very much depends what you define as \"boot time\". For example, Windows optimizes for time to fist UI, meanwhile everything else continues to load and the PC stays unusable for multiple seconds after \"boot\". reply kiwijamo 19 hours agorootparentThis is frequently due to startup apps, not Windows itself. I generally find when I disable stuff like Steam, Teams, Creative Cloud, OEM (e.g. HP) software, etc Windows is usable as soon as I log on. My work Windows laptop has most startup apps disabled (with the exception of OneDrive and Teams which I use frequently enough that it makes sense for it to be enabled on my work laptop) and I log on to a desktop ready to go. My personal laptop has everything except OneDrive disabled. YMMV and I acknowledge the default settings of letting apps insert themselves as Startup apps without user approval is not ideal. I note this is also an issue on MacOS from experience at my previous employer who issued me a Macbook which was configured as per corporate policy to have various apps including anti virus and the like loading on login to desktop. Only platforms that is so far immune to this is open source distros like Debian (using GNOME, its default desktop environment) et al but I've yet to work for an employer that uses Linux. reply gerdesj 19 hours agorootparentprev\"Windows optimizes for time to fist UI,\" I'm going to apologise right now for giggling at your typo. Microsoft have done some horrible things to UI. The start menu - yes they created the fucking thing, yes it is now called start by everyone - own it (think Biro and co and stop being dicks) and it belongs at the left hand side. \"We\" know better than you, lets put it in the middle and surround it with weird shit and lets make it odd and put fucking games controllers on a corporate laptop and other wankery that we can't be bothered to curate because we are so poor but if you love our weather forecasts and shitty ... whomever will pay us .. whatever thing. I think that Microsoft have lost interest in humanity as anything than a pool of subscription slaves to contribute to their bottom line. That is some pretty aggressive fisting. reply pbhjpbhj 18 hours agorootparentThe principal menu is still bottom left doing what they clearly see as most important thing in the OS, advertising shit and feeding you heavily politicised propaganda. So useful! reply nox101 19 hours agorootparentprevMy Windows box starts fast, gets to login in moments, and is usable immediately. Are you sure you don't have a bunch of extra software set to run at startup? Steam? Adobe Creative Cloud? Oculus Support? My corp Mac actually has this issue as it launches some security software, launches the browser, checks that apps are up to date and security patches are applied etc. It takes several seconds (10-20?) before it's ready to use. reply genewitch 19 hours agorootparentprevyou all reboot windows? madness. I got devuan down to about 8 seconds from startup -> login -> shutdown on the tty. Gentoo boots pretty fast to a desktop (maybe 15-20 seconds) - a lot of the slowdown on \"modern\" linux is systemd waiting for NICs and whatever to quiesce. Hilariously, Ubuntu is by far the worst at boot times, i've had ubuntu sit there for minutes because it was airgapped. I kinda lost interest in attempting to speed up boots more than that, maybe if i had some funding i could get debian or gentoo down to a couple of seconds of boot overhead before X/wayland/whatever runs. reply kiwijamo 19 hours agorootparentWindows is pretty fast nowdays on modern hardware (especially if it's booting off an SSD drive) and Debian/GNOME is also pretty fast to a desktop as well. Slow boots off a SSD drive would point at an issue somewhere regardless of your OS. I generally do shutdown on my gaming tower PC as the idle power usage isn't great and shutdown/boot is fast enough that it's not much difference compared to suspend. Laptops though I just suspend -- I often get weeks of uptime in Windows. reply genewitch 18 hours agorootparentI almost want to test this out - shut down my PC, unplug it, hit the power button, wait like 15 minutes, then turn it back on. Will it still be \"pretty fast\"? My (probably wrong) understanding was windows boot times are so fast because it's really just hibernating when you shut down. I'm sure there's technical names for the power state (S0?) - but ram is kept \"warm\" so that resume basically just needs to check that all the devices it needs are connected and reset the software clock. I'm currently showing 50.6GB \"in use\" and 62GB commit on my windows machine. My boot drive is an intel SSD on sata, less than a GB/second - this implies if windows does recover memory from disk on \"cold\" boot my machine will take about a minute to restore RAM. i may be conflating things, but i've lived with this assumption that shutting down my PC is merely hibernating it, and as such, i always pull mains power before removing hardware. reply Filligree 16 hours agorootparentIf you see the BIOS screen, then it isn't suspended. It could still be suspend-to-disk, but desktop PCs don't do that. Windows 'fast boot' does work by saving some critical state on shutdown, but it's still a complete shutdown. reply formerly_proven 8 hours agorootparentprev> Windows is pretty fast nowdays on modern hardware This feels the wrong way around. Windows development just stagnated for about a decade while hardware made huge leaps, so hardware speed increased much faster than Windows became slower. Therefore, \"Windows is pretty fast nowadays on modern hardware\". I remember Windows XP being able to boot from a hard drive without the progress bar making two full revolutions (so, like, 3-4 seconds?). Windows 7 managed to do something similar (finish booting before the animated Windows logo has fully \"bloomed\"), but already required an SSD and a multi-GHz multi-core processor to do so. Windows 10 does a few spinny spins, but uses a CPU that's another integer multiple faster and an NVMe SSD delivering hundreds of thousands of IOPS and gigabytes per second of bandwidth. reply layoric 20 hours agorootparentprevExactly my experience as well. I moved away from Windows (10) earlier this year, and login times (waiting for the user desktop to come up after putting in credentials) took ~10 seconds. Sometimes it was faster after a fresh install, but it never lasted, even when regularly managing what services and apps were loaded on startup. reply NavinF 14 hours agorootparentprevWhen I reboot my Windows PC every 3 months or so, I can start using it as soon as the desktop shows up. No slowdown. I have 5800x3d/64GB/2TB/4090. I don't have any startup apps other than the ones that come built-in with enterprise edition. Why do you have such a different experience? reply yjftsjthsd-h 12 hours agorootparent> Why do you have such a different experience? Well... > I don't have any startup apps other than the ones that come built-in with enterprise edition. There is the matter where 99% of people aren't on enterprise, and of the 1% who are, virtually all are running it laden with a pile of corporate garbage. reply baq 5 minutes agorootparentI'm pretty sure crowdstrike and its competitors can slow down any computer regardless of the OS to the point of uselessness. reply NavinF 11 hours agorootparentprevGuy goes into the doctor's office. Says, \"Doctor, it hurts when I do this. \" You know what the doctor says? \"Don't do that\" Seriously tho, anyone can activate enterprise edition with MAS. And even if you're on home edition, why would it take longer to boot up? All the crap is on your SSD, not your RAM reply Avamander 11 hours agorootparentprevI consider boot time from power off until I can start the first application I want. But I am a bit strict about what I consider slow on modern hardware though. Why should a regular desktop distro wait around five seconds for networking and NTP before displaying login, or why should it take UEFI 5s to start the OS. I can forgive SBCs running off an SD card taking 15-30 seconds to boot, but not a PC that's significantly faster in all other aspects. I'm not even going to start with all the crap that starts on an average Windows desktop. It's disgusting. reply pandemic_region 9 hours agorootparentprevsorry man but that typo had me lol, early mornings here I do apologize. reply nox101 19 hours agoparentprev> except Macbooks I guess??? My M1 MacBook takes an order of magnitude longer to start than my Windows Desktop PC. Once it's started up, leaving it on re-logging in takes no time but rebooting takes a while. reply Pesthuf 17 hours agorootparentIt really is a shame. When Mac OS X first implemented launchd, its boot times improved drastically. It booted really fast even when computers still using hdds. So when Macs got SSDs, they booted incredibly quickly. But then, with some macOS update, they screwed it up and never bothered to fix it. Imagine how fast those things could boot with their super fast drives and SOCs if someone fixed this regression… reply rafram 19 hours agorootparentprevThere’s something wrong with your M1 MacBook. I’ve used three and none of them has taken longer than 20-30 seconds from power button to desktop. reply nox101 18 hours agorootparent20-30 seconds is much longer than the ~6 seconds for my Windows PC. Old article but: https://www.tomshardware.com/reviews/fastest-windows-10-boot... reply rafram 7 hours agorootparentIMO having Windows Fast Boot enabled is cheating. reply sigseg1v 2 hours agorootparentprev20-30s seems extremely slow but I'm not normally using a Mac. Anecdotally on Linux and Windows systems I commonly see 6-10 seconds on a hard reset with absolutely no optimizations reply callalex 1 hour agorootparentIt takes a while to verify all the signatures in every chip to make sure you didn’t do something evil like repair your own hardware. reply PhilipRoman 11 hours agoparentprevI'm not sure how much distros can do here, the userspace part of boot time is negligible (unless there is some horrible misconfiguration, like networkmanager waiting 90 seconds for nonexistent wifi...). My linux box takes about 4 seconds until graphical.target, most of which is connecting to wifi and ntpd, both of which are optional in principle. If you really want a fast boot, ditch all the bootloader compatibility layers, abstractions and dynamic configuration possibilities like initramfs. But then you would be at the mercy of the hardware vendor, which is definitely not worth it. reply Avamander 11 hours agorootparent> My linux box takes about 4 seconds until graphical.target, most of which is connecting to wifi and ntpd, both of which are optional in principle. But why should a login screen wait behind networking target for example? That ordering is up to the distributions. > If you really want a fast boot, ditch all the bootloader compatibility layers, abstractions and dynamic configuration possibilities like initramfs. But then you would be at the mercy of the hardware vendor, which is definitely not worth it. You'd expect that would be the case with SBCs, most if not all do overlays instead of ACPI. Very few also offer UEFI, so there isn't a slow(er) layer there either, but you are at the mercy of the vendor. reply PhilipRoman 9 hours agorootparentLogin screen doesn't wait for graphical.target, its the other way around - display manager must be started for graphical.target to be complete. So in my case, ly-dm started 3 seconds into boot and it doesn't depend on anything significant. Either way, the broader point is that even if distros somehow managed to cut the time in half, thats still just 2 seconds compared to the massive time needed for firmware. The only thing that pops out is systemd-binfmt.service somehow taking almost 1 second, which is strange since AFAIK it just echoes some strings into /proc file. There is still some room for optimization by mounting external drives asynchronously but that's not a safe optimization to make for general use. reply nextos 18 hours agoparentprevI'm confused by this statement. For me Linux boot is incredibly fast, even on old machines with slow storage. For example, my MacBook Air 11 (running Linux) boots to login so fast I barely see any boot logs. systemd-analyze reports the graphical target is reached inTwo things seem to be key here. I don't use a desktop environment. I either boot in text mode (and then startx as needed), or I boot to X with a lightweight login manager (lightdm). > I'm confused by this statement. Should you be confused? reply deivid 12 hours agoparentprevLinux can boot quite quickly with the right settings, I've written about it at [0], but distros (reasonably) build very generic kernels and initramfs, which are not particularly fast to boot [0]: https://blog.davidv.dev/posts/minimizing-linux-boot-times/ reply markus_zhang 19 hours agoprevMy first instinct: can we use some other core? Do we really need Linux to take a photo and transfer it to the cloud? I'm not a hw person so curious how to complete the task with minimum budget. Interesting read. Thank you! reply bigiain 18 hours agoparentMy same first thought. For no reason other than I have a pair of them sitting on my kitchen table right now, I wondered how the ESP32-CAM setup would compare. I think it's only good for 2megapixel images, But I'd bet both its startup time and its power consumption would be close to an order of magnitude lower. (Here's some details if you're curious: https://components101.com/modules/esp32-cam-camera-module ) reply tetris11 6 hours agorootparentI'm always a little perplexed by the world of microcontrollers. How would you program this without having some kind of embedded linux? And where does the OS live in this modules? Or does this sit on a Pi? reply markus_zhang 4 hours agorootparentIn many cases there is no OS, just bare metal. I have dabbed into embedded programming (but never really into hardware) briefly and the process looks like this: you manipulate some pins and they make things work. You read manuals to figure out which pins to use and how to manipulate them to make certain things happen. For example, to make a peripheral work, you first need to connect certain pins (following the manual), then you need to send some black magic signals to these pins to make it work in certain ways (think ROM reading/writing, LCD screen display, etc.). Reading the manual and the data sheets, IMO, is where the real complexity comes from -- and you can always use \"Standard\" components and use a library. Here is a good textbook: https://web.eece.maine.edu/~zhu/book/ If you need an OS sometimes a RTOS is considered instead of Linux. Embedded Linux is pretty \"heavy\" in the embedded world AFAIK. reply tetris11 4 hours agorootparentIn the context of the camera modules above, what would you wire the pins into? Surely a Pi, running Linux? reply grishka 17 hours agoparentprevThe problem is that this particular project uses camera and wireless networking, both requiring very non-trivial drivers. It is possible, in principle, to do it on bare metal, but getting the required peripherals working won't be easy. reply hypercube33 17 hours agorootparentESP is a platform that has both though - wireless and camera on the esp32. Those can quick resume out of a low power sleep and connect to Wi-Fi and dump a picture or a series of pictures - I don't know what's more efficient. reply NavinF 14 hours agorootparentAre you talking about the 2MP ESP32-CAM modules? Those things are an order of magnitude worse when it comes to fps and perceptual image quality vs Arducam's offerings for the RPi. Also all sorts of specialized hardware like depth sensing cameras work out of the box with the RPi. ESP32 can do both wifi and cameras in the same sense that I can run back to back marathons. I just gotta take a couple of naps at hotels along the way. reply m00x 11 hours agorootparentYou can connect the esp32 to a proper camera, you don't just have to use the development board for it. If you're just taking a picture and uploading it via wifi, you're better off doing it bare metal. It can do everything stated in OP's post. MIPI support isn't available until ESP-P4 though. reply kfarr 15 hours agorootparentprevOr Pi Pico W, I've used that on a few projects. Nearly instant boot reply luma 6 hours agorootparentprevI'm not sure if you've worked with embedded but everything you just described shows up for free when you compile your first hello world with the platform SDK. All trivial, solved problems. Take a look at nearly any consumer camera and note that it isn't running linux, or anything like linux. There's a reason RPi isn't used to build actual consumer products. It's a neat toy for tinkering, handy around the shop and home for a bunch of purposes, but it's also making all the wrong tradeoffs for something you can deploy and support at scale. Nothing in the OP use case requires linux, you can do everything cheaper, faster, and FAR more efficiently on an ESP32 or similar. reply exabrial 2 hours agoprevOk decreasing the regulator voltage was a real surprise! I thought switching regulators would be far more efficient at higher voltages! (Less current = less heat) reply arendtio 14 hours agoprevI wondered why a custom kernel came so late. If you want to optimize, wouldn't you start with LFS or some source-based distribution? Autonomous software updates don't seem to be a necessity anyway on such a device. In addition, I wonder if it would be possible to optimize the EFI/BIOS on such a device. At least on my standard Arch Linux desktop, it takes a significant amount of boot time: $ systemd-analyze Startup finished in 10.076s (firmware) + 1.339s (loader) + 1.569s (kernel) + 2.974s (initrd) + 3.894s (userspace) = 19.854s reply daalex 13 hours agoparent> I wondered why a custom kernel came so late. If you want to optimize, wouldn't you start with LFS or some source-based distribution? Autonomous software updates don't seem to be a necessity anyway on such a device. Buildroot (which they used) is made exactly for this. With buildroot, you configure your own \"Distribution\" and generate a single bootable image from it. > In addition, I wonder if it would be possible to optimize the EFI/BIOS on such a device. At least on my standard Arch Linux desktop, it takes a significant amount of boot time: Not exactly sure about raspberry pi hardware, but a lot of other embedded SoCs have a pretty minimal bootloader that runs with u-boot, which is typically very fast (at least if you set the delay it waits for user input to 0) reply creatonez 10 hours agoparentprev> wouldn't you start with LFS or some source-based distribution You don't ever want to actually use LFS (the manual from the LFS project) in the real world as compiling GNU is far too much work. A minimalistic kernel + busybox system is much less pain. But Gentoo would not be a bad option too. reply tetris11 6 hours agoparentprevchrist, you've just shown me that I need to optimize my boot loader (systemd-boot), and how great apparently my firmware is. > systemd-analyze Startup finished in 3.259s (firmware) + 35.127s (loader) + 1.823s (kernel) + 2.927s (userspace) = 43.138s reply jtrueb 20 hours agoprevJust stay booted and use a lower power microcontroller … 105mA … that’s not the right order of magnitude reply declan_roberts 15 hours agoparentEvery single person is reading this with a voice in their head asking \"why not use an esp32 et al?\" But of course the article is good enough because it's interesting, even if it's not the right tool for the job. reply award_ 17 hours agoparentprevI don't understand what this means exactly, could you please elaborate? reply jtrueb 16 hours agorootparentI’m sure there are others, but as mentioned elsewhere in this thread ESP32 or NRF70 could take care of this for a lot less (off of bare metal or RTOS if you just need WiFi and Camera.) reply m00x 11 hours agorootparentA good reason would be the lack of support for MIPI for the camera. reply merpkz 12 hours agoprevWhy did I always had impression that decompressing data is much faster than reading inflated data off disk? Like, if you need to read just 5MB and decompress it would take less time than just to read 10MB off a disk, for example, but this article kinda states the otherwise. reply olex 12 hours agoparentThe article states a \"net-positive energy result\", not necessarily a faster time for this specific optimization. They say GZIP decompression is energy-intensive, so while the combination of read + decompress may be faster, the CPU load during decompression and memory relocation of the decompressed data ultimately consumes more energy than reading an uncompressed kernel and running it directly. reply saagarjha 11 hours agoparentprevThis is actually something that flip-flops across hardware generations and platforms. Hard drives used to be really slow and consumer machines would often reduce data bandwidth by compressing things because processors were “faster” than disk. But today’s SSDs are actually really fast, sometimes so fast that CPUs can barely keep up just processing the data coming off of them, so the balance can also shift in the opposite direction. And in embedded your storage might be slow but you may not have the processing power to spare decompressing. Or maybe you do and it saves on flash write cycles. This is a complicated topic! reply erinaceousjones 12 hours agoparentprevMight've been the case with \"spinning rust\" (hard drives) but solid state storage can have lower access and read times -- no need to wait for a disk to spin up or move read heads to the right position on a platter etc reply kfarr 15 hours agoprevIf you like Rasp Pi ecosystem you might want to try the Pi Pico W, it's similar in spirit to microcontrollers like ESP32 but allows you to use micropython and has a neat set of peripherals that work \"out of the box\": https://shop.pimoroni.com/products/raspberry-pi-pico-w?varia... reply zelo 9 hours agoparentmicropython supports esp32 too reply nyanpasu64 20 hours agoprevI was thinking that Circle (https://github.com/rsta2/circle) might be faster to boot than a kernel, but it doesn't seem to support MIPI cameras. reply abraae 21 hours agoprevVery impressive. I've toyed with using the Pi for an intelligent trail camera. Startup time is critical - a PIR sensor detects an animal passing and you want to be taking photos ASAP so every second counts. Lowering the power usage is awesome too. reply tuatoru 3 hours agoparentJust use a purpose-built trail cam. Sub-second response, optics optimised for trail conditions, weatherproof, robust, durable, long battery life, designed to be secured to trees. There's a bit of engineering in a reliable trail cam. (Don't buy no-name Chinese.) reply abraae 33 minutes agorootparentI already have a couple of Bushnells. My desire is to be able to attach a small network of PIR sensors to each camera get better information. reply ocean_moist 20 hours agoprevI wonder if booting the OpenBSD kernel would be faster. Although, the OpenBSD init system is notoriously slow. Also I feel (but don't know for sure) most of the time before executing the user space program would be spent by systemd. reply jmclnx 20 hours agoparent>Although, the OpenBSD init system is notoriously slow. Is this on the PI where it is slow. On my T420 it seems fine, but the re-linking of various daemons does add time. But that is done for security so I am fine to live with it. Me, I want fast power down time so I can get out the door fast. And so far NetBSD, OpenBSD and Linux seems to meets that need :) reply hamburglar 18 hours agoparentprevDon’t these types of systems generally just nuke init entirely and provide a custom PID 1 ? reply geerlingguy 19 hours agoprevSupposedly on the Pi 5, the SoC could be put to sleep while RP1 remains active, and the RP1 has enough compute to handle like 4 or 8 pixels of data from an attached camera... I think RPi might be able to get much better suspend support with their new PMIC and RP1. But so far still waiting to see something handy like Wake on LAN support native in Pi OS. reply dividuum 7 hours agoparent> Supposedly on the Pi 5, the SoC could be put to sleep while RP1 remains active [..] You mean \"echo +60 > /sys/class/rtc/rtc0/wakealarm && halt\"? reply sydd 10 hours agoprevEhm instead of spending like weeks on this why not use a hardware that is meant for such applications like an ESP32? reply stereo 13 hours agoprevIs the Pi connected to the network with a static IP? Getting a fresh one from DHCP can, in this context, take quite a bit of time and energy. reply willyt 5 hours agoprevAccording to the back of my jar of mayonnaise there is 8400kJ stored in it, enough energy to power this rpi for ~62 days. This is probably a stupid question but just out of curiosity, why do people express electrical energy in Watts per second or Watts per hour instead of Joules. Unless school physics has deserted me completely 1 Ws = 1J no? reply omikun 5 hours agoparentBecause no one talks about units of Ws. It's all Wh or kWh. Or they talk about power instead of energy. reply willyt 1 hour agorootparentWell you didn't read the article because the comparisons of the energy consumed are listed in Ws (Watt Seconds) e.g. > We can now boot into a Linux user space program in less than 3.5s! >~400ms is spent in the Linux kernel (difference between pin 0 and pin 1) >Total energy consumption: 0.364 As * 5.0 V = 1.82 Ws reply raggi 17 hours agoprevAssuming it stays up for about 10-15s this is a saving over staying idle of around 85%, based on the idle burn rate from toms hardware. Not bad at all! reply tuatoru 3 hours agoprevThree seconds? A purpose built trail cam is considered slow if it takes 0.7 seconds to boot up and take a picture. 0.15 s is the going rate these days. reply gigel82 20 hours agoprev3.5s is cool, but if the entire scenario was really connecting to WiFi and uploading an image every couple of minutes, an ESP32 would've been a much better choice for power consumption (unless the camera module you need for Pi has some specific features that none of the esp32-cam compatible cameras does) reply teamonkey 20 hours agoparentESP32 only supports up to 4MB of PSRAM while a single RPi HQ Camera still is 18MB. reply pitaj 19 hours agorootparentDoesn't the camera have it's own framebuffer that the MCU can stream? I don't see why the MCU would have to hold the whole frame in memory. reply j16sdiz 16 hours agorootparentThe library comes with ESP32 use DMA for image stream. Don't think you can workaround that, unless you write your own driver reply teamonkey 19 hours agorootparentprevAt least with ESP32-CAM api, the instruction to capture an image returns a pointer to image data in psram. I would imagine a Pi Zero is more efficient at converting that raw image data to some compressed file format too. reply m00x 11 hours agorootparentESP23-P4 will support up to 32mb in PSRAM, MIPI, and hardware h.264 encoding. It'll be a great chip for video. reply Neywiny 18 hours agoparentprevI might recommend a slightly higher end micro with a mipi csi interface but otherwise agree. This is so much work to do what microcontrollers can do almost effortlessly. reply Sarkie 20 hours agoprevWas expecting to see different governors tested. Is that not a thing on a pi? reply kiwijamo 19 hours agoparentI'm fairly sure this is, I recall playing with this when I first got my Raspi. reply hcfman 13 hours agoprevLovely project reply phoronixrly 20 hours agoprev [–] You really should look into using the right hardware for the purpose instead. (Disclamer - I despise Raspberry and their overpriced closed devices, and also HN maniacally trying to use them for stuff they the wrong choice for) reply nbf_1995 19 hours agoparentWhat sort of hardware would you recommend for this use case? reply nickelpro 16 hours agorootparentLiterally any ESP32 would be better suited. There is zero reason to be booting an entire OS to take a picture and blip it over WiFi. reply moefh 12 hours agorootparentESP32 is great, but it simply can't work with the IMX477 camera used in this project. This camera has resolution of 4072x3176, or about 12M pixels, which is way above what any ESP32 can handle. reply alfanick 8 hours agorootparentI can imagine following should be doable (with assumption that IMX477 has it's own buffer and doesn't DMA directly): 1) take a picture 2) read some lines 3) stream them via WiFi to some server 4) repeat 2-3 until whole picture is read 5) reconstruct the picture from slices on the server side reply teamonkey 44 minutes agorootparentThe sensor doesn’t have a framebuffer (because it’s just a sensor) and the RPi HQ cam is basically just a sensor on a board with some mipi connectors. You might be able to buy a package with an IMX477 sensor and some microcontroller/FPGA and frame buffer ram, but that would cost a lot more. reply megous 3 hours agorootparentprevA bunch of other SoC manufacturers have working system sleep implementation, either manufacturer supported or community supported. Never mind much faster boot options (like hundreds of ms to kernel). So you just need to pick one that also has whatever camera interface you need supported. Say any RK3399 based board can be made to boot to simple userspace in 1-2s and have working upstream camera MIPI-CSI drivers and ISP. System sleep is ~300mW so ~60mA@5V. Pick one with wifi onboard if you need that. And it's all opensource software, no binary crap that can't be optimized. reply megous 2 hours agoparentprev [–] But the \"community\"!!! :D reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The SolarCamPi project optimized the Raspberry Pi Zero 2 W boot time to 3.5 seconds to enhance energy efficiency in a solar-powered camera system.",
      "Key optimizations included disabling unnecessary hardware features, tweaking CPU settings, and using a custom stripped-down kernel.",
      "These changes resulted in a fivefold reduction in energy consumption, demonstrating significant improvements in both boot time and power efficiency."
    ],
    "commentSummary": [
      "Extreme Pi Boot Optimization involves bundling applications in an initramfs linked to the kernel, avoiding filesystem mounts, and potentially replacing BusyBox init with a simple bash script.",
      "Techniques discussed include disabling unnecessary kernel modules, using zstd compression, and testing with chroot to optimize boot times.",
      "The conversation highlights power consumption issues with Raspberry Pi hardware compared to alternatives like Google Coral and ESP32, emphasizing the need for efficient boot and power management strategies."
    ],
    "points": 472,
    "commentCount": 129,
    "retryCount": 0,
    "time": 1725226615
  },
  {
    "id": 41421846,
    "title": "OrbStack: The fast, light, and easy way to run Docker containers and Linux",
    "originLink": "https://orbstack.dev/",
    "originBody": "OrbStack PricingBlogDocs Download Open main menu New: Low memory usage Say goodbye to slow, clunky containers and VMs OrbStack is the fast, light, and easy way to run Docker containers and Linux. Develop at lightspeed with our Docker Desktop alternative. Get OrbStack Learn more Loved by developers at Fast, light, simple No more battery drain or complicated VMs. OrbStack respects your machine, with powerful capabilities. No compromises. Lightning fast Starts in seconds with turbocharged networking, smooth Rosetta x86 emulation, VirtioFS file sharing, and other optimizations for some workloads. Light as a feather Keep it breezy with low CPU and disk usage, minimal memory consumption, and a native Swift app. Battery drain is a thing of the past. Effortless integration Enjoy seamless containers, plus CLI integration, file sharing, and remote SSH editing with Linux machines. Unbelievably simple Drop-in replacement for Docker Desktop. Easily get started with Linux machines in 1 minute with the simple, yet powerful, app and command line. Endlessly capable Run containers, Kubernetes, and Linux distros all with robust integration. Manage containers & machines from anywhere with the menu bar app. Robust connectivity Connect between containers and machines, and use IPv6 painlessly. VPNs and DNS become friends, not foes. See the magic Embark on a seamless journey towards better development, within a matter of seconds. Containers like they’re native Build images quickly and enjoy fast, reliable networking and file sharing. Bind mounts and port forwards just work. Debug containers easily with access to volumes. Run x86 containers with Rosetta. Compose and other tools included. Linux machines without the fuss Run full-blown Linux machines with your favorite distro. Work seamlessly with Visual Studio Code (or your favorite editor) and SSH agent forwarding. Run Intel machines on Apple Silicon with Rosetta. First-class command line integration Live in the terminal? We think our native app is great, but everything can be done from the command line. Run commands and copy files between Mac and Linux with ease. Send notifications and open files and links from Linux. Light as a feather With less than 0.1% background CPU usage on Apple Silicon, OrbStack sips power and stays out of your way. Less than 10 MB of disk space is used out of the box. You’ll never notice it’s running. Feel the difference Skip the wait and leave your charger behind with OrbStack's unmatched performance and efficiency. Speed Open edX Build PostHog CPU & Battery Kubernetes CPU & Battery Supabase Time to provision development environment (lower is better) OrbStack17 min Docker Desktop45 min as of August 2023 Details Packed with helpful features No matter the use case, OrbStack has you covered with features that simplify your workflow and help you move faster. Instant startup Fast network Local domain names Seamless integration Linux machines Rosetta x86 emulation Optimized for Apple Silicon Low CPU usage Dynamic disk Native Swift app SSH agent forwarding File sharing 2-way CLI integration 15 Linux distros SSH Remote VS Code VPN-friendly IPv6 ICMP Ping Traceroute Low initial memory usage Accurate clock Works without admin Bind mounts Volume files on Mac Image files on Mac Host networking eBPF support Native UI Menu bar app Quick global actions Kubernetes See what people say Mark_Shust::learn.phtml @MarkShust I've deleted Docker Desktop from my machine. Because there's something that is 100x better called OrbStack 🔮 It's a drop in replacement which runs faster and eliminates the \"memory & cpu hog\" features of Docker Desktop. Download it at orbstack.dev Michael Roberts @michealjroberts I've recently switched from Docker Desktop to @OrbStack and the performance is absolutely game changing. Docker is now usable on a Mac. Hynek Schlawack @hynek This blows Docker, Colima & what have you completely out of the water. It’s a drop-in replacement for the docker backend & JUST WORKS. It feels faster, but most importantly the update works. Francesco Di Lorenzo @frankdilo If you work with Docker on an M1 Mac, do yourself a favor and install orbstack.dev Every operation feels 100x faster, and it should also have a lighter impact on the battery life of M1 Macs. ⚡🔋 Hat tip to @kandros5591 👏 Koen Bok @koenbok If you use Docker, you really want to check out OrbStack. It’s a beautiful lightweight replacement. orbstack.dev Sibelius Seraphini @sseraphini TIL @OrbStack made me like running docker again Mikael Henriksson @mhenrixon I seriously can't recommend @OrbStack orbstack.dev enough! If you are on a M1/M2 Mac, then @OrbStack will make you extremely happy. It is so close to running docker on Linux that it isn't worth mentioning if there is a difference. Mohamed Akram @tixilite Use @OrbStack and save yourself and your computer fans. Luis Dalmolin @luisdalmolin I just replaced native Docker for OrbStack on my Intel Mac and it is so much better. I can even work while Docker is building now. Show more Frequently asked questions Is OrbStack free? Do I have to pay? How is it different from Docker Desktop? Is Kubernetes supported? Will it work with my tools? How does it work? Why is it fast? Ready to love containers again? Get OrbStack Terms·Privacy·Download © 2024 Orbital Labs, LLC. All rights reserved. We're hiring! Docker is a registered trademark of Docker, Inc. OrbStack is not affiliated with Docker, Inc. in any way.",
    "commentLink": "https://news.ycombinator.com/item?id=41421846",
    "commentBody": "OrbStack: The fast, light, and easy way to run Docker containers and Linux (orbstack.dev)250 points by rpgbr 17 hours agohidepastfavorite126 comments jchw 13 hours agoI don't generally prefer to work on macOS, but if I wind up using macOS to do work, I often find myself working a lot on things in virtual machines and containers. Using Docker Desktop to compile Envoy using the standard Docker build process took somewhere in the ball park of 3 to 4 hours depending on my luck. OrbStack, on the other hand, brought it down to a bit under an hour, much closer to inline with a fresh compilation natively. Needless to say, the kinds of performance benefits I was seeing with OrbStack were game changers, and absolutely justify the cost. Even if Docker Desktop improves to match the performance, OrbStack brings basically the whole WSL2 + Docker experience to macOS, while Docker just brings the usual Docker experience. If you get the value of WSL2 on Windows, you'll probably understand the value of OrbStack on macOS. Sure, macOS is a UNIX environment, so a lot of the same software as Linux does run natively. However, a lot of Linux technologies don't really map to Darwin, so if you're working on Linux stuff on your macOS machine, there are plenty of use cases for virtual machines (case in point, Docker itself) not to mention simply being able to test software and build processes on Linux. The tight integration that OrbStack gives you is far better than just using Parallels or VMware. I have licenses for both at varying versions, but they're largely collecting dust on macOS, as now I basically only ever use traditional virtual machine products on macOS for the purpose of running Windows VMs. I'm sure some people don't have any use for this: their Docker performance is fine, they don't need Linux for anything else, etc. However, for me, it's one of those things that makes macOS much more usable for development work. reply magnio 13 hours agoparentFunny how WSL2 makes Windows much more usable than macOS for development. None of the free options (colima, multipass, etc) I've tried on macOS are as smooth, though OrbStack might be it. I have also moved towards using devcontainers for my projects whenever I can, so that I can spin up my environment on whatever machine I have, or connect to a remote one if the machine doesn't allow it. reply majormajor 1 hour agorootparentI've never found working on WSL2 to be quite as smooth as working on Ubuntu or Fedora directly. I don't really understand why I'd keep Windows in the loop there if I was on non-Mac hardward. And I've also found WSL2 less smooth than just working on Mac natively w/o containers. Containers are a necessary evil for testing certain types of things locally, but even the free tools for working with them on Mac seem fine, though Orbstack's gui is very nice. (Is there a similar GUI for Linux container management? I've just been running shell commands for years now...) Instead of moving more towards containers I've just been moving towards simpler, easier-to-set-up-on-Linux-or-Mac toolchains. But I don't have Windows as a target anyway, so that removes one huge need for containers. reply justin_oaks 40 minutes agorootparentI've used Portainer, which works ok. It's web-based and is easy enough to run as a container itself. My preferred UI for managing containers is Lazydocker. It's a terminal UI, so I can run it on servers too. For the most part I just use the command line on Linux, but when I need to go through a large list of containers, images, or volumes to clean up, lazydocker is much better than the command line. reply jchw 13 hours agorootparentprev> None of the free options (colima, multipass, etc) I've tried on macOS are as smooth, though OrbStack might be it. Yes, I am generally not terribly impressed by colima. Of course, it's great to have as an option, but in practice I ran into issues trying to use it in various places. One issue that I am sure isn't a huge deal to most users is that as far as I could tell, colima did not support IPv6. I didn't try multipass, but I did try Podman Desktop. It had its niceities but largely was behind even Docker Desktop. If you really miss WSL2 on macOS, you might genuinely find OrbStack enticing. Then again, it's not free, and obviously, I don't want to give anyone false hope. For \"home\" use, I just run desktop Linux, using native containers and libvirt for everything. If I had to pay for a decent development experience on my personal machines, I would definitely struggle to justify a subscription charge even if it was good. On the flip side, it's easy to budget OrbStack into the equation for professional use. For your employer it's virtually a no-brainer. reply gigatexal 10 minutes agorootparentLima ssh and you have WSL more or less. What are people missing? reply talldayo 2 hours agorootparentprevImagine paying a subscription service to use something slower than QEMU. Yikes... reply jchw 35 minutes agorootparentOK, I'll try to imagine that. reply pjmlp 12 hours agorootparentprevOnly because it is a Linux VM, and people insist on using Linux specific stuff instead of UNIX, to the point younger generations have no clue about the difference. Even the BSDs and Solaris/Illumos have add to add Linux translation layers. Sad state where POSIX hardly matters for portable UNIX code. reply unilynx 4 hours agorootparentTo mirror the sibling comment, where's the POSIX container/zone/vm whatever specification? If the BSDs and Linux can agree on a meaningful subset, macOS might actually follow reply pjmlp 4 hours agorootparentThere isn't any in POSIX, then again, it isn't as if we now need containers for every executable for any magical reason. Also, just like in the good old days, it isn't hard to have something dealing with HP-UX Vaults, Aix logical partitions, Solaris/Ilumnos Zones, BSD jails, macOS Virtualiztion Framework,.... reply saagarjha 3 hours agorootparentJust listing technologies that sound kind of similar isn’t enough to actually answer the problems people want solved. The “good old days” were basically just people crying about being unable to have any of the features we have now because they don’t match up or differ in subtly different ways. reply pjmlp 1 hour agorootparentBest way to solve problems is not to have them in first place, like getting a Linux laptop for doing Linux work. reply FpUser 38 minutes agorootparentWords of wisdom. I do not really have any dev related problems with WSL2 either. Normally I develop and debug on Windows and deploy to Linux as my code compiles and works natively on both. It is mostly C++ backends lately so I suspect I am in tiny minority. reply unilynx 3 hours agorootparentprevI was responding to 'people insist on using Linux specific stuff instead of UNIX'. As far as I can tell there is no way to do containers without doing highly platform specific stuff. It would be very useful if the platforms worked towards a common 'more than chroot' thing. As far as not really needing it, it's not like computers themselves are anywhere near the bottom of Maslow's pyramid, but that doesn't make them any less useful reply talldayo 2 hours agorootparentprev> Sad state where POSIX hardly matters for portable UNIX code. Given the current state of POSIX applications, I would actually argue that the BSD/Linux hegemony we enjoy is the best possible outcome. The only people that are mad are the people paying for UNIX and expecting to get something better for it. Those people should have learned their lesson in the 90s, I have no empathy for POSIX apologists in 2024. The only \"sad state\" is one where everyday people don't have access to free software. Mac users have always paid a time premium and a performance premium for access to normal development features, this ignorance of MacOS is a pattern that persists since the 90s. Of course nobody is bending over backwards to test portability with a proprietary OS. reply AYBABTME 6 hours agorootparentprevCan you make containers in Darwin? reply shepherdjerred 3 hours agorootparenthttps://darwin-containers.github.io/ reply pjmlp 4 hours agorootparentprevYes, the macOS way, with Virtualization Framework. reply nyrikki 14 minutes agorootparentThe insane stability of the Linux ABI is partially what makes containers useful. The fact that containers can reliably depend on the ABI contract, thus placing almost any clib they wish they want inside the container is fairly unique. That extreme stability of that contract is awesome for namespace decoupling. Unfortunately Apple and Microsoft do not have such stable interfaces. Remember containers are just namespaces. reply saagarjha 3 hours agorootparentprev(No.) reply shepherdjerred 3 hours agoprevThe absolute best feature that OrbStack has is debug shells. Essentially, it lets you attach to any container with all of your favorite tools already present, e.g. vim. https://docs.orbstack.dev/features/debug OrbStack is well worth the price IMO reply hinkley 3 hours agoparentHow the hell do they do that? reply atombender 37 minutes agorootparentLinux, at the kernel level, doesn't have any concept of a \"container\". What you have instead are namespaces. File systems, process lists, networking etc. are all namespaced, and you can set these up \"a la carte\". For example, you can create a new process that has as its file system root /home/blah. It will see every process in the system, it can do networking, etc. — but \"ls\" can only show the files under /home/blah, which appears as /. Inside this process, you can't see any files above this directory. A Docker container is simply a process which has set all its namespaces in such a way as to isolate it from others. \"Entering\" a Docker container is done by setting up your namespace to be the same as that of the container. For example, you can create a new process (a shell, for example) that is a normal process in every way — full access to the root file system and networking and so on — but has the process tree root as the container. The process will see only the processes inside the container. You can do this on Linux today using the nsenter [1] tool. (This is also a way to create simple namespaced processes without Docker.) This allows a mix of namespaces; you can enter the container's namespaces but also retain the ability to run tools that aren't available inside the container. In short, I assume the OrbStack debug command does the exact same thing. It's coincidentally the same concept as an ephemeral container on Kubernetes. [1] https://man7.org/linux/man-pages/man1/nsenter.1.html reply omnicognate 2 hours agorootparentprevThere's a \"how it works\" bit at https://orbstack.dev/blog/debug-shell > In particular, mount namespaces are what Docker and runc use to give each container its own image and view of the filesystem. But unlike chroot(2), you can copy an existing mount namespace into a new one. Debug Shell uses this to copy a container's namespace, creating a new view where we can inject things without them showing up in the original mount namespace or filesystem. reply haberman 12 hours agoprevI have been happily using OrbStack for a while now, and I've had nothing but good experiences. The UI is polished and responsive, the containers have great performance and nice integration with the host, and overall the product seems to be constantly pushing itself to be even better. I admit my greatest confusion about this software is how a product that appears to be a one-man show so quickly became more compelling than the well-funded incumbent (Docker Desktop). This is even more impressive considering that the developer appears to be a college student. Hats off, this is amazing work. reply kdrag0n 12 hours agoparentLove to hear that. We're actually a small team at OrbStack now! reply saagarjha 12 hours agoparentprevI’ll let the actual developer respond but OrbStack has several people working on it now. reply KingMob 9 hours agoprevOrbStack is great in a lot of ways, and I universally prefer it over Docker for Mac. That being said, it wasn't always been smooth sailing. Under the hood, OrbStack uses an 8TB sparse disk image, which doesn't play nice with most backup software. https://github.com/orbstack/orbstack/issues/29 It caused me problems with Backblaze, but the Github issues for this show that it also breaks all sorts of backup software, including tarsnap, Druva inSync, Carbon Cloner, iDrive, Carbonite, and even Time Machine itself when formatted with HFS+, apparently. The official position for a year was \"won't fix\", because it's an Apple technology, and backup software should support that. While technically correct, realistically, sparse image backup support was not very widespread at the time. (I have no idea about now, since I gave up trying to back up my Orbstack image with my whole disk backup.) I like Orbstack, but I wish the devs had moved to exclude the disk image from backups immediately, instead of arguing with people about it for a year first. All that being said, I do still like OrbStack a lot, and I hope to never see a repeat of this problem and how it was handled. reply nwienert 8 hours agoparentThe first reply on the issue you linked seems incredibly professional and well handled, and even recommends excluding the file from backups, I can't see a single issue there. reply KingMob 7 hours agorootparentBeing polite is not quite the same thing as being handled professionally, and definitely not the same thing as handling it correctly. Telling people to exclude the file from backup came too late for many. E.g., Time Machine users with older disks formatted with HFS+ would find their drives crashed/corrupted/wiped, and lost all their backups. Only afterwards would they start googling to see what happened. (Even now, the relevant FAQ still says \"Time Machine supports them, so your backups will not be affected\" which is not always correct.) From the time the issue was opened, to the time they said they admitted they were wrong and excluded the Orbstack image from backups by default, was 13 months. Even if other solutions were on the table, the professional thing to do would have been to exclude the images ASAP, so customers weren't at risk of data loss, and then work on alternatives afterwards. reply ignoramous 5 hours agoparentprev> I like Orbstack, but I wish the devs... devs? afaik, it is just one teenager, Danny Lin (he might be 20 by now, though). reply kdrag0n 3 hours agorootparentA small team now :) (not back then though) reply marvin-hansen 11 hours agoprevI switched to Orbstack about 2 weeks ago after having read about it here on HN. I develop a cloud native system entirely writen in Rust. All my own containers are build without Docker thanks to rules oci in Bazel. However, for integration testing, I'm using internal tools that fire up, say a database container and run the tests all from within Bazel to leverage test caching and parallelization. For a while, i was struggling to get around Dockers slow startup time on Mac. My CI server uses Firecracker VM's to isolate OCI containers so it's really only a docker on Mac issue. My main take away: - I am so close to delete Docker permanently. There is no comparison, not even close. All integration tests run so much faster. - Especially parallel container starts a noticable faster. - I've developed custom docker utils for testing and, believe me, the official Docker API is a humongous pile of garbage that I ended up re-implementing everything by wrapping the Docker command line. To nobody's surprise, even the custom docker utils work way faster and more reliable with OrbStack. - Zero issues. I am still a little bit puzzled that OrbStack basically runs bug-free no matter what I throw at it. Take it as a compliment. What I would like to see: - A Ressource monitor or at least some graph that plots CPU and memory usage. In some rare cases the application in the container runs close to the limit probably because a query takes too long, a process got stuck or whatever. Stuff just happenens. Point is, having an eye on ressource usage helps to spot those corner cases early on. For me, OrbStack is a clear win and a clear keeper. Well done Orb team and I wish you guys all the success in the world. reply princevegeta89 7 hours agoparentI've been using Colima which has been great, and much better than Docker Desktop which sucked ass for me. With Colima, file mounting and sharing caused reliability and permission issues for me though I've applied some workarounds with success. To avoid this mess, I'd much rather move to a VM though. I used VMWare Fusion and UTM but I still had the struggles with file sharing between host and the guest. So I took a lot of steps back and I'm currently running a Lima VM with headless Ubuntu and things are great so far. For Vscode we got the remote SSH plugin and then there is the Jetbrains Gateway as well. I'm sharing my experiences for people in similar shoes to try these out, if that helps! reply rfoo 10 hours agoparentprevI'm in a similar position but I need to make sure I run distro kernel (because that's part of integration) instead of whatever OrbStack shipped. In the end I just run a Linux VM and run everything inside. Zero issues by definition. I'd actually love to use OrbStack Machines cause it feels much nicer than UTM, but, well, I can't run OrbStack's patched Linux kernel :( reply oarmstrong 10 hours agoparentprev> My CI server uses Firecracker VM's to isolate OCI containers Is this something you built yourself? I've been looking for a CI tool that uses Firecracker but never found anything, I started building something myself but it never really got finished. Would love to drop that project and use something off the shelf. reply aayushshah15 5 hours agorootparentI'm obviously biased here but this is what we do at blacksmith dot sh. We run you GitHub Actions on consumer grade desktop CPUs with high single core performance, all inside ephemeral Firecracker VMs. Give us a shot! reply marvin-hansen 5 hours agorootparentprevBuildBuddy. Google it. It's totally next level. My build is 70 crates, hundreds of unit tests, integration tests, multi platform docker images for two platforms, and everything is done in under 2 minutes, if it's slow(!). If I hit only an incremental change, build is completed within 30 seconds. The future is now! reply totetsu 9 hours agoparentprevI did the same thing. Docker Desktop for Macos kept going into resource saving mode and then not responding to anything after some time, so I tried Orbstack after seeing it here. reply withinboredom 13 hours agoprevI love how there is absolutely no mention that it is mac-only (or even what versions of mac are supported), even on the download page. reply raffraffraff 12 hours agoparentWas just about to post this. Apple heads tend to think that Mac is the default. Funny when you realise that the problem OrbStack is trying to fix is that MacOS isn't Linux. reply pjmlp 4 hours agorootparentRather people using a UNIX, that isn't GNU/Linux, instead of sponsoring Linux OEMs. reply withinboredom 3 hours agorootparentPretty sure orbstack won't run on other unix systems. reply pjmlp 1 hour agorootparentBuying a Linux powered laptop would have sorted out the problem in first place. reply me551ah 10 hours agoparentprevWindows already has WSL2 and Docker would run natively on Linux anyway. reply Animats 12 hours agoparentprevYes. I'd like to have something that runs Docker images on desktop but doesn't require a privileged daemon, users, groups, etc. reply PhilipRoman 5 hours agorootparentProbably not what you're looking for but I just wanted to mention Apptainer (previously Singularity). I find that it is usually easier to integrate and doesn't rely on a daemon. You can still use docker images as base. reply mrbluecoat 5 hours agorootparentAgreed. Apptainer is great for this use case. reply suprjami 8 hours agorootparentprevIs Podman Desktop available on your platform? Podman is rootless containers done correctly. reply saagarjha 12 hours agoparentprevWhich other platform would you expect it to be for? reply fulafel 12 hours agorootparentIt advertises as an alternative to Docker Desktop which is for Windows and Linux as well. reply knallfrosch 11 hours agorootparentprevAsked the other way around, why would anyone think a Docker container runner would be tied to MacOS? reply saagarjha 11 hours agorootparentBecause Windows users are unlikely to care about Docker and Linux people don’t pay for stuff reply vultour 9 hours agorootparentThis is hilarious and perfectly sums up my experience with Mac developers. Half of them have no idea Docker Desktop actually installs a Linux VM. They think how amazing their incredibly expensive system is, yet it's mostly a glorified text editor. The WSL experience on Windows convinced me buying a MacOS machine makes no sense. reply eropple 4 hours agorootparentSo I use WSL2 regularly on Windows, but I don't agree at all that buying a Mac doesn't make sense. WSL2 is great, and Windows 10/11 are fine after doing some cleanup...on a desktop. My experience with Windows on even modern laptops is pretty bad. It's very hard to find something with the build quality and affordances of a Mac. Razer makes a good machine but tbh I'd be embarrassed to bring one to a meeting, and I don't like how newer Thinkpads feel and I don't trust Framework to exist in a few years. It's then complicated while seeking reasonably comparable specs--and I'm not a \"oh Apple Silicon sounds warmer\" sort of person, amd64 is just fine with me, but AMD's high-end IGPs generally keep pace with base-model Macbooks, and start to fall behind pretty significantly when you move up to a Pro or a Max. You can add a discrete GPU, but, me, I like battery life, and mobile dGPUs are a mess of compromises anyway. Even if you get over that hurdle, I think Windows feels bad when you're using a touchpad. They haven't cracked that one despite how long they've had to work on it. I wouldn't want to work on a Windows laptop without an external trackball; I carry one with my Mac but rarely use it unless I'm going to be working for a pretty long stretch and I want to save my hands. Windows is still generally my pick for desktops for a lot of reasons (I don't even dual-boot Linux right now!) but this kind of sneering is weird and uncalled-for. reply baq 3 hours agorootparentprevMacs have great hardware (as in, great display and a great touchpad - and the best thing is the computer wakes from sleep when you open the lid, every time; I don't particularly care about the M-series except that it runs super duper cool for how fast it is). That said I've been tooting the horn that they are not good software development machines for about 2 years now (incidentally matches exactly with when I got a work macbook pro). reply saagarjha 9 hours agorootparentprevGlad the humor landed reply withinboredom 11 hours agorootparentprevI work on Windows, but mostly just use it for windowing. Almost all my work is done in WSL2 and Docker. The only things running natively are my IDE, my web browser, and slack. reply yunohn 9 hours agorootparentprevThe vast majority of devs use windows for dev, esp with Docker. Why wouldn’t they care about it? reply globular-toast 2 hours agoparentprevYeah, I was quite confused, especially by the title \"docker containers and Linux\"? What does that mean? If you can run Linux you can run docker. I thought it might have been a batteries included Linux distro at first. reply inopinatus 9 hours agoparentprevIt's in the page title. reply mkl 9 hours agorootparentConveniently left out of the HN link, and mentioned nowhere in the page body. reply julian37 4 hours agoprevkdrag0n's first post about this on HN, afaict: https://news.ycombinator.com/item?id=34100779 Amazing how far they've got since, in just two years. As others have pointed out, it's already \"boring\" software in that it just works. And that's no small feat because this kind of tool requires all kinds of low-level hackery to make work, and make work fast. Hats off! (Happy user here if you couldn't tell.) reply commandersaki 11 hours agoprevOrbStack is by far some of the best software I've encountered on Mac, but unfortunately I have difficulty convincing my employer to pay for a commercial license, and with my sparse Docker usage, I'm confined to using it only for personal/hobby usage. What's amazing is it fixes an (almost) show stopper bug when using libuv (or software that uses it like CMake) with Rosetta 2 [1], with the bug present on all Docker/VMs I've tried except OrbStack. It just seems to get everything right. [1]: https://github.com/libuv/libuv/issues/4279 reply _joel 6 hours agoparent$8 a month/user for the speed and productivity improvement seems, err, shortsighted. reply talldayo 2 hours agorootparentOn the flip side, I empathize with the employer wondering why their \"developer laptop\" needs a monthly subscription to do what their Production server does for free. Maybe they should just use UTM in the meantime. reply _joel 2 hours agorootparentI'm not sure what you mean by prod server in this context, we deploy to k8s. We use testcontainers[1] that run locally on the laptop via IntelliJ. There's a bunch of integration tests that take a good while to boot via docker-desktop. If these tests can be sped up significantly then it's worth that $8 a month. I'd like to remind you that technically docker desktop isn't free, either. Nor is pushing tests to run via CI/CD first. That iteration cycle would take even longer. [1] https://testcontainers.com/ reply cedws 9 hours agoparentprevSorry to be blunt but your employer must be real penny pinchers, it’s not that expensive, and it’s a tool that would help you get the job done. reply commandersaki 9 hours agorootparentFair criticism and I agree -- to that point, we're asked to bring our own devices to work without any compensation or the like (though it does have its advantages). I've considered paying out of my own pocket, but I just don't use Docker outside of work, and that's kind of where I draw the line at paying for software to do work. reply DandyDev 1 hour agorootparentYou have to bring your own device? Do you have a major stake in the company you work for? Do you get an outrageously high salary? If the answer is no on both, you are taken major advantage of and you should quit asap reply danmur 9 hours agorootparentprevSpent all the budget on Apple hardware reply nkmnz 7 hours agorootparentMacBook Air M2 16gb ram leasing: 30€ per month orbstack pro business license: 10€ per month I don't think the hardware cost is prohibitive here. It's the death of a thousand paper cuts of a startup. I agree that orbstack would be a good investment, though. reply danmur 7 hours agorootparentMy (somewhat sarcastic) comment was just that Apple hardware is more expensive than Linux/Windows hardware. If you use Linux then I would say the docker experience is quite good. I wonder if Linux hardware was an option; seems odd to require running stuff under docker but also force people to use macbooks... reply _joel 6 hours agorootparentSome places don't allow it due to MDM not being available/beta/untested for linux, althogh that has changed quite a bit over the past couple of years. reply password4321 5 hours agorootparentprev> MacBook Air M2 16gb ram leasing: 30€ per month How/where does one do this? reply kdrag0n 13 hours agoprevNice to see this here :) I work on OrbStack. Happy to answer questions! reply weikju 11 hours agoparentPlease keep in mind I’m asking with genuine interest as I am a happy OrbStack user otherwise, (for private use). What is the reason Orbstack needs a connection to your license server for continued operation? I was moving and during nearly a month there was no home internet. My server was happily chugging along on wifi though, but one day I connected to it and saw a message that OrbStack couldn’t contact the license server and soon stop functioning. This put me off a bit and made me consider whether I want to run anything I depend on using this. reply password4321 5 hours agorootparentAs you appear to be aware per the prefix to your question, this is the nature of all subscription software... what alternative would you choose if you were the author? Requiring the personal use edition to phone home once a month probably increases the potential sale price of the business by at least one order of magnitude. It would be more interesting to know the plans for tracking down commercial users abusing the personal license, maybe Oracle VirtualBox Extension Pack reverse IP address lookup style. The ins and outs of software license enforcement doesn't play well on HN, though I'm guessing there are few complaints about OrbStack requiring a subscription because they offer a free personal use license and the entry level commercial use license is so cheap vs. the value provided. It's actually exciting to see a dev tool where the developers have a sustainable business model, but this usually means there will be plenty of offers to cash out. reply highwaylights 12 hours agoparentprevWhat’s the security model for OrbStack and its containers? Is OrbStack rootless? Where is the security boundary for the containers? (Are they sandboxed completely from the host?) How does the virtualisation work? (I’d assume Virtualization.framework, so I can run it without Rosetta if all containers will share host architecture?) Does it support Docker-in-Docker and Docker-out-of-Docker? (M1 and M2 Mac’s don’t have hardware for nested virtualisation so I assume this also prevents DiD with OrbStack?) Thanks in advance, eager to try it out. reply kdrag0n 12 hours agorootparentIt's a shared VM and kernel, so the security boundary between containers is only as strong as typical Linux containers, and we don't really use the VM as a strong security boundary right now. The security model is similar to running Docker containers on a native Linux machine for development. Admin privileges aren't required on the macOS side. You can optionally allow a privileged helper for some small niceties, but the VM process never runs as root. The virtualization stack is custom, which allows for a lot of performance and stability improvements. It's not Virtualization.framework or QEMU. Containers don't require virtualization, so Docker-in-Docker works. Not sure what you mean by Docker-out-of-Docker, but you can run Docker in OrbStack Linux machines, and you can use the managed engine from macOS. reply nkmnz 7 hours agoparentprevOne reason I'm still using docker desktop in my (small) company is that our production systems are using docker compose and the networking with domains does not translate 1:1 between orbstack locally and docker compose + nginx in production. Is there an easy way to solve this? reply kdrag0n 7 hours agorootparentOrbStack domains can be nice but you don't have to use them. It's fully compatible with Compose, so you can just run the same commands with no changes to your setup. Did that not work for you? reply styfle 6 hours agoparentprevI have a machine with Colima and don’t want to bork it if I try Orbstack. I think I used “brew install docker docker-compose colima” and then “colima start”. Is “brew install orbstack” a drop in replacement for colima or does it install other things that might conflict? reply kdrag0n 6 hours agorootparentDrop-in: \"orb\" to start, stop it + uninstall + restart Colima to revert. It can optionally install OrbStack's bundled `docker` and `docker compose` binaries, but you can also keep using the Homebrew ones. reply _joel 6 hours agorootparentuse docker contexts, much easier :) # Switch to OrbStack docker context use orbstack # Switch to Colima docker context use colima reply rfoo 10 hours agoparentprevHi, is it possible to add a virtual machine mode to OrbStack? See https://news.ycombinator.com/item?id=41423667 for why. I'm okay with most (or all) nice integrations unavailable. Basically I want a true UTM replacement, the one I can run my own kernel. reply kdrag0n 7 hours agorootparentSorry, no plans for that. That vertical integration is a key part of OrbStack — it's not just for nice extras/integrations. reply rfoo 1 minute agorootparentFair enough. Thanks for answering. reply txdv 13 hours agoparentprevIs the underlying kernel emulated in QEMU? reply kdrag0n 12 hours agorootparentWe use a custom virtualization stack instead of QEMU. It makes a lot of performance and stability improvements possible. reply nrvn 9 hours agoparentprevI have been using colima as a lightweight alternative to docker desktop and the likes of it for almost two years. Looking at the comparison provided on the orbstack website (https://docs.orbstack.dev/compare/colima) it seems to be not very accurate or at least requires some explanations/clarifications. For instance: Low power/CPU usage is advertised as non-existent in colima. This is simply not true. Based on my perception I can't tell whether colima VM is running or not. Unlike docker desktop, especially with kubernetes on. Does not drain my battery, does not bog my CPU down unless I intentionally spin up something resource hungry. ease of use/performance: not everyone needs GUI. colima is fine UX/devex wise with fast startup times. What does \"fast network\" even mean? Linux machines/distros: not a fair comparison. colima stands for \"containers on Lima\" where lima is \"linux machines\" on macos. I.e. if you want arbitrary vms, use lima directly. colima is specifically built to spin up docker/containerd/k3s vms. containers/kubernetes networking: this is opinionated and depends on a specific use case. In general I prefer the idea when my local kubernetes setup looks like the end production setup in the sense that I cannot mess up much with networking, access clusterip services directly from localhost because clusterip services are supposed to be accessible from inside the cluster itself, not from outside. loadbalancer IP is accessible through NodePorts anyways. containers file access: there are plenty of ways you can access files in containers and images. But again, probably there are people who like to browse the guts of a kubernetes node in MacOS Finder. When it comes to files and networking I want to be able to re-use my toolbox used for dealing with remote kubernetes clusters and docker/containerd instances to my local ones. Creating a special case with convenient but non-standard ways to access files as if they were part of my host filesystem may be good for someone, but wrong for someone else because at times when something goes wrong this special case will work as an excuse for \"works on my machine\". Please take the above as my personal experience. And I am in the herd of those who tend to keep everything as minimal and bare as possible with as much standartization/ lack of deviations across different environments as possible. Came to colima after years of minikube just because minikube's experience was no longer good with apple silicon. And there must be a very strong reason to switch to something new when what you have already is good enough. Also, when it comes to GUI, what about Rancher Desktop? reply saagarjha 12 hours agoparentprevWhat exactly is an Orb Stack reply cedws 9 hours agoprevHave been using OrbStack since beta and with a commercial license since February. I can’t praise it enough, it’s elegant, performant software that just works. reply rudi_mk 7 hours agoprevOrbStack has been an absolute lifesaver. Rancher Desktop was great for running a quick K3s cluster locally, but OrbStack's VMs are just great. For someone who likes to run separate envs on Linux, Orb's VMs are great. Pretty performant on my older M1 MBP too. reply vinnymac 6 hours agoprevI have been using OrbStack for 8 months now for personal use. I haven’t experienced a single issue in that time, and use it daily. Can’t say that for much software to be honest. reply Quarrel 6 hours agoprevIt would be handy if it mentioned somewhere near the top of the front page that OrbStack is a macOS utility. So that Linux & Windows people know they can look away. (Looks like a cool tool though!) reply mkermani144 11 hours agoprevIt's not as battery-hungry as official Docker desktop. That's the main reason I switched to it. Now, I'm happier than before. reply SEJeff 13 hours agoprevI love that you can simply type `orb` and get dropped into a Linux vm. Some of the cpu features are super weird (cat /proc/cpuinfo and it is unlike literally any x86 cpu I've seen before), but unless you happen to build stuff that depends on lots of specific cpu features like I do, it works well enough. reply jbverschoor 13 hours agoparentPlease try out my Docker shell container - https://github.com/jrz/container-shell which works great with orbstack reply saagarjha 12 hours agoparentprevI assume it matches whatever Rosetta advertises? reply kdrag0n 12 hours agorootparentIt's because Rosetta doesn't seem to emulate /proc/cpuinfo, so the contents reflect that of the arm64 host. reply SEJeff 6 hours agorootparentYeah, it makes for VERY confused builds when you select on cpu features available. reply dmeijboom 13 hours agoprevHappy user since day one. Since adopting Orbstack most of our frustrations with Docker on Mac OS are gone. reply pawelduda 6 hours agoprevOrbStack is great for me on MacOS and nothing else I tried comes close. reply rahen 8 hours agoprevI'm not sure I fully understand the technical differences between an OrbStack VM and a container, as both seem to use a shared kernel. What would be the closest alternative on Linux? LXD? I've grown accustomed to the convenience of OrbStack. reply suprjami 8 hours agoparentA Buildroot VM which runs just enough Linux to provide Docker and virtio file sharing? You can achieve almost the same thing with Alpine Linux, that's how I run all my containers, one VM per container. Edit: Further down the comments it says OrbStack is a single Linux VM running LXD containers. Oh well, I was close. reply rahen 8 hours agorootparentI currently use Vagrant on Linux, but it's slow and resource heavy. With OrbStack, the ability to set up an Ubuntu or Fedora 'VM' in a few seconds, then install even complex SDN workloads inside is incredible. Now I want something similar on Linux, especially once I switch to Asahi. I haven't tried LXD yet, but it seems to work similarly to OrbStack with the added benefit of having a full Linux kernel and the ability to modprobe modules and create snapshots, something that isn’t possible with OrbStack. I'll have to give it a try. reply suprjami 8 hours agorootparentLXD is a manager for LXC containers. I have the vague idea that it's like k8s for LXC but I don't really know either orchestration tools well enough to say. LXC containers are like Docker/Podman containers except they usually run an init process, so you're not running just one binary inside the container. You can make LXC \"app containers\" which just run one binary Docker/Podman containers. reply fnordlord 6 hours agoprevDoes anyone know if you can run arm64 images on a x86 Linux machine? I'm currently doing it with Docker and QEMU but it is super slow. reply _joel 6 hours agoparentEmulation will generally be pretty slow, much slower than native virtualisation (although Rosetta has tricks to make this quicker). Ideally use multi-arch images or build your own. reply webprofusion 11 hours agoprevErr, you guys know that about 80% of desktops are Windows right? There's a bit of a myth that developers are all using macOS but in practice that's not really the case. reply selcuka 11 hours agoparentI can't see how 80% of desktops being Windows is proof that most developers use macOS is a myth. Developers probably represent much less than 20% of all desktops, so it's a moot point. reply EasyMark 5 hours agoparentprevMaybe they like developing for Mac and that’s their niche, at least to begin with? You have to start somewhere. reply renewiltord 11 hours agoprevOrbstack is great. I use it in order to build a library cross-platform (Linux/Mac amd64/aarch64 all combinations) and it's great how I can do it on my Mac. You can even run a quick shell in a VM that has all your stuff mounted. Perfect user experience. reply ta988 14 hours agoprevAlso a bit more expensive than docker desktop for companies. reply Dansvidania 9 hours agoparentperhaps, but much better in my experience. reply xyst 12 hours agoprevI’m curious how orbstack is able to achieve the performance they claim. reply moondev 10 hours agoparentIt appears to be lxd, I assume a single vm with multiple lxd inside. https://github.com/orbstack/orbstack/issues/461#issuecomment... reply kdrag0n 6 hours agorootparentThe issue submitter just happened to be running LXD in their OrbStack machine. reply sunaookami 12 hours agoparentprevThey have an architecture overview here: https://docs.orbstack.dev/architecture reply quantumwoke 9 hours agorootparentThis is pretty light on the details. reply mootpt 2 hours agoprevalso supports ipv6. reply novolunt 12 hours agoprevThe problem with wsl2 is that it not only requires a virtual machine, but also uses the windows kernel, not the linux kernel reply dwattttt 11 hours agoparentWSL2 doesn't run under the Windows kernel, it runs the Linux kernel under the Windows hypervisor, side-by-side with the Windows kernel (in another lightweight VM). Honestly it's kinda crazy that Windows natively now runs as a VM. reply fake-name 8 hours agoprev [–] OrbStack: The fast, light, and easy way to run Docker containers and Linux* * On MacOS Hosts only. I feel like there should be a rule that if the submission is basically a \"Show HN\" style post (or a link to s piece of software), it should be mentioned in the title if its platform specific. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "OrbStack introduces a lightweight and efficient alternative to Docker Desktop, designed to minimize memory and CPU usage while providing robust capabilities for running Docker containers and Linux.",
      "Key features include fast startup times, low resource consumption, seamless integration with CLI and file sharing, and support for running x86 containers on Apple Silicon using Rosetta.",
      "The product has garnered positive feedback from developers for its performance improvements, particularly on M1/M2 Macs, making it a compelling option for those seeking a more efficient container management solution."
    ],
    "commentSummary": [
      "OrbStack is a new tool for running Docker containers and Linux on macOS, offering significant performance improvements over Docker Desktop.",
      "Users report that OrbStack reduces compile times dramatically and provides a WSL2-like experience on macOS, making it a compelling option for developers.",
      "Despite some issues with backup software and sparse disk images, the overall user feedback highlights OrbStack's polished UI, better integration, and faster performance compared to alternatives like Colima and Docker Desktop."
    ],
    "points": 251,
    "commentCount": 126,
    "retryCount": 0,
    "time": 1725240956
  },
  {
    "id": 41424371,
    "title": "Defrag the Game",
    "originLink": "https://defrag-game.com",
    "originBody": "Hi,A while ago, I came across this https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=KR3TbL3Tl6M on YouTube showing 8 hours of defragmenting a hard drive. For some reason, it inspired me to create this small game.Have fun :)",
    "commentLink": "https://news.ycombinator.com/item?id=41424371",
    "commentBody": "Defrag the Game (defrag-game.com)217 points by v_b 7 hours agohidepastfavorite88 comments Hi, A while ago, I came across this https://www.youtube.com/watch?v=KR3TbL3Tl6M on YouTube showing 8 hours of defragmenting a hard drive. For some reason, it inspired me to create this small game. Have fun :) danbruc 6 hours agoThis is not like defragmenting a disk at all. There are no sectors or clusters, I can and have to move entire files at once. I have to move them in some fixed order and I can only move each once. Files can bump into each other?!? This is extremely confusing if you think the game is about what the names says. reply guestbest 3 hours agoparentThis is generally my fear in creating a game in that the players would take the name and rules more seriously than me as a designer. I liked the game, btw as it captured a certain look and feel as well as was fun to play. reply mrgoldenbrown 1 hour agorootparentI think what happened here is that author didn't include instructions, the UX was not clear, and the author said if you are old enough to remember defrag you'll just know what to do. But on the Internet everyone's a pedant and many of us remember DOS/ windows defrag in more detail than the OP seems to, so there's confusion/complaining. All that is par for the course though and hopefully you will still make and share awesome games! reply pmelendez 5 hours agoparentprevQuoting OP's: |> it inspired me to create this small game. It was inspiration, not a simulation nor it claimed to be realistic. This is the type of artistic license that game designers have always had at their disposal. reply danbruc 2 hours agorootparentI am not complaining about how the game works, I am just saying that there are no instructions, so the only thing I have to work with is the name and the inspiration. And if you know how defragmentation works, this all just makes no sense, why does it automatically select blocks, why can I not move them repeatedly and to any free space? Sure, most people do not know what defragmentation is and how it works, even in developer circles I would not expect people to know if they are not old enough to have worked with computers in the 90s, they might hear about this in one computer science lecture and never think about it again. reply monitron 1 hour agoparentprevIt's quite a bit more \"realistic\" if you imagine it as a simulation of the \"Defragment Free Space\" option that at least some defraggers had. reply kwhitefoot 5 hours agoparentprevI'm pretty sure that there have been disk formats that only write files to consecutive sectors just like memory allocators that only return contiguous blocks of memory. Then you need frequent compaction of the space because it ends up full of small unallocated blocks. See https://www.geeksforgeeks.org/file-allocation-methods/ reply stavros 5 hours agoparentprevYeah, this needs an explanation, I went into it thinking it was like defragging and it took me a while to figure out how to play. Fun game, though. reply IshKebab 2 hours agoparentprevWell... yeah but also defragmenting isn't a game. If you want to make a fun game out of it you're going to need to change a few things. That said, I can't see how this is fun tbh. reply r1chardnl 7 hours agoprevJust a matter of time before Chrome pushes another JS API like File System API and you can actually defrag your drive from the browser. reply ossobuco 5 hours agoparentIt's already there: https://developer.mozilla.org/en-US/docs/Web/API/File_System... reply HeatrayEnjoyer 4 hours agorootparentWhy do APIs like this even exist? There's no legitimate reason for an HTML webpage to need this, it's just creating more attack surface for bad actors. reply zamadatix 2 hours agorootparentThe File System API is a JavaScript API, not an HTML one, so it helps to think about it from that light (programs, not documents). The API allows tools such as photo editors, file converters, code editors, and the like to be given access to a set of files they can work on directly rather than needing to import and export from the browser on every change. If the attack surface is too much for a use case it can be globally denied by default in every major browser so you won't even get prompted. reply HeatrayEnjoyer 1 hour agorootparentJavaScript is just a feature accessory for HTML. There's no meaningful difference. reply zamadatix 18 minutes agorootparentFor whatever your preference in slicing that up is you can carry the \"programs, not documents\" reasons along. reply nox101 2 hours agorootparentprevThe page needs permission. That permission step is similar to the act of downloading a native app. Except for the fact that the broswer gives even less access to your system than a native app so it's safer than a native app. (at least on desktop) That file system API is super useful for cloud based IDEs as just one example reply zamadatix 2 hours agorootparentprevThey say \"like\" this one because it only provides file level interaction, not disk level interaction. reply v_b 7 hours agoparentprevShould already work today with your cloud storage I think reply hinkley 3 hours agoprev> 8 hour defrag In the NT 4 era I had a defrag take almost 18 hours. I started it before leaving for the day and came in the next morning to find it an unknown percentage done. I didn’t trust it would be okay to restart the machine so I had to leave it. That was a problem because we were running version control on this box. But by then everyone was bought in so we got a dedicated machine out of the ordeal, but that was super annoying. We even called Microsoft and got through, but it turns out on NT defragment happened in real mode so there isn’t a lot of memory to buffer copied blocks. So it spends a lot of time seeking on the hard drive. So stupid. reply r1chardnl 7 hours agoprevFrom the title at first I thought this was a Quake browser port [0] [0] https://en.wikipedia.org/wiki/DeFRaG reply pureheartlover 6 hours agoparentI love watching defrag vids on youtube. There's still a strong but small community pumping out world records. A classic from about a decade ago: https://www.youtube.com/watch?v=RUCtMIjL-Z4 reply stavros 5 hours agorootparentI spent two seconds trying to figure out how someone would even do competitive defragmentation, let alone why there are multiple people doing it. reply ponytech 5 hours agoparentprevI thought the same :) reply sixonesixo 6 hours agoparentprevthat would be amazing reply abcd_f 6 hours agoprevOn iPhone drag-n-drop doesn't work. Long tap basically selects part of the gaming field and this selection is not draggable. Once tap is released it shows the Copy/... menu. reply hinkley 2 hours agoparentIt’s because the game ergonomics are questionable. You can only slide files sideways, not past other files. Your phone isn’t broken, not is the game engine. The game rules are. I got other things I’m supposed to be doing right now so I’m gonna go do those. reply mastermedo 6 hours agoparentprevYou need to swipe. Works on iphone 13 + chrome. reply hinkley 2 hours agorootparentI tried swiping, got nothing. I’m not sure what else someone would interpret as drag and drop on a touch screen. That’s gonna be swiping. reply holistio 7 hours agoprevFun game, but scoring seems to be a bit off. If I just smash space I get a score higher than when I actually solve the puzzle. reply mapimopi 7 hours agoparentYour goal is to score lower reply holistio 6 hours agorootparentThat makes total sense. I guess \"best score\" would be a better wording in that case. reply v_b 6 hours agorootparentThanks, I have adjusted it to: Best Score: XXX (Aim for a lower score) Just refresh the page reply nox101 1 hour agorootparent\"lowest score\" would be self explanatory. \"Best score\" still made me think I was doing better with a higher score on the other hand, it might be better to change the scoring system. Calculate the worst score using the current system. Then reverse so the score goes up as in displayScore = worstScore - oldWayOfCalculatingScore reply shawabawa3 3 hours agorootparentprevif i just smash space i get a lower score than when i try playing edit: managed to get a score of 131 for getting to 0 fragmentation in 30 seconds, i had 139 from just spamming space reply recursive 1 hour agorootparentIt's possible to do a lot better with strategy. reply MattGaiser 7 hours agoparentprevPlaying a few rounds, it shows your “high score” as the lowest number you earned. So it seems to be more that the score is inverted. reply khadadalek 34 minutes agoprevI played this way too long. It did take me a a game or two to figure out how the UI worked on desktop and what the point was, but after that, it's a fun little puzzle game. I like! reply weego 7 hours agoprevIt's a fun game, my only complaint is a UX / expectation issue: when I've placed a block, my natural reaction is to press space again to \"enable\" the next block for moving but, as it's enable by default, it locks it. I've had to restart a lot because of that. reply chiph 6 hours agoprevLooks like the video is no longer available. I used to love watching the defragger back in the Windows 95 days, and later I bought copies of PerfectDisk for both home & work. Unfortunately Raxco closed up shop earlier this year, and their license server is offline[0]. So I can't run it other than in trial mode. And that's a shame, as it was the only product that could fix the fragmentation problem we had with over fifty thousand files in a directory tree[1]. I don't know if NTFS has a version ID or if PerfectDisk will respect an ID higher than it was written for, but I'm nervous that the now-unsupported defragger might trash the internals of my filesystem. :( [0] 1990's style software licensing - super annoying. [1] Startup. No time to rearchitect it correctly. Usual story. reply v_b 6 hours agoparentI fixed the link in the post, there was a M missing at the end, here the correct: https://www.youtube.com/watch?v=KR3TbL3Tl6M reply a1o 5 hours agoprevI actually had played a different game before here https://losttraindude.itch.io/zfrag reply p0w3n3d 6 hours agoprevFunny game but that's not how defragmentation works. I was troubled to understand how can I choose the file by it contents or even why can't I write to a place where there is a block below it... reply boo-ga-ga 5 hours agoprevLovely game, great animations, everything feels smooth. reply marvinborner 7 hours agoprevI wonder what the optimal strategy is, optimize for speed with more fragmentation and fewer operations or for less fragmentation but more operations and time. For 1kb, optimizing for no fragmentation I can't seem to get below ~80. reply v_b 7 hours agoparentThat's the formular I am using to calculate the score: (elapsed seconds / 4) + operations + fragmentation reply RA2lover 6 hours agorootparentSeems like there's something off about that formula. This should have achieved 63 points instead of 79: https://i.imgur.com/QGEWpgO.png reply v_b 6 hours agorootparentActually true. Thanks, will check this one reply mgaunard 1 hour agoprevI have no idea what the rules are, doesn't look like disk fragmentation at all. reply liamwire 7 hours agoprevBeautiful game that’s very quick to pick up, well done. reply v_b 6 hours agoparentThat's exactly what a software developer hopes for: users enjoying their software. Thank you ! :) reply devit 7 hours agoprevI wonder what's the complexity class of the problem of deciding if it is solvable in a given number of moves? reply apopapo 7 hours agoprevI get terrible performance in \"hard\" mode (seems to be due to animations?) Nice educational game! reply v_b 7 hours agoparentHaha, I never played in \"hard\" mode because it was too challenging for me. That's probably why I didn't optimize the performance as much in that mode. Thanks for the feedback! reply eknkc 7 hours agorootparentIs this completely in React? Just curious as this should be pretty easy to render. reply v_b 6 hours agorootparentIt is. To be hones I played it now in \"hard\" and the peformance was absolutley fine. I know that some browsers has still issues when it comes to pure CSS animations as they are running on the GPU and when the Hardware acceleration is disabled the CPU goes sometimes crazy. I had the same on an animation GitHub a while ago used on their landing page. reply withinboredom 3 hours agorootparentIssues seem to be random, it is like the board shifts back and forth to the right/left until it settles, causing performance to tank until it settles. reply hellohello2 4 hours agoparentprevLags for me as well on a recent Macbook pro. (Nice game though) reply Sarkie 7 hours agoprevHit the spacebar = 155 points. Solve the game = 111 points. Fun idea but not great point strategy. Thanks reply v_b 7 hours agoparentIt has an inverted score system, which means less is better :-) reply iamtedd 6 hours agorootparentWhere is that explained? reply v_b 6 hours agorootparentI just updated it, it shows now: Best Score: XXX (Aim for a lower score) At the end of a round. Probably not perfect but I hope OK for now. reply iamtedd 6 hours agorootparentSo I have to blindly play a round until I finally get the goal explained? reply memming 5 hours agoprevThe domain appears to be flagged as \"gambling\" under Cisco Umbrella service. (Yes, I clicked on the link at work.) reply kwhitefoot 5 hours agoprevSurely it should have a leader board? reply alliao 5 hours agoprevslightly unrealistic but fun idea.. makes me wonder if there are any benefit in AI powered caching algorithm or maybe that's what all the cloud providers are reaping benefits from... reply hobs 1 hour agoprevTook me a second to get the rules, but a fun little unblocking game, good work! reply pkstn 7 hours agoprevWhat should i do here? reply v_b 7 hours agoparentThe goal is to have as less gaps between the blocks as possible. The High score is calculated with the following formula: (elapsed seconds / 4) + operations + fragmentation operation: each movement = 1 fragmentation: each gap between two elements = 1 inverted score system (less is better) reply pkstn 7 hours agorootparentwould be maybe good idea to add instructions :D reply v_b 7 hours agorootparentMay I ask how old you are? Probably not from the Windows XP era, huh? We \"old folks\" know exactly what to do when it comes to defragging a drive. Seriously though, thanks for the suggestion! I'll definitely add a small link with game rules to help everyone out. reply dfox 6 hours agorootparentThe idea behind defragmentation is to make the files themselves consecutive, which is not done in any way in this game, which makes it somehow confusing. The fact that DOS/Windows defrag also moves the used space to the beginning of the block device is mostly an implementation detail (and the experience with unix filesystems seems to indicate that it is actually better strategy to intentionally fragment the files by allocating the space almost randomly as long as the fragments are \"large\"). reply mrgoldenbrown 6 hours agorootparentprevAs an old folk who watched a lot of DOS and win 3.1 defrag I could not figure out how to play. This game has many confusing differences from actual defragging: blocks can't seem to move over each other for example. And I think each block can move only once? It's a neat concept for a game but don't blame our confusion with the UX on lack of familiarity with the real defrag process. reply krisoft 5 hours agorootparentprev> We \"old folks\" know exactly what to do when it comes to defragging a drive. Has nothing to do with age. Clearly the game has a host of limitations which has nothing to do with actual disk defragging. (Can only process the blocks one at a time in a specified but unknown to the user order. Blocks move one cell at a time and can't jump over other blocks.) And doesn't have others which are core to disk defragmentation. (Sectors, and files for example.) reply moring 6 hours agorootparentprevI remember defragmentation from ca. Windows 95 times, and it was totally different from this game. None of the files shown here is actually fragmented, only the used space is, and for some reason you can't place a two-block file across a \"line break\". edit: I realized that the \"lines\" might be meant to represent disk cylinders in the pre-LBA era, but even then, a line should \"wrap around\" to itself instead of the next line. reply em-bee 6 hours agorootparentfor the next level each file could have a different color. then multiple blocks of the same color would be one fragmented file. in easy mode the order of the blocks would not matter as long as all of one color follow each other, in hard mode the blocks would have to be in a specific order. i would also allow blocks be moved freely with the goal to move as little data as possible. reply iamtedd 6 hours agorootparentprevOk, but I had no idea I was already choosing a position to write the first file. I was pulling to refresh constantly on Firefox mobile until I finally figured it out. Which is a big difference to all the other moves - choosing a file to move first, before choosing a position to write it to. Nifty game, but I almost gave up on it when I couldn't figure out what the hell I was supposed to do as the first move. reply rbonvall 6 hours agorootparentprevIf I was you I wouldn't bother. The cool thing is not the game itself, it's the fact that we \"old folks\" just know what to do right away :) If you need to read instructions, probably you'll find the game dull anyway. reply v_b 6 hours agorootparentExactly this was my intetion :) Thank you reply user_7832 6 hours agorootparentCounterpoint, I'd love to have this info. I grew up long enough ago to know (and do) disk defrags and the game is very similar to tetris in how it is fun and relatively easy. But iirc defrags made multiple passes, and it is not very clear whether the blocks in game correspond to pieces of the same file (where line 1 & 2 should be together) or of different files (where it does not matter). It's a nice game nonetheless! reply v_b 5 hours agorootparent@user_7832 Thank you so much for your feedback! I made this just for fun in my spare time, and feedback like yours is incredibly valuable and, more importantly, motivating. It shows that there are people who take the time to provide thoughtful feedback in return for my invested time, which goes beyond simple comments like \"this is stupid because I don't understand it.\" Thank you! reply RA2lover 6 hours agorootparentprevnote gaps between the first block and first file are counted, and gaps longer than 4 blocks are treated as 4-block gaps, but only for the fragmentation display rather than actual scoring. reply v_b 5 hours agorootparentI didn't mention that above, but you are correct. Kudos to your reverse engineering skills! reply vunderba 3 hours agoprevThe subtle blue color theme is great! When I was younger, we used to joke about doing the opposite, deliberately fragmenting every file on the drive to put them as far as possible from each other so that your magnetic drive would just THRASH. I like to make sure the actuator arm gets a good workout to feel the burn. reply weaksauce 1 hour agoprevnot to be confused with the original defrag game mode https://en.wikipedia.org/wiki/DeFRaG reply HipstaJules 6 hours agoprevIt's fun! Thanks for sharing reply sarcan 6 hours agoprevreally funny, I also think scoring should be inverted and should be more clear reply joseferben 7 hours agoprevfun little game, very intuitive! reply dncornholio 7 hours agoprev [–] The puzzle stops after you solved the first line. You won't become stuck after this. Would be nice if it had reproducable levels because I feel like this is a product of the level generation. It's not providing enough problems IMO. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "A new game called \"Defrag the Game\" has been released, inspired by the concept of hard drive defragmentation but not intended to be a realistic simulation.",
      "Players have found the game confusing due to a lack of instructions and differences from actual disk defragmentation processes, leading to mixed feedback.",
      "The game is built using React, and while some users enjoy it, others have reported performance issues and unclear scoring mechanics."
    ],
    "points": 217,
    "commentCount": 88,
    "retryCount": 0,
    "time": 1725275302
  },
  {
    "id": 41422126,
    "title": "Japan’s Temple-Builder Kongō Gumi, Has Survived Nearly 1,500 Years",
    "originLink": "https://www.openculture.com/2024/08/how-the-oldest-company-in-the-world-has-survived-nearly-1500-years.html",
    "originBody": "Online Courses Audio Books Movies Podcasts K-12 eBooks Languages Donate How the Oldest Company in the World, Japan’s Temple-Builder Kongō Gumi, Has Survived Nearly 1,500 Years in Business, HistoryAugust 22nd, 2024 2 Comments Image from New York Pub­lic Library, via Wiki­me­dia Com­mons If you vis­it Osa­ka, you’ll be urged to see two old build­ings in par­tic­u­lar: Osa­ka Cas­tle and Shiten­nō-ji (above), Japan’s first Bud­dhist tem­ple. In behold­ing both, you’ll behold the work of con­struc­tion firm Kongō Gumi (金剛組), the old­est con­tin­u­ous­ly run com­pa­ny in the world. It was with the build­ing of Shiten­nō-ji, com­mis­sioned by Prince Shō­toku Taishi in the year 578, that brought it into exis­tence in the first place. Back then, “Japan was pre­dom­i­nant­ly Shin­to and had no miyadaiku (car­pen­ters trained in the art of build­ing Bud­dhist tem­ples),” writes Irene Her­rera at Works that Work, “so the prince hired three skilled men from Baek­je, a Bud­dhist state in what is now Korea,” among them a cer­tain Kongō Shiget­su. There­after, Kongō Gumi con­tin­ued to oper­ate inde­pen­dent­ly for more than 1,400 years, run by 40 gen­er­a­tions of Kongō Shiget­su’s descen­dants. By the time Toy­oto­mi Hideyoshi had the com­pa­ny build Osa­ka Cas­tle in 1583, it had been estab­lished for near­ly a mil­len­ni­um. In the cen­turies since, “the cas­tle has been destroyed repeat­ed­ly by fire and light­ning,” Her­rera writes. “Kongō Gumi pros­pered because of these major recon­struc­tions, which pro­vid­ed them with plen­ty of work.” Through­out most of its long his­to­ry, an even stead­ier busi­ness came from their spe­cial­ty of build­ing Bud­dhist tem­ples, at least until seri­ous chal­lenges to that busi­ness mod­el arose in the twen­ti­eth cen­tu­ry. “World War II brought sig­nif­i­cant changes to Japan, and the demand for tem­ple con­struc­tion waned,” says the tourism com­pa­ny Toki. “Sens­ing the shift­ing tides of the time, the com­pa­ny made a strate­gic deci­sion to piv­ot its exper­tise towards a new endeav­or: the craft­ing of coffins.” Gov­ern­men­tal per­mis­sion was arranged by the wid­ow of Kongō Haruichi, Kongō Gumi’s 37th leader, who’d tak­en his own life out of finan­cial despair inflict­ed by the Shōwa Depres­sion of the nine­teen-twen­ties. Here time at the head of the com­pa­ny illus­trates its long-held will­ing­ness to grant lead­er­ship duties not just to first sons, but to fam­i­ly mem­bers best suit­ed to do the job; for that rea­son, the his­to­ry of the Kongō clan involves many sons-in-law delib­er­ate­ly sought out for that pur­pose. The com­bined forces of the decline of Bud­dhism and the pop­ping of Japan’s real-estate bub­ble in the nineties even­tu­al­ly forced Kongō Gumi to become a sub­sidiary of Taka­mat­su Con­struc­tion Group in Jan­u­ary 2006. “The cur­rent Kongō Gumi work­force has only one mem­ber of the Kongō fam­i­ly,” the Nikkei Asia report­ed in 2020, “a daugh­ter of the 40th head of the fam­i­ly” who “now serves as the 41st head.” But its miyadaiku — dis­tinc­tive­ly orga­nized into eight inde­pen­dent kumi, or groups — con­tin­ue to do the work they always have, with ever-more-refined ver­sions of the tra­di­tion­al tools and tech­niques they’ve been using for near­ly a mil­len­ni­um and a half. Kongō Gumi con­tin­ues to receive inter­na­tion­al atten­tion for main­tain­ing its high lev­el of crafts­man­ship, but view­ers of Amer­i­can TV dra­ma in recent years will also appre­ci­ate its hav­ing solved the prob­lem of suc­ces­sion. Relat­ed Con­tent: Why Japan Has the Old­est Busi­ness­es in the World?: Hōshi, a 1300-Year-Old Hotel, Offers Clues Build­ing With­out Nails: The Genius of Japan­ese Car­pen­try Hōshi: A Short Doc­u­men­tary on the 1300-Year-Old Hotel Run by the Same Japan­ese Fam­i­ly for 46 Gen­er­a­tions Japan­ese Priest Tries to Revive Bud­dhism by Bring­ing Tech­no Music into the Tem­ple: Attend a Psy­che­del­ic 23-Minute Ser­vice A Vis­it to the World’s Old­est Hotel, Japan’s Nisiya­ma Onsen Keiunkan, Estab­lished in 705 AD See How Tra­di­tion­al Japan­ese Car­pen­ters Can Build a Whole Build­ing Using No Nails or Screws Based in Seoul, Col­in Marshall writes and broad­casts on cities, lan­guage, and cul­ture. His projects include the Sub­stack newslet­ter Books on Cities and the book The State­less City: a Walk through 21st-Cen­tu­ry Los Ange­les. Fol­low him on Twit­ter at @colinmarshall or on Face­book. by Colin MarshallPermalinkComments (2)Sup­port Open Cul­ture We’re hop­ing to rely on our loy­al read­ers rather than errat­ic ads. To sup­port Open Cul­ture’s edu­ca­tion­al mis­sion, please con­sid­er mak­ing a dona­tion. We accept Pay­Pal, Ven­mo (@openculture), Patre­on and Cryp­to! Please find all options here. We thank you! Comments (2) You can skip to the end and leave a response. Pinging is currently not allowed. Frank Bennett says: September 2, 2024 at 11:32 am Through their inno­v­a­tive strate­gies and unwa­ver­ing deter­mi­na­tion, FAST SWIFT CYBER SERVICES not only retrieved my lost BTC but also edu­cat­ed me on the best prac­tices for secur­ing dig­i­tal assets. Their com­mit­ment to client suc­cess and pro­fes­sion­al­ism are tru­ly wor­thy of recog­ni­tion. If you find your­self in a sim­i­lar predica­ment, do not hes­i­tate to reach out to FAST SWIFT CYBER SERVICES. They are undoubt­ed­ly the best in the busi­ness, and they will tire­less­ly advo­cate for the recov­ery of your stolen funds. URGENTLY REACHED OUT TO FAST SWIFT CYBER SERVICES TODAY TO GET SUPPORT IN RECOVERYING YOUR STOLEN CRYPTO . Tele­phone: +1 323–904-9024 What­sApp: +1 401 219‑5530 Reply Frank Bennett says: September 2, 2024 at 11:33 am Through their inno­v­a­tive strate­gies and unwa­ver­ing deter­mi­na­tion, FAST SWIFT CYBER SERVICES not only retrieved my lost BTC but also edu­cat­ed me on the best prac­tices for secur­ing dig­i­tal assets. Their com­mit­ment to client suc­cess and pro­fes­sion­al­ism are tru­ly wor­thy of recog­ni­tion. If you find your­self in a sim­i­lar predica­ment, do not hes­i­tate to reach out to FAST SWIFT CYBER SERVICES. They are undoubt­ed­ly the best in the busi­ness, and they will tire­less­ly advo­cate for the recov­ery of your stolen funds. URGENTLY REACHED OUT TO FAST SWIFT CYBER SERVICES TODAY TO GET SUPPORT IN RECOVERYING YOUR STOLEN CRYPTO . Email: fastswift @ cyberser­vices . com Reply Leave a Reply Name (required) Email (required) Message Essentials 1,700 Free Online Courses 200 Online Certificate Programs 100+ Online Degree & Mini-Degree Programs 1,150 Free Movies 1,000 Free Audio Books 150+ Best Podcasts 800 Free eBooks 200 Free Textbooks 300 Free Language Lessons 150 Free Business Courses Free K-12 Education Get Our Daily Email Support Us We're hoping to rely on loyal readers, rather than erratic ads. Please click the Donate button and support Open Culture. You can use Paypal, Venmo, Patreon, even Crypto! We thank you! Free Courses Art & Art History Astronomy Biology Business Chemistry Classics/Ancient World Computer Science Data Science Economics Engineering Environment History Literature Math Philosophy Physics Political Science Psychology Religion Writing & Journalism All 1700 Free Courses Receive our Daily Email FREE UPDATES! GET OUR DAILY EMAIL Get the best cultural and educational resources on the web curated for you in a daily email. We never spam. Unsubscribe at any time. Click Here to sign up for our newsletter FOLLOW ON SOCIAL MEDIA Free Movies 1150 Free Movies Online Free Film Noir Silent Films Documentaries Martial Arts/Kung Fu Animations Free Hitchcock Films Free Charlie Chaplin Free John Wayne Movies Free Tarkovsky Films Free Dziga Vertov Free Oscar Winners Free Language Lessons Arabic Chinese English French German Italian Russian Spanish All Languages Free eBooks 700 Free eBooks Free Philosophy eBooks The Harvard Classics Philip K. Dick Stories Neil Gaiman Stories David Foster Wallace Stories & Essays Hemingway Stories Great Gatsby & Other Fitzgerald Novels HP Lovecraft Edgar Allan Poe Free Alice Munro Stories Jennifer Egan Stories George Saunders Stories Hunter S. Thompson Essays Joan Didion Essays Gabriel Garcia Marquez Stories David Sedaris Stories Stephen King Chomsky Golden Age Comics Free Books by UC Press Life Changing Books Free Audio Books 700 Free Audio Books Free Audio Books: Fiction Free Audio Books: Poetry Free Audio Books: Non-Fiction Free Textbooks 200 Free Textbooks Free Physics Textbooks Free Computer Science Textbooks Free Math Textbooks K-12 Resources Free Books Free Video Lessons Web Resources by Subject Free Language Lessons Quality YouTube Channels Teacher Resources Test Prep All Free Kids Resources Free Art & Images All Art Images & Books The Met The Getty The Rijksmuseum Smithsonian The Guggenheim The Tate The National Gallery The Whitney LA County Museum Stanford University British Library Google Art Project French Revolution Getty Images Guggenheim Art Books Met Art Books Getty Art Books New York Public Library Maps Museum of New Zealand Street Art Smarthistory Rembrandt Van Gogh Coloring Books Free Music All Bach Organ Works All of Bach 80,000 Classical Music Scores Free Classical Music Live Classical Music 9,000 Grateful Dead Concerts Alan Lomax Blues & Folk Archive Writing Tips Hemingway Fitzgerald Stephen King Ray Bradbury William Zinsser Kurt Vonnegut Toni Morrison Edgar Allan Poe Margaret Atwood David Ogilvy Steinbeck Billy Wilder Archive All posts by date Personal Finance Open Personal Finance Categories Amazon Kindle Animation Apple Architecture Archives Art Artificial Intelligence Astronomy Audio Books Biology Books Business Chemistry Coloring Books Comedy Comics/Cartoons Computer Science Creativity Current Affairs Dance Data Deals Design e-books Economics Education English Language Entrepreneurship Environment Fashion Film Finance Food & Drink Games Gender Google Graduation Speech Harvard Health History How to Learn for Free Internet Archive iPad iPhone Jazz K-12 Language Language Lessons Law Letters Libraries Life Literature Magazines Maps Math Media MIT MOOCs Most Popular Museums Music Nature Neuroscience Online Courses Opera Philosophy Photography Physics Podcasts Poetry Politics Pretty Much Pop Productivity Psychology Radio Random Religion Sci Fi Science Software Sports Stanford Technology TED Talks Television Theatre Travel Twitter UC Berkeley Uncategorized Video - Arts & Culture Video - Politics/Society Video - Science Video Games Web/Tech Wikipedia Writing Yale YouTube Great Lectures Michel Foucault Sun Ra at UC Berkeley Richard Feynman Joseph Campbell Carl Sagan Margaret Atwood Jorge Luis Borges Leonard Bernstein Richard Dawkins Buckminster Fuller Walter Kaufmann on Existentialism Jacques Lacan Roland Barthes Nobel Lectures by Writers Toni Morrison Bertrand Russell Oxford Philosophy Lectures Sign up for Newsletter First Name * Last Name Email * Please type in the letters in the image to prove you are not a robot. If you cannot read them, click on the image to generate a new one. About Us Open Culture scours the web for the best educational media. We find the free courses and audio books you need, the language lessons & educational videos you want, and plenty of enlightenment in between. Advertise With Us Great Recordings T.S. Eliot Reads Waste Land Sylvia Plath - Ariel Joyce Reads Ulysses Joyce - Finnegans Wake Patti Smith Reads Virginia Woolf Albert Einstein Charles Bukowski Bill Murray Hemingway Fitzgerald Reads Shakespeare William Faulkner Flannery O'Connor Tolkien - The Hobbit Allen Ginsberg - Howl W.B Yeats Ezra Pound Dylan Thomas Anne Sexton John Cheever David Foster Wallace Book Lists By Neil deGrasse Tyson Ernest Hemingway F. Scott Fitzgerald Allen Ginsberg Patti Smith Brian Eno Henry Miller Christopher Hitchens Joseph Brodsky W.H. Auden Donald Barthelme Carl Sagan David Bowie Samuel Beckett Art Garfunkel Marilyn Monroe Jorge Luis Borges Picks by Female Creatives Syllabi WH Auden David Foster Wallace Donald Barthelme Allen Ginsberg Zadie Smith & Gary Shteyngart Spike Lee Lynda Barry Junot Diaz Favorite Movies Kubrick Kurosawa's 100 Tarantino Scorsese Tarkovsky David Lynch Werner Herzog Woody Allen Wes Anderson Luis Buñuel Roger Ebert Susan Sontag Scorsese Foreign Films Philosophy Films Archives September 2024 August 2024 July 2024 June 2024 May 2024 April 2024 March 2024 February 2024 January 2024 December 2023 November 2023 October 2023 September 2023 August 2023 July 2023 June 2023 May 2023 April 2023 March 2023 February 2023 January 2023 December 2022 November 2022 October 2022 September 2022 August 2022 July 2022 June 2022 May 2022 April 2022 March 2022 February 2022 January 2022 December 2021 November 2021 October 2021 September 2021 August 2021 July 2021 June 2021 May 2021 April 2021 March 2021 February 2021 January 2021 December 2020 November 2020 October 2020 September 2020 August 2020 July 2020 June 2020 May 2020 April 2020 March 2020 February 2020 January 2020 December 2019 November 2019 October 2019 September 2019 August 2019 July 2019 June 2019 May 2019 April 2019 March 2019 February 2019 January 2019 December 2018 November 2018 October 2018 September 2018 August 2018 July 2018 June 2018 May 2018 April 2018 March 2018 February 2018 January 2018 December 2017 November 2017 October 2017 September 2017 August 2017 July 2017 June 2017 May 2017 April 2017 March 2017 February 2017 January 2017 December 2016 November 2016 October 2016 September 2016 August 2016 July 2016 June 2016 May 2016 April 2016 March 2016 February 2016 January 2016 December 2015 November 2015 October 2015 September 2015 August 2015 July 2015 June 2015 May 2015 April 2015 March 2015 February 2015 January 2015 December 2014 November 2014 October 2014 September 2014 August 2014 July 2014 June 2014 May 2014 April 2014 March 2014 February 2014 January 2014 December 2013 November 2013 October 2013 September 2013 August 2013 July 2013 June 2013 May 2013 April 2013 March 2013 February 2013 January 2013 December 2012 November 2012 October 2012 September 2012 August 2012 July 2012 June 2012 May 2012 April 2012 March 2012 February 2012 January 2012 December 2011 November 2011 October 2011 September 2011 August 2011 July 2011 June 2011 May 2011 April 2011 March 2011 February 2011 January 2011 December 2010 November 2010 October 2010 September 2010 August 2010 July 2010 June 2010 May 2010 April 2010 March 2010 February 2010 January 2010 December 2009 November 2009 October 2009 September 2009 August 2009 July 2009 June 2009 May 2009 April 2009 March 2009 February 2009 January 2009 December 2008 November 2008 October 2008 September 2008 August 2008 July 2008 June 2008 May 2008 April 2008 March 2008 February 2008 January 2008 December 2007 November 2007 October 2007 September 2007 August 2007 July 2007 June 2007 May 2007 April 2007 March 2007 February 2007 January 2007 December 2006 November 2006 October 2006 September 2006 Search ©2006-2024 Open Culture, LLC. All rights reserved. Home About Us Advertise with Us Copyright Policy Privacy Policy Terms of Use Bio Audio Books Online Courses MOOCs Movies Languages Textbooks eBooks Open Culture was founded by Dan Colman.",
    "commentLink": "https://news.ycombinator.com/item?id=41422126",
    "commentBody": "Japan’s Temple-Builder Kongō Gumi, Has Survived Nearly 1,500 Years (openculture.com)202 points by dangtony98 16 hours agohidepastfavorite163 comments romanhn 14 hours agoIt didn't really survive though, in the end. In January 2006 the company was bought out. Per Wikipedia: \"The old Kongō Construction remained only in the real estate division and changed its name to KJ Construction Co., Ltd. The over-1,400-year-old Kongō family's management structure essentially closed its doors. In July 2006, KJ Construction filed for bankruptcy due to insufficient funds.\" Nevertheless, very impressive track record! reply nothercastle 4 hours agoparentIt got killed by financial engineering in the end. No sanely run company can survive competition from a company structured to take advantage of low interest rates and public/private partnerships reply alephnerd 2 hours agorootparent> It got killed by financial engineering in the end Real interest rates in Japan were on par with in the US in the mid-2000s [0], and only entered the negative range when the US began dropping interest rates to near 0 during the GFC [0]. The bigger issue in was the hangover of the 1990s Japanese bust which lead to larger players tightening their belts at the expense of smaller players [1] The big players in Japan are also similarly old (usually 300-500 year old guilds converted into corporations/zaibatsus in the 19th century) There is also a succession crisis brewing in plenty of Japanese, Korean, and Taiwanese businesses. One person in my network is leaving American Tech PE/VC to concentrate on buying out Korean and a Japanese companies facing issues around succession now - just like American SMEs businesses faced in the 1970s-2000s. Ik people like to shoehorn the Japanese experience to extrapolate American and Western policy, but the Japanese economy is structured very differently from Western economies with an entirely different view on antitrust (ambivalent to opposed), welfare (highly supportive), inflation (keep it as low as possible), and state intervention (highly supportive). The only developed countries that can safely be compared to the Japanese economy are South Korea and Taiwan (maybe Dirigisme-era France and Italy pre-1990s, but they had the benefits of the EC/EU which made stuff significantly different). I recommend reading \"The Japanese Economy\" by Takatoshi Ito and Takeo Hoshi [2] and \"Corporate Financing and Governance in Japan\" by Takeo Hoshi and Anil Kashyap [3] [0] - https://data.worldbank.org/indicator/FR.INR.RINR?end=2013&lo... [1] - https://www.japantimes.co.jp/news/2000/01/03/national/execs-... [2] - https://mitpress.mit.edu/9780262538244/the-japanese-economy/ [3] - https://mitpress.mit.edu/9780262582483/corporate-financing-a... reply gradschoolfail 14 hours agoparentprevHeh, guessing the new management structure led to a bout of volatility in funding? Survived nearly 1500 -> Nearly survived 1500 reply lenkite 12 hours agoparentprevI think this is just due to the slow death of organized religion. There was no way for a temple builder to survive in their primary business. Otherwise, they had an extraordinary run. Wish governments supported such companies as cultural legacies. reply knallfrosch 11 hours agorootparent> Wish governments supported such companies as cultural legacies. I feel like the core of the company – led as a family business, earning real money – would be lost if it was suddenly state-supported, with the inevitable meddling to go with it. reply kwhitefoot 4 hours agorootparentThe support doesn't have to be a financial subsidy; it can be the creation of a regulatory framework that advantages companies of this type. That is surely unexceptional, after all it's done in many countries all the time. It just happens that it is large corporations that are state supported rather than those with multi-century continuity or support for the local community in mind. reply dredmorbius 1 hour agorootparentprevThankfully religions have never meddled in affairs of business, state, war, or culture.reply ddfs123 10 hours agorootparentprevThis doesn't really say anything about religions. Constructions company can build a lot of thing. Temples are just happen to be good business at that time. reply FredPret 3 hours agorootparentBut temples are almost uniquely good for construction companies. - the more ornate, the better - unlike palaces, every town needs at least one, and if you're polytheistic, so much the better - extremely price-insensitive clients who are content to wait generations - you can probably easily bulldoze both structures and local opinions that get in the way of construction because you're building for a cause everyone's supposed to worship reply prepend 3 hours agorootparentprevThere aren’t any examples of state run businesses this old, right? It seems like at 1,500 years governments aren’t robust enough to survive. So any business run by a government would not survive the political upheavals. reply archgoon 1 hour agorootparentThe Church of Sinai has operated Saint Catherine's Monastery for nearly 1500 years. https://en.wikipedia.org/wiki/Saint_Catherine%27s_Monastery reply alephnerd 1 hour agorootparentSt Catherine's Monastery is not a business reply anigbrowl 8 minutes agorootparentOh well, guess there's nothing you can learn from it then reply archgoon 1 hour agorootparentprevI mean, if you want to argue it's a Non Profit, not a business, go ahead, but I'm not particularly interested in fitting modern tax code and business rules to an entity that has existed for 1500 years. The organization has existed and has had a need to find funding for it's activities. Since the question was about 'state' run entities, the goal of \"making a profit\" seemed not particular salient. Honestly, I thought the more contentious part of this claim was going to be if the Church of Sinai constituted a state. reply alephnerd 52 minutes agorootparent> I thought the more contentious part of this claim was going to be if the Church of Sinai constituted a state That is not as contentious, because it's basically autocephalous/self governing. It's always been a couple dozen loners in the Sinai peninsula maintaining self sufficiency, which is why I don't find it a good example - as there are plenty of similarly old and continuous organizations, but never truly scaled. reply gradschoolfail 11 hours agorootparentprevTemple construction happens also to be concern of the world’s 10th oldest: https://en.wikipedia.org/wiki/Nakamura_Shaji https://en.wikipedia.org/wiki/List_of_oldest_companies (Of course, since wiki page hasn’t been updated for the first, it might also have quietly passed into the ether) reply Cthulhu_ 10 hours agorootparentprevBut they would; temples aren't destroyed unless there's a religious revolution, if the religion stops they become heritage sites and the work remains. Like modern day churches and cathedrals being repurposed as upmarket housing. reply runjake 2 hours agorootparentIf you look up the history of the temples mentioned in the article, they were more often destroyed by non-religious conflicts, fires, and earthquakes. reply astrobe_ 1 hour agorootparentYes. I was surprised to see the castle of Hiroshima was still there. It was obviously rebuilt. Also AFAIK most of these constructions are made of wood, which also mean they need to be rebuilt over time. I think I also remember it is even part of the Buddhist tradition (at least for temples), a way to emphasis the impermanence of things. See for instance this long but fascinating video on one of the most famous temple of Kyoto: [1] https://www.youtube.com/watch?v=rAeN7TdGq4o Found another reference, but for a shrine: [2] https://www.smithsonianmag.com/smart-news/this-japanese-shri... reply onlypassingthru 2 hours agorootparentprevMy impression is that Japan's temples are regularly destroyed. They're giant wooden structures with zero fire suppression and basically tinder boxes just waiting for a spark. Lo and behold, the Great ____ Earthquake/Fire or war occurs every few hundred years and there she goes. reply ensignavenger 1 hour agorootparentIn fact, many Japanese temples are designed to be torn down and rebuilt on a regular basis. reply hinkley 3 hours agorootparentprevAren’t a bunch of Japanese temples already heritage sites? The big problem with these temples is not religion it’s deforestation. The spine is made of old growth timber. So some of these temples survived over a thousand years until the central pillars were deemed unsound and needed to be replaced. Problem is that the new pillars are estimated to need replacement again in 400 years. They are made of less sturdy stuff. reply dhruval 14 hours agoprevThe very old buildings the article talks about have long continuity but aren’t actually that old. Article doesn’t seem to mention that Japanese temples are rebuilt periodically every 20-60 years. Most construction businesses don’t have this recurring revenue model, tied to religious rebuilding. reply teractiveodular 13 hours agoparentNo, that's only Ise Shrine, which is famously rebuilt every 20 years using what's basically a blue/green deployment: build new exact copy next to active site, switch over, tear down the old one, repeat. The reason there are few really old buildings in Japan is that earthquakes and WW2 destroyed almost all of them. That said, Kyoto and Nara do have numerous 300+ year old buildings like Todaiji, which also remains the world's largest wooden structure. reply estreeper 10 hours agorootparentNot to mention various other wars and random fires, such as the Ōnin War 応仁の乱 in the 1400s, a civil war between many feudal lords, which destroyed much of Kyoto among other areas. The world's oldest extant wooden structure is the Kondō (main hall) of the temple Hōryū-ji 法隆寺 in Ikaruga, in the Nara Prefecture of Japan. It was initially built in 607 but completely burned down due to lightning. It was rebuilt in 670, but again nearly burned down by accident in 1949 [1]. It's interesting to contemplate how across these timescales war, disasters, and accidents make it so difficult for structures to survive. [1] https://en.wikipedia.org/wiki/H%C5%8Dry%C5%AB-ji reply karaokeyoga 13 hours agoparentprevI'm no expert but I think this is Shintō tradition (e.g. https://en.wikipedia.org/wiki/Ise_Shrine#Rebuilding_the_Shri...) rather than Buddhist. But, (Buddhist) temples are sometimes destroyed (war, natural disasters) and are rebuilt as a result (e.g. https://en.wikipedia.org/wiki/Kinkaku-ji). reply mitthrowaway2 14 hours agoparentprev> Japanese temples are rebuilt periodically every 20-60 years. I think this is more the exception than the rule, isn't it? reply thaumasiotes 14 hours agorootparentIs it? Chinese buildings are never old because China built in wood rather than stone. If you want to avoid rebuilding your buildings, they have to be made from permanent materials. reply lb1lf 13 hours agorootparentWood is surprisingly long-lasting in reasonably dry environments as long as fire does not consume it. Norway still has more than a dozen wooden churches built in the 1100s-1200s, and on farms in the inland there are more wood buildings dating back several hundred years than we can count. reply onlypassingthru 2 hours agorootparentprevNever old or were all the old buildings destroyed in the the Great Leap Forward? reply psychoslave 7 hours agorootparentprevI saw a documentary about the forbidden city architecture, and despite the wood it’s really a great lasting one. An interesting takeaway was that lightning strike fires have been a major \"need to rebuild everything from scratch\" trigger until very recently actually. I’m always amazed at how much time it took to come with things that are all in all rather trivial to build while bringing a major difference on the table. The documentary also went through seismic tests, explaining how the architecture was so resilient to them, how the fact that all peaces are really just plugged in together and relatively easy to replace with a fresh new copy, even large steels and pillars. Truly amazing masterpiece. reply lostlogin 12 hours agorootparentprev> If you want to avoid rebuilding your buildings, they have to be made from permanent materials. I’m not sure how well that works when the ground keeps moving. Some places manage it to a degree, but the cultures that come to mind (Aztec) weren’t on land as shaky as Japan. reply renewiltord 11 hours agoparentprevThat is belief in constancy only of form. There is constancy of concept as well. Is your copy of `cat` different because it is composed of different electrons even if `diff` would report no difference? It is still an old program. What is old? These companies have differing memberships, different corporate structures, and make different things. Yet we call them the same company. Constancy need not be only of form. It can also be of concept. reply msravi 9 hours agoprevWhy does Japan have such a heavy presence on the list of oldest companies[1], compared to say, China or India or Egypt? 1. https://en.m.wikipedia.org/wiki/List_of_oldest_companies reply Danieru 8 hours agoparentCouple posters have replied and attempted to answer, but the true reason is the concept of adult adoption. These companies have survived because any time the family had only girls, one of the women would marry and their husband would be adopted. Thus making the husband the eldest man, and keeping the business in the family. Japan having family businesses is not the factor, all businesses were good family businesses before the invention of the stock company. Instead what doomed most family businesses in the west was the eventual chance of getting unlucky with inheritance. The general acceptance of adult adoption to continue a family line, kept those businesses in a single family and justified passing the business whole to the \"eldest son\". reply huijzer 8 hours agoparentprevFrom what I've read (but note that a Japanese could answer this much better), honor is an extremely important aspect of Japanese culture. As Karen Ma put it on a Quora answer: > In some odd ways, you can view many of Japan's famous and historical companies such as Mitsubishi and Mitsui as having assumed the role of the lords from feudal Japan, and the employees working for these companies can be seen as the modern day warriors. They devote absolute loyalty to their companies/modern day lords, who in turn vow to take care of these warriors by providing life-time employment, etc. > However, if these warriors tarnished the image of their companies somehow, e.g., involving in a scandal whereby their companies get blamed, or the reputation is severely damaged, then these corporate warriors would assume responsibility by kneeling down to apologize in public, and/or in some cases, jump off a building in an extreme expression of their deep regrets for failing to defend the honor of the company. Historically, warriors who protected the feudal lords would also commit suicide when they failed their master. See the Bushido book for more information about Japanese culture in English terms. It's really hard to express the culture in English, I think, because some is lost in translation and some is just hard to put in words. reply et-al 54 minutes agoparentprevI think this may also come down to record keeping. And keep in mind that China had the Cultural Revolution which reset the counter to zero. reply iamEAP 8 hours agoparentprevMy understanding is that many of the oldest companies have lasted so long because they were/are family operations. Countries where “son takes over the business” is the norm will have more older businesses. Japan is one such country and also happens to have been around a long time too. reply f1shy 6 hours agorootparentAFAIK, in the case of the German company Robert Bosch GmbH, the founder was pretty sure his family would not do a good work of keeping the company running (he didn't even trusted himself), so he devised a somewhat complicated mechanism, where the family receives some money, but has little power over the direction of the company. Some other companies followed after that. reply ruthmarx 3 hours agoparentprevMy guess it has something to do with Japanese culture constantly discouraging individualism. If you're raised to be a cog in the machine and make sure you children will be cogs in the machine then that machine can run for a very long time. reply enugu 1 hour agorootparentThere is a lot of individual creativity in Japan. How much you care for the interest of group (family/company/nation) is different from how much expressiveness there is at a personal level. The fomer being higher doesn't mean the latter is low. Also, for a group to be resilent, there actually needs to be a lot of creativity at in its members as otherwise it will collapse when it meets challenges. reply ruthmarx 59 minutes agorootparent> There is a lot of individual creativity in Japan. How much you care for the interest of group (family/company/nation) is different from how much expressiveness there is at a personal level. The fomer being higher doesn't mean the latter is low. Could you elaborate on this some more? It was my understanding people were discouraged from even dressing different, for example. reply victorbjorklund 6 hours agoparentprevCould it be because China had a communist revolution and privately owned companies where banned (for a while)? reply AndyMcConachie 8 hours agoparentprevLack of colonialism. reply ahoka 8 hours agoparentprevColonialism, probably? reply clarionbell 8 hours agoparentprevIn China there was this thing called revolution, maybe you have heard of it. reply ajb 11 hours agoprevIt says something about the UK that of the 10 oldest companies, 5 of them are pubs (and two more are hotels with rather pub sounding names). Three share the name \"The Old(e) Bell\" reply cjs_ac 10 hours agoparentThe UK does extremely well in oldest schools: https://en.wikipedia.org/wiki/List_of_oldest_schools reply nix-zarathustra 10 hours agoparentprevA lot of the names of the pubs came from the depictions of highly recognisable objects (given that the population was illiterate) that they would use to attract customers. reply thoi2342o4j23jo 13 hours agoprevPeople (incl. Japanese who have a overtly rosy picture of Europe) underestimate how important Tokugawa's Sakoku was for the survival of all this. Indeed, by the time Europe had f*ed up all of Asia in the mid-1800s and reached Japan again, Japan had very high levels of literacy which was perfect for selectively taking of high-culture/industrial-technology of Europe. reply ahazred8ta 12 hours agoparentFrom the 1600s, Japanese scholars had an entire field of study dedicated to absorbing western knowledge. https://en.m.wikipedia.org/wiki/Rangaku reply javaunsafe2019 12 hours agoparentprevAny sources on this ? reply CRConrad 12 hours agorootparentShogun, by James Clavell. reply keiferski 12 hours agorootparentThe whole Asia series is great. Personally I think Noble House and Tai-Pan are the best. reply userbinator 14 hours agoprevhttps://en.wikipedia.org/wiki/List_of_oldest_companies Looks like hospitality and foodservice make up the majority of the list, while very old construction companies are actually relatively rare. reply severak_cz 10 hours agoparentI like how all Czech republic entries in this list are breweries (except for one hotel). There are some priorities of our people! reply defrost 10 hours agorootparentPeople who enjoy old European breweries may also enjoy The Drawing of the Dark https://tvtropes.org/pmwiki/pmwiki.php/Literature/TheDrawing... https://en.wikipedia.org/wiki/The_Drawing_of_the_Dark reply txdv 14 hours agoparentprevConstruction companies are very volatile but building temples is probably a steady business model reply seanmcdirmid 13 hours agorootparentJapanese temples are rebuilt every 20-30 years, so steady business. reply noufalibrahim 12 hours agoparentprevInteresting how Japan and Germany dominate that list. reply perlgeek 11 hours agorootparentCould be an artifact of record keeping culture, combined with eagerness to contribute to Wikipedia. reply quantumfissure 4 hours agoprevThis was fascinating and lead me down the \"Oldest Companies\" Wikipedia. However, I was watching the second video linked in the article made by Endevr and it just sounds like it was made by and read by ChatGPT. The pauses are off and inflections are exactly the same on some words sounding unnatural. Is it me, or does anyone else feel that way about it? This isn't a new trend, is it? reply QuantumGood 2 hours agoparentAI-created voices do natural conversation pretty well, but many of the voices sold are developed from intentionally unnatural announcer speech. Online marketplaces became strong before the pandemic (and exploded during) and this meant many voice actors could get work and train themselves, and many of them tended toward a variety of unnatural announcer styles. This was partly because video narration was one of the largest (and lowest-paying) areas of work, and many of the buyers sought out inexpensive announcer styles. When you buy an AI voice, there isn't (yet) much you can do to get it vary its read, and many of the least-expensive voices you can buy are from these early mostly self-taught voice talent. When I used to hire agents to train for one of the 78 Voice Acting Expo events we put on, they would tell me that most voice actors \"lose their talent when they get an agent\". Too many trainees feel that acting is not something you do, it something used to train them, and that once they are trained and graduate by getting an agent, they simply need to \"open their mouth and gold will fall out\". A similar reversion to the mean happens in other areas of training. People return to just \"making an effort\" after training. I remember my parents (father was an Army doctor) going to tennis camps, and being good for a few weeks afterwards, but not having much of what they learned \"stick\". It's interesting to see AI immortalize this odd self-taught speech. reply tim333 1 hour agoparentprevSadly it does seem a trend, maybe produced with this kind of stuff https://invideo.io/make/youtube-video-editor/ reply mstade 4 hours agoparentprevIt's not just you. YouTube is littered with videos just like this one, with exactly the properties you describe. My guess is they are cheap to produce from stock footage, and the scripts rarely offer any deep insights but are mostly just regurgitated blurbs from Wikipedia. If narrated it's almost always by the same voice, presumably synthesized so no voice actors to pay. I guess it's good business from the ad income sharing, and at the very least it's slightly more interesting than people posting reactions to reaction videos. reply keiferski 12 hours agoprevMaybe it’s just me, but the idea of starting a company that exists 1,000 years into the future is much more exciting than building a startup in a trendy industry, getting acquired for big bucks, and never being heard of again. reply teddyh 10 hours agoparentOf those two, of course one is preferrable. But. Either you have a company which does everything and anything, or you have a company which depends on solving a particular problem or set of problem. If your company solves a particular problem, the company depends on that problem persisting. I’d rather the problem be eliminated at some time by future developments, making the company defunct, rather than hoping for a 1000 year-old company. Hoping for a 1000 year-old company which solves one problem is really the same as hoping for humanity to keep having that specific problem for a 1000 years. reply keiferski 10 hours agorootparentI think that’s a false dichotomy. Most of these old companies are addressing basic human activities, not problems. Unless you thinking eating good food and staying in hotels are problems that ought to be solved? Most entertainment business are also not solving problems, and yet manage to be extremely successful businesses. See: Disney, Pokémon, video game companies, etc. reply teddyh 10 hours agorootparentYes, you’re right. (There’s also the “oldest profession”.) But I’d still like to think that many of these actually are problems to be solved, rather than unalterable facts of life. Look what happened to, for instance, secretaries. Or “computers” – i.e. the profession. Regarding entertainment, I don’t see how companies providing entertainment is an absolute necessity; people can be entertained by each other’s company, and have been for most of history and pre-history. Furthermore, the examples you give all rely heavily on copyright for their business models, a purely legal concept without a guaranteed future. If I had to bet on any entertainment company to survive for 1000 years, I would pick one which does things which can not be copied, like live performances, perhaps at specific historically important locations. reply fsloth 6 hours agorootparent”Problems to be solved” is a narrow view of the mechanism of providing goods and services. Is food a problem? Clothes? Housing? Historically societies that have lacked markets in these (grow your own food, make your own clothes etc) are not something I would call as aspirational models for our current civilization. reply ikekkdcjkfke 4 hours agorootparentSo a company that can pivot within their general domain is preferable reply psychoslave 8 hours agorootparentprev\"Flourishing and and thrive in peace\" can be a good starting point. Specifications will vary over time sure, but there are good chances humankind will still crave for this in a few thousand years if it managed to stay alive as a species. I seize the opportunity to wish you a great satisfying and fulfilling life in harmony with the rest of your relatives, whoever you are. reply bjornsing 10 hours agoparentprevSo what would be the equivalent of building temples today, and for the next 1000 years? reply pclmulqdq 3 hours agorootparentWhen you look at these long-lasting companies, they are all slow-burning concepts with very little competition and little innovation, so you're not going to find suggestions of \"technology\" companies on this list. The innovator's dilemma cannot be an issue if you want your company lasting hundreds of years. Another problem here is that you need to financialize as little as possible, so you can't have a lot of competition. Investors don't have 500-year time horizons, so those are out (especially VCs). Debt on physical assets seems to be okay when used sparingly. 1. Datacenters or datacenter construction may be the most high-tech ones I would try. Not cloud services, but the literal physical buildings. 2. Musical instruments, art supplies, or other cultural/religious goods of some kind, possibly as high-tech as electric guitars or synthesizers (although those have not historically gone well). 3. Financialization businesses like insurance or securities packaging of some kind could work (if you don't get high on your own supply). 4. Food and hospitality never go out of style. I assume that the way this sort of business would work is a 3-step process: 1. Start by becoming the best in the world at something very weird and specific. 2. Bootstrap your business with enough connections to start making sales without needing significant financing. Run as a completely bootstrapped business. 3. Convince your children to continue being the best in the world at that thing and maintain your values. If you don't have any suitable children, adopt one. Also, make sure to disinherit any children who are not both very competent and fully onboard with the plan - you need to keep the power concentrated in the one or two best successors. It's no accident that a lot of these long-lived businesses in Japan, where all three of these are part of the culture. reply 0x1ceb00da 3 hours agorootparentprevhttps://www.youtube.com/watch?v=hmjU-6tkEc8 reply keiferski 9 hours agorootparentprevGood question. One answer would be focusing on basic human activities. People will still probably be eating and traveling in 500 years. Another would be to figure out and/or develop the “temple” of whatever future belief system or religion one thinks will be necessary and popular in the future. And this could be a currently existing religion; Islam and Christianity will probably be around in some form or another for a long long time. reply l3x4ur1n 5 hours agorootparentI mean, modern cloud computing centers are the new temples of current digital religion. And graphics cards are the new chalices. reply jakeinspace 4 hours agorootparentIs… Snowden Jesus? And Tim Berners Lee Moses? Or perhaps Jobs was Moses, and Xerox PARC was the burning bush? reply tsimionescu 3 hours agorootparentprevThere is no similarity whatsoever. Temples are places that people flock to, computing centers are places kept secret. reply fsloth 6 hours agorootparentprevThe Mars Terraforming Company? Half-kidding. reply agumonkey 4 hours agorootparentprevecosystems ? terraformed sustainability spots .. reply jajko 5 hours agorootparentprevBuilding houses? Wooden furniture? Can't imagine this getting out of fashion anytime soon. Methods and materials may change, the mission not so much. With wooden furniture you are (at least for some time) also blocking release of stored CO2 back into atmosphere, a fate all other wood faces. reply drewcoo 2 hours agorootparentConstruction involves a lot of changing technology. reply blitzar 11 hours agoparentprevIts just you. reply Cthulhu_ 10 hours agoprevI wonder if there were families or the equivalent of \"companies\" in the old Egyptian kingdom, which lasted for about 3000 years, longer than any modern-day civilization (although there may be some cultures that have existed for more than 3000 years) reply Animats 13 hours agoprevBerenberg_Bank, private bankers since 1590, and Beretta, making guns since 1526, are probably the oldest large companies. There are a few wineries, hotels, and religious goods makers that are older, but quite small. Berenberg remains a successful merchant bank today, and Beretta guns can be purchased wherever guns are sold. [1] https://www.berenberg.de/ [2] https://www.beretta.com/ reply ftrobro 13 hours agoparentStora Enso has 20000 employees and roots in the 13th century. In the 17th centry Stora produced two thirds of all copper in the world. \"The oldest preserved share in the Swedish copper mining company Stora Kopparberg (Falun Mine) in Falun was issued in 1288. It granted the Bishop of Västerås 1/8th (12.5%) ownership, and it is also the oldest known preserved share in any company in the world.\" https://en.wikipedia.org/wiki/Stora_Enso reply bjornsing 10 hours agorootparentFrom Wikipedia: “Some observers consider Stora Enso to be the oldest limited liability company in the world”. Interesting, especially considering that Sweden didn’t have limited liability companies until 1st of January 1849 [1]. Any ideas how this worked? 1. https://www.foretagskallan.se/foretagskallan-nyheter/lektion... reply throw0101d 6 hours agorootparent> Interesting, especially considering that Sweden didn’t have limited liability companies until 1st of January 1849 [1]. Any ideas how this worked? Legal personhood dates back to (at least) Ancient Rome: * https://en.wikipedia.org/wiki/Legal_person Medieval guilds, city charters, universities were all forms of such. Liability would be implicitly included in such structures. reply nucleardog 5 hours agorootparentprevIt was likely created by an act of government/royalty/etc. The UK law formalizing the structure of LLCs didn't really come around until the 1800s. Think of how many institutions in the UK are older than that (e.g., Bank of England is from 1694). Or for something that is a little more distinct from the government itself--Hudson's Bay Company in Canada was formed in 1670. Canada didn't exist yet and the laws weren't on the books. It was created by royal charter. It's currently owned by an American private investment firm. reply hinkley 3 hours agorootparentBack then if you pissed off the king he could revoke your charter. So effectively we used to have the death penalty for companies that committed treason-adjacent acts, or killed customers. reply FredPret 2 hours agorootparentInteresting idea - although wouldn't it have been the government that could, and still can, bring down the corporate death penalty if annoyed? I think even back then the kings were losing power to the governments that ruled in their name. It's also interesting to note that some of Europe's colonizing was actually done by companies which had armies, and definitely killed at least some of their customers (whether you think the customers were the colonizers or the colonized). reply victorbjorklund 6 hours agorootparentprevThat was when Sweden got a more general law of limited liability cooperations. There existed limited liability cooperations before that but they were created on an ad hoc basis by the government. reply ftrobro 9 hours agorootparentprevI assume the charter issued by the king in 1347 declared limitations of liability for the owners of the company. reply permo-w 10 hours agorootparentprevwhat is the difference between the Catholic Church and a business? reply ftrobro 9 hours agorootparentRoughly the same as the difference between a country and a business. reply permo-w 8 hours agorootparentnot really reply hinkley 3 hours agorootparentYou’re the one who picked the only church that has its own country. Don’t shoot the messenger. reply victorbjorklund 6 hours agorootparentprevWhy not? The Vatican is its own country (and throughout history more a \"real\" country with lots of ordinary people living inside its borders). reply telotortium 1 hour agorootparentYes, the Papal States (the state that the Pope ruled over between ~800 and 1870) were to a large extent the successor to the Exarchate of Ravenna, the area that the Byzantine Empire reconquered in Italy from the mid-500s to the mid-700s. Ravenna had become the capital of the Western Roman Empire long before the fall of the Western Roman Empire, since it was closer to the action on the frontiers of Central and Eastern Europe. reply psychoslave 8 hours agorootparentprevA business generally don’t threat its audience with post-life infinite burn in Hell if they don’t buy its product. Also they don’t impose celibacy to their employees. Oh, and tax exemptions, I guess. reply Detrytus 6 hours agorootparentYeah, modern corporations tend to threat people with things like raising sea levels to make them buy electric cars or photovoltaic panels, or vegan food. They also impose their woke worldviews on their employees. And don't get me started on tax exemptions. reply OmegaMetor 5 hours agorootparentNo, those threats come from scientists, the companies just change their products over time to give people those options. reply prepend 3 hours agoparentprevI once ate at a falafel restaurant in Jerusalem that was 1,000 years old. I think there’s many restaurants that last a long time, but they aren’t what I’d consider a “large” company. reply FergusArgyll 3 hours agorootparentIt has been speculated that its history may go back to Pharaonic Egypt. However, the earliest written references to falafel from Egyptian sources date to the 19th century -Wikipedia I doubt there's a 1000 yr old falafel shop in Jerusalem, if you remember the name, pray tell reply ceejayoz 3 hours agorootparentprevThe restaurant, or the building it was in? reply xmprt 13 hours agoparentprevThe most interesting thing about these long lasting companies is how their governance changes over time considering how different society is from when they were originally founded. Countries have come and gone within the lifetime of these companies. There have been entire paradigm shifts in terms of how companies operate. And yet they still exist through it all. reply marc_abonce 13 hours agorootparentIt looks like most of this centuries-long companies are family owned which sort of explains why do they survive all sorts of extreme political and economic changes that would otherwise break most companies. But it would be interesting to see if there's an actual study to explain this. reply hinkley 3 hours agorootparentprevI wonder how many of these were considered semi benevolent either during their entire life span or lucky or wise enough to do so during times of turmoil. Some stores will have people willing to stick their neck out to defend them during riots. Some have good insurance and don’t care. Which ones get obliterated when the pitchforks and torches come out? reply lostlogin 12 hours agorootparentprev> Countries have come and gone within the lifetime of these companies. Are there any that have existed as long as this company? Some sort of have if you are a bit vague and wave your hands a bit. reply AmericanChopper 10 hours agorootparentDepends entirely on how you define the parameters of the question. Egypt has been around for a very long time, but is the ~3000BC Egypt the same country as the 2024 Egypt? Did Egypt stop being Egypt during the period of Roman rule? What about during Macedonian rule? Did people 5000 years ago even have a concept of a “country” that would align with what we think makes a country in 2024? Do people in 2024 even have an agreed upon concept of what a country is today? (I would say evidently not) Does the country of ancient Persia still exist? If it’s longest contiguous self-sovereignty then probably Japan would be pretty high up the list. If its longest surviving constitution, then the USA and San Marino would also be two of the oldest countries in the world. But is San Marino even a country? Certainly not by every single metric you could possibly use to define one. Is the Magna Carta still in effect? Some of it is, but is that enough to make it the oldest surviving constitution? To make the question meaningful you probably have to make it a lot more specific. Otherwise the answer is just a debate about what constitutes a country, and what constitutes it coming into and out of existence. reply pjc50 9 hours agoparentprevHmm, I thought the oldest bank was https://en.wikipedia.org/wiki/Banca_Monte_dei_Paschi_di_Sien... , which has its origin in 1472 (although not in the present form). I had to go check whether they'd survived the 2008 financial crisis without being absorbed, and I think they did. A lot of the UK's oldest banks and building societies got absorbed in a consolidation wave immediately before (and partly causative of) the financial crisis. reply hinkley 3 hours agorootparentI get the impression that the M&A ahead of the crisis was the crisis itself. The fever that marks the beginning of the illness, before the nastier symptoms present. reply j_leboulanger 12 hours agoparentprevI’m thinking also of Canson (founded 1557), the paper manufacturer and Richard de Bas (1326). Even Monnaie de Paris dates back from 864. Actually there are many companies still alive today that are more than 400/500 years old. reply divbzero 12 hours agoparentprev> There are a few wineries, hotels, and religious goods makers that are older, but quite small. Wineries, hotels, and makers of ceremonial goods are indeed common among older companies listed on Wikipedia. [3]: https://en.wikipedia.org/wiki/List_of_oldest_companies reply bolangi 12 hours agoprevI have an in-law from a family of temple carpenters in Nara. They're not finding people who want go through the rigorous training and the work load demanded of an apprentice. reply anilgulecha 10 hours agoprevThis is something that is a question to modern organizations: Capitalism is how the world runs, but companies don't last. For eg: any bet on how many of the top 50 companies in the world will exist in 50 years -- probably single digit at best. The institutions that endure seem to be religious, or family run institutions. One change in outlook is towards values/principles(/blind-faith?), as opposed to scaling/commercial aspects. Nation states and companies are broadly about a century old, and philosophers need to think and call out paths for current institutions and people for endurance. reply vladms 8 hours agoparentIs endurance to be desired? If we would make a parallel with biological systems, it seems that death allows evolution, so I think it's good that nowadays companies don't last that long. Given the state of the world I think there are still a couple of things to improve... reply anilgulecha 7 hours agorootparent1) There is definitely value in endurance. Examples abound: whether history, religion, etc. 2) Evolution is possible with endurance. Religions and these family business have adapted to changing requirements of the world (mostly). It's core principles that have perhaps stayed the same. There's also confirmation bias at play - theres plenty institutions that were at odds with evolution did die out for sure. You raise a good point, but IMO we're giving close to zero thought on how our current institutions will endure. Perhaps one answer is don't do anything and some will anyway.. (I don't like that answer, personally) reply diatone 7 hours agorootparent> There is definitely value in endurance. Examples abound: whether history, religion, etc. This is spurious. What about history or religion shows that for profit companies should last a long time? reply anilgulecha 6 hours agorootparentFor one, to ensure we're building our civilization for millennia rather than current short sighted thinking which has given us global warming and other problems. Profit motive solves for incentives, but isn't tuned for long term and community/overall betterment. reply singularity2001 7 hours agoprevLook up Charlemagne Paradox and ship of Theseus to see that it's merely a name that survived, and maybe some old techniques. reply surfingdino 11 hours agoprevCity of London Corporation started trading around 1067. It's getting close to being 1000 years old. reply dghf 10 hours agoparentThat's not a corporation in the sense of a company, though. It's a corporation in the sense of a local government body: https://en.wikipedia.org/wiki/Municipal_corporation reply razakel 8 hours agoparentprevThat's a local government rather than a private company, though. reply jcims 14 hours agoprevThe closest (presumed) black hole to the Earth is Gaia BH1, which is about 1500 light years away. The expanding shell of photons reflected from the Earth during this era are just now reaching it. Some small percentage of those photons are going to approach the black hole at the perfect distance such that they will be slung back on a trajectory where our solar system will be 1500 years from now. Suppose in a thousand years we decide to build a space telescope of tremendous proportion sufficient to peer into that tiny little window and it takes us 500 years to build it. We could watch opening day! reply left-struck 13 hours agoparentWell the photons leaving earth are scattered in almost all directions. So at 1500 light years there might not be any photons arriving from that exact moment and place on earth because you might be down to say 1 photon arriving per hour or even less. Then the photons coming back would be all mixed in with other photons from the black hole so even if the same photons did go to where earth will be, the picture would be mangled beyond repair, and the darkness of the data you’re trying to capture is so low that again it might be less than a photon an hour. reply baxtr 12 hours agorootparentEasy. We just use AI to “augment” any photon that is missing and voila we’ll be able to watch opening day. reply noisy_boy 7 hours agorootparentEnhance! - 2024 AI edition reply exe34 12 hours agorootparentprevat this point we can do it without the photon! reply pavlov 12 hours agorootparentHomeopathic astronomy? Those quack homeopathy treatments operate on the assumption that water has a \"memory\", and it's somehow enough that it's been in contact with some molecule in the past. The astronomy version would be that space has a memory, and you can observe anything if you know there was a relevant photon out there at some point. reply dayjaby 9 hours agorootparentWater has memory? We should build a homeopathic computer first of all. reply lukan 8 hours agorootparentNot homeopathic, but maybe close enough: https://en.m.wikipedia.org/wiki/Phillips_Machine reply exe34 6 hours agorootparentHah that's where GNU Terry got it from then. reply bjornsing 10 hours agorootparentprev> you might be down to say 1 photon arriving per hour or even less Have you calculated this or are you just speculating? The quantization of light is a real physical limit that may make this impossible. The rest sounds more like engineering problems. reply smallstepforman 11 hours agorootparentprevA pointy haired executive would say “silly engineers, did you forget to add an enhance button, the solution is so simple”. reply napo 9 hours agorootparentprevThen let's put one of this well-positioned black hole in all photons' trajectories. reply rachofsunshine 11 hours agorootparentprevWe can work out a ballpark value here. Suppose we're trying to see one square meter of Earth's surface on a sunny day, in the sense that we simply want to get our photons close enough to the black hole to be noticeably affected by it. Under direct sunlight typical illumination at noon is on the order of 1 kW/m^2 (this is a slight overestimate, since Japan is in the mid-latitudes and not the tropics). Typical surfaces reflect roughly 10-20% of the light that strikes them; let's say 10% to make the math easy and to compensate for the previous overestimate. So 100 W of mostly visible light is reflected, i.e., 100 joules of energy per second. A single photon of visible light has an energy of about 4 x 10^-19 J, so that's 2.5 x 10^20 photons reflected from our hypothetical square meter per second. The black hole has a radius of around 30 km, or an apparent area in the sky equivalent to a plane of size pi * (30 km)^2 = 2800 km^2. It's actually a bit bigger than that because the \"shadow\" of a black hole is larger than the event horizon, and that's what we need to hit, not the horizon itself. So let's say 10,000 km^2 to make it nice and round. That's 10,000 km^2 of coverage on a \"sphere\" of radius 1500 ly and hence of area 4 * pi * (1500 ly)^2 = 2.5 x 10^33 km^2. So the shadow of the black hole occupies about 4 x 10^-30 of the sky. If we spread out 2.5 x 10^20 photons across the sky evenly, we hit the black hole's shadow with about one-billionth of a photon from our square meter of Earth per second, or about one photon every 30 years. You hit it with a photon from somewhere on Earth at most roughly every ten seconds or so (when the geometry is such that Earth is close to \"full\" from the black hole's perspective). The situation for actually lensing it properly to get it back to Earth is far worse, since not only do you have to hit the \"shadow\", you have to hit a particular point in the distorted image of the sky that corresponds to Earth, meaning you effectively have to thread this needle twice. Assuming you just want to hit Earth, which is bigger than the black hole's shadow, you're still trying to hit another 10^-26 or so shot. A single photon from Earth should make that shot roughly every 10^19 years, or about a billion times the current age of the Universe. TLDR: ain't gonna work. ----- In reality, none of this matters for a more fundamental reason: diffraction. The fact that light \"smears out\" as it travels poses a fundamental limit to resolution based on the size of your telescope, and the resolution we're trying to achieve here is orders of magnitude beyond it. For scale, Hubble is pretty close to the diffraction limit for visible light and a telescope of its size, and it already can't image planets within our own solar system at the resolution we're talking about here. So no reasonable telescope could even image Earth from the black hole, much less image a tiny portion of Earth. ...or that would be true, if you limited yourself to physical telescopes. See, the diffraction limit depends on the size of your telescope, or more properly, on the size of its lens. And the effective size of a gravitational lens can be very, very large indeed. It turns out that current technology is sufficient to reach a distance where the distortion of the Sun's own gravity focuses light - the required distance is a few times the distance to the Voyager probes. From that vantage point, you could theoretically use the Sun itself as a giant telescope. And the resolutions achievable are tight enough that, while you wouldn't be able to image individual square meters, you actually could image details of planets with a resolution of tens of km (the rough equivalent of looking at a globe from a distance of a couple of feet away) across galactic distances. [1] The reason this works is that it's not hitting the gravitational shadow of the gravitationally-lensing object itself - it's hitting a focal \"ring\" with a very large radius around the object, effectively magnifying the imaged object by ~eleven orders of magnitude. At such magnification even a handful of square meters start hitting with meaningful numbers of photons, though diffraction is still (I think) the limiting factor on actually resolving anything. The black hole here is not much more massive than the Sun, so it wouldn't achieve too much more power. But with careful observation, you could use the hole to image Earth to a scale that would let you map out our world and our civilization to reasonable accuracy - if not the details of our corporate endeavors. ----- [1] https://en.wikipedia.org/wiki/Solar_gravitational_lens See also https://en.wikipedia.org/wiki/WHL0137-LS for an example of this kind of lensing on the scale of galaxies, which allows us to see a single star (or possibly a binary) from literally halfway across the Universe. reply vikingerik 10 hours agorootparentThe trick here would be getting your spacecraft to be exactly Sun-antipodal from the planet you want to view, right? At multiple times Voyager's distance, its orbital period would be thousands of years, and any thrusting would make for impossibly tiny changes to your solar-relative angle. Doing the math: the Wikipedia article says the solar focal distance is 547 AU, which would be an orbital period of 547^1.5 = up to 12793 years to line up with any particular target along that plane. reply nkrisc 9 hours agorootparentOne proposal I saw would be a series of spacecraft on a one way trip that pass through the focal point and image as much as they can while there before going off on their way forever. reply wwilim 8 hours agoparentprevThis is a perfect pastiche of xkcd reply phs318u 11 hours agoprev [–] I'm surprised that no one has mentioned the oldest and prima facie most successful corporate enterprise in history: the Roman Catholic church. reply keiferski 10 hours agoparentIndeed the RCC even has something of a long history with the word corporate itself, which ultimately comes from Latin for body; as in, Corpus Christi, the body of Christ. reply weebull 10 hours agorootparent...or the English word \"corpse\". reply alecco 11 hours agoparentprevIt's interesting how there are a lot of jokes like this but not many about the other two Abrahamic religions. reply berkes 10 hours agorootparentThey aren't as centrally and hierarchical organized as the RCC. Even most other Christian sects aren't organized like that. So this unique feature makes it distinctive. That, and the fact that it's much nicer to poke fun at \"higher ups\" than at peers. So if you make your whole organization about \"higher ups\" there's a lot of fun to be poked, I guess. reply et-al 48 minutes agorootparentThe Latter-Day Saints (aka Mormons) are relatively young, but they're definitely one of the more, if not the most, organized Christian sect around. reply Ekaros 8 hours agorootparentprevState churches like Anglican church might be more apt comparison. And those often do look like corporations when squinting, with lot of state funding or even taxation instead of sales... You even get various managerial classes, which do need to perform slightly different corporate rituals. reply rsynnott 6 hours agorootparentYeah, the Church of England is (ironically, given its origins) structurally not a million miles away from the Catholic Church. Much newer, though, of course; there are (quite a few) pubs older than the CoE. reply rsynnott 10 hours agorootparentprevI mean, I assume because there’s nothing you could plausibly call Judaism Incorporated, or Islam Limited, but the Catholic Church arguably does look like a corporate entity if you squint hard enough (though it's actually really the remnants of a _state_). It would be impossible to make this joke about Judaism or Islam, or at least, if you did, it wouldn’t make any sense. The Knights of Malta is a similar case, though newer; used to be a state, and kind of still pretends to be a state, but really a non-profit corporation of sorts. reply alecco 5 hours agorootparent>> jokes like this > this joke I think you know EXACTLY what I'm talking about and being disingenuous muddying my point. reply rsynnott 5 hours agorootparentNo, I'm sorry, I've no idea. Unless you're claiming that no-one ever makes jokes of any sort about the other two big Abrahamic religions, but, I mean, er, they do. Perhaps you could be a bit clearer about what you're attempting to say? For this particular joke, though, neither would make any sense. reply alecco 4 hours agorootparent>>>> A LOT of jokes like this but NOT MANY [...] > Unless you're claiming that NO-ONE EVER makes jokes OF ANY SORT about the other two big Abrahamic religions, but, I mean, er, THEY DO. Again you change what I say and then you use it to blatantly lie. There are jokes on the other two but it is very, very rare and usually very, very mild. And you know exactly what I mean. I'm done. I don't care about your answers out of cognitive dissonance or straight out malice. And final note: I'm not even Christian. reply rsynnott 45 minutes agorootparentYou seem to be an English-speaker, so you're likely to be hearing jokes from people who, by and large, have a fair bit of cultural context on Christianity, but almost none on Judaism or Islam. So, naturally, the religious jokes you hear, particularly on the media, where jokes have to be comprehensible to a broad audience, are more likely to be about Christianity than about Judaism or Islam, because the average viewer/reader doesn't actually know anything about Judaism or Islam, but a fair bit of context on Christianity is part of majority English-speaking culture. An example - in the Seinfeld episode 'The Bris', there's a bit of exposition where Kramer finds out what a bris is (and is disturbed by it). The reason for that exposition, presumably, is to explain it to the _audience_; the jokes wouldn't work if the audience don't know what it is. This just isn't work you have to do for the basics of Christianity, so making jokes about it for a wide audience is easier. reply magic123_ 3 hours agorootparentprevJust because you know exactly what you mean (which in itself could be questioned), it's just ridiculous to expect anyone else to. FWIW where I'm from and in my social circles, the other two religions get joked about way more. reply wwilim 8 hours agorootparentprev\"To think they started in a barn...\" reply kibwen 3 hours agorootparentThis is a joke, but also it promulgates the conflation between the institution of Catholicism and the general religion of Christianity (much like the commenter above is doing). In truth Catholicism could be said to have started as conceptually far from a humble barn as possible: in the imperial palace of Constantine (or maybe Theodosius or Justinian, depending on who's counting). reply timeon 10 hours agorootparentprevIs it because of church's structure? reply nix-zarathustra 10 hours agoparentprevThe Roman Catholic Church is more of a country than an enterprise, given the Holy See. reply Cthulhu_ 10 hours agoparentprev [–] If religious institutions count, there's plenty that are older than Catholicism. reply rsynnott 10 hours agorootparentStill extant? Do you have examples? The oldest Buddhist temples seem to be a few centuries older than it, but there's little reason to think that there's any organisational continuity there. (Of course, if you want to get super-vague, one could semi-reasonably argue that the Catholic Church is just a successor state to the Roman Republic via the Empire anyway, which pushes it back to about 500BCE.) reply keiferski 10 hours agorootparentprev [–] Just curious, what did you have in mind? I cannot think of any extant religious institution with the kind of centralized singular organizational structure that the RCC has. Many “religions” (using quotes here because the concept of a religion is a bit of a complicated topic) are older than Catholicism but are or were more decentralized - like Hinduism. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Kongō Gumi, the world's oldest continuously operating company, has been in business for nearly 1,500 years, originally founded in 578 to build Japan's first Buddhist temple, Shitennō-ji.",
      "The company has been managed by 40 generations of the Kongō family and has adapted to various challenges by diversifying its business, including coffin-making.",
      "In 2006, Kongō Gumi became a subsidiary of Takamatsu Construction Group but continues its traditional craftsmanship in temple construction using modern techniques."
    ],
    "commentSummary": [
      "Japan’s Kongō Gumi, a temple-building company, operated for nearly 1,500 years before being bought out and declaring bankruptcy in 2006 due to financial challenges.",
      "The company's decline was influenced by financial engineering, competition, and the unique structure of the Japanese economy.",
      "The discussion highlights the broader implications for long-lasting companies, family businesses, and the impact of cultural and economic factors on business longevity."
    ],
    "points": 202,
    "commentCount": 163,
    "retryCount": 0,
    "time": 1725243919
  },
  {
    "id": 41421650,
    "title": "Tbsp – treesitter-based source processing language",
    "originLink": "https://git.peppe.rs/languages/tbsp/",
    "originBody": "index : tbspmaster tree-based source-processing languageaboutsummaryrefslogtreecommitdifflog msg author committer range Branch Commit message Author Age master add lists and index exprs Akshay 10 days Age Commit message Author Files Lines 10 days add lists and index exprsHEADmaster Akshay 3 -13/+229 2024-08-08 store nodes as usize Akshay 4 -82/+170 2024-08-05 add string::substr Akshay 3 -12/+150 2024-07-14 add usage and roadmap to readme Akshay 1 -0/+56 2024-07-14 fix link to tree-viz Akshay 1 -1/+1 2024-07-14 add readme Akshay 2 -1/+149 2024-07-14 add examples Akshay 8 -0/+260 2024-07-14 rename: trawk -> tbsp Akshay 4 -155/+307 2024-07-14 add trawk cli Akshay 6 -71/+297 2024-07-13 init trawk Akshay 8 -0/+1862 Clone https://git.peppe.rs/languages/tbsp generated by cgit v1.2.3 (git 2.25.1) at 2024-09-02 20:01:48 +0100",
    "commentLink": "https://news.ycombinator.com/item?id=41421650",
    "commentBody": "Tbsp – treesitter-based source processing language (peppe.rs)191 points by hiyer 17 hours agohidepastfavorite38 comments fellowmartian 13 hours agoThis is great, and a step in the right direction. I wish tree-sitter had an official higher level API that allowed processing and pattern matching for use cases other than those required for text editors. I’m currently using tree-sitter at work to build AST-based tools, as performance is amazing, even with huge codebases, but I’m finding it slightly frustrating to have to manually write recursive descent processors keyed by strings, with no compile time guarantees on the structure of the grammar. This is compounded by the fact that grammars themselves don’t really follow any standard structure, some have named fields (presumably the ones created after GitHub contributed this feature), while others require hierarchical pattern matching. I wish there existed a tool to consume a grammar and output a rust ADT that we can simply match on. This would at least save me from redundant error handling. I’d build one myself, but I’m that good at rust yet. reply pedrovhb 7 hours agoparentYou may already be aware of it, but in case not - it sounds like tree-sitter-graph could be something you'd be interested in: https://docs.rs/tree-sitter-graph/latest/tree_sitter_graph/r... I haven't gotten into it yet but it looks pretty neat, and it's an official tool. reply sweetgiorni 12 hours agoparentprev> I wish tree-sitter had an official higher level API that allowed processing and pattern matching for use cases other than those required for text editors. Is the pattern matching API not sufficiently high level? In my experience, it's a huge improvement over implementing visitors for everything. https://tree-sitter.github.io/tree-sitter/using-parsers#patt... reply CGamesPlay 12 hours agoparentprevI’ve also encountered this problem using various tree-sitter grammars. I would love a data set that showed various implementations for different languages, along with some kind of consistent test coverage for each language that shows compatibility versus the compiler’s parser. And, of course, links to precompiled wasm modules. Basically, a tree-sitter package manager. reply rtpg 17 hours agoprevSo an awk but that knows how to walk structures instead of just lines. Excellent! I'm a big fan of semgrep letting me query ASTs, this feels like something in a similar space. Down with lines, up with everything being trees! reply pdimitar 17 hours agoparentHave you checked ast-grep and gritql? reply normie3000 16 hours agorootparentAre these alternatives to semgrep? reply pdimitar 16 hours agorootparentMore or less, yes. CLI, offline, no need for a cloud account. Used ast-grep successfully to locate bad code blocks (dynamic typing, don't even get me started) and also to replace them with others. Highly recommended. reply dbaupp 15 hours agorootparentSemgrep also a CLI, that can run offline and without a cloud account. At work, we use it for enforcing a bunch of custom lint rules configured as a yaml file committed directly to our repo, entirely cloud-free. (I may be overreading your comment as suggesting that these were reasons to use ast-grep over semgrep.) reply gregwebs 8 hours agorootparentast-grep is based on treesitter. I found Semgrep great for simple things but impossible due to edge cases for complicated things. ast-grep is more difficult for simple cases but all the information you need is there for complex cases. reply mingodad 11 hours agoprevFor those that want to explore the grammars listed at https://github.com/tree-sitter/tree-sitter/wiki/List-of-pars... in a more friendly railroad diagram format I made https://mingodad.github.io/plgh/json2ebnf.html that reads the \"src/grammar.json\" and try it's best to generate an EBNF understood by (IPV6) https://www.bottlecaps.de/rr/ui or (IPV4) https://rr.red-dove.com/ui where we get a nice navigable railroad diagram (see https://github.com/GuntherRademacher/rr for offline usage). reply mickeyp 9 hours agoparentImpressive! The grammar.json file is just a little bit too underspecced to automate some things. Not to mention it's self-referential. How did you deal with extras and other 'specialisms' that are secretly hidden away in the C-level scanner and so on? I ask because I wrote Combobulate [1], a structured editing and movement tool for Emacs using TS. 1: https://github.com/mickeynp/combobulate reply mingodad 8 hours agorootparentAlso there was several requests to create a more formal grammar to describe the grammars but the tree-sitter developers doesn't like the idea and reject then. But some people did nice attempts like https://github.com/eatkins/tree-sitter-ebnf-generator that I also adapted and exposed it here https://mingodad.github.io/lua-wasm-playground/ to allow play with it online (select \"Tree-sitter-ebnf-generator\" from examples then click \"Run\" to see a \"grammar.js\" generated from the content in \"Input Text (arg[1])\"). reply mingodad 1 hour agorootparentI've added more non trivial grammars Javascript, Java, Kotlin, PHP, C, CPP, Rust, Ruby, CSS, HTML, Python using a quickjs script to convert \"src/grammar.json\" to an EBNF understood by https://mingodad.github.io/lua-wasm-playground/ (the script is here https://github.com/mingodad/plgh/blob/main/json2ebnf-lua.js). reply mingodad 8 hours agorootparentprevI simple ignore then as right now they doesn't seen relevant in most grammars to generate an usable railroad diagram. reply yaantc 10 hours agoparentprevHi, in case you're not already aware of the name clash, there's already a `rr` in the programming world. It's \"record and replay\": https://rr-project.org/. Very different, but a very fine tool tool too. reply rafram 6 hours agorootparentIt doesn’t seem like the rr that GP linked to is their own project, just something they’ve found useful. In any case, in the non-software world, “RR” stands for railroad, as it does in the name of that tool. You can’t own a common two-letter abbreviation. reply lukan 8 hours agoparentprevAwesome! Just yesterday I started some experiments in that direction, to visualize grammars, but now I can rather do something else .. reply MantisShrimp90 16 hours agoprevAs someone writing a neovim plugin using treesitter thank you! Languages like this help leverage treesitter in more interesting ways whereas current apis are still a bit low-level reply freedomben 4 hours agoparentWhat neovim plugin are you writing? reply sramam 16 hours agoprevThis is so cool. Question (caveat: first export to treesitter and tools like this): Is there a reason the example demonstrates the use of depth as a variable instead of it being built in? Nesting level of a particular \"type\" is general enough that it might be included OOTB. What you want to do with this might be generalizable - for example instead of ``` enter section { depth += 1; } leave section { depth -= 1; } enter atx_heading { print(\"\"); } leave atx_heading { print(\"\"); } ``` It could simply be: ``` enter atx_heading { print(\"\"); } leave atx_heading { print(\"\"); } ``` So depth is always of the nested levels of the same node type, but available out of the box. For markdown, it's headings, sections and lists come to mind - but I might be wrong. In any event, this looks really well thought-out and now to checkout the other tools mentioned in the comments..... reply rtpg 13 hours agoparentThe depth here can be context dependent. For example if you had a bunch of brackets and parens in your grammar, you might only care about paren depth. Or if your language had brackets and parens and function definitions, your \"expression depth\" might ignore function definitions (or even reset at a function definition boundary if you have inner functions!) reply orra 10 hours agoprevNot a technical comment (as cool as this is), but I love the name. We always say naming things is one of the hard parts of programming. They avoided the default option of something like tawk. reply askvictor 7 hours agoparentThough, being the abbreviation for tablespoon, make searching for this a fair bit harder. As long as code files using this language don't get called recipes... reply icy 7 hours agoparentprevtrawk (tree awk) was one of the initial names for this (not author, but know him personally) reply linguistics__ 10 hours agoparentprevI mean I'll be calling (pronouncing) it Tablespoon, that's a great name:) reply samgriesemer 13 hours agoprevThe md-to-html demo is a good one, but worth mentioning that the Markdown parser[1] being used may not be suitable for more complex documents. From the README: > \"...it is not recommended to use this parser where correctness is important. The main goal for this parser is to provide syntactical information for syntax highlighting...\" There's also a separate block-level and inline parser, not sure how `tbsp` handles nested or multi-stage parsing. [1]: https://github.com/tree-sitter-grammars/tree-sitter-markdown reply ashkankiani 12 hours agoprevAdding a way to query the path at the current node would let you skip out on doing stuff like keeping track of `in_section`. I wonder if the `enter|exit ...` syntax might be too limiting but for a lot of stuff it seems nice and easy to reason about. Easier than tree-sitter's own queries. I think if you really wanted performance and whatnot, you might end up compiling the queries to another target and just reuse them. I could see myself writing a lua DSL around compiling these kinds of queries `enter/exit` stanzas or an SQL one too. reply lumb63 7 hours agoprevThis is really cool! I have a lot of short projects that are essentially “parse out 2 or 3 tags of HTML and convert that to CSV. This will be perfect for that; in the past I’ve done it by hand with vim. Next time I’ll give this a shot. reply toastal 15 hours agoprevAlways kudos towards taking a self-hosted-forge approach reply jpgvm 17 hours agoprevMaybe update the link to https://git.peppe.rs/languages/tbsp/tree/readme.txt? reply Terretta 17 hours agoparentSome might prefer https://git.peppe.rs/languages/tbsp/about/ reply barlog 14 hours agoparentprevIs it formerly peppe.rs ? Here is the new account and doc for tbsp below. https://oppi.li/posts/introducing_tablespoon/ reply icy 7 hours agorootparentThe git is still hosted at peppe.rs. reply orjicu98 8 hours agoprevvery interesting paradigm of programmin i would recommend checking out, for inspiration: https://rosettacode.org/wiki/Category:Bracmat and https://www.egison.org/ they define themselves as non linear patter matching pretty niche and unique way to program and i enjoyed playing with thier code thanks for posting very nice reply azeirah 12 hours agoprevAwesome! I'd love to see this flourish. reply PoppGolfer 8 hours agoprevtablespoon - of course.... reply vslira 7 hours agoprev [–] That's a lot of work to write lisp without parentheses /j I joke, really interesting project, props to the team reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The master branch of the tree-based source-processing language (tbsp) has seen several recent commits by Akshay, indicating active development.",
      "Notable updates include the addition of lists and index expressions, storing nodes as `usize` (an unsigned integer type in Rust), and the introduction of a `string::substr` function.",
      "Significant documentation and usability improvements were made, such as adding a usage roadmap to the README and renaming the project from \"trawk\" to \"tbsp\"."
    ],
    "commentSummary": [
      "Tbsp is a source processing language based on Treesitter, a tool for parsing and analyzing code.",
      "Users are discussing the need for a higher-level API for non-editor use cases and the absence of standard grammar structures.",
      "Tools like tree-sitter-graph, ast-grep, and related projects like Semgrep are suggested for better handling and visualization of grammars."
    ],
    "points": 191,
    "commentCount": 38,
    "retryCount": 0,
    "time": 1725239056
  },
  {
    "id": 41423303,
    "title": "Telephone Line Rural Outside Plant",
    "originLink": "http://cityinfrastructure.com/single.php?d=RuralOutsidePlant&t=Rural%20Outside%20Plant",
    "originBody": "Rural Outside Plant 1 of 24 Another section of this web site talked about outside plant, which is the telephone company's term for the cabling and other equipment which connects your home telephone to their Central Office. This diagram shows an overview, and below are some pictures and descriptions of how outside plant is different for rural areas. The main differences are that the Central Offices are typically smaller, and the cable distances are much greater. 2 of 24 Here is a typical Central Office. Note it is only one storey, but is still well-kept, and mostly windowless. 3 of 24 Around back are some air conditioners, technician's trucks, and even a small aluminum motor boat (the technicians working in this area often have to run telephone lines to islands). Also, at the right are some Jumpered Wire Interfaces (JWI), which split the high pair count cables from the Central Office (such as 1,200 pairs) to smaller cables (such as 200 pairs) for distribution to terminals and people's houses. 4 of 24 Here's another Central Office. This one has a few meters of unused 1,200-pair feeder cable in front (much more attractive than plastic pink flamingos). 5 of 24 Around back, no security cameras, but there is good lighting, and of course, air conditioners. 6 of 24 The front door has a mechanical push-button lock, and a discrete sign. 7 of 24 Here's a close-up of the 1,200 pair cable. It is about 4 cm in diameter. 8 of 24 The feeder cables coming out of the Central Office are all buried, but within a few meters of the building, they surface to come be run up a utility pole. Note the ancient lead-covered splice enclosure. 9 of 24 Here's the top of that utility pole. These cables carry everything that this Central Office does (this is what is called a “single point of failure” – one car accident, and there's a lot of people with no phone service). There's another lead closure at the top-left. 10 of 24 As shown in the close-up of the 1,200-pair feeder cable above, cable construction is to have twisted pairs covered by a thick plastic protective jacket. After enough sun and flexing in the wind, the cable jacket can develop leaks, which could allow water to seep in between the cable pairs. This would change the electrical characteristics of the cable, and cause many problems (such as cross-talk between telephone lines and distorted signals). Therefore paper insulated cable (these cables will all be more than 40 years old) and sometimes newer cable) are pressurized with air, typically less than 9 pounds per square inch (for comparison, automobile tires typically have a pressure of more than 30 pounds per square inch). This provides several benefits: Rather than water seeping into the cable, air will leak out, and this keeps the cable dry. The flow of air through the cable will dry and remove any moisture that does get into the cable. By measuring the pressure along test points in the cable, and graphing this, a technician can determine approximately where the cable jacket is bad (the pressure will be lower where the air leaks out). I'm sure you've seen the little packages of dessicant (which look like restaurant coffee sugar packets) of that often come (along with a warning not to eat it) with electronic and other products which have been shipped from overseas. This stuff is a chemical that likes to absorb water (from the damp ocean crossing), so the moisture won't damage the goods. Similarly, there is a need to ensure that the air used to pressurize the cable is dry, and this blue crystalline material is dessicant, and does just that. The air compressor (or “bottled gas”, where the air comes from a compressed air tank) would be in the Central Office, and feeds the black hose, so the air passes through the dessicant, and the hose continues up the utility pole to pressurize the cables father along. 11 of 24 Here's a close-up of the dessicant canister. It reminds technicians to: Change the desiccant when it turns pink. That the maximum pressure allowed is 25 pounds per square inch (automobile tires typically have a pressure of 28 to 40 pounds per square inch). And to be gentle with it. This device is made by Jameson Corporation, and is model J-100-8. 12 of 24 Here is a new air pipe (in an urban location) from a central office, waiting to be connected through to a cable vault farther down the road. 13 of 24 This air pipe is made by Superior Essex. Their catalogue page is here. It shows that this type of pipe is typically installed in ducts (underground plastic conduits), the pipe has an outside diameter of 18 mm, and has a 4 mil (about the thickness of paper) aluminum tape inside the pipe (since the plastic used would otherwise allow water vapour to pass through the pipe wall (it is important to keep the air dry). 14 of 24 To split a feeder cable into smaller cables (to each go in different directions) a splice enclosure is needed. Here is a really old lead one (on top), and a newer plastic (and openable) one below it. Cables with a lead splice closure are old enough that the wires are likely paper insulated (as the bundle of spliced wires is covered in a protective and insulating cloth before the lead closure is sealed with solder, plastic insulated wires can also be enclosed in lead closures, without damage when the lead is sealed with solder). Due to the difficulty of opening and resealing the lead closures, and the health concerns for technicians working with the lead, telephone companies are working at removing this type of closure. Modern buried telephone cables are generally grease filled: when the cable is manufactured, a gel is injected to fill the interstitial spaces between the twisted pairs, so water cannot seep in. In contrast, aerial cables are generally dry, and do not have this gunk. Attached to the lead splice cover is a pressure transducer to enable remote monitoring of the pressure in the cable. A web page for a typical outside plant pressure transducer made by TX Technology Corporation is here. This points out that the transducer is designed to measure pressures from 0 to 9.5 pounds per square inch, and has a corresponding output from 100 kΩ to 3,820 kΩ. More detailed information is here. It points out that the transducer has a water-tight screw cap (with a knurled edge for finger tightening, and a little ball-chain so it won't be lost if dropped) a which can be removed to set the zero-pressure point for the transducer, according to the altitude at which it is installed. The flexible cable hanging down is the electrical signal from the transducer, and is connected to a pair of wires in the lower cable so the pressure at this location can be remotely monitored at the central office. Because most central office activities (such as changing the telephone line features which subscribers receive and trouble-shooting problems) can now be done remotely, most central offices are not normally staffed. Therefore, the system (at the nearest central office) which monitors all the remote pressure transducers will usually be itself monitored remotely. When pressurized cable is spliced to dry or greased-filled cable, a plug must be poured into the end of the pressurized cable, so the air does not leak out. 15 of 24 Now we get to a really interesting part. As you drive along rural roads, you'll see what appear to be paint cans, each with a this cable coming out the top. If you're really bored, you may also notice that they are exactly 6,000 feet apart (that would be 1.14 miles, and 1.83 km). Just as you can walk slowly through water, but cannot easily run (since water is more viscous than air), higher-frequency electrical signals are attenuated (made quieter) more than lower-frequency signals. In urban areas, there are generally enough customers within a 5 km radius of Central Offices to justify building a Central Office, and in 5 km of cable, the signals are not distorted too much. In rural areas, customers are farther apart, and the cable runs to customers are longer. The capacitance of the cable (which is analogous to the greater viscosity of water) would attenuate the high-frequency signals (distorting the sound), so inductors (which counter-act the capacitance) are connected to each pair of wires. Since the capacitance is spread-out along the length of the cable, the inductance also has to be distributed along the cable. A popular scheme is called H88: the “H” refers to a distance of 6,000 feet between inductors, and the “88” refers to the inductance value of 88 mH (milliHenrys). 16 of 24 As you might have guessed, these therefore are not paint cans, but are the enclosures for the loading coils. If there is a 600-pair cable, then you need 600 loading coils (these look something like little spools of thread), and you need to attach each to the feeder cable. Here there are three old loading coils (two large, and one smaller metal enclosure mounted on the utility pole), and one newer black plastic loading coil enclosure attached (with stainless steel straps) to the cable at the left. A splice enclosure allows the cable from the loading coil enclosures to be spliced to the feeder cable 17 of 24 Here's a close-up of those big old loading coil enclosures. 18 of 24 As more cables are installed, more loading coils are needed. Here's the newest loading coil (cute, isn't it). 19 of 24 That's it for the loading coils, but on the very next utility pole (and this does generally happen, it will be on a directly adjacent utility pole, as the spacing is also 6,000 feet, likely to simplify installation), there's something else. Rather than being up high, these are generally a waist-height. 20 of 24 So we have the feeder cables running along, and a 3M splice enclosure bringing a few of the twisted pairs in the cable down the utility pole ... 21 of 24 Down to these, which are T1 repeaters. Rather than the analogue signals carried by telephone lines, a T1 is a digital signal which carries data at 1,544,000 bits/s (on the exact same type of twisted pairs as the voice telephone lines). There are many advantages to T1 signals, including being able to carry 24 conversations over two twisted pairs, not gathering cumulative noise along the length of the cable run, and being able to carry (somewhat) high-speed data. But, the problem is that the signal needs to be amplified periodically – every 6,000 feet in fact. The amplifier is actually called a repeater, since it outputs a binary signal (which has only two states, on or off). 22 of 24 This is the older of the two. The feeder cable is pressurized, and so is the cable coming down to this repeater enclosure, and in fact, the repeater enclosure is pressurized as well. At the base of the white enclosure, you can see the clamp (with padlock) which provides the air-tight seal. Since there are active electronics in this enclosure, and they can't have cooling fans (since it is an air-tight enclosure), these enclosures are always white to reflect the sunlight (and some of the heat) as these bake in the summer sun. 23 of 24 Here's the newer enclosure, it is an HRE-458 HiGain Remote Therm-O-Nator Enclosure from ADC DSL Systems, Inc. Some documentation for it is here, and it can hold up to ten cards, such as this HDSL line extender which extends the range of two full-duplex 784 kbits/s DSL connections by up to 12,000' using two 24 gauge copper twisted pairs. The enclosure has heat sink fins on top (since heat rises, this will be where it gets the hottest). These help cool the enclosure by providing more surface area, so it can radiate more heat. 24 of 24 Here's a look at the bottom, showing the cable entry, and also a pressure relief valve to release the pressure before opening the enclosure. Another opening allows the pressure to be measures. The thinner black wire is to ground the enclosure, so goes to a metal stake driven into the ground.",
    "commentLink": "https://news.ycombinator.com/item?id=41423303",
    "commentBody": "Telephone Line Rural Outside Plant (cityinfrastructure.com)148 points by Bluestein 11 hours agohidepastfavorite48 comments Dead_Lemon 7 hours agoI've been enjoying the videos of 'Look Mum No Computer', building his own 60's based, electromechanical telephone exchange, is his Museum of everything else. https://www.youtube.com/watch?v=tK1lH8pjXTo His second channel has some more dedicated content on telephone systems, https://www.youtube.com/playlist?list=PLKnS0AB2CTN_eu8k8rgaO... He has spent a fair amount of time building it out, from initially receiving his first exchanging and getting it to work, and adding more to it It fun just to watch how the system selects lines and routes around the exchange. Other interesting things, like how the dial and engaged tones are generated, and how prerecorded messages are played back to a number that is no longer in service, something like, 'This number no longer exists, please try again' reply volf_ 3 hours agoparentAlso check out https://www.youtube.com/@ConnectionsMuseum The channel is about the fully functional Central Office turned Museum in Seattle reply hyperbolablabla 4 hours agoparentprevSo phreaking cool reply jagged-chisel 1 hour agorootparentiswydt reply hiatus 2 hours agoparentprevI don't know if it's just me but the playlist link you shared just redirects to the homepage. reply paradox460 3 hours agoprevAs a kid in Los Alamos, the mesa I lived on was far enough from the central office[1] that it had some loading coils between us and them. This meant that we couldn't get DSL on that mesa. The mesa across the way didn't have the loading coils, and thus was able to get DSL. I remember the jealousy of my friend being able to download DOOM WADs in a couple of seconds, while I had to schedule them, or convince my dad to download them on the much faster connection at LANL. Eventually we managed to get either an ISDN line or a T1 line, I cannot remember which, but shortly thereafter Cable internet became available, and rendered the whole problem moot. [1] Los Alamos had one central office, with a big microwave relay in the top of it: https://i.imgur.com/Lcfj9oA.jpeg reply SoftTalker 3 hours agoprevI didn't know that these cables are all pressurized with air to keep leaks out (and to dry out any leaks that do happen). To me, that was honestly the most interesting thing in the article. reply ale42 10 hours agoprevI love landline phones (when they work right, which is not the case everythere) because usually they have better sound quality than mobile (which can be good-to-horrible depending on network quality) and almost zero latency. But it's time to switch to fiber optics! reply linsomniac 6 hours agoparentIf you think POTS sounds good, you should try ISDN, it'll knock your socks off! Back in the mid-90s I got ISDN BRI (2x64Kbps channel) service in to replace analog modem service. It would connect in well under a second, and while connected at 128K we could receive a phone call (dropping one of the channels, so having voice plus 64K data), and the phone calls sounded quite good. It used to be that for recording remote interviews or even I believe just general voice recording like audio books, the media companies would have you come into a location that had ISDN, and if you were a real big timer you might have ISDN in your home studio. That was back in the day when they gave a crap, then the pandemic came along and the media companies seemed to be happy throwing any crappy video chat up for broadcast, not matter how echoy the room you're in or how many drop-outs. WRT fiber optics, we are just now starting to see Q.com (Century Link) deploying fiber to the neighborhoods. Up in Canada in a similar sized city they deployed fiber back in 2000, but in the states QWest wouldn't do it because, I've been told, it would open up allowing CLECs to put DSL equipment in neighborhoods, and let them cherry-pick neighborhoods to offer service in. Finally a few years ago the city stepped in a ran fiber to every house, which honestly is a better option IMHO. reply shepherdjerred 3 hours agorootparentI've had Quantum Fiber in Seattle for a year or two now. It's fantastic! Symmetrical upload/download, no data cap, 1gbps, and I pay something like $75/mo. I was paying $100/mo to Comcast for the same thing, though I had 1.2gbps down/35mbps up. reply linsomniac 1 hour agorootparentGood to know, I was passingly wondering what the service level was that they were offering. CenturyLink currently can only offer me 60Mbps/5Mbps for $55/mo, until Q.com builds out more of the town. That compares poorly with the city FTTH which is 1G/1G for $70/mo, 2G/2G for $100, or 10G/10G for $200/mo. A static IPv4 is another $20/mo (which is admittedly pricy for an add-on, but $90/mo for gig with static feels fine to me). reply wrycoder 3 hours agorootparentprevIs your endpoint routable? Is the IP fixed or dynamic? reply volf_ 3 hours agorootparentYes. Dynamic as the IP is renewed everytime your device resets reply schiffern 9 hours agoparentprevWe often talk of developing nations \"leapfrogging\" landlines and going straight to mobile, but they're also going straight to fiber. It would be fascinating to see this same type of breakdown for rural fiber infrastructure. One obvious difference is that fiber can't self-power a phone, but with ubiquitous mobile phones/solar panels/powerbanks that doesn't strike me as a huge show-stopper. Thanks OP, great post and content. Now I'll go through the world with new eyes! EDIT: found the fiber page http://cityinfrastructure.com/single.php?t=Fibre%20Optic%20C... reply xattt 8 hours agorootparentCell phone coverage has been abysmal in my part of the world, to the point where 911 calls can be unreliable (1). (1) https://www.cbc.ca/news/canada/prince-edward-island/pei-cell... reply gary_0 5 hours agorootparentThe telecom situation in Canada is ridiculous. Even in Greater Vancouver, the 3rd largest metropolitan area in Canada and the 34th in North America, there are dead zones everywhere with major providers. I'm in a suburban development that was mostly built in the last 5-10 years, and there still aren't any towers near here so my bedroom and foyer have no reception (not 1 bar, I mean my phone says \"no service, you must be in the wilderness\"). I have to stand by a window to make calls. And this is a wood-frame building on flat terrain, next to two major highways. reply elzbardico 3 hours agorootparentprevThere's also a lot of replacing copper cabling with fiber due to copper cables being frequently stolen. reply Bluestein 9 hours agorootparentprevInteresting, the \"straight-to-fiber\" leapfrogging. Was not aware. Makes sense.- I'd be interested to know - qua infra - what their power grids are looking like ... reply detourdog 8 hours agorootparentEstonia when it left the Soviet Union was offered a used phone system from a country that wanted to upgrade. Estonia decided to build new. https://theconversation.com/estonia-is-a-digital-republic-wh... reply Bluestein 8 hours agorootparentSmart move.- PS. Also, interesting that there - apparently - is a \"second hand\" market for used phone systems. As in, wholesale.- reply detourdog 5 hours agorootparentObviously excepting the cruelty I love the modern world. I marvel at the organization and patterns. The Soviet Union was suffering some food crisis in the 90’s. One morning the news was discussing Clinton granting food aid to them. That same morning as my subway crossed by the Dominoe sugar factory there was already a Russian ship docked. That was such a strange cause and effect moment for me. reply marcus0x62 6 hours agoparentprev> But it's time to switch to fiber optics! The PSTN has been hybrid fiber/copper for decades. The vast majority of inter-CO traffic is carried on fiber optic lines. Many POTS lines are carried on fiber optic carriers from the central office to a subscriber loop carrier or similar device and then only travel a short distance to the subscriber premises on copper lines. reply zabzonk 4 hours agorootparentin the UK it is typically fibre to the box on the street, and then copper from that to the house. providers would love you to subscribe to fibre to the house (so they can charge you exorbitant prices for it), but really YAGNI for most people at least in my experience. reply sgt101 2 hours agorootparentThat used to be the case - but it's rapidly becoming standard to be directly connected to fibre. I believe that something like 60% of UK premises have a fibre connection available and I expect that all the providers will push folks off copper as fast as they can. Because copper is a pain in the arse compared to fibre (for the provider). For the consumer copper has one key positive that fibre just doesn't - it works in a power cut. reply razakel 6 hours agoparentprevIt was time to switch to fiber 50 bloody years ago. reply ape4 4 hours agoparentprevNaive question: Was fiber always digital? I could imagine varying the intensity of the a laser signal to send sound. reply ooterness 4 hours agorootparentRadio-frequency over fiber (RFoF) signals are usually analog. By intensity-modulating the laser, it's relatively easy to convert a GHz-wide analog signal from electrical to optical and back. https://en.wikipedia.org/wiki/Radio_over_fiber https://www.rp-photonics.com/radio_and_microwave_over_fiber.... reply declan_roberts 4 hours agorootparentprevI can't imagine that subtle light intensity would survive the various light amplifiers used along the way. reply ooterness 3 hours agorootparentAnalog signals won't survive a 1000km undersea cable, but for a few kilometers you don't need amplifiers at all. The loss-per-meter of optical fiber is much lower than a coax cable. reply zabzonk 4 hours agorootparentprevbut ... why? reply mschuster91 9 hours agoparentprev> I love landline phones (when they work right, which is not the case everythere) because usually they have better sound quality than mobile (which can be good-to-horrible depending on network quality) and almost zero latency. That was the old landlines, of actual POTS, era. Back then, there was a direct electrical circuit literally switched using relays between both participants in a call, with only amplifiers, switches and power sources in between. More modern systems used banks of relays, and then it all went downhill quality-wise. First, the telco core systems were replaced with digital trunks that had ADCs on both ends of a call in the regional distribution center, and consumers were switched over to ISDN for telephony. Then, the analog/ISDN frontends moved to the curb side where ADSL, VDSL and nowadays G.fast frontends were added to the mix, which were connected to the telco network using fiber. Then, analog and ISDN were shut down, with voice phone calls being migrated to VoIP. And nowadays, it's the full evolution with GPON - on the telco side, there's only fibers and a single TX/RX pair of transmission modules serving up to 64 customers. What used to require a whole multi-story building can now be done in the space of a better-quality shed. And the analog frontend is only at the CPE, if there is an analog frontend present at all and it's not VoIP softphones or DECT. reply freeopinion 3 hours agorootparentI'm not sure what you mean by \"better-quality shed\" but cabinet sizes today are often less than 1 cubic meter. I guess you know that, but thought it might surprise some people. One cabinet doesn't really replace a multi-story building. Many cabinets spread out over the service area do the job. But each cabinet can perform all the functions that used to happen in the large building. They just make it economical to perform those functions for 100 - 1000 subscribers, instead of having to centralize them into a single location that serves 5,000 - 100,000. Those cabinets are not a result of fiber. They were more a necessity of high bandwidth services without fiber. Think ADSL. Fiber actually makes it possible to go back to more centralized service while providing even more bandwidth. You can deploy passive fiber splitters in an old-fashioned pedestal and keep the active optics in the multi-story building for 100,000 subscribers again. Maybe you meant that the active optics would only fill a small shed's worth of space in that old building. I finally caught up to you. reply toast0 3 hours agorootparentprevIn the US, at least in the states I lived in, ISDN telephony was always niche, the price was too high unless you needed it for a remote studio, or you had a teleconference setup or needed the blazing fast 128kbit dial up experience. Analog phones with a digitizer at the central office or remote terminal is still a very good calling experience with minimal latency. 8-bit u-law @ 8000 Hz isn't great audio quality, but the sampling delay is near zero, and when it was all PRI digital (t1/isdn/etc) switching, multiplexing was done per sample, so there was no significant buffering (a two sample buffer would be sufficient at any switching point). Mobile uses complex compression with significant sampling delay and sends data in bursts so there's packetization delay. VoIP often uses complex compression (but you can configure for u-law) and is usually 20ms packets, plus you've got to add a jitter buffer to account for packets taking different amounts of time to traverse the network. Packet switching clearly won over circuit switching, but we've lost the very low latency local calling we used to have, and I don't think anyone is willing to send 1000 packets per second for voice calls to get close to where we were. For long distance calling, probably improved routes that were run for packet switching reduce latency enough to cancel out the increased factors. reply Dibby053 7 hours agorootparentprevMy new ISP took this to another level: if you transfer your landline phone number they send you a voice-only SIM card and a 4G router into which you're supposed to plug your landline. Calls to the landline number are redirected to the number in the SIM (with a significant delay). I wonder why they did it this way instead of implementing VoIP, especially since the all-in-one GPON/Wi-Fi router already has a landline port. reply actionfromafar 5 hours agorootparentMaybe requirements on availability? reply dfc 4 hours agorootparentprevWhat ISP do you use? reply Bluestein 10 hours agoparentprevTotally.- PS. But, can you do fence-wire comms with fiber? :) reply ale42 10 hours agorootparent> PS. But, can you do fence-wire comms with fiber? :) Maybe with a transparent plastic fence :-D reply Bluestein 9 hours agorootparentThere you go.- (But your fence bend radius is limited, though ... :) reply russfink 21 minutes agoprevA lesson in how not to use parentheses in technical writing. reply Jordan_Pelt 6 hours agoprevI really want to see the insides of those buildings. reply mjcl 2 hours agoparentThere's some videos on the AT&T Tech Channel on YouTube that show inside the CO, like this one for the \"Speedy cutover service\": https://www.youtube.com/watch?v=saRir95iIWk reply volf_ 3 hours agoparentprevhttps://www.youtube.com/@ConnectionsMuseum There's a fully functional system deployed in Seattle as a Museum reply kibwen 3 hours agoprev> Here's a close-up of the 1,200 pair cable. Terminating that must be a lot of fun. Please tell me they have some clever device that makes this task easier. reply paradox460 3 hours agoparentThey had splice tools, but you were still threading cables to each other by hand. The model train club I used to be a member of was full of old telephone guys, and they'd share old stories reply sgt101 2 hours agoparentprevYeah - there are colour codes you can use to find the pair that you want to connect, they are arranged in a mystical system of binders. It's like a map. reply zikduruqe 19 minutes agorootparentBack in my telephone days, I used to use this to remember my pair colors. We Rape Beautiful Young Virgins (for the White Red Black Yellow Violet) and Big Old Gob of Bull Shit (Blue Orange Green Brown Slate). There were other mnemonics other people used. https://en.wikipedia.org/wiki/25-pair_color_code Back in my younger days when I ran a switching office, I used to rip a few bong hits, put on some music and wire DSX panels on the weekends and just zen out. It was therapeutic. reply WarOnPrivacy 5 hours agoprev [–] Now we get to a really interesting part. As you drive along rural roads, you'll see what appear to be paint cans, each with a this cable coming out the top. As you might have guessed, these therefore are not paint cans, but are the enclosures for the loading coils. If there is a 600-pair cable, then you need 600 loading coils (these look something like little spools of thread), and you need to attach each to the feeder cable. I hadn't seen that config before. (looong-time infra rubbernecker). I assume I've seen variants but am not recalling what they look like. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The rural outside plant involves the telephone company's cabling and equipment connecting homes to the Central Office, with notable differences such as smaller Central Offices and longer cable distances.",
      "Key components include Jumpered Wire Interfaces (JWI) for splitting high pair count cables, feeder cables, utility poles, and splice enclosures for distributing cables.",
      "Advanced equipment like T1 repeaters and HRE-458 HiGain Remote Therm-O-Nator enclosures are used to amplify digital signals and manage heat dissipation."
    ],
    "commentSummary": [
      "The discussion highlights the transition from traditional copper-based telephone systems to modern fiber optics, emphasizing the benefits of fiber optics in terms of speed and reliability.",
      "Users share personal experiences and insights about various telecommunication technologies, including ISDN, DSL, and fiber optics, and their impact on connectivity and service quality.",
      "The conversation also touches on the challenges and peculiarities of rural and urban telecom infrastructure, such as the use of loading coils, the pressurization of cables, and the replacement of copper with fiber to prevent theft."
    ],
    "points": 148,
    "commentCount": 48,
    "retryCount": 0,
    "time": 1725261688
  },
  {
    "id": 41423577,
    "title": "Upgrading a Toshiba NAS HDD Firmware on Linux",
    "originLink": "https://syscall.eu/blog/2024/08/28/toshiba_hdd_firmware/",
    "originBody": "Bof. No theme, no regular posting. Archive © 2014-2024. Raphaël Rigo CC-BY-SA 4.0 About. Upgrading a Toshiba NAS HDD firmware on Linux 28 Aug 2024 TL;DR I reversed the firmware updater of my Toshiba HDD to be able to update it on Linux. The following commands should work, USE AT YOUR OWN RISK: $ wget https://www.canvio.jp/en/support/download/hdd/ot_ihdd/fw/ISFw.dat $ grep -C2 MODELNAME ISFw.dat # ^ # |___ identify the right filename here $ wget https://www.canvio.jp/en/support/download/hdd/ot_ihdd/fw/sk060202.ftd # hdparm --fwdownload-mode3 sk060202.ftd /dev/sdX Context I bought a Toshiba HDWG480 HDD for my NAS. hdparm -I /dev/XXX gives the following output: ATA device, with non-removable media Model Number: TOSHIBA HDWG480 Serial Number: 3430A00RFR0H Firmware Revision: 0601 Transport: Serial, ATA8-AST, SATA 1.0a, SATA II Extensions, SATA Rev 2.5, SATA Rev 2.6, SATA Rev 3.0 Standards: Used: unknown (minor revision code 0x006d) Supported: 10 9 8 7 6 5 Likely used: 10 [...] As usual, I wanted to check if any firmware update is available. Toshiba’s dedicated webpage lists version 0602 as available for my model. Unfortunately, as expected, there’s no firmware update process provided for Linux users, only an “Internal Storage Firmware Update Utility” is provided for Windows. Update files are not provided either. Goals So, our goals are: understand where the updater gets its update files from reverse engineer the flashing process itself to reimplement it on Linux Reversing the Windows Updater Intro Running the installer1 with Wine works perfectly, resulting in the following files being installed under Program Files (x86): 18312 ISFw.exe: PE32 executable (native) Intel 80386, for MS Windows, 4 sections 2434952 TosISFw.exe: PE32 executable (GUI) Intel 80386, for MS Windows, 5 sections 2172296 TosISFwSvc.exe: PE32 executable (GUI) Intel 80386, for MS Windows, 5 sections 2362248 TosISFwTray.exe: PE32 executable (GUI) Intel 80386, for MS Windows, 5 sections A quick look (filename, imports) hints at the following goals for each program: ISFW.exe is a driver (DriverEntry export), probably in charge of effectively flashing the update. TosISFw.exe is the GUI TosISFwSvc.exe is the userland service (as the service related imports show) TosISFwTray.exe most probably handles a tray icon Finding the update files The obvious move is too grep for URLs in the various installed binaries. Unfortunately, it leads nowhere apart from URLs related to the digital signatures. However, grepping for HttpOpenRequest, an API often used by Windows programs to download files, gives two results: TosISFw.exe and TosISFwSvc.exe. Let’s look at TosISFwSvc.exe which is smaller and let’s see if we can find the URL by checking the xrefs. The call is in the function at 0x00401040, and looks like this: v15 = HttpOpenRequestW(v14, L\"GET\", &v36[(_DWORD)lpBuffer], 0, (LPCWSTR)szReferrer, 0, 0x84000000, 0); the function is obviously a “download” helper, as all the API calls show. Let’s rename it dlfile. There are only two Xrefs to dlfile: if ( !RegOpenKeyExW( HKEY_LOCAL_MACHINE, L\"SYSTEM\\\\CurrentControlSet\\\\Services\\\\TosISFwSvc\", 0, 0x20019u, &phkResult) && readregstring((LPBYTE)&String, &phkResult, L\"FwURL\") && lstrlenW(&String) ) { sub_401000(); LOBYTE(v47) = 2; if ( dlfile(&String, (int)v38) ) [...] sub_4052E0(&lpValueName, L\"%s%d\", L\"URL\", phkResult); v25 = 0; if ( !RegOpenKeyExW( HKEY_LOCAL_MACHINE, L\"SYSTEM\\\\CurrentControlSet\\\\Services\\\\TosISFwSvc\", 0, 0x20019u, &v25) && readregstring((LPBYTE)&String, &v25, lpValueName) && lstrlenW(&String) && dlfile(&String, (int)v36) ) The first one gives us our answer: the URL is stored in the registry. It’s actually written by the InstallShield setup. The value is http://www.canvio.jp/en/support/download/hdd/ot_ihdd/fw/ISFw.dat Parsing the update file The file is an ini file, which is trivial to read and parse: [VERS] VERSION=\"20240513\" [Firmware] 0000=qa060378.ftd 0000model=\"TOSHIBA HDWG21E\" 0000rev=\"0603\" 0000rev0000=\"0601\" 0000native=0 0000option=0 0001=qa060378.ftd 0001model=\"TOSHIBA HDWG21C\" 0001rev=\"0603\" 0001rev0000=\"0601\" 0001native=0 0001option=0 [...] 0008=sk060202.ftd 0008model=\"TOSHIBA HDWG480 \" 0008rev=\"0602\" 0008rev0000=\"0601\" 0008native=0 0008option=0 [...] ; 905CBD24 in my case, the drive is number 8. What’s interesting is the checksum at the end. It’s the CRC32 of the file, minus the last 10 bytes, which can be easily checked with the slice and crc32 tools of my hacking Swiss army knife rsbkb: $ slice -- ISFw.dat 0 -10crc32 905cbd24 Now obviously, let’s try to download the relevant file: $ wget https://www.canvio.jp/en/support/download/hdd/ot_ihdd/fw/sk060202.ftd Resolving www.canvio.jp (www.canvio.jp)... 23.72.248.205, 23.72.248.202 Connecting to www.canvio.jp (www.canvio.jp)|23.72.248.205|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 1171456 (1.1M) [...] Just for fun we can check if cpu_rec_rs can identify any code in the binary: $ ~/tools/cpu_rec_rs/cpu_rec_rs sk060202.ftd Loading corpus from \"/home/trou/tools/cpu_rec_rs/cpu_rec_corpus/*.corpus\" ------------------------------------------------- FileRangeDetected Architecture ------------------------------------------------- sk060202.ftdWhole fileARMhf ------------------------------------------------- So the firmware is probably running on an ARM SoC (it is). Understanding the update process Now, how is the file sent to the drive to actually perform the update? Recall that we have 4 binaries and we saw the ISFW.exe is actually a driver. The DriverEntry function is actually extremely simple: NTSTATUS __stdcall DriverEntry(PDRIVER_OBJECT DriverObject, PUNICODE_STRING RegistryPath) { int v2; // eax readregistry(); v2 = flashfirmware(); sub_1001812(v2 % 100 == 0, 1, v2); return NtTerminateProcess((HANDLE)0xFFFFFFFF, 0); } I’ve already renamed readregistry and flashfirmware as the functions are easy to identify: char readregistry() { [...] RtlInitUnicodeString(&DestinationString, L\"\\\\REGISTRY\\\\MACHINE\\\\SYSTEM\\\\CurrentControlSet\\\\Services\\\\TosISFwSvc\"); [...] if ( NtOpenKey(&KeyHandle, 0x20019u, &ObjectAttributes) >= 0 ) { RtlInitUnicodeString(&ValueName, L\"FW_Serial\"); if ( NtQueryValueKey(KeyHandle, &ValueName, KeyValuePartialInformation, KeyValueInformation, 0x800u, &ResultLength) >= 0 ) { memcpy(&fwserial, &KeyValueInformation[3], KeyValueInformation[2]); [...] RtlInitUnicodeString(&ValueName, L\"FW_CurRev\"); memcpy(&fw_cur, &KeyValueInformation[3], KeyValueInformation[2]); [...] RtlInitUnicodeString(&ValueName, L\"FW_NewRev\"); memcpy(fw_new, &KeyValueInformation[3], KeyValueInformation[2]); [...] RtlInitUnicodeString(&ValueName, L\"FW_Model\"); memcpy(fw_model, &KeyValueInformation[3], KeyValueInformation[2]); [...] RtlInitUnicodeString(&ValueName, L\"FW_FWFile\"); wmemcpy(path, L\"\\\\??\\\\\", 4); memcpy(&path + 4, &KeyValueInformation[3], KeyValueInformation[2]); [...] } Registry values (set by TosISFwSvc.exe) are read and copied into global variables, which I renamed according the registry value name. Here’s the start of flashfirmware: int flashfirmware() { [...] Handle = 0; fwdata = 0; fwsize = 0; memset(&drivedata, 0, sizeof(drivedata)); printf(L\"%s Firmware: %s -> %s\", fw_model, &fw_cur, fw_new); printf(L\"DO NOT TURN OFF THE PC WHILE ANY FIRMWARE UPDATE IS RUNNING.\"); printf( L\"Your device may become unusable if you do this and Toshiba is not \" \"responsible for any damage, including any necessary replacement of \" \"the unit, caused by your doing so.\"); HeapHandle = RtlCreateHeap(2u, 0, 0, 0, 0, 0); if ( HeapHandle ) { status = readfile(&path, &fwdata, &fwsize); if ( !(status % 100) ) { Handle = verifydisk(&fwserial, &fw_cur, fw_model, &drivedata); [...] verifydisk is very important, yet relatively simple (with everything already renamed): HANDLE __stdcall verifydisk(PCWSTR serial, PCWSTR cur, WCHAR *model, IDENTIFY_DEVICE_DATA *devdata) { HANDLE hdl; // edi UNICODE_STRING cur_; // [esp+10h] [ebp-104h] BYREF struct _UNICODE_STRING serial_; // [esp+18h] [ebp-FCh] BYREF UNICODE_STRING model_from_drive_u; // [esp+20h] [ebp-F4h] BYREF UNICODE_STRING serial_from_drive_u; // [esp+28h] [ebp-ECh] BYREF UNICODE_STRING model_; // [esp+30h] [ebp-E4h] BYREF UNICODE_STRING fwrev_from_drive_u; // [esp+38h] [ebp-DCh] BYREF DWORD *drivenumber; // [esp+40h] [ebp-D4h] HANDLE hdl_; // [esp+44h] [ebp-D0h] char v14; // [esp+4Bh] [ebp-C9h] BYREF WCHAR model_from_drive[50]; // [esp+4Ch] [ebp-C8h] BYREF WCHAR serial_from_drive[30]; // [esp+B0h] [ebp-64h] BYREF WCHAR fwrev_from_drive[18]; // [esp+ECh] [ebp-28h] BYREF [...] for ( drivenumber = 0; (unsigned int)drivenumber = 0 && (InputBuffer.CurrentTaskFile[reg_Status] & 9) == 0 ) { return 1; } return v6; } NtDeviceIoControlFile is now used with IOCTL_ATA_PASS_THROUGH_DIRECT, which as the name implies, sends a raw ATA command to the drive. Actually understanding the request is a bit complex as the ATA_PASS_THROUGH_DIRECT structure specifies both data buffers and “registers” through the CurrentTaskFile field. CurrentTaskFile is an array used to index 8 registers, both as input and output. Using the documentation, we can create two enums to use in IDA: enum ATA_INPUT_REGISTERS : __int32 { reg_Features = 0x0, reg_Sector_Count_in = 0x1, reg_Sector_Number_in = 0x2, reg_Cylinder_Low_in = 0x3, reg_Cylinder_High_in = 0x4, reg_Device_Head_in = 0x5, reg_Command = 0x6, reg_Reserved = 0x7, }; enum ATA_OUTPUT_REGISTERS : __int32 { reg_Error = 0x0, reg_Sector_Count_out = 0x1, reg_Sector_Number_out = 0x2, reg_Cylinder_Low_out = 0x3, reg_Cylinder_High_out = 0x4, reg_Device_Head_out = 0x5, reg_Status = 0x6, reg_Reserved_out = 0x7, }; So the command here is 0xEC. The ATA/ATAPI command set specification, found here, describes the IDENTIFY DEVICE – ECh, PIO Data-In command, which returns a lot of data. Thankfully, Microsoft gives us the IDENTIFY_DEVICE_DATA structure which has everything. The following code then verify we have the “right” drive by comparing the serial, model and firmware version from the returned data to the ones stored in the registry. int __stdcall get_drive_serial(IDENTIFY_DEVICE_DATA *drivedata, wchar_t *dest, int destlen, char stripflag) { return (int)getdrive_data_string( drivedata, dest, destlen, offsetof(IDENTIFY_DEVICE_DATA, SerialNumber), 20, stripflag); } [...] get_drive_serial(devdata, serial_from_drive, 30, 1); [...] RtlInitUnicodeString(&serial_from_drive_u, serial_from_drive); [...] if ( RtlEqualUnicodeString(&serial_, &serial_from_drive_u, 0) ) { if ( RtlEqualUnicodeString(&cur_, &fwrev_from_drive_u, 0) && RtlEqualUnicodeString(&model_, &model_from_drive_u, 0) ) Actually sending the firmware file Once the driver has identified and verified the disk is actually flashable, it proceeds with the actual update: [...] MaxBlocksPerDownloadMicrocodeMode03 = drivedata.MaxBlocksPerDownloadMicrocodeMode03; if ( !drivedata.MaxBlocksPerDownloadMicrocodeMode03 || drivedata.MaxBlocksPerDownloadMicrocodeMode03 == 0xFFFF ) { MaxBlocksPerDownloadMicrocodeMode03 = 128; } else if ( drivedata.MaxBlocksPerDownloadMicrocodeMode03 >= 0x80u ) { MaxBlocksPerDownloadMicrocodeMode03 = 128; } if ( MaxBlocksPerDownloadMicrocodeMode03 >= drivedata.MinBlocksPerDownloadMicrocodeMode03 && MaxBlocksPerDownloadMicrocodeMode03 ) { fwblocks = fwsize >> 9; fwblocks2 = fwsize >> 9; v1 = 60; do { printprogress(); wait((LARGE_INTEGER)500LL); --v1; } while ( v1 ); for ( fwsize = 0; (int)fwsize = fwblocks2 ) goto LABEL_25; } status = 6009; LABEL_25: fwblocks = fwblocks2; } if ( !(status % 100) ) break; v5 = 2; do { printprogress(); wait((LARGE_INTEGER)500LL); --v5; } while ( v5 ); } if ( !(status % 100) ) { if ( get_IDENTIFY_DEVICE_DATA(Handle, &drivedata, 0x200u) ) { get_drive_fw_rev(&drivedata, newfwrev, 18, 1); if ( wcsncmp(fw_new, newfwrev, wcslen(fw_new)) ) status = 6011; } else { status = 6010; } } } else { LABEL_35: status = 6006; } [...] if ( status % 100 ) printf(L\"Update Failed. \"); else printf(L\"Update Succeeded. \"); As you can see, the updater verifies an interesting field from the drive information data: MaxBlocksPerDownloadMicrocodeMode03. Let’s check what this means. Sending ATA firmware update commands Documentation The following excerpt from the ATA command set describes the meaning of the field: A.11.5.3.4 DM MAXIMUM TRANSFER SIZE field If: a) the value of the DM MAXIMUM TRANSFER SIZE field (see table A.30) is greater than zero; b) the value of the DM MAXIMUM TRANSFER SIZE field is less than FFFFh; c) the DOWNLOAD MICROCODE SUPPORTED bit (see A.11.5.2.20) is set to one or the DOWNLOAD MICROCODE DMA SUPPORTED bit (see A.11.5.2.6) is set to one; and d) the DM OFFSETS DEFERRED SUPPORTED bit (see A.11.5.3.1) is set to one, or the DM OFFSETS IMMEDIATE SUPPORTED bit (see A.11.5.3.3) is set to one, then the DM MAXIMUM TRANSFER SIZE field indicates the maximum number of 512-byte data blocks permitted by a DOWNLOAD MICROCODE command (see 7.7) or a DOWNLOAD MICROCODE DMA command (see 7.8) that specifies a subcommand of: a) Download with offsets and save microcode for immediate and future use (i.e., 03h); or b) Download with offsets and save microcode for future use (i.e., 0Eh). Otherwise, no maximum is indicated (i.e., there is no maximum number of 512-byte data blocks). The IDENTIFY DEVICE data contains a copy of the DM MAXIMUM TRANSFER SIZE field (see IDENTIFY DEVICE data word 235 in table 45). Of course, we want to check this DOWNLOAD MICROCODE command: The DOWNLOAD MICROCODE command allows the host to alter the device’s microcode. The data transferred using the DOWNLOAD MICROCODE command and the DOWNLOAD MICROCODE DMA command is vendor specific. [...] Downloading and activating microcode involves the following steps: 1) download: the host transfers updated microcode data to the device in one or more DOWNLOAD MICROCODE commands or DOWNLOAD MICROCODE DMA commands; 2) save: after receiving the complete updated microcode data, if specified by the download microcode mode, then the device shall save the updated microcode data to nonvolatile storage; and 3) activate: the device begins using the saved or deferred microcode data for the first time after an event specified by the download microcode mode and the saved or deferred microcode data becomes the active microcode data. The BLOCK COUNT field specifies the number of 512-byte data blocks that shall be transferred. The BLOCK COUNT field is specified in the COUNT field and the LBA field (see table 37). DOWNLOAD Subcommands actually define the update behavior: Actual code char ATA_CMD_DOWNLOAD_MICRO(HANDLE FileHandle, __int16 currentblock, int blocks_to_flash, void *fwdata) { struct _IO_STATUS_BLOCK IoStatusBlock; // [esp+Ch] [ebp-38h] BYREF char v6; // [esp+17h] [ebp-2Dh] ATA_PASS_THROUGH_DIRECT InputBuffer; // [esp+18h] [ebp-2Ch] BYREF IoStatusBlock.Status = 0; IoStatusBlock.Information = 0; memset(&InputBuffer, 0, sizeof(InputBuffer)); InputBuffer.Length = 0x28; InputBuffer.AtaFlags = ATA_FLAGS_DRDY_REQUIRED|ATA_FLAGS_DATA_OUT|ATA_FLAGS_NO_MULTIPLE; *(_WORD *)&InputBuffer.CurrentTaskFile[reg_Sector_Count_in] = blocks_to_flash;// BLOCK COUNT *(_WORD *)&InputBuffer.CurrentTaskFile[reg_Cylinder_Low_in] = currentblock;// BUFFER OFFSET v6 = 0; InputBuffer.DataTransferLength = blocks_to_flash = 0 && (InputBuffer.CurrentTaskFile[6] & 9) == 0 )// status { return 1; } return v6; } As you can see, the ATA_CMD_DOWNLOAD_MICRO just follows the specification. The only weird point is the Device register, which is basically obsolete, but is set to 0xE0. Just to be sure, I checked hdparm source code to see the value set in the command, and indeed, they also set it to 0xE0, so it’s probably legacy cruft: enum {ATA_USING_LBA= (1 lob.dev = 0xa0ATA_USING_LBA; Conclusion So basically, the updater does: download the list of updates check if a drive matches, set registry values the driver takes over and: checks if the drive is not connected through USB verifies it’s the actual drive specified in the registry using the IDENTIFY DEVICE command loops and sends the firmware update, 128 512-bytes chunks at a time, using the DOWNLOAD MICROCODE command verifies the drive was updated using the IDENTIFY DEVICE command Actually doing the update YOLO, I tried on my main NAS drive: # hdparm -I /dev/sdbgrep FirmwareFirmware Revision: 0601 # hdparm --fwdownload-mode3 sk060202.ftd --yes-i-know-what-i-am-doing --please-destroy-my-drive /dev/sdb /dev/sdb: fwdownload: xfer_mode=3 min=1 max=4224 size=512 ............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................... . Done. # hdparm -I /dev/sdbgrep FirmwareFirmware Revision: 0602 \\o/ Version 1.20.0410, MD5: 7cc7dc301f7b8a45cc56ee25e5707cc2, Date: 2023-12-27 ↩",
    "commentLink": "https://news.ycombinator.com/item?id=41423577",
    "commentBody": "Upgrading a Toshiba NAS HDD Firmware on Linux (syscall.eu)127 points by pabs3 10 hours agohidepastfavorite40 comments wannacboatmovie 9 hours ago> As usual, I wanted to check if any firmware update is available Updating HDD firmware is something you do to resolve a very specific problem, not ... just because it's available. People are blind to the fact that updates can and do introduce new bugs. reply kasper93 5 hours agoparent> Updating HDD firmware is something you do to resolve a very specific problem, not ... just because it's available. It is important to check if there is an update and what has been fixed. Like with any software, it may introduce new bugs, but blindly suggesting to \"not touch, if it's not broken\" is harmful too. Some time ago Samsung rolled out SSDs that were self-destructing after very short period of time and fixed this in firmware. If your SSD breaks or start having problems it is already too late to update, you have to be proactive. And hardware vendors doesn't release firmware updates for nothing, in most cases there is very good reason for that. reply M95D 1 hour agorootparentStop encouraging the manufacturers to ship bad firmware that \"will fix later\". reply syntheticnature 28 minutes agorootparentI think the manufacturers needed no encouragement, and at this point it would take multi-national intervention to get the genie back in the bottle. The poster you replied to simply recognized the situation for what it is: Samsung is still a going concern after releasing SSDs with firmware that would brick them after a relatively short service lifespan. reply Dalewyn 4 hours agorootparentprev>Some time ago Samsung rolled out SSDs that were self-destructing after very short period of time and fixed this in firmware. If it broke, fix it. If it ain't broke, don't fix it. The latter became a rule of life because many people decided to fix what ain't broke and got burned for their troubles. reply lhamil64 3 hours agorootparentBut how would you know it's broken unless you proactively check for updates? reply numpad0 17 minutes agorootparentJust checking for updates is fine, actually installing every single firmware versions is bad. This is because embedded firmware are less moving parts more tightly packed, which makes their failure modes inevitably catastrophic; they're incapable of progressively degrading like Electron apps, but the whole system always spontaneously crash into the wall and die from just one typo, and you don't want that. reply rbanffy 8 hours agoparentprevIt depends on what is in the changelog. If there are performance or durability improvements, you might want to change the firmware even if you are not facing a significant issue. The downside is the risk to data on the disk - don't do that (or anything, really) on a drive that holds the only copy of something important. If the drive is being moved to a different array or machine and the data is to be lost anyway, the risk is very low and, if the process is easy (unlike this) it might be a sensible move. I agree \"just because it's new\" is a poor justification to risk data. reply worewood 3 hours agorootparentMore often than not, the changelog just states \"performance improvement\" or \"bug fix\", without any detail on what they've done. For example, I've been bitten before by Dell due to plundervolt updates that removed the undervolting capability under the umbrella of \"security fixes\". reply rbanffy 2 hours agorootparent> I've been bitten before by Dell due to plundervolt updates that removed the undervolting capability That's enterprise computing for you. Been bitten by that kind of shenanigan more often than I can remember. reply HeatrayEnjoyer 2 hours agorootparentHappened to a colleague. Not sure if he ever found out how to rollback to the older version. reply miah_ 6 hours agorootparentprevHP has a bootable Linux CD that updates all the firmware on their devices, since the early 00's. We used to regularly update firmware across our entire fleet of servers during maintenance cycles. Never had a failure. reply Asmod4n 4 hours agorootparentYou are speaking about enterprise grade hardware which is meant to be updated. Consumer stuff not as much. reply naming_the_user 6 hours agorootparentprevBack in the day I'd just wing it, hey, firmware update the only harddrive I own, what could go wrong. Now if it's not on at least two drives within a few hours of something new (photo, video, work done, whatever) it seems like a terrible risk. Part getting old, part being able to afford to have redundancy, I guess. Storage feels so much cheaper now. reply vocram 6 hours agorootparentAnd in part because you remember all the times YOLO went wrong and you bricked stuff / lost data reply prmoustache 8 hours agoparentprevWell it is nice to stay current with the news about your harddrive. Wheren't there are some point some SSD from Intel or Samsung that would eventually brick themselves unless you applied some firmware? I remember having patched some SSDs for this very reason the last time I worked on on premise bare metal systems. reply EvanAnderson 8 hours agorootparentThe SSD firmware failure mode you're describing was a thing: https://www.cisco.com/c/en/us/support/docs/field-notices/705... reply jonhohle 3 hours agorootparentprevCrucial M4s certainly had one around 2010/2011. They would “fail” after 5,000 hours. reply numpad0 4 hours agorootparentprevStay current with news is good, stay unproven with firmware isn't. reply justinclift 6 hours agorootparentprev> Wheren't there are some point some SSD [...] would eventually brick themselves unless you applied some firmware? Yeah, that was a thing with older enterprise SAS SSDs a few years ago. HP, Dell, Lenovo, Cisco, etc, all affected as they all rebadge the available hardware manufacturer's drives. And several manufacturers have had bricking-firmware problems over the years. reply perching_aix 6 hours agoparentprevIt's just software like any other. It's vulnerable and it has defects. So it's very reasonable to at least check if there's an update available. > People are blind to the fact that updates can and do introduce new bugs. I do agree that this fact is often underappreciated - the single biggest cause of breakages are usually the rollout of changes themselves. But again, it's just like with any other software. reply Palomides 2 hours agoparentprevchangelogs are generally useless and manufacturers hate having to release firmware updates, so the mere existence of an update is pretty strong evidence there's something seriously wrong it's not like web or app dev where you can ship trivial upgrades every day for free reply TacticalCoder 6 hours agoparentprev> Updating HDD firmware is something you do to resolve a very specific problem, not ... just because it's available. Indeed. As an anecdotical data point: number of personal and servers HDD firmware upgraded over four decades (!)... Zero. Zero isn't not a lot. We should ask people who know what it's like to have a lot of HDDs: does BackBlaze upgrade their HDDs' firmwares? reply bustling-noose 7 hours agoparentprevaccording to the release notes 0602 fixed some SMART failures. Seems pretty important to me reply _joel 8 hours agoparentprevDepends if they've read the changelog and saw something useful or not, right? reply lupusreal 6 hours agoparentprevDon't fix it if it ain't broke. reply mkesper 10 hours agoprevList of devices upgradable easily from Linux by using firmware released on LVFS: https://fwupd.org/lvfs/devices/ reply dijit 8 hours agoparentThis solves such an important need, updating device firmware and bios’ was such a pain for the longest time, most manufacturers tend to give out only Windows executables- if you are lucky then some DOS compatible binary might be included, and then you could boot into FreeDOS. BIOS's got better about reading their own firmware from VFAT, but still getting the driver was a pain, because there was a strong preference for .exe's on websites. Seems much better now, I can run a small handful of commands and have my bios updated. It's still hard to know which motherboards/laptops are compatible with fwupd though. reply Thaxll 6 hours agoparentprevI was really surprised by that, I upgraded to Ubuntu 22 and magically it can upgrade firmware on my dell labptop. reply rwmj 2 hours agorootparentIt didn't just happen. Richard Hughes works with loads of different companies and gets them to provide the updates in the right format to work with LVFS, no easy task at all. https://blogs.gnome.org/hughsie/2023/12/06/100-million-firmw... reply klaas- 7 hours agoprevthere is something similar for WD drives as well. https://github.com/not-a-feature/wd_ssd_firmware_update/ https://github.com/not-a-feature/wd_fw_update I really hope some day there will be a big disk manufacturer that natively supports lvfs - I would pay a premium for that. reply fake-name 8 hours agoprev> hdparm --fwdownload-mode3 sk060202.ftd --yes-i-know-what-i-am-doing --please-destroy-my-drive /dev/sdb If nothing else, I certainly appreciate `hdparm`'s CLI flags reply 0xcde4c3db 5 hours agoparentDocumentation of this seems to have disappeared into the ether, but I'm reminded of the time that glxgears (or a distro package of it?) briefly turned off FPS output by default, with the argument to turn it on being something like --i-acknowledge-that-this-tool-is-not-a-benchmark Basically, people were complaining about \"major regressions\" in glxgears frame rates that were really just minor fluctuations in how long it took to clear and swap buffers, since glxgears does almost no actual rendering (by modern standards). reply Dwedit 1 hour agoparentprevHdparm's manual is amazing. \"This is EXTREMELY DANGEROUS and will very likely cause massive loss of data. DO NOT USE THIS COMMAND.\" \"VERY DANGEROUS, DON'T EVEN THINK ABOUT USING IT.\" \"VERY DANGEROUS, DO NOT USE!!\" \"This command is EXTREMELY DANGEROUS and could destroy both the drive and all data on it. DO NOT USE THIS COMMAND.\" \"EXCEPTIONALLY DANGEROUS. DO NOT USE THIS OPTION!!\" \"VERY DANGEROUS.\" \"(DANGEROUS)\" There's a reason why TvTropes lists the \"hdparm\" command under \"Schmuck Bait\". reply superkuh 4 hours agoprev>What’s interesting is the checksum at the end. It’s the CRC32 of the file, minus the last 10 bytes, which can be easily checked with the slice and crc32 tools of my hacking Swiss army knife rsbkb: I want to know the story of how he realized it was the CRC of the file minus the last 10 bytes. That's gotta be an interesting thought path. reply mschuster91 10 hours agoprev> The first one gives us our answer: the URL is stored in the registry. It’s actually written by the InstallShield setup. I... I mean, I get why they did this, rather than building a proper userspace application... but who the fuck thought this would be something that's acceptable to ship to consumers? And what happens in case there are multiple different disk models installed in the same system? reply echoangle 10 hours agoparentIf I understand it correctly, the URL lets you download a file that maps every Toshiba disk model to a firmware version (???). So having different disk models doesn’t change anything, the program just gets the file, checks which drive needs which version, and then downloads these firmware binaries and installs them. reply philjohn 9 hours agoparentprevOr someone social engineers you into clicking on a .reg file which changes these URL's to something malicious that will brick your drives. reply HHad3 9 hours agorootparentThey might just as well send any other .reg file that runs a program (e.g. by creating an autoboot entry, COM server, service, ...) that bricks devices. reply dark-star 10 hours agoprev [–] I usually use fwupd on Linux, which also downloads (and installs) SSD firmware. At least for my SSD, it did (also a Toshiba SSD IIRC) reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A user successfully reverse-engineered a Toshiba HDD firmware updater to work on Linux, originally only available for Windows.",
      "The process involved extracting update files, understanding the flashing process, and using specific Linux commands to update the firmware.",
      "This achievement allows Linux users to update their Toshiba NAS HDD firmware without relying on Windows tools."
    ],
    "commentSummary": [
      "The discussion centers on the importance and risks of updating Toshiba NAS HDD firmware on Linux.",
      "Firmware updates can resolve specific issues but may also introduce new bugs, making it crucial to review changelogs and update only when necessary.",
      "The conversation highlights various experiences and opinions on firmware updates, emphasizing the need for caution and the potential consequences of both updating and not updating firmware."
    ],
    "points": 127,
    "commentCount": 40,
    "retryCount": 0,
    "time": 1725265246
  },
  {
    "id": 41425563,
    "title": "Sleep on it: How the brain processes many experiences – even when 'offline'",
    "originLink": "https://news.yale.edu/2024/08/14/sleep-it-how-brain-processes-many-experiences-even-when-offline",
    "originBody": "Sleep on it: How the brain processes many experiences — even when ‘offline’ In a new study, Yale researchers uncover how the brain, during sleep, replays and bundles many of the experiences that occur in our waking hours. By Kevin Dennehy August 14, 2024 4 min read Share this with Facebook Share this with X Share this with LinkedIn Share this with Email Print this (AI-generated image, created and edited by Michael S. Helfenbein) Humans and other animals encounter and remember countless experiences each day; when we sleep, groups of cells in the brain known as neuronal ensembles replay these experiences to consolidate them into memories and “preplay” futures ones, which enables faster encoding of new experiences into memories later on. Better understanding how these neuronal ensembles represent, or depict, these experiences would offer important insights into how memory and the mind function. But most studies to date have focused solely on animals undergoing just one or a small handful of sequential experiences — and it remains unclear how exactly the brain is able to process numerous experiences simultaneously during sleep. In a new study, Yale scientists revealed a generative coding capacity in the brain’s hippocampus — an area responsible for memory and learning — which enables the brain to bundle together the representations of some 15 unrelated experiences that occurred across one full day within single sub-second events, known as frames, during sleep. In real life we are continuously experiencing new contexts and events that all need to be encoded distinctly and remembered later without a major interference between them. George Dragoi This computer-like capacity for parallel processing of different chains of information helps explain why humans and other animals are able to process a cascade of experiences and either keep separate or combine their meanings. The findings were published in the journal Nature Neuroscience. “The brain mechanisms we uncovered are relevant for how we form and express internally generated representations about the world, like memories, imagining, and insight,” said George Dragoi, an associate professor of psychiatry and of neuroscience at Yale School of Medicine and corresponding author of the study. An increasing amount of neuroscience research is exploring how neuronal ensembles represent experiences in the brain, a complex process that has implications for learning and memory, cognitive mapping, and spatial navigation. The fact that most studies involve animals undergoing a single experience, however, has prevented researchers from assembling a more complete picture. “In real life we are continuously experiencing new contexts and events that all need to be encoded distinctly and remembered later without a major interference between them,” Dragoi said. “The way the brain solves this problem is not known and experiments attempting to address this topic are essentially missing. “Computational models have proposed that exposure to multiple experiences would lead to a ‘catastrophic interference’ between the brain representations of new and older experiences, causing the individual to forget the latter,” Dragoi said. “That, of course, is not how daily life works.” For the new study, the researchers recorded the activity of hippocampal neurons in rats that were allowed to move freely through 15 different spatial contexts over 19 ½ hours, a time span that included periods of extended sleep, during a single day. (The periods of sleep were used to investigate “offline” activity in the animals’ brains, in terms of preplay and replay of experiences.) Using innovative data analysis, they identified several coding schemes in the hippocampus that boost its network capacity and efficiency during sleep and allow the brain to process representations of several experiences without interference. Specifically, they found that the brain is able to “flicker” between time-compressed representations from two or more distinct experiences within the same sleep preplay and replay events, a feature that greatly increases network capacity for parallel information processing without interference during sleep. In addition, independent experiences can be bound together into longer preplay/replay episodes representing sequential aspects of day-long experiences in the order in which they occurred compressed into replay episodes less than a second in duration. The researchers also identified a kind of serial position effect in this process, whereby the first and most recent experiences had the strongest representations during the animals’ sleep, a phenomenon similar to the effect observed in human memory in which people tend to recall the first and last events in a series of events or items. Other authors of the paper are Kefei Liu and Jeremie Sibille, a former associate research scientist and postdoctoral associate, respectively, in Dragoi’s lab at Yale School of Medicine. Health & Medicine Share this with Facebook Share this with X Share this with LinkedIn Share this with Email Print this Media Contact Bess Connolly : elizabeth.connolly@yale.edu,",
    "commentLink": "https://news.ycombinator.com/item?id=41425563",
    "commentBody": "Sleep on it: How the brain processes many experiences – even when 'offline' (yale.edu)116 points by PaulHoule 4 hours agohidepastfavorite50 comments timshell 1 hour agoHippocampal replay was the main subject of my dissertation. It has been studied primarily in rodents, but there have been a lot more human studies in the meantime. My PhD proposal was to suggest that cognitive fatigue is an adaptive construct. Rather than reflect a depletion of glucose and that people can't function anymore, cognitive fatigue is a suggestion for the agent to go 'offline' and replay. Two of my collaborators wrote an extremely influential paper writing down a Q-learning equation for replay: https://www.nature.com/articles/s41593-018-0232-z reply bmitc 47 minutes agoparentWhat do you mean by agent? Human, brain, some component of the brain, etc.? reply arcanemachiner 34 minutes agorootparentSeems like \"human\", \"rat\", etc. in this context. reply samstave 1 hour agoparentprevThis is amazing to hear. Have you studied the hippocampus memory of hummingbirds much? Their glucose is consumed to preserve their extraordinary 3d spatial memory for all their food sources. reply timshell 58 minutes agorootparentWhoa very cool, had no idea about that. I've always been intrigued to see whether there could a reconciliation between the normative replay theory and the glucose depletion theory. A paper that made me think there could be a route: https://pubmed.ncbi.nlm.nih.gov/34381214/ reply maxbond 11 minutes agoparentprevYou should rest and meditate on what you have learned. reply uv-depression 3 hours agoprevStarting with my undergrad but fully committing to it by grad school, I (and several of my friends who went through similar programs in math/cs) have a strategy that uses this. If, for example, I had a new problem set in a math course, I would bash my head against it in the evening for an hour or two. I'd make an honest attempt but move on from problems quickly if I got stuck. I'd rarely get much done. Then, I'd do my best to get a good night's sleep (at least 7.5 hours quality sleep). In the morning I'd try the problems again first thing after coffee, and frequently found that I could do a significant portion of the problems, or at least make headway. This might be biased by the fact that I'm really much more of a morning person to begin with, but I know several people who use this strategy. reply euroderf 2 hours agoparentWhile programming Java full-time, I found myself waking in the middle of the night with some big chunk of my brain grinding away on coding issues. Not good. reply huijzer 2 hours agorootparentI agree. It can definitely be useful, but not if I'm stressing too much about it. Then, waking up feels like I was hit by a bus in the night. reply tzs 2 hours agoparentprevI do the same with the NYT crossword puzzles. The puzzle for a day is released at 10 pm NY time (except the Sunday and Monday puzzles are released 4 hours earlier) the day before, which is 7 pm in my time zone. I start the puzzle at the end of my day. If I get stuck and cannot finish it before I fall asleep, probably 95% of the time when I take a look again sometime the next day I immediately see answers to several of the things I was stuck on and finishing the puzzle goes smoothly. reply Terr_ 1 hour agorootparentWas that because your mind was working on it in the background, or because a reset in state allowed the next attempt to find new paths? I wonder if it would be possible to make a study to someone distinguish between those, like where the control group gets REM sleep and the experimental group gets some kind of anesthesia. Is there a difference on how well each group does \"returning\" to a puzzle, compared to working on a fresh one? reply sidnb13 2 hours agoparentprevCool to see that this worked well for someone. Super hard to force the key insight in a problem to magically appear given more time sunk into it. Big weakness of mine honestly, and requires a lot of self-awareness to pull myself out of a problem-solving rut. I like the idea of hacking sleep - do you find yourself priming your mind with the problem before nodding off? Curious how a bedtime wind-down routine factors into how effective this is. reply schmidtleonard 1 hour agorootparentOver years of math undergrad and grad school I tried very hard and was never able to get this to work, so you're not alone. I was able to reliably reproduce hopeful feelings after sleep, but upon investigation the \"new leads\" were either things I had already tried (and forgotten why they didn't work) or they were the type of imprecise high-level vague direction ideas that were never difficult to generate and still had 99% of the true effort remaining to grind through the details. reply bloopernova 2 hours agoprevAdmiral Raymond Spruance of the World War 2 US Navy was known as very calm in a crisis; he was very serious about getting enough sleep so that he was well-rested during any battles. When other officers would stay awake for 36 to 48 hours at a stretch, he would read a novel and get sleep because he knew he had enormous responsibilities that needed him at his best. He also walked 8+ miles a day, even when at sea he would make sure he walked around the ship, usually with some other officers to discuss any pertinent issues of the day. Walking is great for turning over problems in your mind, or even just daydreaming to give your subconscious mind \"space to work\". reply encomiast 1 hour agoparentI am also a habitual walker, though I don't typically get eight miles in. I often listen to books and podcasts while walking and at times wonder if I'm doing myself a disservice by not just letting my mind wander. One the one hand, it is about the only time I allow myself a solid hour to listen to something, but on the other maybe it's time better spent giving 'space to work' as you say. reply Towaway69 1 hour agorootparentTry listening to “white noise” or sound-scapes - something that provides an endless blanket of sound without providing input that the brain has to actively process. reply Towaway69 2 hours agoprevI’ve been lucky enjoy to have been able to live around my unconscious. I made a conscious decision to allow my unconscious to guide me through life. The original idea to do this came from Le Corbusier[1] who once described his process of working as being a phase of collecting details on a project, a phase of doing something else (allowing his unconscious to work on the project) and finally he would sit down and complete the project. The disadvantage is that I never know when inspiration hits and when exactly I will get something done. It’s important to be organised and have everything written down is my approach. Also I give myself time and room to explore possible solutions from seemingly unrelated areas - a kind of zen navigation[2] for project work. [1] https://en.wikipedia.org/wiki/Le_Corbusier [2] https://www.goodreads.com/quotes/667285-he-had-a-tremendous-... reply financetechbro 29 minutes agoparentDo you have more details on your strategy? reply keiferski 3 hours agoprevSomething I've been wondering about - but have been unable to find any solid research on - is if it would be \"optimal\" to sleep immediately after any learning/training session, whether it be mental or physical, instead of just resting while still awake. If sleep is the best state for the body to be in to consolidate memories, reduce fatigue, etc., then it would seem logical to try and be in the sleep state as much as possible. Obviously the difficult part is actually being able to fall asleep on command without using some kind of pharmaceutical, but I do think falling asleep quickly is something that can be learned: https://www.inc.com/melanie-curtin/want-to-fall-asleep-faste... reply mtalantikite 2 hours agoparentWould love to see some research on it, but this reminds me of the structure of a traditional yoga asana practice and I've wondered the same thing about rest after a learning/training session. Typically at the end of a practice session of yoga asana (and sometimes in between postures) you'll take savasana and just rest in open awareness. A teacher of mine would always say this is the most important part of class, to let everything integrate in. When I started training Muay Thai I found that I often would \"lose\" a lot of what we had worked on in class, and then started taking savasana right when I got home. In that not-quite-sleep state my brain would replay what we worked on. Sometimes if I'm really bashing into a wall with some coding problem I'll just take savasana for 10-15 minutes and get back to it. I feel like it helps. reply nope1000 3 hours agoparentprevFunnily enough I wonder if a burst of adrenaline after learning is effective. Kind of tricking your brain into thinking it just survived a dangerous situation and must retain whatever lead up to it. reply whycome 2 hours agorootparentUsing our evolutionary predispositions for good rather than evil?? I always wondered in a half serious way if sex (just innuendo or tittilating images or something) could have positive effects on learning if done right for the same reasons: evolutionarily wanting to retain information if it has a better chance of leading to mating. Of course you'd only test this with adult students. reply keiferski 3 hours agorootparentprevI was watching one of those performance science podcasts (Hubermann, I think) and I do believe he said that if you take a cold shower immediately after learning, it increases the likelihood that you'll remember it. So I wonder if the optimal learning pattern would be learn > cold shower > sleep. Don't quote me though, as it's been awhile. reply timshell 1 hour agoparentprevThis was somewhat the thesis of my dissertation. I suggested cognitive fatigue was an adaptive construct that biases people to go offline and replay their memories, and that this was decision-theory optimal from a learning / reward perspective. https://mayank-agrawal.com/papers/AgrawalMattarCohenDaw21.pd... reply Towaway69 1 hour agoparentprevWhen I feel fatigue coming on, I just lie on a sofa with some soundscape playing on my noise cancellation headphones. I close my eyes and allow my mind to drift. Similar to the phase before falling asleep. Most of the time, this mind drifting is enough but sometimes I fall asleep - both states help. reply whycome 2 hours agoparentprevThe whole setup of the modern school day is dumb. It's too early for many growing minds. And it doesn't balance what's taught with a chance to reflect on it. And the school year should be the whole year with more breaks rather than a summer time off. It would be pretty cool to have some sort of siesta for students in the day. Maybe one of those private schools would do it. reply Buttons840 21 minutes agoprevI've often though about sleep in RPG terms. Sleeping gives me 1 experience point to put into any skill, and I get to choose which skill gets the experience point by what I work on during the day. I haven't always succeeded, but I try to at least work-on or study something I care about before bed. reply escapecharacter 18 minutes agoparentI love this! When dealing with a difficult problem, I like to think about it in my head as falling asleep. I find I don’t necessarily have the solution upon waking, but I will understand the space better, and be less fixated on whatever my initial thought was. reply yamrzou 2 hours agoprevRelated: The Committee of Sleep: How Artists, Scientists, and Athletes Use Dreams for Creative Problem-Solving – https://en.wikipedia.org/wiki/The_Committee_of_Sleep reply RHSman2 2 hours agoprevCar drive: Bash head against wall all day. Give up. Drive home in zoned out state and realize solution (or at least the unseen issue). reply ricardo81 3 hours agoprevInteresting, as I would divide my dreams up 25/25/25/25 between mundane daily experiences, the same or very similar dream, totally new situations and finally the surreal ones where you magically end up in random places and random situations. Always figured it's a blend of taking past and recent experiences and re-ordering them, with a hint of hypothetical scenarios for the future. The \"flicker\" sounds like a good A/B test for the hypothetical while the replays are good for memorisation. I can often tell when I'm dreaming when it comes to the more hypothetical ones due to dodgy physics or whatever (try nipping my face and can't feel anything) so I'm probably buggering that process up a bit. Maybe an INTJ trait. I remember doing that as a kid and being able to fly, but nowadays often I can't get beyond 10 metres above ground. Been rate limited. reply Hadriel 1 hour agoprevOk can someone explain how they reached this conclusion that the brain is able to separate, merge, or drop experiences during sleep within 1 second? The rat experiment mentioned doesnt explain how they are able to interpret brain signals and map them to prior experiences. reply Almondsetat 3 hours agoprevSleeping to solidify memories and concepts is like when you were a kid and you just slept off the entire 8 hours car journey. Not only you get the sleep, not only you get the result, but you also didn't even notice it happen reply wrycoder 3 hours agoprevSince this is processing of past events and future possibles during sleep, would it be fair to hypothesize that animals that sleep actively (appear to dream) are conscious when awake? reply Towaway69 2 hours agoparentSome go as far as believing that plants have consciousness. Which isn’t surprising considering slime moulds: > Slime molds have a variety of behaviors otherwise seen in animals with brains.[0] [0] https://en.wikipedia.org/wiki/Slime_mold reply visarga 1 hour agoprevIt's what LLMs are missing. They don't sleep. If only they could sleep, they would be able to make novel experiences stick past the context buffer. Sleep is like fine-tuning on previous interactions. reply dr_dshiv 3 hours agoprevAre we unconscious when we sleep or do we merely lose the capacity to remember? How could we tell the difference? reply krisoft 2 hours agoparent> Are we unconscious when we sleep I don't think that is the right question to ask. Sleeping person is unconscious almost by definition. They don't respond to stimuli and they don't do much of anything besides breathing and just laying there. > do we merely lose the capacity to remember? That is a better question. Some people remembers their dreams. Sometimes people can remember stimuli which happened while they were asleep. (For example it happened multiple times to me that noises happening around me where incorporated into my dreams in various forms.) So if sleeping were just amnesia then these dream memories would need to be explained somehow. reply dr_dshiv 0 minutes agorootparentI disagree that sleep is necessarily unconscious. It’s like a coma — but is the internal world still running? For instance, maybe we are conscious in different phases of sleep but not others. reply CuriouslyC 3 hours agoparentprevResearch has shown that we form memories related to things that happen around us in our sleep and are conscious in some ways. We don't form episodic memories of sleep time and it's likely that what it's like to be conscious while asleep is quite different from our waking experience even aside from dreams. reply patafemma 2 hours agoparentprevI guess it depends on how you define consciousness. I think by most definitions, we definitely are unconscious when we are asleep. reply dr_dshiv 9 minutes agorootparentDreaming is clearly both sleep and conscious reply harry_ord 2 hours agoparentprevI think there's a medical difference between unconscious and sleeping. At least I don't think being forced unconscious by something (a bonk on the head) is like sleeping reply swayvil 50 minutes agoparentprevEver entered a room and immediately forgot why you came in? Dream might be much the same. Memory could be attached to context. Change the context extremely and you lose the associated memories. And dream is an extreme change of context. reply guerrilla 3 hours agoparentprevAre we sure there is a difference? reply namero999 3 hours agorootparentOf course there is a difference. You are probably conscious right now of more things that you don't even register, like the movement of your chest while breathing, sounds outside of your window, etc. It's indeed the difference between consciousness and metaconsciousness, the latter being the ability to re-represent an experience to your cognition (which remembering is an instance of). A very doable experiment. Whether you remember your dreams or not, next time you wake up, ask yourself whether you were conscious just a moment before waking up. reply guerrilla 1 hour agorootparent> You are probably conscious right now of more things that you don't even register I would say this is a contradiction. > A very doable experiment. Whether you remember your dreams or not, next time you wake up, ask yourself whether you were conscious just a moment before waking up. This is begging the question. It seems possible that we were conscious of our dreams if we remember them and were not conscious of them if we don't. reply fredgrott 2 hours agoprevA way to improve it is to use ZettelKasten note taking to detail the problems in tackling the problem so that when you wake up you can review those notes before re-examining your approach to the problem... I started using this approach about 20 days ago...came up with new software architecture beyond cleanarch due to this new using of those techniques. reply swayvil 3 hours agoprevAfter much thought I have decided that thought is central to this whole thing. Anybody who disagrees is dreaming. EDIT Satire is lost on you people. reply not_a_dane 3 hours agoprev [–] spit on it. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Yale researchers discovered that the hippocampus replays and bundles waking experiences into memories during sleep, enhancing memory encoding and recall.",
      "The study, published in Nature Neuroscience, showed that the brain can compress up to 15 unrelated experiences into sub-second frames, improving network capacity and efficiency.",
      "Findings revealed a serial position effect, where the first and most recent experiences had the strongest representations, offering insights into memory formation and cognitive processes."
    ],
    "commentSummary": [
      "The brain processes experiences during sleep through hippocampal replay, aiding in memory consolidation and problem-solving.",
      "Cognitive fatigue triggers the brain to replay memories, suggesting that rest is crucial for learning and cognitive function.",
      "Techniques such as taking breaks, walking, or meditating are discussed as strategies to optimize learning and problem-solving."
    ],
    "points": 116,
    "commentCount": 49,
    "retryCount": 0,
    "time": 1725286628
  },
  {
    "id": 41425259,
    "title": "DOjS – A DOS JavaScript Canvas with Sound",
    "originLink": "https://github.com/SuperIlu/DOjS",
    "originBody": "DOjS A DOS JavaScript Canvas with sound. DOjS is a JavaScript programming environment for systems running MS-DOS, FreeDOS or any DOS based Windows (like 95, 98, ME). It features an integrated editor, graphics & sound output, mouse/keyboard/joystick input and more (see below). It was inspired by Processing which is described on Wikipedia as: Processing is an open-source graphical library and integrated development environment (IDE) / playground built for the electronic arts, new media art, and visual design communities with the purpose of teaching non-programmers the fundamentals of computer programming in a visual context. It also has a p5js compatibility mode where some of the functions of p5js are available and scripts can have a similar structure to Processing sketches. You can type in a script with the builtin or your favorite text editor and then run it on a DOS command prompt. DOjS is pronounces like doge, but ending with an \"s\". DOjS was only possible due to the work of these people/projects: MuJS JavaScript interpreter The Allegro library and Allegro XC DJGPP from DJ Delorie and the Linux compile scripts by jwt27. The people that contributed to p5js. The Glide source cleanup of Ozkan Sezer. AllegroPNG PNG loader for Allegro DZCOMM COM port library libcpuid for cpuid module curl and OpenSSL for curl module cylindrix for IPX module nanosvg for SVG loading noise for perlin noise generation genann for neural network engine SQLite for sqlite module Watt32 for TCP/IP networking zip for ZIP file access zlib for compression stb_image.h for JPEG loading AnimatedGIF for rendering GIF animations. PL_MPEG for mpeg1 decoding pdfgen for PDF rendering. micromod for MOD playback. ibxm for MOD, S3M and XM playback. ini for INI file reading. Mesa for OpenGL libwebp for WebP decoding/encoding Contact You can find me on Mastodon, in the DOjS Discord or on Twitter if you want... Download and quick start You can find binary releases on the GitHub release page. Just extract the contents of the archive and run DOjS.exe. DOjS runs in Dosbox and on real hardware or a virtual machine with MS-DOS, FreeDOS or any DOS based Windows like Windows 95/98/ME. To use 3Dfx/Glide support you need a Voodoo card or DOSBox-X (see below). If you run it on real hardware you need at least a 80386 with 4MB. I recommend a Pentium class machine (>= 100MHz) with at least 32MB RAM. The example files run fine on an Athlon 1GHz and with 256MB RAM. The following hardware/functions are available: 8/16/24 and 32 bit 2D graphics. On 24/32bit display modes alpha channel transparency is available. BMP, PCX, TGA, QOI and PNG image reading and writing, JPEG and SVG loading GRX font loading and rendering Keyboard input Mouse input Joystick/Joyport input File IO MIDI output WAV output Audio input/sampling Allegro 3D rendering (software) 3dfx/Glide3 3D rendering output (hardware) Mesa/OpenGL wrapper with 3dfx based hardware acceleration p5js compatibility direct io-port access (inb, outb, etc) LPT or parallel port access (bi-directional) COM or serial port access IPX and TCP/IP networking ZIP file access GIF-Animation, FLC/FLI, MPEG1 or OggVorbis playback HTTPS support through libcurl and mbedTLS PDF generation Examples See DOStodon for an complex examples. It is a full Mastodon client implemented using DOjS. A minimal script You can find the following example in examples/exampl.js: /* ** This function is called once when the script is started. */ function Setup() { pink = new Color(241, 66, 244, 255); // define the color pink } /* ** This function is called repeatedly until ESC is pressed or Stop() is called. */ function Loop() { ClearScreen(EGA.BLACK); TextXY(SizeX() / 2, SizeY() / 2, \"Hello World!\", pink, NO_COLOR); TextXY(10, 10, \"rate=\" + GetFramerate(), EGA.BLACK, EGA.LIGHT_BLUE); } /* ** This function is called on any input. */ function Input(event) { str = JSON.stringify(event); } Open this script with DOjS.EXE examples\\exampl.js or use DOjS.EXE -r examples\\exampl.js to run it without starting the integrated editor first. If the script does not exist the editor loads the template for a new script. p5js compatibility If you want to write scripts using the syntax of p5js you need to use Include('p5'); as first line of your script. You can find the following example in examples/examplp5.js: Include('p5'); /* ** This function is called once when the script is started. */ function setup() { pink = color(241, 66, 244); // define the color pink } /* ** This function is called repeatedly until ESC is pressed or Stop() is called. */ function draw() { background(EGA.BLACK); stroke(pink); fill(pink); text(\"Hello p5js World!\", width / 2, height / 2); stroke(EGA.LIGHT_BLUE); fill(EGA.LIGHT_BLUE); text(\"rate=\" + getFrameRate(), 10, 10); } More info can be found at the end of this README in the section Usage and in the API documentation. Take a look at the examples/ as well. additional packages DOjS has a very simple integrated package manager (DPM). It can be started with DPM.BAT. A working packet driver is needed to connect to the package index and download packages using HTTPS. Packages (and the package index) are fetched from the DOjS/jSH package repository. Downloaded packages are put into JSBOOT.ZIP in the PACKAGE/ directory. Feel free to submit any packages you want to include in that repository using a pull request. DPM commands: installed - list installed packages. remove - remove package. fetch - fetch package index from server. install - install a package (and its dependencies) from package index. list - list available packages in index. setindex - set index URL (HTTP or HTTPS). help - this help.; quit - exit dpm. 3dfx/Glide support DOjS supports most of the Glide3 API that was used with 3dfx accelerator cards. The following hardware is supported: Voodoo 1 [tested] Voodoo 2 [tested] Voodoo 3 [tested] Voodoo 4 [tested by tunguska] Voodoo 5 [tested by tunguska] Voodoo Rush (all versions) [tested] Voodoo Banshee (PCI and AGP) [tested] Additionally you can use DOSBox-X which emulates a Voodoo 1 card. Glide functions can be found in the 3dfx-module in the documentation, Javascript support functions have a \"FX\" prefix, all native functions are prefixed with \"fx\". Detailed Glide3-API documentation can be found on the internet, e.g. on FalconFly Central. Make sure you grab the Glide3 SDK and not Glide2! You can use the included DOS version of TEXUS.EXE to convert bitmaps to 3df texture files that can be loaded as textures. !!! Attention !!! 3dfx/Glide3 support ONLY works in plain DOS, NOT in the DOS/command window of Windows 9x! Be sure to always boot into a pure DOS prompt before trying to use any of the fx-functions! Before using 3dfx/Glide3 support you need to copy the appropriate GLIDE3X.DXE into the same directory as DOJS.EXE. You can do so by using the V_XXX.BAT scripts in the distribution ZIP archive. Software created with DOjS DutchTux has created a GUI toolkit for DOjS: https://github.com/dutchtux3000/jiyuai I created a Mastodon client for MS-DOS using DOjS: https://github.com/SuperIlu/DOStodon I made a text adventure with DOjS: https://superilu.itch.io/spacebutton And also a match-numbers-game: https://superilu.itch.io/numgam Compilation You can compile DOjS on any modern Linux (the instructions below are for Debian based distributions) or on Windows 10 using Windows Subsystem for Linux (WSL). Setup Windows Subsystem for Linux (WSL) according to this guide (I used Ubuntu 18.04 LTS). Preparation Build and install DJGPP 12.2.0 according to this guide. Install NVM. I used the following command lines to update/install my dependencies: sudo apt-get update sudo apt-get dist-upgrade sudo apt-get install bison flex curl gcc g++ make texinfo zlib1g-dev g++ unzip htop screen git bash-completion build-essential zip dos2unix python3 nvm install node npm install -g jsdoc npm install -g better-docs And the following commands to build and install DJGPP to /home/ilu/cross.: git clone https://github.com/jwt27/build-djgpp.git cd build-djgpp ./build-djgpp.sh --target=i586-pc-msdosdjgpp --prefix=/home/ilu/cross all Getting & Compiling DOjS Open a shell/command line in the directory where you want the source to reside. Checkout DOjS from Github: git clone https://github.com/SuperIlu/DOjS.git Make sure DJGPP is in your PATH and DJDIR is set (e.g. I have these lines in my ~/.profile): # DJGPP export PATH=/home/ilu/djgpp/bin/:/home/ilu/djgpp/i586-pc-msdosdjgpp/bin/:$PATH export DJDIR=/home/ilu/djgpp/ If you used Windows-Tools to check out DOjS from git you may need to fix the newlines of the shell scripts by using make fixnewlines. Now you are ready to compile DOjS with make clean all. This might take some time as the dependencies are quite large. make distclean will clean dependencies as well. make zip will create the distribution ZIP and make doc will re-create the HTML help. Compile the Linux version of DOjS There is an experimental Linux version of DOjS. It only supports a subset of the DOS version and should be considered ALPHA! See this file for more information. Notes 3dfx/Glide3 In order to compile DOjS you need Glide3 includes and binaries. The ones included with the DOjS sources were created using my glide repository on GitHub. GRX Fonts DOjS comes pre-bundled with all fonts included with GRX (files ending with \".FNT\"). If you want/need additional fonts you can find a very simple tool to convert TTF/BDF fonts to GRX format here. Results may vary... A minimal version capable of converting BDF fonts to FNT is included with DOjS (FONTCONV.EXE). You can find information on how to convert a TTF to BDF here. Live coding If you run DOjS on a computer with network interface and a matching packet driver you can (sort of) live code using the VSCode extension in vscode\\livedojs-0.0.4.vsix. You need to start DOjS -r examples/websvr.js and then set the IP address in VSCode using the command DOjS: Set hostname. Live coding sketches must look like below to work: // livedojs exports.Setup = function () { } exports.Loop = function () { ClearScreen(EGA.BLACK); FilledBox(10, 10, 70, 20, EGA.GREEN); } The first line must be exactly // livedojs The file must end with .js Only Setup() and Loop() are available, Input() does not work. p5js compatibility does not work, you must code using DOjS native API If the hostname is set the sketch will be automatically be uploaded on save The sketch can be uploaded using DOjS: Upload sketch manually you can access the JSLOG.TXT of the running server by using DOjS: get logfile History See the changelog for the projects history. Planed work Stack trace selector in the editor TCP/IP remote logging/debugging. add FFT module add webp decoder (https://github.com/webmproject/libwebp/blob/main/doc/api.md) Add ZIP file functions (e.g. https://libzip.org/users/ or https://github.com/kuba--/zip). Implement 3df file loading from ZIP add/implement some more math functions https://mathjs.org/ https://github.com/evanw/lightgl.js Fix bugs! Anything fun... http://www.speech.cs.cmu.edu/flite/ http://speect.sourceforge.net/ http://espeak.sourceforge.net/ Licenses See LICENSE file for all licenses. DOjS All code from me is released under MIT license. MuJS MuJS is released under ISC license. See COPYING in the MuJS folder for details. Allegro Allegro 4 is released under the Giftware license (https://liballeg.org/license.html). GRX fonts The GRX fonts are under MIT and other licenses. See copying.grx in LICENSE for details. The converted fonts from the Linux Font Project are in the public domain. IPX and dosbuffer sub-system This code is taken from the game Cylindrix by Hotwarez LLC, Goldtree Enterprises. It was released under GPLv2. CWSDPMI.EXE CWSDPMI DPMI host is licensed under GPL. The documentation states: The files in this binary distribution may be redistributed under the GPL (with source) or without the source code provided. 3dfx/Glide3 The code is licensed under \"3DFX GLIDE Source Code General Public License\". Source code is available at https://github.com/SuperIlu/glide DZComm DZComm serial library is release as gift-ware. See readme.txt in the dzcomm folder for details. Logo The DOjS logo dog was downloaded from Pexels and kindly provided by Iago Garcia Garcia. The logo font is Comic relief by Jeff Davis provided under SIL OPEN FONT LICENSE Version 1.1. WAVs All WAV files were downloaded from BigSoundBank and are licensed under WTFPL https://bigsoundbank.com/detail-0283-song-of-rooster.html https://bigsoundbank.com/detail-1102-bell-bike-5.html https://bigsoundbank.com/detail-1023-explosion-far-away.html MIDs The MIDI files were downloaded from the FreeDOOM project and are licensed under this license. p5js and examples p5js is is released under LGPL. The examples are licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. zlib zlib is released under zlib license. alpng Copyright (c) 2006 Michal Molhanec This software is provided 'as-is', without any express or implied warranty. In no event will the authors be held liable for any damages arising from the use of this software. Permission is granted to anyone to use this software for any purpose, including commercial applications, and to alter it and redistribute it freely, subject to the following restrictions: The origin of this software must not be misrepresented; you must not claim that you wrote the original software. If you use this software in a product, an acknowledgment in the product documentation would be appreciated but is not required. Altered source versions must be plainly marked as such, and must not be misrepresented as being the original software. This notice may not be removed or altered from any source distribution. zip code See UNLICENSE in zip directory. WATTCP See manual.txt in watt32 directory. OpenSSL The OpenSSL toolkit stays under a double license, i.e. both the conditions of the OpenSSL License and the original SSLeay license apply to the toolkit. cURL See COPYING in curl directory. genann See LICENSE in neural.dxelib. sqlite See LICENSE.md in sqlite.dxelib. libcpuid See COPYING in cpuid.dxelib. nanosvg See LICENSE.txt in nanosvg.dxelib. noise See LICENSE.md in noise.dxelib. nanojpeg See nanojpeg.c in jpeg.dxelib. nanojpeg See LICENSE in gifanim.dxelib. Usage Command line Usage: DOjS.EXE [] [script parameters] -r : Do not invoke the editor, just run the script. -l : Use 50-line mode in the editor. -w: Screen width: 320 or 640, Default: 640. -b: Bit per pixel:8, 16, 24, 32. Default: 32. -s : No wave sound. -f : No FM sound. -a : Disable alpha (speeds up rendering). -x : Allow raw disk write (CAUTION!) -t : Disable TCP-stack -n : Disable JSLOG.TXT. -j: Redirect JSLOG.TXT to . dojs.ini All command line options can also be provided in dojs.ini (which is read at startup from the current directory). See the included example for details. Editor keys F1 : Open/Close help SHIFT-F1 : Function context help F3 : Save script F4 : Run script F7 : Find text F9 : Show/Close logfile F10 : Quit Shift-F4 : Truncate logfile and run script Shift-F7 : Find again CTRL-D : Delete current line SHIFT+Movement : Select text, releasing SHIFT deselects CTRL-C : Copy selection CTRL-X : Cut selection CTRL-V : Paste CTRL-LEFT : Previous word CTRL-RIGHT : Next word CTRL/PAGE-UP : One page up CTRL/PAGE-DOWN : One page down HOME : Go to start of line END : Go to end of line CTRL-HOME : Go to start of line CTRL-END : Go to end of line TAB : Insert spaces until next TAB-stop at cursor SHIFT-TAB : Reduce indentation of line TAB size is 4. The help viewer will remember the current position. The logfile can be truncated by pressing DEL in the log viewer. Scripts and resources Scripts, as well as resources can either be stored in the file system or in ZIP files. To load data from a zip file the format is = (e.g. data.zip=mypic.bmp). DOjS can be started with a script, a script in a ZIP file or no parameters. If the script was loaded from a ZIP file the running script can obtain resources from the same ZIP file by using ZipPrefix() to obtain paths refering to that ZIP. If the script was not started from a ZIP ZipPrefix() just passes through the file name (thus loading the file from HDD). If no arameters are supplied DOjS will first try to load .ZIP=MAIN.JS and then JSBOOT.ZIP=MAIN.JS. Examples: DOJS.EXE -r script.js will start script.js from the HDD, ZipPrefix(\"pic.bmp\") will yield pic.bmp. DOJS.EXE -r data.zip=script.js will start script.js from the ZIP file data.zip, ZipPrefix(\"pic.bmp\") will yield data.zip=pic.bmp. HURTZ.EXE DOjS was renamed to HURTZ.EXE. It will start MAIN.JS from the ZIP file HURTZ.ZIP, ZipPrefix(\"pic.bmp\") will yield HURTZ.ZIP=pic.bmp. DOJS.EXE The script was added to JSBOOT.ZIP. DOjS will start MAIN.JS from the ZIP file JSBOOT.ZIP, ZipPrefix(\"pic.bmp\") will yield JSBOOT.ZIP=pic.bmp. API documentation You can find the full API doc in the doc/html/ directory. Go to the p5.js hompage for p5.js reference. Script format Scripts need to provide three functions: Setup(), Loop() and Input(). Scripts are loaded and executed top-own. After that Setup() is called once and then Loop() repeatedly. Input() is called whenever mouse of keyboard input happens. Setup() This function is called once at startup. It can initialize variables, setup hardware, etc. Loop() This function is called after setup repeatedly until Stop() is called. After calling Stop() the program ends when Loop() exits. Input(event) This function is called whenever mouse/keyboard input happens. IPX networking DOjS supports IPX networking. Node addresses are arrays of 6 numbers between 0-255. Default socket number and broadcast address definitions can be found in jsboot/ipx.js. Drawing functions See API doc for details. Processing/p5js compatibility layer Add Include('p5'); as first line to your script. After that you have (limited) p5.js compatibility. Things that don't work: Anything 3D (objects, lights camera, etc) Key release events work different for Allegro and are simulated for p5js. Only simple vertices are supported. no DOM Logfile All output via Print() and Println() is sent to the file JSLOG.TXT. You can use Debug() instead and output is only generated when you set the global variable DEBUG=true. Remote logging/debugging This feature allows you to debug a running script via IPX networking and a second machine. To use remote logging do the following: Put both machines on the same network. Run DOJS.EXE -r JSBOOT\\LOGVIEW.JS on one machine. Enable debugging by setting DEBUG=true and enable remote debugging by REMOTE_DEBUG=true. You can either modify JSBOOT\\FUNC.JS or change the variables at the very beginning of your script. This works fine with two instances of DOSBox as well. Please note that if the log messages are transmitted to fast the receiving instance of DOJS might skip some of these when displaying.",
    "commentLink": "https://news.ycombinator.com/item?id=41425259",
    "commentBody": "DOjS – A DOS JavaScript Canvas with Sound (github.com/superilu)113 points by AlexeyBrin 5 hours agohidepastfavorite12 comments redbell 1 minute ago> If you run it on real hardware, you need at least an 80386 with 4MB. I recommend a Pentium class machine (>= 100MHz) with at least 32MB RAM. This is nostalgic (¬‿¬) I recall my very first computer was an Intel Pentium I with 16MB of RAM and around 2.5GB of HDD. Nowadays, even the cheapest smartphone would outperform, by far, those machines. reply xhrpost 4 hours agoprevThis is great work! I've been interested in having a ready to go dev environment for DOS where you just do straight INT 10H development like back in the day. Is it possible to compile work here to an actual x86 DOS executable that could run on DOS without this environment? reply SuperIlu 1 hour agoparentNo, sadly you can't. But there is a packaging mechanism where you can put all scripts and assets into a ZIP file and you only need to ship the DOJS.EXE and the ZIP. You can also (sort of) rename the EXE... reply thom 3 hours agoprevDiscovered to my delight that iDOS is back on the App Store[1]. Immediately got Windows 3.11 and MSVC++ 1.52 up and running, and will definitely experiment with DOjS now. Much more fun than getting iSH up to scratch for a real development environment, honestly. 1: https://apps.apple.com/us/app/idos-3/id1580768213 reply debo_ 2 hours agoprevNeeds NIBBLES and GORILLA or it's not real. Maybe that can be my first project. It looks delightful. reply SuperIlu 1 hour agoparentI'd love to include that as a contribution. I've created a text adventure with a friend and a number puzzle using DOjS: https://superilu.itch.io/ reply scandox 3 hours agoprev> LPT or parallel port access Last time I tried I couldn't get this working with DOSBox. Can someone who knows this stuff well comment on whether this represents an extension of DOSbox capabilities or if I've just missed what DOSbox can already do? reply polpo 3 hours agoparentThis is a framework for building things that run on DOS (yes, that means running JavaScript on DOS). If what you’re running DOS on has a working parallel port, DOjS can use it. reply scandox 3 hours agorootparentAh yes sorry that is clear in my head now reply username3 1 hour agoprevAre there any terminal UI frameworks for the web? I want to create web apps that only use keyboard shortcuts. reply makach 4 hours agoprev [–] This is amazing, represents a beautiful playground similar to the early systems, Basic, Amos, aso. reply SuperIlu 1 hour agoparent [–] And you can create real applications with it. Like DOStodon, the mastodon client for MS-DOS: https://github.com/SuperIlu/DOStodon reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "DOjS is a JavaScript programming environment designed for MS-DOS, FreeDOS, or DOS-based Windows, featuring an integrated editor, graphics, sound output, and input support for mouse, keyboard, and joystick.",
      "It offers compatibility with p5js, allowing scripts to be written and run from a DOS command prompt, and supports various multimedia and networking functionalities, including 2D/3D graphics, audio sampling, and IPX/TCP/IP networking.",
      "DOjS can run in DOSBox, real hardware, or virtual machines, requiring at least a 386 with 4MB RAM, though a Pentium class machine with 32MB RAM is recommended for optimal performance."
    ],
    "commentSummary": [
      "DOjS is a JavaScript framework that allows developers to create applications for DOS, including sound and graphics, using a canvas element.",
      "It requires at least an Intel 80386 with 4MB of RAM, but a Pentium class machine with 32MB RAM is recommended for better performance.",
      "Developers can package scripts and assets into a ZIP file and ship it with DOJS.EXE, enabling the creation of real applications like DOStodon, a Mastodon client for MS-DOS."
    ],
    "points": 113,
    "commentCount": 12,
    "retryCount": 0,
    "time": 1725283989
  },
  {
    "id": 41425383,
    "title": "They don't make 'em like that any more: the 3.5mm headphone jack socket",
    "originLink": "https://kevinboone.me/headphonejack.html",
    "originBody": "Kevin Boone Home Contact CV Software Articles 🔍 They don’t make ’em like that any more: the 3.5mm headphone jack socket “It it ain’t broke, replace it with something that is.” About five years ago I was suddenly, unexpectedly taken ill. Not just ‘that’s a bit nasty’ ill, but ‘prepare for the worst’ ill. One thing that kept my spirits up in hospital, in the long watches of the night, was listening to comedy shows and audiobooks. I used my smartphone for this, since I had it with me, and a pair of old, wired headphones that I just had time to grab on my way to the ambulance. I survived, of course, as evidenced by my continued ramblings on this site. But it was an unpleasant experience, made just a little better by a simple piece of technology: the 3.5mm headphone jack. Now, of course, I do own wireless headphones and earbuds – I think almost everybody does. I also own several of those irritating USB dongles, that provide a 3.5mm port for devices that don’t have one. But here’s the problem: I can’t use my Bluetooth earbuds while they’re charging. And I can’t easily charge my phone whilst it’s connected to the USB dongle. In a critical-care facility, it’s hard enough to find one free mains socket to connect a charger to, let alone two. In the debate about the benefits of wired and wireless headphones, I doubt anybody is thinking “What if I get sick?” It certainly wasn’t something I was thinking, either, until I actually did. Still, that experience made me think about all the advantages of having a headphone jack, some of which I’d thought about before, and some I hadn’t. Sound quality is better. Maybe that won’t always be the case, but it is now. All decent headphones have an analog jack. Almost any headphone or earphone will work with almost anything with a standard jack socket. That isn’t the case for USB dongles. Maybe that won’t always be the case, but it is now. I can use the headphone jack to connect my phone or tablet to an amplifier, should the need arise. For certain headphones, that need does arise. I can charge my phone whilst listening to music, which I do all day. I don’t have to carry around a stupid dongle, which I will invariably lose. Ordinary wired earbuds can be small enough to wear whilst sleeping. I’ve never seen Bluetooth earbuds that are. The headphone jack is a “just works” kind of technology: there’s nothing complicated about it, and its not encumbered by patents, so anybody can make compatible equipment. So, although “What if I get sick?” probably isn’t at the top of the list of questions that will guide your buying decision, we have to wonder what other things we lose, by replacing a well-established, robust technology with a complicated, flaky one. On the other hand, the advantages of doing away with the headphone jack are: Your cellphone is about ten pence cheaper. Er… that’s it. What makes the loss of the headphone jack so hard to bear is that it wasn’t done for the consumer’s benefit. To be sure, manufacturers made certain claims about the alleged benefits of losing the jack, but few of them stand up to much logical scrutiny. The first manufacturer to make a point of dropping the headphone jack (I believe) was not Apple – as is commonly believed – but Oppo, and back in 2014. Their reason for doing so was at least a credible technical one: they said it made their phones about half a millimetre thinner. Maybe that was a selling point, maybe it wasn’t. But Apple couldn’t fall back even on this claim, because people found ways to fit a 3.5mm jack socket into the iPhones that lacked one, and even posted videos on Youtube showing how they did it. It wasn’t easy, but it was clearly possible. If Apple genuinely thought that omitting the jack would leave more room for other features, they didn’t actually provide any. It’s notable that a number of companies mocked Apple’s decision to drop the headphone jack, before quietly doing the same themselves: Samsung and Google in particular. Samsung even cynically tried to withdraw all the advertising in which they had mocked Apple. Of course, nothing is ever really gone on the Internet, so we can continue to marvel at Samsung’s barefaced duplicity. Some manufacturers claimed that the presence of the headphone jack made it difficult to keep their phones waterproof; but there’s a whole range of good-quality phones from around 2019-2020 that are waterproof to a reasonable degree, without sacrificing the jack. No. All of these weak excuses are simply distractions from the real reason Apple, Samsung, and Google dropped the headphone jack: they all have a substantial investment in the manufacture of wireless headphones. Apple owns Beats – this was a multi-billion dollar investment, in a company that manufactures Bluetooth headphones. Samsung owns Harmon, which is know for the Harmon-Kardon and JBL audio brands. Again, these were multi-billion dollar acquisitions for Samsung, in companies with a strong interest in wireless audio. Google owns Synaptics, Dysonics, RevX, and Tempow, all of which are active in the development of wireless audio. Google also hired Peter Liu from Bose, who was one of the original developers of the Bluetooth Low Energy specification. It is very much in the interest of companies like Apple, Samsung, and Google to encourage their customers to buy into wireless Bluetooth headphones. Or, better yet, to force them to do so, by taking away the means to do anything else. After all, their executives have to justify the billions of dollars they’ve spent, acquiring suppliers and developers of wireless audio equipment. The 3.5mm headphone jack has almost nothing to recommend it, technically speaking. It was criticized by hi-fi enthusiasts almost from its inception. The only things it has going for it are its simplicity, and the fact that everybody uses it. Well, everybody outside the world of mobile gadgets, anyway. This simplicity and ubiquity is a great benefit to consumers, which is why Apple, et al., don’t want to provide it – they have nothing to gain if consumers spend less money on their products. The loss of the headphone jack would have hurt even if there were good technical reasons for it. As it turns out, there are none – it’s just another cynical way for big businesses to gouge consumers. A side effect of their strategy is that wired headphones themselves are becoming less available, as cellphone users were until recently major purchasers of these devices. It’s not difficult to get top-quality headphones with a jack – they all have one; but there are fewer and fewer mid-priced wired earbuds on the market. The way to discourage companies behaving this way is for us all to take our business elsewhere. It’s still possible to get decent cellphones from Motorola, Asus, and Sony that retain the 3.5mm jack. I don’t believe that anything recent from Apple, Samsung, or Google has one, for reasons I explained earlier. Still, there are older cellphone models from these suppliers that do have a jack, and which are still good phones. I own the Samsung S10+, S10e, and Note 9, for example. They’re a few years old, but they still do everything I want and more. If you’re a fan of the 3.5mm jack, it’s time to vote with your wallet. Categories: hifi, TDMTLTAM Last update Sep 02 2024",
    "commentLink": "https://news.ycombinator.com/item?id=41425383",
    "commentBody": "They don't make 'em like that any more: the 3.5mm headphone jack socket (kevinboone.me)107 points by ingve 5 hours agohidepastfavorite156 comments UtopiaPunk 21 minutes agoHeadphone jacks are easier to use with friends. A few years ago, if a friend was riding with me in the car, I would offer them a chance to plug their phone into the audio system using a 3.5mm cable. Now, most of my friends don't have a phone with the audio jack, and pairing their phone via bluetooth is a small headache that also seems to have a small random chance of failure. Similarly, I used to keep a \"headphone splitter\" cable in my laptop back and backpack. If I were listening to something interesting or funny, I could share that with someone, connecting two (or more!) pairs of headphones to one device. I think it may be technically possible to do something similar on the latest bluetooth standards, but even thinking about trying to do it makes me tired. On a different note, I have an old but nice hifi stereo in my home. It has a few different audio sources, but the one I use the most is my previous smartphone, which sits next to the stereo, permanently connected with a 3.5mm cable. It has no mobile data plan, but it connects to my home's wifi, and I use it to play music from a streaming service and to my media server that holds a collection of ripped CDs. I think it's a great way to extend the usefulness of an elecronic device, but that is only made possible by utilizing widely adopted standards. reply outlore 13 minutes agoparenti feel your pain about splitting of audio without a headphone jack. there are some devices like the Airfly Duo (no affiliation) that can connect via Bluetooth to two devices, but those require that at least your device has an audio jack reply freehorse 49 minutes agoprev> The headphone jack is a “just works” kind of technology: there’s nothing complicated about it [..] While the connector itself is indeed simple, a DAC is also needed inside, and one needs a decent DAC/amp on the phone to get a decent signal. In a cheaper smartphone, you are probably better off with bluetooth/aptx. Moreover, jack cables \"just work\" until they start making weird stuff depended on how they get bent or stretched or the connectors touch. I experience a surge of anxiety even writing this right now. reply ghusto 40 minutes agoparent> In a cheaper smartphone, you are probably better off with bluetooth/aptx Even a cheap phone’s DAC is going to sound better than any BT codecs. reply Kirby64 20 minutes agorootparentNot true, modern BT codecs can be essentially transparent, and cheap 3.5mm jacks can have all sorts of issues. Bad noise performance, bad interchannel isolation, pop click issues, etc. don’t underestimate how badly you can design a 3.5mm jack especially if the phone only costs like $50 total. reply WaitWaitWha 3 hours agoprevI prefer wireless locally, and wired when traveling. I use a two inexpensive LG neckband style wireless headsets during workout, short (under 4 hour flight); and whatever I can get my hands on flat wired headset, for long flights. Loss of buds: I have seen too many travelers freak out with their earbuds dropping on the floor on trains, planes, and taxis. With the wireless neckband and wired sets, there is much less chance of losing them, and even if I lose them the cost is minimal. Battery runs out: I have yet to have a wireless headset that can do a good job on long flights. They will run out of juice, specially if I turn on noise cancellation. Battery concerns: At several airports, I have to pull the wireless headsets out and place them separately because (justified or not) concerns over battery fires and \"technology\". No one cares about wired headsets. Microphones: I have yet to experience small, portable wireless headsets (not headphones) that have good enough microphones without a boom. Even the \"inline\" microphones for wired headsets often out-do wireless earbuds and similar. Size: Unless I use earbuds of some sort, a full around and even over the ear wireless headsets are significantly larger than some small wireless in-ear solution. When traveling size and weight counts. Earbuds although significantly smaller, they still have the charging pod/box that make them larger. The flat wired headsets just rarely tangle, and easy to fold. I can shovel one (or more) in any pocket, not have to worry about batteries, batteries exploding, and recharging. I do like the freedom of wireless when working out. Q: Anyone uses earbuds for conference calls? The biggest issues for me are either they cannot hear me, the background noise is too much, or they die too fast. I would welcome some suggestions. It would need to be able to pair with Android, iOS and PC. Thanks! reply Kirby64 2 hours agoparentModern ANC headphones (over ear) have plenty of battery life for any flight. Most are north of 30 hours, some reaching 50 hours even with ANC on. For planes there’s just nothing better than over ear headphones for noise canceling. reply Timshel 2 hours agorootparentDifferent products for different peoples/usage. If Bose made a refresh of the old wired QC25 I would probably buy it instantly just to be sure to have something when my current pair fail. And having a removable battery ensure that the part which age the fastest can be changed trivially. reply Kirby64 31 minutes agorootparentWhy would you optimize for quick changing something that needs to be changed, pessimistically, every 2 years? You can swap the batteries in the newer models, it’s not that hard. In every other way the newer models are superior. Far better ANC, better sounding, better battery life, able to actually be charged… etc reply hedgehog 2 hours agorootparentprevI've been buying used QC25s, there are plenty of parts available to refresh and keep them working. I think everything in them is off patent now so theoretically someone could start making compatible main boards and then the user base would be able to fully decouple from Bose's product roadmap. reply et-al 47 minutes agorootparentprevWhy the QC25s over the QC35s? reply vindex10 2 hours agoparentprev> I prefer wireless locally, and wired when traveling. I'd go even bolder: wireless locally, mp3 player (wired) when traveling. I still have an IRiver from 2010s and its battery lasts forever. While my phone can survive a day, then, without me worrying about getting lost without Maps and power :) reply MrVandemar 4 hours agoprevI went shopping for a new mobile phone this year. Excluded anything that did not include 3.5mm headphone jack. I don't own wireless headphones, and while I grant it does solve the various problem of wires it clearly introduces the problem of batteries and charging. (Can you even replace batteries in wireless headphones that aren't holding charge anymore? Never mind, don't answer that, I can guess). Anecdotally I feel like wired headphones run the battery down less than bluetooth broadcast. I bought a Motorola something or other. Works fine. reply hddherman 4 hours agoparentFairphone has made Fairbuds [0] and Fairbuds XL [1], both with easily replaceable batteries. So at least there is one option out there. [0] https://shop.fairphone.com/fairbuds [1] https://shop.fairphone.com/fairbuds-xl reply lillesvin 14 minutes agorootparentI got a set of Fairbuds XL at work because it made sense to buy something that could last a long time and be repaired and I really wanted to support Fairphone's basic premise — repairable gadgets with long support. Here's my experience with them that nobody asked for. First of all, the sound is fine. Nothing exceptional but certainly not bad. I'd say they compare pretty well to my Beyerdynamic DT 770 Pro (80 Ohm) or my old Sennheiser Urbanite XL. They also sit pretty well on my head for extended periods of time, which is nice, but will obviously vary from person to person. They don't have any fancy Teams-integration, which is a plus for me but a deal-breaker to others. They hold battery very well. I haven't tested it in depth but I've used them for maybe 3 full workdays without charging them, so maybe around 24 hours of active use and they still had some juice left. But the firmware... What a disappointment. The headphones have 3 settings, ANC, ambient and \"normal\". I personally prefer \"normal\" but the headphones don't remember the setting across restarts, so every time I turn them on I have to sit through the boot sound (because system sounds can't be interrupted), wait for the audio feedback to finish saying \"connected\", and if a second device is connected, \"second device connected\", then click a physical button, wait for it to finish saying \"ambient sounds\", and finally click a third time to hear it say: \"noise cancelling off\", and _then_ I can start using them. It's OK the first 5-10 times but then it just gets really, really annoying. I went to their forums about a year ago to suggest it as a feature but learned that Fairphone actually don't interact with the forums, it's just user-to-user interaction, so suggestions don't really make it further from there. That's fair, so I contacted their support about it instead. They suggested that I contact the store that my workplace bought the headphones from. (I didn't think that was really going to solve the issue, so I chose to just ignore that.) They've released 2 firmware updates since then, but no storing mode across reboots. They did however manage to glitch out the boot sound in one firmware update, so it played 2/3 of the audio only to interrupt itself and play the second half of the sound again. The last firmware update fixed that at least. And before someone suggests that there might be no place to store aforementioned setting, they can store bluetooth pairings and EQ presets on the headphones. The noise cancellation preference could be stored in less than a byte. Unfortunately the firmware isn't OSS so I can't even fix it myself. /rant reply ray_v 4 hours agorootparentprevI want to love these but at the price point you can basically buy 3-4 sets of (likely) technically comparable wireless earbuds that will (likely) last a year or two. How long can I expect fairbuds to last? I can't imagine it would be close to a decade even with replacing batteries reply prmoustache 3 hours agorootparentThe point is mostly to avoid ewaste, not save money. reply ray_v 2 hours agorootparentI guess that's also kinda my poorly made point -- I imagine that these earbuds are like any other electronic device in the fact that they'll break in a handful of years and end up being irreparable in some way that results in just replacing them. I'm not sure what the answer is to any of this of course reply LegitShady 23 minutes agorootparentprevif they wanted to avoid ewaste they wouldn't have removed the 3.5mm jack and I would still use normal headphones. reply djtango 4 hours agoparentprevI have been using my current Beyerdynamics for about 8-9 years now, still going strong. I changed out the velour pads and they feel like new. I've lugged them around across the world and commuted with them day in day out. They have no place in this world of planned obsolescence but I'm still more than happy with them. Didn't realise motorola's made 3.5mm phones. I have been bound to Asus and Xperias who made smaller phones with water resistance and a 3.5mm jack. Now I think I'm back to Xperia again because Asus have vacated the small phone segment reply secondcoming 4 hours agorootparentI've used a Nokia (HMD) XR20 phone for a few years. Weather proof with a 3.5mm jack. reply davkan 4 hours agoparentprevI used to be on the wired only train until I got bone conducting headphones (shokz). Those became 90% of my usage. I don’t really have problems with battery life or charging now that I’ve switched. reply WaitWaitWha 2 hours agorootparentI love the idea, look, and feel. How is the external sounds impact your hearing? i.e. can you process the shokz audio when there is too much external/extraneous audio? reply Game_Ender 2 hours agorootparentSince they lack noise isolation over ear or tight fitting buds this can be a problem. I have the OpenSwim Pro and they are fine outside except for really high noise. But while on a treadmill in the Gym they could not overwhelm the background noise. reply KoolKat23 4 hours agoparentprevCharging is barely an issue these days. I use nothing ear 2a earphones. They last 7/8 hours on a charge but I've never noticed this as they charge when I put them in the case (the case has 40 hours charge I believe). I think, since April, I've plugged them in twice. I switch between these and Sennheiser headphones, which I've probably charged 3 times in the same period. Some of the other brands have wireless charging for the case too, so if you've set up the charger somewhere convenient that the case is used, honestly I don't think you'd notice it has a battery. reply input_sh 3 hours agoparentprevI'm sure you'd like my (over-ear) Sennheisers. A battery lasts around 20h (2-3x that on newer models), I can just insert a 3.5mm cable and they work, and I have successfully replaced the battery and the earpads. Been using the same pair since around 2017. The only reason I'm seriously considering it's time for an upgrade is that they charge via a micro-B cable, which was quite frankly unacceptable for a \"premium\" brand even back in 2017. The question I keep asking myself for the past two or so years is: is that enough of a nuisance to spend another €400? reply secondcoming 4 hours agoparentprevSame, I have too many things to charge as it is. I also own pricey earphones that have worked fine for years. Just throwing them away is dumb. When I had to upgrade my iPad only one had a 3.5mm jack option and was fortunately the cheapest. reply Kim_Bruning 4 hours agoprevBluetooth headphones seem to add sufficient lag that they prevent me from playing an instrument (like a synth) over them. I'm not sure bluetooth can solve this problem, but I'd be pleased to be surprised. reply pclmulqdq 3 hours agoparentBluetooth builds in some buffering to deal with contention on the airwaves and packet loss while keeping the audio stream going. That buffer is the lag you are hearing. It is quite substantial, and there is a natural tradeoff here - you can use more power to (theoretically) reduce buffer size by improving the SNR of the signal, but if you run out of buffer, you are going to drop samples. Even USB audio has some buffering to handle bus contention, but it is quite small in comparison. reply luuurker 3 hours agoparentprevSome headphones have a low latency mode. On mine it's called \"gaming mode\": https://i.imgur.com/4h5Oj4S.png I don't know what changes behind the scenes, but it does improve latency. The only downside I noticed is the reduced range, eg, it stops working on a different room where normal mode still works. reply NoboruWataya 3 hours agoprevI too like the simplicity and standardisation of the 3.5mm headphone jack, and think it's a shame that it's fallen out of fashion in smartphones. But I think this is something that a small number of people get really disproportionately angry about. It's most obvious every time Fairphone crops up in discussion here, and all you see on HN are people furiously shitting on it over its lack of headphone jack. > If you’re a fan of the 3.5mm jack, it’s time to vote with your wallet. Not sure why the author thinks this hasn't been happening already, and the 3.5mm jack is simply losing the popular vote. I really just don't think that many people care about it, in the scheme of things. If removing it helps make the phone even marginally thinner, cheaper or more waterproof, I suspect most consumers will happily make that trade-off. Bluetooth headphones can also be more convenient in that you don't have to remain wired to your phone or deal with tangled cords, etc. Like the author, I also have a Samsung Galaxy S10 that still has the headphone jack but a few months ago I finally caved and bought a pair of bluetooth earphones. reply goosedragons 2 hours agoparentThe war has already been lost. Headphone jacks are basically only in low end phones now. They used to be in mid range devices too, but even there they are gone. You have to really compromise to get it which is a shame. What I do wish is if somebody at least made is a USB C phone dock similar to what Apple made for 30 pin and lightning iPhones with audio out jacks. There are dongles that let you charge and do audio out but not in nice dock form. reply AtlasBarfed 43 minutes agorootparentIt is truly bizarre that flagship phones are the ones that are dropping the most features. And yet, we are approaching the day very soon where there's no point in getting the next year's flagship phone. It's not faster. It's not better. It doesn't have a better battery. The camera's not going to get any better. It's going to be the same form factor. At some point phones will stop charging ridiculous amounts of money for 128 GB of RAM, when a terabyte of storage is approaching $50 in retail cost. More ports SD card. I can see all of it coming back on the table. Cuz you're going to want features if you get a nice phone. reply jprete 3 hours agoparentprevI used to care, but eventually got good Bluetooth earbuds and haven't looked back. Credibly waterproof phones are a big selling point although there's still fine print on warranty coverage. I think it's still the case that Bluetooth headphones cost more for the same quality, though. reply watwut 3 hours agoparentprev> Not sure why the author thinks this hasn't been happening already, and the 3.5mm jack is simply losing the popular vote. When you are buying smartphone, you can not selectively select the features. If you used iPhone and bought apps, you will buy iPhone even if it is missing jack or whatever. I know that I disliked quite a lot about how phones were/are changing ... and when my phone life ends, I have to buy another one. I have no real choice when it comes to this. reply thusky 3 hours agorootparentSame, one generation 3.5mm was a given, next time I needed a phone I have no choice. Who asked me? I would have, if given the choice, bought a phone with wired headphones, an SD card slot, and an IR blaster like my previous phone had but none of those were options. Now the phone I have is bigger than I wanted, has worse battery life, and kills my run tracking apps once the screen has been off for 2 minutes with no option to disable that behavior (obviously spackling over the pitifully small battery by annoyingly killing anything using power) On the plus side it has a 120 hz display that doesn't help me either. reply bombcar 3 hours agoparentprevThe modern 3.5 jack is wired CarPlay. That's the entirety of the matter; and bluetooth is finally good enough for wireless headphones. reply martin_a 3 hours agoparentprev> But I think this is something that a small number of people get really disproportionately angry about. Totally true! I'm also baffled by the number of people who seem to lose anything that is not connected to something else with a wire. Just the commenters in this thread that are just a tiny 3.5 mm jack away from losing their fifteenth pair of headsets... Amazing! reply selectodude 2 hours agorootparentA USB-C headphone adapter from apple is $9. I love my wired headphones. My iPhone 15 has an extremely capable headphone jack. This is such a solved problem. reply BriggyDwiggs42 2 hours agorootparentprevMy car is too old for bluetooth audio, so I have to connect either the dongle or the charger. The dongles i can buy from gas stations always break after about two months, while the gas station aux cable they connect to has lasted years. I also always run out of power on long drives. reply stouset 2 hours agorootparentDongles exist which allow you to charge and play audio at the same time. And… stop buying garbage products from gas stations? You are buying the most cheaply-built item possible from a manufacturer and merchant who have zero concern with repeat business. Pay a few bucks more once for something made by a manufacturer with a reputation and stop throwing more money down the drain. reply TrianguloY 1 hour agoprevMy reason for sticking with the jack (and buying a phone that has one) is that I extensively jump between my phone, computer, tablet, 3ds, switch (and sometimes other consoles) and the jack is the most plug&listen I know that just works reply outlore 11 minutes agoprevi’ve started carrying the cheap wired Apple earbuds because the call/microphone quality on Bose QC45 headphones and Ultra Open earbuds is so bad, especially when outside. i really wish there existed some solution to use the phone’s built-in mic when using bluetooth headphones reply thusky 3 hours agoprevThey missed my biggest frustration with Bluetooth audio. I want to connect to the TV or my phone, but my headphones want to connect to my computer upstairs or vice versa. Now I have to go upstairs, apologize to the person using that device, and reach over their shoulder to unpair before it lets me connect to my phone. With a 3.5mm I know exactly which device I'm going to connect to and I don't have to negotiate with any 3rd parties for the privilege. reply ndsipa_pomu 3 hours agoparentTotally - the user interface is so much easier with a 3.5mm jack. Want to pair it to a different device, just unplug it from the current one and plug it in the new one. No limits such as being only able to pair with two or three devices. reply TheBozzCL 1 hour agoparentprevThis is incredibly frustrating with iPhones. At least Android and Windows lets you disable automatic connections, but on an iPhone your only choice is to unpair. reply goosedragons 2 hours agoparentprevI wish NFC pairing was more widespread. It's only really supported on Android phones but it solved that issue. Just tap the two things together and boom paired. reply bloak 4 hours agoprevIt's nowhere near as widely used, but there is such a thing as a 2.5mm jack, and you can buy a converter from 2.5mm male to 3.5mm female. Has any telephone handset ever had a 2.5mm headphone jack? (Presumably no telephone handset has ever had a ¼-inch jack, even in olden times?) reply findthewords 3 hours agoparentOld Nokias and other pre-smartphone era phones did. reply prmoustache 3 hours agoparentprevMy Bose QC 35 headphones have a 2.5mm socket but on the headphones end for when you'd want to use them wired. It came with a cable with a 3.5mm male plug for the source device and the 2.5mm male plug on the side that goes to the headphones. Never seen a wired headset with 2.5mm male plug that goes to the source device however. reply Kirby64 3 hours agoparentprevNot headsets, but Bose ANC headphones have used a 2.5mm jacks for years (and still do). They give you a 2.5 to 3.5mm cable, though. I imagine this is likely just to drive cable sales, though, as there isn’t any real reason you need the 2.5mm jack on their relatively big headphones. reply searedsteak 4 hours agoparentprevI had an HTC Wizard (branded by T-Mobile) many year ago, which had a 2.5mm jack. reply Astronaut3315 3 hours agorootparentI have the Cingular version and had forgotten this detail. Sure enough, you’re right- it has a 2.5mm jack on it. How unusual. reply ginko 2 hours agoparentprevI think some portable minidisc players and discmans around 2000 used 2.5mm. reply whs 2 hours agoprevAll the phones I used were Nexus and Pixel. Pixel 3a XL was my last Pixel and now I switched to Sony. They're expensive - they're priced without care to competitor's pricing and sold at Sony stores only. Most people in the street wouldn't know Sony still make phones today. I don't think I'll go back to Pixel until Sony drop the headphone jack as well, or someone invented a lightweight pluggable backpack that charges everything inside. Until then I'm not touching the backpack when I'm at home - the wireless mouse use disposable AA batteries, my portable battery stays uncharged, the laptop is charged while using it. Also on Bluetooth, the phone connects to the Tesla and the Samsung soundbar with SBC as the only option. The only thing that use something else is my DAC with Sony's own LDAC. There's nowhere telling you why it doesn't use better codec. Wired always deliver the best quality your hardware could. reply mikestew 3 hours agoprevMy only complaint with the lack of a 3.5mm jack is that people apparently can’t figure out BT headphones, so they just play anything and everything through the phone speakers, whether others are around or not. It’s like the boombox era of the 80s, only with much more shitty sound quality, and it’s Grandma being obnoxious and not some punk teenager. reply sincerely 2 hours agoparentI think it’s that phones no longer ship with a cheap pair of wired headphones reply zeta0134 4 hours agoprevI've come around on USB-C headphones, which seem to be reeeeasonably decent and which, as an added bonus, bypass the absurdly terrible sound chip on my laptop to provide decent quality audio for two of my devices. But until phones ship with two of the ports, they fail to solve the \"use while charging\" issue, and there's still the secondary issue of 3.5mm devices being absolutely everywhere on this green earth, and not in the remotest way compatible with this fancy new USB-C thing. There's not a reverse dongle, and there really can't be, as the 3.5mm jack doesn't provide power. reply prmoustache 3 hours agoparentThe reverse dongle could exist but it would have to be battery powered. This is just an analog to digital converter after all. reply sandreas 1 hour agoprevSo, while this is kind of true, and I totally support having headphone jacks in phones (I'm on a Pixel 4a) this post lacks many details and \"alternatives\". Modern phones might have wireless charging - so charging while listening is possible even with a dongle. There are USB-C only headphones - so not always a dongle is required. There are (overear) Bluetooth headphones that support charging while listening > The headphone jack is a “just works” kind of technology: there’s nothing complicated about it, and its not encumbered by patents, so anybody can make compatible equipment. Oh boy did Apple have success using a proprietary chip for their volume control in EarPods[1] and preventing others except 1more from supporting it. Although proprietary I just love the support oft TRRS driven playback control Apple introduced (play, Pause, rewind etc). Android also supports this these days, although not AS good. I even submitted a PR[2] to audiobookshelf to support Apple like headset controls, but it has not been merged yet. I still use an iPod Nano 7g to listen to audio books until today :-) 1: https://tinymicros.com/wiki/Apple_iPod_Remote_Protocol 2: https://github.com/advplyr/audiobookshelf-app/pull/1218 reply bjoli 55 minutes agoparentI have had so many issues with usb c audio. Disconnection, bad contact, broken connectors. They break all the time. 3.5 or die. I have bought Motorola phones the last 3 phones I have had. They are great. reply zczc 1 hour agoparentprevAs far as I remember, TRRS playback control was implemented first by Nokia, but Nokias had 2.5mm jack and switched to 3.5mm only after iPhone. reply jauntywundrkind 1 hour agoparentprevSome of the dongles are also absurdly unobtrusive. And stunningly cheap. The main downside as i see it (besides the jack not being a default) is that few also are sleek and have usb power. I also think people don't really grok how much complexity & size the jack adds. The footprint of the jack is significant (>3 the plug size). It requires physical reinforcement around it. Often it needs additional chips & passives that take up more space. Keeping water intrusion out requires more careful design. I spent a decade quietly thinking I might never ever use Bluetooth, wondering why people would give up something so concrete for something a little more complex. But I bought some cheap Plantronics Backbeat 903's and found it quite enjoyable being untethered, used them for almost a decade, and have found few of my fears or concerns manifested in practice. It's been great. reply aredox 3 hours agoprevRose-tinted glasses strike again... The audio chips in phones were woeful. Not every headphones could be driven by them. There was a whole cottage industry of DAC that you had to plug between your phone and your headset. As a very deep hole, the jack was also a dust/lint catcher, almost impossible to clean. And because of its length, it had a lot of leverage on the board, requiring fairly heavy-duty soldering to avoid damaging the board. And the first reason the jack went out is not thinness but water resistance. reply starky 1 hour agoparentWe long ago got to the point where audio circuits in phones were perfectly fine for typical headphones. Especially considering the circuitry was mostly built into the SoCs. Good audio circuitry that is completely transparent is easy to design and been known for decades. I had multiple phones with IPx7/8 water resistance and a headphone jack (e.g. LG G6 and Samsung S10) that is a bullshit excuse. reply pessimizer 3 hours agoparentprevYou aren't speaking to infants, we were all alive when the only real choice was wired headphones, and plenty of people still use wired headphones now. I think it was wonderful when headphones always worked, usually sounded fine (sometimes magnificent), and were available for $10. > There was a whole cottage industry of DAC that you had to plug between your phone and your headset. If there was, it was minuscule. I've never heard of people doing that in the wild. > As a very deep hole, the jack was also a dust/lint catcher, almost impossible to clean. Back then, the products were expected to be used long enough for this to become a problem. After a decade, I bet some of those holes were pretty dirty, although who would know. Modern portable tech does not have the disadvantage of durability. > because of its length, it had a lot of leverage on the board, requiring fairly heavy-duty soldering to avoid damaging the board. True. Can't deny this. reply catlikesshrimp 3 hours agorootparent>>because of its length, it had a lot of leverage on the board, requiring fairly heavy-duty soldering to avoid damaging the board. Strawman? I doubt many people even thought about it. For them, bluetooth was available. Now it is almost the only option. reply pdoege 1 hour agorootparentZ stack strength and rigidity is a huge driver because it reduces charge back. Margins are super tight for a lot of OEMs and the PMs eliminate any non-profit features. Off the top of my head, there are savings in: Pick and place Stack Assembly Testing Improved phones/hour and therefore shorter/cheaper factory runs Packaging, especially if you eliminate the shitty wired earpieces in the box Less weight/volume and cheaper shipping Reduced warranty / chargeback because things that don’t exist can’t fail All of these savings are small. But remember that the goal is to make/sell 500K+ units. And, this is an industry where the bean counters will kill their mothers to shave a penny off of the BOM. So, yeah, for the OEM eliminating headphone jacks is a complete no brainer. reply catlikesshrimp 3 hours agoparentprevThe water resistance myth strikes again. https://en.m.wikipedia.org/wiki/Samsung_Galaxy_S8 Water resistance + 3.5mm jack + sdcard tray reply t0bia_s 1 hour agoprevI don't use wireless headphones because they are impractical and quality is low and I feel unconfortable to put wireless emitter almost in my brain. I don't use 3,5mm jack on my phone as well, because output from S10e is terrible. So I connect fiio DAC via USB-C and wired Shure headphones to DAC. I don't understand why anyone, who cares about sound quality, complainis about output, that crippling that quality. reply BugsJustFindMe 3 hours agoprevEveryone gets to feel their own feelings, but there's just so much that doesn't resonate with me here... > I can’t use my Bluetooth earbuds while they’re charging. Many bluetooth headphones have battery life measuring in tens of hours. And every set I've used, long life or otherwise, recharge to 80% in a handful of minutes. I agree that an airpod's miniscule battery life is appalling, but you can stand to pull them out of your ears for five minutes every four hours, and you can charge them one at a time so you never need to stop listening, and my Bose QC35IIs still get more than an entire day of playtime after multiple years of recharge cycles. > In a critical-care facility, it’s hard enough to find one free mains socket to connect a charger to, let alone two. I haven't used a single-port USB charger in a decade. All of my chargers have multiple ports on them. GaN tech makes them very compact even at high power output. > Sound quality is better. Maybe in the abstract, but for most people this isn't meaningfully true in any way that actually matters to them. And if you're listening to \"comedy shows and audiobooks\" it definitely doesn't matter. Speech has an extremely limited useful frequency range, and those tracks are typically extremely compressed without any ill effect. > The headphone jack is a “just works” kind of technology... Nothing is ever fully a \"just works\" kind of technology. Things only just work until they stop working. The 3.5mm jack wore out after a year or so on every device I've ever owned that experienced plug/unplug cycles a few times per day because of accumulated minuscule amounts of force over time. This is more likely for devices like phones which are ultracompact and go in your pocket. Google for variations of \"3.5mm port broken\" or \"loose audio jack\" some time and you'll see that this is a common problem. The wires themselves also wear out from repeated flexing over time, even with strain relief. I had a pair of Shure E2c years ago that stopped working if I didn't hold a bend in the non-replaceable cable at a particular spot with a rubber band. > Ordinary wired earbuds can be small enough to wear whilst sleeping. I’ve never seen Bluetooth earbuds that are. Then you didn't really look IMO. Bluetooth headsets for sleeping is a whole cottage industry now. Anecdotally, I personally sleep fine in honking large Bose QC35 IIs, but that obviously depends on sleep position. reply D13Fd 2 hours agoparentCompletely agreed. Beyond that , the cost of adding a headphone jack is not the price of the physical component. It’s the fact that it forces the phone to be bulkier in one dimension or another. There is less space for other components. reply Jakob 3 hours agoprevI prefer wired too, because of the much reduced latency and better sound quality both in and out. Especially important with calls around the world, where electron/light speed already adds 150 ms. I would hope that my call partner acted similarly but unfortunately they nearly never do. Maybe some future directed microphone and speaker setup in rooms will finally lead to the same comfort without the wire. reply thayne 3 hours agoparent> electron/light speed Tangent, but changes in the electric field travel at the speed of light (in a copper wire, which is slightly slower than in a vacuum). The electrons themselves move much, much slower. The speed of light is what matters for speed of information transfer. It is analogous to a pipe of water. If you increase or decrease the pressure of the water at the input of the pipe, you can detect that difference in pressure at the other end long before the water molecules at the beginning of the pipe get at the time of the change get to the end of the pipe. reply Eric_WVGG 2 hours agoprevMy unpopular opinion is that wired earphones are really great if you really love the sensation of getting your ears ripped off when your cord hooks on something when you stand up, and you don't care much about maximizing battery life in your mobile device. They are also truly ridiculous now that you can just swap out your cable for a USB audio cable. (If the cord is hard-wired to the headphones… okay so you have cheap headphones? Why even care then?) I don't get it. reply exodust 2 hours agoparent> I don't get it. My iPad Pro has no 3.5mm jack, so I must use the flimsy USB dongle to use my Beyerdynamic DT 990 Pro headphones (great open-back headphones). Why doesn't a \"pro\" iPad have a 3.5mm jack? It makes no sense. When the iPad battery gets low, I can't charge the iPad while using the headphones. There is nothing \"pro\" about this. Sometimes I like to connect my phone to my powered studio monitors with a 3.5mm cable. Again, the phone can't be charged while I do this. It's why I keep an old iPhone 6s around because it has the 3.5mm. reply debo_ 2 hours agoprevIf USB-C becomes the new standard for wired headphones, I'm ok with that, especially if it means thinner phones. I inherited a Pixel 3A a couple years after it was released, and I still have it. I didn't even realize that headphone jacks were being phased out. It would be nice if we started to get more than one usb port on a phone, but I already have small USB-C docks for laptops that would work well. reply soniman 3 hours agoprevDoes anyone else use a cheap MP3 player and RSS feeds or am I the last dinosaur? reply saulpw 2 hours agoparentI use a Sansa clip because it has clickable buttons that I can feel for when I can't use a phone screen, like at the dentist or in a sky village with light restrictions. Also I don't ever load my phone with the 2GB of my favorite mp3s, and I don't want to (and sometimes can't) stream music from a service on the internet. reply mitthrowaway2 2 hours agorootparentI use this too, since like 2013 or something. Still works. Also it has an SD card slot, so plenty of storage. And it includes a real working FM radio, weighs approximately nothing, and can clip to my sleeve. Battery lasts for ages. I never saw the appeal of putting music on my phone. reply luuurker 2 hours agoparentprevI use RSS feeds. No MP3 player because my phone does the same job without me having to carry a second device :P reply gpsx 3 hours agoprevI seem to have noticed a marked increase in the number of people in public listening to music with no headphones over the past several years, as in going from essentially 0 to it now being a thing. I wonder if this came from people not wanting use or buy USB headphones? Or because phones don't come with headphones anymore? (Personally, I have earpods but don't like them. I use a set of standard Apple headphones.) reply d_sem 3 hours agoprevReminds me of the late Neil Postman, who gave space to consider that technological trends have secondary effects that can potential make life worse. As an avid user of wireless headphones I think its worth briefly entertaining the side effects. Increased expectation of isolation in classically social settings, possible long term ear damage, increased baseline cost to consumer. reply AStonesThrow 2 hours agoprevI was pleased to find that USB-C earphones are now inexpensive and plentiful. It was a must-purchase for my Pixel. The USB audio interface is mature and stable. It better supports the little remote button controls too. There are unfortunately two drawbacks which may make USB inferior to other interfaces: the C plug is small and weak. Already my first set of earphones became unusable due to a loose, flaky connector. Also, given that phones only sport a single USB, the earphones monopolize it and, sadly, prevent charging, PC interface, tethering, etc. reply jessriedel 4 hours agoprevObviously there is the cynical explanation of forcing consumers to buy pricey wireless headphone, but what are the stated arguments that manufacturers give for not including the jack? Is it literally the space requirements? (But ofc my wireless headphones and their charging case take up much more room.) Separately on this: > The way to discourage companies behaving this way is for us all to take our business elsewhere. It’s still possible to get decent cellphones from Motorola, Asus, and Sony that retain the 3.5mm jack. Choosing the most important tool in your life based on this one hostile feature seems like a high price to pay. (Should I vow to never do business with Google in any form?) Maybe just better to commit to buying wireless headphones from an opposing company? That removes the manufacturers incentive. reply pclmulqdq 3 hours agoparentThe reason was literally to make the phones thinner. The 3.5 mm jack was the thickest component by far, and it has to sit under the screen. reply mitthrowaway2 2 hours agorootparentBut phones aren't really that thin, especially with the camera lenses. Why didn't they just put the 3.5 mm jack on the other side from the cameras, protruding a little bit from the rear housing, exactly enough for the phone to rest stably on a flat surface without rocking? reply throwawayffffas 2 hours agorootparentprevThat was the stated reason. The iPhone 14 is 7.8mm deep without a 3.5mm jack the iPod Touch (4th gen) was 7.1mm with a 3.5mm jack. reply throwawayffffas 2 hours agorootparentAdditionally as other have stated there are thinner (2.5mm) audio jacks. reply catlikesshrimp 3 hours agorootparentprevSpace is not a constrain in many flagship phones. Check this comparison of (unofficial specs) s24 vs s8 (0.5mm appart. S8 also had sd card slot) https://m.gsmarena.com/compare.php3?idPhone1=12773&idPhone2=... This is the datasheet of a generic 3.5mm It is thinner than that: 3.2mm. https://www.cuidevices.com/product/resource/sp-3530.pdf reply qilo 2 hours agorootparentJust the tip is 3.2 mm. Ring and sleeve are 3.5 mm. reply jamesgeck0 2 hours agoparentprevI've read speculation that because the jack can pick up electrical fields, you have to design the phone around it. Otherwise the user will hear buzzing in their headphones. reply j16sdiz 3 hours agoparentprevSpace, and water/dust proofing reply catlikesshrimp 3 hours agorootparentThere have been aweasome flagship phones with ip68 and 3.5mm audio jack https://en.m.wikipedia.org/wiki/Samsung_Galaxy_S8 So, no. Waterproof casing is an excuse. I went to (Edited) A Mainstream Chinese Brand now that Samsung dropped the ball. I dont get audio jack, either, but I have IR blaster and double physical sim reply saberience 2 hours agorootparentI think you've missed the point a little or are perhaps are being slightly obtuse. Of course it's POSSIBLE to make a phone with waterproofing and a 3.5mm headphone jack, and of course it POSSIBLE to make a modern thin phone with a 3.5.mm headphone jack taking up extra space... The point is, it's simply harder and more expensive to make a highly waterproof and slim phone, while having to have another large hole in the phone which requires a long connector to fit inside it. And when you consider that extra expense and R&D required to design the phone shell and internal architecture, versus the actual demand for wired headphones (basically zero these days), it's obvious why major phone makers don't bother to include it. It's simply a matter of cost benefit analysis. Lots of cost, very little benefit. No mystery. reply mitthrowaway2 2 hours agorootparentThe waterproof 3.5mm jack connector isn't an R&D cost, it's just a standard component you can buy from Digikey; comes with an o-ring. A whole generation of waterproof phones had them, like the Sony Xperia. They look like this: https://www.digikey.com/en/products/detail/cui-devices/SJ-35... reply pdoege 1 hour agorootparentYeah, that might not be the best example. Normally you’d want a double seal or really tuned compression to reliably hit IP68. And the o-ring adds a manufacturing step. And you have to design the case to properly compress the oring. And case assembly is harder because screwing up that interface will increase chargeback. And you’ll need to modify the audio test fixtures to add a jack. And the audio test has to include a headphone test. Any failures increases rework, so you gotta budget for that too. Probably need to add a cheap earbud to the box, so you gotta add a packaging step and a bigger box. And once you sell the phone, any failure within the contracted return window will increase chargeback. Seems like a lot of faf. I tell you what, why don’t we wait for a bigger OEM to remove the darned things, and if it doesn’t hurt there bottom line we’ll just quietly scrap the idea? And that’s how we got here. reply mitthrowaway2 1 hour agorootparentYou're implying it's because of cost-savings, but OEMs still typically offer 3.5 mm jacks on their lower-end models (even waterproof ones, like the Xperia AceIII). It's the expensive flagships they've removed them from. I think a better explanation is that high-end models are fashion items while lower-end models are functional items, and it's fashionable to copy Apple. reply thusky 2 hours agorootparentprev\"These days\" that wasn't the case four years ago when they arbitrarily took it away. How would you know what the level of demand is? I would selectively purchase a phone with a headphone jack over one without, but that demand is meaningless without an option. Apple led the pack with the highest R&D budget of them all, with a premium smartphone. They, uniquely, took the headphone jack away while launching airpods. You're right about there being no mystery there. reply gravitronic 1 hour agoprevBrings to mind a viral tweet I saw years ago, \"my roommate asked to charge his cigarette but he had to wait as I was charging my book. The future sucks\" reply dgrin91 2 hours agoprevMy understanding of the advantages is that the 3.5mm Jack is \"big\" in terms of space taken on the internal of the phone, and that real estate is valuable. Also it was becoming a bottleneck for phone thickness. Don't know if that's all just marketing bs though reply bluedino 3 hours agoprevI own at least ten pairs of headphones, as well as some small amps and a DAC, but I end up going back to the $19 Aukey Bluetooth earbuds from Amazon. They sound good enough, battery still lasts 5 hours and they must be six years old, and they're cheap enough where I don't care if they are damaged or lost, but I haven't managed to lose them. Sure, on an airplane I'll drag along some noise cancelling ones, and I keep a wired set of Sennheisers in my bag for a backup, but I never use them otherwise. reply rwmj 4 hours agoprevI'd probably like bluetooth headphones more if they actually worked more than 50% of the time. Probably because the rooms where I use them are filled with RF noise from so many other devices, they just don't work reliably enough to be usable. They work for a while and then drop out, or simply can't connect at all. Luckily Sony still sell wired headphones. reply buro9 4 hours agoprevI know it's not what he is looking for: https://www.belkin.com/uk/p/3.5mm-audio-usb-c-charge-adapter... A USB-C adaptor for mobile phones to allow charging whilst listening on a 3.5mm headphone jack. reply Vecr 4 hours agoparentHow's the quality on that? I think similar devices made weird popping noises sometimes. reply buro9 3 hours agorootparentBelkin, along with Anker, make pretty good things and I trust them... I don't know how to criticise a \"charge whilst playing music\" thing as it does both of the things it claims to do and I've not tried silly things like chaining this with other dongles. reply TheBozzCL 1 hour agoprevIt’s sad, but at least portable USB DACs have come a long way. My personal choice is the Qudelix 5K. reply prmoustache 4 hours agoprevWhile it is hard to do damage to a 6.3mm TRS socket and plug, I wouldn't say the same of the 3.5mm one. As a kid / teenager I damaged a number of sockets and bent a number of 3.5mm male TRS plugs. So I wouldn't call it a \"just works\" technology as it is far from perfect. reply elric 1 hour agoparentI've worn out more USB-C earphones in the 2 years since I've been forced to use them, than I have 3.5mm earphones in the 30+ years since I first got a Sony Walkman. The connectors and wires are so stupidly fragile. They're bulky. They're rectangular and can't rotate in the way the cable is pulled (unlike a 3.5mm jack). They always stick straight out (at least I haven't seen any 90° angled versions). Converters only make the problem worse, because now you have a fragile USB-C dongle sticking out and a 3.5mm jack so it's extra bulky and prone to damage. The wireless ones bug me to no end. Two more batteries to manage, two more single points of failure. Maybe I should dust off that old walkman. reply floodle 3 hours agoparentprevUSB C ports break just when I look at them slightly wrongly. In comparison to that, 3.5mm is a dream. reply prmoustache 3 hours agorootparentI haven't managed to brake one yet but I admit on a thinkpad I own the cable appear to be wiggly once plugged to it. reply Izkata 2 hours agorootparentThis happened to one of my phones after a few years, turned out it was a bunch of lint compressed into the port preventing the cable from going in all the way. I got it all out with a staple (only thing I could find that was small enough to fit), then the cable started snapping into the port like new. reply martin_a 3 hours agorootparentprevJust use wireless charging. It works fine. I've 3D printed a little cover for my USB C port as I just don't need it for anything. Will keep that little port fresh for years... reply prmoustache 3 hours agorootparentYou are saying that as if all smartphone were compatible. reply martin_a 3 hours agorootparentWell, what shall I say without sounding snarky... I'd choose a smartphone that offers wireless charging because that is the state of art and it just works. It makes my life easier. I can just rest it on a little charging pad and move on. No worries about broken cables, broken USB ports and whatnot. Yeah, maybe there's inefficiency while loading, but we're talking about so little energy that gets lost, I don't really care. Just like Bluetooth just works and makes my life easier. My little Anker earbuds charge in their case, they can live in my gym bag without getting lost, sound quality is fine, no connection issues at all, even across the gym (like 20 meters) with dozens of other BT earbud users around. Oh, and the case also has three LEDs to show me how full the battery in the case is. Charge it an hour with a USB-C cable and I'm good to go for weeks. reply karmakaze 3 hours agoparentprevTrue, but I find the 6.3mm to be overkill (except for commercial use). I'm hoping for the 4.4mm plugs that are used on hifi headphones to replace 6.3mm. reply bloopernova 4 hours agoprevUgh, this infuriates me to no end. I used to own LG V-series of mobile phones. They had a better-than-usual DAC and a headphone socket. Then LG stopped making that series. Now I have a pixel. Now I have a USB external DAC (TempoTec Sonata HD pro) that used to work with Spotify, but now the only way I can use it is with a specific USB DAC application that hooks into Tidal. I'm assuming Android updated its audio stack in such a way as to break my external DAC. It's the same with my little desktop DAC, a Schiit Modi. I just want to be able to listen to music on my preferred headphones, using a good quality DAC! reply tlhunter 3 hours agoprevI've held onto my Pixel 4a5g as long as I could, being the last Google phone with a headphone jack. My Pixel 9 arrives in a few weeks but I was able to buy a used iPod to help satisfy my 3.5mm needs. reply thusky 3 hours agoprevIt isn't even \"Bluetooth vs 3.5mm\" it's 3.5mm vs. Not having 3.5mm Every phone prior to 2020 had both. If your 3.5mm broke that sucks, but that would just put you in the exact situation we have today generally. If you never use it anyway why do you care? I just don't understand how so many people are arguing in favor of a company obviously making a move to force their customers into buying something they didn't necessarily want. reply maeln 4 hours agoprevI use to own expensive (~250+€) bluetooth earbuds, with ANC and all that jazz. I broke them by trying to clean them one time (my ears are very \"waxy\" and every earbuds always ends up coating in nastiness from my ears very quickly, so i need to clean them regularly). So I went back to the cheap wired (but still USB-c) earbuds I got. I do resonate a lot with this article. Wired earbuds just works. With wireless earbuds I cannot count how many time I had issue with bluetooth. The microphone on every wireless earbuds is awful because you cannot put it right to your mouth like you can with wired ones. You have a limited battery time. Wireless earbuds are bulkier so they get out of your ears easier, ... The only thing I miss is the ANC, which was surprisingly working well on trains and planes. And yeah, I which I still had a jack on my phone. My best wired earbuds use jack, so I have to carry this annoying dongle, usb-c is also flimsier, and I am way more worried about breaking it, since I also need it to charge my phone and transfer files. reply ndsipa_pomu 4 hours agoprevAs much as I agree generally that headphone sockets are great, there's a couple of missed disadvantages with including them in your phone: waterproofing and thickness. reply searedsteak 4 hours agoparentThe article addresses both points: > The first manufacturer to make a point of dropping the headphone jack (I believe) was not Apple – as is commonly believed – but Oppo, and back in 2014. Their reason for doing so was at least a credible technical one: they said it made their phones about half a millimetre thinner. Maybe that was a selling point, maybe it wasn’t. But Apple couldn’t fall back even on this claim, because people found ways to fit a 3.5mm jack socket into the iPhones that lacked one, and even posted videos on Youtube showing how they did it. It wasn’t easy, but it was clearly possible. If Apple genuinely thought that omitting the jack would leave more room for other features, they didn’t actually provide any. > Some manufacturers claimed that the presence of the headphone jack made it difficult to keep their phones waterproof; but there’s a whole range of good-quality phones from around 2019-2020 that are waterproof to a reasonable degree, without sacrificing the jack. reply jpgvm 3 hours agoparentprevYou can make them waterproof and the last thing I want right now is a thinner and even more fragile phone. I want the old Nexus 5 just with newer chips and camera. Indestructible poly-carbonate shell w/non-slip rubberized coating, good sized screen, headphone jack, really good battery life, no nonsense OS. Nothing added to newer phones (Pixel or iPhone) have improved my experience, all have made them worse in various ways. Newer phones are less durable and more expensive because they are made from fragile \"luxury\" materials like glass. They are thinner and have crappy battery life as a result (though this is getting better as batteries have caught up to design ambition). The thinness is rendered moot by needing a case. I didn't need a case on my Nexus 5, it was already indestructible. New phone + case is definitely thicker as a result. Actual advantages of USB-C or BT audio mostly come down to a higher quality DAC in those devices vs crap they put on a lot of phones/laptops/etc. Thing is that doesn't need to be the case, you can totally have a properly good DAC on-board. Especially if you aren't fighting for thinness and can put it on an isolated daughter board. IMO the enemies of a good phone design are thinness and aluminium + glass construction. It turns what should be a utilitarian device into a fashion accessory and because that is what the high-end looks like there is nothing but a sea of copycats doing the same thing but worse. reply criley2 4 hours agoparentprevMany phones had great waterproof ratings with a headphone socket. Nearly all phones today are thick enough for sockets, a 3.5mm would fit fine on my Pixel 7 pro. The thinness wars ended when too many people sat on their phones and bent them. reply Kirby64 3 hours agoparentprevDid you even read the article? The author points out both of those points are essentially just excuses. Phones haven’t been made thinner, and you can still fit 3.5mm jacks in most phones, and there are plenty of waterproof phones with a 3.5mm jack. reply saberience 2 hours agorootparentDude, no one ever claimed that you can't have a waterproof phone with a jack, the point, which is fairly obvious, is that it's much harder to make a highly waterproof phone when you have a big ass hole in it for a 3.5mm jack. I.e. it's cost benefit analysis. It's annoying, hard, and expensive if you want to make a phone which is say waterproof to 10m or 15m while having a 3.5mm jack hole in it, which most people don't care about anyway. So easy solution, stop having the jack. reply mproud 3 hours agoprevIsn’t adding a headphone jack introducing another pathway for liquid to enter a device, or would well-constructed hardware prevent that from happening? reply searedsteak 3 hours agoparentFrom the article: > Some manufacturers claimed that the presence of the headphone jack made it difficult to keep their phones waterproof; but there’s a whole range of good-quality phones from around 2019-2020 that are waterproof to a reasonable degree, without sacrificing the jack. reply cosmotic 4 hours agoprevAnother positive point for wireless headphones: you never have to deal with detangling a cord, getting caught in it, or it pulling on you. reply hobs 4 hours agoparentYep, and then they are much easier to lose, step on, have drop out of your ear while you are running and disappear. I have literally found a half dozen sets of airpods out in the world, whereas before wireless earbuds became popular I never found a single pair of abandoned headphones. The bigger headphones dont have this problem as much but they are significantly heavier because they have to include all the electronics and batteries in them. reply mikestew 3 hours agorootparentYep, and then they are much easier to lose, step on, have drop out of your ear while you are running and disappear Somewhere on a rails-to-trails at the foot of the Cascade Mountains is a single Beats Powerbeat that was flung to the ground in the middle of a 50 mile race after I pulled a piece of clothing over my head. I was leading the race, so I spent just the barest amount of time looking, but never found it. Damned things ain’t cheap, either. I should have just thrown the other one to the ground, so at least someone might have a matched set. At the same time, if I had to dick around with wired headphones, I wouldn’t have used them at all. reply luuurker 3 hours agoprevI avoided phones without a headphone jack for a while for similar reasons. I didn't want to use a dongle or buy new wired headphones, and I didn't want to use a 1-to-2 USB-C/lightning dongle to listen to music and charge at the same time. Then I invested on a Sony WH-1000XM3 and suddenly battery life wasn't a problem anymore. That was a big change from the cheap bluetooth earphones I had used until that point, which had terrible battery life. I could use them for a full day, maybe forget to charge them, and it never ran out of battery. So I stopped using wired headphones. The downside was the price... the WH-1000XM3 wasn't cheap, but things have changed. Last year I wanted something smaller, so I bough the Anker Liberty 4 NC. Much cheaper, good noise cancelling, good enough sound quality, and from time to time use them for 8 hours straight (AAC mode) without putting them in the case. The earphones + case can last a week without charging them (with my usage of course). It wouldn't be a problem even if I was in hospital for a while, like in OP's case. So I'd say that the list of downsides is getting shorter as good bluetooth headphones get cheaper. It's still more expensive, but it's a different world compared to 5 years ago. If you still want to use wired headphones, then yeah, nothing has changed and losing the headphone jack is bad. But if you're willing to try wireless, then it's not as bad as it used to be. reply liendolucas 2 hours agoprevNothing beats the cable. It simply works. You don't need to worry about running out of battery, bluetooth disconnections or getting hurt in case a battery explodes (as was discussed in a thread about someone who if I recall correctly got their Bose headphones turning on fire). Wireless audio should always be a secondary thing. All devices should come with the beloved jack. Even if you purchase some respectable audio speakers or sound bars is very likely they come without it. Is really lame. But as the article mentions, these wireless headphones are designed to be purchased over and over again, hence the reason to put this technology everywhere. As someone else said it, would be awesome to have a regulation to force companies to always provide the headphone jack. reply JumpCrisscross 2 hours agoparent> Nothing beats the cable. It simply works Except when it didn’t. The cables got tangled, caught, kinked and broken. Sure, the well-made ones didn’t threaten to detach from the buds. But well-made wireless headphones don’t suffer the problems you mention. > would be awesome to have a regulation to force companies to always provide the headphone jack I suppose we should also require everything play vinyl? reply liendolucas 2 hours agorootparentWireless headphones have an expiry date, when the battery is completely out you have to throw them away. Up to this date I haven't witnessed a single pair of earbuds that its battery can be easily replaced. Attempting to do so might break them beyond repairability. So is not only that is the wireless thing, is that these are also built so if you attempt to open them you break them, this for me is another reason not to buy them. I do own a pair of wired Audio Technica headphones. Since 2016 they have experienced use almost every day. I do still use them to this very day. Only thing I have to do is replace the earpads from time to time. reply JumpCrisscross 2 hours agorootparent> do own a pair of wired Audio Technica headphones They seem to work well for you. I respect that choice. That doesn’t mean it has to be compatible without an adapter with every device on the market. (In the same way every device shouldn’t have to support wireless headphones.) reply scrapheap 4 hours agoprevIt's disappointing seeing the slow decline in the number of devices that include a 3.5mm headphone jack. Personally I don't want any hassle from my headphones, I just want to plug them in and use them. reply johnchristopher 4 hours agoparentDoes it apply to usb-c headphones ? I am quite happy with the AKG usb-c wired headphone I got w/ my samsung phone (I even bought a second set as a replacement for when I misplace them). reply scrapheap 3 hours agorootparentI suspect that if the current trend in dropping the 3.5mm headphone jack continues then I'll have to move to USB-C headphones or at least an adapter. reply blackeyeblitzar 4 hours agoprevI recently tried out wired headphones (over a USBC adapter) after years of using true wireless ones and was blown away by the sound quality difference. I forgot how amazing things can sound, when I chose convenience. Apart from limitations of Bluetooth and the confusing landscape of codecs, there are physical limitations - wireless sets have to make room for antennas and batteries and chips that could otherwise be used for pure sound quality instead. reply catlikesshrimp 3 hours agoprevIt seems they flagged this post. I can only find it by searching for keywords. I think I will change one of the speakers of my new jack-less phone for a switching audio jack port. reply inciampati 4 hours agoprevIs water resistance a reason why we're seeing the elimination of the 3.5mm jack? reply searedsteak 4 hours agoparentFrom the article: > Some manufacturers claimed that the presence of the headphone jack made it difficult to keep their phones waterproof; but there’s a whole range of good-quality phones from around 2019-2020 that are waterproof to a reasonable degree, without sacrificing the jack. reply KoolKat23 3 hours agoparentprevLower bill of material cost for the manufacturers and more space for other parts in the device. reply EarlKing 4 hours agoprev> The headphone jack just works ...except when you can't make good contact and you wind up with one stereo channel muted and you have to fidget manically to fix it....which seems to occur with every damn headphone jack on every device without exception. reply ThrowawayR2 1 hour agoparentAmen; I'm surprised more people aren't bringing this up. I like the idea of having a wired headphone connection to my phone and other audio devices but I don't like the 3.5mm TRS headphone plugs/jacks. Make it a magsafe-style connector or something that's immune from wearing out or bad connections and I'd be delighted. reply exabrial 3 hours agoprevIts literally one of the dumbest things the \"environmentalists\" have shoved down consumers throats. \"environmentalists\" being you know: - https://www.apple.com/environment/ - https://www.samsung.com/us/aboutsamsung/sustainability/envir... - https://sustainability.google/ It's all greenwashed bullshit. reply thousand_nights 4 hours agoprevi don't get why the author makes it out to be some big conspiracy, many people including myself are very happy with wireless headphones and would never go back to the hassle of untangling wires also there are wireless headphones which have 24 hour battery life reply Miraltar 3 hours agoparentYes but why don't they give us both options as many people miss the jack ? reply striking 4 hours agoprev [–] Voting with your wallet probably isn't going to work, because you probably represent a drop in the bucket of sales. If you want this changed, start a campaign and write to your representative in Congress. If the EU could make Apple put USB-C on the iPhone, maybe you can get the 3.5mm jack back on your phone. But you won't get there by kidding yourself thinking your individual sale matters. --- I'm seeing any number of dongles that include a charge port on Amazon, like this one: https://a.co/d/hwiLAqp Wireless charging for your phone is also an option. reply margalabargala 3 hours agoparentVoting with your wallet by failing to purchase a phone from a huge corp like Samsung, is not something that will change Samsung's behavior, I agree. Voting with your wallet by buying a phone with a headphone jack, especially from a smaller maker like Unihertz, is impactful and helps ensure those alternatives stay around. reply striking 3 hours agorootparentMaybe! But I checked Unihertz's site and it seems like their newest upcoming release, the Jelly Max, will be lacking a headphone jack too: https://www.unihertz.com/products/jelly-max To their credit, it appears to come with an adapter. My guess is that Unihertz, among others, is probably either reselling an existing design or contracting minor changes to an existing design. So unless you're voting with your wallet hard enough to shift the tides of the entire white-label phone manufacturing industry, I think I'm still doubting the impact here. reply tedunangst 2 hours agoparentprevAlso, a law that every laptop must include a DB9 serial port. reply striking 2 hours agorootparentIn truth, it's in the same ballpark of ridiculous to me. reply JumpCrisscross 2 hours agorootparentprev> a law that every laptop must include a DB9 serial port /s? reply krisoft 2 hours agoparentprev [–] > Voting with your wallet probably isn't going to work, because you probably represent a drop in the bucket of sales. I mean... it worked. People voted with their valets and the side who likes tangled cables to listen to music from their phones lost the vote. That is literally voting with your valet in action. I understand that you probably mean \"voting with your wallet won't work\" in the sense that it won't change the situation. But it is also a bit like saying that democracy doesn't work because my party didn't win, because there were not enough people supporting it. A bit against the principle of the thing. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The 3.5mm headphone jack offers better sound quality, compatibility with various devices, and the ability to charge the phone while listening, making it more reliable and convenient than wireless alternatives.",
      "Major manufacturers like Apple, Samsung, and Google have removed the headphone jack to push wireless audio technology, benefiting financially at the expense of consumer convenience.",
      "Consumers can still find phones with 3.5mm jacks from brands like Motorola, Asus, and Sony, or opt for older models from Apple, Samsung, and Google."
    ],
    "commentSummary": [
      "The removal of 3.5mm headphone jacks from most modern phones has made sharing audio and connecting to other devices more cumbersome.",
      "Bluetooth headphones, while popular, face issues such as limited battery life, connectivity problems, and inferior microphone quality compared to wired headphones.",
      "Many users still prefer phones with headphone jacks for their simplicity, reliability, and superior sound quality."
    ],
    "points": 107,
    "commentCount": 156,
    "retryCount": 0,
    "time": 1725285097
  },
  {
    "id": 41420112,
    "title": "'Mindblowing' fake AMD Ryzen 7 7800X3D chip investigated – buyers beware",
    "originLink": "https://www.tomshardware.com/pc-components/cpus/mindblowing-fake-amd-ryzen-7-7800x3d-chip-investigated-buyers-beware",
    "originBody": "PC Components CPUs 'Mindblowing' fake AMD Ryzen 7 7800X3D chip investigated — buyers beware News By Mark Tyson published yesterday Use a platform with buyer protections when looking for a used bargain. Comments (8) When you purchase through links on our site, we may earn an affiliate commission. Here’s how it works. (Image credit: Der8auer) TechTuber Der8auer has highlighted the plight of one of his fans who was scammed into buying a fake AMD Ryzen 7 7800X3D processor, normally one of the best CPUs for gaming. The expert overclocker talks viewers through some of the outward signs that this chip was a fake, which could prevent others from falling for scams like this. He also purchased the \"mindblowing\" counterfeit from the scam victim to take a closer look, delid it, and deliver a thorough analysis. Beware! Fake Ryzen 7800X3D CPUs are being sold - YouTube Watch On A Der8auer fan named Bruce bought the fake chip online via a Romanian outlet known as OLX. This is said to be like the Facebook marketplace, and consists mostly of private sellers, with returns or warranties not a realistic option. Bruce thought he saved about €100 on the typical European retail price of the 7800X3D, by snapping up this chip for €300… Any warm glow of satisfaction from grabbing a bargain will have rapidly dissipated after receiving the chip and plugging the CPU into the motherboard for its first boot. Powering up a system with this chip reveals that it is dead. Nothing happens. Bruce did some basic checks, probing pads using a multimeter, but didn’t see any signs of life. Der8auer to the rescue Der8auer purchased the dead chip for the full retail price of a new model, meaning that Bruce could go and get a new, fully guaranteed chip from a reputable supplier. It also meant that we could enjoy witnessing the overclocker’s keen eye as he analysed the useless 7800X3D-a-like lump. Even before Der8auer received the physical product from Bruce, he spotted some tell-tale signs that things were not all as they should be. Going from the photos alone, Der8auer noticed that the chip substrate color was wrong (too blue, not enough green). This could have been a photography lighting issue and was hard to confirm until the product was received. Secondly, on a genuine AMD X3D chip, capacitors which you see between the ‘octopus’ legs are covered in a protective resin, while the fake had shiny uniform blocks. Image 1 of 4 IHS has bump for CCD and I/O die replication(Image credit: Der8auer) PCB, no chip die(Image credit: Der8auer) Fake used different font, spacing, etc(Image credit: Der8auer) Real delidded X3D chip (left), the fake (right)(Image credit: Der8auer) On receiving the chip, the color difference and lack of resin were confirmed. With the supposed 7800X3D in hand, Der8auer also noted the fake chip had a thinner PCB and was much less a tight fit into the CPU loading mechanism. Measurements confirmed a PCB thickness of just 0.964mm for the fake, compared to 1.308mm on the genuine X3D processor - a significant difference. Using identical photos of the fake / original and photoshop layer opacity levels Der8auer shows that it is easy to see a lot of IHS/engraving differences between the chips. Some of these differences weren’t surfaced from inspections using the naked eye, without side-by-side comparison. Stay On the Cutting Edge: Get the Tom's Hardware Newsletter Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors By submitting your information you agree to the Terms & Conditions and Privacy Policy and are aged 16 or over. After his exterior visual inspection, Der8auer decided it was time to delid this unresponsive and non-genuine-looking AMD branded processor. Delidding wasn’t as expected either, as the IHS separated with a lot less effort than usual. Now for the big reveal – there was no silicon on the substrate, not even some broken or lower-spec chip was present on the PCB. The maker of this faux-X3D created a rectangular bump on the underside of the IHS to mimic the CCD and I/O die, so before delid it looked like a chip was present in the gap. Der8auer summed up that the effort put into faking the PCB and IHS made the fake chip look “professional.” It certainly seems good enough to pass inspection for those who haven’t seen or handled many X3D chips in person, and the packaging was good too. The main fails of the counterfeiters were PCB color, and surface mount capacitor glue/resin detail, as noted above, but the capacitor number and positioning were “spot on,” according to Der8auer. Actually, the TechTuber ramped up his praise of the fake product, towards the end of the video. The IHS was of particularly good quality, he asserted, as it lacked the pronounced side-machining marks seen on the original. Finally, there is the question of the time and effort put into this fake. This suggests that there could be many more of these around, perhaps. So, please be careful out there. This isn't the first and won't be the last CPU fake enthusiasts will need to be wary of. Mark Tyson News Editor Mark Tyson is a news editor at Tom's Hardware. He enjoys covering the full breadth of PC tech; from business and semiconductor design to products approaching the edge of reason. SEE MORE CPUS NEWS MORE ABOUT CPUS AMD 128-core Zen 5-based EPYC 9755 'Turin' tested: 2X faster than 128-core predecessor Intel Arrow Lake and Lunar Lake CPUs are unaffected by crashing issues — Vmin Shift Instability issue only impacts 13th and 14th Gen CPUs LATEST Windows 11 skips past 50% market share milestone in latest Steam survey SEE MORE LATEST ► SEE ALL COMMENTS (8) 8 Comments Comment from the forums great Unknown I think you mean \" there is no silicon on the substrate....\" Reply TeamRed2024 If the deal seems too good to be true... Reply bill001g TeamRed2024 said: If the deal seems too good to be true... It would actually be less suspect price if the cpu were sold as used. New in the box you would more suspect it was stolen. Buying from a individual on something like facebook is always a huge risk in itself. Reply JRStern They didn't put a little slip of paper inside saying \"Surprise!\"? Reply YSCCC TeamRed2024 said: If the deal seems too good to be true... That's why for new stuffs, especially tech related I never buy used online, unlike camera lens you can't bring a body to try it out and look for obvious issues. One couldn't expect to see such degree of faking though, I am always amazed about how the fakers go beyond and above to make it look so genuine just to scam ppl.... Reply Hooda Thunkett YSCCC said: That's why for new stuffs, especially tech related I never buy used online, unlike camera lens you can't bring a body to try it out and look for obvious issues. One couldn't expect to see such degree of faking though, I am always amazed about how the fakers go beyond and above to make it look so genuine just to scam ppl.... Honestly, is it that much cheaper to make a fake look this good? Isn't there an easier way? Reply YSCCC Hooda Thunkett said: Honestly, is it that much cheaper to make a fake look this good? Isn't there an easier way? I doubt os, CNC the IHS and laser script it isn't cheap to begin with.. Reply Pierce2623 bill001g said: It would actually be less suspect price if the cpu were sold as used. New in the box you would more suspect it was stolen. Buying from an individual on something like facebook is always a huge risk in itself. On something equivalent to Facebook marketplace I won’t even buy tech stuff unless it’s like an old cheap GPU like a 1070 or something. I got some fake Xreal Air glasses from Mercari a long time ago and they didn’t do ANYTHING to help me. Reply VIEW ALL 8 COMMENTS Show more comments",
    "commentLink": "https://news.ycombinator.com/item?id=41420112",
    "commentBody": "'Mindblowing' fake AMD Ryzen 7 7800X3D chip investigated – buyers beware (tomshardware.com)98 points by doener 22 hours agohidepastfavorite43 comments alecsm 21 hours agoI expected a real working clone of the Ryzen chip. Calling it mindblowing is a bit exaggerate since it's basically a piece of metal/plastic with no electronics in it. reply fluoridation 21 hours agoparentIt is very unusual that someone would go to this much effort instead of using a real dead CPU or re-lasering a lower spec one. reply userbinator 20 hours agorootparentIndeed, remarked CPUs have been a known scam for decades by now. At least those will somewhat work and delay the arousal of suspicion, while this is an instant fail. Perhaps this was made for warranty fraud? reply Animats 20 hours agorootparentprevYes. Repeat business will be zero. The seller can't sell very many before they have to shut down and go into hiding. Yet it takes a lot of cost and effort to set this up. As a scam business plan, it's not a good one. reply imglorp 16 hours agorootparentThat's exactly the Amazon scammer business model. They can have a new store with a new name in seconds and be back in business with none of that pesky customer service and other accountability. reply bangaladore 20 hours agorootparentprevWith a chinese manufacturer, I think you could probably make about 100 of these for less than a few thousand bucks easily. With all the cost in the cnc'd heat spreaders. Maybe 100 forAliexpress is legit That's way too positive. Aliexpress is loaded with counterfeit products as well. reply userbinator 15 hours agorootparentprevThere are also plenty of used CPUs of older models, but those tend to be fine since they don't really die unless abused (or are certain Intel 13th and 14th gen models...) and were probably run at stock settings for the few years the server it was in was warrantied for before being sent to recycling (creating tons of unnecessary waste, but good to see people have figured out how to encourage reuse while also profiting from it.) I've also purchased used pre-Rowhammer RAM from there, and it was perfect too. reply ClassyJacket 20 hours agoparentprevI was going to say - I didn't think it was plausible that anyone had the capability to manufacture competitive chips, without the world knowing their foundry exists. Would have been funny if it was real, but was actually a 486, or something. Probably not possible due to motherboard compatibility\\pin configurations or something, but still. reply kens 16 hours agoprevA few years ago I bought an 8086 chip on eBay and it turned out to be fake, a random logic array chip relabeled as an 8086. It made for interesting die photos at least. It hardly seems worthwhile for someone to fake a chip that gets sold for $3.80. https://www.righto.com/2020/08/inside-counterfeit-8086-proce... reply userbinator 15 hours agoparentThose scammers who will sell you a chip with whatever you wanted printed on it probably profit the most from \"collectors\" who don't ever try to verify what they actually have. reply echoangle 20 hours agoprevWhy would you go that far to make a fake? If the buyer can’t do a chargeback, you can just ship a rock, and if they can, how does shipping something that’s obviously broken help you prevent a chargeback? I don’t get it. reply chrisfosterelli 19 hours agoparentPlausible deniability? I feel like sending a literal rock puts a banner on it for being a scam but something that looks like the chip although doesn't function leaves lots of room to argue & misdirect: the issue is elsewhere with the receiver's computer setup, it was installed incorrectly, a legitimate CPU was sent but was damaged in transit or by the user and has no warranty, etc. The vast majority of buyers do not have the ability to open up the CPU and tell what they're looking at. OLX presumably does not want outright scams but also doesn't want to put any effort into warranty, returns, customer service, etc. You mostly just have to make it murky enough I would guess. reply echoangle 19 hours agorootparentI still don’t understand how they make any money from this, who wouldn’t immediately dispute the purchase if they put the CPU in their PC and it doesn’t boot? As a customer, I don’t really care what happened to the product before if it arrives and it’s broken. I ask for a return and if the seller gives me trouble, I do a dispute with PayPal and get my money back. I don’t even have to diagnose the issue. reply chrisfosterelli 16 hours agorootparentI understand that OLX is like Facebook marketplace where how money is transferred is up to the buyer and seller, so often it's transferred in a way that doesn't enable disputes. For e.g. in Canada if you etransfer someone you have no way to dispute the transaction. reply numpad0 10 hours agorootparentprevPresumably it's set up so scammers can cash out before dispute opens, or so that the platform is forced to eat the refund? reply brudgers 18 hours agorootparentprevIf a purchase is not through a credit card network, there is not a general process for disputing a charge. reply imtringued 12 hours agorootparentIt's called PayPal. reply hedora 16 hours agoparentprevI’d guess the person selling it is not the counterfeiter. Perhaps they got a “deal” on a tray of them, or are fencing things they thought “fell off a truck”. reply Retr0id 18 hours agoparentprevI'm theorizing here, but if you're a novice PC builder and you buy a bunch of parts and put them together and the system doesn't boot, you're probably going to think you fucked up. You don't have an easy way of testing parts individually. Maybe you replace the motherboard first, and of course that doesn't work, so then you order some new RAM, and so on. If you spend long enough troubleshooting then it's too late to return the CPU. reply BLKNSLVR 15 hours agorootparentI don't think I'm exactly a 'novice' system builder*, but when my son's computer died a couple of years back we bought replacement RAM, Motherboard and Power Supply before realising it was the CPU that had died (didn't have spare compatible parts to try out). At least we've got spare parts if the other components die now... In my 25-odd years of building and using PCs (and the odd few servers) I'd not had a CPU die on me, so it was the last thing I suspected. Wasn't until after we'd worked it out that we looked it up and found that it was somewhat a systemic problem with these specific CPUs after ~1 year of use. I was determined it couldn't have been the CPU - until it couldn't have been anything else. *Although in hindsight I may have acted like one. Extra story: 20-something years ago I had a slightly misaligned heatsink on AMD CPU which caused the machine to crash after a few minutes of gaming. I took the heatsink all the way off and decided to put my knuckle on the die and boot up the machine. It took what felt like a millisecond for the die to feel 'nuclear' hot and the machine, thankfully, auto-switched off. I've had a LOT of respect for the job heatsinks do since then. Once the heatsink was properly seated, the machine booted up no worries, and that CPU kept going until it was system upgrade time. Bulletproof! reply freedomben 4 hours agorootparentThank you for sharing this story! I've long wondered what would happen without a heatsink, but have been too chicken to try it myself. It's a bit of a curse to learn best through destructive means :-) reply userbinator 9 hours agorootparentprevI took the heatsink all the way off and decided to put my knuckle on the die and boot up the machine. It took what felt like a millisecond for the die to feel 'nuclear' hot and the machine, thankfully, auto-switched off. You're lucky you didn't get a severe burn on your hand or kill the CPU --- early AMD CPUs, notably from the late 90s / early 2000s, were infamous for catastrophically overheating without a heatsink. There's a video from Tom's Hardware showing that, after which AMD started adding more thermal protection. (There are various assertions floating around that that video was fake, but given that no one seems to have made a \"myth-busting\" video in the 20+ years since it was released, despite the clear incentives for YouTubers to do so, and instead others have shown how hot those CPUs can get, I suspect it's real. Now that those CPUs and other hardware from that era are actually somewhat collectible, the likelihood of someone trying to repeat that video is even lower.) reply BLKNSLVR 4 hours agorootparentI did think I had killed the CPU at the time, but being an impoverished student at the time I had no choice but to see if it was OK - and thankfully it was. The heat was quick and intense enough that I took my finger off very quickly - it may have actually overheated and shut down faster than I took my finger (knuckle of my pinky) off, which might have saved me from a more lasting burn. reply rootusrootus 19 hours agoparentprevI imagine this wasn't shipped, it was a person-to-person transaction. Probably cash or equivalent. A rock wouldn't pass muster, but a regular buyer would look at this \"chip\" and be fooled. By the time they figure it out, the seller has moved on to the next target. reply shantara 21 hours agoprevBought on OLX, which is an Eastern/Central European version of Craigslist. Not a place that you should be buying expensive electronics without considering a possibility that you’re being scammed reply Beijinger 3 hours agoprevMaybe a small batch that was never meant to be used by scammers. For exhibition at trade fairs of for photographs? Then one dude might have thought, why not try to sell them, make a quick buck. reply userbinator 20 hours agoprevThey certainly have been getting more convincing. I still remember this crude attempt 14 years ago: https://www.overclockers.com/forums/threads/reported-fake-in... reply scrlk 20 hours agoparentNot a CPU, but I remember Nvidia being the source of many jokes back in the day for their Fermi mock up using wood screws: https://bit-tech.net/news/tech/graphics/fermi-card-on-stage-... reply minkles 20 hours agoprevThat’s quite a bit of effort gone into a plausible looking fake. As always buy from a reputable seller. There are few real bargains out there. It’s usually less interesting on the EE side where you’ll get something that looks like an expensive opamp but turns out to be an LM358. It might even partially work in circuit! reply throwaway48476 18 hours agoprevBusiness moves at the speed of trust. Such low trust society practices haem everyone. reply tonetegeatinst 17 hours agoprevI bet you could do this by the following and I would hazard a guess that they do something like the following. 1. Buy a real CPU 2. Measure where the layout of pins are, the different parts visible to the naked eye, and then rip the top off to draw up a CAD file. 3. Use a cheap desktop mill to mass produce a bunch of the top metal pieces, buy any small resistor part you might need. 4. Get a PCB design that mimicks the CPU layout with contacts on bottom that look realistic enough. 5 assemble your fake metal piece, any visable nockoff component, to the cheap PCB. 6. Do a fraud where a good CPU is purchased from a company not likely to disassemble the CPU and might write it off as a DOA chip or a damaged in shipping. Return the fake CPU in the box/system, and you just got a free CPU you could resell on the black market or sell to sanctioned parties. This is stupid because of the effort needed to make a fake chip and your betting your life in jail no one does a decent inspection. Hell you need to laser etch the CPU to match whatever legit thing your stealing, so many ways to get caught. reply jowdones 5 hours agoprevOLX is basically a second hand flea market. Only form of protection you have is the price: should be so low as to not hurt you much in case the product is defective and seller ghosts you. I never had a problem and bought many things on it, most expensive a ZX Spectrum clone with CP/M and floppy drive for 400 euro. My brother bought a couple of brand new smartphones for like 50% discount and they were genuine. It works more often than not but there's always the risk. reply ksec 19 hours agoprev [–] We are in 2024 and somehow people still falls for the same scam as they did 30 years ago. But I guess it is good these stories get reposted and hopefully more people are aware of it. reply cocodill 15 hours agoparent [–] I remember people buying bricks in a VCR box at the flea market in the early nineties. Scam works no matter what time it is. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "TechTuber Der8auer exposed a counterfeit AMD Ryzen 7 7800X3D CPU bought by a fan from OLX, a Romanian marketplace, highlighting the risks of purchasing tech from unverified sources.",
      "The fake CPU had several telltale signs, such as incorrect substrate color, lack of protective resin on capacitors, and a thinner PCB, with no actual silicon present upon delidding.",
      "Der8auer praised the quality of the counterfeit but warned buyers to be cautious, emphasizing the importance of buying from reputable sources to avoid such scams."
    ],
    "commentSummary": [
      "A counterfeit AMD Ryzen 7 7800X3D chip, essentially a non-functional piece of metal/plastic, is under investigation, raising buyer caution.",
      "The scam has sparked discussions about its potential use for warranty fraud and the unsustainable nature of such fraudulent business models.",
      "The prevalence of counterfeit products on platforms like Aliexpress and OLX, and the difficulties buyers face in disputing fraudulent transactions, are also highlighted."
    ],
    "points": 98,
    "commentCount": 43,
    "retryCount": 0,
    "time": 1725222670
  },
  {
    "id": 41421591,
    "title": "Inductive or Deductive? Rethinking the Fundamental Reasoning Abilities of LLMs",
    "originLink": "https://arxiv.org/abs/2408.00114",
    "originBody": "Computer Science > Artificial Intelligence arXiv:2408.00114 (cs) [Submitted on 31 Jul 2024 (v1), last revised 7 Aug 2024 (this version, v2)] Title:Inductive or Deductive? Rethinking the Fundamental Reasoning Abilities of LLMs Authors:Kewei Cheng, Jingfeng Yang, Haoming Jiang, Zhengyang Wang, Binxuan Huang, Ruirui Li, Shiyang Li, Zheng Li, Yifan Gao, Xian Li, Bing Yin, Yizhou Sun View PDF HTML (experimental) Abstract:Reasoning encompasses two typical types: deductive reasoning and inductive reasoning. Despite extensive research into the reasoning capabilities of Large Language Models (LLMs), most studies have failed to rigorously differentiate between inductive and deductive reasoning, leading to a blending of the two. This raises an essential question: In LLM reasoning, which poses a greater challenge - deductive or inductive reasoning? While the deductive reasoning capabilities of LLMs, (i.e. their capacity to follow instructions in reasoning tasks), have received considerable attention, their abilities in true inductive reasoning remain largely unexplored. To investigate into the true inductive reasoning capabilities of LLMs, we propose a novel framework, SolverLearner. This framework enables LLMs to learn the underlying function (i.e., $y = f_w(x)$), that maps input data points $(x)$ to their corresponding output values $(y)$, using only in-context examples. By focusing on inductive reasoning and separating it from LLM-based deductive reasoning, we can isolate and investigate inductive reasoning of LLMs in its pure form via SolverLearner. Our observations reveal that LLMs demonstrate remarkable inductive reasoning capabilities through SolverLearner, achieving near-perfect performance with ACC of 1 in most cases. Surprisingly, despite their strong inductive reasoning abilities, LLMs tend to relatively lack deductive reasoning capabilities, particularly in tasks involving ``counterfactual'' reasoning. Subjects: Artificial Intelligence (cs.AI) Cite as: arXiv:2408.00114 [cs.AI](or arXiv:2408.00114v2 [cs.AI] for this version)https://doi.org/10.48550/arXiv.2408.00114 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Kewei Cheng [view email] [v1] Wed, 31 Jul 2024 18:47:11 UTC (817 KB) [v2] Wed, 7 Aug 2024 00:52:07 UTC (817 KB) Full-text links: Access Paper: View PDF HTML (experimental) TeX Source Other Formats view license Current browse context: cs.AInewrecent2024-08 Change to browse by: cs References & Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer (What is the Explorer?) Litmaps Toggle Litmaps (What is Litmaps?) scite.ai Toggle scite Smart Citations (What are Smart Citations?) Code, Data, Media Code, Data and Media Associated with this Article Links to Code Toggle CatalyzeX Code Finder for Papers (What is CatalyzeX?) DagsHub Toggle DagsHub (What is DagsHub?) GotitPub Toggle Gotit.pub (What is GotitPub?) Links to Code Toggle Papers with Code (What is Papers with Code?) ScienceCast Toggle ScienceCast (What is ScienceCast?) Demos Demos Replicate Toggle Replicate (What is Replicate?) Spaces Toggle Hugging Face Spaces (What is Spaces?) Spaces Toggle TXYZ.AI (What is TXYZ.AI?) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower (What are Influence Flowers?) Connected Papers Toggle Connected Papers (What is Connected Papers?) Core recommender toggle CORE Recommender (What is CORE?) About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs. Which authors of this paper are endorsers?Disable MathJax (What is MathJax?)",
    "commentLink": "https://news.ycombinator.com/item?id=41421591",
    "commentBody": "Inductive or Deductive? Rethinking the Fundamental Reasoning Abilities of LLMs (arxiv.org)89 points by belter 18 hours agohidepastfavorite105 comments godelski 13 hours agoI'm really tired of these papers and experiments. You cannot test reasoning when you don't know what's in the training set. You have to be able to differentiate reasoning from memorization, and that's not trivial. Moreso, the results look to confirm that at least some memorization is going on. Do we really not think GPT has extensively been trained on arithmetic in base 10, 8, and 16? This seems like a terrible prior. Even if not explicitly, how much code has it read that performs these tasks. How many web pages, tutorials, Reddit posts cover oct and hex? They also haven't defined zero shot correctly. Arithmetic in these bases aren't 0-shot. They're explicitly in distribution... I'm unsure about base 9 and 11. It's pretty interesting to see that GPT 4 is much better at these. Anyone know why? Did they train on these? More bases? Doesn't seem unreasonable but I don't know. The experimentation is also extremely lacking. The arithmetic questions only have 1000 tests where they add two digits. This is certainly in the training data. I'm also unconvinced by the syntax reasoning tasks since the transformer (attention) architecture seems to be designed for this. I'm also unconvinced these tasks aren't in training. Caesar ciphers are also certainly in the training data. The prompts are also odd and I guess that's why they're in the appendix. For example, getting GPT to be better at math or many tasks by having it write python code is not novel. There's some stuff here but this really doesn't seem like a lot of work for 12 people from a top university and a trillion dollar company. It's odd to see that many people when the experiments can be run in a fairly short time. reply Animats 10 hours agoparentWe can tell some of what's in the training set. One of the answers for the inductive reasoning test begins \"begin from the rightmost digit\". Look that phrase up in Google. It shows up in Chegg, Course Hero, and Brainly content for elementary arithmetic. If you bash on those how-to articles, available for bases 2 and 10, you can probably generate the pattern for base 8. This looks like an LLM doing the usual LLM thing - finding relevant items and combining them to fit. This doesn't require the level of abstraction and induction the authors impute to the LLM. Ordinary LLM behavior explains this, once you've found the relevant training data. People often solve problems that way too, of course. reply Terr_ 1 hour agorootparentThat reminds me of an old paper about \"Benny's Rules\", a case-study focused on a kid who seemed to be doing better than average in math tests when it came to final answers... but for all the wrong reasons, using an inferred set of arbitrary text manipulation rules. The intent was to point out that the educational approach was flawed, but I think there are interesting parallels to token processing in LLMs, which--unlike a human child--are built in such a way that crazy partial-fit rules are likely their only option. > Benny believed that the fraction 5/10 = 1.5 and 400/400 = 8.00 because he believed the rule was to add the numerator and denominator and then divide by the number represented by the highest place value. https://blog.mathed.net/2011/07/rysk-erlwangers-bennys-conce... reply hanrelan 11 hours agoparentprevYou'll probably find this talk [1] interesting. They control all the training data for small LLMs and then perform experiments (including reasoning experiments). [1] Physics of LLMs: https://www.youtube.com/watch?v=yBL7J0kgldU&t=7s reply om8 12 hours agoparentprevHow to you define memorization and reasoning? There is a large grey area in between them. Some say that if you can memorize facts and algorithms and apply them to new data, it is a memorization. Some say that it is reasoning. More than that -- It's not clear that what humans do is not \"just\" a memorization. We can always look at human experience mechanisticly and say that we don't think -- we just memorized thinking patterns and apply them when speaking and \"thinking\" reply godelski 10 hours agorootparent> It's not clear that what humans do is not \"just\" a memorization. While I agree that there is a lot of gray in-between I think you are misrepresenting my comment. And I'm absolutely certain humans do more than memorization. Not all humans, but that's not the bar. Some humans are brain damaged and some are in fact babies (and many scientific do agree that sentience doesn't appear at birth). If you doubt me I very much encourage you to dive deeper into the history of science and get doing deep deep knowledge on any subject. Because you'll find this happen all the time. But if you apply a loose enough definition to memorization (that isn't one that would be generally agreed upon if you used it's logical conclusions) then yeah, everything is memorization. But everything is foo if I define everything to be foo, so let's not. reply imtringued 10 hours agorootparentprev> Some say that if you can memorize facts and algorithms and apply them to new data, it is a memorization. Some say that it is reasoning. Memorizing facts and algorithms is memorization. The rest of what you are talking about is not. Applying existing knowledge on new data without deriving new information is generalization. An example of this is the case of a semantic segmentation model classifying a car that it has never seen. If the model was not trained on birds, it will never classify a bird as a bird. Computation of decidable problems is a large, possibly the largest subset of reasoning. Most humans do not struggle with solving decidable problems, the problem is that they are slow and can only solve small problem sizes, but most problems encountered in practice aren't one large decidable problem, but a long chain of many small, dozens to hundreds of heterogeneous problems that are seamlessly mixed with one another. LLMs struggle with decidable problems that are out of distribution, but you can give a human instructions on how to do something they have never done before and they will follow them with no problem. > More than that -- It's not clear that what humans do is not \"just\" a memorization. I hope it is clear that I did not memorize this message I am writing here and that it is the unique result of processes inside my brain that were not captured in the training process of an LLM. >We can always look at human experience mechanisticly and say that we don't think -- we just memorized thinking patterns and apply them when speaking and \"thinking\" Again you are trying to twist this in an absurd direction. Let's come up with a teleoperated humanoid robot on Mars that is controlled by a human on Earth. The robot acts exactly like a human does. Does this mean the robot is now capable of reasoning and thinking like a human, simply because it is replaying a recording of the human's body and speech? This is the argument you are making. You're arguing that the robot's ability to replay a human's actions is equivalent to the processes that brought about that human action. reply godelski 52 minutes agorootparent> Let's come up with a teleoperated humanoid robot on Mars One example I've always liked is from Star Trek. They got holodecks and no one thinks those are sentient people even though they are adaptive. I don't care what Iilya said, mimicking a human does not make a human. It may look like a duck, swims like a duck, and quack like a duck, then it's probably a duck, but you haven't ruled out an advanced animatronic. In fact, I'm betting right now people could make an animatronic that would convince most people it is a duck because most people just don't know the nuances of duck behavior. reply akomtu 12 hours agorootparentprevA lot of reasoning is similar to interpolation within a sparse set of observations. Memorization is rounding up to the nearest known example. Basic guess is linear interpolation. And reasoning is about discovering the simplest rule that explains all the observations and using this rule to extrapolate. reply Infinity315 12 hours agoparentprevI think the results still tell us something. Discrepancies in mathematical ability between the various bases would seem to suggest memorization as opposed to generalization. reply AdieuToLogic 15 hours agoprevLarge Language Model algorithms do not reason. They are statistical text generators, whose results are defined by their training data set. This is why the paper cited reads thusly: Despite extensive research into the reasoning capabilities of Large Language Models (LLMs), most studies have failed to rigorously differentiate between inductive and deductive reasoning ... There is no differentiation because what was sought is the existence of what does not. The authors then postulate: This raises an essential question: In LLM reasoning, which poses a greater challenge - deductive or inductive reasoning? There is no such thing as \"LLM reasoning.\" Therefore, the greatest challenge is accepting this fact and/or that anthropomorphism is a real thing. reply godelski 13 hours agoparent> They are statistical text generators, whose results are defined by their training data set Honestly I'm pissed at the research community. It's fraud. If you don't know what's in the training data you simply cannot differentiate reasoning from memorization. Beyond that, the experiments are almost certainly in the training data. Like come on! I feel like I'm going crazy here. How can any coder not think LLMs are training on oct and hex‽ https://news.ycombinator.com/item?id=41422751 reply og_kalu 5 hours agorootparentOf course they've been trained on oct and hex. The question is would the results be largely valid if this was done on a human who had learnt how to perform base 8, 9, 11 etc arithmetic instead ? I mean, they're clearly not trying to test the ability to derive base arithmetic from scratch. reply astrange 15 hours agoparentprevThey are not statistical text generators. They are black boxes wrapped in an interface part of which is a statistical text generator. You can write programs into transformer models and run them deterministically; they aren't \"statistical\". reply godelski 13 hours agorootparentCan you cite the deterministic part? And I don't think fixing your seeds count as making a model not statistical, though yes deterministic. It's also still statistical if it gives you the same answer 99999/100000 times. You can definitely tune these things to be much more certain about certain problems but it tends to decrease capabilities in others. I also don't like the term \"black box.\" While they aren't transparent they aren't completely opaque either. A big reason I didn't like the term is that I feel it also encourages people to not research this more. While we don't completely know what's going on I see no reason we can't. Is there some proof they their calculations are an unbreakable encryption or is it just a hard problem. I'm pretty sure it's the latter, and I think it's good to differentiate \"we're dumb\" from \"indeterminate\" reply astrange 10 hours agorootparent> Can you cite the deterministic part? And I don't think fixing your seeds count as making a model not statistical, though yes deterministic. I was thinking temperature=0, but what more do you need than that? (nb there is also some randomness from non-associative FP operations happening in different orders) > I also don't like the term \"black box.\" While they aren't transparent they aren't completely opaque either. A white box is a subset of a black box here. The important part is that the sampler/text generation is wrapped around the transformer model and is not actually the same thing as it. reply godelski 8 hours agorootparent> I was thinking temperature=0, but what more do you need than that? Temperature isn't a thing exclusive to LLMs or ML. It's a general technique from statistics where you're modifying the variance of the distribution (also see truncation). And as you're aware, temperature zero isn't actually temperature zero. So say such a thing makes something non-statistical is the same as saying prime numbers don't exist because any prime p * 0 is 0. > A white box is a subset of a black box here No. A white box and black box sit at opposite ends of a spectrum which is just saying how much we understand something. Complexity isn't what makes something a black box, it's our lack of understanding that does. Of course this tends to coinside, but there's plenty of extremely complex things we have a great understanding of, even if not to infinite precision. Please take your passion and use it to drive you to learn about these things deeper. It's actually the same advice I give to the LLM fanboys who think it's AGI. But trying to dispel that myth without correct information makes it harder. It muddies the waters. These topics are extremely complex and the issue with the ML field is itself a hypocritical claim that it is easy (scale is all you need while calling these machines black boxes). I mean we can talk about the elephant in the room but certainly Von Neumann has said enough. reply astrange 7 hours agorootparent> No. A white box and black box sit at opposite ends of a spectrum which is just saying how much we understand something. So it's a subset, because \"understanding something\" is a refinement of the state of \"not understanding something\" - you can just pretend you don't know what's happening in that part of the system and it is now a black box. reply desumeku 4 hours agorootparentSemantic word games aren't a crowd-winning form of argument. reply godelski 1 hour agorootparentIt's worse when you play that semantic game to make your point stronger (changing your original meaning) and willfully misinterpreting the other person. Everyone loves being willfully misinterpreted reply taylorius 10 hours agorootparentprevThe issue with comprehending LLM's internal workings is just that they're so big. The operation of the network itself is deterministic - but it's output is a set of probabilities over the value of the next token in the stream. At that point you have to choose one, based on that probability distribution, and then start the process again. That choice is where the randomness comes in. reply godelski 10 hours agorootparentJust to clarify, are you disagreing with me? Correcting me? Adding context for others? I guess I'm missing the intent reply taylorius 10 hours agorootparentJust adding context, elaborating a little on the deterministic / statistical aspects of an LLM. I don't disagree with what you said, I'm afraid - so not much prospect for a back and forth :-) reply stavros 15 hours agoparentprevI really dislike these non-sequitur arguments of \"LLMs do not reason, because \", as if a detail on how they work unequivocally proves the impossibility of reasoning. reply quantadev 14 hours agorootparentI've noticed that on HackerNews about 80% of all debates or discussions where people disagree, boils down to a disagreement about the definition of a word. reply fedeb95 11 hours agorootparentfeel free to extend to other contexts. It was basically Socrates' argument. reply throwawaytemp29 10 hours agorootparentprevThat is certainly true, for some definition of 80%. reply slashdave 13 hours agorootparentprevI see. Well, I claim my pet rock can think. What do you mean it doesn't have brain cells, what kind of argument is that? reply Quiark 10 hours agorootparent\"This alien super-computer made from entangled iron atoms clearly is not thinking because it doesn't have neurons\" you mean like this? reply desumeku 4 hours agorootparentChatGPT - Our very own alien super-computer! reply fragmede 11 hours agorootparentprevMy pet silicon rock was processed by TSMC in a design by Nvidia, and does this trick called inference that very much does look like thinking. Who made yours? reply Y_Y 4 hours agorootparentI deem your rock to be disqualified on the basis of its performance clearly having been enhanced by doping. reply anon373839 13 hours agoparentprev> Large Language Model algorithms do not reason. My belief is that what LLMs do is best described as approximating the outputs of reasoning. This is different from reasoning itself and also different from simply regurgitating the most similar training examples. I also think it's extremely challenging for people to understand the significance of LLM output because language is intertwined with meaning. So if you construct a valid and seemingly responsive sequence of words in response to a prompt, there is a strong illusion of purpose behind those words, even if they were assembled in a completely naive fashion. reply levitatorius 7 hours agorootparentThis! One simple argument is that language is NOT a magical reasoning substance in itself, but a communication medium. It is medium for passing (a) meaning. So first there is a meaningful thought (worth of sharing), then an agent puts a SIGNIFIER on that meaningful thought, then communicates it to the recipient. Communication medium can be a sentence, it can also be an eyewink or a tail wiggle. Or a whistle. The \"language\" can be created on the spot, if two subjects get a meaning of signifier by intuition (e.g. I look at the object, you follow my gaze). So the fallacy of the whole LLM field is the belief that language has some intrinsic meaning. Or if you mix the artifacts of language in some very smart way, the meaning will emerge. But it doesn't work if meaning occurs before the word. The text in books has no reasoning, it was authors. The machine shuffling the text fragments does not have a meaningful thought. The engineer which devised a shuffling machine had some meaningful thought, the users of the machine have same thoughts, but not the machine itself. To put it another way, if there was an artificial system capable of producing meaningful thoughts, it is not a presence of language which produces a proof, it's communication. Communication requires an agent (as in \"agency\") and an intent. We have neither in LLM. As to the argument that we ourselves are mere stochastic parrots - of course we can produce word salads, or fake mimics of coherent text, it is not a proof that LLM IS the way our minds work. It is just a witness to the fact language is a flexible medium for the meanings behind - it can just as well be used for cheating, pretending, etc. reply mistermann 4 hours agorootparent> So the fallacy of... The text from this point on seems to have lost contextual awareness of what preceded it (which was excellent imho). reply gaganyaan 15 hours agoparentprevDefine reason before making grandiose claims. reply quantadev 14 hours agorootparentI think \"reasoning\" is the best word in the English language that I know of to describe what LLMs are doing. Lots of people disagree because for about 2000 years that word always implied consciousness, and LLMs definitely don't have consciousness. reply HeatrayEnjoyer 13 hours agorootparentIt's not possible to know if anyone has consciousness, other than them themselves. We must be *very* careful before making authoritative statements about who and what has qualia. reply godelski 13 hours agorootparentThe logic goes the other way. The claim that is extraordinary is that a rock with electricity has consciousness. Nothing else we've built has shown evidence of consciousness and there's good explanations for the results we see without needing consciousness. Sure, it's still debatable for us humans (the term isn't well defined) but that doesn't change the direction of required proof. reply gaganyaan 20 minutes agorootparentIt's not the silicon that's conscious of things, it's the model that happens to use that silicon. reply mistermann 4 hours agorootparentprevAny assertion has a burden of proof, you are likely referring to cultural/colloquial norms/beliefs on the matter. There is cultural/normative truth, and then there are various stricter/technical interpretations (using forms of logic other than binary, which causes reality to appear very differently), and making such distinctions is typically culturally \"discouraged\" (it is rude, pedantic, not what HN is for, etc). reply godelski 1 hour agorootparentConsciousness is not binary. The burden of proof does have direction. It's in the direction of the more complicated thing. Do you think a rock is conscious? What about lightning? If you're 99.999% of people, then the answer is no. So if you want to claim AI is conscious you need make the claim where inanimate becomes animate. And you know what they say about extraordinary claims... But personally I don't believe in ghosts, even those in machines reply gaganyaan 12 minutes agorootparentSee my other comment too, but I agree. Rocks and lightning aren't conscious of anything, because they have no state that represents anything. Amoeba are conscious of some things, because they have state that represents a tiny slice of the world. Cats are conscious of much more, then LLMs and humans in turn. It's not about animate vs inanimate, it's about models that represent something. There's also some confusion because we have limited language here. A person can be \"unconscious\", but that doesn't mean they've lost their world model. It's just currently not executing. gaganyaan 14 hours agorootparentprevDefine consciousness before making that claim either. reply quantadev 14 hours agorootparentI'm fine with the standard dictionary definition in this case. :P reply gaganyaan 14 hours agorootparentThere's as many definitions as there are dictionaries, but let's try picking \"awareness\". LLMs are aware of many things, so they are conscious of those things, meaning they display some level of consciousness. reply quantadev 13 hours agorootparentNice one. Now do \"qualia\" reply gaganyaan 21 minutes agorootparentQualia is a silly god of the gaps style argument. There's no difference between \"seeing red\" and \"having your neurons tickled so that you think you're seeing red\". People really don't understand consciousness, but it's actually quite simple when you realize that the question isn't \"is this conscious?\", it's \"what is this conscious of?\". A rock is not conscious of anything, because it has no state that represents anything. A sunflower is conscious of the sun's position, because it has state that represents that. A cat is conscious of much more, such as \"this mouse is food\". An LLM is conscious of much more, but less than a human. The LLM is a model that is conscious of many things, as experienced through the medium of human text. reply Fellshard 9 hours agorootparentprevThe grandiose claim would be that LLMs have reason to begin with. It is quite normal for things to not have reasoning capacity. reply seanmcdirmid 11 hours agoparentprevLLMs are statistical text generators whose results depend on the model and the context given. They have gotten so good because the context they can effectively operate over keeps getting really big. If you take the model and operate on a small context, you will get very uninteresting results. The only reason it seems like it is reasoning is because it’s probably stuffing a lot of reasoning in its context, and regurgitating that out in ways that are statically weighted with other things in the context on what is being reasoned about. Frankly, even most commenters on HN don’t get how LLMs operate, thinking the model itself is what knows about different bases like hex and oct, when really, it searched up a bunch of material on different bases to include in the context before the model was ever activated. reply aurareturn 15 hours agoparentprevBrains do not reason - they are a neural network whose results are defined by their experiences, memories, and sensory inputs. I'm tired of reading comments from people who keep repeating that LLMs don't think, don't reason, isn't intelligence because it is not human. If your definition of the above is because it's not human, it's quite useless as a comment. We know LLMs aren't biological human brains. So what? Define what reasoning is to you. Then tell us why LLMs don't reason and why it matters. reply imtringued 9 hours agorootparentArtificial intelligence is still intelligence, even if it is just a shallow copy of human intelligence. What irritates me when I see comments like yours is that precise knowledge of weaknesses of LLMs is necessary to either improve LLMs, so most of the people who claim LLMs reason or are already AGI basically deny the ability to improve them, since they are already perfect. Research into studying the limitations of the current generation of AI is unwanted and by extension so is the next generation of AI. reply cscurmudgeon 14 hours agorootparentprevNot OP. But: 1. Reasoning is ability to at least carry out proofs in FOL (first-order logic). FOL can simulate Turing Mach 2. LLMs are formally equivalent to only a subset of FOL. Why is this important? To model human mathematics, you need at least first-order logic. These arguments have been around for decades, e.g., Penrose. I am tired of people bringing up strawmen arguments (\"Not intelligent because not human!\") reply scarmig 14 hours agorootparentIs there a proof that collections of human neurons are capable of carrying out proofs in first order logic, in full generality? reply fmbb 14 hours agorootparentIs anyone trying to prove that all humans can? reply gaganyaan 14 hours agorootparentprevCan a cat reason? It knows nothing of FOL or math, but can be very smart when figuring out how to catch a mouse. reply Infinity315 13 hours agorootparentThe term 'reason' is being overloaded here. The type of 'reason' a cat uses is different from the 'reason' used in math The information a cat uses is incomplete whereas the information used in math and logic is theoretically all accessible. The reasoning a cat uses allows for inconsistencies with its model because of its use of incomplete information whereas no inconsistencies are permissible in math and logic. Formally speaking, math uses deductive reasoning whereas the cat uses abductive reasoning. reply logicchains 11 hours agorootparentprevTransformers with chain of thought can use FOL: https://arxiv.org/abs/2310.07923 reply AdieuToLogic 13 hours agorootparentprev> Brains do not reason ... They can, at times, and do so best when emotion is not involved. > I'm tired of reading comments from people who keep repeating that LLMs don't think, don't reason, isn't intelligence because it is not human. LLM's represent a category of algorithm. Quite elegant and useful in some circumstances, but an algorithm none the less. A quick search produced this[0] example discussing same. Another reference, which may not be authoritative based on whatever most recent edit the link produces, is[1]: A large language model (LLM) is a computational model capable of language generation or other natural language processing tasks. As language models, LLMs acquire these abilities by learning statistical relationships from vast amounts of text during a self-supervised and semi-supervised training process. > Define what reasoning is to you. Reasoning was the process I went through to formulate this response, doing so with intent to convey meaning as best as I can, and understand as best as possible the message to which I am replying. > Then tell us why LLMs don't reason and why it matters. LLM's do not possess the ability to perform the process detailed above. This is why it matters. 0 - https://github.com/rasbt/LLMs-from-scratch 1 - https://en.wikipedia.org/wiki/Large_language_model reply viraptor 13 hours agorootparent> Reasoning was the process I went through to ... That's not a useful definition for judging whether LLMs reason or not. It's not something we can measure on an objective level and introduces another concept of intent which is just as vague as reasoning. Specifically, an LLM can produce a similar message to what you posted. Everything else about that process is not defined well enough to differentiate you. reply Vampiero 11 hours agorootparentOk, that's cool, now ask GPT to solve any programming or logic problem at all and maybe you'll start to understand why you can reason and why it can't. reply viraptor 11 hours agorootparentIt can solve some problems and not others. But that would be again a different definition of reasoning, not what the parent wrote. And it would exclude animals/humans as reasoning, because they can't solve all logic problems. reply hydrox24 16 hours agoprevIs there a good reason to exclude abductive reasoning from an analysis like this? It's even considered by at least one of the referenced papers (Fangzhi 2023a). Abductive reasoning is common in day-to-day life. It seeks the best explanation for some (often incomplete) observations, and reaches conclusions without certainty. I would have thought it would be important to assess for LLMs. reply soferio 16 hours agoparenthttps://en.wikipedia.org/wiki/Abductive_reasoning Is abductive inference synonymous with bayesian inference? reply keiferski 14 hours agorootparentHere’s a good page to read on that: https://plato.stanford.edu/entries/abduction/#AbdVerBayConTh... reply randcraw 14 hours agorootparentprevI like to think of abductive reasoning as the basis for science that explains natural processes that happened in the past -- like astronomy and geology and evolution -- where experiments are too big to conduct or processes too slow to observe in real-time. So we propose mechanistic explanations for nonobvious outcomes like the formations of stars, or motion of large land mass via plate tectonics or glaciation, or long-range organism speciation over millennia. That's the role for abduction, to explain how all that happened. reply User23 14 hours agorootparentprevNo, but agreement with priors is one way one might choose between possibilities. For example suppose you go outside and the streets are wet. Perhaps it rained, or perhaps someone drove a fire truck around spraying water all over the streets. You might select the former because of its higher prior probability. reply refulgentis 15 hours agoparentprevMy instinct is it is a distinction without a difference in this context. i.e. if deductive is \"I watched the cue ball hit the 8 ball, therefore, the 8 ball is moving\" and abductive is \"the 8 ball is moving towards me, therefore the cue ball must have hit it. I cannot claim to have deduced this because I did not observe it\", LLMs cannot observe the situation, so any deduction (in the binary induction/deductive sense) must be done by abduction. reply randcraw 14 hours agoprevThe conclusions of the authors that LLMs can reason inductively very well runs counter to what I've read elsewhere. A big part of doing induction is the ability to generalize a shared pattern from multiple disparate examples, recognizing the essential elements that are necessary and sufficient to satisfy that pattern's operators' constraints. To date, I've seen consensus that LLMs can match verbs or basic relational operators across examples, thereby associating the mechanisms in similar events that lead to similar outcomes. But extending that facility further, to employing predicate logic operators, or even the simpler propositional ones appears to fall largely outside LLM capabilities. To suggest then that LLMs can then perform higher-order reasoning skills yet, like the modeling of contrapositives, this seems quite a stretch. reply golergka 13 hours agoparentI've just successfully chatted to ChatGPT about equivalence or at least high similarities between QFT, neural networks and cellular automata (referencing Wofram's work). Does that pattern matching count? reply xwolfi 11 hours agorootparentAnd you were able to verify, of course, that anything new or surprising to you (as in, not a simple derivation of your own prompts), was true ? I noticed that if I ask it to tell me how good cryptocurrencies are, it'll do it, and then if I say I disagree and they're wrong, it'll simply switch and agree with me as well. The thing has no care for truth, no opinion of its own, no ability to insist, and just feeds you whatever is statistically close to your own questions. reply Vampiero 11 hours agorootparentprevNo but GPT is really good at fooling laymen who are not experts of a field, and it stands to reason that it just fed you a bunch of bs reply xiphias2 13 hours agoprevTransformers are amazing pattern matchers and terrible use of GPUs for reasoning, which is mostly search + execution of highly non-linear programs (lambda calculus). I love seeing Victor Taelin experimenting with parallizing these programs (with HVM and other experiments with proof languages), but it's sometimes a bit sad how much time researchers take in making papers about existing things instead of trying to improve the state-of-the art in something that's most probably missing from the current models. reply jcims 16 hours agoprevLLMs don’t feel like a whole brain, they feel like the impulsive side that gets filtered by other processes. reply AdieuToLogic 15 hours agoparent> LLMs don’t feel like a whole brain ... Because they are not. LLM's are a better form of Bayesian inference[0] in that the generated tokens are statistically a better fit within a larger context. 0 - https://en.wikipedia.org/wiki/Bayesian_inference reply stavros 15 hours agorootparentThis strikes me as saying \"Brains aren't brains, they're merely a collection of neurons that output some voltage in response to their input voltage\". reply suprjami 15 hours agorootparentYou're comparing the physical item with the reasoning capabilities of that item. A popular LLM joke at the moment is \"How many Rs in strawberry?\" You, a human being, understand this question. The purpose of the activity is to count the letter R in that word and give the one correct answer. LLMs don't understand any of that. They don't know what words are, what letters are, what numbers are, what counting is, that a question can have one definite correct answer or many answers, what a question is, nor what an answer is. They break your input into tokens and then look at the most likely set of output tokens given your input. That's all. If you train a model on enough sensible input tokens and sensible responses then the output will mostly seem human and sensible. But it's never reasoning. reply seanmcdirmid 11 hours agorootparent> They break your input into tokens and then look at the most likely set of output tokens given your input. That's all. That isn’t right: the pre processor provides a lot of material on strawberries and counting r’s, which is then pretending to the question…and then they predict the next sentence as an answer to the question. The model by itself doesn’t know anything, it it just a statistical processor of context, just tokenizing the question and using the model to predict the answer would actually give you less than a wrong answer, it would be gibberish. It messes up on the question because the context it retrieves based on the question text isn’t useful in producing the correct answer. reply imtringued 9 hours agorootparent>because the context it retrieves based on the question text isn’t useful in producing the correct answer. \"retrieves\" is the wrong word. Each token (in GQA a small tuple of tokens is summarized into a single token), becomes an element in the KV cache. The dot product of every token with every other token is taken (matrix multiplication) and then a new intermediate token is produced using softmax() and multiplication by the V matrix. What the attention mechanism is supposed to do is combine two tokens and form a new token. In other words, it is supposed to perform the computation of a function f(a,b) = c. The attention layer is supposed to see \"count r\" and \"strawberry\" and determine the answer 3. Well, at least in theory. Given the combination \"count r\" and \"r\", it is practically guaranteed that the attention mechanism succeeds. What this tells us is that the tokenization of the word \"strawberry\" is causing the model to fail, since it doesn't actually see the letters on the character level. So it is correct to say that the attention mechanism does not have the correct context to produce the correct answer, but it is wrong to say that \"retrieval\" is necessary here. The reason why it doesn't make sense to label what is happening as \"reasoning\" is that the model does not consider its own limitations and plans around them. Most of the work so far has been to brute force more data and more FLOPS, with the hope that it will just work out anyway. This isn't necessarily a bad strategy as it follows the harsh truth learned from the bitter lesson, but the bitter lesson never told us that we can't improve LLMs through human ingenuity, just that human ingenuity must scale with compute and training data. For example, the human ingenuity of \"self play\" training (as opposed to synthetic data) works just fine, precisely because it scales so well. Instead of complaining so much about humans trying to \"gotcha\" the LLMs, what we really ought to build is an adversarial model that learns to \"gotcha\" LLMs automatically and include it in the training process. reply viraptor 12 hours agorootparentprev> They break your input into tokens and then look at the most likely set of output tokens given your input. That's all. That's humans as well, possibly. This description gets repeated over and over and is factually correct, but we still don't know if brains do anything more. The \"it's not reasoning\" may be true, but it doesn't follow from just that description. reply gaganyaan 15 hours agorootparentprevThey very much do understand words, letters, etc. Why do you think otherwise? Because of one trick question? reply suprjami 15 hours agorootparentYou are fooled into thinking that producing a set of output tokens which mimic actual human input and output tokens displays understanding. It doesn't. \"How many Rs in strawberry?\" is not a trick question. That's about as straight and factual as a question could be. reply quantadev 14 hours agorootparentIntelligence is a vast spectrum of capabilities. There are people who function normally but cant't recognize faces. There are people who can't see or understand anything on their left side. Even savantism is an example where some brains have nearly superhuman capabilities in one area, but are almost mentally retarded in other areas, like common sense, and yes even letter counting. All the letter counting failure shows is that maybe all LLMs lean a bit more towards autistic brains than towards the actual average human brain. reply gaganyaan 14 hours agorootparentprevHumans have many well-documented cognitive shortcomings and failure modes. Does that mean we don't reason either? reply suprjami 14 hours agorootparentWe aren't talking about a human mind which operates in unexpected or ways which don't conform with society. Don't bring an appeal to neurodivergence to an LLM argument. We are talking about a computer program whose operation we understand, can observe, and can debug. Modern LLMs certainly take a lot of human effort to do this, but it can be done. reply gaganyaan 35 minutes agorootparentThis isn't about neurodivergence. Every single human suffers from a long list of cognitive shortcomings. We just call them things like \"optical illusions\" and find them interesting, but don't then go on to make silly claims like \"humans can't reason\". reply jcims 11 hours agorootparentprevAsk it this. \"Please spell the word strawberry with a phonetic representation of each letter then tell me how many 'r's are in the word strawberry?\" It's gotten the answer right every time I've tried. reply gaganyaan 33 minutes agorootparentAnother one is to just ask it to spell it out with dashes in between each letter. If anyone's wondering, it then gets it right because that changes the tokenization, changing how the model actually \"sees\" it. reply og_kalu 14 hours agorootparentprev>\"How many Rs in strawberry?\" is not a trick question. To a system that sees letters and words, sure. To a system that doesn't, you're just asking a blind man to count how many apples are on the table and patting yourself on the back for his failure. It just doesn't make any sense to begin with. And this is before the fact that human intelligence is rife with absurd seeming failure modes and cognitive biases. It's frankly very telling that these token related questions are the most popular kind of questions for these discussions. This is no testable definition of reasoning or intelligence that will cleanly separate LLMs and Humans. That is the reality today. And it should make anybody pause. reply kortilla 14 hours agorootparent> you're just asking a blind man to count how many apples are on the table Which input is it you think an LLM doesn’t have to be able to count the number of letters in a word you literally provide it reply isaacfung 13 hours agorootparentThe text is converted to embeddings after tokenization. The neural networwk only sees vectors. Imagine the original question is posed in English but it is translated to Chinese and then the LLM has to answer the original question based on the Chinese translation. It's a flaw of the tokenization we choose. We can train an LLM using letters instead of tokens as the base units but that would be inefficient. reply daveguy 13 hours agorootparentBy that definition the LLM literally does not see anything. LLMs predict tokens. That's it. reply gaganyaan 28 minutes agorootparentThe LLM sees tokens, and predicts next tokens. These tokens encode a vast world, as experienced by humans and communicated through written language. The LLM is seeing the world, but through a peephole. This is pretty neat. The peephole will expand soon, as multimodal models come into their own, and as the models start getting mixed with robotics, allowing them to go and interact with the world more directly, instead of through the medium of human-written text. reply isaacfung 13 hours agorootparentprevIt sees embeddings that is trained to encode semantic meanings. The way we tokenize is just a design choice. Character level models(e.g. karpathy's nanoGPT) exist and are used for educational purpose. You can train it to count number of 'r' in a word. https://x.com/karpathy/status/1816637781659254908?lang=en reply davnn 14 hours agorootparentprevChatGPT answer: There are *two* \"R\"s in the word \"strawberry.\" reply AdieuToLogic 13 hours agorootparent>> A popular LLM joke at the moment is \"How many Rs in strawberry?\" > ChatGPT answer: There are two \"R\"s in the word \"strawberry.\" Given enough instances of the \"LLM joke\" in a training data set, the joke itself having a consistent form (sequence of tokens) and likely followed by the answer having a similarly consistent form (sequence of tokens), the probability of the latter being produced as quoted is high. reply imtringued 9 hours agorootparentThere is a lot of broken English on the internet and yet LLMs are better at English than the average native speaker. This failure mode has nothing to do with the training data. reply eightysixfour 16 hours agoparentprevWhile there is sometimes an exaggeration of the differences, I have always found LLMs to behave like (and have many of the weaknesses of) the left hemisphere of the brain as described in books like “The Master and His Emissary.” Considering the left is the language center, this shouldn’t be surprising. reply bob1029 10 hours agoprevLLMs are incredible about mapping to a space of already seen things. When this space is unimaginably large, you can be fooled for a long time. But, they clearly struggle with generalization and rule following. This failure to generalize (extrapolate, deduce, compute) is why we still can't fire all of our DBAs. Has anyone encountered an LLM-based text-to-SQL engine that actually gets the job done? I think that's your best canary. I stopped caring somewhere around \"transpose these 2 letters of the alphabet\" not working consistently. reply calf 10 hours agoprevWhy does it have to be an either-or? Maybe LLMs are doing a bit of both, in a weird hybrid way; it is both doing a statistical calculation and yet the network is parameterized to do some very rudimentary (and nonhuman) reasoning computations. That's plausible to me, and explains why the reasoning is so hard to isolate... Just like how looking at a human brain it is hard to isolate the reasoning capacities. reply Datagenerator 12 hours agoprevThe human mind wonders and takes time to dream autonomously. Perhaps the llm.c we need for the next breakthrough addresses rounds of meditation in it's training in order to provoke more reason alike features to the NextGen LLM. reply sfink 15 hours agoprevConfession: I haven't read the paper. But any mention of LLM reasoning ability ought to address the obvious confound: the LLM is trained on examples of deductive reasoning, inductive reasoning, abductive reasoning, SAT-solver reasoning, geniuses' musings, etc. If they replicate one of those examples, then should that be called \"reasoning\" of any sort or not? Regurgitating those examples may even involve some generalization, if the original topics of an example are swapped out (perhaps by a nearby topic in latent space). Given that it appears they're training and testing on synthetic problems, this objection probably does not apply to their actual results. But given the fuzziness it creates for the definition of \"reasoning\" of any sort, I would have expected some working definition of reasoning in the paper's abstract. Training on Moby Dick and thus being able to regurgitate text from Moby Dick does not mean the LLM is capable of writing a new Moby Dick-like book. (Thankfully; one is more than enough!) reply viraptor 12 hours agoparentThe tasks used are artificially created and don't exist in the training sets. For example there's very little practical math in base 11 on the internet, or English with explicitly mixed up but rule based grammar. reply moktonar 8 hours agoprevAsking them to make ASCII art is the final test, to me. reply WaitWaitWha 14 hours agoprev [–] Neither. LLMs are just really, really good pattern matchers with enormous set of patterns. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The study explores the distinction between deductive and inductive reasoning in Large Language Models (LLMs), a topic that has not been thoroughly examined before.",
      "Researchers introduced the SolverLearner framework to evaluate LLMs' inductive reasoning, finding that LLMs perform exceptionally well in inductive tasks but struggle with deductive reasoning, particularly in counterfactual scenarios.",
      "This research is significant as it highlights the strengths and weaknesses of LLMs in different types of reasoning, providing insights for future improvements in AI models."
    ],
    "commentSummary": [
      "The debate centers on whether Large Language Models (LLMs) like GPT are truly reasoning or merely regurgitating learned patterns from their training data.",
      "Some argue that LLMs are statistical text generators and not capable of genuine reasoning, while others discuss their ability to perform inductive or deductive reasoning.",
      "The conversation also highlights the limitations of LLMs and potential areas for improvement."
    ],
    "points": 89,
    "commentCount": 105,
    "retryCount": 0,
    "time": 1725238146
  },
  {
    "id": 41422283,
    "title": "Parsing Awk Is Tricky",
    "originLink": "https://www.raygard.net/awkdoc/pages/awk_parsing_is_tricky.html",
    "originBody": "Parsing awk is tricky What is the grammar and meaning of awk code? Maybe a yacc expert could know. If you only know what the Awk book (by A, K, & W, 1st or 2nd Ed.) says, you’d be missing some details. For example, the Awk book and many other documents say a for statement is: for (expression₁; expression₂; expression₃) statement (or any of the three expressions can be empty). But try this: awk 'BEGIN{for (; x++0; printf(\"Enter data: \")) { ## stuff with data } But even if it could be useful, very few users would ever know about it because it’s undocumented outside the formal grammar. A few interesting cases Case 1 Consider this: awk 'BEGIN{if (1 < 2 && x = 3) print x}'. According to the POSIX grammar this should be a syntax error, but it prints 3. The spec says This grammar has several ambiguities that shall be resolved as follows: Operator precedence and associativity shall be as described in Expressions in Decreasing Precedence in awk. Assignment = has lower precedence than &&, which has lower precedence than <. The statement should parse as: if (((1 < 2) && x) = 3), and the expression to the left of = must be an lvalue, which it clearly is not. (The additional parentheses are notional; no parentheses are allowed around an lvalue.) The rules are similar in C, and a statement like this is a syntax error in C. Case 2 Another odd one, adapted from gawk test getline.awk: running this in bash (as e.g. ./getline_test1.sh gawk): #!/usr/bin/bash awk=$1 echo -e 'ABC'|$awk 'BEGIN {x = y = \"!\"a = (getline x y); print a, xa = (getline x + 1); print a, xa = (getline x - 2); print a, x }' with any of gawk, nawk, nnawk, goawk, bbawk gives the same result: 1! A 2 B -1 C But running this (as getline_test2.awk): BEGIN {x = y = \"!\"cmd = \"echo A\"; a = (cmdgetline x y); close(cmd); print a, xcmd = \"echo B\"; a = (cmdgetline x + 1); close(cmd); print a, xcmd = \"echo C\"; a = (cmdgetline x - 2); close(cmd); print a, x } gives the same result as above in gawk, mawk, and bbawk, but goawk gets a parsing error on the “echo A” line, and nawk/nnawk gives: 1! A 11 B 1-2 C This seems really odd to me. The original awk (nawk/nnawk – Kernighan’s OneTrueAwk) apparently parses (cmdgetline x y) as ((cmdgetline x) y), but parses (cmdgetline x + 1) as ((cmdgetline x) (+ 1)) and (cmdgetline x - 2) as ((cmdgetline x) (- 2)). (That is, the y, the + 1, and the - 2 are treated as strings concatenated with the result of (cmdgetline x).) This is despite the fact that the right side of a concatenation excludes an expression beginning with + or -, according to POSIX, as it must because it otherwise makes a + b ambiguous as to whether it’s (a + b) or (a) (+b). Case 3 BEGIN {$0 = \"2 3 4\"; $$0++; print} prints 3, except bbawk says “Unexpected token”, and my awk as of this writing prints 2 4 4. Which is “correct”? Apparently nawk, gawk, mawk, and goawk work as follows (bbawk gets a syntax error): in $$0++, the $0 is \"2 3 4\" but the ++ forces it numeric, as 2, so the post-increment applies to $0 which sets the entire record to 3. The subsequent outer $ selects field 3 of $0, which does not exist, so the value of $$0++ is the empty string. My awk tries to obey the precedence rules in POSIX, which have $ at higher precedence than ++, so evaluates $$0 first as $2, selecting the second field, and then the ++ increments it to 4. But wait, there’s more! Try BEGIN {a = 2; b[1] = 2; $0 = \"33 44\"; print $a; $a++; print; print $b[1]; $b[1]++; print b[1]; print} In gawk, mawk, goawk, bbawk, and my awk, it prints 44 33 45 45 2 33 46 But in nawk/nnawk, it prints 44 33 45 45 3 33 45 What’s happening in nawk/nnawk is: $a++ increments the field $a (i.e. $2), but $b[1]++ increments the array value b[1] and does not change the field. All the other awks increment field 2 in both cases, as one might expect. Once again, the original One True Awk’s behavior seems inconsistent and not easily discernible from the yacc grammar, nor from the documentation. Case 4 BEGIN {$0=\"3 4 5 6 7 8 9\"; a=3; print $$a++++; print} prints 7 3 4 6 6 8 8 9 except bbawk and my awk currently indicate a syntax error. Similar to case 3 above; $a selects field 3, which is 5, increments it, but then $$a++ is a reference to field 5, which is 7, and that is printed as the value of $$a++++, but then that field is incremented, giving $0 the value “3 4 6 6 8 8 9”. My awk (and apparently bbawk?) parse $$a++++ as if it were (($($a))++)++ and reject the outer ++ because (($($a))++) is a value, not an lvalue. The parentheses here are again notional; an lvalue cannot be in parentheses. Case 5 BEGIN {a[y] = 1; x = y in a + 2; print x} prints an empty line in bbawk 3 in wak 12 in nnawk/nawk (!) a syntax error message at ‘+’ in gawk, mawk, goawk Apparently nnawk/nawk treats the + 2 as a string to be concatenated with the 1 from evaluating y in a as true. What causes these peculiarities? Aho, Weinberger, and Kernighan have written that The development of awk was significantly shortened by using UNIX tools. The grammar is specified with yacc; the lexical analysis is done by lex. Using these tools made it easy to vary the syntax of the language during development. In The Unix Programming Environment, Kernighan and Rob Pike wrote (footnote, p. 254): The yacc message “reduce/reduce conflict” indicates a serious problem, more often the symptom of an outright error in the grammar than an intentional ambiguity. Compiling One True Awk (nawk/nnawk) gets 85 reduce/reduce conflicts in addition to 44 shift/reduce conflicts. The original yacc grammar for awk has many ambiguities. I don’t know much about yacc yet, but I understand it’s basically an LALR(1) parser generator, but with additional features to resolve what would otherwise be ambiguities. I suspect that these features make it hard to understand exactly what the parser does if you are not a yacc expert. The actual awk language is determined by what the parser accepts and what it does with that. My guess is that there may not be any true LALR(1) grammar for awk, maybe no LR(1) grammar, and probably no LL(1) grammar either. This makes writing a recursive-descent parser by hand somewhat difficult. The POSIX grammar is in a yacc-like format and was obviously written with some reference to the original yacc grammar for awk. I can say that with some confidence because it includes the for (simple_statement ...) business discussed above, which one would never know without studying the original yacc grammar. But as shown above, existing implementations do not always follow POSIX grammar, and when they differ they usually follow the original awk behavior. I asked Arnold Robbins (gawk maintainer and contributor to One True Awk) about case 1. He replied “The answer, as unsatisfying as it may be, is that Awk has always worked this way.” Also, regarding case 1 above, Ben Hoyt had the same issue in goawk. He resolved it with the commit that included this comment: The other awks support this by using a yacc grammar which supports backtracking, and as Vitus13 said on reddit: “If there are two syntactically valid parsings and one is a semantic error, the error handling may resolve the ambiguity towards the valid parsing. In this case, you can only assign to L values, so trying to assign to (1&&x) doesn’t make any sense.” I believe this is a misconception; yacc does not support backtracking (though there is a different program, btyacc, that does). I think Ben and Vitus13 are wrong here; yacc does not see multiple syntactically valid parsings, it sees only the parsing that it performs deterministically, and many of the problems understanding what nawk/nnawk does are due to the way yacc resolves conflicts.",
    "commentLink": "https://news.ycombinator.com/item?id=41422283",
    "commentBody": "Parsing Awk Is Tricky (raygard.net)88 points by oliverkwebb 15 hours agohidepastfavorite69 comments mmsc 6 hours agoAwk is something that I think every programmer and especially every sysadmin should learn. 8 like the comparison at the end and have never heard of nnawk or bbawk before. I recently made a dashboard to compare four versions of awk output together, since not all awk scripts I'll run the same on each version: https://megamansec.github.io/awk-compare/ I'll have to add those:) reply hulium 2 hours agoparentawk is also not hard to understand, scroll through the Wikipedia page for a few minutes https://en.wikipedia.org/wiki/AWK#Structure_of_AWK_programs It runs an action for each line in the input (optionally filtered by regex). You get automatic variables $1,$2... for the words in the line split by spaces. The syntax is almost like a simple subset of Javascript. Builtin functions are similar to C standard library. If you have input in text that is separated in columns with a delimiter, and you want do simple operations on that (filter, map, aggregate), it can be done quickly with awk. That's all you need to know about awk. reply Chris2048 6 hours agoparentprev> every programmer and especially every sysadmin should learn There are lots of things \"everyshould learn\", usually by people who already did so. I still have a bunch of AI/ML items on that list too. What's the advantage of learning AWK over Perl? reply mbivert 2 hours agorootparent> What's the advantage of learning AWK over Perl? Getting awk in your head (fully) takes about an afternoon: reading the (small and exhaustive) man page, going through a few examples, trying to build a few toys with it. Perl requires much, much more effort. Great gain/investment ratio. reply Chris2048 2 hours agorootparentanother commenter said something similar - But nothing says you have to learn everything - you can learn a subset of perl that does everything you would want to do (with awk), would that take as long? reply mbivert 1 hour agorootparentYup, but defining that subset isn't free! Perhaps some people did the work already, but I'd still be cautious as to how much Perl one actually need to know to use those comfortably. reply Snoddas 5 hours agorootparentprevBoth will get you where you want to go, but I don't think the usecase for perl and awk are the same. I reach for awk when my bash-scripts get a bit messy, perl is/was for when I want to build a small application (or nowdays python). But both perl and python require cpan/pip to get the most out of and with awk, I just nead awk. reply LegionMammal978 3 hours agorootparentIs there any particular functionality which does exist in awk, but doesn't exist in Perl or Python without third-party libraries? I've always found \"Python + built-in modules\" more than sufficient for my text-manipulation needs. (Also, it lets me handle binary data and character data in the same program, which is very useful for certain tasks.) reply williamcotton 2 hours agorootparentIt’s just that awk has a concise syntax that can make for some really quick one-liners in your terminal prompt. Why spend a minute or two in Python if you can get an answer in 15 seconds instead? reply kevindamm 1 hour agorootparent> Why spend a minute or two in Python if you can get an answer in 15 seconds instead? Because you (or someone else) can run your Python later if needed, and have confidence the output will be the same. Sure, there are some times when a one-liner is needed, and you can always put that one line in a document for others to run. I can think of many times when I was on-call and needing to grep some data out of logs that wasn't already in a graph/dashboard somewhere. When time is of the essence, or if you're really really sure that you won't need to run the same or similar thing ever again, even if the data changes. I even changed my shell to make up-arrow go through commands with the same prefix instead of linearly traversing command history because I had so many useful one-liners I re-ran later. But as I've gotten more experienced, I've come to appreciate the value of committing those one liners to code as early as possible, and having that code reviewed. Sometimes a really useful tool will even emerge from that. reply shawn_w 3 hours agorootparentprevI put off learning awk for literal decades because I knew perl, but then I picked it up and wish I had done so earlier. I still prefer perl for a lot of use cases, but in one-liners, awk's syntax makes working with specific fields a lot more convenient than perl's autosplit mode. `$1` instead of `$F[0]`, basically. reply Chris2048 1 hour agorootparentbut, then couldn't you use \"cut\" as even simpler syntax? reply stouset 1 hour agorootparent`cut` doesn’t work natively on data that’s been aligned with multiple spaces, you need a `tr -s` pass first. It also doesn’t let you reorder or splice together fields. I used it for years but now that I have a working understanding of `awk` I have never looked back. reply shawn_w 1 hour agorootparentprevMaybe if all you want to do is unconditionally extract certain columns from your data. But even in that case cut doesn't let you use a regular expression as the field delimiter. reply philipov 1 hour agorootparentprevEvery linux system comes with awk already on it. Perl has to be installed, and might not be available on a system you don't control. reply rlonstein 6 hours agorootparentprev- Awk is defined in POSIX - Awk is on more systems than Perl - Awk has more implementations than Perl reply chrsig 5 hours agorootparentawk is also a much smaller language than perl, so it's generally less effort to teach, learn, and read. reply Chris2048 2 hours agorootparentIs it not possible to learn a subset of perl? reply chrsig 2 hours agorootparentLearning any language more or less starts with learning a subset of it. Asking a new hire to \"learn awk\" vs \"learn perl\" have two very different time investments attached to them. Tasking someone with \"learning a subset of perl\" begets the question \"what subset?\", and a very exhausting conversation with someone(s) routinely asking \"so?\" follows. After spending a large amount of time re-litigating which subsets of perl features we want that awk already supplies. reply Chris2048 2 hours agorootparentprev> Awk is defined in POSIX so? > Awk is on more systems than Perl By what metric? > Awk has more implementations than Perl so? reply rlonstein 1 hour agorootparentWhatever you think my opinion is of Perl you're probably wrong and the tone of your advocacy is kind of odd. Awk is older and as a part of POSIX the version found on unix-like environments will be (outside of extensions) compatible with others. If one or one without the extensions you want isn't present you can choose an implementation, even one in Go and it'll work. Perl, and I've been writing Perl since Perl4, doesn't have those characteristics. It's a much more powerful language that has changed over the years and it is not always present by default on a unix-like system. Because the maintainers value backward compatibility, even scripts written on Perl5.005 have a fair chance of working on a modern version but it's not assumed (and you shouldn't assume anything about modules). Because Awk is fossilized, you can assume that. reply Chris2048 1 hour agorootparentThe first and last items in your list provide no reason why they are relevant, there is no \"tone\", nor \"advocacy\" - it's not \"odd\" to ask for that context, as given here. reply RodgerTheGreat 14 hours agoprevI think this is a good illustration of why parser-generator middleware like yacc is fundamentally misguided; they create totally unnecessary gaps between design intent and the action of the parser. In a hand-rolled recursive descent parser, or even a set of PEG productions, ambiguities and complex lookahead or backtracking leap out at the programmer immediately. reply jasone 13 hours agoparentHard disagree. Yacc has unnecessary footguns, in particular the fallout from using LALR(1), but more modern parser generators like bison provide LR(1) and IELR(1). Hand-rolled recursive descent parsers as well as parser combinators can easily obscure implicit resolution of grammar ambiguities. A good LR(1) parser generator enables a level of grammar consistency that is very difficult to achieve otherwise. reply thomasmg 11 hours agorootparent> Hand-rolled recursive descent parsers as well as parser combinators can easily obscure implicit resolution of grammar ambiguities. Could you give a concrete, real-life example of this? I have written many recursive-descent parsers and never ran into this problem (Apache Jackrabbit Oak SQL and XPath parser, H2 database engine, PointBase Micro database engine, HypersonicSQL, NewSQL, Regex parsers, GraphQL parsers, and currently the Bau programming language). I have often heard that Bison / Yacc / ANTLR etc are \"superior\", but mostly from people that didn't actually have to write and maintain production-quality parsers. I do have experience with the above parser generators, eg. for university projects, and Apache Jackrabbit (2.x). I remember that in each case, the parser generators had some \"limitations\" that caused problems down the line. Then I had to spend more time trying to work around the parser generator limitations than actually doing productive work. This may sound harsh, but well that's my experience... I would love to hear from people that had a different experience for non-trivial projects... reply tgv 6 hours agorootparentThe original comment says that using yacc/bison is \"fundamentally misguided.\" But parser generators make it easy to add a correct parser to your project. It's obviously not the only way. Hand-rolling has a bunch of pitfalls, and easily leads to apparently correct behavior that does weird things on untested input. Your comment then is a bit like: I've never had memory corruption in C, so Rust/Java/etc. is for toy projects only. reply masfuerte 5 hours agorootparentprevIf you start with an unambiguous grammar then you aren't going to introduce ambiguities by implementing it with a recursive descent parser. If you are developing a new grammar it is quite easy to accidentally create ambiguities and a recursive descent parser won't highlight them. This becomes painful when you try to evolve the grammar. reply HelloNurse 5 hours agorootparentprevA large portion of this consistency is not making executive decisions about parsing ambiguities. The difference between \"the language is implicitly defined by what the parser does\" and \"the grammar for the language has been refined one failed test at a time\" is large and practically important. reply tgv 11 hours agorootparentprevSame. LR(k) and LL(k) are readable and completely unambiguous, in contrast to PEG, where ambiguity is resolved ad hoc: PEG doesn't have a single definition, so implementations may differ, and the original PEG uses the order of the rules and backtracking to resolve ambiguity, which may lead to different resolutions in different contexts. Ambiguity does not leap out to the programmer. OTOH, an LL(1) grammar can be used to generate a top-down/recursive descent parser, and will always be correct. reply tannhaeuser 10 hours agoparentprevI think it would be interesting and adequate to hear about and link to the reflections of the original awk authors (Aho, Kernighan, Weinberg et al) considering they were also experts for yacc and other compiler-compiler tools from the 1977–1985 era and authors of the dragon book. After all, awk syntax was the starting point for JavaScript including warts such as regexp literals, optional semicolons, for (e in a), delete a[e], introducing the function keyword to a C-like language, etc. I recall at least Kernighan talked about optional semicolons as something he‘d reconsider given the chance. reply Levitating 12 hours agoparentprevAnd GNU is notorious for their use of yacc. Even gnulib functions like parse_datetime (primarily used to power the date command) rely on a yacc generated parser. reply bonzini 10 hours agorootparentThat's mostly for historical reasons. Nobody felt the need to switch and do all the work needed to avoid breaking edge cases. GCC used to have Bison grammars but it switched to recursive descent about 20 years ago. The C++ grammar was especially horrible. reply ufo 7 hours agoprevAnother tricky bit is deciding whether \"/\" is the division operator or the start of a regular expression. IIRC, awk does this in a context sensitive manner, by looking at the previous token. reply teleforce 10 hours agoprevIf you think AWK is hard to parse then try C++. The latter is so hard to parse thus very slow compile time that most probably inspired a funny programmer skit like this, one of the most popular XKCDs of all time [1]. Then come along fast compilation modern languages like Go and D. The latter is such a fresh air is that even though it's a complex language like C++ and Rust but it managed to compile very fast. Heck it even has RDMD facility that can perform compiled REPL as you interacting with the prompt similar to interpreted programming languages like Python and Matlab. According to its author, the main reason D has very fast compile time (as long as you avoid the CTFE) is because of the language design decisions avoid the notorious symbols that can complicated symbol table just like happened in C++ and the popular > overloading for I/O and shifting. But the fact that Rust come much later than C++ and D but still slow to compile is bewildering to say the least. [1] Compiling: https://xkcd.com/303/ reply moomin 9 hours agoparentPretty sure Rust's compile times are a function of the complex type system and generic instantiation. Everything's a trade-off. reply pornel 3 hours agorootparent`cargo check` that does all the parsing, type system checks, and lifetime analysis is pretty fast compared to builds. Rust compilation time spends most time in LLVM, due to verbosity of the IR it outputs, and during linking, due to absurd amount of debug info and objects to link. When cargo check isn't fast, it's usually due to build scripts and procedural macros, which are slow due to being compiled binaries, so LLVM, linking, and running of an unoptimized ton of code blocks type checking. reply masklinn 9 hours agorootparentprevExcept in some rare edge cases, it’s mostly the latter, indirectly: in the average crate the vast majority of the time is spent in LLVM optimization passes and linking. Sometimes IR generation gets a pretty high score, but that’s somewhat inconsistent. reply dotancohen 9 hours agorootparentprevWhich are damn more important (to me) than is the compile time metric. reply fnord77 3 hours agorootparentprevIIRC, rust's long compile times are because it is basically doing static analysis, looking for potential errors reply keybored 9 hours agoparentprev> According to its author, the main reason D has very fast compile time (as long as you avoid the CTFE) is because of the language design decisions avoid the notorious symbols that can complicated symbol table just like happened in C++ and the popular > overloading for I/O and shifting. But the fact that Rust come much later than C++ and D but still slow to compile is bewildering to say the least. The reasons why Rust (rustc) is slow to compile are well-known. Not bewildering. reply orwin 8 hours agorootparentRust isn't particulary slow to compile as long as you keep opt-level to 1 and the number of external library minimal. But even them it isn't as slow as C++ (but i write shit C++ code, i've heard that modern C++ is way better, i learned with C++98 and never really improved my style despite using C++11). reply kragen 6 hours agorootparenthttp://canonical.org/~kragen/sw/dev3/gcd.rs, which uses no external libraries, takes 400–450ms to compile with rustc -C opt-level=1 gcd.rs (buggy program, i know). gcc 12, which is not anyone's idea of a fast c compiler, compiles the c equivalent http://canonical.org/~kragen/sw/dev3/gcd.c in 70–90ms, so the rust compiler is 300–500% slower tcc, which is most people's idea of a fast c compiler, compiles gcd.c in 8–9ms, so the rust compiler is 4300–5500% slower so from my point of view 'rust isn't particularly slow to compile' is off by about an order of magnitude is it as slow as c++? well, g++ compiles the c++ version of the same code http://canonical.org/~kragen/sw/dev3/gcd.cc in 460–490ms. so in this case compiling rust is, yeah, on the order of 10% faster than compiling c++? i feel like that's basically the same of course you can make compiling c++ arbitrarily slow with templates reply elegantlie 38 minutes agorootparentI think you've struck on the actual reason: Rust programmers don't perceive compile times as slow, and don't really view it as a problem. Thus, nobody works on making them faster. Every language has tradeoffs, and every language community has priorities. In general, the Rust community doesn't care about compilation speed. For now, the community has basically decided that incremental cached compilations are good enough. Which is fair, because there's only so many engineering hours, and the language has a lot of other priorities that fast to compile languages like Go ignore. I'm biased towards C and Go's way of thinking about language design, which I know a lot of other people hate. But, there's also the universal problem that once you introduce a feature into a language, people will have a field day using it in contexts where it's not needed. Just like Perl programmers have never met a regex they've never disliked, and C++ programming have never heard of a bad operator overload, Rust programmer's have never seen a bad procedural macro or external crate dependency. Showing just a little bit of restraint using complex or slow to compile language features goes a long way, but it seems like most devs (in all languages) can't resist. Go is partially fast to compile because it just tells devs they aren't allowed to do 90% of the slow-to-compile things that they want to do. Powerful languages like Rust and C++ give devs the choice, and they almost always choose the slow-to-compile but elegant option. At least, until the build hits an hour, then they wish compile times were faster. For the record, I'm not bashing C++ or Rust, I'm a C++ developer by trade. reply kragen 23 minutes agorootparenthaha, yes, exactly probably nobody but distribution packagers and bsd committers would care about the compile time if it happened while you were editing the code reply orwin 6 hours agorootparentprev> of course you can make compiling c++ arbitrarily slow with templates This might be my problem :/ (template are the closest to metaprogramming I can find outside of Lisps) Tbf I was mostly comparing my experience with Rust, SBCL and C++, to me it was a given that C was an order of magnitude faster (3 order of magnitude seems a bit much). I found opt-level=1 quite early and managed to feel way better about rust and let C++ go (i was toying with polynomial regressions) (I rolled my own matrix library :D never do that!) Thank you for the informations. reply kragen 6 hours agorootparentyeah! you can get an enormous amount of metaprogramming mileage out of c++ templates. i think the pattern-matching paradigm embodied by sfinae is maybe a better fit for, effectively, user-defined language extensions, than the more straightforward imperative approach lisp uses by default. but c++ templates are unnecessarily hard to debug i think, for reasons that aren't inherent to the pattern-matching paradigm i didn't get c to compile three orders of magnitude faster, just 44×–56× faster (4400% to 5500%). sorry to be confusing! i've certainly experienced the temptation to roll my own matrix library more than once, and i'll definitely have to do it at least once for the zorzpad. i may do something this week in order to understand the simplex method better; my operations research class was years ago, and i've forgotten how it works, probably because i never implemented it in software, just worked through examples by hand and on the chalkboard reply orwin 4 hours agorootparentHonestly, it was a school project, i had time and my final internship was month away, so i took the time to do it. Barely finished in time and it was quite lousy, but i was proud of it. It was my peak \"Dunning-Kruger\", because i was probably the most mathematically-inclined of all my classmates, and thought i was really clever. Funny stuff, during my final internship i made a heavy use of scikit-image, learned about openBlas and unterstood how much better low-level libraries were for matrix computation, and how far away my own library was. And at my next job i was setting up our PaaS VMs with a lot of stuff, including TitanX with Cuda and pytorch, informed myself on the tools i was installing (i did set up tutorials in notebooks for an easy launch), and then understood i was years behind and way less informed than i thought i was. I think i learned about HN around that time. reply jangliss 5 hours agoprevSurely it is AWKward? reply librasteve 7 hours agoprevjust use raku reply v3ss0n 11 hours agoprev [–] Reading awk as a human is hard too. And performance of awk is crap. A lot slower than most interpreter language out there. I had replaced all the awk scripts in python and everything is a lot faster. reply mananaysiempre 9 hours agoparent> And performance of awk is crap. [...] I had replaced all the awk scripts in python and everything is a lot faster. My experience points exactly the other way: for data-processing tasks, especially streaming ones, even Gawk is a lot faster than Python (pre-3.11), and apparently I’m not the only one[1]. If you’re not satisfied with Gawk’s performance, though, try Nawk[2] or, even better, Mawk[3]. (And stick to POSIX to ensure your code works in all of them.) [1] https://brenocon.com/blog/2009/09/dont-mawk-awk-the-fastest-... [2] https://github.com/onetrueawk/awk [3] https://invisible-island.net/mawk/ reply LegionMammal978 3 hours agorootparentDo you know of any performance comparisons vs. PyPy? I find it works extremely well as a drop-in replacement for CPython when only the built-in modules are needed, which should generally hold for awk-like use cases. Yet some brief searching doesn't seem to yield any numbers. reply tannhaeuser 11 hours agoparentprevDiscussing performance only makes sense in the context of a particular awk implementation, like TFA is doing as well. If you‘re (stuck) on gawk, try setting LANG=C to prevent Unicode/multi-byte regexp execution, or switch to mawk (which according to [1] is much faster than cpython). [1]: https://brenocon.com/blog/2009/09/dont-mawk-awk-the-fastest-... reply actuallyalys 6 hours agorootparentHonestly only makes sense in the context of a Python library and implementation as well, since so many libraries use C extensions in order to speed up processing. Also, Python has gotten a lot faster over time. reply n4r9 10 hours agoparentprevAwk is blazingly fast for some operations. I remember using it to solve Project Euler problem 67 [0] in a couple of milliseconds, which is more comparable to C/Rust than Python. Weirdly the forum posts from between 2013 and 2023 are missing so I can't see what I wrote there. [0] https://projecteuler.net/problem=67 reply oguz-ismail 11 hours agoparentprev [–] skill issue reply creesch 10 hours agorootparentSure. I do not live in the terminal. But, I work with Linux enough to comfortably navigate around, read various shell scripts with relative ease. With the exception of awk. Which to me signals that, at least in my case, awk has a higher barrier for entry compared to most other things in the same environment. So with alternatives around I can more easily parse myself, I happily concede that I have a skill issue with awk. reply keybored 8 hours agorootparentprevEven the eminent Mr. A., W., and K. had sKiLl isSueS when designing this language, apparently. You can only ask so much from regular programmers. reply watt 10 hours agorootparentprevonce there are more productive alternatives that require less specialized \"skill\", your condescending \"skill issue\" becomes a devex issue, and basically a productivity gap which will doom your language or tool. reply DonHopkins 10 hours agorootparentprev [–] You just need to have the skill to overcome whatever non-technical, legacy, lack of education, or poor judgement issues that are steamrolling you into choosing to use awk instead of a sane rational decent modern efficient maintainable language. reply orwin 8 hours agorootparentTo be fair, sometimes awk is just faster to call. In all other case, as my sibling says, use perl :D reply dotancohen 9 hours agorootparentprev [–] Perl, then? reply mst 7 hours agorootparentThe rule of thumb back at Netcraft was to prototype in awk/sed for brevity/expressiveness and then port to perl for production use for performance reasons. Been a couple decades since I was wrangling the survey systems there though, no idea what it looks like now. reply kragen 6 hours agorootparenti very much appreciate the server surveys; for a time i read the report every month! reply forinti 6 hours agorootparentprev [–] As a dare from a friend I compared my Perl solution to an AWK solution: $time perl -MData::Dumper -ne '$n{length($_)}++; END {print Dumper(%n)}' bigfile.txt $VAR1 = '1088'; $VAR2 = 349647; real 0m1.326s user 0m0.814s sys 0m0.371s $time awk 'length($0) > max { max=length($0) } END { print max }' bigfile.txt 1087 real 0m21.400s user 0m18.596s sys 0m0.455s I prefer Perl, but I have no issue with AWK and I actually use it frequently. reply scbrg 4 hours agorootparent [–] Well. I don't know. Those two programs don't really do the same thing. There's an awful lot of comparisons in the second one. After making the awk program more similar to the Perl program, and using mawk instead of gawk (which is quite a bit slower) the numbers look a bit different: $ seq 100000000 > /tmp/numbers $ time perl -MData::Dumper -ne '$n{length($_)}++; END {print Dumper(%n)}' /tmp/numbers $VAR1 = '7'; $VAR2 = 900000; $VAR3 = '8'; $VAR4 = 9000000; $VAR5 = '5'; $VAR6 = 9000; $VAR7 = '4'; $VAR8 = 900; $VAR9 = '6'; $VAR10 = 90000; $VAR11 = '10'; $VAR12 = 1; $VAR13 = '2'; $VAR14 = 9; $VAR15 = '3'; $VAR16 = 90; $VAR17 = '9'; $VAR18 = 90000000; real 0m16.483s user 0m16.071s sys 0m0.352s $ time mawk '{ lengths[length($0)]++ } END { max = 0; for(l in lengths) if (int(l) > max) max = int(l); print max; }' /tmp/numbers 9 real 0m5.980s user 0m5.493s sys 0m0.457s [edit]: Actually had a bug in the initial implementation. Of course. reply forinti 4 hours agorootparent [–] I used them both to find the longest line in a file. The Perl option just spits out the number of times each line length occurs. It will get messy if you have many different line lengths (which was not my case). You also have to take into account that awk does not count the line terminator. Let's try the opposite: make the Perl script more like the AWK one. $ time perl -ne 'if(length($_)>$n) {$n=length($_)}; END {print $n}' rockyou.txt 286 real 0m2,569s user 0m2,506s sys 0m0,056s $ time awk 'length($0) > max { max=length($0) } END { print max }' rockyou.txt 285 real 0m3,768s user 0m3,714s sys 0m0,048s reply shawn_w 3 hours agorootparent [–] `perl -lne ...` to have perl strip the trailing newlines like awk does. Should give the same result with it. reply forinti 3 hours agorootparent [–] You're right. It even makes the times converge. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Parsing the awk programming language is complex, with its grammar and meaning posing challenges even for yacc experts.",
      "Various awk versions exhibit inconsistencies in parsing, leading to different results for the same code, highlighting ambiguities in the original awk grammar.",
      "Notable figures like Arnold Robbins (gawk maintainer) and Ben Hoyt (goawk) recognize these inconsistencies, attributing them to the deterministic nature of yacc parsing and conflict resolution."
    ],
    "commentSummary": [
      "The discussion highlights the importance of learning Awk for programmers and system administrators, emphasizing its simplicity and efficiency for text manipulation tasks.",
      "Comparisons are made between Awk and other scripting languages like Perl and Python, noting that Awk's concise syntax and built-in availability on Unix-like systems make it particularly useful for quick, one-liner operations.",
      "The conversation also touches on the challenges of parsing languages, with some users advocating for hand-rolled parsers over parser generators like yacc, citing ease of understanding and maintenance."
    ],
    "points": 88,
    "commentCount": 69,
    "retryCount": 0,
    "time": 1725246276
  },
  {
    "id": 41421325,
    "title": "Dublin Core, what is it good for?",
    "originLink": "https://www.thisdaysportion.com/posts/dublin-core-what-is-it-good-for",
    "originBody": "Dublin Core, what is it good for? 01 Sep 2024 …or Schema, microformats or Open Graph? TLDR There are several popular meta schemas out there. Open Graph may be the best supported, but if you want your meta data to be picked up by a particular service you might need to do a bit of research. Or support them all. What’s a meta schema? Meta schemas enable us to embed structured information in web pages, such as articles, blog posts or book reviews. This can include fairly basic information, such as publication date and author, and extended information, such as the publisher, copyright, genre and keywords. Although this information may seem self-evident – you can probably infer the publication date of this post because it sits under the title, for example – schemas make the data easily findable by computers. Furthermore, with some schema implementations, you can add information to your document that you don’t want always want to display on the page, such as copyright. How to add meta schema data to your posts There are a couple of basic ways to add information about your document to the HTML. Add the data to the document head The first, naturally enough, is to add it to the document head. In fact, HTML already has an element made for the purpose – . Add name and content pairs to set meta data. The three non-technical, standard items are description, author and keywords: The highest bestest powered rifleNote: Theelement is a special instance of HTML meta data. As there are not many useful meta name attributes beyond author and description, developers, search engines and academics have written more expressive schemas. I’ll go through these in a bit more detail, but one of them is Dublin Core, which has 22 meta data items, which you can add to the document head in pretty much the same way as the original meta name attributes. In this example, we’ve added language and publication date to the author and description:Sometimes, we can also add meta data to the document head using json wrapped in a element. Schema.org allows this method. In this example, we’re adding information about the publisher and an associated image:{ \"@context\": \"https://schema.org/\", \"@type\": \"Blog\", \"@id\": \"https://www.thisdaysportion.com/\", \"mainEntityOfPage\": \"https://www.thisdaysportion.com/\", \"name\": \"This day’s portion\", \"description\": \"A blog about Aspen life.\", \"publisher\": { \"@type\": \"Organization\", \"@id\": \"https://www.thisdaysportion.com/\", \"name\": \"This day’s portion\", \"logo\": { \"@type\": \"ImageObject\", \"@id\": \"https://www.thisdaysportion.com/images/faust-staves.jpg\", \"url\": \"https://www.thisdaysportion.com/images/faust-staves.jpg\", \"width\": \"600\", \"height\": \"600\" } }, \"blogPost\": [ { \"@type\": \"BlogPosting\", \"@id\": \"https://moriarty.thisdaysportion.com/without.html\", \"mainEntityOfPage\": \"https://www.moriarty.thisdaysportion.com/without.html\", \"headline\": \"The highest bestest powered rifle (no article, no microformats)\", \"name\": \"The highest bestest powered rifle (no article, no microformats)\", \"description\": \"An account of being fired into the stars upon oneâ€™s death.\", \"datePublished\": \"2024-05-01\", \"dateModified\": \"2024-05-02\", \"author\": { \"@type\": \"Person\", \"@id\": \"https://www.thisdaysportion.com/\", \"name\": \"Hunter S Thompson\" }, \"image\": { \"@type\": \"ImageObject\", \"@id\": \"https://www.thisdaysportion.com/images/faust-staves.jpg\", \"url\": \"https://www.thisdaysportion.com/images/faust-staves.jpg\", \"height\": \"600\", \"width\": \"600\" }, \"url\": \"https://moriarty.thisdaysportion.com/without.html\", \"keywords\": [ \"Aspen\", \"Guns\", \"Wild Turkey\" ] } ] } Add the data to the HTML, using attributes or classes Another schema – there’s no easy to use w3 schema for HTML, unfortunately, just XML – is Microformats. You add microformat meta data by using a set of defined classes in your HTML. This time, we’re adding categories and identifying the actual content with the e-content class:The highest bestest powered rifle (with microformats in the HTML) By Hunter S Thompson 1 May 2024…Wild Turkey, Guns, Aspen.Schema.org uses HTML itemscope, itemtype and itemprop attributes instead of classes. Note how the markup can get quite complex when you nest itemtypes – in this case the Person sits within the BlogPosting:The highest bestest powered rifle (Schema in markup) Hunter S Thompson 1 May 2024…Keywords: Guns, Wild Turkey, AspenWhat schemas can I use and how should I add them? As you can tell, you have choices here, whether you want them or not. The main schemas I’m aware of are: Schema.org Microformats Dublin Core Open Graph. This is Meta’s schema that originally enabled Facebook to automatically format any links you’d add to a post, displaying a thumbnail, title and a summary. It’s been adopted by most social media and beyond, and contains a good range of meta items. The HTML defaults The schema you choose will dictate how you add it. Dublin Core and Open Graph add data to the document head while you add microformats with HTML classes. Schema.org can be used in the head and the body. Adding data to the head has the advantage of hiding it from the rendered page. I’d also argue it’s cleaner than mixing it with your HTML, although Schema.org’s json is fussy. Using classes instead of attributes strikes me as a failure to separate semantics from styling, although I appreciate this is a mainly hypothetical problem. Ideally, I’d just use Dublin Core as it’s placed in the head and is a simple list of names and content. Unfortunately, your choice doesn’t have much to do with ease of use. Depending on what you want to achieve, you may have to use more than one schema. Where are schemas used and how? This is where it gets complicated. So far, we’ve looked at how we add various schemas to our documents without considering how this meta data will actually be used. Some popular uses for meta data are: In read-it-later services, such as Pocket, Instapaper and Omnivore In Google search and social media link snippets In academic services, such as Zotero, a reference and bibliography app. You can add a web page to Zotero and and it will use the schema meta data to create a bibliographic reference. Because there are several schemas and no “official” version, these services are free to adopt whichever they want. To further muddy things, they can also choose how they interpret meta data. To get some insight into how schemas are used in the real world, I ran a few tests by feeding three of the above services different versions of the same document: One with no schemas beyond the basic HTML defaults One marked up with microformats in the HTML One with Schema.org json added to the head One with Schema.org itemprop attributes in the HTML One with Dublin Core meta elements in the head One with Open Graph meta elements in the head Support across the services varied. Instapaper Schema Support Plain HTML Partial. Just the title from the title element. Microformats No Dublin Core No Open Graph Partly. Just the title and the article listing image. Schema json No Schema HTML Yes As you can see, Instapaper only has partial support for the various schemas. Interestingly, it takes the Open Graph title over the document’s . Schema.org is supported, but only when it’s added to the HTML using itemprop attributes. Omnivore Schema Support Plain HTML Partial. It is able to get the date from the raw HTML. Uses the title element. Microformats Yes Dublin Core Yes Open Graph Just the image. Schema json Yes Schema HTML Yes Omnivore is a good meta data citizen, providing support for the main schemas, including Schema.org’s json. Zotero Schema Support Plain HTML Partial. Just the title from the title element. Microformats No Dublin Core Yes Open Graph Yes, including date Schema json No Schema HTML No I’d guess that Zotero’s choice of meta schemas is a reflection of its age and library background: Dublin Core’s development predates Schema.org and Microformats. It’s interesting that it has made a nod to modern developments (the meta data world turns reassuringly slowly) by supporting Open Graph. A note on social media and search results I didn’t test extensively across social media as I don’t have Twitter, Facebook or Instagram accounts. Open Graph is the accepted meta data standard here, which you can use when linking to a page. Here’s an example of how Pinafore, a Mastodon app, creates a formatted link to a web page when you toot its URL: And the BBC web page head Open Graph markup that Pinafore uses:Although Google purports to use its own Schema.org data to construct objects like cards in its search results, the only semi reliable meta items are the pageand the , which are used in results snippets: So what schema(s) should I use? Sorry to disappoint, but the answer is it depends. Your document will need a . Some services demand a particular schema. If you want to send webmentions, you have to use microformats. Zotero – which is widely used across universities – requires Dublin Core or Open Graph. If you want a formatted link to your post on social media, you’ll need Open Graph. I was quite surprised by the extent to which Open Graph has been adopted by other services. If you were just going to choose one, this is maybe the one I’d suggest. For some semblance of control of search snippets, add a . If you’re supporting Schema.org and only want to implement it in one way, itemprop attributes in the body have better support in my small sample. The problem is there are several schemas out there, and many services of varying ages. To cover everything you’d need to add a lot of meta data. — Leon Paternoster. Got a question or comment? Get in touch. Email mail@thisdaysportion.com, or try me on micro.blog or Mastodon. HTML ← Previous post ’s good for SEO 28 Aug 2024",
    "commentLink": "https://news.ycombinator.com/item?id=41421325",
    "commentBody": "Dublin Core, what is it good for? (thisdaysportion.com)88 points by MrVandemar 19 hours agohidepastfavorite28 comments dmje 13 hours agoDC was massive in museums in the 90s. I think there are still remnant uses today - stuff like schema is a good reason for thinking about on-page metadata and dc was a part of that. I was involved with a gov / lottery funded series of projects called “New Opportunities Fund” [0] which mandated DC markup. The exciting idea for us at the time was that we’d be able to create simple cross-site searchable assets. So we (I was at The Science Museum at the time) could create our project with 30k museum records in it, the NHM could make theirs and then ultimately someone could make a “portal” (ah, the 90s phrases are flooding back…) where users could search across all the NOF funded sites. To the best of my knowledge the portal part was never made - we all did the dc bit but nothing global emerged from NOF. There is (to this day) a conversation about how to allow this sort of interop across museum data. On the one side are SemWeb types, on the other lightweight microformat types. I’m massively over simplifying - but this is sort of how it goes. I’ve always been fairly much in the latter camp. DC and microformats are incredibly crude - when you say an object has a “date” for example it clearly needs qualifying. Date it was made? Found? Used? Bought? Etc… - BUT to me it’s better to have this crude description than the alternative which is some kind of deeply complex (and thus never to be agreed / implemented across tens/hundreds/thousands of museums) sort of “perfect” standard. Of course nowadays much of this is made irrelevant by good search, and the way the majority of people search the web. A general audience doesn’t actually want to search for all paintings made by x artist on y date - and when they do they’re content (for good or bad) to settle with Google results. And I guess AI will help. Maybe. There are still a lot of data interop projects in museums and cultural heritage - stuff like the Museums Data Service [1] is brand new, TANC [2] has been going a while - and many more out there. [0] https://www.gov.uk/government/organisations/new-opportunitie... [1] https://museumdata.uk/ [2] https://www.nationalcollection.org.uk/ reply cratermoon 1 hour agoparent> much of this is made irrelevant by good search Perhaps we're seeing a resurgence of interesting in good metadata as a result of the decline in quality of search? > A general audience doesn’t actually want to search for all paintings made by x artist on y date This a common fate of cataloging systems: they are made by archivists, for archivists. Most people aren't archivists, they are looking for something in the context of their particular use for the information. Sönke Ahrens in his book \"How to Take Smart Notes\" says, \"Do they wonder where to store a note or how to retrieve it? The archivist asks: Which keyword is the most fitting? A writer asks: In which circumstances will I want to stumble upon this note, even if I forget about it? It is a crucial difference.\" reply tejtm 11 hours agoprevWell it still just got my eye twitching. Not really Dublin core itself, it is one of the more sedate ontologies. But to keep up with the pack they did err, refine and expand into \"terms\" and \"elements\" but not cleanly so we will forever have the same labels for nodes in different Dublin core name spaces. You can have academic reasons till the cows come home but the bottom line is: You had one job. ``` The four DCMI namespaces are: http://purl.org/dc/elements/1.1/ The /elements/1.1/ namespace was created in 2000 for the RDF representation of the fifteen-element Dublin Core and has been widely used in data for more than twenty years. This namespace corresponds to the original scope of ISO 15836, which was published first in 2003 and last revised in 2017 as ISO 15836-1:2017 [ISO 15836-1:2017. http://purl.org/dc/terms/ The /terms/ namespace was originally created in 2001 for identifying new terms coined outside of the original fifteen-element Dublin Core. In 2008, in the context of defining formal semantic constraints for DCMI metadata terms in support of RDF applications, the original fifteen elements themselves were mirrored in the /terms/ namespace. As a result, there exists both a dc:date (http://purl.org/dc/elements/1.1/date) with no formal range and a corresponding dcterms:date (http://purl.org/dc/terms/date) with a formal range of \"literal\". While these distinctions are significant for creators of RDF applications, most users can safely treat the fifteen parallel properties as equivalent. The most useful properties and classes of DCMI Metadata Terms have now been published as ISO 15836-2:2019 [ISO 15836-2:2019]. While the /elements/1.1/ namespace will be supported indefinitely, DCMI gently encourages use of the /terms/ namespace. http://purl.org/dc/dcmitype/ The /dcmitype/ namespace was created in 2001 for the DCMI Type Vocabulary, which defines classes for basic types of thing that can be described using DCMI metadata terms. http://purl.org/dc/dcam/ The /dcam/ namespace was created in 2008 for terms used in the description of DCMI metadata terms. ``` reply JKCalhoun 17 hours agoprevI only knew of Dublin Core as it relates to image metadata. I was told it was popular among photo-journalists (it has tags: publisher, keyword, creator). The more nerdy EXIF metadata is what the camera often provides and tells you about how the image was taken (f-stop, shutter speed), not who or what. reply ofrzeta 15 hours agoparentNot \"who\" or \"what\" but \"where\" can also be saved in the EXIF data. reply SSLy 5 hours agorootparentPhotographer entry can be done in camera-specific section, it's recognized by a lot of parsers reply mschuster91 11 hours agorootparentprevNow if there were some universal standard for embedding alt-texts into a picture that would also survive right-click \"copy image\" and paste-uploading... not just for social media (where you'll get blasted for forgetting one even just one time) but also for websites and newspapers where the image description has to be edited manually in a CMS and is, again, not attached to the picture itself... reply edent 7 hours agorootparentThere is. The problem is that automatically attached alt-text isn't particularly useful. You don't know what the intention is of an image. Is it of a banana? A specific banana? The sticker on the banana? https://shkspr.mobi/blog/2023/07/should-you-embed-alt-text-i... And, no, this isn't something which AI can help with. https://tink.uk/thoughts-on-screen-readers-and-image-recogni... reply qingcharles 2 hours agorootparentFantastic articles, thank you. I work with alt text a lot. I used a hinted LLM prompt for the first pass, and then I edit if needs be. Sometimes it misses obvious details, other times it sees things (most) human eyes would never see. Like all tools, just have to be careful how you use it. reply gnz11 5 hours agoparentprevI think most of the news media has long switched to IPTC meta data. reply JKCalhoun 4 hours agorootparentYou're right and I am wondering now if I was confusing IPTC with Dublin Core. (Oops.) reply anotherhue 17 hours agoprevNamed for Dublin, Ohio in case you were wondering. No need for comments about the deterioration of O'Connell St. reply deepfriedbits 16 hours agoparentAssume it's connected to OCLC, the Ohio Library College Center, in Dublin? reply dredmorbius 12 hours agorootparentYes: OCLC’s research staff were instrumental in the development of the initiative, starting with a hallway conversation at the 2nd International World Wide Web Conference in late 1994. OCLC researchers Stuart Weibel and Eric Miller, OCLC Office of Research Director Terry Noreault, Joseph Hardin of the National Center for Supercomputing Applications (NCSA), and the late Yuri Rubinsky of SoftQuad, were remarking about the difficulty of finding resources on the Web. Their discussion provided the impetus for development of the Dublin Core Metadata Element Set, now known simply as “Dublin Core,” now an international metadata standard.reply defrost 14 hours agoparentprevI was hoping it was a genre to rival the Limerick Grind of the Rubber Bandits. reply PaulHoule 18 hours agoprevI first encountered Dublin Core when I was working at a big university library. My take was it was an embarrassment compared to the 1970 MARC standard https://en.wikipedia.org/wiki/MARC_standards that it was more of what you'd expect from an elementary school library as opposed to a university library. Specifically it never implemented a way to (1) use authority records and (2) specify the order of the authors. It was the kind of thing that wrecked people's perception of \"the semantic web\" before it even got started. reply Spartan-S63 16 hours agoparentAt the same time, it seems like in some circles Dublin Core is what got metadata standardization started. I encountered it as an older format in the mid-2010s when working on data discoverability for geospatial datasets. At the time, we were emitting Dublin Core as one format for our datasets in the archive. We were actively transitioning to supporting a more fully featured FGDC format as well as diving into the ISO 19115 standard and translating to that. In all, I think Dublin Core was, at one point, useful. However, metadata standards have moved forward with more specialized schemas that are more useful for discoverability. reply ggm 17 hours agoparentprevI also was massively disappointed. I think it was the \"we dont want to argue so lets put the least argumentative join over everything said in the room that one time\" outcome. If you ever play with date-time in images, and dive into EXIF date-time encoding you enter the door of \"yes, we know people need to say \"around 1800\" but we've decided not to make a canonical system for indicating approximate dates, ante- or post- dates, or the necessary mapping into YYYY-MM-DD:HH:MM:SS so instead you can come up with your own non-standard\" And a lot of the discussion points back to the DC reply knadh 15 hours agoprevOmeka-S[1] is an open source publishing platform (for museums, libraries, artifact collections etc) that has first class support for Dublin Core. Dublin Core “clicked” for me when we started using it in Omeka to publish a collection of digitised books online[2]. - https://omeka.org - https://gpura.org reply aorth 11 hours agoprevDublin Core is the main metadata schema for many institutional repositories, for example the DSpace platform https://github.com/DSpace/dspace. The schema essentially only covers basic bibliographic metadata and has a strong pre-digital library feel to it. We end up augmenting with other custom schemas to be able to describe content in our repository, for example podcasts and journal articles with different issue and online dates, as well as extra metadata like author affiliations, funders, internal programs etc. reply rjsw 7 hours agoprevIf you are adding metadata to a schema then you may as well copy Dublin Core instead of creating your own incompatible equivalent from scratch. reply kkfx 2 hours agoprevA summary: it's a successfully failed idea we can reach a day something like semantic search thanks to carefully written metadata, or we can classify anything to make anything easy to retrieve as a single information atom (a book, a report, a map) or even inside it finding just the bit of information we look for not in a single atom but across many. Another Library of Babels/Biblioteca universalis by Conrad Gessner (~1545). Unfortunately while in theory the system could work we can't ensure anyone use is WELL in practice and just some metadata to classify anything in a coherent way it's far from being enough. DC was an immense diplomatic effort in library science still with a damn limited practical outcome. reply turnsout 16 hours agoprevI’ve been asking this question for literally 20 years and still haven’t come up with any answer. I’d love to support it, but… why? reply riffraff 14 hours agoparentThe article gives a simple reason: some things support it. If you want nice snippets in google search, Instagram, zotero etc.. you can use it. The real reason was always \"so you can publish data people can use programmatically\" but turns out this doesn't work cause the interest of publishers (\"visit my site\") and the interest of consumers (\"I want an answer\") are not aligned. reply astrange 15 hours agoparentprevIt seemed people in the 2000s had some sort of mystical belief about computers that if you took all your data and put it in some kind of XML format it would give you good karma. reply porker 13 hours agorootparentWe did. I don't think we comprehended how others would use it for their own commercial gain. reply todfox 3 hours agoprevAbsolutely nothin'! reply westurner 4 hours agoprev [–] Do regular search engine index DCMI dcterms:? Doe Google Scholar or Google Search index schema.org/CreativeWork yet? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Meta schemas like Open Graph, Schema.org, microformats, and Dublin Core embed structured information in web pages, making data easily findable by computers.",
      "Open Graph is widely adopted by social media, while Schema.org is preferred for Google search snippets; using multiple schemas may be necessary depending on the service.",
      "Meta schemas are used in read-it-later services, social media snippets, and academic services, with varying levels of support across different platforms."
    ],
    "commentSummary": [
      "Dublin Core (DC) was pivotal in the 90s for metadata and schema in museums, aiming for cross-site searchable assets, but a global portal never materialized.",
      "Today, there's a debate between using complex standards and simpler microformats, with good search engines and AI reducing the need for detailed metadata.",
      "DC remains relevant in projects like the Museums Data Service and TANC, and is used in platforms like Omeka-S and DSpace, despite its practical implementation being limited."
    ],
    "points": 88,
    "commentCount": 28,
    "retryCount": 0,
    "time": 1725234904
  }
]
